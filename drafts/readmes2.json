{"language":{"0":"GLSL","1":"PowerShell","2":"Python","3":"JavaScript","4":"PHP","5":"Python","6":"Python","7":"Python","8":"Python","9":"C","10":"HTML","11":"Jupyter Notebook","12":"Shell","13":"Python","14":"R","15":"Shell","16":"Java","17":"C++","18":"C++","19":"Haskell","20":"Fortran","21":"MATLAB","22":"HTML","23":"R","24":"Java","25":"HTML","26":"HTML","27":"Java","28":"Jupyter Notebook","29":"HTML","30":"Jupyter Notebook","31":"HTML","32":"Java","33":"Java","34":"Jupyter Notebook","35":"Python","36":"Java","37":"HTML","38":"Jupyter Notebook","39":"JavaScript","40":"PHP","41":"Jupyter Notebook","42":"Python","43":"Python","44":"Python","45":"Python","46":"C","47":"Jupyter Notebook","48":"JavaScript","49":"HTML","50":"HTML","51":"Eagle","52":"C","53":"Ruby","54":"Python","55":"Jupyter Notebook","56":"Python","57":"OpenSCAD","58":"JavaScript","59":"R","60":"Python","61":"Shell","62":"C#","63":"Ruby","64":"Rust","65":"Ruby","66":"R","67":"C#","68":"Makefile","69":"Go","70":"Python","71":"HTML","72":"Ruby","73":"R","74":"C","75":"CSS","76":"Python","77":"Python","78":"R","79":"C++","80":"HTML","81":"Python","82":"PHP","83":"Java","84":"JavaScript","85":"nesC","86":"JavaScript","87":"Diff","88":"HTML","89":"Python","90":"HTML","91":"TeX","92":"Go","93":"Jupyter Notebook","94":"R","95":"Jupyter Notebook","96":"Python","97":"R","98":"C++","99":"Java","100":"Dockerfile","101":"Jupyter Notebook","102":"Jupyter Notebook","103":"Python","104":"Python","105":"Java","106":"R","107":"HTML","108":"JavaScript","109":"C++","110":"C++","111":"Jupyter Notebook","112":"C++","113":"R","114":"Jupyter Notebook","115":"Jupyter Notebook","116":"R","117":"Fortran","118":"JavaScript","119":"Shell","120":"JavaScript","121":"Python","122":"Python","123":"Python","124":"Python","125":"HTML","126":"Squirrel","127":"Python","128":"R","129":"Other","130":"Jupyter Notebook","131":"Jupyter Notebook","132":"Lua","133":"R","134":"HTML","135":"R","136":"Python","137":"Java","138":"Ballerina","139":"HTML","140":"PHP","141":"JavaScript","142":"Java","143":"Python","144":"VBA","145":"Jupyter Notebook","146":"R","147":"Clojure","148":"R","149":"JavaScript","150":"R","151":"C","152":"C++","153":"Python","154":"Python","155":"C++","156":"Python","157":"Shell","158":"R","159":"Nu","160":"Python","161":"PHP","162":"Python","163":"C++","164":"Jupyter Notebook","165":"JavaScript","166":"Other","167":"Jupyter Notebook","168":"Python","169":"Jupyter Notebook","170":"Jupyter Notebook","171":"Java","172":"HTML","173":"JavaScript","174":"C++","175":"R","176":"R","177":"Python","178":"Fortran","179":"C#","180":"C++","181":"Python","182":"C++","183":"Java","184":"Python","185":"Jupyter Notebook","186":"C++","187":"JavaScript","188":"R","189":"Python","190":"Julia","191":"NCL","192":"Java","193":"JavaScript","194":"HTML","195":"C++","196":"CSS","197":"Python","198":"C","199":"JavaScript","200":"HTML","201":"CoffeeScript","202":"PHP","203":"PHP","204":"Python","205":"Ruby","206":"Python","207":"JavaScript","208":"Python","209":"R","210":"PHP","211":"JavaScript","212":"C++","213":"R","214":"Python","215":"R","216":"Java","217":"R","218":"C++","219":"PHP","220":"Jupyter Notebook","221":"PHP","222":"Elixir","223":"C++","224":"Python","225":"Python","226":"HTML","227":"R","228":"Clojure","229":"Dart","230":"C++","231":"C++","232":"Python","233":"Jupyter Notebook","234":"Java","235":"HTML","236":"Python","237":"R","238":"Jupyter Notebook","239":"Ruby","240":"Jupyter Notebook","241":"Python","242":"C","243":"ActionScript","244":"Python","245":"Swift","246":"CoffeeScript","247":"R","248":"JavaScript","249":"JavaScript","250":"C++","251":"Python","252":"Python","253":"Python","254":"HTML","255":"HTML","256":"C++","257":"MATLAB","258":"Python","259":"Eagle","260":"JavaScript","261":"Jupyter Notebook","262":"Go","263":"R","264":"C++","265":"JavaScript","266":"Python","267":"R","268":"Jupyter Notebook","269":"Python","270":"C#","271":"JavaScript","272":"Jupyter Notebook","273":"C++","274":"JavaScript","275":"C#","276":"HTML","277":"R","278":"R","279":"Vue","280":"C++","281":"Jupyter Notebook","282":"Jupyter Notebook","283":"C++","284":"Python","285":"JavaScript","286":"R","287":"Python","288":"Python","289":"Java","290":"Python","291":"C++","292":"JavaScript","293":"JavaScript","294":"HTML","295":"Python","296":"JavaScript","297":"Jupyter Notebook","298":"TypeScript","299":"HTML","300":"Python","301":"C","302":"R","303":"Shell","304":"Python","305":"JavaScript","306":"C++","307":"Python","308":"Python","309":"Python","310":"Erlang","311":"Python","312":"Swift","313":"JavaScript","314":"HTML","315":"JavaScript","316":"Python","317":"Jupyter Notebook","318":"HTML","319":"Jupyter Notebook","320":"HTML","321":"C++","322":"Python","323":"Go","324":"Go","325":"R","326":"JavaScript","327":"Python","328":"Python","329":"HTML","330":"Other","331":"Python","332":"JavaScript","333":"Python","334":"C++","335":"JavaScript","336":"JavaScript","337":"JavaScript","338":"R","339":"Python","340":"JavaScript","341":"PHP","342":"PHP","343":"C","344":"PHP","345":"C#","346":"Python","347":"JavaScript","348":"C#","349":"JavaScript","350":"R","351":"R","352":"JavaScript","353":"JavaScript","354":"JavaScript","355":"Prolog","356":"Other","357":"Other","358":"JavaScript","359":"Other","360":"Eagle","361":"R","362":"Python","363":"Python","364":"Python","365":"Java","366":"Java","367":"JavaScript","368":"JavaScript","369":"R","370":"JavaScript","371":"Java","372":"HTML","373":"CSS","374":"Java","375":"Python","376":"Jupyter Notebook","377":"R","378":"HTML","379":"R","380":"Jupyter Notebook","381":"Java","382":"JavaScript","383":"Roff","384":"R","385":"Objective-C","386":"C++","387":"C++","388":"TeX","389":"JavaScript","390":"R","391":"R","392":"JavaScript","393":"JavaScript","394":"Java","395":"Python","396":"JavaScript","397":"Jupyter Notebook","398":"Fortran","399":"JavaScript","400":"CoffeeScript","401":"C++","402":"TypeScript","403":"R","404":"Java","405":"JavaScript","406":"Other","407":"RPC","408":"Python","409":"Other","410":"C#","411":"Python","412":"JavaScript","413":"C#","414":"C++","415":"Python","416":"Shell","417":"Python","418":"JavaScript","419":"CSS","420":"R","421":"C++","422":"R","423":"Python","424":"Shell","425":"HTML","426":"HTML","427":"Python","428":"R","429":"Jupyter Notebook","430":"MATLAB","431":"Python","432":"R","433":"Ruby","434":"Shell","435":"R","436":"Vim script","437":"Java","438":"Fortran","439":"Jupyter Notebook","440":"C++","441":"HTML","442":"Python","443":"Kotlin","444":"Python","445":"Python","446":"Python","447":"C++","448":"JavaScript","449":"Perl","450":"MATLAB","451":"Rust","452":"R","453":"R","454":"PHP","455":"C++","456":"Java","457":"Batchfile","458":"HTML","459":"R","460":"Ruby","461":"Ruby","462":"Jupyter Notebook","463":"Ruby","464":"HTML","465":"Ruby","466":"R","467":"JavaScript","468":"R","469":"C#","470":"Python","471":"Shell","472":"Java","473":"Jupyter Notebook","474":"Python","475":"C#","476":"Java","477":"JavaScript","478":"C++","479":"CSS","480":"Jupyter Notebook","481":"Jupyter Notebook","482":"Java","483":"Java","484":"PowerShell","485":"C#","486":"C++","487":"Java","488":"PowerShell","489":"Objective-C","490":"Java","491":"Python","492":"Jupyter Notebook","493":"Java","494":"Java","495":"C#","496":"C++","497":"C#","498":"C#","499":"Python","500":"Jupyter Notebook","501":"C","502":"Java","503":"CSS","504":"C#","505":"Ruby","506":"C++","507":"C#","508":"Python","509":"Java","510":"JavaScript","511":"Java","512":"JavaScript","513":"Java","514":"R","515":"C#","516":"Java","517":"Other","518":"CSS","519":"HTML","520":"Ruby","521":"JavaScript","522":"Java","523":"R","524":"C++","525":"C#","526":"Java","527":"CSS","528":"Java","529":"HTML","530":"Python","531":"HTML","532":"JavaScript","533":"R","534":"C#","535":"C++","536":"Python","537":"C++","538":"Vue","539":"JavaScript","540":"Java","541":"Python","542":"R","543":"C","544":"HTML","545":"Python","546":"HTML","547":"Python","548":"CSS","549":"Python","550":"Java","551":"MATLAB","552":"JavaScript","553":"Python","554":"Python","555":"Python","556":"C#","557":"Java","558":"C++","559":"MATLAB","560":"C++","561":"JavaScript","562":"Java","563":"Java","564":"Shell","565":"JavaScript","566":"R","567":"PHP","568":"Python","569":"Scala","570":"HTML","571":"C","572":"JavaScript","573":"JavaScript","574":"R","575":"HTML","576":"R","577":"Python","578":"Python","579":"Python","580":"Java","581":"PHP","582":"HTML","583":"Other","584":"R","585":"Java","586":"Java","587":"Java","588":"Jupyter Notebook","589":"JavaScript","590":"R","591":"BlitzBasic","592":"HTML","593":"CSS","594":"C#","595":"C++","596":"C#","597":"Jupyter Notebook","598":"Python","599":"Java","600":"JavaScript","601":"JavaScript","602":"Java","603":"JavaScript","604":"Java","605":"C++","606":"JavaScript","607":"HTML","608":"Processing","609":"JavaScript","610":"Java","611":"C","612":"HTML","613":"C","614":"HTML","615":"Python","616":"Jupyter Notebook","617":"C#","618":"Lua","619":"Jupyter Notebook","620":"Java","621":"JavaScript","622":"TeX","623":"C","624":"Python","625":"Python","626":"MATLAB","627":"JavaScript","628":"JavaScript","629":"Python","630":"R","631":"Swift","632":"Swift","633":"C","634":"MATLAB","635":"Java","636":"Java","637":"JavaScript","638":"Python","639":"R","640":"Vim script","641":"C#","642":"Java","643":"Python","644":"C++","645":"Jupyter Notebook","646":"Go","647":"JavaScript","648":"Python","649":"C++","650":"JavaScript","651":"Kotlin","652":"Python","653":"JavaScript","654":"Python","655":"Python","656":"Shell","657":"Vue","658":"Batchfile","659":"JavaScript","660":"R","661":"Python","662":"R","663":"Vim script","664":"HTML","665":"Python","666":"Python","667":"JavaScript","668":"R","669":"Python","670":"TeX","671":"Go","672":"C++","673":"Shell","674":"Java","675":"HTML","676":"Java","677":"CSS","678":"HTML","679":"PHP","680":"HTML","681":"Go","682":"C++","683":"Elixir","684":"MATLAB","685":"C++","686":"JavaScript","687":"Ruby","688":"Ruby","689":"R","690":"Python","691":"JavaScript","692":"HTML","693":"Python","694":"HTML","695":"Ruby","696":"Java","697":"HTML","698":"Vue","699":"Java","700":"JavaScript","701":"Objective-C","702":"C#","703":"Swift","704":"JavaScript","705":"Python","706":"Python","707":"PHP","708":"PHP","709":"MATLAB","710":"C++","711":"Roff","712":"C++","713":"MATLAB","714":"TypeScript","715":"JavaScript","716":"HTML","717":"Lua","718":"TypeScript","719":"TypeScript","720":"TypeScript","721":"CSS","722":"JavaScript","723":"JavaScript","724":"HTML","725":"Java","726":"HTML","727":"CSS","728":"Stata","729":"HTML","730":"C","731":"Ruby","732":"Python","733":"TeX","734":"HTML","735":"JavaScript","736":"Vue","737":"HTML","738":"Java","739":"JavaScript","740":"JavaScript","741":"Java","742":"JavaScript","743":"Python","744":"CSS","745":"Python","746":"Python","747":"TeX","748":"Python","749":"JavaScript","750":"Python","751":"HTML","752":"HTML","753":"HTML","754":"JavaScript","755":"HTML","756":"JavaScript","757":"PHP","758":"JavaScript","759":"HTML","760":"C#","761":"HTML","762":"MATLAB","763":"HTML","764":"TeX","765":"R","766":"C++","767":"HTML","768":"JavaScript","769":"HTML","770":"R","771":"Jupyter Notebook","772":"TypeScript","773":"C++","774":"TeX","775":"HTML","776":"JavaScript","777":"R","778":"CoffeeScript","779":"HTML","780":"Mathematica","781":"HTML","782":"Python","783":"PHP","784":"HTML","785":"PHP","786":"HTML","787":"Jupyter Notebook","788":"C++","789":"Jupyter Notebook","790":"TypeScript","791":"C++","792":"HTML","793":"JavaScript","794":"TeX","795":"C++","796":"TypeScript","797":"C++","798":"MATLAB","799":"C++","800":"C#","801":"JavaScript","802":"Python","803":"HTML","804":"Assembly","805":"CSS","806":"HTML","807":"JavaScript","808":"Jupyter Notebook","809":"Java","810":"R","811":"HTML","812":"Python","813":"Python","814":"Jupyter Notebook","815":"Other","816":"PHP","817":"JavaScript","818":"Go","819":"TeX","820":"Python","821":"Java","822":"Jupyter Notebook","823":"Go","824":"C","825":"TeX","826":"C++"},"content":{"0":"EnvironmentalVisualEnhancements\nVisual enhancements including clouds, lights, etc.\nSome portions of this project are under the GNU General Public License (DDS texture loader)\nand should be distributed as-such. This project was added to replace the functionality of the\ntexture importer that would normally be able to perform this task upon loading the textures, but\nwas unavailable to modders.\nThe remainder of the project is under the following license:\nThe MIT License (MIT)\nCopyright (c) 2013 Ryan Bray\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and\/or sell copies of\nthe Software, and to permit persons to whom the Software is furnished to do so,\nsubject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\nFOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\nIN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\nCONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n","1":"dbachecks\n\ndbachecks is a framework created by and for SQL Server pros who need to validate their environments. Basically, we all share similar checklists and mostly just the server names and RPO\/RTO\/etc change.\nThis open source module allows us to crowd-source our checklists using Pester tests. Such checks include:\n\nBackups are being performed\nIdentity columns are not about to max out\nServers have access to backup paths\nDatabase integrity checks are being performed and corruption does not exist\nDisk space is not about to run out\nAll enabled jobs have succeeded\n\nInteractive dbachecks PowerShell Notebooks for Azure Data Studio\nYou can find a set of interactive PowerShell Notebooks which will introduce you to all of the core concepts in Robs GitHub. There is a set of .NET interactive Jupyter Notebooks\nhttps:\/\/github.com\/SQLDBAWithABeard\/JupyterNotebooks\/tree\/master\/notebooks\/dotNETNotebooks\/dbachecks\nand a set of Jupyter Notebooks that will run in Azure Data Studio\nhttps:\/\/github.com\/SQLDBAWithABeard\/JupyterNotebooks\/tree\/master\/notebooks\/NotDotNet\/dbachecks\nBoth will use a docker container to show you how dbachecks works.\nThere is a zip file containing the Notebooks here\nhttps:\/\/github.com\/SQLDBAWithABeard\/Presentations\/raw\/master\/Notebooks\/dbachecks\/Notebooks.zip\nHave questions about development? Please visit our Wiki. Anyone developing this module should visit that Wiki page (after fully reading this readme) for a brief overview.\nBuild Status\n\n\n\n\nDevelopment Branch Build - Unit testing Click Here\n\n\n\nMaster Branch Build - Module version update and Code Signing Click Here\n\n\n\nMaster Branch Release - Release to PowerShell Gallery Click Here\n\n\n\nWant to know how our CD process works? Read this blog post and see how the team manage it\nPrerequisites\nClient requirements\n\nPowerShell 5 + is required.\nAutomatic installation of the dependent modules will only be provided via the PowerShell Gallery.\n\nWhen you install from the Gallery, it'll auto-install:\n\ndbatools\nPester\nPSFramework\n\nWhen you import, it'll auto-import\n\ndbatools\nPester\nPSFramework\n\nIf you have already installed the module and you update it, you may be required to update the Pester or the PSFramework modules before it will import. If you see a message like\n\nThen you need to\nInstall-Module Pester -SkipPublisherCheck -Force\nImport-Module Pester -Force\n\nYou may need to do the same thing for the PSFramework or dbatools modules also\nSQL requirements\ndbachecks uses dbatools for most of it's data gathering so it supports SQL Versions from SQL 2000 to SQL vNext including SQL running on Linux. (dbachecks will not install on PowerShell Core yet so can not be run on a Linux client) Obviously some of the Services and disk space checks will not work against instances running on Linux as they are using gWindows API calls.\nGetting started\nChecks are performed using Invoke-DbcCheck which is basically a wrapper for Invoke-Pester. This means that supported Invoke-Pester parameters work against Invoke-DbcCheck.\nIn this module, a \"Check\" is synonymous with a \"Tag\" in Pester. So you can Invoke-DbcCheck and specify a Check that you want to run. You can see a list of the available Checks with Get-DbcCheck.\n\nOnce you've decided on the Check(s) you want to run, it's time to ensure you have a list of servers to run the checks against.\nMaking server lists\nSimilar to the dbatools module, dbachecks accepts -SqlInstance and -ComputerName parameters.\nInvoke-DbcCheck -SqlInstance $servers -Checks SuspectPage, LastBackup\nIf you have a simplified (single) environment, however, you can set a permanent list of servers. \"Servers\" include both SQL Server instances and Windows servers. Checks that access Windows Server (e.g. disk space checks) will utilize -ComputerName parameter. A pure SQL Server command(s) (such as the backup check) utilizes the -SqlInstance parameter.\n# Set the servers you'll be working with\nSet-DbcConfig -Name app.sqlinstance -Value sql2016, sql2017, sql2008, sql2008\\express\nSet-DbcConfig -Name app.computername -Value sql2016, sql2017, sql2008\n\n# Look at the current configs\nGet-DbcConfig\n\n# Invoke a few tests\nInvoke-DbcCheck -Checks SuspectPage, LastBackup\nWhat it looks like\n\nOther ways to execute checks against specific servers\nAdditional Invoke-DbcCheck examples:\nInvoke-DbcCheck -Check Backup -SqlInstance sql2016\nInvoke-DbcCheck -Check RecoveryModel -SqlInstance sql2017, sqlcluster\n\n$sqlinstance = Get-DbaRegisteredServer -SqlInstance sql2017 -Group Express\nInvoke-DbcCheck -Check Backup -SqlInstance $sqlinstance\n\nInvoke-DbcCheck -Check Storage -ComputerName server1, server2\nCheck and ExcludeCheck\nWe tag each of our Checks using singular descriptions such as Backup, Database or Storage. You can see all the Pester related Tags using Get-DbcTagCollection or Get-DbcCheck.\nEach Check generally has a few Tags but at least one Tag is unique. This allows us to essentially name a Check and using these Tags, you can either include (-Check) or Exclude (-ExcludeCheck) in your results. The Exclude will always take precedence.\nFor example, the Database Tag runs a number of Checks including Backup Checks. The command below will run all Database Checks except for the Backup Checks.\nInvoke-DbcCheck -Check Database -ExcludeCheck Backup -SqlInstance sql2016 -SqlCredential (Get-Credential sqladmin)\nAll valid Pester syntax is valid for dbachecks so if you'd like to know more, you can review their documentation.\nReporting on the data\nSince this is just PowerShell and Pester, results can be exported then easily converted to pretty reports. We've provided two options: Power BI and SMTP mail.\nPower BI Visualizations!\nWe've also included a pre-built Power BI Desktop report! You can download Power BI Desktop from here or it is now offered via the Microsoft Store on Windows 10.\nNote: We strongly recommend that you keep your PowerBI Desktop updated since we can add brand-new stuff that appears on the most recent releases.\nTo use the Power BI report, pipe the results of Invoke-DbcCheck to Update-DbcPowerBiDataSource (defaults to C:\\Windows\\temp\\dbachecks), then launch the included dbachecks.pbix file using Start-DbcPowerBi. Once the Power BI report is open, just hit refresh.\n# Run checks and export its JSON\nInvoke-DbcCheck -SqlInstance sql2017 -Checks SuspectPage, LastBackup -Show Summary -PassThru | Update-DbcPowerBiDataSource\n\n# Launch Power BI then hit refresh\nStart-DbcPowerBi\n\nThe above report uses Update-DbcPowerBiDataSource's -Environment parameter.\n# Run checks and export its JSON\nInvoke-DbcCheck -SqlInstance $prod -Checks LastBackup -Show Summary -PassThru | \nUpdate-DbcPowerBiDataSource -Environment Prod\n\ud83d\ude0d\ud83d\ude0d\ud83d\ude0d\nSending mail\nWe even included a command to make emailing the results easier!\n$outputDirectory = (Get-DbcConfigValue -Name app.maildirectory)\n$filename = $outputDirectory + '\\file.xml'\nInvoke-Dbccheck -OutputFile $fileName -OutputFormat NunitXML\n\n$outputpath = $outputDirectory + \"\\index.html\"\n$reportunit = \"ModulePath\\bin\\ReportUnit.exe\"\n& $reportunit $outputDirectory\n\n$htmlbody = Get-Content -Path $outputpath -ErrorAction SilentlyContinue | Out-String\n\nSend-MailMessage -To clemaire@dbatools.io -From nobody@dbachecks.io -SMTP smtp.ad.local -BodyAsHtml $htmlbody\n\nIf you'd like to test locally, check out PaperCut which is just a quick email viewer that happens to have a built-in SMTP server. It provides awesome, built-in functionality so you can send the reports!\nAdvanced usage\nSkipping some internal tests\nThe Check LastGoodCheckDb includes a test for data purity. You may be in an environment that can't support data purity. If this check needs to be skipped, you can do the following:\nGet-DbcConfig *skip*\nSet-DbcConfig -Name skip.dbcc.datapuritycheck -Value $true\nNeed to skip a whole test? Just use the -ExcludeCheck which is auto-populated with both Check names and Pester Tags.\nSetting a global SQL Credential\nSet-DbcConfig persists the values. If you Set-DbcConfig -Name app.sqlcredential -Value (Get-Credential sa) it will set the SqlCredential for the whole module, but not your local console! So cool.\nYou can also manually change the SqlCredential or Credential by specifying it in Invoke-DbaCheck:\nInvoke-DbaCheck -SqlInstance sql2017 -SqlCredential (Get-Credential sqladmin) -Check MaxMemory\nManipulating the underlying commands\nYou can also modify the parameters of the actual command that's being executed:\nSet-Variable -Name PSDefaultParameterValues -Value @{ 'Get-DbaDiskSpace:ExcludeDrive' = 'C:\\' } -Scope Global\nInvoke-DbcCheck -Check Storage\nCan I run tests not included the module?\nIf you have super specialized checks to run, you can add a new repository, update the app.checkrepos config and this will make all of your tests available to Invoke-DbcCheck. From here, you can pipe to Send-DbcMailMessage, Update-DbcPowerBiDataSource or parse however you would parse Pester results.\n\nSo first, add your repository\nSet-DbcConfig -Name app.checkrepos -Value C:\\temp\\checks -Append\nThen add additional checks. We recommend using the development guidelines for dbachecks.\n\nI'd like to run my checks in SQL Server Agent\nGreat idea! Remember that this module requires PowerShell version 4.0, which doesn't always mesh with SQL Server's PowerShell Job Step. To run dbachecks, we recommend you use CmdExec. You can read more at dbatools.io\/agent.\nIf you do choose to use the PowerShell step, don't forget to Set-Location somewhere outside of SQLSERVER:, otherwise, you'll get errors similar to this\n\nI don't have access to the PowerShell Gallery, how can I download this?\nThis module has a number of dependencies which makes creating a GitHub-centric installer a bit of a pain. We suggest you use a machine with PowerShellGet installed and Save all the modules you need:\nSave-Module -Name dbachecks, dbatools, PSFramework, Pester -Path C:\\temp\nThen move them to somewhere in your $env:PSModulePath, perhaps Documents\\WindowsPowerShell\\Modules or C:\\Program Files\\WindowsPowerShell\\Modules.\nRead more\nRead more about dbachecks from a number of our original contributors!\n\nAnnouncing dbachecks \u2013 Configurable PowerShell Validation For Your SQL Instances by Rob Sewell\nintroducing dbachecks - a new module from the dbatools team! by Chrissy LeMaire\ninstall dbachecks by Chrissy LeMaire\ndbachecks commands by Chrissy LeMaire\ndbachecks \u2013 Using Power BI dashboards to analyse results by Cl\u00e1udio Silva\nMy wrapper for dbachecks by Tony Wilhelm\nChecking backups with dbachecks by Jess Promfret\ndbachecks please! by Garry Bargsley\ndbachecks \u2013 Configuration Deep Dive by Rob Sewell\nTest Log Shipping with dbachecks by Sander Stad\nChecking your backup strategy with dbachecks by Joshua Corrick\nEnterprise-level reporting with dbachecks by Jason Squires\nAdding your own checks to dbachecks by Shane O'Neill\ndbachecks - A different approach for an in-progress and incremental validation by Cl\u00e1udio Silva\ndbachecks - Improved Descriptions by Rob Sewell\nDBACHECKS \u2013 SQL SERVER COMPLIANCE TESTING WITH SIMPLE CONFIGURATION MANAGEMENT by Stuart Moore\ndbachecks \u2013 Which Configuration Item For Which Check ? by Rob Sewell\n*https:\/\/sqldbawithabeard.com\/2018\/04\/08\/checking-availability-groups-with-dbachecks\/ by Rob Sewell\n\nKnow of any more blog posts about dbachecks? - Please add them here.\nParty\nNice work!\nHow to Contribute\nWe welcome contributions to the project. You can fork the repository, make changes and create a Pull Request. Rob has written a guide here\n","2":"ESC-50: Dataset for Environmental Sound Classification\n\nOverview | Download | Results | Repository content | License | Citing | Caveats | Changelog\n\u00a0\n\u00a0\n\u00a0\n\n\nThe ESC-50 dataset is a labeled collection of 2000 environmental audio recordings suitable for benchmarking methods of environmental sound classification.\nThe dataset consists of 5-second-long recordings organized into 50 semantical classes (with 40 examples per class) loosely arranged into 5 major categories:\n\n\n\nAnimals\nNatural soundscapes & water sounds \nHuman, non-speech sounds\nInterior\/domestic sounds\nExterior\/urban noises\n\n\n\n\nDog\nRain\nCrying baby\nDoor knock\nHelicopter\n\n\nRooster\nSea waves\nSneezing\nMouse click\nChainsaw\n\n\nPig\nCrackling fire\nClapping\nKeyboard typing\nSiren\n\n\nCow\nCrickets\nBreathing\nDoor, wood creaks\nCar horn\n\n\nFrog\nChirping birds\nCoughing\nCan opening\nEngine\n\n\nCat\nWater drops\nFootsteps\nWashing machine\nTrain\n\n\nHen\nWind\nLaughing\nVacuum cleaner\nChurch bells\n\n\nInsects (flying)\nPouring water\nBrushing teeth\nClock alarm\nAirplane\n\n\nSheep\nToilet flush\nSnoring\nClock tick\nFireworks\n\n\nCrow\nThunderstorm\nDrinking, sipping\nGlass breaking\nHand saw\n\n\n\nClips in this dataset have been manually extracted from public field recordings gathered by the Freesound.org project. The dataset has been prearranged into 5 folds for comparable cross-validation, making sure that fragments from the same original source file are contained in a single fold.\nA more thorough description of the dataset is available in the original paper with some supplementary materials on GitHub: ESC: Dataset for Environmental Sound Classification - paper replication data.\nDownload\nThe dataset can be downloaded as a single .zip file (~600 MB):\nDownload ESC-50 dataset\nResults\nNumerous machine learning & signal processing approaches have been evaluated on the ESC-50 dataset. Most of them are listed here. If you know of some other reference, you can message me or open a Pull Request directly.\n\nTerms used in the table:\n\u2022 CNN - Convolutional Neural Network\u2022 CRNN - Convolutional Recurrent Neural Network\u2022 GMM - Gaussian Mixture Model\u2022 GTCC - Gammatone Cepstral Coefficients\u2022 GTSC - Gammatone Spectral Coefficients\u2022 k-NN - k-Neareast Neighbors\u2022 MFCC - Mel-Frequency Cepstral Coefficients\u2022 MLP - Multi-Layer Perceptron\u2022 RBM - Restricted Boltzmann Machine\u2022 RNN - Recurrent Neural Network\u2022 SVM - Support Vector Machine\u2022 TEO - Teager Energy Operator\u2022 ZCR - Zero-Crossing Rate\n\n\n\n\nTitle\nNotes\nAccuracy\nPaper\nCode\n\n\n\n\nUnsupervised Filterbank Learning Using Convolutional Restricted Boltzmann Machine for Environmental Sound Classification\nCNN with filterbanks learned using convolutional RBM + fusion with GTSC and mel energies\n86.50%\nsailor2017\n\n\n\nLearning from Between-class Examples for Deep Sound Recognition\nEnvNet-v2 (tokozume2017a) + data augmentation + Between-Class learning\n84.90%\ntokozume2017b\n\n\n\nNovel Phase Encoded Mel Filterbank Energies for Environmental Sound Classification\nCNN working with phase encoded mel filterbank energies (PEFBEs), fusion with Mel energies\n84.15%\ntak2017\n\n\n\nKnowledge Transfer from Weakly Labeled Audio using Convolutional Neural Network for Sound Events and Scenes\nCNN pretrained on AudioSet\n83.50%\nkumar2017\n\ud83d\udcdc\n\n\nUnsupervised Filterbank Learning Using Convolutional Restricted Boltzmann Machine for Environmental Sound Classification\nCNN with filterbanks learned using convolutional RBM + fusion with GTSC\n83.00%\nsailor2017\n\n\n\nDeep Multimodal Clustering for Unsupervised Audiovisual Learning\nCNN + unsupervised audio-visual learning\n82.60%\nhu2019\n\n\n\nNovel TEO-based Gammatone Features for Environmental Sound Classification\nFusion of GTSC & TEO-GTSC with CNN\n81.95%\nagrawal2017\n\n\n\nLearning from Between-class Examples for Deep Sound Recognition\nEnvNet-v2 (tokozume2017a) + Between-Class learning\n81.80%\ntokozume2017b\n\n\n\n\ud83c\udfa7 Human accuracy\nCrowdsourcing experiment in classifying ESC-50 by human listeners\n81.30%\npiczak2015a\n\ud83d\udcdc\n\n\nObjects that Sound\nLook, Listen and Learn (L3) network (arandjelovic2017a) with stride 2, larger batches and learning rate schedule\n79.80%\narandjelovic2017b\n\n\n\nLook, Listen and Learn\n8-layer convolutional subnetwork pretrained on an audio-visual correspondence task\n79.30%\narandjelovic2017a\n\n\n\nLearning Environmental Sounds with Multi-scale Convolutional Neural Network\nMulti-scale convolutions with feature fusion (waveform + spectrogram)\n79.10%\nzhu2018\n\n\n\nNovel TEO-based Gammatone Features for Environmental Sound Classification\nGTSC with CNN\n79.10%\nagrawal2017\n\n\n\nLearning from Between-class Examples for Deep Sound Recognition\nEnvNet-v2 (tokozume2017a) + data augmentation\n78.80%\ntokozume2017b\n\n\n\nUnsupervised Filterbank Learning Using Convolutional Restricted Boltzmann Machine for Environmental Sound Classification\nCNN with filterbanks learned using convolutional RBM\n78.45%\nsailor2017\n\n\n\nLearning from Between-class Examples for Deep Sound Recognition\nBaseline CNN (piczak2015b) + Batch Normalization + Between-Class learning\n76.90%\ntokozume2017b\n\n\n\nNovel TEO-based Gammatone Features for Environmental Sound Classification\nTEO-GTSC with CNN\n74.85%\nagrawal2017\n\n\n\nLearning from Between-class Examples for Deep Sound Recognition\nEnvNet-v2 (tokozume2017a)\n74.40%\ntokozume2017b\n\n\n\nSoundnet: Learning sound representations from unlabeled video\n8-layer CNN (raw audio) with transfer learning from unlabeled videos\n74.20%\naytar2016\n\ud83d\udcdc\n\n\nLearning from Between-class Examples for Deep Sound Recognition\n18-layer CNN on raw waveforms (dai2016) + Between-Class learning\n73.30%\ntokozume2017b\n\n\n\nNovel Phase Encoded Mel Filterbank Energies for Environmental Sound Classification\nCNN working with phase encoded mel filterbank energies (PEFBEs)\n73.25%\ntak2017\n\n\n\nClassifying environmental sounds using image recognition networks\n16 kHz sampling rate, GoogLeNet on spectrograms (40 ms frame length)\n73.20%\nboddapati2017\n\ud83d\udcdc\n\n\nLearning from Between-class Examples for Deep Sound Recognition\nBaseline CNN (piczak2015b) + Batch Normalization\n72.40%\ntokozume2017b\n\n\n\nNovel TEO-based Gammatone Features for Environmental Sound Classification\nFusion of MFCC & TEO-GTCC with GMM\n72.25%\nagrawal2017\n\n\n\nLearning environmental sounds with end-to-end convolutional neural network (EnvNet)\nCombination of spectrogram and raw waveform CNN\n71.00%\ntokozume2017a\n\n\n\nNovel TEO-based Gammatone Features for Environmental Sound Classification\nTEO-GTCC with GMM\n68.85%\nagrawal2017\n\n\n\nClassifying environmental sounds using image recognition networks\n16 kHz sampling rate, AlexNet on spectrograms (30 ms frame length)\n68.70%\nboddapati2017\n\ud83d\udcdc\n\n\nVery Deep Convolutional Neural Networks for Raw Waveforms\n18-layer CNN on raw waveforms\n68.50%\ndai2016, tokozume2017b\n\ud83d\udcdc\n\n\nClassifying environmental sounds using image recognition networks\n32 kHz sampling rate, GoogLeNet on spectrograms (30 ms frame length)\n67.80%\nboddapati2017\n\ud83d\udcdc\n\n\nWSNet: Learning Compact and Efficient Networks with Weight Sampling\nSoundNet 8-layer CNN architecture with 100x model compression\n66.25%\njin2017\n\n\n\nSoundnet: Learning sound representations from unlabeled video\n5-layer CNN (raw audio) with transfer learning from unlabeled videos\n66.10%\naytar2016\n\ud83d\udcdc\n\n\nWSNet: Learning Compact and Efficient Networks with Weight Sampling\nSoundNet 8-layer CNN architecture with 180x model compression\n65.80%\njin2017\n\n\n\nSoundnet: Learning sound representations from unlabeled video\n5-layer CNN trained on raw audio of ESC-50 only\n65.00%\naytar2016\n\ud83d\udcdc\n\n\n\ud83d\udcca Environmental Sound Classification with Convolutional Neural Networks - CNN baseline\nCNN with 2 convolutional and 2 fully-connected layers, mel-spectrograms as input, vertical filters in the first layer\n64.50%\npiczak2015b\n\ud83d\udcdc\n\n\nauDeep: Unsupervised Learning of Representations from Audio with Deep Recurrent Neural Networks\nMLP classifier on features extracted with an RNN autoencoder\n64.30%\nfreitag2017\n\ud83d\udcdc\n\n\nClassifying environmental sounds using image recognition networks\n32 kHz sampling rate, AlexNet on spectrograms (30 ms frame length)\n63.20%\nboddapati2017\n\ud83d\udcdc\n\n\nClassifying environmental sounds using image recognition networks\nCRNN\n60.30%\nboddapati2017\n\ud83d\udcdc\n\n\nComparison of Time-Frequency Representations for Environmental Sound Classification using Convolutional Neural Networks\n3-layer CNN with vertical filters on wideband mel-STFT (median accuracy)\n56.37%\nhuzaifah2017\n\n\n\nComparison of Time-Frequency Representations for Environmental Sound Classification using Convolutional Neural Networks\n3-layer CNN with square filters on wideband mel-STFT (median accuracy)\n54.00%\nhuzaifah2017\n\n\n\nSoundnet: Learning sound representations from unlabeled video\n8-layer CNN trained on raw audio of ESC-50 only\n51.10%\naytar2016\n\ud83d\udcdc\n\n\nComparison of Time-Frequency Representations for Environmental Sound Classification using Convolutional Neural Networks\n5-layer CNN with square filters on wideband mel-STFT (median accuracy)\n50.87%\nhuzaifah2017\n\n\n\nComparison of Time-Frequency Representations for Environmental Sound Classification using Convolutional Neural Networks\n5-layer CNN with vertical filters on wideband mel-STFT (median accuracy)\n46.25%\nhuzaifah2017\n\n\n\n\ud83d\udcca Baseline - random forest\nBaseline ML approach (MFCC & ZCR + random forest)\n44.30%\npiczak2015a\n\ud83d\udcdc\n\n\nSoundnet: Learning sound representations from unlabeled video\nConvolutional autoencoder trained on unlabeled videos\n39.90%\naytar2016\n\ud83d\udcdc\n\n\n\ud83d\udcca Baseline - SVM\nBaseline ML approach (MFCC & ZCR + SVM)\n39.60%\npiczak2015a\n\ud83d\udcdc\n\n\n\ud83d\udcca Baseline - k-NN\nBaseline ML approach (MFCC & ZCR + k-NN)\n32.20%\npiczak2015a\n\ud83d\udcdc\n\n\nA mixture model-based real-time audio sources classification method\nDictionary of sound models used for classification (accuracy is computed on segments instead of files)\n94.00%\nbaelde2017\n\n\n\nNELS - Never-Ending Learner of Sounds\nLarge-scale audio crawling with classifiers trained on AED datasets (including ESC-50)\nN\/A\nelizalde2017\n\ud83d\udcdc\n\n\nUtilizing Domain Knowledge in End-to-End Audio Processing\nEnd-to-end CNN with learned mel-spectrogram transformation\nN\/A\ntax2017\n\ud83d\udcdc\n\n\nDeep Neural Network based learning and transferring mid-level audio features for acoustic scene classification\nTransfer learning from various datasets, including ESC-50\nN\/A\nmun2017\n\n\n\nFeatures and Kernels for Audio Event Recognition\nMFCC, GMM, SVM\nN\/A\nkumar2016b\n\n\n\nA real-time environmental sound recognition system for the Android OS\nReal-time sound recognition for Android evaluated on ESC-10\nN\/A\npillos2016\n\n\n\nComparing Time and Frequency Domain for Audio Event Recognition Using Deep Learning\nDiscriminatory effectiveness of different signal representations compared on ESC-10 and Freiburg-106\nN\/A\nhertel2016\n\n\n\nAudio Event and Scene Recognition: A Unified Approach using Strongly and Weakly Labeled Data\nCombination of weakly labeled data (YouTube) with strong labeling (ESC-10) for Acoustic Event Detection\nN\/A\nkumar2016a\n\n\n\n\nRepository content\n\n\naudio\/*.wav\n2000 audio recordings in WAV format (5 seconds, 44.1 kHz, mono) with the following naming convention:\n{FOLD}-{CLIP_ID}-{TAKE}-{TARGET}.wav\n\n{FOLD} - index of the cross-validation fold,\n{CLIP_ID} - ID of the original Freesound clip,\n{TAKE} - letter disambiguating between different fragments from the same Freesound clip,\n{TARGET} - class in numeric format [0, 49].\n\n\n\nmeta\/esc50.csv\nCSV file with the following structure:\n\n\n\nfilename\nfold\ntarget\ncategory\nesc10\nsrc_file\ntake\n\n\n\nThe esc10 column indicates if a given file belongs to the ESC-10 subset (10 selected classes, CC BY license).\n\n\nmeta\/esc50-human.xlsx\nAdditional data pertaining to the crowdsourcing experiment (human classification accuracy).\n\n\nLicense\nThe dataset is available under the terms of the Creative Commons Attribution Non-Commercial license.\nA smaller subset (clips tagged as ESC-10) is distributed under CC BY (Attribution).\nAttributions for each clip are available in the  LICENSE file.\nCiting\n\nIf you find this dataset useful in an academic setting please cite:\n\nK. J. Piczak. ESC: Dataset for Environmental Sound Classification. Proceedings of the 23rd Annual ACM Conference on Multimedia, Brisbane, Australia, 2015.\n[DOI: http:\/\/dx.doi.org\/10.1145\/2733373.2806390]\n\n@inproceedings{piczak2015dataset,\n  title = {{ESC}: {Dataset} for {Environmental Sound Classification}},\n  author = {Piczak, Karol J.},\n  booktitle = {Proceedings of the 23rd {Annual ACM Conference} on {Multimedia}},\n  date = {2015-10-13},\n  url = {http:\/\/dl.acm.org\/citation.cfm?doid=2733373.2806390},\n  doi = {10.1145\/2733373.2806390},\n  location = {{Brisbane, Australia}},\n  isbn = {978-1-4503-3459-4},\n  publisher = {{ACM Press}},\n  pages = {1015--1018}\n}\n\nCaveats\nPlease be aware of potential information leakage while training models on ESC-50, as some of the original Freesound recordings were already preprocessed in a manner that might be class dependent (mostly bandlimiting). Unfortunately, this issue went unnoticed when creating the original version of the dataset. Due to the number of methods already evaluated on ESC-50, no changes rectifying this issue will be made in order to preserve comparability.\nChangelog\nv2.0.0 (2017-12-13)\n\n\u2022 Change to WAV version as default.\n\nv2.0.0-pre (2016-10-10) (wav-files branch)\n\n\u2022 Replace OGG recordings with cropped WAV files for easier loading and frame-level precision (some of the OGG recordings had a slightly different length when loaded).\u2022 Move recordings to a one directory structure with a meta CSV file.\n\nv1.0.0 (2015-04-15)\n\n\u2022 Initial version of the dataset (OGG format).\n\n","3":"Leaflet Environmental Layers (LEL)\n\n \n\n\n\nA leaflet plugin that has a collection of layers containing environmental data pulled in from different sources. See this demo page for a simple demonstration of the plugin.\nTable of Contents\n\nWhat is LEL\nInstallation\nUsage\nDependencies\nGetting started\nFeatures\nLayers\nAdding LEL features individually\nAdding layers individually\nContributing\nReach out to the maintainers\nAbout PublicLab\n\nInstallation\nInstall using NPM with: npm install leaflet-environmental-layers\nSee Dependencies below for what you need to include for basic usage and for individual layers.\nUsage\nInstantiate a collection of environmentally related Leaflet layers with the L.LayerGroup.EnvironmentalLayers(options) function:\nL.LayerGroup.EnvironmentalLayers({\n  \/\/ simpleLayerControl: true,\n  addLayersToMap: true,\n  include: ['odorreport', 'clouds', 'eonetFiresLayer', 'Unearthing', 'PLpeople'], \/\/ display only these layers\n  \/\/ exclude: ['mapknitter', 'clouds'], \/\/ layers to exclude (cannot be used at same time as 'include'\n  \/\/ display: ['eonetFiresLayer'], \/\/ which layers are actually shown as opposed to just being in the menu\n  hash: true,\n  embed: true,\n  \/\/ hostname: 'domain name goes here'\n}).addTo(map);\nWhen specifying layers to include or exclude, use their names as listed in the table below.\nOptions\n\n\n\nOption\nType\nDefault\nDescription\n\n\n\n\nbaseLayers\nObject\n-\nPassed in as { 'Standard': baselayer } where 'Standard' is the name given to the layer and baselayer is the variable containing the base tile layer(L.tileLayer()). It can have more than one base layer. At least one base layer should be added to the map instance. If no baseLayers are provided it is defaulted to a grey-scale base map.\n\n\nsimpleLayerControl\nBoolean\nfalse\nIf set to true, it will replace LEL's layer menu with leaflet's default layers control.\n\n\naddLayersToMap\nBoolean\nfalse\nIf set to true, adds all layers in the include option to the map by default.\n\n\ninclude\nArray\nArray\nIf provided, adds the given layers to the layer menu or layers control. If not provided, adds all the layers to the layer menu or layers control.\n\n\nexclude\nArray\n-\nIf provided, excludes the given layers from the layer menu or layers control.\n\n\ndisplay\nArray\n-\nIf provided, displays the given layers by default on the map.\n\n\nhash\nBoolean\nfalse\nIf true, provides hash support for the map.\n\n\nembed\nBoolean\nfalse\nIf true, adds an embed control that generates code to the map for embedding the map on other sites.\n\n\nhostname\nString\n'publiclab.github.io'\nUses the value in place of hostname in the URL generated in the embed code.\n\n\n\nDependencies\n\nInstall Bootstrap(Required for the layers menu)\nInstall @fortawesome\/fontawesome-free\nAdd the following to the head of the HTML file that would contain the map\n\n<!-- Required for PLpeople layer - must load before dist\/LeafletEnvironmentalLayers.js -->\n<script src=\"..\/node_modules\/leaflet-blurred-location\/dist\/Leaflet.BlurredLocation.js\"><\/script>\n<script src=\"..\/node_modules\/leaflet.blurred-location-display\/dist\/Leaflet.BlurredLocationDisplay.js\"><\/script>\n\n<!-- Required for all maps -->\n<script src=\"..\/node_modules\\jquery\\dist\\jquery.min.js\"><\/script>\n<script src=\"..\/dist\/LeafletEnvironmentalLayers.js\"><\/script>\n<link href=\"..\/node_modules\/leaflet\/dist\/leaflet.css\" rel=\"stylesheet\" \/>\n<link href=\"..\/dist\/LeafletEnvironmentalLayers.css\" rel=\"stylesheet\" \/>\n<link href=\"..\/node_modules\\@fortawesome\\fontawesome-free\\css\\all.min.css\" rel=\"stylesheet\" \/>\n\n<!-- Bootstrap - not needed if you use simpleLayerControl:true -->\n<script src=\"..\/node_modules\\bootstrap\\dist\\js\\bootstrap.min.js\"><\/script>\n<link rel=\"stylesheet\" href=\"..\/node_modules\\bootstrap\\dist\\css\\bootstrap.min.css\">\n\n<!-- Required for setting hash:true -->\n<script src=\"..\/lib\/leaflet-fullUrlHash.js\"><\/script>\n\n<!-- Required for search control -->\n<script src=\"..\/node_modules\/leaflet-google-places-autocomplete\/src\/js\/leaflet-gplaces-autocomplete.js\"><\/script>\n<link rel=\"stylesheet\" href=\"..\/node_modules\/leaflet-google-places-autocomplete\/src\/css\/leaflet-gplaces-autocomplete.css\">\n<script src=\"https:\/\/maps.googleapis.com\/maps\/api\/js?key=AIzaSyAOLUQngEmJv0_zcG1xkGq-CXIPpLQY8iQ&libraries=places\"><\/script>\n\n<!-- Required for purpleLayer -->\n<script src=\"..\/node_modules\/heatmap.js\/build\/heatmap.min.js\"><\/script>\n<script src=\"..\/node_modules\/leaflet-heatmap\/leaflet-heatmap.js\"><\/script>\n\n<!-- Required for wisconsin Layer -->\n<script src=\"https:\/\/unpkg.com\/esri-leaflet@2.2.3\/dist\/esri-leaflet.js\"><\/script>\n<script src=\"https:\/\/unpkg.com\/esri-leaflet-renderers@2.0.6\"><\/script>\n\n<!-- Required for windRose Layer -->\n<script src=\"..\/src\/windRoseLayer.js\"><\/script>\n\n<!-- Required for Unearthing Layer -->\n<script src=\"..\/lib\/glify.js\"><\/script>\nGetting started\nInstallation Instructions\n\nClone this repository to your local environment.\nRun npm install to install all the necessary packages required.\nOpen examples\/index.html in your browser to look at the preview of the library.\n\nInstructions for a developer\n\nInstall grunt - https:\/\/gruntjs.com\/installing-grunt.\nMake the changes you are working on in the respective \/src files.\nRun grunt build to generate files in the \/dist directory.\nRun grunt transpile to transpile es6 code and copy files needed to run the tests to the \/dist directory.\nRun grunt jasmine to run tests on the LEL layers and ensure they pass.\nRun npm run start to start a local server.\nRun npm run cy:run:chrome to run e2e and integration tests.\nTest your changes on a browser by opening examples\/index.html.\n\nFeatures\nZoom or Pan\nClick and drag the map to pan it.\nChange the Base Map and Overlay layers\nUse the button on right-most corner to change the way the background of the map looks.\nSee More Data\n\nToggle certain layers on and off using the Layers button in the toolbar.\nLayers with near-real-time or real-time data will have the 'NRT\/RT' mark on them.\nMore information on the layer data will be available when clicking the 'i' button on the layer\nLayers that allow contributions will have a report button or contribute button.\nLayers will be visible on the menu only when the map view intersects with the layer's bounds or zoom levels.\nA badge displays the number of new layers in the map view when the map intersects with new layers\n\nRead more about the layers menu here.\nClick on a Point\nClick on a point or marker on the map to learn more about it.\nMinimal mode\nClick on the button group on the left, below the zoom controls, to change between default markers mode and minimal markers mode. Use minimal markers mode for a smoother experience when using multiple layers with many markers.\nRead more about this feature here.\nURL Hash\nThe map page's URL hash updates on map movement and when a layer is added or removed from a map. This helps preserve map state when refreshing or copying the URL to another page.\nEmbed Code\nClick on the button at the bottom on the left side of a map to generate an embed code so that the map page can be embedded in other sites.\nLayers\nThe information of each layer can be found here: Layer Information\n\n\n\nLayer Name\nColor\n\n\n\n\nPLpeople\nN\/A\n\n\nwisconsin\nN\/A\n\n\nfracTrackerMobile\nN\/A\n\n\npurpleLayer\n#8b0000\n\n\npurpleairmarker\n#800080\n\n\nskytruth\n#ff0000\n\n\nfractracker\n#ffff00\n\n\npfasLayer\n#00ff00\n\n\ntoxicReleaseLayer\n#008000\n\n\nodorreport\n#ff00ff\n\n\nmapknitter\n#D50039\n\n\nPower\n#ffc0cb\n\n\nTelecom\n#0000ff\n\n\nPetroleum\n#a52a2a\n\n\nWater\n#4B0082\n\n\nincome\n#006400\n\n\namericanIndian\n#800000\n\n\nasian\n#ffa500\n\n\nblack\n#FFD700\n\n\nmulti\n#ffc0cb\n\n\nhispanic\n#DCDCDC\n\n\nnonWhite\n#808080\n\n\nwhite\n#a52a2a\n\n\nplurality\n#800000\n\n\nclouds\n#80dfff\n\n\ncloudsClassic\n#b3f0ff\n\n\nprecipitation\n#00ff55\n\n\nprecipitationClassic\n#00008b\n\n\nrain\n#8080ff\n\n\nrainClassic\n#1a1aff\n\n\nsnow\n#80ffe5\n\n\npressure\n#e62e00\n\n\npressureContour\n#ff3300\n\n\ntemperature\n#ff3300\n\n\nwind\n#00008b\n\n\ncity\n#b3ffff\n\n\nwindrose\n#008000\n\n\nTerritories\n#000000\n\n\nLanguages\n#000000\n\n\nTreaties\n#000000\n\n\naqicnLayer\n#000000\n\n\nopenaq\n#000000\n\n\nluftdaten\n#000000\n\n\nopensense\nN\/A\n\n\nosmLandfillMineQuarryLayer\nN\/A\n\n\neonetFiresLayer\n#78fffa\n\n\nUnearthing\nN\/A\n\n\n\nAdding LEL features individually\nAdd a legend\nIn src\/legendCreation.js, add addLayerNameURLPair(layer_var, \"img_url\");, where layer_var is consistent with the variable used in example\/index.html and img_url is the source of the image to be used as the legend.\nAdd an embed control\nCreation\n\/\/ Assuming your map instance is in a variable called map\nL.control.embed(options).addTo(map);\n\nThe optional options object can be passed in with any of the following properties:\n\n\n\nOption\nType\nDefault\nDescription\n\n\n\n\nposition\nString\n'topleft'\nOther possible values include 'topright', 'bottomleft' or 'bottomright'\n\n\nhostname\nString\n'publiclab.github.io'\nSets hostname for the URL in the embed code\n\n\n\nAdd hash support for easy sharing of map\nAdd link\n    <script src=\"..\/lib\/leaflet-fullUrlHash.js\"><\/script>\n\nCreation\n    \/\/ Assuming your map instance is in a variable called map\n    \/\/ Assuming an object with all the map layers is in a variable called allMapLayers\n    var hash = new L.FullHash(map, allMapLayers);  \n\nAdd the layers menu\nPrerequisites\n\nBootstrap\njQuery\n\nDependencies\n\nInstall Bootstrap(Required for the layers menu)\nInstall @fortawesome\/fontawesome-free\nAdd the following to the head of the HTML file that would contain the map\n\n<!-- jQuery --> \n<script src=\"..\/node_modules\\jquery\\dist\\jquery.min.js\"><\/script>\n\n<!-- Bootstrap --> \n<script src=\"..\/node_modules\\bootstrap\\dist\\js\\bootstrap.min.js\"><\/script>\n<link rel=\"stylesheet\" href=\"..\/node_modules\\bootstrap\\dist\\css\\bootstrap.min.css\">\n\n<!-- Required includes -->\n<script src=\"..\/dist\/LeafletEnvironmentalLayers.js\"><\/script>\n<link href=\"..\/node_modules\/leaflet\/dist\/leaflet.css\" rel=\"stylesheet\" \/>\n<link href=\"..\/dist\/LeafletEnvironmentalLayers.css\" rel=\"stylesheet\" \/>\n<link href=\"..\/node_modules\\@fortawesome\\fontawesome-free\\css\\all.min.css\" rel=\"stylesheet\" \/>\n\nUsage example\n  var baseMaps = {\n    'Standard': L.tileLayer('TILE_LAYER_URL').addTo(map),\n    'Dark': L.tileLayer('TILE_LAYER_URL')\n  };\n\n  var overlayMaps = {\n    'wisconsin': Wisconsin_NM,  \/\/ Assuming 'Wisconsin_NM' is the variable that holds the wisconsin layer object\n    'indigenousLands': {\n      category: 'group', \/\/ Let's the control know if this should be rendered as a group\n      layers: { \/\/ Layers making the group\n        'Territories': IndigenousLandsTerritories,  \/\/ Assuming 'IndigenousLandsTerritories' is the variable that holds the respective layer object\n        'Languages': IndigenousLandsLanguages,  \/\/ Assuming 'IndigenousLandsLanguages' is the variable that holds the respective layer object\n        'Treaties': IndigenousLandsTreaties,  \/\/ Assuming 'IndigenousLandsTreaties' is the variable that holds the respective layer object\n      },\n    },\n  };\n\n  var leafletControl = new L.control.layersBrowser(baseMaps, overlayMaps);\n  leafletControl.addTo(map);\nCreation\nL.control.layersBrowser(baseMaps, overlayMaps).addTo(map);\n\n\nbaseMaps and overlayMaps are object literals that have layer names as keys and Layer objects as values. Read more about Leaflet's Control.Layers.\nbaseMaps will be hidden if only one base map is provided\nThe layer information displayed for each layer is stored in info.json\nThe layer name(key) in the overlayMaps object should match the keys in info.json\nThe layers are filtered according to the map view\nWhen there are new layers present in the map view when moving around a badge is displayed near the layer control icon on the top right showing the number of new layers in the view\n\nAdd minimal mode control\nCreation\n\/\/ Assuming your map instance is in a variable called map\n\/\/ Assuming your layers menu or layers control instance is in a variable called layersControl\nL.control.minimalMode(layersControl).addTo(map);\n\nAdd search control\nLEL uses leaflet-google-places-autocomplete for the search control feature.\nAdding layers individually\nTo use Wisconsin Non-Metallic Layer\nAdd\n  <script src=\"https:\/\/unpkg.com\/esri-leaflet@2.2.3\/dist\/esri-leaflet.js\"><\/script>\n  <script src=\"https:\/\/unpkg.com\/esri-leaflet-renderers@2.0.6\"><\/script>\n\nCreation\n  var Wisconsin_NM = wisconsinLayer(map) ;\n\nTo use Fractracker Mobile Layer\n  var FracTracker_mobile = L.geoJSON.fracTrackerMobile();\n\nTo use Purple Layer\n<script src=\"..\/node_modules\/heatmap.js\/build\/heatmap.min.js\"><\/script>\n<script src=\"..\/node_modules\/leaflet-heatmap\/leaflet-heatmap.js\"><\/script>\n\nTo use Unearthing Layer\n<script src=\"..\/lib\/glify.js\"><\/script>\n\nTo use PLpeople Layer\nThese must be included in the file before \/dist\/LeafletEnvironmentalLayers.js:\n    <script src=\"..\/node_modules\/leaflet-blurred-location\/dist\/Leaflet.BlurredLocation.js\"><\/script>\n    <script src=\"..\/node_modules\/leaflet.blurred-location-display\/dist\/Leaflet.BlurredLocationDisplay.js\"><\/script>\n\n_Real Time Layers\ncity (by openWeather)\n    var city = L.OWM.current({intervall: 15, minZoom: 3});\n\nWindRose (by openWeather)\n  <script src=\"..\/src\/windRoseLayer.js\"><\/script>\n\n  var windrose = L.OWM.current({intervall: 15, minZoom: 3, markerFunction: myWindroseMarker, popup: false, clusterSize:       50,imageLoadingBgUrl: 'https:\/\/openweathermap.org\/img\/w0\/iwind.png' });\n  windrose.on('owmlayeradd', windroseAdded, windrose);\n\nOpen Infra Map\nOpenInfraMap_Power Layer\nvar OpenInfraMap_Power = L.tileLayer('https:\/\/tiles-{s}.openinframap.org\/power\/{z}\/{x}\/{y}.png',{\n    maxZoom: 18,\n    attribution: '&copy; <a href=\"http:\/\/www.openstreetmap.org\/copyright\">OpenStreetMap<\/a>, <a href=\"http:\/\/www.openinframap.org\/about.html\">About OpenInfraMap<\/a>'\n});\n\nOpenInfraMap_Petroleum Layer\nvar OpenInfraMap_Petroleum = L.tileLayer('https:\/\/tiles-{s}.openinframap.org\/petroleum\/{z}\/{x}\/{y}.png', {\n  maxZoom: 18,\n  attribution: '&copy; <a href=\"http:\/\/www.openstreetmap.org\/copyright\">OpenStreetMap<\/a>, <a href=\"http:\/\/www.openinframap.org\/about.html\">About OpenInfraMap<\/a>'\n});\n\nOpenInfraMap_Telecom Layer\nvar OpenInfraMap_Telecom = L.tileLayer('https:\/\/tiles-{s}.openinframap.org\/telecoms\/{z}\/{x}\/{y}.png', {\n  maxZoom: 18,\n  attribution: '&copy; <a href=\"http:\/\/www.openstreetmap.org\/copyright\">OpenStreetMap<\/a>, <a href=\"http:\/\/www.openinframap.org\/about.html\">About OpenInfraMap<\/a>'\n});\n\nOpenInfraMap_Water Layer\nvar OpenInfraMap_Water = L.tileLayer('https:\/\/tiles-{s}.openinframap.org\/water\/{z}\/{x}\/{y}.png',{\n  maxZoom: 18,\n  attribution: '&copy; <a href=\"http:\/\/www.openstreetmap.org\/copyright\">OpenStreetMap<\/a>, <a href=\"http:\/\/www.openinframap.org\/about.html\">About OpenInfraMap<\/a>'\n});\n\nSpreadsheet-based layers\nWe can source locations from a spreadsheet in a format like this:\n\n\n\nTitle\nLatitude\nLongitude\nNotes\n\n\n\n\nFirst\n29.671282\n-95.17829\nThe first marker\n\n\nSecond\n29.760371\n-95.504828\nThe second marker\n\n\nThird\n29.917755\n-95.283494\nThe third marker\n\n\n\nThe layer is constructed like this:\nvar layer = L.SpreadsheetLayer({\n  url: 'https:\/\/docs.google.com\/spreadsheets\/d\/14BvU3mEqvI8moLp0vANc7jeEvb0mnmYvH4I0GkwVsiU\/edit?usp=sharing', \/\/ String url of data sheet\n  lat: 'Latitude', \/\/ name of latitude column\n  lon: 'Longitude', \/\/ name of longitude column\n  columns: ['Title', 'Notes'], \/\/ Array of column names to be used\n  generatePopup: function() {\n    \/\/ function used to create content of popups\n  },\n  \/\/ imageOptions: \/\/ optional, defaults to blank\n  \/\/ sheetNum: \/\/ optional, defaults to 0 (first sheet)\n});\nlayer.addTo(map);\nRead more here: https:\/\/github.com\/publiclab\/leaflet-environmental-layers\/blob\/master\/src\/util\/googleSpreadsheetLayer.js\nWe're going to try spinning this out into its own library; see: https:\/\/github.com\/publiclab\/leaflet-environmental-layers\/issues\/121\nContributing\nPlease read CONTRIBUTING.md for details on our code of conduct, the process for submitting pull requests, and steps to add new layers.\nReach out to the maintainers\nReach out to the maintainers here: https:\/\/github.com\/orgs\/publiclab\/teams\/maintainers\nAbout PublicLab\nPublic Lab is a community and non-profit democratizing science to address environmental issues that affect people.\n^back to top\n","4":"Emoncms\n\n\nEmoncms is an open-source web application for processing, logging and visualising energy, temperature and other environmental data and is part of the OpenEnergyMonitor project.\n\nRequirements\n\nPHP (tested with 7.0.30)\nMYSQL or MariaDB (tested with 15.1)\nApache (tested with 2.4.25)\nRedis* (tested with 3.2.6)\n\n*Redis is recommended because it reduces the number of disk writes and therefore prolongs disk life (noticeably on SD cards e.g. RaspberryPi). Some input-processors also require redis and fail silently if redis is not installed. Some environments such as shared hosting or as far as we have tried windows servers don't support redis hence why emoncms has a fall back mode that allows core operation without redis.\nUsing Emoncms\nImportant: Standard Emoncms and Emoncms.org\nThere are differences between the standard version of emoncms and the version of emoncms running on emoncms.org. This repository contains the code for the standard version of emoncms. This is the version installed on the OpenEnergyMonitor SD Card that comes with the EmonPi and EmonBase and is recommended for all self-install versions of emoncms.\nThe emoncms.org version Github: emoncms\/emoncmsorg is a fork that is specific for multi-server installations. While both versions share the same roots, the code for emoncms.org differs significantly from the standard version of emoncms, the user experience is intended to be similar but there are currently a number of differences in the API and look of the inputs and feeds interfaces as well as a reduced feature set in general on emoncms.org in order to ensure stability. In general development on emoncms.org moves slower than the standard emoncms for this reason.\n1. From the Guide\n\nGuide: Core Concepts - Core Emoncms concepts including inputs, input processing and feeds.\nGuide: Creating daily kWh graphs - How to create daily kWh graphs from cumulative kWh electricity\/heat energy feeds.\nGuide: Daily Averages - How to extract daily averages from temperature, humidity & power feeds.\nGuide: Exporting CSV - How to use the graph module and feeds interface to export CSV data for use in 3rd party programs such as OpenOffice Calc or Excel.\nGuide: Histograms - How to use the histogram tool in the graph module.\nGuide: Home Energy Monitor - Example of configuring the MyElectric dashboard.\nGuide: Solar PV Monitor - Example of configuring the MySolar dashboard.\n\n2. Emoncms Terminology\n\nInput: An incoming datasource. Each input has an associated \"node\" identifier and a \"key\" sub-identifier. Inputs are entry points, only the last value and time of the input is recorded. To record historic data a feed needs to be created from an input.\nInput: Node: A grouping identifier for an input or feed.\nInput: Key: A sub-identifier for items within each Node.\nInput process list (or input processing): A list of processes* performed sequentially on each input value as it is received on that input.\nProcess: A function that can be attached to the process list of an input to change the value or to save the value to a feed*.\nFeed: A place where data is recorded, a time-series of datapoints. The standard time-series databases used by emoncms are PHPFina and PHPTimeSeries and were written as part of the emoncms project.\n\n\nFor a description of what each input process does in emoncms, see the helper note within the emoncms input processing configuration interface.\n\n3. Emoncms.org API Reference\nThe following API references apply to emoncms.org. They differ slightly to the API available on EmonPI\/EmonBase installs, the API refrence for which can be found from the inputs and feed pages when logged in locally.\n\nInput API reference\nFeed API reference\n\nInstall\nRecommended:\n\nNew: Debian build script\nPre built emonSD SD-card Image Download\nPurchase pre-loaded SD card\n\nExperimental (not currently up to date):\n\nMulti-platform using Docker Container\n\nOther (less supported, not tested on latest versions of emoncms)\n\nShared Linux Hosting\nWindows Emoncms is developed and tested on Linux only and so additional research, steps may be required that are not covered in this guide.\n\nModules\nModules can be installed by downloading or git cloning into the emoncms\/Modules folder. Be sure to check for database updates in Administration menu after installing new modules:\n\n\nGraph module - Advanced graphing module that integrates with the emoncms feed list, highly recommended; examples of use can be found in emoncms guide [1][2][3][4].\n\n\nDevice module - Automatically configure inputs and feeds using device templates.\n\n\nDashboards module - Required for creating, viewing and publishing dashboards.\n\n\nApp module - Application specific dashboards e.g. MyElectric, MySolar.\n\n\nConfig - In-browser emonhub.conf editor and emonhub.log log viewer. Use git clone to install.\n\n\nWifi module - Wifi configuration interface designed for use on the emonPi\n\n\nDemandShaper module - Schedule smartplugs, EmonEVSE smart EV chargers, heatpumps to run at best time in terms of: carbon, cost, grid strain. Based on day ahead forecasts.\n\n\nRemoteAccess module - Emoncms Remote Access client (Beta)\n\n\nThere are many other available modules such as the event module and openbem (open source building energy modelling module): check out the Emoncms repo list.\n3rd party modules\n\nCarbonCoop: ServiceAPI module\nCarbonCoop: Auth0 module\n\nBranches\n\n\nmaster - The latest and greatest developments. Potential bugs, use at your own risk! All pull-requests should be made to the master branch.\n\n\nstable - emonPi\/emonBase release branch, regularly merged from master. Slightly more tried and tested. See release change log.\n\n\nARCHIVE low-write (v8.5) - Old emonpi\/emonbase emoncms version (July 15 emonSD ready-to-go SD card image). Low-write mode is now available in v9.0. The low write version of emoncms is designed for running on SD cards. This is a cut down version of emoncms supporting only the phpfina and phptimeseries feed engines (no in built feed averaging or histograms) and a reduced input processor set. Archived branch\n\n\nUpgrade\n\nUpgrading emoncms\n\nData Backup\n\nBackup\nRaspberry Pi Backup \/ Restore module (emonPi \/ emonBase)\n\nDevelopment\n\nEmoncms Community Forum\n\nDocumentation development\nFor developers: The following lists the locations of the files that define emoncms's inbuilt documentation for the input and feed API's and input process descriptions:\n\nThe input API helper page emoncms\/Modules\/input\/Views\/input_api.php\nThe feed API helper page emoncms\/Modules\/feed\/Views\/feedapi_view.php\nInput process descriptions are defined in the process list definition object at the top of the process list definition file here: emoncms\/Modules\/process\/process_processlist.php\n\nTools\n\nPHPFina data file viewer - Easily explore phpfina timeseries feed engine data files directly without a full emoncms installation. Useful for checking backups and archived data.\n\nDesign\nNote: due to ongoing development some docs may now be outdated\n\nEmoncms architecture\nInput processing implementation\nDeveloping a new Module\nGlobal variables in Emoncms\n\nEmoncms timeseries database design (feed storage)\n\nEmoncms time series database development history\nVariable interval time series\nFixed interval time series\nFixed interval with averaging time series\nImproving write performance with buffering\n\nAndroid App\nGoogle Play\nGitHub Repo\nDevelopment Forum\nMore information\n\nCloud hosted platform - http:\/\/emoncms.org\nOpenEnergyMonitor Forums\nOpenEnergyMonitor Homepage\n\n","5":"\n\nEARS: Environmental Audio Recognition System\nEARS is a proof of concept implementation of a convolutional neural network for live environmental audio processing & recognition on low-power SoC devices (at this time it has been developed and tested on a Raspberry Pi 3 Model B).\nEARS features a background thread for audio capture & classification and a Bokeh server based dashboard providing live visualization and audio streaming from the device to the browser.\nCaveats:\nEARS is quite taxing on the CPU, so some proper cooling solution (heatsink) is advisable. Nevertheless, when not using the Bokeh app too much, it should work fine even without one.\nThe live audio stream can get choppy or out-of-sync, especially when using the mute\/unmute button.\nActual production deployments would profit from a server-node architecture where SoC devices are only pushing predictions, status updates and audio feeds to a central server handling all end user interaction, material browsing and visualization. This may be implemented in future versions, but no promises here.\nQuick look\n\nInstallation\nEARS has been developed and tested on a Raspberry Pi 3 Model B device. To recreate the environment used for developing this demo:\nStep 1 - prepare a Raspberry Pi device\n\nGet a spare Raspberry Pi 3 Model B with a blank SD card.\nInstall a Raspbian Jessie Lite distribution (tested on version April 2017):\n\nDownload a Raspbian Jessie Lite image from RaspberryPi.org.\nUse Etcher to flash the SD card (see Raspberry Pi docs for details).\n\n\nBoot the device with the new card.\nAttach some input & display devices for configuration.\nLogin using default credentials (user: pi, password: raspberry).\nSetup Wi-Fi access (see Wi-Fi config on Raspberry Pi).\nUse sudo raspi-config to enable SSH.\nRecreate SSH host keys:\n\nsudo rm \/etc\/ssh\/ssh_host_*\nsudo dpkg-reconfigure openssh-server\nStep 2 - install Python 3.6 using Berry Conda\n\nInstall conda for armv7l to \/opt\/conda:\n\nwget http:\/\/repo.continuum.io\/miniconda\/Miniconda3-latest-Linux-armv7l.sh\nchmod +x Miniconda3-latest-Linux-armv7l.sh\nsudo .\/Miniconda3-latest-Linux-armv7l.sh\n\n\nAdd export PATH=\"\/opt\/conda\/bin:$PATH\" to the end of \/home\/pi\/.bashrc. Then reload with source \/home\/pi\/.bashrc.\n\n\nInstall Python with required packages:\n\n\nconda config --add channels rpi\nconda create -n ears python=3.6\nsource activate ears\nconda install cython numpy pandas scikit-learn cffi h5py\n\nMake sure PortAudio headers are available. If not, installing pyaudio will complain later on:\n\nsudo apt-get install portaudio19-dev\nStep 3 - download EARS and install requirements\n\nDownload EARS source code and unpack it to \/home\/pi\/ears. Then install the required packages by issuing:\n\npip install -r \/home\/pi\/ears\/requirements.txt\n\nPlug a Zoom H1 microphone into the USB port (or some other audio device, but that's the one I used for initial testing), switch it into an audio interface mode (44.1 kHz\/16 bit), and verify it's listed by python -m sounddevice.\nUpdate the --allow-websocket-origin option inside \/home\/pi\/ears\/run.sh file with the IP address of the Raspberry Pi device.\nFinally, run the app with:\n\nchmod +x \/home\/pi\/ears\/run.sh\ncd \/home\/pi\/ears\n.\/run.sh\n\nPoint the web browser to: http:\/\/RASPBERRY_PI_IP:5006\/\n\nTraining new models\nFor the time being, EARS comes preloaded with a very rudimentary model trained on the ESC-50 dataset (convnet consisting of 3 layers, 3x3 square filters), so it's recognition capabilities are limited for actual live scenarios.\nIf you want to train the same model on a different dataset:\n\nDownload the source code to a workstation\/server with a GPU card.\nPut all audio files (WAV) into ears\/dataset\/audio.\nReplace the ears\/dataset\/dataset.csv file with new CSV:\n\nfilename,category\n\n\nRun python train.py - this should result in the following files being generated on the server:\n\n\n\n\nFile\nDescription\n\n\n\n\nmodel.h5\nweights of the learned model\n\n\nmodel.json\na serialized architecture of the model (Keras >=2.0.0)\n\n\nmodel_labels.json\ndataset labels\n\n\n\n\nUpload the new model files to the Raspberry Pi device and restart the app.\n\nIf you want to train a completely different model, then you can have a look at train.py. In this case you probably know what to do either way.\nPhotos from my development field:\n \nLicense\nMIT \u00a9 Karol J. Piczak\n","6":"Mycodo\nEnvironmental Regulation System\nLatest version: 8.8.8\nMycodo is open source software for the Raspberry Pi that couples inputs and outputs in interesting ways to sense and manipulate the environment.\n  \n\nMycodo Manual\nMycodo API (Latest Version: v1)\nMycodo Support Android App\nMycodo Wiki\nMycodo Custom Inputs and Controllers Repository\nFor technical support discussion, use the Mycodo Forum\n\nDonate\nI have always made Mycodo free and I don't intend on changing that. However, if you find Mycodo useful and would like to support its continued development, please consider becoming a sponsor at github.com\/sponsors\/kizniche\n\n\nTable of Contents\n\nDonate\nFeatures\nUses\nScreenshots\nInstall Mycodo\nSupport\nManual\nREST API\nAbout PID Control\nSupported Inputs and Outputs\nCustom Inputs, Outputs, and Controllers\nLinks\nLicense\nLanguages\nThanks\n\n\n\nFeatures\n\nInputs that record measurements from sensors, GPIO pin states, analog-to-digital converters, and more (or create your own Custom Inputs).\nOutputs that perform actions such as switching GPIO pins high\/low, generating PWM signals, executing shell scripts and Python code, and more (or create your own Custom Outputs).\nFunctions that perform tasks, such as coupling Inputs and Outputs in interesting ways, such as PID controllers, Conditional Controllers, Trigger Controllers, to name a few (or create your own Custom Functions).\nWeb Interface for securely accessing Mycodo using a web browser on your local network or anywhere in the world with an internet connection, to view and configure the system, which includes several light and dark themes.\nDashboards that display configurable widgets, including interactive live and historical graphs, gauges, output state indicators, measurements, and more (or create your own Custom Widgets).\nAlert Notifications to send emails when measurements reach or exceed user-specified thresholds, important for knowing immediately when issues arise.\nSetpoint Tracking for changing a PID controller setpoint over time, for use with things like terrariums, reflow ovens, thermal cyclers, sous-vide cooking, and more.\nNotes to record events, alerts, and other important points in time, which can be overlaid on graphs to visualize events with your measurement data.\nCameras for remote live streaming, image capture, and time-lapse photography.\nEnergy Usage Measurement for calculating and tracking power consumption and cost over time.\nUpgrade System to easily upgrade the Mycodo system to the latest release to get the newest features or restore to a previously-backed up version.\nTranslations that enable the web interface to be presented in different Languages.\n\n\nFigure: Automated Hydroponic System Build\n\n\nUses\nOriginally developed to cultivate edible mushrooms, Mycodo has evolved to do much more. Here are a few things that have been done with Mycodo:\n\nMy projects\n\nHydroponic System Automation (Archive)\nMushroom cultivation (Archive)\nGround-based plant cultivation\nMaintaining honey bee apiary homeostasis (Archive)\nMaintaining humidity in an underground artificial bat cave (Archive)\nRemote radiation monitoring and mapping (Archive)\nCooking sous-vide (Archive)\nMaintaining a light schedule and regulating humidity, ramping from 90 % to 50 % over a 4 week period to acclimatize micropropagated American chestnut plantlets from laboratory to ambient outdoor conditions (Archive)\n\n\nFeatured\n\n\nProjects of others\n\nMaintaining aquatic systems (e.g. fish, hydroponic, aquaponic)\nMaintaining terrarium, herpetarium, and vivarium environments\nIncubating young animals and eggs\nAging cheese\nDry-aging, curing, and smoking meat (Archive)\nFermenting beer, food, and tobacco\nControlling reflow ovens\nCulturing microorganisms\nTreating agricultural waste water (Archive)\n...and more\n\nLet me know how you use Mycodo and I may include it on this list.\n\nScreenshots\nVisit the Screenshots page of the Wiki.\n\nInstall Mycodo\n\nPrerequisites\n\nRaspberry Pi single-board computer (any version: Zero, 1, 2, 3, or 4)\nRaspberry Pi Operating System flashed to a micro SD card\nAn active internet connection\n\nMycodo has been tested to work with Raspberry Pi OS Lite (2020-05-27), and also the Desktop version if using Mycodo version => 8.6.0.\n\nInstall\nOnce you have the Raspberry Pi booted into the Raspberry Pi OS with an internet connection, run the following command in a terminal to initiate the Mycodo install:\ncurl -L https:\/\/kizniche.github.io\/Mycodo\/install | bash\n\nInstall Notes\nMake sure the install script finishes without errors. A log of the output will be created at ~\/Mycodo\/install\/setup.log.\nIf the install is successful, the web user interface should be accessible by navigating a web browser to https:\/\/127.0.0.1\/, replacing 127.0.0.1 with your Raspberry Pi's IP address. Upon your first visit, you will be prompted to create an admin user before being redirected to the login page. Once logged in, check that the time is correct at the top left of the page. Incorrect time can cause a number of issues with measurement storage and retrieval, among others. Also ensure the host name and version number at the top left of the page is green, indicating the daemon is running. Red indicates the daemon is inactive or unresponsive. Last, ensure any java-blocking plugins of your browser are disabled for all parts of the web interface to function properly.\nIf you receive an error during the install that you believe is preventing your system from operating, please create an issue with the install log attached. If you would first like to attempt to diagnose the issue yourself, see Diagnosing Issues.\nA minimal set of anonymous usage statistics are collected to help improve development. No identifying information is saved from the information that is collected and it is only used to improve Mycodo. No other sources will have access to this information. The data collected is mainly what and how many features are used, and other similar information. The data that's collected can be viewed from the 'View collected statistics' link in the Settings -> General page. There is an opt out option on the General Settings page.\n\nSupport\nBefore making a post to the forum or issue tracker on github, please read the\nManual.\n\nNeed assistance with Mycodo\nIf Mycodo is supposedly operating correctly and you would like assistance with how to configure the system or to merely discuss something related to Mycodo, do a search on the Mycodo Forum for a similar discussion. If a similar topic doesn't already exist on the forum, create a new post in the appropriate subforum.\n\nBug in the Mycodo Software\nIf you believe there is a bug in the Mycodo software, first search through the guthub Issues and see if your issue has already recently been discussed or resolved. If your issue is novel or significantly mre recent than a similar one, you should create a New Issue. When creating a new issue, make sure to read all information in the issue template and follow the instructions. Replace the template text with the information being requested (e.g. \"step 1\" under \"Steps to Reproduce the issue\" should be replaced with the actual steps to reproduce the issue). The more information you provide, the easier it is to reproduce and diagnose the issue. If the issue is not able to reproduced because not enough information is provided, it may delay or prevent solving the issue.\n\nManual\nThe Mycodo Manual may be found at https:\/\/kizniche.github.io\/Mycodo\nThe Mycodo Wiki also contains useful information.\n\nREST API\nThe latest API documentation can be found here: API Information and API Endpoint Documentation.\n\nAbout PID Control\nA proportional\u2013integral\u2013derivative (PID) controller is a control loop feedback mechanism used throughout industry for controlling systems. It efficiently brings a measurable condition, such as temperature, to a desired state (setpoint). A well-tuned PID controller can raise to a setpoint quickly, have minimal overshoot, and maintain the setpoint with little oscillation.\n\n\n\n\nThe top graph visualizes the regulation of temperature. The red line is the desired temperature (setpoint) that has been configured to change over the course of each day. The blue line is the actual recorded temperature. The green vertical bars represent how long a heater has been activated for every 20-second period. This regulation was achieved with minimal tuning, and already displays a very minimal deviation from the setpoint (\u00b10.5\u00b0 Celsius). Further tuning would reduce this variability further.\nSee the PID Controller and PID Tuning sections of the manual for more information.\n\nSupported Inputs and Outputs\nAll supported Inputs, Outputs, and other devices can be found under the Supported Devices section of the manual.\n\nCustom Inputs, Outputs, and Controllers\nMycodo supports importing custom Input, Output, and Controller modules. you can find more information about each in the manual under Custom Inputs, Custom Outputs, and Custom Functions.\nIf you would like to add to the list of supported Inputs, Outputs, and Controllers, submit a pull request with the module you created or start a New Issue.\nAdditionally, I have another github repository devoted to custom Inputs, Outputs, and Controllers that do not necessarily fit with the built-in set and are not included by default with Mycodo, but can be imported. These can be found at kizniche\/Mycodo-custom.\n\nLinks\nThanks for using and supporting Mycodo, however depending where you found this documentation, you may not have the latest version or it may have been altered, if not obtained through an official distribution site. You should be able to find the latest version on github or my web site at the following links.\nhttps:\/\/github.com\/kizniche\/Mycodo\nhttps:\/\/KyleGabriel.com\n\nLicense\nSee License.txt\nMycodo is free software: you can redistribute it and\/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\nMycodo is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\nA full copy of the GNU General Public License can be found at http:\/\/www.gnu.org\/licenses\/gpl-3.0.en.html\nThis software includes third party open source software components. Please see individual files for license information, if applicable.\n\nLanguages\n\nNative: English\nComplete: Dutch,\nGerman,\nFrench,\nItalian,\nNorwegian,\nPolish,\nPortuguese,\nRussian,\nSerbian,\nSpanish,\nSwedish,\nChinese.\n\nBy default, mycodo will display the default language set by your browser. You may also force a language in the settings at [Gear Icon] -> Configure -> General -> Language\nIf you would like to improve the translations, you can submit a pull request with an amended .po file from ~\/Mycodo\/mycodo\/mycodo_flask\/translations\/ or start a New Issue detailing the corrections.\n\nEnglish\nThe native language used in the software.\n\nDutch\nMycodo is een geautomatiseerd monitoring- en regelsysteem dat is gebouwd\nom op de Raspberry Pi te draaien (versies Zero, 1, 2, 3 en 4).\nOorspronkelijk ontworpen om eetbare paddenstoelen te kweken, is Mycodo\nuitgegroeid tot het vermogen om veel meer te doen, waaronder het kweken\nvan planten, het kweken van micro-organismen, het onderhouden van\nbijenbijen bij de bijen, het incuberen van dieren en eieren, het\nonderhouden van aquatische systemen, het ouder worden van kazen, het\nfermenteren van voedsel en tabak, het koken eten (sous-vide) en meer.\nHet systeem bestaat uit een backend (daemon) en een frontend\n(gebruikersinterface). De backend voert metingen uit van sensoren en\napparaten, co\u00f6rdineert vervolgens een diverse reeks antwoorden op die\nmetingen, inclusief het vermogen om outputs te moduleren (relais, PWM,\ndraadloze outlets), omgevingsomstandigheden te regelen met elektrische\napparaten onder PID-regeling (gestage regeling of omschakeling tijd),\ntimers plannen, foto's maken en video streamen, acties activeren wanneer\nmetingen aan bepaalde voorwaarden voldoen (relais moduleren, opdrachten\nuitvoeren, per e-mail op de hoogte stellen, etc.) en meer. De frontend is\neen webinterface die gemakkelijke navigatie en configuratie mogelijk\nmaakt vanaf elk apparaat met een browser.\n\nFrench\nMycodo est un syst\u00e8me de surveillance et de r\u00e9gulation automatis\u00e9 con\u00e7u\npour fonctionner sur le Raspberry Pi (versions z\u00e9ro, 1, 2, 3 et 4).\nCon\u00e7u \u00e0 l'origine pour cultiver des champignons comestibles, Mycodo s'est\nd\u00e9velopp\u00e9 pour inclure la capacit\u00e9 de faire beaucoup plus, notamment la\nculture de plantes, la culture de micro-organismes, le maintien de\nl'hom\u00e9ostasie du rucher des abeilles, la mise en incubation des animaux\net des \u0153ufs, la maintenance des syst\u00e8mes aquatiques, le vieillissement\ndes fromages, la fermentation nourriture (sous vide), et plus.\nLe syst\u00e8me comprend un serveur (d\u00e9mon) et une interface utilisateur\n(interface utilisateur). Le syst\u00e8me effectue des mesures \u00e0 partir de\ncapteurs et d\u2019appareils, puis coordonne un ensemble divers de r\u00e9ponses \u00e0\nces mesures, notamment la possibilit\u00e9 de moduler les sorties (relais,\nPWM, prises sans fil), de r\u00e9guler les conditions environnementales avec\ndes appareils \u00e9lectriques sous contr\u00f4le PID (r\u00e9gulation continue ou\nbasculement temps), planifiez des minuteries, capturez des photos et des\nflux vid\u00e9o, d\u00e9clenchez des actions lorsque les mesures r\u00e9pondent \u00e0\ncertaines conditions (moduler des relais, ex\u00e9cuter des commandes, notifier\npar courrier \u00e9lectronique, etc.), etc. L'interface Web est une interface\nWeb qui facilite la navigation et la configuration \u00e0 partir de tout\nappareil compatible avec le navigateur.\n\nGerman\nMycodo ist ein automatisiertes \u00dcberwachungs- und Regulierungssystem, das\nf\u00fcr den Raspberry Pi (Versionen Zero, 1, 2, 3 und 4) entwickelt wurde.\nUrspr\u00fcnglich f\u00fcr die Kultivierung von Speisepilzen konzipiert, hat Mycodo\ndie F\u00e4higkeit zu weitaus mehr erweitert, darunter die Kultivierung von\nPflanzen, die Kultivierung von Mikroorganismen, die Aufrechterhaltung der\nHom\u00f6ostase der Bienenhaus-Bienenh\u00e4user, die Inkubation von Tieren und\nEiern, die Aufrechterhaltung von Wassersystemen, das Altern von K\u00e4se, das\nG\u00e4ren von Lebensmitteln und Tabak sowie das Kochen Essen (Sous-Vide) und\nmehr.\nDas System besteht aus einem Backend (Daemon) und einem Frontend\n(Benutzeroberfl\u00e4che). Das Backend f\u00fchrt Messungen von Sensoren und Ger\u00e4ten\ndurch und koordiniert dann eine Vielzahl von Reaktionen auf diese\nMessungen, einschlie\u00dflich der M\u00f6glichkeit, Ausg\u00e4nge (Relais, PWM,\ndrahtlose Ausg\u00e4nge) zu modulieren und Umgebungsbedingungen mit elektrischen\nGer\u00e4ten unter PID-Steuerung zu regulieren (stetige Regelung oder\nUmschaltung) Zeit), Zeitpl\u00e4ne planen, Fotos aufnehmen und Videos streamen,\nAktionen ausl\u00f6sen, wenn Messungen bestimmte Bedingungen erf\u00fcllen (Relais\nmodulieren, Befehle ausf\u00fchren, per E-Mail benachrichtigen usw.) und vieles\nmehr. Das Frontend ist eine Weboberfl\u00e4che, die eine einfache Navigation und\nKonfiguration von jedem Browser-f\u00e4higen Ger\u00e4t aus erm\u00f6glicht.\n\nItalian\nMycodo \u00e8 un sistema di monitoraggio e regolazione automatico che \u00e8 stato\ncreato per funzionare sul Raspberry Pi (versioni Zero, 1, 2, 3 e 4).\nOriginariamente progettato per coltivare funghi commestibili, Mycodo \u00e8\ncresciuto fino a comprendere la capacit\u00e0 di fare molto di pi\u00f9, coltivando\npiante, coltivando microrganismi, mantenendo l'omeostasi delle api apistiche\ndel miele, incubando animali e uova, mantenendo sistemi acquatici, formaggi\nstagionati, alimenti fermentati e tabacco, cucinando cibo (sous-vide) e\naltro ancora.\nIl sistema comprende un backend (demone) e un frontend (interfaccia utente).\nIl back-end esegue misurazioni da sensori e dispositivi, quindi coordina un\ninsieme diversificato di risposte a tali misurazioni, inclusa la possibilit\u00e0\ndi modulare le uscite (rel\u00e8, PWM, prese wireless), regola le condizioni\nambientali con dispositivi elettrici sotto controllo PID (regolazione costante\no commutazione tempo), programmare i timer, acquisire foto e trasmettere\nvideo, attivare azioni quando le misurazioni soddisfano determinate condizioni\n(modulazione di rel\u00e8, esecuzione di comandi, notifica via e-mail, ecc.) e\naltro. Il frontend \u00e8 un'interfaccia web che consente una facile navigazione e\nconfigurazione da qualsiasi dispositivo abilitato per il browser.\n\nNorwegian\nMycodo er et automatisert overv\u00e5kings- og reguleringssystem som ble bygget\nfor \u00e5 kj\u00f8re p\u00e5 Raspberry Pi (versjoner Zero, 1, 2, 3 og 4).\nMycodo er opprinnelig utviklet for \u00e5 dyrke spiselige sopp, og har vokst\ntil \u00e5 inkludere muligheten til \u00e5 gj\u00f8re mye mer, inkludert dyrking av\nplanter, dyrking av mikroorganismer, opprettholder honningbi apiary\nhomeostasis, inkubering av dyr og egg, opprettholde akvatiske systemer,\naldrende oster, fermenterende matvarer og tobakk, matlaging mat (sous-vide)\nog mer.\nSystemet best\u00e5r av en backend (daemon) og en frontend (brukergrensesnitt).\nBackend utf\u00f8rer m\u00e5linger fra sensorer og enheter, og koordinerer deretter\net mangfoldig sett med svar p\u00e5 disse m\u00e5lingene, inkludert muligheten til \u00e5\nmodulere utganger (rel\u00e9er, PWM, tr\u00e5dl\u00f8se uttak), regulere milj\u00f8forhold med\nelektriske enheter under PID-kontroll (stabil regulering eller endring over\ntid), planlegge timere, ta bilder og streame video, utl\u00f8se handlinger n\u00e5r\nm\u00e5lingene oppfyller visse forhold (modulere rel\u00e9er, utf\u00f8re kommandoer,\nvarsle via e-post, etc.) og mer. Frontend er et webgrensesnitt som gj\u00f8r det\nenkelt \u00e5 navigere og konfigurere fra hvilken som helst nettleseraktivert\nenhet.\n\nPolish\nMycodo to zautomatyzowany system monitorowania i regulacji, kt\u00f3ry zosta\u0142 zbudowany do pracy na Raspberry Pi (wersje Zero, 1, 2 i 3).\nPierwotnie zaprojektowany do uprawy grzyb\u00f3w jadalnych, Mycodo rozwin\u0119\u0142o si\u0119, aby umo\u017cliwi\u0107 znacznie wi\u0119cej, w tym upraw\u0119 ro\u015blin, hodowl\u0119 mikroorganizm\u00f3w, utrzymanie homeostazy pszcz\u00f3\u0142 miodnych, inkubacj\u0119 zwierz\u0105t i jaj, utrzymanie system\u00f3w wodnych, dojrzewanie ser\u00f3w, fermentacj\u0119 \u017cywno\u015bci i tytoniu, gotowanie jedzenie (sous-vide) i nie tylko.\nSystem sk\u0142ada si\u0119 z zaplecza (demona) i frontendu (interfejsu u\u017cytkownika). Backend przeprowadza pomiary z czujnik\u00f3w i urz\u0105dze\u0144, a nast\u0119pnie koordynuje zr\u00f3\u017cnicowany zestaw odpowiedzi na te pomiary, w tym mo\u017cliwo\u015b\u0107 modulacji wyj\u015b\u0107 (przeka\u017aniki, PWM, wyj\u015bcia bezprzewodowe), regulacj\u0119 warunk\u00f3w \u015brodowiskowych za pomoc\u0105 urz\u0105dze\u0144 elektrycznych pod kontrol\u0105 PID (regulacja sta\u0142a lub prze\u0142\u0105czanie czas), ustawianie timer\u00f3w, robienie zdj\u0119\u0107 i strumieniowanie wideo, wyzwalanie dzia\u0142a\u0144, gdy pomiary spe\u0142niaj\u0105 okre\u015blone warunki (modulacja przeka\u017anik\u00f3w, wykonywanie polece\u0144, powiadamianie przez e-mail itp.) i nie tylko. Frontend to interfejs sieciowy, kt\u00f3ry umo\u017cliwia \u0142atw\u0105 nawigacj\u0119 i konfiguracj\u0119 z dowolnego urz\u0105dzenia obs\u0142uguj\u0105cego przegl\u0105dark\u0119.\n\nPortuguese\nO Mycodo \u00e9 um sistema automatizado de monitoramento e regula\u00e7\u00e3o que foi\nconstru\u00eddo para rodar no Raspberry Pi (vers\u00f5es Zero, 1, 2, 3 e 4).\nOriginalmente concebido para cultivar cogumelos comest\u00edveis, o Mycodo\ncresceu para incluir a capacidade de fazer muito mais, incluindo cultivar\nplantas, cultivar microorganismos, manter a homeostase do api\u00e1rio de\nabelhas, incubar animais e ovos, manter sistemas aqu\u00e1ticos, queijos\nenvelhecidos, fermentar alimentos e tabaco, cozinhar comida (sous-vide) e\nmuito mais.\nO sistema compreende um backend (daemon) e um frontend (interface de\nusu\u00e1rio). O backend conduz medi\u00e7\u00f5es a partir de sensores e dispositivos e\ncoordena um conjunto diversificado de respostas a essas medi\u00e7\u00f5es,\nincluindo a capacidade de modular sa\u00eddas (rel\u00e9s, PWM, tomadas sem fio),\nregular as condi\u00e7\u00f5es ambientais com dispositivos el\u00e9tricos sob controle\nPID (regula\u00e7\u00e3o est\u00e1vel ou troca tempo), agendar cron\u00f4metros, capturar\nfotos e transmitir v\u00eddeo, acionar a\u00e7\u00f5es quando as medi\u00e7\u00f5es atenderem a\ndeterminadas condi\u00e7\u00f5es (modular rel\u00e9s, executar comandos, notificar por\ne-mail etc.) e muito mais. O frontend \u00e9 uma interface da web que permite\nf\u00e1cil navega\u00e7\u00e3o e configura\u00e7\u00e3o a partir de qualquer dispositivo habilitado\npara navegador.\n\nRussian\nMycodo - \u044d\u0442\u043e \u0430\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u0430\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043c\u043e\u043d\u0438\u0442\u043e\u0440\u0438\u043d\u0433\u0430 \u0438 \u0440\u0435\u0433\u0443\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f,\n\u0441\u043e\u0437\u0434\u0430\u043d\u043d\u0430\u044f \u0434\u043b\u044f \u0440\u0430\u0431\u043e\u0442\u044b \u043d\u0430 Raspberry Pi (\u0432\u0435\u0440\u0441\u0438\u0438 Zero, 1, 2, 3 \u0438 4).\n\u041f\u0435\u0440\u0432\u043e\u043d\u0430\u0447\u0430\u043b\u044c\u043d\u043e \u0440\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u0430\u043d\u043d\u044b\u0439 \u0434\u043b\u044f \u0432\u044b\u0440\u0430\u0449\u0438\u0432\u0430\u043d\u0438\u044f \u0441\u044a\u0435\u0434\u043e\u0431\u043d\u044b\u0445 \u0433\u0440\u0438\u0431\u043e\u0432, Mycodo\n\u0432\u044b\u0440\u043e\u0441 \u0438 \u0442\u0435\u043f\u0435\u0440\u044c \u0441\u043f\u043e\u0441\u043e\u0431\u0435\u043d \u0434\u0435\u043b\u0430\u0442\u044c \u0433\u043e\u0440\u0430\u0437\u0434\u043e \u0431\u043e\u043b\u044c\u0448\u0435, \u0432\u043a\u043b\u044e\u0447\u0430\u044f \u0432\u044b\u0440\u0430\u0449\u0438\u0432\u0430\u043d\u0438\u0435\n\u0440\u0430\u0441\u0442\u0435\u043d\u0438\u0439, \u0432\u044b\u0440\u0430\u0449\u0438\u0432\u0430\u043d\u0438\u0435 \u043c\u0438\u043a\u0440\u043e\u043e\u0440\u0433\u0430\u043d\u0438\u0437\u043c\u043e\u0432, \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u0430\u043d\u0438\u0435 \u0433\u043e\u043c\u0435\u043e\u0441\u0442\u0430\u0437\u0430 \u043f\u0430\u0441\u0435\u043a\u0438\n\u043c\u0435\u0434\u043e\u043d\u043e\u0441\u043d\u044b\u0445 \u043f\u0447\u0435\u043b, \u0438\u043d\u043a\u0443\u0431\u0430\u0446\u0438\u044e \u0436\u0438\u0432\u043e\u0442\u043d\u044b\u0445 \u0438 \u044f\u0438\u0446, \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u0430\u043d\u0438\u0435 \u0432\u043e\u0434\u043d\u044b\u0445 \u0441\u0438\u0441\u0442\u0435\u043c,\n\u0441\u0442\u0430\u0440\u0435\u043d\u0438\u0435 \u0441\u044b\u0440\u043e\u0432, \u0444\u0435\u0440\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u043e\u0432 \u0438 \u0442\u0430\u0431\u0430\u043a\u0430, \u043f\u0440\u0438\u0433\u043e\u0442\u043e\u0432\u043b\u0435\u043d\u0438\u0435 \u043f\u0438\u0449\u0438. \u0435\u0434\u0430\n(sous-vide) \u0438 \u043c\u043d\u043e\u0433\u043e\u0435 \u0434\u0440\u0443\u0433\u043e\u0435.\n\u0421\u0438\u0441\u0442\u0435\u043c\u0430 \u0432\u043a\u043b\u044e\u0447\u0430\u0435\u0442 \u0432 \u0441\u0435\u0431\u044f \u0431\u044d\u043a\u044d\u043d\u0434 (\u0434\u0435\u043c\u043e\u043d) \u0438 \u0438\u043d\u0442\u0435\u0440\u0444\u0435\u0439\u0441 (\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u0441\u043a\u0438\u0439\n\u0438\u043d\u0442\u0435\u0440\u0444\u0435\u0439\u0441). \u0411\u044d\u043a\u044d\u043d\u0434 \u043f\u0440\u043e\u0432\u043e\u0434\u0438\u0442 \u0438\u0437\u043c\u0435\u0440\u0435\u043d\u0438\u044f \u043e\u0442 \u0434\u0430\u0442\u0447\u0438\u043a\u043e\u0432 \u0438 \u0443\u0441\u0442\u0440\u043e\u0439\u0441\u0442\u0432, \u0437\u0430\u0442\u0435\u043c\n\u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0438\u0440\u0443\u0435\u0442 \u0440\u0430\u0437\u043d\u043e\u043e\u0431\u0440\u0430\u0437\u043d\u044b\u0439 \u043d\u0430\u0431\u043e\u0440 \u043e\u0442\u0432\u0435\u0442\u043e\u0432 \u043d\u0430 \u044d\u0442\u0438 \u0438\u0437\u043c\u0435\u0440\u0435\u043d\u0438\u044f, \u0432\u043a\u043b\u044e\u0447\u0430\u044f\n\u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0443\u043b\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0432\u044b\u0445\u043e\u0434\u044b (\u0440\u0435\u043b\u0435, \u0428\u0418\u041c, \u0431\u0435\u0441\u043f\u0440\u043e\u0432\u043e\u0434\u043d\u044b\u0435 \u0432\u044b\u0445\u043e\u0434\u044b),\n\u0440\u0435\u0433\u0443\u043b\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0443\u0441\u043b\u043e\u0432\u0438\u044f \u043e\u043a\u0440\u0443\u0436\u0430\u044e\u0449\u0435\u0439 \u0441\u0440\u0435\u0434\u044b \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u044d\u043b\u0435\u043a\u0442\u0440\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u0443\u0441\u0442\u0440\u043e\u0439\u0441\u0442\u0432\n\u043f\u043e\u0434 \u0443\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0435\u043c \u041f\u0418\u0414 (\u043f\u043e\u0441\u0442\u043e\u044f\u043d\u043d\u043e\u0435 \u0440\u0435\u0433\u0443\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0438\u043b\u0438 \u043f\u0435\u0440\u0435\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u0435). \u0432\u0440\u0435\u043c\u044f),\n\u043f\u043b\u0430\u043d\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0442\u0430\u0439\u043c\u0435\u0440\u044b, \u0437\u0430\u0445\u0432\u0430\u0442\u044b\u0432\u0430\u0442\u044c \u0444\u043e\u0442\u043e\u0433\u0440\u0430\u0444\u0438\u0438 \u0438 \u043f\u043e\u0442\u043e\u043a\u043e\u0432\u043e\u0435 \u0432\u0438\u0434\u0435\u043e, \u0437\u0430\u043f\u0443\u0441\u043a\u0430\u0442\u044c\n\u0434\u0435\u0439\u0441\u0442\u0432\u0438\u044f, \u043a\u043e\u0433\u0434\u0430 \u0438\u0437\u043c\u0435\u0440\u0435\u043d\u0438\u044f \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u044e\u0442 \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u043d\u044b\u043c \u0443\u0441\u043b\u043e\u0432\u0438\u044f\u043c\n(\u043c\u043e\u0434\u0443\u043b\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0440\u0435\u043b\u0435, \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0442\u044c \u043a\u043e\u043c\u0430\u043d\u0434\u044b, \u043e\u0442\u043f\u0440\u0430\u0432\u043b\u044f\u0442\u044c \u0443\u0432\u0435\u0434\u043e\u043c\u043b\u0435\u043d\u0438\u044f \u043f\u043e\n\u044d\u043b\u0435\u043a\u0442\u0440\u043e\u043d\u043d\u043e\u0439 \u043f\u043e\u0447\u0442\u0435 \u0438 \u0442. \u0434.) \u0438 \u043c\u043d\u043e\u0433\u043e\u0435 \u0434\u0440\u0443\u0433\u043e\u0435. \u0418\u043d\u0442\u0435\u0440\u0444\u0435\u0439\u0441 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442 \u0441\u043e\u0431\u043e\u0439\n\u0432\u0435\u0431-\u0438\u043d\u0442\u0435\u0440\u0444\u0435\u0439\u0441, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043e\u0431\u0435\u0441\u043f\u0435\u0447\u0438\u0432\u0430\u0435\u0442 \u043f\u0440\u043e\u0441\u0442\u0443\u044e \u043d\u0430\u0432\u0438\u0433\u0430\u0446\u0438\u044e \u0438 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0443 \u0441 \u043b\u044e\u0431\u043e\u0433\u043e\n\u0443\u0441\u0442\u0440\u043e\u0439\u0441\u0442\u0432\u0430 \u0441 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u043e\u0439 \u0431\u0440\u0430\u0443\u0437\u0435\u0440\u0430.\n\nSerbian\n\u041c\u0438\u0446\u043e\u0434\u043e \u0458\u0435 \u0430\u0443\u0442\u043e\u043c\u0430\u0442\u0441\u043a\u0438 \u0441\u0438\u0441\u0442\u0435\u043c \u0437\u0430 \u043d\u0430\u0434\u0437\u043e\u0440 \u0438 \u0440\u0435\u0433\u0443\u043b\u0430\u0446\u0438\u0458\u0443 \u043a\u043e\u0458\u0438 \u0458\u0435 \u043d\u0430\u043f\u0440\u0430\u0432\u0459\u0435\u043d \u0434\u0430\n\u0440\u0430\u0434\u0438 \u043d\u0430 \u0420\u0430\u0441\u043f\u0431\u0435\u0440\u0440\u0438 \u041f\u0438 (\u0432\u0435\u0440\u0437\u0438\u0458\u0435 \u0417\u0435\u0440\u043e, 1, 2, 3 \u0438 4).\n\u041e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u043d\u043e \u0434\u0438\u0437\u0430\u0458\u043d\u0438\u0440\u0430\u043d \u0437\u0430 \u0443\u0437\u0433\u0430\u0458\u0430\u045a\u0435 \u0458\u0435\u0441\u0442\u0438\u0432\u0438\u0445 \u0433\u0459\u0438\u0432\u0430, \u041c\u0438\u0446\u043e\u0434\u043e \u0458\u0435 \u043d\u0430\u0440\u0430\u0441\u0442\u0430\u043e \u043d\u0430\n\u043c\u043e\u0433\u0443\u045b\u043d\u043e\u0441\u0442 \u0434\u0430 \u0443\u0440\u0430\u0434\u0438 \u043c\u043d\u043e\u0433\u043e \u0432\u0438\u0448\u0435, \u0443\u043a\u0459\u0443\u0447\u0443\u0458\u0443\u045b\u0438 \u043a\u0443\u043b\u0442\u0438\u0432\u0438\u0440\u0430\u045a\u0435 \u0431\u0438\u0459\u0430\u043a\u0430, \u043a\u0443\u043b\u0442\u0438\u0432\u0438\u0441\u0430\u045a\u0435\n\u043c\u0438\u043a\u0440\u043e\u043e\u0440\u0433\u0430\u043d\u0438\u0437\u0430\u043c\u0430, \u043e\u0434\u0440\u0436\u0430\u0432\u0430\u045a\u0435 \u0445\u043e\u043c\u0435\u043e\u0441\u0442\u0430\u0437\u0435 \u043f\u0447\u0435\u043b\u0438\u045a\u0435\u0433 \u043c\u0435\u0434\u0430, \u0438\u043d\u043a\u0443\u0431\u0438\u0440\u0430\u045a\u0435 \u0436\u0438\u0432\u043e\u0442\u0438\u045a\u0430\n\u0438 \u0458\u0430\u0458\u0430, \u043e\u0434\u0440\u0436\u0430\u0432\u0430\u045a\u0435 \u0432\u043e\u0434\u0435\u043d\u0438\u0445 \u0441\u0438\u0441\u0442\u0435\u043c\u0430, \u0441\u0442\u0430\u0440\u0435\u045a\u0435 \u0441\u0438\u0440\u0435\u0432\u0430, \u0444\u0435\u0440\u043c\u0435\u043d\u0442\u0438\u0441\u0430\u045a\u0435 \u0445\u0440\u0430\u043d\u0435 \u0438\n\u0434\u0443\u0432\u0430\u043d, \u043a\u0443\u0445\u0430\u045a\u0435 \u0445\u0440\u0430\u043d\u0430 (\u0441\u043e\u0443\u0441-\u0432\u0438\u0434\u0435), \u0438 \u0432\u0438\u0448\u0435.\n\u0421\u0438\u0441\u0442\u0435\u043c \u0441\u0430\u0434\u0440\u0436\u0438 \u0431\u0430\u0446\u043a\u0435\u043d\u0434 (\u0434\u0430\u0435\u043c\u043e\u043d) \u0438 \u0444\u0440\u043e\u043d\u0442\u0435\u043d\u0434 (\u043a\u043e\u0440\u0438\u0441\u043d\u0438\u0447\u043a\u0438 \u0438\u043d\u0442\u0435\u0440\u0444\u0435\u0458\u0441). \u0411\u0430\u0446\u043a\u0435\u043d\u0434\n\u0432\u0440\u0448\u0438 \u043c\u0435\u0440\u0435\u045a\u0430 \u043e\u0434 \u0441\u0435\u043d\u0437\u043e\u0440\u0430 \u0438 \u0443\u0440\u0435\u0452\u0430\u0458\u0430, \u0437\u0430\u0442\u0438\u043c \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0438\u0440\u0430 \u0440\u0430\u0437\u043b\u0438\u0447\u0438\u0442\u0435 \u043e\u0434\u0433\u043e\u0432\u043e\u0440\u0435 \u043d\u0430\n\u0442\u0430 \u043c\u0435\u0440\u0435\u045a\u0430, \u0443\u043a\u0459\u0443\u0447\u0443\u0458\u0443\u045b\u0438 \u043c\u043e\u0433\u0443\u045b\u043d\u043e\u0441\u0442 \u043c\u043e\u0434\u0443\u043b\u0430\u0446\u0438\u0458\u0435 \u0438\u0437\u043b\u0430\u0437\u0430 (\u0440\u0435\u043b\u0435\u0458\u0438, \u041f\u0412\u041c, \u0431\u0435\u0436\u0438\u0447\u043d\u0435\n\u0443\u0442\u0438\u0447\u043d\u0438\u0446\u0435), \u0440\u0435\u0433\u0443\u043b\u0438\u0441\u0430\u045a\u0435 \u0443\u0441\u043b\u043e\u0432\u0430 \u043e\u043a\u043e\u043b\u0438\u043d\u0435 \u0441\u0430 \u0435\u043b\u0435\u043a\u0442\u0440\u0438\u0447\u043d\u0438\u043c \u0443\u0440\u0435\u0452\u0430\u0458\u0438\u043c\u0430 \u043f\u043e\u0434 \u041f\u0418\u0414\n\u043a\u043e\u043d\u0442\u0440\u043e\u043b\u043e\u043c (\u0441\u0442\u0430\u043b\u043d\u0430 \u0440\u0435\u0433\u0443\u043b\u0430\u0446\u0438\u0458\u0430 \u0438\u043b\u0438 \u043f\u0440\u043e\u043c\u0435\u043d\u0430 \u0432\u0440\u0435\u043c\u0435), \u0440\u0430\u0441\u043f\u043e\u0440\u0435\u0434 \u0432\u0440\u0435\u043c\u0435\u043d\u0430, \u0441\u043d\u0438\u043c\u0430\u045a\u0435\n\u0444\u043e\u0442\u043e\u0433\u0440\u0430\u0444\u0438\u0458\u0430 \u0438 \u0441\u0442\u0440\u0438\u043c\u043e\u0432\u0430\u045a\u0435 \u0432\u0438\u0434\u0435\u043e \u0441\u043d\u0438\u043c\u0430\u043a\u0430, \u0430\u043a\u0446\u0438\u0458\u0435 \u043f\u043e\u043a\u0440\u0435\u0442\u0430\u045a\u0430 \u043a\u0430\u0434\u0430 \u043c\u0435\u0440\u0435\u045a\u0430\n\u0438\u0441\u043f\u0443\u045a\u0430\u0432\u0430\u0458\u0443 \u043e\u0434\u0440\u0435\u0452\u0435\u043d\u0435 \u0443\u0441\u043b\u043e\u0432\u0435 (\u043c\u043e\u0434\u0443\u043b\u0430\u0446\u0438\u0458\u0430 \u0440\u0435\u043b\u0435\u0458\u0430, \u0438\u0437\u0432\u0440\u0448\u0430\u0432\u0430\u045a\u0435 \u043a\u043e\u043c\u0430\u043d\u0434\u0438,\n\u043e\u0431\u0430\u0432\u0435\u0448\u0442\u0430\u0432\u0430\u045a\u0435 \u043f\u0443\u0442\u0435\u043c \u0435-\u043f\u043e\u0448\u0442\u0435, \u0438\u0442\u0434.), \u0438 \u0458\u043e\u0448 \u043c\u043d\u043e\u0433\u043e \u0442\u043e\u0433\u0430. \u0424\u0440\u043e\u043d\u0442\u0435\u043d\u0434 \u0458\u0435 \u0432\u0435\u0431\n\u0438\u043d\u0442\u0435\u0440\u0444\u0435\u0458\u0441 \u043a\u043e\u0458\u0438 \u043e\u043c\u043e\u0433\u0443\u045b\u0430\u0432\u0430 \u0458\u0435\u0434\u043d\u043e\u0441\u0442\u0430\u0432\u043d\u0443 \u043d\u0430\u0432\u0438\u0433\u0430\u0446\u0438\u0458\u0443 \u0438 \u043a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u0458\u0443 \u0441\u0430 \u0431\u0438\u043b\u043e\n\u043a\u043e\u0433 \u0443\u0440\u0435\u0452\u0430\u0458\u0430 \u0441\u0430 \u043e\u043c\u043e\u0433\u0443\u045b\u0435\u043d\u0438\u043c \u043f\u0440\u0435\u0442\u0440\u0430\u0436\u0438\u0432\u0430\u0447\u0435\u043c.\n\nSpanish\nMycodo es un sistema automatizado de monitoreo y regulaci\u00f3n que fue creado\npara ejecutarse en la Raspberry Pi (versiones cero, 1, 2, 3 y 4).\nOriginalmente dise\u00f1ado para cultivar hongos comestibles, Mycodo ha crecido\npara incluir la capacidad de hacer mucho m\u00e1s, incluido el cultivo de plantas,\nel cultivo de microorganismos, el mantenimiento de la homeostasis de las\nabejas, la incubaci\u00f3n de animales y huevos, el mantenimiento de los sistemas\nacu\u00e1ticos, el envejecimiento de los quesos, la fermentaci\u00f3n de alimentos y el\ntabaco, la cocina. comida (sous-vide), y m\u00e1s.\nEl sistema comprende un backend (daemon) y un frontend (interfaz de usuario).\nEl backend realiza mediciones desde sensores y dispositivos, luego coordina\nun conjunto diverso de respuestas a esas mediciones, incluida la capacidad\nde modular salidas (rel\u00e9s, PWM, salidas inal\u00e1mbricas), regular las\ncondiciones ambientales con dispositivos el\u00e9ctricos bajo control PID\n(regulaci\u00f3n constante o cambio tiempo), programe temporizadores, capture\nfotos y transmita videos, active acciones cuando las mediciones cumplan\nciertas condiciones (module rel\u00e9s, ejecute comandos, notifique por correo\nelectr\u00f3nico, etc.) y m\u00e1s. La interfaz es una interfaz web que permite una\nf\u00e1cil navegaci\u00f3n y configuraci\u00f3n desde cualquier dispositivo con navegador.\n\nSwedish\nMycodo \u00e4r ett automatiserat \u00f6vervaknings- och reglersystem som byggdes\nf\u00f6r att springa p\u00e5 Raspberry Pi (versioner noll, 1, 2, 3 och 4).\nMycodo har ursprungligen utformats f\u00f6r att odla \u00e4tliga svampar, och har\nd\u00e4rmed \u00f6kat m\u00f6jligheten att g\u00f6ra mycket mer, inklusive odling av v\u00e4xter,\nodlingsmikroorganismer, uppr\u00e4tth\u00e5llande av honeybee apiary homeostasis,\ninkubering av djur och \u00e4gg, uppr\u00e4tth\u00e5llande av vattenlevande system,\n\u00e5ldrande ostar, j\u00e4sning av mat och tobak, matlagning mat (sous-vide)\noch mer.\nSystemet innefattar en backend (daemon) och en frontend\n(anv\u00e4ndargr\u00e4nssnitt). Bakgrunden utf\u00f6r m\u00e4tningar fr\u00e5n sensorer och\nenheter och samordnar sedan en m\u00e4ngd olika svar p\u00e5 dessa m\u00e4tningar,\ninklusive m\u00f6jligheten att modulera utg\u00e5ngar (rel\u00e4er, PWM, tr\u00e5dl\u00f6sa\nuttag), reglera milj\u00f6f\u00f6rh\u00e5llandena med elektriska enheter under\nPID-kontroll (st\u00e4ndig reglering eller byte \u00f6ver tid), schemal\u00e4gg timer,\nta bilder och str\u00f6mma video, utl\u00f6s \u00e5tg\u00e4rder n\u00e4r m\u00e4tningar uppfyller\nvissa villkor (modulera rel\u00e4er, utf\u00f6ra kommandon, meddela via e-post\netc.) och mer. Frontend \u00e4r ett webbgr\u00e4nssnitt som m\u00f6jligg\u00f6r enkel\nnavigering och konfiguration fr\u00e5n alla webbl\u00e4saraktiverade enheter.\n\nChinese\nMycodo\u662f\u4e00\u4e2a\u81ea\u52a8\u76d1\u63a7\u548c\u8c03\u8282\u7cfb\u7edf\uff0c\u53ef\u5728Raspberry Pi\u4e0a\u8fd0\u884c\uff08\u7248\u672c\u4e3aZero\uff0c1,2,3\u548c4\uff09\u3002\nMycodo\u6700\u521d\u8bbe\u8ba1\u7528\u4e8e\u79cd\u690d\u53ef\u98df\u7528\u7684\u8611\u83c7\uff0c\u5df2\u7ecf\u53d1\u5c55\u5230\u80fd\u591f\u505a\u66f4\u591a\u7684\u4e8b\u60c5\uff0c\u5305\u62ec\u79cd\u690d\u690d\u7269\uff0c\u57f9\u517b\u5fae\u751f\u7269\uff0c\u4fdd\u6301\u8702\u871c\u8702\u623f\u7a33\u6001\uff0c\u5b75\u5316\u52a8\u7269\u548c\u9e21\u86cb\uff0c\u7ef4\u6301\u6c34\u751f\u7cfb\u7edf\uff0c\u9648\u5e74\u5976\u916a\uff0c\u53d1\u9175\u98df\u54c1\u548c\u70df\u8349\uff0c\u70f9\u996a\u98df\u7269\uff08sous-vide\uff09\u7b49\u7b49\u3002\n\u8be5\u7cfb\u7edf\u5305\u62ec\u540e\u7aef\uff08\u5b88\u62a4\u8fdb\u7a0b\uff09\u548c\u524d\u7aef\uff08\u7528\u6237\u754c\u9762\uff09\u3002\u540e\u7aef\u4ece\u4f20\u611f\u5668\u548c\u8bbe\u5907\u8fdb\u884c\u6d4b\u91cf\uff0c\u7136\u540e\u534f\u8c03\u5bf9\u8fd9\u4e9b\u6d4b\u91cf\u7684\u5404\u79cd\u54cd\u5e94\uff0c\u5305\u62ec\u8c03\u5236\u8f93\u51fa\uff08\u7ee7\u7535\u5668\uff0cPWM\uff0c\u65e0\u7ebf\u63d2\u5ea7\uff09\u7684\u80fd\u529b\uff0c\u901a\u8fc7PID\u63a7\u5236\u7684\u7535\u6c14\u8bbe\u5907\u8c03\u8282\u73af\u5883\u6761\u4ef6\uff08\u7a33\u5b9a\u8c03\u8282\u6216\u8f6c\u6362\u65f6\u95f4\uff09\uff0c\u5b89\u6392\u8ba1\u65f6\u5668\uff0c\u6355\u83b7\u7167\u7247\u548c\u6d41\u89c6\u9891\uff0c\u5728\u6d4b\u91cf\u6ee1\u8db3\u7279\u5b9a\u6761\u4ef6\u65f6\u89e6\u53d1\u64cd\u4f5c\uff08\u8c03\u5236\u7ee7\u7535\u5668\uff0c\u6267\u884c\u547d\u4ee4\uff0c\u901a\u8fc7\u7535\u5b50\u90ae\u4ef6\u901a\u77e5\u7b49\uff09\u7b49\u7b49\u3002\u524d\u7aef\u662f\u4e00\u4e2aWeb\u754c\u9762\uff0c\u53ef\u4ee5\u4ece\u4efb\u4f55\u652f\u6301\u6d4f\u89c8\u5668\u7684\u8bbe\u5907\u8f7b\u677e\u5bfc\u822a\u548c\u914d\u7f6e\u3002\n\nThanks\n\nAlembic\nBootstrap\nDate Range Picker\nFlask\nFlask-Babel\nFlask-Limiter\nFlask-RestPlus\nFlask-WTF\nFontAwesome\ngridstack.js\nGunicorn\nHighcharts\nInfluxDB\njQuery\nPyro5\nSQLAlchemy\nSQLite\ntoastr\n\n","7":"NO LONGER SUPPORTED\nEBOWLA\nUSAGE: .\/ebowla.py exe_dll_shellcode genetic.config\n\nThen: Compile your code\n\nKnown Issues\nThe current version is locked into golang version <= 1.9.5 known working on golang 1.6: https:\/\/github.com\/Genetic-Malware\/Ebowla\/issues\/23\nIf someone wants to update the codebase to support LDFlags for golang 1.9+ we accept pull requests!\nMSF x86 EXE file output not compatible with MemoryModule (use DLL or x64 EXE\/DLL)\nhttps:\/\/github.com\/Genetic-Malware\/Ebowla\/issues\/12\nPowershell output was tested on powershellv5\nPresentation Resources\nSlides:\nInfiltrate 2016: https:\/\/github.com\/Genetic-Malware\/Ebowla\/raw\/master\/Infiltrate_2016_Morrow_Pitts_Genetic_Malware.pdf\nEkoparty 2016: https:\/\/github.com\/Genetic-Malware\/Ebowla\/blob\/master\/Eko_2016_Morrow_Pitts_Master.pdf\nDemos:\nDemo1:\nhttps:\/\/www.youtube.com\/watch?v=rRm3O7w5GHg\nDemo2:\nhttps:\/\/youtu.be\/Bu_qDrbX9Zo\nDemo3:\nhttps:\/\/youtu.be\/mlh70LtwmDo\nDemo4 (PowerShell):\nhttps:\/\/youtu.be\/lyedtAtATGc\nContact:\n  twitter:\n    @wired33\n    @midnite_runr\n    \n\nDocumentation\n  https:\/\/github.com\/Genetic-Malware\/Ebowla\/blob\/master\/documentation.md\n  \n  Also read genetic.config\n\n\nPayload Support\n\n\n\nPayload\nPython\nGO\nPowerShell(tested on v5)\n\n\n\n\nReflective DLL\nx32 \/ x64 - None\nx32 \/ x64 - In Memory\nx32 \/ x64 - In Memory\n\n\nDLL\nx32 \/ x64 - None\nx32 \/ x64 - In Memory\nx32 \/ x64 - In Memory\n\n\nEXE\nx32 \/ x64 - On Disk\nx32 \/ x64 - In Memory\nx32 \/ x64 - In Memory\n\n\nShell Code\nx32 \/ x64 - In Memory\nx32 \/ x64 - In Memory\nx32 \/ x64 - In Memory\n\n\nPython Code\nx32 \/ x64 - In Memory\nx32 \/ x64 - None\nNone\n\n\nPowershell code\nNone\nNone\nYes\n\n\nFile Drop\nYes\nIn Progress\nYes\n\n\n\nCredits\nhttps:\/\/github.com\/vyrus001\/go-mimikatz\nhttps:\/\/github.com\/PowerShellMafia\/PowerSploit\/blob\/master\/CodeExecution\/Invoke-ReflectivePEInjection.ps1\nhttps:\/\/github.com\/PowerShellMafia\/PowerSploit\/blob\/master\/CodeExecution\/Invoke-Shellcode.ps1\nContributing\nIf you have a bug report, submit an issue.  Include the OS that you tested everything on, including the server (victim).\nOutput of commands we like:\nWindows:\n  systeminfo\n  \nLinux:\n  uname -a\n  \n\nIf you want to contribute code please do so.  We ask that you actually submit something substantial, fixing spacing doesn't count, or making our code fully pep8.\nLook at our issues for ideas where you can help: https:\/\/github.com\/Genetic-Malware\/Ebowla\/issues\nsecretsquirrel is on IRC #freenode as midnite_runr\nContributors\nhttps:\/\/github.com\/wired33 (wrote most of the golang payload code)\nhttps:\/\/github.com\/secretsquirrel (wrote the python payload code and most of the encryption code)\n","8":"\nLadybug for Grasshopper\nLadybug is a free and open source environmental plugin for Grasshopper to help designers create an environmentally-conscious architectural design.  The initial step in the design process should be the weather data analysis; a thorough understanding of the weather data will, more likely, lead designers to high-performance design decisions.\nLadybug imports standard EnergyPlus Weather files (.EPW) in Grasshopper and provides a variety of 2D and 3D designer-friendly interactive graphics to support the decision-making process during the initial stages of design. The tool also provides further support for designers to test their initial design options for implications from radiation and sunlight-hours analyses results. Integration with Grasshopper allows for an almost instantaneous feedback on design modifications, and as it runs within the design environment, the information and analysis is interactive.\nHere is Ladybug in a less than 5-minute video\nLicence\nLadybug: A Plugin for Environmental Analysis (GPL) started by Mostapha Sadeghipour Roudsari\nCopyright (c) 2013-2015, Mostapha Sadeghipour Roudsari\nLadybug is free software; you can redistribute it and\/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 3 of the License, or (at your option) any later version.\nLadybug is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\nYou should have received a copy of the GNU General Public License along with Ladybug; If not, see http:\/\/www.gnu.org\/licenses\/.\n@license GPL-3.0+ http:\/\/spdx.org\/licenses\/GPL-3.0+\nUseful links\nLadybug group page on Grasshopper\nFacebook page\nLadybug on Twitter\nContributors\n\n","9":"1 - Introduction\nThis repository contains platform independent drivers for STMicroelectronics sensors. Sensor drivers and examples were written in C programming language.\nThis repository contains two types of folders, identifiable using the following naming convention:\n\nfolder that contains the sensor drivers, named  xxxxxxx_STdC where  xxxxxxx identifies the a sensor part number,\nfolder that contains the demo project, named  _prj_XXXXXXXwhere  XXXXXXX is the name of the ST evaluation board,\n\nAnother folder, named  _resources,  can not be identified with the two types described above and contains other useful resources such as libraries and predefined device configurations used in some examples. In order to clone the complete content of this folder use the command:\ngit clone --recursive https:\/\/github.com\/STMicroelectronics\/STMems_Standard_C_drivers\n\n1.a - Sensor driver folder structure\nEvery sensor driver folder contains:\n\nxxxxxxx_STdC\\driver : the C sensor driver (.h and .c) to be included in your project. Driver documentation can be generated using the Doxigen tool.\nxxxxxxx_STdC\\example:  examples showing how to integrate the C driver in a project. They are written for STM32 Microcontrollers using the STM32CubeMX tool, but they can be used as a guideline for every platform.\nREADME: additional info about the specific driver.\n\n1.b - Demo project folder structure\nEvery demo project folder contains a single configuration file for the STM32CubeMX tool named _prj_XXXXXXX\\XXXXXX.iocwhere  XXXXXXX is the name of the ST evaluation board.\nUsing the STM32CubeMX tool ( configured with the related MCU Package )  and the .ioc file, it is possible to create a project in which you can easily run the examples available in each sensor drivers folder.\n\n2 - Integration details\nThe driver is platform-independent, you only need to define the two functions for read and write transactions from the sensor hardware bus (ie. SPI or I\u00b2C).\n2.a Source code integration\n\n\nInclude in your project the driver files of Sensor (.h and .c) located in the xxxxxxx_STdC\\driverfolder of the corresponding product\n\n\nDefine in your code the read and write functions that use the I\u00b2C or SPI platform driver like the following:\n\n\n\/** Please note that is MANDATORY: return 0 -> no Error.**\/\nint32_t platform_write(void *handle, uint8_t Reg, uint8_t *Bufp, uint16_t len)\nint32_t platform_read(void *handle, uint8_t Reg, uint8_t *Bufp, uint16_t len)\n\nDeclare and initialize the structure of device interface:\n\nxxxxxxx_ctx_t dev_ctx; \/** xxxxxxx is the used part number **\/\ndev_ctx.write_reg = platform_write;\ndev_ctx.read_reg = platform_read;\n\nIf needed by the platform read and write functions, initialize the handle parameter:\n\ndev_ctx.handle = &platform_handle;\n2.b Required properties\n\n\nA standard C language compiler for the target MCU\nA C library for the target MCU and the desired interface (ie. SPI, I2C)\n\n\n\n3 - Running Examples\nThey are written for STM32 Microcontrollers using STM32CubeMX tool, but they can be used as a guideline for every platform.\n3.a Using a STMicroelectronics evaluation boards\nIn case of using the supported STMicroelectronics evaluation boards the examples file(.c) can run without applying any modifications (as is).\nIn order to do that, please follow the following steps:\n\nDownload and install STM32CubeMX  tool and the related MCU package (i.e. STM32CubeF4 for NucleoF411 and STEVAL_MKI109V3).\nOpen the  .ioc configuration file associated to the selected evaluation board with the STM32CubeMX tool. The  .ioc configuration files for the supported evaluation boards can be found in the related ST evaluation board demo project folder.\nGenerate the project using the STM32CubeMX tool and select your preferred IDE \/ Toolchain.\nAdd to your project the STMicroelectronics sensor driver. Driver files are located in the sensor drivers folder atxxxxxxx_STdC\\driver\\xxxxxxx_reg.c(.h) where  xxxxxxx identifies the sensor part number.\nAdd to your project the example source file (.c) that you are interested in. Example files are located in the sensor drivers folder at xxxxxxx_STdC\\example where  xxxxxxx identifies a sensor part number.\nUncomment the selected board definition in section \/* STMicroelectronics evaluation boards definition *\/ in the selected example file (.c).\nAdd the call to the example function inside the while(1) loop in the main() function themain.c file automatically generated by the  STM32CubeMX tool.\nEnjoy :-)\n\n3.b Running examples using different hardware\nIf a different MCU is used, please follow these steps:\n\n\nAdd to your project the STMicroelectronics sensor driver.  Driver files are located in the sensor drivers folder atxxxxxxx_STdC\\driver\\xxxxxxx_reg.c(.h) where  xxxxxxx identifies a sensor part number.\n\n\nAdd to your project the example source file (.c) that you are interested in. Example files are located in the sensor drivers folder at xxxxxxx_STdC\\example where  xxxxxxx identifies the sensor part number.\n\n\nComment all the definitions of the boards in section `\/* STMicroelectronics evaluation boards definition *\/ in the selected example file(.c).\n\n\nAdd the call to the example function inside the while(1) loop in yourmain() function.\n\n\nModify in the selected example file (.c) the hardware-related functions:\n\nplatform_write(void *handle, uint8_t Reg, uint8_t *Bufp,uint16_t len)\nplatform_read(void *handle, uint8_t Reg, uint8_t *Bufp, uint16_t len)\nif needed add\/replace the hardware-related functions reported in the example file.\n\n\n\nEnjoy :-)\n\n\n\nMore Information: http:\/\/www.st.com\nCopyright (C) 2018 STMicroelectronics\n","10":"Technical Environmental Systems: General Information and Software Installation Instructions\nWelcome to Polimi's \"Technical Environmental Systems\" course.\nBefore attending the first session of the course you should fill the following survey in which you will inform us about your contact information, academic background, and software skills.\nCourse Survey\nTES Survey Link\nIn this survey you will be asked to create an account on the following websites and insert the corresponding account informatio:\nDropbox Registration\nIn case you do not have a DropBox account, You should crate a free account here and indicate the corresponding email address in the first section of the survey\nGithub Registration\nIn case you do not have an account on Github, please create one here, for your username please use a human readable format (e.g. MRossi, RossiMarco, Rossi_Marco and not M007R92 !\nBuilding Component Library (BCL) Registration\nPlease create and account on the NREL's Building Component Library https:\/\/bcl.nrel.gov\/  (username format: the same as a github account)  Once you create an account, in your dashboard you will find an API key. Please save that number so that you can have easy access to it.\n\nSoftware Installation\nIn this course, we will use EnergyPlus, Sketchup and  OpenStudio which should be downloaded and installed. You can also download  the files (For windows - 64bit) from the following DropBox link.\n\nImportant Note: Pay attention that the softwares should be installed in the same order as given below:\n\n\nEnergyPlus\nSketchUp\nOpenStudio\n\n\n\nIt is noteworthy that, in case you already have the SketchUp software installed on your computer, you might have to re-install it as the OpenStudio version might not be compatible with your installed version of SketchUp.\n\n\nIn order to check whether you have correctly installed the above-mentioned softwares, you should verify that you have the OpenStudio add-on added to your SketchUp tools.\n\n\nIn case you are using another operating system (e.g. Linux, MacOs, Windows 32bits), you can download them from the following links:\n\n\nEnergyPlus:\nIn this Link you can download the suitable  version of the software based on your operating System\n\n\nSketchUp:\nYou can find the suitable installation file (SketchUp Make 2016) for your operating system from this Link, Pay attention that we are going to use SketchUp Make and not SketchUp Pro which is a commercial software.\n\n\nOpenStudio:\nThe installation files of OpenStudio for different operating system can be found here.\n\n\nProject Description\nIn this project, geometry of a commercial building should be first introduced in SketchUp and the other characteristics of the building should be then defined employing OpenStudio. The latter software should next be used to calculate the yearly heating and cooling consumption of the building for a base case. Next, a parametric study, should be conducted in order to investigate the effect of changing the position and wall characteristics on the building\u2019s yearly energy consumption. Accordingly, the simulation should be performed for three different cities and three different walls, and the corresponding obtained yearly consumptions should be compared with the ones of the base case.\nPay attention that you should conduct the sensitivity analysis on the walls just for one city\nGroup Information\nYou can send the information about the members of your group via this link till 11\/12\/2019, you will be assigned a time-slot\nDetails Regarding the Final Exam\nThe final written examination will include exercises and theoretical questions. The exercises will be similar to and on the same topics as the ones which were solved in the class. The theoretical questions instead will only be posed from the topics in the context of which no exercise was solved\u00a0(including \"solar radiation\", \"heat transfer through windows\", \"Heat gain, infiltration, and ventilation\", \"centralized HVAC system\", and \"solar thermal systems\"). In the theoretical questions, the students are not required to write down the corresponding formulas and should instead be able to explain the concepts through explanation or schematic representation if needed.\u00a0\nFormulas\nThe students are only required to remember the formulas related heat transfer through walls (through conduction and convection heat transfer in series or parallel conditions) and simplified\u00a0heat transfer through wall calculations.\u00a0Other formulas will be given in the exam paper; thus, the students are  not allowed to bring any formula paper. The RLF and weather data tables along with the psychometric chart (if needed) will also be provided in the exam and the student should not bring them.\u00a0\nCalculator\u00a0\nThe students should clearly remember to bring a simple calculator\n","11":"CEE690-02: Environmental Spatial Data Analysis\nFall 2020\nCourse Information\nLectures are on Tuesdays and Thursdays from 3:30 PM - 4:45 PM. The course website is on GitHub (https:\/\/github.com\/chaneyn\/CEE690-02). Class announcements will be made via Sakai (CEE690.02.F20).\nInstructor\nProfessor Nathaniel W. Chaney (Nate)\nEmail: nathaniel.chaney@duke.edu\nOffice: FCIEMAS 2463\nOffice hours: Thursdays after class via Zoom\nTA\nLaura Torres\nEmail: lpt14@duke.edu\nOffice hours: Mondays 8-10am via Zoom\nCourse Description\nEnvironmental Spatial Data Analysis (ESDA) provides an introduction on how to leverage large volumes of spatial environmental data using primarily Python. The topics that will be covered include an overview of basic spatial statistics, spatial interpolation, kriging, conditional simulation, terrain analysis, dimensionality reduction, and spatial prediction. Existing software packages in Python will be introduced and used to explore the listed topics.\nPrerequisites\nAlthough there are no class prerequisistes, a strong foundation in programming will make this class much easier. Please contact Nate if you have concerns.\nReadings\nThere are no required textbooks. Reading will be provided via journal articles, online materials, and tutorials.\nGrades and workload\nThe course grade is based on three items:\n\nHomework: 40%\nParticipation: 20%\nFinal Project: 40%\n\nHomework\nThere will be 4 homework assignments. Each assignment will be provided and completed within a corresponding Jupyter notebook. Completed assignments will be submitted via a private GitHub repository that each student will have for the course; assignments submitted via any other method will not be accepted. Each assignment must be submitted before class on the day listed on the schedule below. Late homeworks will not be accepted.\nParticipation\n\nStudents should follow along the lecture on their personal jupyter lab Docker container that they will use for the course.\nEach student will present twice. The first presentation will involve describing a dataset and the second will be present a journal article.\n\nCollaboration\nCollaboration in completing assignments is permitted. However, each student must write up their assignment independently. We will be checking for identical homeworks.\nFinal Project\nThe final project can be done in groups of 2 or individually. The expectations for the project will increase with the group size. It will involve the following components:\n\nInitial Proposal (October 22nd via email)\n\n3 pages max, single-spaced, 12 point font size, 1 inch margin\nContains: Title, introduction, objectives, data, methodology, and timeline of tasks\n\n\nOral presentation (November 17th and 19th in class)\n\n12 minute oral presentation, 3 minutes for questions\nEveryone needs to be present for each presentation\n\n\nFinal report (November 24th via email)\n\n10 pages max, single-spaced, 12 point font size, 1 inch margin\nContains: Title, introduction, data, methods, results, discussion, and conclusion\n\n\n\nSchedule\nNote that the schedule is subject to change.\n\n\n\nDate\nTopic\nNew Software\nAssignments\nArticle\n\n\n\n\n08\/18\nIntroduction\nJupyter\/GitHub\/Bash\n-\n-\n\n\n08\/20\nPython overview\nPython\n-\nLin, J., 2012\n\n\n08\/25\nMulti-dimensional arrays I\nNumPy\n-\nLu et al., 2018 (Owen Daly)\n\n\n08\/27\nVisualizing data\nMatplotlib\n-\nRougier et al., 2014 (Keqi He)\n\n\n09\/01\nData storage\nPickle\/H5py\/NetCDF\/GeoTiff\n-\nExtance, 2016 (Laura Torres)\n\n\n09\/03\nProbability\/Statistics I\nScipy\n-\nHolmes, 2018 (Celine Robinson)\n\n\n09\/08\nProbability\/Statistics II\n-\nHW #1 due\nWalther and Moore, 2005 (Sarah Scott)\n\n\n09\/10\nBayesian Statistics\n-\n-\nPrathvikumar, 2019 (Gary Jiang)\n\n\n09\/15\nMap projections I\nCartopy\n-\nLapaine, 2017 (Lijia Gao)\n\n\n09\/17\nMap projections II\nGDAL\n-\nAsay, 2020 and Simmon, 2017 (Huda Aslam)\n\n\n09\/22\nMulti-dimensional arrays II\nCDO\/Xarray\n-\nHoyer and Hamman, 2017 (Cary Shindell)\n\n\n09\/24\nVector Data\nOGR\/Shapely\/GeoPandas\n-\nKreveld, 2006 (Rundong Ji)\n\n\n09\/29\nCluster Analysis I\nScikit-Learn\n-\nMishra, 2017 (Peiran Wang)\n\n\n10\/01\nCluster Analysis II\n-\n-\n-\n\n\n10\/06\nDimensionality Reduction\n-\nHW #2 due\n-\n\n\n10\/08\nDecision Trees\n-\n-\nHomer et al., 2004 (Huda Aslam)\n\n\n10\/13\nNo class\n-\n-\n-\n\n\n10\/15\nRandom Forests\n-\n-\nKaminska, J., 2018 (Sarah Scott)\n\n\n10\/20\nBoosting\n-\n-\nCai, J., et al., 2020 (Celine Robinson)\n\n\n10\/22\nSimple Kriging\n-\nProposal due\nWong, D., et al., 2004 (Gary Jiang)\n\n\n10\/27\nOrdinary Kriging\n-\n-\nPouladi, N., et al., 2019 (Lijia Gao)\n\n\n10\/29\nSemivariogram\n-\n-\nHengl, T., et al., 2007 (Owen Daly)\n\n\n11\/03\nRegression Kriging\n-\nHW #3 due\n-\n\n\n11\/05\nTerrain Analysis I\n-\n-\n-\n\n\n11\/10\nTerrain Analysis II\n-\n-\nMoore, I., et al., 1991 (Keqi He)\n\n\n11\/12\nScaling up code\nNumba\/Mpi4py\/Dask\n-\nBakharia, A., 2018 and Grover, P., 2018 (Cary Shindell)\n\n\n11\/17\nOral Presentations\n-\n-\n-\n\n\n11\/19\nOral Presentations\n-\n-\n-\n\n\n11\/24\nWritten report due\n-\nHW #4 due\n-\n\n\n\n","12":"Environmentalizer\nNOTE: At the moment, this script will not work when run by itself. It has been modified to work with an OS X companion app. To run as a stanalone script, please check out commit: ce4f529d9ee09725c529dfb5fafd046c3f064c59.\nA bash script to quickly and easily bootstrap a well-setup programming\nenvironment. It assumes a fresh install of OS X 10.9 (Mavericks) or OS X 10.10 (Yosemite).  Any software already installed will be skipped.\nWhat It Sets Up\n\nFlatiron School's standard .bash_profile, which includes case-insensitive auto completion, a nice prompt with git branch awareness, and many useful shortcuts.\nHomebrew\nGit\nSQlite3\nRVM, Ruby 2.2.* and their dependencies\nThe Learn gem and its dependencies\nSublime Text 3 with Package Control, Solarized Theme, and proper tab defaults\nSensible .gitconfig, .gitignore, .gemrc, and .irbrc files\nSSH Key for GitHub\nA simple directory structure for well-organized code\nGoogle Chrome\n\nWhat You Need Before You Begin\n\nKnow your admin password (you'll need to enter it once when the script first runs)\nKnow your GitHub username\nKnow the email address associated with your GitHub account\nA personal access api token for GitHub. You can create one here: https:\/\/github.com\/settings\/tokens\/new. The name doesn't matter. You MUST select the write:public_key scope.\nYou MUST to have pre-installed Xcode, accepted its license, and have the Command Line Tools.\n\nNotes\n\nYou'll need to run this script from an account with admin status. (DO NOT prepend sudo to the command below.)\nWhen the script first runs, you'll need to enter your admin password once for Homebrew to install and again for Sublime's symlink.\nDuring installation, Sublime Text will open for a few seconds and then close automatically. Do not close it yourself. This step is required for some important directories to be created.\n\nUsage\ncurl -L \"https:\/\/raw.githubusercontent.com\/flatiron-school\/environmentalizer\/master\/runner.sh\" | bash\nTesting\nEnvironmentalizer utilizes Bats (Bash Automated Testing System) for testing.\nInstallation\n\n$ git clone https:\/\/github.com\/sstephenson\/bats\n$ cd bats\n$ .\/install.sh \/usr\/local\n\nUse\nRunning Tests\n\nRun tests with $ bats test\nAlternatively, run $ bin\/test\n\nWriting Tests\n\nAdd all test files to the test directory\nTest files should have the .bats extension\nAll files need the #!\/usr\/bin\/env bats shebang at the top\nSee a sample in test\/sample.bats\nFor more documentation, visit the (Bats Readme)[https:\/\/github.com\/sstephenson\/bats\/blob\/master\/README.md]\n\nTODO\n\nExtract 'check if file exists and if it has this content' logic into\nreusable function\nWrite tests\n\n","13":"Enviro+\nDesigned for environmental monitoring, Enviro+ lets you measure air quality (pollutant gases and particulates), temperature, pressure, humidity, light, and noise level. Learn more - https:\/\/shop.pimoroni.com\/products\/enviro-plus\n\n\n\n\nInstalling\nYou're best using the \"One-line\" install method if you want all of the UART serial configuration for the PMS5003 particulate matter sensor to run automatically.\nNote The code in this repository supports both the Enviro+ and Enviro Mini boards. The Enviro Mini board does not have the Gas sensor or the breakout for the PM sensor.\n\n\nOne-line (Installs from GitHub)\ncurl -sSL https:\/\/get.pimoroni.com\/enviroplus | bash\n\nNote report issues with one-line installer here: https:\/\/github.com\/pimoroni\/get\nOr... Install and configure dependencies from GitHub:\n\ngit clone https:\/\/github.com\/pimoroni\/enviroplus-python\ncd enviroplus-python\nsudo .\/install.sh\n\nNote Raspbian Lite users may first need to install git: sudo apt install git\nOr... Install from PyPi and configure manually:\n\nRun sudo pip install enviroplus\n\nNote this wont perform any of the required configuration changes on your Pi, you may additionally need to:\n\nEnable i2c: raspi-config nonint do_i2c 0\nEnable SPI: raspi-config nonint do_spi 0\n\nAnd if you're using a PMS5003 sensor you will need to:\n\nEnable serial: raspi-config nonint set_config_var enable_uart 1 \/boot\/config.txt\nDisable serial terminal: sudo raspi-config nonint do_serial 1\nAdd dtoverlay=pi3-miniuart-bt to your \/boot\/config.txt\n\nAnd install additional dependencies:\nsudo apt install python-numpy python-smbus python-pil python-setuptools\n\nAlternate Software & User Projects\n\nenviro monitor - https:\/\/github.com\/roscoe81\/enviro-monitor\nmqtt-all - https:\/\/github.com\/robmarkcole\/rpi-enviro-mqtt - now upstream: see examples\/mqtt-all.py\nadafruit_io.py - https:\/\/github.com\/dedSyn4ps3\/enviroplus-python\/blob\/master\/examples\/adafruit_io.py - uses Adafruit Blinka and BME280 libraries to publish to Adafruit IO\nenviroplus_exporter - https:\/\/github.com\/tijmenvandenbrink\/enviroplus_exporter - Prometheus exporter (with added support for Luftdaten and InfluxDB Cloud)\n\nHelp & Support\n\nGPIO Pinout - https:\/\/pinout.xyz\/pinout\/enviro_plus\nSupport forums - http:\/\/forums.pimoroni.com\/c\/support\nDiscord - https:\/\/discord.gg\/hr93ByC\n\n","14":"Environmental_Data_Analytics_2020\nCourse repository for Environmental Data Analytics (ENV 872L) at Duke University, spring 2020\nStudent:\n","15":"Earth Analytics Python Conda Environment\n\n\n\n\n\n\nWelcome to the Earth Analytics Python Environment Repository! Here you will find a conda environment that can be installed on your computer using a .yaml file. You will also find a docker image that can be used to actually run the environment in a containerized environment.\nContributors:\n\nLeah A. Wasser (@lwasser)\nFilipe fernandes (@ocefpaf)\nTim Head (@betatim)\nChris Holdgraf (@choldgraf)\nMax Joseph  (@mbjoseph)\nMartha Morrissey\n\nGetting started with the Conda Environment\n1. Install the Earth Lab Conda Environment on your Local Computer.\nTo begin, install git and conda for Python 3.x (we suggest 3.6).\nInstalling git: https:\/\/git-scm.com\/book\/en\/v2\/Getting-Started-Installing-Git\nInstalling miniconda: https:\/\/docs.conda.io\/en\/latest\/miniconda.html\nAbout Conda Environments: https:\/\/conda.io\/docs\/user-guide\/tasks\/manage-environments.html\nTutorial On Setup\nIf you want a more detailed tutorial on setting up this environment using miniconda,\nplease visit our learning portal: https:\/\/www.earthdatascience.org\/workshops\/setup-earth-analytics-python\/\nWe recommend installing everything using the with conda-forge channel.\nQuick Start: Setup Your Environment\nThe tutorial above will provide you with more detailed setup instructions.\nBut here are the cliff notes:\nTo begin, install the environment using:\nconda env create -f environment.yml\nThis will take a bit of time to run.\n\nAlso note that for the code above to work, you need to be in the directory where the environment.yml file lives so CD to that directory first\n\n$ cd earth-analytics-python-env\nUpdate Your EA Environment from the YAML File\nYou can update your environment at any time using:\nconda env update -f environment.yml\nTo manage your conda environments, use the following commands:\nView envs installed\nconda info --envs\nActivate the environment that you'd like to use\nConda 4.6 and later versions (all operating systems):\nconda activate earth-analytics-python\n\nThe environment name is earth-analytics-python as\ndefined in the environment.yml file.\nDocker Build\n\nTo run a docker container you need to do the following:\n\n\nInstall docker and make sure it is running.\n\n\nBuild the docker image on your compute locally. Be patient - this will take a bit of time.\nRun the following lines to build the docker image locally:\n\n\ncd earth-analytics-python-env\ndocker build -t earthlab\/earth-analytics-python-env .\ndocker run -it -p 8888:8888 earthlab\/earth-analytics-python-env\n\n\n\nRun the image.\n\nTo run your earth-analytics image, use the following code:\ndocker run --hostname localhost -it -p 8888:8888 earthlab\/earth-analytics-python-env\nNOTE: earthlab\/earth-analytics-python-env is the name of this image as built above. To\nview all images on your computer, type\ndocker images --all\nOne you run your image, you will be given a URL at the command line. Paste that puppy\ninto your browser to run jupyter with the earth analytics environment installed!!\nUpdating the Earth Analytics Environment\nIf you wish to update the earth analytics environment, do the following.\n\nmake a PR with changes to master\nAn code admin will merge the PR into the master branch\nCheck & wait till Dockerhub has built the image for the merging of the PR you can see builds in progress, here\n\n","16":"\n\n\n\n\n\n\n\n\ud83d\udcd6 About:\nA general overworld surface expansion, that further incentivises exploring existing biomes, and completes and improves them visually.\n\n\n\n\n","17":"PCRaster\nEnvironmental modelling software\nPCRaster is a collection of tools and software libraries tailored to the construction of spatio-temporal environmental models. Application domains are amongst others hydrology (rainfall-runoff, global water balance, groundwater (with Modflow)), ecology, or land use change. Two scripting languages (Python and PCRcalc) include a rich set of spatial operations for manipulating and analysing raster maps. A Python framework supports Monte Carlo simulations and data assimilation (Ensemble Kalman Filter and Particle Filter). The Aguila tool allows for the interactive visualisation of stochastic spatio-temporal data.\nYou can find more information about our research and development projects on our website. Information on PCRaster is given at the project website, and online documentation can be found here. For questions regarding the usage of PCRaster please use our mailing list, bugs can be reported via our issue tracker.\nPackages are available for Linux, macOS and Windows via conda-forge.\n\n\n\nOS\nCompilers\nStatus\n\n\n\n\nLinux, macOS\ngcc-7, gcc-8, clang-6\n\n\n\nWindows\nvs-2017\nChecked manually\n\n\n\n","18":"Spatio-Temporal Voxel Layer \nThis is a drop in replacement for the voxel_grid voxel representation of the environment. This package does a number of things to improve on the voxel grid package and extend the capabilities offered to the users, under a LGPL v2.1 license. Developed and maintained by Steven Macenski at Simbe Robotics.\nThis package sits on top of OpenVDB, an open-source C++ library built by Dreamworks \"comprising a novel hierarchical data structure and a suite of tools for the efficient storage and manipulation of sparse volumetric data discretized on three-dimensional grids. It is developed and maintained by DreamWorks Animation for use in volumetric applications typically encountered in feature film production.\"\nLeveraging OpenVDB, we have the ability to efficiently maintain a 3 dimensional voxel-representative world space. We wrap this with ROS tools and interfaces to the navigation stack to allow for use of this layer in standard ROS configurations. It is certainly possible to utilize this package without ROS\/Navigation and I invite other competing methodologies to develop here and create interfaces.\nSample videos are shown below of a robot using 7 depth cameras with less than 50% of a core, and another robot using a VLP-16.\n\n\n\n7 Depth Cameras\nVLP-16 LIDAR\n\n\n\n\n\n\n\n\n\nWe found in experimental trials with 6 7hz dense stereo RGBD cameras we ran the major move_base process at 20-50% nominal from 80-110% on a 5th gen i7 CPU in the global costmap updating using the existing voxel_layer.\nWe've received feedback from users and have robots operating in the following environments with STVL:\n\nRetail\nWarehouses\nFactories\nLibraries\nHospitals\nHospitality\nRoboCup@Home\nOil and Gas\n\nSteve spoke at ROSCon 2018 about STVL and his presentation is linked here (or click on image).\n\nCite This Work\nYou can find this work here.\n@article{doi:10.1177\/1729881420910530,\n    author = {Steve Macenski and David Tsai and Max Feinberg},\n    title ={Spatio-temporal voxel layer: A view on robot perception for the dynamic world},\n    journal = {International Journal of Advanced Robotic Systems},\n    volume = {17},\n    number = {2},\n    year = {2020},\n    doi = {10.1177\/1729881420910530},\n    URL = {https:\/\/doi.org\/10.1177\/1729881420910530}\n}\n\nSpatio-\nThe Spatio in this package is the representation of the environment in a configurable voxel_size voxel grid stored and searched by OpenVDB.\nIn addition, buffered measurement readings have the option to run an approximate voxel grid filter, parameterizable at runtime in the configuration yamls. It is incredibly useful to reduce spikes in move_base cpu due to dense measurement readings when getting close to objects (i.e. more points), but does increase the overhead very slightly (1-2%) for nominal operations. It's a trade off but I recommend using it.\nBelow is an example a size of map that is trivial for the Spatio-Temportal Voxel Grid to maintain and render. This accounts for a 60,000 sq.ft. retail store with 710,765 voxels at a 0.05m resolution, with a size in memory of a mere 6.45MB.\n\n-Temporal\nThe Temporal in this package is the novel concept of voxel_decay whereas we have configurable functions that expire voxels and their occupation over time. Infrasture was created to store times in each voxel after which the voxel will disappear from the map. This is combined with checking inclusion of voxels in current measurement frustums to accelerate the decay of those voxels that do not have measurements but should if still in the scene and remain marked. This is done rather than simply clearing them naively or via costly raytracing. The time it takes to clear depends on the configured functions and acceleration factors.\nVoxel acceleration uses given FOV to compute the frustum geometry. Depth cameras (e.g. Intel Realsense) are modeled with traditional 6-planed cubical frustums. 3D lidars (e.g. Velodyne VLP 16) are modeled with their hourglass-shaped FOV. Although many 3D lidars have 360 degree horizontal FOV, it is possible to use a narrower angle for the clearing frustum by setting the hFOV parameter accordingly.\nFuture extensions will also to query a static map and determine which connected components belong to the map, not in the map, or moving. Each of these three classes of blobs will have configurable models to control the time they persist, and if these things are reported to the user.\nBelow is an example of instantaneous decay, where readings in frustum are accelerated and decayed at each iteration. The models provided can be tuned to do this, or persist through linear or exponental equations. The second example has the acclerated frustum with tuned decay times and acceleration factors in navigation mode.\n\n\nLocal Costmap\nThis package utilizes all of the information coming in from the robot before the decay time for the local costmap. Rather than having a defined, discrete spatial barrier for the local planner to operate in, it instead relies on the user configuration of the layer to have a short decay time of voxels (1-30 seconds) so that you only plan in relavent space. This was a conscious design requirement since frequently the local planner should operate with more information than other times when the speed is greater or slower. This natively implements dynamic costmap scaling for speed.\nIt is the user's responsibility to chose a decay time that makes sense for your robot's local planner. 5-15 seconds I have found to be nominally good for most open-sourced local planner plugins. I do not recommend using this for planar lidars, 2D raytracing for professional grade lidars is sufficiently efficient and effective.\nGlobal Costmap\nSimilar to the local costmap, the amount of information you want to store due to entropy in your scenes depend on your use-case. It is certainly possible to not decay the voxels in the global map at all. However, in practical application, I find a time 15-45 seconds to be a good balance due to things moving in the scene (i.e. store, warehouse, construction zone, office, etc). Permanent voxels set decay to -1. I do not recommend using this for planar lidars, 2D raytracing for professional grade lidars is sufficiently efficient and effective.\nMapping\nAs the images above suggest, you can use this to map an environment in 3D in realtime if you choose. If you enable mapping mode, then it will maintain the entire voxel grid and you can save the map using the services provided. At the moment, I support mapping but there is no probabilistic (yet!) marking framework, so what the sensor sees is what the map gets. This is likely to change in the near to middle term future as 3D localization becomes more interesting to the enterprise robotics community.\nYou can run multiple instances of the layer one to map and other to navigate if you want to navigate while mapping the environment. Mapping will also save incremental maps in the launch directory. Maps may be visualized using vdb_viewer. The costmap and occupancy point clouds will not generate in this mode from this layer. Utility functions are provided so you don't need to learn anything about vdb files to convert to a pcl pointcloud in vdb2pc.hpp.\nIf you would like to be involved in this work, I would gladly take contributors and coauthors.\nInstallation\nAs of July 8 it is available via apt-get:\nsudo apt-get install ros-kinetic-spatio-temporal-voxel-layer\n\nInstall from source\nRequired dependencies ROS Kinetic, navigation, OpenVDB, TBB.\nsudo rosdep init && rosdep update && rosdep install --from-paths src --ignore-src -r -y\nConfiguration and Running\ncostmap_common_params.yaml\nAn example fully-described configuration is shown below.\nNote: We supply two PCL filters within STVL to massage the data to lower compute overhead. STVL has an approximate voxel filter to make the data more sparse if very dense. It also has a passthrough filter to limit processing data within the valid minimum to maximum height bounds. The voxel filter is recommended if it lowers CPU overhead, otherwise, passthrough filter. No filter is also available if you pre-process your data or are not interested in performance optimizations.\nrgbd_obstacle_layer:\n  enabled:               true\n  voxel_decay:           20     #seconds if linear, e^n if exponential\n  decay_model:           0      #0=linear, 1=exponential, -1=persistent\n  voxel_size:            0.05   #meters\n  track_unknown_space:   true   #default space is unknown\n  observation_persistence: 0.0  #seconds\n  max_obstacle_height:   2.0    #meters\n  unknown_threshold:     15     #voxel height\n  mark_threshold:        0      #voxel height\n  update_footprint_enabled: true\n  combination_method:    1      #1=max, 0=override\n  obstacle_range:        3.0    #meters\n  origin_z:              0.0    #meters\n  publish_voxel_map:     true   # default off\n  transform_tolerance:   0.2    # seconds\n  mapping_mode:          false  # default off, saves map not for navigation\n  map_save_duration:     60     #default 60s, how often to autosave\n  observation_sources:   rgbd1_clear rgbd1_mark\n  rgbd1_mark:\n    data_type: PointCloud2\n    topic: camera1\/depth\/points\n    marking: true\n    clearing: false\n    min_obstacle_height: 0.3     #default 0, meters\n    max_obstacle_height: 2.0     #defaule 3, meters\n    expected_update_rate: 0.0    #default 0, if not updating at this rate at least, remove from buffer\n    observation_persistence: 0.0 #default 0, use all measurements taken during now-value, 0=latest \n    inf_is_valid: false          #default false, for laser scans\n    clear_after_reading: true    #default false, clear the buffer after the layer gets readings from it\n    filter: \"voxel\"              #default passthrough, apply \"voxel\", \"passthrough\", or no filter to sensor data, recommended to have at one filter on\n    voxel_min_points: 0          #default 0, minimum points per voxel for voxel filter\n  rgbd1_clear:\n    enabled: true                #default true, can be toggled on\/off with associated service call\n    data_type: PointCloud2\n    topic: camera1\/depth\/points\n    marking: false\n    clearing: true\n    min_z: 0.1                   #default 0, meters\n    max_z: 7.0                   #default 10, meters\n    vertical_fov_angle: 0.7      #default 0.7, radians\n    horizontal_fov_angle: 1.04   #default 1.04, radians\n    decay_acceleration: 1.       #default 0, 1\/s^2. If laser scanner MUST be 0\n    model_type: 0                #default 0 (depth camera). Use 1 for 3D Lidar\n\nMore configuration samples are included in the example folder, including a 3D lidar one.\nlocal\/global_costmap_params.yaml\nAdd this plugin to your costmap params file.\n- {name: rgbd_obstacle_layer,     type: \"spatio_temporal_voxel_layer\/SpatioTemporalVoxelLayer\"}\nRunning\nroslaunch [navigation_pkg] move_base.launch\nEnabing\/disabling observation_sources real-time\nTo enable\/disable observation sources use a ros service for each source:\n~rgbd_obstacle_layer\/$(source_name)\/toggle_enabled (std_srvs\/SetBool)\n\nrequest.data = true   \/\/ Enable observation source\nrequest.data = false  \/\/ Disable observation source\n\nExample:\nrosservice call \/move_base\/global_costmap\/rgbd_obstacle_layer\/rgbd_back\/toggle_enabled \"data: true\"\nrosservice call \/move_base\/local_costmap\/rgbd_obstacle_layer\/rgbd_back\/toggle_enabled \"data: false\"\n\nDebug and Model Fitting\nI have made the frustum transformations available for visualization and debugging. You may enable them by the VISUALIZE_FRUSTUM macro, though be aware it takes a substantial decrease on performance since we're creating and destroying a ros publisher at a non-trivial rate.\nThis can also be used for situations where you do not know your camera's proper frustum FOVs. It is possible to enable it and tweek the FOVs until you get the appropriate coverage of the space your sensor carves out in the global space. You should only do this with one sensor at a time or else your frustum in rviz might jitter around. ;-)\nInteresting side note\nWe are able to iterate over very large grids for voxel decay, however there is clearly for every frequency (running at 1, 5, 10, 100hz) an upper limit. In the image below, we don't actually hit the limit of the data structure, but iterating at 2hz, we hit the limit of ROS' ability to publish a sufficiently large point cloud in that  time period, we are still running but you can see the robot at the end of an aisle without occupancy points, but still costmap marking from the underlying grid.\nTo counter this I include a service to save the grid in the .vdb format for later visualization, and for this reason I do not recommend visualizing the grid during nominal operations unless your decay time is relatively low (0-15 seconds) or else the layer may not meet its frequency requirements due to publishing this massive pointcloud.\n\n","19":"envy\n\n\n\n\n\nLet's face it, dealing with environment variables in Haskell isn't that satisfying.\nimport System.Environment\nimport Data.Text (pack)\nimport Text.Read (readMaybe)\n\ndata ConnectInfo = ConnectInfo {\n  pgPort :: Int\n  pgURL  :: Text\n} deriving (Show, Eq)\n\ngetPGPort :: IO ConnectInfo\ngetPGPort = do\n  portResult <- lookupEnv \"PG_PORT\"\n  urlResult  <- lookupEnv \"PG_URL\"\n  case (portResult, urlResult) of\n    (Just port, Just url) ->\n      case readMaybe port :: Maybe Int of\n\tNothing -> error \"PG_PORT isn't a number\"\n\tJust portNum -> return $ ConnectInfo portNum (pack url)\n    (Nothing, _) -> error \"Couldn't find PG_PORT\"\n    (_, Nothing) -> error \"Couldn't find PG_URL\"\n    -- Pretty gross right...\nAnother attempt to remedy the lookup madness is with a MaybeT IO a. See below.\n{-# LANGUAGE GeneralizedNewtypeDeriving #-}\n\nimport Control.Applicative\nimport Control.Monad.Trans.Maybe\nimport Control.Monad.IO.Class\nimport System.Environment\n\nnewtype Env a = Env { unEnv :: MaybeT IO a }\n    deriving (Functor, Applicative, Monad, MonadIO, Alternative, MonadPlus)\n\ngetEnv :: Env a -> IO (Maybe a)\ngetEnv env = runMaybeT (unEnv env)\n\nenv :: String -> Env a\nenv key = Env (MaybeT (lookupEnv key))\n\nconnectInfo :: Env ConnectInfo\nconnectInfo = ConnectInfo\n   <$> env \"PG_HOST\"\n   <*> env \"PG_PORT\"\n   <*> env \"PG_USER\"\n   <*> env \"PG_PASS\"\n   <*> env \"PG_DB\"\nThis abstraction falls short in two areas:\n\nLookups don't return any information when a variable doesn't exist (just a Nothing)\nLookups don't attempt to parse the returned type into something meaningful (everything is returned as a String because lookupEnv :: String -> IO (Maybe String))\n\nWhat if we could apply aeson's FromJSON \/ ToJSON pattern to give us variable lookups that provide both key-lookup and parse failure information?\nArmed with the GeneralizedNewTypeDeriving extension we can derive instances of Var that will parse to and from an environment variable. The Var typeclass is simply:\nclass Var a where\n  toVar   :: a -> String\n  fromVar :: String -> Maybe a\nWith instances for most concrete and primitive types supported (Word8 - Word64, Int, Integer, String, Text, etc.) the Var class is easily deriveable. The FromEnv typeclass provides a parser type that is an instance of MonadError String and MonadIO. This allows for connection pool initialization inside of our environment parser and custom error handling. The ToEnv class allows us to create an environment configuration given any a. See below for an example.\n{-# LANGUAGE ScopedTypeVariables        #-}\n{-# LANGUAGE RecordWildCards            #-}\n{-# LANGUAGE GeneralizedNewtypeDeriving #-}\n{-# LANGUAGE OverloadedStrings          #-}\n{-# LANGUAGE DeriveDataTypeable         #-}\n------------------------------------------------------------------------------\nmodule Main ( main ) where\n------------------------------------------------------------------------------\nimport           Control.Applicative\nimport           Control.Exception\nimport           Control.Monad\nimport           Data.Either\nimport           Data.Word\nimport           System.Environment\nimport           System.Envy\n------------------------------------------------------------------------------\ndata ConnectInfo = ConnectInfo {\n      pgHost :: String\n    , pgPort :: Word16\n    , pgUser :: String\n    , pgPass :: String\n    , pgDB   :: String\n  } deriving (Show)\n\n------------------------------------------------------------------------------\n-- | FromEnv instances support popular aeson combinators *and* IO\n-- for dealing with connection pool initialization. `env` is equivalent to (.:) in `aeson`\n-- and `envMaybe` is equivalent to (.:?), except here the lookups are impure.\ninstance FromEnv ConnectInfo where\n  fromEnv _ =\n    ConnectInfo <$> envMaybe \"PG_HOST\" .!= \"localhost\"\n\t\t<*> env \"PG_PORT\"\n\t\t<*> env \"PG_USER\"\n\t\t<*> env \"PG_PASS\"\n\t\t<*> env \"PG_DB\"\n\n------------------------------------------------------------------------------\n-- | To Environment Instances\n-- (.=) is a smart constructor for producing types of `EnvVar` (which ensures\n-- that Strings are set properly in an environment so they can be parsed properly\ninstance ToEnv ConnectInfo where\n  toEnv ConnectInfo {..} = makeEnv\n       [ \"PG_HOST\" .= pgHost\n       , \"PG_PORT\" .= pgPort\n       , \"PG_USER\" .= pgUser\n       , \"PG_PASS\" .= pgPass\n       , \"PG_DB\"   .= pgDB\n       ]\n\n------------------------------------------------------------------------------\n-- | Example\nmain :: IO ()\nmain = do\n   setEnvironment (toEnv :: EnvList ConnectInfo)\n   print =<< do decodeEnv :: IO (Either String ConnectInfo)\n   -- unsetEnvironment (toEnv :: EnvList ConnectInfo)  -- remove when done\nOur parser might also make use a set of an optional default values provided by the user,\nfor dealing with errors when reading from the environment\ninstance FromEnv ConnectInfo where\n  fromEnv Nothing =\n    ConnectInfo <$> envMaybe \"PG_HOST\" .!= \"localhost\"\n\t\t<*> env \"PG_PORT\"\n\t\t<*> env \"PG_USER\"\n\t\t<*> env \"PG_PASS\"\n\t\t<*> env \"PG_DB\"\n\n  fromEnv (Just def) =\n    ConnectInfo <$> envMaybe \"PG_HOST\" .!= (pgHost def)\n\t\t<*> envMaybe \"PG_PORT\" .!= (pgPort def)\n\t\t<*> env \"PG_USER\" .!= (pgUser def)\n\t\t<*> env \"PG_PASS\" .!= (pgPass def)\n\t\t<*> env \"PG_DB\" .!= (pgDB def)\nNote: As of base 4.7 setEnv and getEnv throw an IOException if a = is present in an environment. envy catches these synchronous exceptions and delivers them\npurely to the end user.\nGenerics\nAs of version 1.0, all FromEnv instance boilerplate can be completely removed thanks to GHC.Generics! Below is an example.\n{-# LANGUAGE DeriveGeneric #-}\nmodule Main where\n\nimport System.Envy\nimport GHC.Generics\nimport System.Environment.Blank\n\n-- This record corresponds to our environment, where the field names become the variable names, and the values the environment variable value\ndata PGConfig = PGConfig {\n    pgHost :: String -- \"PG_HOST\"\n  , pgPort :: Int    -- \"PG_PORT\"\n  } deriving (Generic, Show)\n\ninstance FromEnv PGConfig\n-- Generically creates instance for retrieving environment variables (PG_HOST, PG_PORT)\n\nmain :: IO ()\nmain = do\n  _ <- setEnv \"PG_HOST\" \"valueFromEnv\" True\n  _ <- setEnv \"PG_PORT\"  \"66354651\" True\n  print =<< do decodeEnv :: IO (Either String PGConfig)\n -- > PGConfig { pgHost = \"valueFromEnv\", pgPort = 66354651 }\nIf the variables are not found in the environment, the parser will currently fail with an error about the first missing field.\nThe user can decide to provide a default value, whose fields will be used by the generic instance, if retrieving them from the environment fails.\ndefConfig :: PGConfig\ndefConfig = PGConfig \"localhost\" 5432\n\nmain :: IO ()\nmain =\n  _ <- setEnv \"PG_HOST\" \"customURL\" True\n  print =<< decodeWithDefaults defConfig :: IO (Either String PGConfig)\n -- > PGConfig { pgHost = \"customURL\", pgPort = 5432 }\nSuppose you'd like to customize the field name (i.e. add your own prefix, or drop the existing record prefix). This too is possible. See below.\n{-# LANGUAGE DeriveGeneric #-}\nmodule Main where\n\nimport System.Envy\nimport GHC.Generics\n\ndata PGConfig = PGConfig {\n    connectHost :: String -- \"PG_HOST\"\n  , connectPort :: Int    -- \"PG_PORT\"\n  } deriving (Generic, Show)\n\ninstance DefConfig PGConfig where\n  defConfig = PGConfig \"localhost\" 5432\n\n-- All fields will be converted to uppercase\ninstance FromEnv PGConfig where\n  fromEnv = gFromEnvCustom Option {\n                    dropPrefixCount = 7\n                  , customPrefix = \"CUSTOM\"\n\t\t  }\n\nmain :: IO ()\nmain =\n  _ <- setEnv \"CUSTOM_HOST\" \"customUrl\" True\n  print =<< do decodeEnv :: IO (Either String PGConfig)\n -- PGConfig { pgHost = \"customUrl\", pgPort = 5432 }\nIt's also possible to avoid typeclasses altogether using runEnv with gFromEnvCustom.\n{-# LANGUAGE DeriveGeneric #-}\nmodule Main where\n\nimport System.Envy\nimport GHC.Generics\n\ndata PGConfig = PGConfig {\n    pgHost :: String -- \"PG_HOST\"\n  , pgPort :: Int    -- \"PG_PORT\"\n  } deriving (Generic, Show)\n\n-- All fields will be converted to uppercase\ngetPGEnv :: IO (Either String PGConfig)\ngetPGEnv = runEnv $ gFromEnvCustom defOption\n                                   (Just (PGConfig \"localhost\" 5432))\n\nmain :: IO ()\nmain = print =<< getPGEnv\n -- PGConfig { pgHost = \"localhost\", pgPort = 5432 }\n","20":"envy\n\n\n\n\n\nLet's face it, dealing with environment variables in Haskell isn't that satisfying.\nimport System.Environment\nimport Data.Text (pack)\nimport Text.Read (readMaybe)\n\ndata ConnectInfo = ConnectInfo {\n  pgPort :: Int\n  pgURL  :: Text\n} deriving (Show, Eq)\n\ngetPGPort :: IO ConnectInfo\ngetPGPort = do\n  portResult <- lookupEnv \"PG_PORT\"\n  urlResult  <- lookupEnv \"PG_URL\"\n  case (portResult, urlResult) of\n    (Just port, Just url) ->\n      case readMaybe port :: Maybe Int of\n\tNothing -> error \"PG_PORT isn't a number\"\n\tJust portNum -> return $ ConnectInfo portNum (pack url)\n    (Nothing, _) -> error \"Couldn't find PG_PORT\"\n    (_, Nothing) -> error \"Couldn't find PG_URL\"\n    -- Pretty gross right...\nAnother attempt to remedy the lookup madness is with a MaybeT IO a. See below.\n{-# LANGUAGE GeneralizedNewtypeDeriving #-}\n\nimport Control.Applicative\nimport Control.Monad.Trans.Maybe\nimport Control.Monad.IO.Class\nimport System.Environment\n\nnewtype Env a = Env { unEnv :: MaybeT IO a }\n    deriving (Functor, Applicative, Monad, MonadIO, Alternative, MonadPlus)\n\ngetEnv :: Env a -> IO (Maybe a)\ngetEnv env = runMaybeT (unEnv env)\n\nenv :: String -> Env a\nenv key = Env (MaybeT (lookupEnv key))\n\nconnectInfo :: Env ConnectInfo\nconnectInfo = ConnectInfo\n   <$> env \"PG_HOST\"\n   <*> env \"PG_PORT\"\n   <*> env \"PG_USER\"\n   <*> env \"PG_PASS\"\n   <*> env \"PG_DB\"\nThis abstraction falls short in two areas:\n\nLookups don't return any information when a variable doesn't exist (just a Nothing)\nLookups don't attempt to parse the returned type into something meaningful (everything is returned as a String because lookupEnv :: String -> IO (Maybe String))\n\nWhat if we could apply aeson's FromJSON \/ ToJSON pattern to give us variable lookups that provide both key-lookup and parse failure information?\nArmed with the GeneralizedNewTypeDeriving extension we can derive instances of Var that will parse to and from an environment variable. The Var typeclass is simply:\nclass Var a where\n  toVar   :: a -> String\n  fromVar :: String -> Maybe a\nWith instances for most concrete and primitive types supported (Word8 - Word64, Int, Integer, String, Text, etc.) the Var class is easily deriveable. The FromEnv typeclass provides a parser type that is an instance of MonadError String and MonadIO. This allows for connection pool initialization inside of our environment parser and custom error handling. The ToEnv class allows us to create an environment configuration given any a. See below for an example.\n{-# LANGUAGE ScopedTypeVariables        #-}\n{-# LANGUAGE RecordWildCards            #-}\n{-# LANGUAGE GeneralizedNewtypeDeriving #-}\n{-# LANGUAGE OverloadedStrings          #-}\n{-# LANGUAGE DeriveDataTypeable         #-}\n------------------------------------------------------------------------------\nmodule Main ( main ) where\n------------------------------------------------------------------------------\nimport           Control.Applicative\nimport           Control.Exception\nimport           Control.Monad\nimport           Data.Either\nimport           Data.Word\nimport           System.Environment\nimport           System.Envy\n------------------------------------------------------------------------------\ndata ConnectInfo = ConnectInfo {\n      pgHost :: String\n    , pgPort :: Word16\n    , pgUser :: String\n    , pgPass :: String\n    , pgDB   :: String\n  } deriving (Show)\n\n------------------------------------------------------------------------------\n-- | FromEnv instances support popular aeson combinators *and* IO\n-- for dealing with connection pool initialization. `env` is equivalent to (.:) in `aeson`\n-- and `envMaybe` is equivalent to (.:?), except here the lookups are impure.\ninstance FromEnv ConnectInfo where\n  fromEnv _ =\n    ConnectInfo <$> envMaybe \"PG_HOST\" .!= \"localhost\"\n\t\t<*> env \"PG_PORT\"\n\t\t<*> env \"PG_USER\"\n\t\t<*> env \"PG_PASS\"\n\t\t<*> env \"PG_DB\"\n\n------------------------------------------------------------------------------\n-- | To Environment Instances\n-- (.=) is a smart constructor for producing types of `EnvVar` (which ensures\n-- that Strings are set properly in an environment so they can be parsed properly\ninstance ToEnv ConnectInfo where\n  toEnv ConnectInfo {..} = makeEnv\n       [ \"PG_HOST\" .= pgHost\n       , \"PG_PORT\" .= pgPort\n       , \"PG_USER\" .= pgUser\n       , \"PG_PASS\" .= pgPass\n       , \"PG_DB\"   .= pgDB\n       ]\n\n------------------------------------------------------------------------------\n-- | Example\nmain :: IO ()\nmain = do\n   setEnvironment (toEnv :: EnvList ConnectInfo)\n   print =<< do decodeEnv :: IO (Either String ConnectInfo)\n   -- unsetEnvironment (toEnv :: EnvList ConnectInfo)  -- remove when done\nOur parser might also make use a set of an optional default values provided by the user,\nfor dealing with errors when reading from the environment\ninstance FromEnv ConnectInfo where\n  fromEnv Nothing =\n    ConnectInfo <$> envMaybe \"PG_HOST\" .!= \"localhost\"\n\t\t<*> env \"PG_PORT\"\n\t\t<*> env \"PG_USER\"\n\t\t<*> env \"PG_PASS\"\n\t\t<*> env \"PG_DB\"\n\n  fromEnv (Just def) =\n    ConnectInfo <$> envMaybe \"PG_HOST\" .!= (pgHost def)\n\t\t<*> envMaybe \"PG_PORT\" .!= (pgPort def)\n\t\t<*> env \"PG_USER\" .!= (pgUser def)\n\t\t<*> env \"PG_PASS\" .!= (pgPass def)\n\t\t<*> env \"PG_DB\" .!= (pgDB def)\nNote: As of base 4.7 setEnv and getEnv throw an IOException if a = is present in an environment. envy catches these synchronous exceptions and delivers them\npurely to the end user.\nGenerics\nAs of version 1.0, all FromEnv instance boilerplate can be completely removed thanks to GHC.Generics! Below is an example.\n{-# LANGUAGE DeriveGeneric #-}\nmodule Main where\n\nimport System.Envy\nimport GHC.Generics\nimport System.Environment.Blank\n\n-- This record corresponds to our environment, where the field names become the variable names, and the values the environment variable value\ndata PGConfig = PGConfig {\n    pgHost :: String -- \"PG_HOST\"\n  , pgPort :: Int    -- \"PG_PORT\"\n  } deriving (Generic, Show)\n\ninstance FromEnv PGConfig\n-- Generically creates instance for retrieving environment variables (PG_HOST, PG_PORT)\n\nmain :: IO ()\nmain = do\n  _ <- setEnv \"PG_HOST\" \"valueFromEnv\" True\n  _ <- setEnv \"PG_PORT\"  \"66354651\" True\n  print =<< do decodeEnv :: IO (Either String PGConfig)\n -- > PGConfig { pgHost = \"valueFromEnv\", pgPort = 66354651 }\nIf the variables are not found in the environment, the parser will currently fail with an error about the first missing field.\nThe user can decide to provide a default value, whose fields will be used by the generic instance, if retrieving them from the environment fails.\ndefConfig :: PGConfig\ndefConfig = PGConfig \"localhost\" 5432\n\nmain :: IO ()\nmain =\n  _ <- setEnv \"PG_HOST\" \"customURL\" True\n  print =<< decodeWithDefaults defConfig :: IO (Either String PGConfig)\n -- > PGConfig { pgHost = \"customURL\", pgPort = 5432 }\nSuppose you'd like to customize the field name (i.e. add your own prefix, or drop the existing record prefix). This too is possible. See below.\n{-# LANGUAGE DeriveGeneric #-}\nmodule Main where\n\nimport System.Envy\nimport GHC.Generics\n\ndata PGConfig = PGConfig {\n    connectHost :: String -- \"PG_HOST\"\n  , connectPort :: Int    -- \"PG_PORT\"\n  } deriving (Generic, Show)\n\ninstance DefConfig PGConfig where\n  defConfig = PGConfig \"localhost\" 5432\n\n-- All fields will be converted to uppercase\ninstance FromEnv PGConfig where\n  fromEnv = gFromEnvCustom Option {\n                    dropPrefixCount = 7\n                  , customPrefix = \"CUSTOM\"\n\t\t  }\n\nmain :: IO ()\nmain =\n  _ <- setEnv \"CUSTOM_HOST\" \"customUrl\" True\n  print =<< do decodeEnv :: IO (Either String PGConfig)\n -- PGConfig { pgHost = \"customUrl\", pgPort = 5432 }\nIt's also possible to avoid typeclasses altogether using runEnv with gFromEnvCustom.\n{-# LANGUAGE DeriveGeneric #-}\nmodule Main where\n\nimport System.Envy\nimport GHC.Generics\n\ndata PGConfig = PGConfig {\n    pgHost :: String -- \"PG_HOST\"\n  , pgPort :: Int    -- \"PG_PORT\"\n  } deriving (Generic, Show)\n\n-- All fields will be converted to uppercase\ngetPGEnv :: IO (Either String PGConfig)\ngetPGEnv = runEnv $ gFromEnvCustom defOption\n                                   (Just (PGConfig \"localhost\" 5432))\n\nmain :: IO ()\nmain = print =<< getPGEnv\n -- PGConfig { pgHost = \"localhost\", pgPort = 5432 }\n","21":"Environmental Sound Classification\nHere, an algorithm to classify environmental sounds with the aim of providing contextual information to devices such as hearing aids for optimum performance is proposed. We use signal sub-band energy to construct signal-dependent dictionary and matching pursuit algorithms to obtain a sparse representation of a signal. The coefficients of the sparse vector are used as weights to compute weighted features. These features, along with mel frequency cepstral coefficients (MFCC), are used as feature vectors for classification. Experimental results show that the proposed method gives an accuracy as high as 95.6 %, while classifying 14 categories of environmental sound using a Gaussian mixture model (GMM). For more details, please refer to [1]. Please cite [1] if you are using this code.\nA note on the data : All data were obtained from the website http:\/\/freesound.org. The class wise data information can be obtained from the file \"finalList.list\".\n[1] Sivasankaran, S.; Prabhu, K.M.M., \"Robust features for environmental sound classification,\" Electronics, Computing and Communication Technologies (CONECCT), 2013 IEEE International Conference on , vol., no., pp.1,6, 17-19 Jan. 2013\n","22":"http:\/\/environmentalcomputing.net\/\n\n","23":"LandGIS \u2014 Open Land Data service\nHengl, T., Kilibarda, M., Ognjen Antonijevic, O., Glusica, L., Krizan, J.\n\n\n\n\n\n\n\n\n\n\n\n\nGeneral specifications\nAccessing data\nAccessing data from Zenodo\nAccessing data from Google Earth Engine\nThe file naming convention\nThe land mask\nCloud-optimized GeoTIFF\nRelief and geology\nLand cover, land use and administrative data\nVegetation indices\nLand degradation indices\nClimatic layers\nSoil properties and classes\nPotential natural vegetation\nHydrology and water dynamics\nReferences\n\n\n\n\nLandGIS\nLandGIS is a Web-GIS system providing access to spatial layers and services\ncovering global land mass (at spatial resolutions of 1 km, 250 m or finer resolution).\nIt aims at becoming an OpenStreetMap for land data. Access to spatial layers is\npossible via interactive visualizations and\/or Open Source software solutions.\nRead more about this project here.\n\nThe LandGIS layers, if not specified otherwise, are licensed under the\nCreative Commons Attribution-ShareAlike 4.0 International license (CC BY-SA) and\/or\nthe Open Data Commons Open Database License (ODbL). This implies that anyone can use,\nor build upon, the LandGIS data without restrictions.\nSee the Copyright and License page for more details.\nUsers can access LandGIS data via the four main channels:\n\nLandGIS App at https:\/\/landgis.opengeohub.org,\nOpenGeoHub Geonode installation at https:\/\/maps.opengeohub.org,\nLandGIS REST API services at https:\/\/landgisapi.opengeohub.org,\nLandGIS WCS at https:\/\/geoserver.opengeohub.org\/landgisgeoserver\/web\/,\nZenodo.org to access a (version-controlled) back-up copy of data via a DOI,\n\nData portal https:\/\/landgis.opengeohub.org is the landing page where users can browse maps, query values by\nlocation, and find out about most recent news and activities. Geonode at https:\/\/maps.opengeohub.org\nis a generic layer repository for accessing layers installed via OpenGeoHub Geoserver.\nIt allow users i.e. producers of layers to edit and update metadata and descriptions,\ncreate map views, learn how to use WCS, WMS or similar. A copy of the raw data can be obtained\nvia zenodo.org or similar public data repositories.\nAccessing data\nLandGIS data services REST API (https:\/\/landgisapi.opengeohub.org) contains scripts and functions\nthat allow users to and developers to fetch raw data (point queries) in some simple textual\nformats such as GeoJSON, csv, compressed GeoTIFFs or similar. The following query would fetch monthly precipitations at a location X, Y:\nhttps:\/\/landgisapi.opengeohub.org\/query\/point?lat=7.58033&lon=35.6561&coll=layers1km&regex=clm_precipitation_imerge.(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)_m_1km_s0..0cm_.*_v0.1.tif\n\nwhich results in:\nProject description\t\n0\t\"https:\/\/opengeohub.org\/about-landgis\"\nDescription of all codes\t\n0\t\"https:\/\/github.com\/envirometrix\/landGISmaps\/\"\nresponse\t\n0\t\nlon\t35.6561\nlat\t7.5803\nclm_precipitation_imerge.apr_m_1km_s0..0cm_2014..2018_v0.1.tif\t149\nclm_precipitation_imerge.aug_m_1km_s0..0cm_2014..2018_v0.1.tif\t194\nclm_precipitation_imerge.dec_m_1km_s0..0cm_2014..2018_v0.1.tif\t48\nclm_precipitation_imerge.feb_m_1km_s0..0cm_2014..2018_v0.1.tif\t51\nclm_precipitation_imerge.jan_m_1km_s0..0cm_2014..2018_v0.1.tif\t56\nclm_precipitation_imerge.jul_m_1km_s0..0cm_2014..2018_v0.1.tif\t184\nclm_precipitation_imerge.jun_m_1km_s0..0cm_2014..2018_v0.1.tif\t198\nclm_precipitation_imerge.mar_m_1km_s0..0cm_2014..2018_v0.1.tif\t109\nclm_precipitation_imerge.may_m_1km_s0..0cm_2014..2018_v0.1.tif\t203\nclm_precipitation_imerge.nov_m_1km_s0..0cm_2014..2018_v0.1.tif\t81\nclm_precipitation_imerge.oct_m_1km_s0..0cm_2014..2018_v0.1.tif\t152\nclm_precipitation_imerge.sep_m_1km_s0..0cm_2014..2018_v0.1.tif\t197\n\nto determine a soil type (USDA great group) use:\nhttps:\/\/landgisapi.opengeohub.org\/query\/point?lat=30.2543&lon=-95.5811&coll=predicted250m&regex=sol_grtgroup_usda.soiltax_c_250m_b0..0cm_1950..2017_v0.1.tif\n\nwhich gives e.g.:\nProject description\t\n0\t\"https:\/\/opengeohub.org\/about-landgis\"\nDescription of all codes\t\n0\t\"https:\/\/github.com\/envirometrix\/landGISmaps\/\"\nresponse\t\n0\t\nlon\t-95.5811\nlat\t30.2543\nsol_grtgroup_usda.soiltax_c_250m_s0..0cm_1950..2017_v0.1.tif\t30\ninfo\t\n0\t\nX\t30\nNumber\t30\nGroup\t\"paleudalfs\"\nGreat_Group_2015_match\t\"Paleudalfs\"\nSuborder\t\"Udalfs\"\nOrder\t\"Alfisols\"\n\n\nImage: Example of spatial query on soil types (USDA great groups) in the LandGIS app.\nTo list all available layers use: https:\/\/landgisapi.opengeohub.org\/query\/layers\nTo query values for multiple points (currently limited to max 50 points)\nprovide a GeoJSON with point feature collection and layer name from the table:\ncurl -X POST --form \"points=@test_points.geojson\" --form \"layer=pnv_fapar_proba.v.jul_d_1km_s0..0cm_2014..2017_v0.1.tif\" https:\/\/landgisapi.opengeohub.org\/query\/points -o results.json \n\nwhere test_points.geojson is the GeoJSON file containing coordinates of points.\nMore examples of how to construct spatial queries are available at:\nhttps:\/\/landgisapi.opengeohub.org\nIn addition to the REST access, you can access the LandGIS data using the\nWeb Coverage Service (WCS) functionality of the Geoserver e.g. to subset layers using a bounding box.\nFor example, to download surface temperature for July for an area\nof about 300 by 300 km you can use:\nhttps:\/\/geoserver.opengeohub.org\/landgisgeoserver\/ows?service=WCS&version=2.0.1&\nrequest=GetCoverage&\ncoverageId=layers1km:clm_lst_mod11a2.jul.day_m_1km_s0..0cm_2000..2017_v1.0&\nsubset=Lat(41,45)&subset=Long(32,35)\n\nThe read limit for WCS is 8GB and response size limit is 400MB. This means that\nWCS might fail if you try to fetch too large bounding boxes. If this happens we\nrecommend instead downloading whole GeoTIFFs from Zenodo.\nTo produce the whole world GeoTIFFs clay content map at e.g. 5 km you can use:\nhttps:\/\/geoserver.opengeohub.org\/landgisgeoserver\/ows?service=WCS&version=2.0.1\n&request=GetCoverage\n&coverageId=predicted250m:sol_clay.wfraction_usda.3a1a1a_m_250m_b30..30cm_1950..2017_v0.2\n&scalefactor=0.05\n\nHere scalefactor multiplies the input pixel size accordingly. Note, you can\nalso convert to other projection systems on-the-fly (see this tutorial for more info).\n\nImage: Parameter settings for adding LandGIS WMS to QGIS.\nAccessing data from Zenodo\nTo download whole layers from zenodo you can use the R packages jsonlite and RCurl:\n> library(jsonlite)\n> library(RCurl)\n> library(rgdal)\n\nYou first need to authenticate yourself by using a Zenodo API TOKEN\n(see: how to obtain API TOKEN):\n> TOKEN = scan(\"~\/TOKEN_ACCESS\", what=\"character\")\n\nTo download the MODIS LST images at 1 km you can use the bucket ID dep.id = \"1435938\" which gives:\n> dep.id = \"1435938\"\n> x = fromJSON(system(paste0('curl -H \\\"Accept: application\/json\\\" -H \\\"Authorization: Bearer ', \n        TOKEN, '\\\" \\\"https:\/\/www.zenodo.org\/api\/deposit\/depositions\/', dep.id, '\\\"'), intern=TRUE))\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 58704  100 58704    0     0  80219      0 --:--:-- --:--:-- --:--:-- 80196\n> str(x, max.level = 1)\nList of 15\n $ conceptdoi  : chr \"10.5281\/zenodo.1420114\"\n $ conceptrecid: chr \"1420114\"\n $ created     : chr \"2018-09-26T18:29:02.934312+00:00\"\n $ doi         : chr \"10.5281\/zenodo.1435938\"\n $ doi_url     : chr \"https:\/\/doi.org\/10.5281\/zenodo.1435938\"\n $ files       :'data.frame':\t102 obs. of  5 variables:\n $ id          : int 1435938\n $ links       :List of 18\n $ metadata    :List of 15\n $ modified    : chr \"2018-10-07T16:28:33.956582+00:00\"\n $ owner       : int 43652\n $ record_id   : int 1435938\n $ state       : chr \"done\"\n $ submitted   : logi TRUE\n $ title       : chr \"Long-term MODIS LST day-time and night-time temperatures, sd and differences at 1 km based on the 2000\u20132017 time series\"\n\nThis shows that there are total of 102 files in this folder. To download all temperatures for August,\nwe would hence use:\n> sel.tif = x$files$links$download[grep(\"aug\", x$files$links$download)]\n\nwhich gives a total of 9 files:\n> sel.tif\n[1] \"https:\/\/www.zenodo.org\/api\/files\/57591d98-08b1-464d-86b2-aff632b16f82\/clm_lst_mod11a2.aug.day_l.025_1km_s0..0cm_2000..2017_v1.0.tif\"\n[2] \"https:\/\/www.zenodo.org\/api\/files\/57591d98-08b1-464d-86b2-aff632b16f82\/clm_lst_mod11a2.aug.day_m_1km_s0..0cm_2000..2017_v1.0.tif\"\n[3] \"https:\/\/www.zenodo.org\/api\/files\/57591d98-08b1-464d-86b2-aff632b16f82\/clm_lst_mod11a2.aug.daynight_m_1km_s0..0cm_2000..2017_v1.0.tif\" \n[4] \"https:\/\/www.zenodo.org\/api\/files\/57591d98-08b1-464d-86b2-aff632b16f82\/clm_lst_mod11a2.aug.day_sd_1km.png\"\n[5] \"https:\/\/www.zenodo.org\/api\/files\/57591d98-08b1-464d-86b2-aff632b16f82\/clm_lst_mod11a2.aug.day_sd_1km_s0..0cm_2000..2017_v1.0.tif\"\n[6] \"https:\/\/www.zenodo.org\/api\/files\/57591d98-08b1-464d-86b2-aff632b16f82\/clm_lst_mod11a2.aug.day_u.975_1km_s0..0cm_2000..2017_v1.0.tif\"\n[7] \"https:\/\/www.zenodo.org\/api\/files\/57591d98-08b1-464d-86b2-aff632b16f82\/clm_lst_mod11a2.aug.night_l.025_1km_s0..0cm_2000..2017_v1.0.tif\"\n[8] \"https:\/\/www.zenodo.org\/api\/files\/57591d98-08b1-464d-86b2-aff632b16f82\/clm_lst_mod11a2.aug.night_m_1km_s0..0cm_2000..2017_v1.0.tif\"\n[9] \"https:\/\/www.zenodo.org\/api\/files\/57591d98-08b1-464d-86b2-aff632b16f82\/clm_lst_mod11a2.aug.night_u.975_1km_s0..0cm_2000..2017_v1.0.tif\"\n\nthese can be further downloaded using download.file function or similar.\nThere is also an R package for zenodo (zen4R) that makes downloading files even easier.\nAccessing data from Google Earth Engine\nGoogle Earth Engine users can access a snapshot of OpenLandMap.org layers using the following address:\n\nhttps:\/\/code.earthengine.google.com\/?asset=users\/opengeohub\/landgis\n\nDescription of layer names and units used can be find here.\nNote that sync between the layers on the OpenLandMap.org and Google Earth Engine is done\nonly once a year, hence, if you wish to use the most up-to-date layers at any moment,\ndownloading maps from either Zenodo or via the WCS is recommended.\nTo access OpenLandMap layers you can also refer to the public data sets at:\n\nhttps:\/\/developers.google.com\/earth-engine\/datasets\/tags\/openlandmap\n\nThe file naming convention\nLandGIS file names is based on a simple 7-level nomenclature (see\ncomplete list):\n\n\nTheme code,\n\n\nGeneric variable name,\n\n\nVariable procedure combination (standard abbreviation),\n\n\nPosition in the probability distribution \/ variable type:\na.  m = mean value,\nb.  d = median value,\nc.  l.159 = lower 68% probability threshold (quantile),\nd.  u.841 = upper 68% probability threshold (quantile), for\none-sided probability use \u201cuo\u201d,\ne.  sd.1 = 1 standard deviation (\u201csd\u201c can be also used),\nf.  md = model deviation (in the case of ensemble predictions),\ng.  td = cumulative difference (usually based on time-series of values),\nh.  c = classes i.e. factor variable,\ni.  p = probability or fraction,\nj.  sse = Shannon Scaled Entropy index\n\n\nSpatial support (usually horizontal block) in m or km e.g. \u201c250m\u201d\n\n\nDepth reference or depth interval e.g. \u201cb0..10cm\u201d below (\"b\"),\nabove (\"a\") ground or at surface (\"s\"),\n\n\nTime reference (begin end time) in standard date format e.g.\n\u201c01.Feb.2018\u201d,\n\n\nVersion of the map (major release - update - bug fix).\n\n\nThis is an example of file name for soil pH estimated using H2O suspension\npredicted at 30 cm depth from surface:\nsol_ph.h2o_usda.4c1a2a_md_250m_s30..30cm_1950..2017_v0.1.tif\n\nNote from this example the following:\n\n\nNo mathematical symbols are used e.g. \"+\" or \"\/\",\n\n\nno capitalized letters are used,\n\n\n\"..\" is used to indicate range,\n\n\n\".\" is used to indicate space,\n\n\nbegin, end dates follow common conversion e.g. \"1.jan.2000\",\n\n\nThe land mask\nThe bounding box of interest for LandGIS data is:\nXmin = -180.00000\nYmin = -62.00081\nXmax = 179.99994\nYmax = 87.37000\n\nThe image sizes at various standard resolutions are:\n\n250m = 172800P x 71698L,\n500m = 86400P x 35849L,\n1km = 43200P x 17924L,\n\n\nImage: Land mask derived using the ESA land cover time series of maps\n2000\u20132015. Red areas indicate barren lands, light green indicates\npermanent ice areas.\nThe standard spatial resolutions are derived using simple\nrule of thumb:\n\n\n250 m = 1\/480 d.d. = 0.002083333\n\n\n500 m = 1\/240 d.d. = 0.004166667\n\n\n1 km = 1\/120 d.d. = 0.008333333\n\n\nLandGIS works with a standard land mask derived using the ESA time series of land cover maps 2000\u20132015:\nlcv_landmask_esacci.lc.l4_c_250m_s0..0cm_2000..2015_v1.0.tif\n\n\ud83d\udcc2 Download layer\nIt contains the following values:\n\n\n1 = land (all remaining pixels not permanent water, desert or ice)\n\n\n2 = permanent water bodies (consistently water body 2000\u20132015)\n\n\n3 = permanent bare areas (consistently bare areas \/\ndeserts 2000\u20132015)\n\n\n4 = permanent ice (consistently ice 2000\u20132015)\n\n\nIf you need a global equal area projection (e.g. to be able to derive total stocks \/ density of features in N\/km-squared)\nwe advise using the Goode Homolosine projection:\n+proj=igh +ellps=WGS84 +units=m +no_defs\n\n\nImage: 100 by 100 km blocks and land mask in the Goode Homolosine projection.\n\ud83d\udcc2 Download layer\nThe bounding box would in this case be:\nXmin = -20037508\nYmin = -6728980\nXmax = 20037508\nYmax = 8421750\n\nand the corresponding image sizes is:\n\n250m = 172800P x 71698L,\n\nCloud-optimized GeoTIFF\nAll layers included in the LandGIS system have been pre-processed following the GDAL's cloud-optimized GeoTIFF\ninstructions. To process large (global land mask at 250 m resolution or finer) GeoTIFFs please use the following\nsettings:\ngdalwarp layer.vrt layer.tif \n   -tr 0.002083333 0.002083333 \n   -te -180.00000 -62.00081 179.99994 87.37000\n   -wm 2000 -co \\\"COMPRESS=LZW\\\" -co \\\"BIGTIFF=YES\\\"\n\nTo prepare a cloud-optimized GeoTIFF use:\ngdaladdo layer.tif -r near 2 4 8 16 32 64 128\ngdal_translate layer.tif layer-co.tif -mo \\\"CO=YES\\\" -co \\\"TILED=YES\\\" -co \\\"BLOCKXSIZE=512\\\" \n        -co \\\"BLOCKYSIZE=512\\\" -co \\\"COMPRESS=LZW\\\" -co \\\"COPY_SRC_OVERVIEWS=YES\\\" \n        --config GDAL_TIFF_OVR_BLOCKSIZE 512\n\nThis will add tiles and optimize compression. CO=YES indicates that the GeoTIFF has been cloud-optimized.\nRelief and geology\nRelief parameters were derived derived using SAGA GIS (http:\/\/www.saga-gis.org\/)\nand the MERIT DEM (Yamazaki et al. 2017) projected in the Equi7 grid system\n(Bauer-Marschallinger et al. 2014). Once derived, DEM derivatives were then\nreprojected to the lon-lat system. See processing steps.\n1.1 Slope in radians\nBased on the MERIT DEM (Yamazaki et al. 2017) derived using SAGA GIS and Equi7 grid system.\ndtm_slope_merit.dem_m_250m_s0..0cm_2017_v1.0.tif\n\n\ud83d\udcc2 Download layer\n1.2 SAGA Topographic Wetness Index (TWI)\nBased on the MERIT DEM (Yamazaki et al. 2017) derived using SAGA GIS and Equi7 grid system.\ndtm_twi_merit.dem_m_500m_s0..0cm_2017_v1.0.tif\n\n\ud83d\udcc2 Download layer\n1.3 Module Multiresolution Index of Valley Bottom Flatness (MRVBF)\nBased on the MERIT DEM (Yamazaki et al. 2017) derived using SAGA GIS and Equi7 grid system.\ndtm_vbf_merit.dem_m_250m_s0..0cm_2017_v1.0.tif\n\n\ud83d\udcc2 Download layer\n1.4 Rock type\nBased on the USGS Global Ecophysiography map \/ Global Lithological Map database v1.1 (GLiM, Hartmann and Moosdorf, 2012).\ndtm_lithology_usgs.ecotapestry_c_250m_s0..0cm_2017..2018_v0.1.tif\n\n\ud83d\udcc2 Download layer\n\u2139\ufe0f Classes\n1.5 Landform class\nBased on the USGS Global Ecophysiography map (Sayre et al. 2014).\ndtm_landform_usgs.ecotapestry_c_250m_s0..0cm_2017..2018_v0.1.tif\n\n\ud83d\udcc2 Download layer\n\u2139\ufe0f Classes\nUSGS Global Ecophysiography map is property of the U.S. Department of the Interior, U.S. Geological Survey.\n1.6 Density of Earthquakes for the last 100 years\nBased on the USGS global earthquakes database (http:\/\/earthquake.usgs.gov\/earthquakes\/). We considered only earthquakes with magntiude 4 or higher (405,885 quakes in total).\nProcessing steps are explained here.\ndtm_earthquakes.dens_earthquake.usgs_m_1km_s0..0cm_1910..2017_v1.0.tif\n\n\ud83d\udcc2 Download layer\n1.7 Cosine of the aspect\nBased on the MERIT DEM (Yamazaki et al. 2017) described in Amatulli et al. (2019; Geomorpho90m dataset).\ndtm_aspect-cosine_merit.dem_m_250m_s0..0cm_2018_v1.0.tif\n\n\ud83d\udcc2 Download layer\n1.8 Sine of the aspect\nBased on the MERIT DEM (Yamazaki et al. 2017) described in Amatulli et al. (2019; Geomorpho90m dataset).\ndtm_aspect-sine_merit.dem_m_250m_s0..0cm_2018_v1.0.tif\n\n\ud83d\udcc2 Download layer\n1.9 Convergence\nBased on the MERIT DEM (Yamazaki et al. 2017) described in Amatulli et al. (2019; Geomorpho90m dataset). Derived using GRASS and Equi7 grid system.\ndtm_convergence_merit.dem_m_250m_s0..0cm_2018_v1.0.tif\n\n\ud83d\udcc2 Download layer\n1.10 Compound topographic index\nBased on the MERIT DEM (Yamazaki et al. 2017) described in Amatulli et al. (2019; Geomorpho90m dataset). Derived using GRASS and Equi7 grid system.\ndtm_cti_merit.dem_m_250m_s0..0cm_2018_v1.0.tif\n\n\ud83d\udcc2 Download layer\n1.11 Maximum multiscale deviation\nBased on the MERIT DEM (Yamazaki et al. 2017) described in Amatulli et al. (2019; Geomorpho90m dataset). Derived using WHITEBOX and Equi7 grid system.\ndtm_dev-magnitude_merit.dem_m_250m_s0..0cm_2018_v1.0.tif\n\n\ud83d\udcc2 Download layer\n1.12 Scale of the maximum multiscale deviation\nBased on the MERIT DEM (Yamazaki et al. 2017) described in Amatulli et al. (2019; Geomorpho90m dataset). Derived using WHITEBOX and Equi7 grid system.\ndtm_dev-scale_merit.dem_m_250m_s0..0cm_2018_v1.0.tif\n\n\ud83d\udcc2 Download layer\n1.13 Easthness\nBased on the MERIT DEM (Yamazaki et al. 2017) described in Amatulli et al. (2019; Geomorpho90m dataset). Derived using GDAL.\ndtm_easthness_merit.dem_m_250m_s0..0cm_2018_v1.0.tif\n\n\ud83d\udcc2 Download layer\n1.14 Geomorphon clasess\nBased on the MERIT DEM (Yamazaki et al. 2017) described in Amatulli et al. (2019; Geomorpho90m dataset). Derived using GRASS and Equi7 grid system. See description of the geomorphon classes.\ndtm_geom_merit.dem_c_250m_s0..0cm_2018_v1.0.tif\n\n\ud83d\udcc2 Download layer\n1.15 Northness\nBased on the MERIT DEM (Yamazaki et al. 2017) described in Amatulli et al. (2019; Geomorpho90m dataset). Derived using GDAL.\ndtm_northness_merit.dem_m_250m_s0..0cm_2018_v1.0.tif\n\n\ud83d\udcc2 Download layer\n1.16 Profile curvature\nBased on the MERIT DEM (Yamazaki et al. 2017) described in Amatulli et al. (2019; Geomorpho90m dataset). Derived using GRASS and Equi7 grid system.\ndtm_pcurv_merit.dem_m_250m_s0..0cm_2018_v1.0.tif\n\n\ud83d\udcc2 Download layer\n1.17 Maximum multiscale roughness\nBased on the MERIT DEM (Yamazaki et al. 2017) described in Amatulli et al. (2019; Geomorpho90m dataset). Derived using WHITEBOX and Equi7 grid system.\ndtm_rough-magnitude_merit.dem_m_250m_s0..0cm_2018_v1.0.tif\n\n\ud83d\udcc2 Download layer\n1.18 Roughness\nBased on the MERIT DEM (Yamazaki et al. 2017) described in Amatulli et al. (2019; Geomorpho90m dataset). Derived using GDAL.\ndtm_roughness_merit.dem_m_250m_s0..0cm_2018_v1.0.tif\n\n\ud83d\udcc2 Download layer\n1.19 Scale of the maximum multiscale roughness\nBased on the MERIT DEM (Yamazaki et al. 2017) described in Amatulli et al. (2019; Geomorpho90m dataset). Derived using WHITEBOX and Equi7 grid system.\ndtm_rough-scale_merit.dem_m_250m_s0..0cm_2018_v1.0.tif\n\n\ud83d\udcc2 Download layer\n1.20 Tangential curvature\nBased on the MERIT DEM (Yamazaki et al. 2017) described in Amatulli et al. (2019; Geomorpho90m dataset). Derived using GRASS and Equi7 grid system.\ndtm_tcurv_merit.dem_m_250m_s0..0cm_2018_v1.0.tif\n\n\ud83d\udcc2 Download layer\n1.21 Vector ruggedness measure\nBased on the MERIT DEM (Yamazaki et al. 2017) described in Amatulli et al. (2019; Geomorpho90m dataset). Derived using GRASS and Equi7 grid system.\ndtm_vrm_merit.dem_m_250m_s0..0cm_2018_v1.0.tif\n\n\ud83d\udcc2 Download layer\nLand cover, land use and administrative data\n2.1 Land cover images for 1992 to 2015\nBased on the European Space Agency (ESA) Climate Change Initiative (ESACCI-LC).\nlcv_land.cover_esacci.lc.l4_c_250m_s0..0cm_*_v1.0.tif\n\n\ud83d\udcc2 Download layer\n\u2139\ufe0f Classes\nCCI Land cover time series \u00a9 ESA Climate Change Initiative \u2014 Land Cover led by UCLouvain (2017).\n2.2 Surface water occurrence probability\nBased on the Pekel et al. (2016) \/ provided by EC Joint Research Centre.\nTo download the higher resolution version of this map visit https:\/\/global-surface-water.appspot.com\/\nlcv_water.occurance_jrc.surfacewater_p_250m_b0..200cm_1984..2016_v1.0.tif\n\n\ud83d\udcc2 Download layer\n2.3 Nightlights changes\n2nd principal component based on the Version 4 DMSP-OLS Nighttime Lights Time Series 1997\u20132014. See processing steps.\nlcv_nightlights.stable_dmsp.pc2_m_1km_s0..0cm_1992..2013_v1.0.tif\n\n\ud83d\udcc2 Download layer\n2.4 Croplands historic\nTime-series of maps showing cropland evolution for the past 12,000 years\nbased on the HYDE v3.2 data set (Klein Goldewijk et al. 2017).\nlcv_landuse.cropland_hyde_p_10km_s0..0cm_*_v3.2.tif\n\n\ud83d\udcc2 Download layer\n2.5 Pastures historic\nTime-series of maps showing pastures evolution for the past 12,000 years\nbased on the HYDE v3.2 data set (Klein Goldewijk et al. 2017).\nlcv_landuse.pasture_hyde_p_10km_s0..0cm_*_v3.2.tif\n\n\ud83d\udcc2 Download layer\nHistoric land use maps HYDE data set is property of Netherlands Environmental Assessment Agency (PBL).\nVegetation indices\nFAPAR vegetation indices have been derived using the quantile function and data.table package.\nFor detailed processing steps please refer to Hengl et al. (2018).\n3.1 FAPAR median monthly value 2014\u20132017\nBased on the Copernicus PROB-V FAPAR product.\nveg_fapar_proba.v.*_d_250m_s0..0cm_2014..2017_v1.0.tif\n\n\ud83d\udcc2 Download layer\n3.2 FAPAR median annual value 2014\u20132017\nBased on the Copernicus PROB-V FAPAR product.\nveg_fapar_proba.v.annual_d_250m_s0..0cm_2014..2017_v1.0.tif\n\n\ud83d\udcc2 Download layer\n3.3 FAPAR standard deviation annual value 2014\u20132017\nBased on the Copernicus PROB-V FAPAR product.\nveg_fapar_proba.v.annual_sd_250m_s0..0cm_2014..2017_v1.0.tif\n\n\ud83d\udcc2 Download layer\nLand degradation indices\n4.1 Soil organic carbon stock change (0\u201330 cm)\nEstimated SOC loss (0\u201330 cm) based on the European Space Agency (ESA) Climate Change Initiative\n(ESACCI-LC) land cover maps 2001\u20132015. This only shows estimated SOC loss (in kg\/m2) as a result of\nchange in land use \/ land cover. See processing steps.\nldg_organic.carbon.stock_msa.kgm2_td_250m_b0..30cm_2001..2015_v0.1.tif\n\n\ud83d\udcc2 Download layer\n4.2 Tree-covered and intact forest landscapes\nBased on the UNEP historic forest cover map, ESA land cover time series and\nintact forest landscape (IFL 2000, 2013 and 2016) data (Potapov et al. 2013).\nOnly two classes are considered: (1) intact forest areas, and (2) tree-covered areas. See processing steps.\nldg_forest.cover_esacci.ifl_c_250m_s0..0cm_*_v0.1.tif\n\n\ud83d\udcc2 Download layer\nThe intact forest landscapes is a project supported by University of Maryland, Greenpeace, World Resources Institute, and Transparent World.\n4.3 Landscape degradation degree\nBased on the comparison of land cover changes in a 9 km search radius (Nowosad et al., 2018).\nldg_landscape.degradation_sil.9km_c_250m_s0..0cm_1992..2015_v1.0.tif\n\n\ud83d\udcc2 Download layer\nProduced by Space Informatics Lab, University of Cincinnati.\nClimatic layers\nClimatic layers are available only at resolution of 1 km or 500 m.\nLong-term Land Surface Temperature was derived from the MODIS MOD11A2\nLand Surface Temperature (LST) images 2000\u20132017 using the data.table package and quantile function in R.\nSee processing steps.\nMODIS land products are property of Land Processes Distributed Active Archive Center, U.S. Geological Survey.\n5.1 Long-term Land Surface Temperature daytime monthly mean\nBased on the MODIS MOD11A2 Land Surface Temperature (LST) images 2000\u20132017.\nclm_lst_mod11a2.*.day_m_1km_s0..0cm_2000..2017_v1.0.tif\n\n\ud83d\udcc2 Download layer\n5.2 Long-term Land Surface Temperature daytime monthly sd\nBased on the MODIS MOD11A2 Land Surface Temperature (LST) images 2000\u20132017.\nclm_lst_mod11a2.*.day_sd_1km_s0..0cm_2000..2017_v1.0.tif\n\n\ud83d\udcc2 Download layer\n5.3 Long-term Land Surface Temperature monthly day-night difference\nBased on the MODIS MOD11A2 Land Surface Temperature (LST) images 2000\u20132017.\nclm_lst_mod11a2.*.daynight_m_1km_s0..0cm_2000..2017_v1.0.tif\n\n\ud83d\udcc2 Download layer\n5.4 Precipitation monthly in mm\nBased on the Global Precipitation Measurement Integrated Multi-satellitE Retrievals for GPM (IMERG) 2014\u20132018 and WorldClim v2 (Fick and Hijmans 2017), CHELSA climate (Karger et al. 2017) rainfall monthly images.\nclm_precipitation_imerge.*_m_1km_s0..0cm_2014..2018_v1.0.tif\n\n\ud83d\udcc2 Download layer\nGlobal Precipitation Measurement Integrated Multi-satellitE Retrievals for GPM (IMERG) is provided by NASA Goddard Space Flight Center.\n5.5 Snow probability monthly\nBased on the CCI Land Cover dataset \/ MOD10A2 product at 500 m for the period 2000\u20132012.\nclm_snow.prob_esacci.*_p_1km_s0..0cm_2000..2016_v1.0.tif\n\n\ud83d\udcc2 Download layer\nSoil properties and classes\nFor mapping soil properties and classes we use a compilation of published point data\ncoming from various national and international soil point data providers.\nThe most important sources of training points include:\n\nUSDA National Cooperative Soil Characterization Database,\nAfrica Soil Profiles Database,\nLUCAS Soil database,\nReposit\u00f3rio Brasileiro Livre para Dados Abertos do Solo (FEBR),\nSistema de Informaci\u00f3n de Suelos de Latinoam\u00e9rica y el Caribe (SISLAC),\nThe Northern Circumpolar Soil Carbon Database (NCSCD),\nDokuchaev Soil Science Institute \/ Ministry of Agriculture of Russia (soil profiles for Russia),\nWHRC global mangrove soil carbon dataset,\nLocal data sets such as Silva et al. (2019),\n\nAdditional points, if not available through these databases, have been also imported from the WoSIS Soil Profile Database (Batjes et al. 2017).\nPredictions are based on 3D Machine Learning ensemble models estimated using\nthe SuperLearner and caret packages. Predictive Soil Mapping steps and sample outputs are\ndescribed in detail in Hengl and MacMillan (2019).\nFor soil variable names we use consistently the National Cooperative Soil Characterization Database\ncolumn names and codes. For example:\nsol_bulkdens.fineearth_usda.4a1h_m_250m_b30..30cm_1950..2017_v0.2.tif\n\nrefers to the db_od column in the database and 4a1h laboratory method (bulk density oven-dry), as described in:\n\nLaboratory Methods Manual (SSIR 42) - NRCS - USDA,\nSoil Survey Field and Laboratory Methods Manual - NRCS - USDA\n\nContinuous 3D soil properties are predicted at 6 standard depths:\n\n0, 10, 30, 60, 100 and 200 cm\n\nand then aggregated to standard depth intervals (5):\n\n0\u201310, 10\u201330, 30\u201360, 60\u2013100 and 100\u2013200 cm\n\nStandard prediction errors (eithers as the prediction variance of prediction confidence limits)\nare provided for each soil property \/ depth. For example:\nsol_bulkdens.fineearth_usda.4a1h_md_250m_b30..30cm_1950..2017_v0.2.tif\n\ncontains standard deviation of the ensemble models (independent prediction variance). The md provides only an estimate of the prediction error and currently can not be used to derive prediction intervals.\nData import, overlay and model fitting to produce predictions of soil properties and classes are\nexplained in detail here. Principles of Predictive Soil Mapping are outlined in detail in the PSMwR book.\n\nImage: General workflow for generation of soil properties and classes using Machine Learning.\nSeveral improvements have been implemented to spatial prediction of soil properties and classes (in comparison to Hengl et al. 2017, and Sanderman et al. 2017):\n\n\nNew RS-based layers have been added to the list of covariates including Copernicus FAPAR time series of images,\nMERIT DEM multiscale DEM derivatives, ALOS radar images, MODIST LST aggregates and IMERGE precipitation images,\n\n\nSelection of the ensemble model is now run via the SuperLearner package framework, which allows for incorporating spatial subsetting in the Cross-Validation of models,\n\n\nAn estimate of the prediction uncertainty \/ error is provided via the ensemble model standard deviation,\n\n\nSoil type maps are now based on over 360,000 training points (compare with ca 70,000 in the previous run),\n\n\nFor each point quality flag (completeness) is used as case.weights in the training process,\n\n\nArtifacts \/ extrapolation problems, especially in the soil carbon maps, are now dealt with by using the most up-to-date (ESA) land cover map,\n\n\nTo use these soil maps in combination with local data (e.g. to produce ensemble or finer resolution maps for local areas),\nconsider following some of these approaches:\n\nManon, C., Dobarco, M.R, Arrouays, D., Minasny, B. and N.P.A. Saby. (2019). \u201cMerging Country, Continental and Global Predictions of Soil Texture: Lessons from Ensemble Modelling in France.\u201d Geoderma 337: 99\u2013110. https:\/\/dx.doi.org\/10.1016\/j.geoderma.2018.09.007.\nRamcharan, A., Hengl, T., Nauman, T., Brungard, C., Waltman, S., Wills, S., & Thompson, J. (2018). \u201cSoil Property and Class Maps of the Conterminous United States at 100-Meter Spatial Resolution.\u201d Soil Science Society of America Journal, 82(1), 186-201. https:\/\/dl.sciencesocieties.org\/publications\/sssaj\/abstracts\/82\/1\/186\n\n6.1 USDA soil taxonomy great groups\nPredicted distribution based on machine learning predictions (random forest) from global compilation of soil profiles.\nsol_grtgroup_usda.soiltax_c_250m_s0..0cm_1950..2017_v0.1.tif\n\n\ud83d\udcc2 Download layer\n\u2139\ufe0f Classes\nUSDA great groups are explained in detail in:\n\nIllustrated Guide to Soil Taxonomy - NRCS - USDA,\nUSDA: Soil Formation and Classification,\n\nMore detailed soil class maps of USA can be found in Ramcharan et al. (2018).\n\nImage: Example of a general workflow of how LandGIS can be used to recommend optimal soil use practices at farm scale based on accurately predicting the soil type (in this case USDA great group).\n6.2 Hapludalfs\nExample of predicted distribution of the \u201chapludalfs\u201d: soils with argillic (clay accumulation) subsoil horizon.\nsol_grtgroup_usda.soiltax.hapludalfs_p_250m_s0..0cm_1950..2017_v0.2.tif\n\n\ud83d\udcc2 Download layer\n6.3 Soil organic carbon content in x 5 g \/ kg\nBased on machine learning predictions from global compilation of soil profiles and samples.\nTo convert to % divide by 2.\nsol_organic.carbon_usda.6a1c_m_250m_b*..*cm_1950..2017_v0.2.tif\n\n\ud83d\udcc2 Download layer\n6.4 Bulk density in x 10 kg\/m3\nBased on machine learning predictions from global compilation of soil profiles and samples.\nsol_bulkdens.fineearth_usda.4a1h_m_250m_b*..*cm_1950..2017_v0.2.tif\n\n\ud83d\udcc2 Download layer\n6.5 Clay content in %\nBased on machine learning predictions from global compilation of soil profiles and samples.\nsol_clay.wfraction_usda.3a1a1a_m_250m_b*..*cm_1950..2017_v0.2.tif\n\n\ud83d\udcc2 Download layer\n6.6 Sand content in %\nBased on machine learning predictions from global compilation of soil profiles and samples.\nsol_sand.wfraction_usda.3a1a1a_m_250m_b*..*cm_1950..2017_v0.2.tif\n\n\ud83d\udcc2 Download layer\n6.7 Soil texture class (USDA system)\nDerived using the predicted clay, silt and sand content images and the soiltexture R package.\nsol_texture.class_usda.tt_m_250m_b*..*cm_1950..2017_v0.2.tif\n\n\ud83d\udcc2 Download layer\n\u2139\ufe0f Classes\n6.8 Soil pH in H2O\nBased on machine learning predictions from global compilation of soil profiles and samples.\nsol_ph.h2o_usda.4c1a2a_m_250m_b*..*cm_1950..2017_v0.2.tif\n\n\ud83d\udcc2 Download layer\n6.9 Soil water content at 33kPa (field capacity)\nBased on machine learning predictions from global compilation of soil profiles and samples.\nTraining points are based on a global compilation of soil profiles\n(USDA NCSS, AfSPDB, ISRIC WISE, EGRPR, SPADE, CanNPDB, UNSODA, SWIG, HYBRAS and HydroS).\nData import steps are available here. Spatial prediction steps are described in detail here.\nsol_watercontent.33kPa_usda.4b1c_m_250m_b*..*cm_1950..2017_v0.1.tif\n\n\ud83d\udcc2 Download layer\nPotential Natural Vegetation\n7.1 Potential distribution of biomes\nPotential Natural Vegetation biomes global predictions of classes (based on the BIOMES 6000 data set).\nProcessing steps and generation of predictions is explained in detail in Hengl et al. (2018).\npnv_biome.type_biome00k_c_1km_s0..0cm_2000..2017_v0.1.tif\n\n\ud83d\udcc2 Download layer\n\u2139\ufe0f Classes\n7.2 Potential FAPAR monthly\nPotential Natural Vegetation FAPAR predicted monthly median (based on PROB-V FAPAR 2014\u20132017).\npnv_fapar_proba.v.***_d_1km_s0..0cm_2014..2017_v0.1.tif\n\n\ud83d\udcc2 Download layer\n\u2139\ufe0f Classes\n7.3 Difference potential vs actual FAPAR monthly\nDerived as a difference between the predicted potential and actual Copernicus FAPAR 2014\u20132017.\npnv_fapar_proba.v.annualdiff_d_1km_s0..0cm_2014..2017_v0.1.tif\n\n\ud83d\udcc2 Download layer\nHydrology and water dynamics\n8.1 FLO1K mean annual streamflow 1960\u20132015\nFLO1K mean annual streamflow in m3 \/ sec 1960\u20132015 derived at 1 km resolution\nusing data from 1960 through 2015.\nhyd_ann.streamflow_flo1k.mean_m_1km_s0..0cm_*_v1.0.tif\n\n\ud83d\udcc2 Download layer\n8.2 FLO1K maximum annual streamflow 1960\u20132015\nFLO1K maximum annual streamflow in m3 \/ sec 1960\u20132015 derived at 1 km resolution\nusing data from 1960 through 2015.\nhyd_ann.streamflow_flo1k.max_m_1km_s0..0cm_*_v1.0.tif\n\n\ud83d\udcc2 Download layer\n8.3 FLO1K minimum annual streamflow 1960\u20132015\nFLO1K minimum annual streamflow in m3 \/ sec 1960\u20132015 derived at 1 km resolution\nusing data from 1960 through 2015.\nhyd_ann.streamflow_flo1k.min_m_1km_s0..0cm_*_v1.0.tif\n\n\ud83d\udcc2 Download layer\nReferences\n\n\nAmatulli G, McInerney D, Sethi T, Strobl P, Domisch S. (2019).\nGeomorpho90m - Global high-resolution geomorphometry layers: empirical evaluation and accuracy assessment.\nPeerJ Preprints 7:e27595v1 https:\/\/doi.org\/10.7287\/peerj.preprints.27595v1\n\n\nBarbarossa, V., Huijbregts, M. A., Beusen, A. H., Beck, H. E., King, H., & Schipper, A. M. (2018).\nFLO1K, global maps of mean, maximum and minimum annual streamflow at 1 km resolution from 1960 through 2015. Scientific data, 5, 180052. https:\/\/doi.org\/10.1038\/sdata.2018.52\n\n\nBatjes N.H., Ribeiro E., van Oostrum A., Leenaars J., Hengl T., and Mendes de Jesus J. (2017).\nWoSIS \u2014 Providing standardised soil profile data for the world,\nEarth System Science Data 9, 1-14, https:\/\/doi.org\/10.5194\/essd-9-1-2017\n\n\nFick, S. E., & Hijmans, R. J. (2017). WorldClim 2: new 1\u2010km spatial resolution climate surfaces for global land areas.\nInternational Journal of Climatology, 37(12), 4302-4315. https:\/\/doi.org\/10.1002\/joc.5086\n\n\nHartmann, J., & Moosdorf, N. (2012). The new global lithological map database GLiM:\nA representation of rock properties at the Earth surface.\nGeochemistry, Geophysics, Geosystems, 13(12). https:\/\/doi.org\/10.1029\/2012GC004370\n\n\nHengl, T., MacMillan, R.A., (2019). Predictive Soil Mapping with R.\nOpenGeoHub foundation, Wageningen, the Netherlands, 340 pages. ISBN: 978-0-359-30635-0.\n\n\nHengl T., Walsh M.G., Sanderman J., Wheeler I., Harrison S.P., Prentice I.C. (2018)\nGlobal mapping of potential natural vegetation: an assessment of machine learning algorithms for estimating land potential. PeerJ 6:e5457\nhttps:\/\/doi.org\/10.7717\/peerj.5457\n\n\nHengl, T., de Jesus, J.M., Heuvelink, G.B., Gonzalez, M.R.,\nKilibarda, M., Blagoti\u0107, A., Shangguan, W., Wright, M.N., Geng,\nX., Bauer-Marschallinger, B. and Guevara, M.A., (2017).\nSoilGrids250m: Global gridded soil information based on machine learning.\nPLoS one, 12(2), p.e0169748. https:\/\/doi.org\/10.1371\/journal.pone.0169748\n\n\nKarger, D. N., Conrad, O., B\u00f6hner, J., Kawohl, T., Kreft, H., Soria-Auza, R. W., ... & Kessler, M. (2017).\nClimatologies at high resolution for the earth\u2019s land surface areas.\nScientific data, 4, 170122. https:\/\/doi.org\/10.1038\/sdata.2017.122\n\n\nKlein Goldewijk, K., Beusen, A., Doelman, J., Stehfest, E. (2017).\nAnthropogenic land-use estimates for the holocene - hyde 3.2.\nEarth Syst. Sci. Data, 9, 927-953. https:\/\/doi.org\/10.5194\/essd-9-927-2017\n\n\nBauer-Marschallinger, B., Sabel, D., & Wagner, W. (2014).\nOptimisation of global grids for high-resolution remote sensing data.\nComputers & Geosciences, 72, 84-93. https:\/\/doi.org\/10.1016\/j.cageo.2014.07.005\n\n\nPekel, J. F., Cottam, A., Gorelick, N., & Belward, A. S. (2016).\nHigh-resolution mapping of global surface water and its long-term changes.\nNature, 540(7633), 418. http:\/\/dx.doi.org\/10.1038\/nature20584\n\n\nPotapov, P., Hansen, M. C., Laestadius, L., Turubanova, S., Yaroshenko, A. et al. (2013).\nThe last frontiers of wilderness: Tracking loss of intact forest landscapes from 2000 to 2013.\nScience Advances, 2017; 3:e1600821 https:\/\/dx.doi.org\/10.1126\/sciadv.1600821\n\n\nRamcharan, A., Hengl, T., Nauman, T., Brungard, C., Waltman, S., Wills, S., & Thompson, J. (2018).\nSoil Property and Class Maps of the Conterminous United States at 100-Meter Spatial Resolution.\nSoil Science Society of America Journal, 82(1), 186-201. https:\/\/dl.sciencesocieties.org\/publications\/sssaj\/abstracts\/82\/1\/186\n\n\nSamuel-Rosa, A., Dalmolin, R., Gubiani, P., Teixeira, W., Olivieira, S. D. M., Viana, J., ... & Ottoni, M. (2018).\nBringing together brazilian soil scientists to share soil data. In Embrapa Solos-Artigo em anais de congresso (ALICE).\nIn: REUNI\u00c3O SUL BRASILEIRA DE CI\u00caNCIA DO SOLO, 12., 2018, Xanxer\u00ea. Solo, \u00e1gua, ar e biodiversidade:\ncomponentes essenciais para a vida: anais. Chapec\u00f3: Argos, 2018.\n\n\nSanderman, J., Hengl, T., Fiske, G., (2017). The soil carbon debt of 12,000 years of human land use.\nPNAS, https:\/\/dx.doi.org\/10.1073\/pnas.1706103114\n\n\nSayre, R., Dangermond, J., Frye, C., Vaughan, R., Aniello, P., Breyer, S., ... & Wright, D. (2014).\nA new map of global ecological land units\u2014an ecophysiographic stratification approach.\nWashington, DC: Association of American Geographers.\n\n\nSilva, B. P. C., Silva, M. L. N., Avalos, F. A. P., de Menezes, M. D., & Curi, N. (2019).\nDigital soil mapping including additional point sampling in Posses ecosystem services pilot watershed, southeastern Brazil. Scientific reports, 9(1), 1-12.\n\n\nYamazaki, D., Ikeshima, D., Tawatari, R., Yamaguchi, T., O'Loughlin,\nF., Neal, J.C., Sampson, C.C., Kanae, S. and Bates, P.D., (2017)\nA high\u2010accuracy map of global terrain elevations. Geophysical\nResearch Letters, 44(11), pp.5844-5853. https:\/\/doi.org\/10.1002\/2017GL072874\n\n\n","24":"Environmental Data Abstraction Layer (EDAL)\n\n\nDocumentation\nSource code\nIssues\nCHANGELOG\n\nThe EDAL project comprises a set of libraries to deal with the manipulation and visualisation of environmental data.  They were originally created as part of ncWMS but are standalone libraries which ncWMS uses.\nEDAL consists of a number of modules, each focused on a different task.  These modules are outlined below\nEDAL Modules\nEDAL Common\nThe edal-common module contains the core data model used in EDAL, as well as in-memory implementations of this data model, common utility methods, and exceptions.\nEDAL Graphics\nThe edal-graphics module contains code for generating images from the core EDAL data types.  This includes map images, as well as timeseries, vertical profile, and vertical section charts.  Additionally there are custom SLD (Styled Layer Descriptor) handlers to allow for the precise specification of how to assemble a map image, allowing arbitrarily complex plotting of multiple simultaneous data layers.\nThis module depends on the edal-common module.\nEDAL CDM\nThe edal-cdm module uses the Unidata NetCDF-Java libraries to read data into the core EDAL data model.  It reads CF-compliant gridded NetCDF files as well as OPeNDAP, GRIB, and several other formats (see http:\/\/www.unidata.ucar.edu\/software\/thredds\/current\/netcdf-java\/reference\/formats\/FileTypes.html for a list).  It also includes a data reader capable of reading the UK Met Office EN3\/4 in-situ datasets (http:\/\/www.metoffice.gov.uk\/hadobs\/en3\/ and http:\/\/www.metoffice.gov.uk\/hadobs\/en4\/).\nThis modules depends on the edal-common module.\nEDAL WMS\nThe edal-wms module contains an implementation of the WMS (Web Map Service) standard with a number of custom requests suited to exposing environmental data over the web.  This module is not a complete packaged WMS - it supplies all of the required servlet classes, but requires a data catalogue to be implemented to map WMS layer names to the EDAL data objects.\nThis module depends on the edal-common module and the edal-graphics module\nEDAL XML Catalogue\nThe edal-xml-catalogue module contains an implementation of a data catalogue in an XML format. This allows configuration of a set of datasets through XML for provision to the graphics module.\nThis module depends on the edal-common module and the edal-graphics module\nGodiva 3\nThe edal-godiva module is a Google Web Toolkit (GWT) based WMS client.  It supports all of the extended WMS requests supplied by the edal-wms module.\nThis module does not depend on any others.\nEDAL was developed primarily to factor out common functionality from the original ncWMS (http:\/\/sourceforge.net\/projects\/ncwms\/)\nCaching of datasets\nCaching of datasets to improve performance is implemented using Ehcache.\nTwo distinct caches are included in EDAL:\n\nA cache for datasets \"featureCache\"\nA cache for maps \"meshDatasetCache\"\n\nWhen using ncWMS2 another cache is available:\n\nA cache for dynamic datasets  \"dynamicCache\"\n\nConfiguration for the caches can be configured using ehcache.xml which can be specified at run-time with the JVM parameter '-Dehcache.config=\"\/path\/to\/ehcache.xml\"'.\nThe default configuration is specified in \/common\/src\/main\/resources\/ehcache.xml.\nThe Ehcache cache can be distributed using Terracotta by specifying the parameters in ehcache.xml.\nAn example file is provided in \/common\/src\/main\/resources\/ehcache.terracotta.xml.\nLicence\nCopyright (c) 2010 The University of Reading\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions\nare met:\n1. Redistributions of source code must retain the above copyright\n   notice, this list of conditions and the following disclaimer.\n2. Redistributions in binary form must reproduce the above copyright\n   notice, this list of conditions and the following disclaimer in the\n   documentation and\/or other materials provided with the distribution.\n3. Neither the name of the University of Reading, nor the names of the\n   authors or contributors may be used to endorse or promote products\n   derived from this software without specific prior written permission.\n4. If you wish to use, with or without modification, the Godiva web\n   interface, the logo of the Reading e-Science Centre must be retained\n   on the web page.\n\nTHIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\nIMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\nOF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\nIN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\nINCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\nNOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\nTHIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nAuthors and Contributors\nThe EDAL libraries are developed by the Reading e-Science Centre and are maintained by @guygriffiths.\nContributors:\n\n@yosoyjay\n@kwilcox\n\n","25":"Candidate specification for the Environmental Data Retrieval API\n\nThis is the GitHub repository of the OGC Environmental Data Retrieval API Standard Working Group (EDR API SWG).\nThe OGC API - Environmental Data Retrieval candidate standard is part of the OGC API suite of standards. OGC API standards define modular API building blocks to spatially enable Web APIs in a consistent way. OpenAPI is used to define the reusable API building blocks.\nThe public comment period on the EDR API closed September 28th. Go here for more information.\nA public Hackathon\/Sprint was held virtually in March 2020 and another will be held 9-10 November 2020 to help finalise the specification. There was a public Webinar outlining the Sprint's objectives on Wednesday 4 November 2020.\nThe repository contains:\n\nWorking Group Charter\nStandard document, as a work-in-progress draft.\nBest Practice document, as a work-in-progress draft\n\nIt will also contain the plan of work and links to other relevant documents such as minutes, actions and notes of meetings on the associated Wiki pages.\nDraft Spec\nThe latest draft of the standard in this repository is built daily (based on the configuration contained in the asciidoctor.json file):\n\nOGC API - Environmental Data Retrieval Standard\nDRAFT EDR OpenAPI Document\n\nBest Practice\n\nOGC API - Environmental Data Retrieval Best Practice\n\nEDR API Vision\nThe EDR API can be considered a 'Sampling API'. EDR queries create discrete sampling geometries that can sample a relatively persistent data store resource. The query and its response are transient resources, which can be made persistent for re-use if required. EDR is agnostic to whether the data store is a digital data cube that could be sampled anywhere or pre-existing samples of, or a model of, real world phenomena. While the former is the emphasis, EDR APIs can provide a list of pre-defined or pre-existing monitoring\/modeled \"locations\" which can be accessed by location identifier. There is an assumption that the data store is non-sparse, in that most queries are expected to return useful values rather than 'data not found'.\nEDR API Query Patterns\nThe EDR API Standard Working Group charter lists initial deliverables in section 4.1 and a number of additional tasks in section 4.2. There is also an \"out of scope\" statement in section 3.2.\nSummarizing these sections. EDR Query Patterns will be:\n\n\n1 - Position: Retrieve data for point\/position or identified location with n parameters at a time instant, or a timeseries, or a vertical profile for a time instant.\n\n\n2 - Area:  Retrieve data within a polygon or rectangular tile\/subset at a time instant, or a timeseries, or a vertical profile for a time instant.\n\n\n3 - Trajectory and Corridor: Retrieve data along a 2D, 3D or 4D trajectory or within a defined corridor around a trajectory.\n\n\n4 - Ensembles: Support for explicitly related ensembles of EDR resources. [Note: This will be in a later version]\n\n\nThese patterns would be accessed through endpoints like:\n\/collections\/{collectionID}\/{queryType}?\n  coords={wkt-geometry}&\n  parametername={parameter_1},{parameter_n}&\n  datetime={RFC3339\/ISO8601}&\n  f={format}&\n  {queryType-specific-parameter_n_}={queryType-specific-paramete_n_value}\n\nContributing\nThe contributor understands that any contributions, if accepted by the OGC Membership, shall be incorporated into OGC standards documents and that all copyright and intellectual property shall be vested to the OGC.\nPull Requests from contributors are welcomed. However, please note that by sending a Pull Request or Commit to this GitHub repository, you are agreeing to the terms in the Observer Agreement https:\/\/portal.ogc.org\/files\/?artifact_id=92169\n","26":"Environmental_Data_Analytics\nData analytics course for Duke University. Course code: ENV 872L\nUser: Kateri Salk\nInstructions for using this repository:\n\nFork this repository into your own GitHub account.\nClone your forked repository onto your local drive.\nTo pull updates from this repository, add this repository as an upstream remote:\n\ngit remote add upstream https:\/\/github.com\/KateriSalk\/Environmental_Data_Analytics\n\nTo verify that this repository is the upstream remote:\n\ngit remote -v\nYour own repository should be listed as \"origin\" and this repository should be listed as \"upstream.\"\n\nTo pull updates from this repository:\n\ngit pull upstream master\nOR\ngit fetch upstream\ngit merge upstream\/master\n\nIf a conflict arises during merge, update the file(s) to your liking, stage them and commit them.\n\ntesting merge error with Taylor\n","27":"Environmental_Data_Analytics\nData analytics course for Duke University. Course code: ENV 872L\nUser: Kateri Salk\nInstructions for using this repository:\n\nFork this repository into your own GitHub account.\nClone your forked repository onto your local drive.\nTo pull updates from this repository, add this repository as an upstream remote:\n\ngit remote add upstream https:\/\/github.com\/KateriSalk\/Environmental_Data_Analytics\n\nTo verify that this repository is the upstream remote:\n\ngit remote -v\nYour own repository should be listed as \"origin\" and this repository should be listed as \"upstream.\"\n\nTo pull updates from this repository:\n\ngit pull upstream master\nOR\ngit fetch upstream\ngit merge upstream\/master\n\nIf a conflict arises during merge, update the file(s) to your liking, stage them and commit them.\n\ntesting merge error with Taylor\n","28":"India Rainfall Analysis\nMotivation and Description\nMonsoon prediction is clearly of great importance for India.Two types of rainfall predictions\ncan be done, They are\n\nLong term predictions: Predict rainfall over few weeks\/months in advance.\nShort term predictions: Predict rainfall a few days in advance in specific locations.\n\nIndian meteorological department provides forecasting data required for project. \n    In this project we are planning to work on long term predictions of rainfall. \n    The main motive of the project is to predict the amount of rainfall in a particular division or state well in advance. \n    We predict the amount of rainfall using past data.\nDataset\n\nDataset1(dataset1)\nThis dataset has average rainfall from 1951-2000 for each district, for every month.\nDataset2(dataset2)\nThis dataset has average rainfall for every year from 1901-2015 for each state.\n\nMethodology\n\nConverting data in to the correct format to conduct experiments.\nMake a good analysis of data and observe variation in the patterns of rainfall.\nFinally, we try to predict the average rainfall by separating data into training and\ntesting. We apply various statistical and machine learning approaches(SVM,\netc) in prediction and make analysis over various approaches. By using various\napproaches we try to minimize the error.\n\n","29":"Reproducible Research in Ecology, Evolution, Behaviour, and Environmental Studies\nAims\n\n\nReproduce the figures, tables, statistical methods, and numerical\nmodelling of selected published papers (examples here).\n\n\nLearn, collaborate, and create about science.\n\n\nMake our reproductions publically available.\n\n\nLearn how to make our own research reproducible.\n\n\nPaper selection\nWe will likely spend a lot of time on any single paper, so their\nselection is very important. Please make suggestions here. Raw data must be available. Reproduction should appear feasible in a\ncouple of months (eight meetings) at most. Probably good to focus on papers with mostly analyses of empirical data (rather than lots of numerical modelling).\nPlease email authors of a paper when we start the reproduction, telling them what we're up to.\nReproduction guidelines\nReproductions will be in R markdown, and should be generously commented.\nWe will use the google R style guide.\nData manipulations allowed only in R (and other open source software, if\nrequired) are permitted. No alteration of original data files allowed.\nOutcome\n\n\nA fully reproduced paper would be one that can be reproduced from\nthe raw datasets, which should ideally be available online here.\n\n\nAn online report of our reproduction, with code.\n\n\nOutstanding issues.\n\n\nResearch ideas.\n\n\nParts of the paper we decided to not reproduce and why.\n\n\nWeekly meetings\nInformation here.\nRemote participation\nIndividuals might like to contribute to a reproduction outside the meeting time, or may not be able to attend the meetings. Anyone can read and contribute to the reproduction on github (look here for instructions about how to; if you do not know what git and Github are, please look at these resources to get you started). For particularly motivated folk that cannot attend the weekly meetings, we may arrange electronic attendance of the weekly meetings, e.g., via skype.\nCommunication\nPlease use the RREEBES github repository Issues and Wiki for as much communication as possible. There will be no email list.\nGaining 1 ECTS\nStudents at UZH can gain 1 ECTS for actively participating in the reproduction of two papers and attending at least 20 meetings. Please make an attendance form and bring it to each meeting. This course is BIO633. See more in the Vorlesungsverzeichnis entry.\n","30":"Environmental Sound Classification with Convolutional Neural Networks - paper replication data\n\nAbstract:\n\nThis paper evaluates the potential of convolutional neural networks in classifying short audio clips of environmental sounds. A deep model consisting of 2 convolutional layers with max-pooling and 2 fully connected layers is trained on a low level representation of audio data (segmented spectrograms) with deltas. The accuracy of the network is evaluated on 3 public datasets of environmental and urban recordings. The model outperforms baseline implementations relying on mel-frequency cepstral coefficients and achieves results comparable to other state-of-the-art approaches.\n\nPaper:\n\nAuthor version of the paper: Environmental Sound Classification with Convolutional Neural Networks.\n\nCiting:\n\nK. J. Piczak. Environmental Sound Classification with Convolutional Neural Networks. In Proceedings of the IEEE 25th International Workshop on Machine Learning for Signal Processing (MLSP), pp. 1-6, IEEE, 2015.\n\nSupplementary materials:\n\nPoster slides:\n\n\n\nRelated work:\n\nESC: Dataset for Environmental Sound Classification \n\n","31":"\n\nEdit this ontology!\nTBD\nEnvironmental conditions, treatments and exposures ontology (ECTO)\nThe purpose of this ontology is to create compositional classes that\nassemble existing OBO ontologies such as ExO, CHEBI and ENVO to make\nready-made precomposed classes for use in describing:\n\nexperimental treatments of plants and model organisms (e.g. modification of diet, lighting levels, temperature)\nexposures of humans or any other organisms to stressors through a variety of routes, for purposes of public health, environmental monitoring etc\nstimuli, natural and experimental\nany kind of environmental condition or change in condition that can be experienced by an organism or population of organisms on earth\n\nThe scope is very general and can include for example plant treatment regimens, as well as human clinical exposures (although these may better be handled by a more specialized ontology)\nAn example of a class (in manchester syntax) is:\nClass: ECTO:0000977\n Annotations: rdfs:label \"exposure to ultrafine respirable suspended particulate matter via inhalation\"\n Annotations: IAO:0000115 \"A exposure event involving the interaction of an exposure receptor to ultrafine respirable suspended particulate matter via inhalation.\"\n Annotations: oio:hasExactSynonym \"ultrafine respirable suspended particulate matter exposure, via inhalation\"\n EquivalentTo: ExO:0000002 and RO:0002233 some ENVO:01000416 and BFO_0000050 some ExO:0000057 ## 'exposure event' and 'has input' some ultrafine respirable suspended particulate matter and 'part of' some inhalation\n\nQuick Start\nThere is no public browser yet. Use one of the following files:\n\nsubsets\/ecto-basic.obo - for OBO-Edit users\necto.owl - open in Protege5\n\nNote to open the OWL in Protege you will need to check out the repo so\nthat the catalog can be used.\nRelationships to other ontologies\nOntologies used in composition (largely orthogonal):\n\nExposure Ontology (ExO) - used as the upper ontology, for based classes such as 'exposure', different routes such as 'ingestion'\nChemical Entities of Biological Interest (CHEBI) - use for both entities and roles\nEnvironment Ontology (ENVO) - environmental materials, processes\nNanoParticle Ontology (NPO) - radiation\nRelations Ontology (RO) - relations\nPhenotypic Quality Ontology (PATO) - qualities\nUBERON Anatomy Ontology - tissue types (not used yet)\nNCI Thesaurus (NCIT) - activities such as smoking\nSustainable Development Goals Interface Ontology (SDGIO) - social entities\nPopulation and Community Ontology (PCO) - population attributes (e.g. overcrowding)\n\nSimilar ontologies (overlapping\/non-orthogonal)\n\nZebrafish Experimental Conditions Ontology (ZECO) - zebrafish-specific conditions\nS Pombe Experimental Conditions Ontology (SPECO) - pombase-specific conditions\nPlant Environment Conditions Ontology (PECO) - plant-specific environmental conditions and treatments\nGene Ontology (GO) - subset shadows many classes here eg. gene expression in response to X\nSNOMED - has an exposure subset, but closed\nNCI Thesaurus (NCIT) - very broad, but contains some exposure terms.\nExperimental Conditions Ontology (XCO) - experimental conditions (mammal-centric? rat in particular)\nWikidata - subclasses of hazard (wikidata:Q1132455)[https:\/\/www.wikidata.org\/wiki\/Q1132455]\n\nSee below for the merge experiment with these ontologies.\nWe aim to reuse existing open ontologies as far as possible; for orthogonal ontologies, this is via axiomatization.\nNote on ENVO: it may seem that ENVO is an overlapping\/non-orthogonal ontology, but following our design patterns here this should be considered orthogonal; analogous to the relationship between an anatomical ontology and a variant\/aberrant phenotype ontology.\nAnother new ontology to note is the UNEP Sustainable Development Goals ontology -- https:\/\/github.com\/SDG-InterfaceOntology\/sdgio\/ -- this is being built in a modular fashion using ENVO and is seeding the creation of many useful social classes we will need, e.g. poverty, access to resources, etc.\nReleases\nRelease files are in top level\n\nobo\nowl\n\nNote: these are only for testing so far, not stable! These should not be considered real releases.\nThe proposed ID space is very tentative\nModeling\nThe model we are using is aligned with the environmental conditions\nmodel in PhenoPackets. We attempt to follow ExO where possible.\nWe treat exposures as events; in ontological terms, they are types of\noccurrents. Specifically, they are interactions between a receptor\n(typically an organism, but could be a population of organisms) and a\nstressor (an agent or process that has a potential effect on the\nreceptor). The stressor may interact with the organism through some\nkind of environmental medium (e.g. air, water, soil), and may enter\nvia some route (e.g. permeating the skin or analogous barrier).\nIn some cases the route may be indirect: passive smoking or drug use\nby a mother during pregnancy.\nThis model permits a variety of pre-composed classes. We defined and\ngenerate these using Dead Simple OWL Design Patterns (DOSDPs)\nSee src\/patterns for the list of patterns in use.\nThe basic idea is that a term like 'increased exposure to arsenic\nthrough ingestion\/diet' can be composed using classes from ontologies\nsuch as ExO and CHEBI. We can see this as filling in slots in our\ndatamodel.\nAnnotation Guide\nBroadly speaking, this ontology is designed to support both pre and\npost composed use cases.\nWith the pre-composed approach, the curator uses a \"ready-made\" ECTO\nclass expressing the combination of values required for different\nslots.\nWith the post-composed approach, ECTO can largely be disposed of, and\ninstead the description is assembled by the curator by filling in the\nrequired slots like 'stressor'.\nThe two approaches are compatible. Post-composed descriptions can be\nautomatically classified against the pre-composed ECTO. Similarly any\ndescription that uses ECTO can be unwound (or 'unfolded') to a\npre-composed description, using the OWL equivalence axioms in the\nontology.\nOntology Source\nMost of the ontology is stored as CSVs in src\/ontology\/modules\nSee the Makefile for how the ontology is compiled from CSV modules.\nSee the .omn files for a human-readable set of descriptions\nSee the README-editors.md file in the src\/ontology directory for\ninstructions on how to edit, maintain or release the ontology.\nMerge Experiment\nSee src\/mappings for an exploration of merging multiple exposure ontologies using kboom\nThe intent is not to use this ontology: rather to help gap fill and understand what is out there.\n","32":"Cordova Sensors Plugin\nThe sensors are capable of providing raw data with high precision and accuracy, and are useful if you want to monitor three-dimensional device movement or positioning, or you want to monitor changes in the ambient environment near a device. For example, a game might track readings from a device's gravity sensor to infer complex user gestures and motions, such as tilt, shake, rotation, or swing. Likewise, a weather application might use a device's temperature sensor and humidity sensor to calculate and report the dewpoint, or a travel application might use the geomagnetic field sensor and accelerometer to report a compass bearing.\nAt this moment this plugin is implemented only for Android!\nDemos\nSee in https:\/\/github.com\/fabiorogeriosj\/cordova-plugin-sensors-demo\nInstall\n$ cordova plugin add https:\/\/github.com\/fabiorogeriosj\/cordova-plugin-sensors.git\n\nMethods\nsensors.enableSensor(\"TYPE_SENSOR\")\nEnable sensor.\nsensors.disableSensor()\nDisable sensor.\nsensors.getState(successCallback, errorCallback)\nGet values sensor.\nUsing in Ionic\n  APP.controller(\"indexController\", function ($scope, $interval){\n\n      function onSuccess(values) {\n          $scope.state = values[0];\n      };\n      \n      function onError(error) {\n          throw error;\n      };\n\n      document.addEventListener(\"deviceready\", function () {\n        \n        sensors.enableSensor(\"PROXIMITY\");\n\n        $interval(function(){\n          sensors.getState(onSuccess, onError);\n        }, 100);\n\n\n      }, false);\n\n  });\nType sensors\nPROXIMITY - Measures the proximity of an object in cm relative to the view screen of a device.\nACCELEROMETER - Measures the acceleration force in m\/s2 that is applied to a device on all three physical axes (x, y, and z), including the force of gravity.\nGRAVITY - Measures the force of gravity in m\/s2 that is applied to a device on all three physical axes (x, y, z).\nGYROSCOPE - Measures a device's rate of rotation in rad\/s around each of the three physical axes (x, y, and z).\nGYROSCOPE_UNCALIBRATED - Rate of rotation (without drift compensation) around the x axis.\nLINEAR_ACCELERATION - Measures the acceleration force in m\/s2 that is applied to a device on all three physical axes (x, y, and z), excluding the force of gravity.\nROTATION_VECTOR - Measures the orientation of a device by providing the three elements of the device's rotation vector.\nSTEP_COUNTER - Number of steps taken by the user since the last reboot while the sensor was activated.\nGAME_ROTATION_VECTOR - Rotation vector component along the x axis (x * sin(\u03b8\/2)).\nGEOMAGNETIC_ROTATION_VECTOR - Rotation vector component along the x axis (x * sin(\u03b8\/2)).\nMAGNETIC_FIELD - Measures the ambient geomagnetic field for all three physical axes (x, y, z) in \u03bcT.\nMAGNETIC_FIELD_UNCALIBRATED - Geomagnetic field strength (without hard iron calibration) along the x axis.\nORIENTATION - Measures degrees of rotation that a device makes around all three physical axes (x, y, z).\nAMBIENT_TEMPERATURE - Measures the ambient room temperature in degrees Celsius (\u00b0C). See note below.\nLIGHT - Measures the ambient light level (illumination) in lx.\nPRESSURE - Measures the ambient air pressure in hPa or mbar.\nRELATIVE_HUMIDITY - Measures the relative ambient humidity in percent (%).\nTEMPERATURE - Measures the temperature of the device in degrees Celsius (\u00b0C).\nFor more information about sensors Android see Android Sensors Overview\n","33":"About NoiseCapture App\n\nNoiseCapture App is Android App dedicated to the measurement of environmental noise.\nDescription\nNoiseCapture App is an Android App project for measuring environmental noise using a smartphone. The goal is to produce relevant noise indicators from audio measurements, including a geospatial representation. Measurements can be shared with the community in order to produce participatory noise maps. NoiseCapture App is a component of a global infrastructure, i.e. a Spatial Data Infrastructure (SDI), called the OnoMap SDI, that allows to process and represent the geospatial information, like noise maps.\n\nA  full description of the whole OnoMap SDI, including the NoiseCapture App, is given in the wiki pages.\nAn user guide, for the use of the NoiseCapture App, is proposed within the NoiseCapture App (see the 'Help' page in the menu of NoiseCapture App).\n\nFeatures\nNoiseCapture App features are divided into 3 parts:\n\n\nMeasurement - Once the sound level calibration is done, the user start the measurement in order to record each second the LAeq, an average sound energy over a period of 1s. The spectrum repartition of the sound are analysed and stored using the Fourrier transform. The device location are recorded while measuring the sound level. The user has the hability to provide his own feedback about the feeling of the noise environment.\n\n\nExtented report - Advanced statistics are computed locally on the phone and shown to the user. For each user's measurement the locations of the noise levels are displayed in a map.\n\n\nShare results with the community - Anonymous results are transfered to Virtual Hubs (web server) and post-processed in order to build a noise map that merge all community results. Participative noise maps can be displayed within the NoiseCapture App, or online at https:\/\/onomap.noise-planet.org\/.\n\n\nDevelopments\nNoiseCapture App is a collaboration between the Environmental Acoustic Research unit (Ifsttar) and the Lab-STICC CNRS. If you need more information about the project developped by the Environmental Acoustic Research unit and the Lab-STICC, on this topic, go to http:\/\/www.noise-planet.org.\nFunding\nThis application was developed under the initial funding the European project ENERGIC-OD, with the help of the GEOPAL program.\nLicense\nNoiseCapture App is released under the GENERAL PUBLIC LICENSE Version 3. Please refer to GPLv3 for more details.\nFollow us\nFollow the developement of NoiseCapture App (and more...) on Twitter at @Noise_Planet\n\n","34":"Python for Environmental Science\nRepo for the Jupyter notebooks and code for a programming course at the Justus-Liebig-University Giessen. This course is meant to get students from not knowing how to program at all, to being able to use the pandas library to work with data and make good figures with matplotlib. I try to get the topics across in a universal way, so the skills taught are not restricted to environmental science. The title is meant to refer that this course covers things, that are useful when working in environmental science and is less about environmental science itself.\nThe intended way to teach this course is the following:\nThis is a reversed classroom course, which means that the students are meant to take a look at the notebook on the day before class, watch all the videos and at least read the practice questions. In the classroom the students and teacher discuss the practice questions and then the students do the exercises on their own, but can ask the teacher at any time to help them out. This way enables the students to get the most knowledge out of their teachers and also allows students to even do this course with no teacher at all (though it is probably quite helpful to have one).\nIf you want to contribute, I'd be happy to hear from you. The easiest way is to simply send me a pull request. If any questions arise, please contact me.\nIf you do not have a Python distribution on your computer already, I can recommend WinPython, but the course is also doable with other ones.\nThis course is based on Jupyter Notebooks; if you do not know how to use them, take a look here.\n","35":"Open Simulation Interface (OSI)\n\nThe Open Simulation Interface [1] (OSI) is a generic interface based on Google's protocol buffers for the environmental perception of automated driving functions in virtual scenarios.\nAs the complexity of automated driving functions rapidly increases, the requirements for test and development methods are growing. Testing in virtual environments offers the advantage of completely controlled and reproducible environment conditions.\nIn this context, OSI defines generic interfaces to ensure modularity, integrability, and interchangeability of the individual components:\n\nFor more information on OSI see the official documentation or the official reference documentation for defined protobuf messages.\n[1] Hanke, T., Hirsenkorn, N., van-Driesten, C., Garcia-Ramos, P., Schiementz, M., Schneider, S. & Biebl, E. (2017, February 03). A generic interface for the environment perception of automated driving functions in virtual scenarios. Retrieved January 25, 2020, from https:\/\/www.hot.ei.tum.de\/forschung\/automotive-veroeffentlichungen\/\nUsage\nExample of writing and reading an OSI message in Python\nfrom osi3.osi_sensorview_pb2 import SensorView\nfrom osi3.osi_sensordata_pb2 import SensorData\n\ndef main():\n    \"\"\"Initialize SensorView and SensorData\"\"\"\n    sensorview = SensorView()\n    sensordata = SensorData()\n\n    \"\"\"Clear SensorData\"\"\"\n    sensordata.Clear()\n\n    \"\"\"Get boundary line attributes from SensorView\"\"\"\n    sv_ground_truth = sensorview.global_ground_truth\n    sv_lane_boundary = sv_ground_truth.lane_boundary.add()\n    sv_boundary_line = sv_lane_boundary.boundary_line.add()\n    sv_boundary_line.position.x = 1699.20\n    sv_boundary_line.position.y = 100.16\n    sv_boundary_line.position.z = 0.0\n    sv_boundary_line.width = 0.13\n    sv_boundary_line.height = 0.0\n\n    \"\"\"Set boundary line attributes to SensorData\"\"\"\n    sd_lane_boundary = sensordata.lane_boundary.add()\n    sd_boundary_line = sd_lane_boundary.boundary_line.add()\n    sd_boundary_line.position.x = sv_boundary_line.position.x\n    sd_boundary_line.position.y = sv_boundary_line.position.y\n    sd_boundary_line.position.z = sv_boundary_line.position.z\n    sd_boundary_line.width = sv_boundary_line.width\n    sd_boundary_line.height = sv_boundary_line.height\n\n    \"\"\"Serialize SensorData which can be send\"\"\"\n    string_buffer = sensordata.SerializeToString()\n\n    \"\"\"Clear SensorData to show parsing from string\"\"\"\n    sensordata.Clear()\n\n    \"\"\"The received string buffer can now be parsed\"\"\"\n    sensordata.ParseFromString(string_buffer)\n\n    \"\"\"Print SensorData\"\"\"\n    print(sensordata)\n\nif __name__ == \"__main__\":\n    main()\nOutput:\nlane_boundary {\n  boundary_line {\n    position {\n      x: 1699.2\n      y: 100.16\n      z: 0.0\n    }\n    width: 0.13\n    height: 0.0\n  }\n}\nSee Google's documentation for more tutorials on how to use protocol buffers with Python or C++.\nInstallation\nDependencies\nInstall cmake 3.10.2:\n$ sudo apt-get install cmake\nInstall pip3 and missing python packages:\n$ sudo apt-get install python3-pip python3-setuptools\nInstall protobuf 3.0.0:\n$ sudo apt-get install libprotobuf-dev protobuf-compiler\nBuild and install for C++ usage:\n$ git clone https:\/\/github.com\/OpenSimulationInterface\/open-simulation-interface.git\n$ cd open-simulation-interface\n$ mkdir build\n$ cd build\n$ cmake ..\n$ make\n$ sudo make install\nInstall for Python usage:\nLocal:\n$ git clone https:\/\/github.com\/OpenSimulationInterface\/open-simulation-interface.git\n$ cd open-simulation-interface\n$ sudo pip3 install virtualenv\n$ virtualenv -p python3 venv\n$ source venv\/bin\/activate\n$ python3 -m pip install .\nGlobal:\n$ git clone https:\/\/github.com\/OpenSimulationInterface\/open-simulation-interface.git\n$ cd open-simulation-interface\n$ sudo pip3 install .\nFor Windows installation see here for more information.\n","36":"MinCED - Mining CRISPRs in Environmental Datasets\nMinCED is a program to find Clustered Regularly Interspaced Short Palindromic\nRepeats (CRISPRs) in full genomes or environmental datasets such as assembled\ncontigs from metagenomes. Iff you want to identify CRISPRs in raw short read\ndata, in the size range of 100-200bp try using Crass (https:\/\/github.com\/ctskennerton\/Crass)\nMinCED runs from the command-line and was derived from CRT (http:\/\/www.room220.com\/crt\/):\nCharles Bland et al., CRISPR Recognition Tool (CRT): a tool for automatic\ndetection of clustered regularly interspaced palindromic repeats, BMC\nBioinformatics 8, no. 1 (2007): 209.\n\nINSTALLATION\nYou need to install these dependencies first:\n\nJava (http:\/\/www.java.com\/en\/download\/)\n\nthere is a Makefile in the source directory so installation should be as simple as:\ncd <download_folder>\nmake\n\nTo run MinCED:\n.\/minced [options] file.fa\n\nThe help page can be obtained by typing:\n.\/minced --help\n\nYou can get the MinCED version this way:\n.\/minced --version\n\nNOTE: Always keep minced and minced.jar in the same folder!\nEXAMPLES\nFinding CRISPRs in the E. coli genome:\n.\/minced ecoli.fna\n\nTo find repeats in short sequences, we need to decrease the minimum number of\nrepeats to find. For example, in 100 bp reads, we could not possibly find more\nthan 2 repeats:\nminced -minNR 2 metagenome.fna\n\nThe output can be large, so save it in a file:\nminced -minNR 2 metagenome.fna metagenome.crisprs\n\nYou can also save both the table output and the gff output at the same\ntime:\nminced ecoli.fna out.txt out.gff\n\nCOPYRIGHT AND LICENSE\nCopyright 2011      Florent ANGLY     <florent.angly@gmail.com>\n          2013-2019 Connor SKENNERTON <c.skennerton@gmail.com>\n\nMinCED is free software: you can redistribute it and\/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\nMinCED is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\nYou should have received a copy of the GNU General Public License\nalong with MinCED.  If not, see <http:\/\/www.gnu.org\/licenses\/>.\n\nBUGS\nAll complex software has bugs lurking in it, and this program is no exception.\nIf you find a bug please post an issue on github https:\/\/github.com\/ctSkennerton\/minced\/issues\n","37":"BuildingSimulationProject_Polimi_TES\nThis repository includes the files and presentations of group projects on simulation of  Buildings with OpenStudio (EnergyPlus) in the context of echnical Environmental Systems (Politecnico di Milano)\nIn order to insert the personal and contact information of members of your group you should fill in the following form: Project Group Information Form\nImportant note: Only one of the members of the group should fill in the form and should insert the personal and contact information of all members.\n","38":"\nGEOG2021 Environmental Remote Sensing\n##Course Tutors\nProf. P. Lewis\nDepartment of Geography\nUniversity College London\n[Educational Aims and Objectives of the Course]  [Course workload and assessment] [Timetable 2015-16] [[Reading List](#Reading List)] [How to run the practicals elsewhere]\n\n####Educational Aims and Objectives of the Course\nTo enable the students to:\n\nUnderstand the nature of remote sensing data and how they are acquired\nUnderstand different types of remote sensing instruments and their missions\nUnderstand basic image representation and processing\nUnderstand how Earth Observation data can be combined with other sources of data and data techniques (e.g. GIS)\nUnderstand how EO data can be used in environmental science (particularly via classification and monitoring)\nDevelop practical skills in these areas, which may be useful in planning of dissertations\nDevelop links with the second year course on Geographic Information Systems Science and with othet courses as appropriate (e.g. hydrology, environmental systems)\nLay the foundations for the third year course on Earth Observation\n\n\n####Course workload and assessment\n#####Expected Course Load\n\n\n\nComponent\nHours\n\n\n\n\nLectures\n8\n\n\nPrivate Reading\n80\n\n\nSupervised Laboratory Work (Computing)\n24\n\n\nIndependent Laboratory Work (Computing)\n20\n\n\nRequired Written Work\n10\n\n\nTOTAL\n142\n\n\n\nUsual range 100-150 for 1\/2 course unit\n\n#####Assessment\n\n100% Assessed Practical (3500 words) - submission date standard 2nd year submission date i.e. Weds 23th March 2016 (12 noon).\n\nN.B.\n\nPenalties for late submission and over length WILL be applied\nDifferent arrangements for JYA\/Socrates (make sure you inform the lecturers if this affects you)\n\n\n####Timetable 2014-15\n\n\n\n\nMonday 09:00-10:00\nThursday 11:00-12:00\nThursday 12:00-13:00\n\n\n\n\nWeek 1\n09\/1\/17 LECTURE 1 Introduction to course; Environmental Remote Sensing\n14\/1\/16 COMPUTING 1 Introductory Computing\n14\/1\/16 COMPUTING 2 Image Display\n\n\nWeek 2\n18\/1\/16 LECTURE 2 Image Display and Enhancement\n21\/1\/16 COMPUTING 2 Data download\n21\/1\/16 COMPUTING 2 Image Display\n\n\nWeek 3\n25\/1\/16 LECTURE 3 Spatial Information\n28\/1\/16 COMPUTING 2 Spatial Filtering\n28\/1\/16 COMPUTING 2 Spatial Filtering\n\n\nWeek 4\n01\/2\/16 LECTURE 4 Image Classification\n04\/2\/16 COMPUTING 3 Classification\n04\/2\/16 COMPUTING 3 Classification\n\n\nWeek 5\n08\/2\/16 LECTURE 5 Spectral Information\n11\/2\/16 COMPUTING 3 Classification\n11\/2\/16 COMPUTING 3 Classification\n\n\nWeek 6\nREADING WEEK\nREADING WEEK\nREADING WEEK\n\n\nWeek 7\n22\/2\/16 LECTURE 6 Environmental Modelling: I\n25\/2\/16 COMPUTING 4 Project\n25\/2\/16 COMPUTING 4 Project\n\n\nWeek 8\n29\/2\/16 LECTURE 6 Environmental Modelling: II\n03\/3\/16 COMPUTING 4 Project\n\n\n\nWeek 9\n07\/3\/16  COMPUTING 4 Project\n\n10\/3\/16 COMPUTING 4 Project\n\n\nWeek 10\n14\/3\/15 PROJECT DISCUSSIONS (Physics A1\/3)\n17\/3\/16 COMPUTING 4 Project\n17\/3\/16 COMPUTING 4 Project\n\n\nWeek 11\n21\/3\/16 Project\n\n\n\n\n\nTopic Revision Notes\n\n\n\n\n\nLectures in (Physics A1\/3 (4th floor))\nComputing in Pearson Building, UNIX Computer lab, PB 110a\n\n####Reading List\n\nJensen, John R. (2006) Remote Sensing of the Environment: an Earth Resources Perspective, Hall and Prentice, New Jersey, 2nd ed.\nJensen, John R. (1995, 2004) Introductory Digital Image Processing: A Remote Sensing Perspective (Prentice Hall Series in Geographic Information Science)\nJones, H. G and Vaughan, R. A. (2010) Remote Sensing of Vegetation, OUP, Oxford.\nLillesand, T., Kiefer, R. and Chipman, J. (2004) Remote Sensing and Image Interpretation. John Wiley and Sons, NY, 5th ed.\nMather, P. (2004) Computer processing of remotely sensed images: an introduction\n\n\n####How to run the practicals elsewhere\nYou can download all of the notes and practicals from this site.\nTo run the practicals, you will need access to ENVI and the datasets associated with each practical.\nNote that installing IDL\/Envi is likely to take around 2.5 GB of space.\nIf you download ENVI, make sure you also download the license file. If you install ENVI on your own computer, make sure you follow the instructions on setting up the license server after downloading the software and license file from the UCL software database.\nYou can also run the practicals using desktop@UCL Anywhere\n\n","39":"EAO Project Information & Collaboration System (EPIC)\nEPIC is the BC Environmental Assessment Office's web-based project information and collaboration system, a tool to improve the efficiency and transparency of the provincial environmental assessment process by providing citizens and stakeholders with more intuitive access to project data and information.\nBuilt through the Office's EAO Systems Modernization Project (ESM), in alignment with and as a pathfinding project of the BCDevExhange collaboration between the Office of the Chief Information Officer and Government Communication and Public Engagement's Government Digital Experience teams, this application is a tool to support the work of EAO staff, project proponents, and other stakeholders as environmental assessments are conducted.\nFeatures\nThe features provided by the web-based EPIC application include:\n\nGreater transparency, understanding and public participation in the Environmental Assessment (EA) process\nComprehensive project details, status, important dates, contact information, and other relevant information\nPublic-facing view of documents related to proposed and ongoing development projects\nMaps showing exactly where projects are located within the province\n\nBrowser Compatibility\n\nIE 11\/Edge\nSafari (evergreen)\nChrome (evergreen)\nFirefox (evergreen)\n\nContent Author Prerequisites\n\nA GitHub account with 2-factor authentication enabled.\nWrite access to this repository\n\nDeveloper Requirements\nEPIC has been built using MongoDB, Express, AngularJS and NodeJS.  See http:\/\/mean.io\/ for more information on the project's development stack. Basic globally install requirements for Win32, OSX, or Linux are as follows:\n\nnode@ = 6.11.3\nnpm@ >= 2.15.1\nmongodb-server@ >= 2.6.x\ngrunt@ >= 0.4.5\ngit\nyarn >= 1.3.2\n\nThe following environment variables must be set in order for a Minio object storage instance to be used for document uploads:\n\nMINIO_HOST - the URL pointing to a Minio instance (can be play.minio.io)\nMINIO_ACCESS_KEY - the minio access key to be used for authentication\nMINIO_SECRET_KEY - the minio secret key to be used for authentication\n\nInstallation\nyarn install\nNote: If you've previously done an installation, and are upgrading from npm to yarn and node 4 -> 6, make sure you delete the node_modules\/ folder and public\/lib\/ folder.\nDevelopment mode\nPlease set your PATH, MINIO_HOST, MINIO_ACCESS_KEY, MINIO_SECRET_KEY, and MONGODB_DATABASE variables before running.\nexport MONGODB_DATABASE=\u201cmean-dev\u201d\nexport MINIO_HOST=\"minio-esm-dev-esm-dev.pathfinder.gov.bc.ca\"\nexport PATH=\"[you path here]\"\nexport MINIO_ACCESS_KEY=\"[access key here]\"\nexport MINIO_SECRET=\"[secret key here]\"\nnpm start\nWindows Environment Variables\nIf you are using a Mingw64, Cygwin64 or git bash, then you can set the above variables in your .bashrc at your posix root directory (the directory you start in when you start your posix environment).\nRestart your terminal and type \"env\" to check if your settings are there.  If not, then you can try to create a .bash_profile file containing the following code:\n\tif [ -f ~\/.bashrc ]\n\tthen\n\t\t. ~\/.bashrc\n\tfi\n\nProduction Mode\ngrunt build && NODE_ENV=production node server.js\nAfter this you may open up a browser of your choice and navigte to http:\/\/localhost:3000\/\nUnit Tests\nThe unit tests are broken into two pieces: the client tests, and the server tests.\nClient\nRun npm run test-client\nThis will execute the unit tests using Karma and Jasmine. See the karma.conf.js\nThis will create a code coverage report at build\/coverage\/client.\nServer\nRun npm run test-server\nThis will execute the unit tests using Mocha. See the mocha_istanbul grunt task.\nThis will create a code coverage report at build\/coverage\/server.\nFunctional Tests\nRun npm run e2e\nPrerequisites\n\nA Mongo DBMS must already be running as a service.\n\nThis will trigger the following steps, via the gruntfile:\n\nCreate a new functional test database\nStart the functional test server\nRun the functional tests\nDrop the functional test database\nShutdown the functional test server\n\nConfigurable Environment Variables\n\n\n\nEnvironment Variable\nDefault Value\nDescription\n\n\n\n\nFUNCTIONAL_HOST\nlocalhost\nlocation of the functional test server\n\n\nFUNCTIONAL_PORT\n3001\nport of the functional test server\n\n\nBASEURL\nhttp:\/\/localhost:3001\nthe url targeted by the functional tests\n\n\nMONGODB_FUNC_HOST\nlocalhost\nlocation of the mongodb instance targeted by the functional test server\n\n\nMONGODB_FUNC_PORT\n27017\nport of the mongodb instance targeted by the functional test server\n\n\nMONGODB_FUNC_DATABASE\nmem-dev-func\nname of the database used by the functional test server\n\n\n\nProject Status\nThe project was released in February 2017 as a public beta, with continuing engagement, co-design and development proceeding to enhance the web application through future releases.  Feedback, involvement and contribution are greatly appreciated!  If you have any comments, please send us an email at epicsupport.eao@gov.bc.ca or click https:\/\/www.projects.eao.gov.bc.ca\/contact to learn more.\nVisual Studio Code\nTo use our Visual Studio Code extensions copy the contents of vscodeextensions.txt in the root directory and paste it into bash. If it doesnt work, make sure you have the Code CLI installed code --version and if it's not installed open the command palette (shift + command + p) and run Shell Command: install 'code' command in PATH.\nHow to Contribute\nFeel free to create pull requests from the default \"master\" branch, click here to create one automatically: https:\/\/github.com\/bcgov\/esm-server\/pull\/new\/master.\nLicence\nCopyright 2018 Province of British Columbia\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n","40":"Iowa Environmental Mesonet\nIf using this code causes your server to have kittens, it is your own fault.\n\nThis monolith drives much of the ingest, processing, product generation, and\nweb presence of the IEM.  Hopefully it can\nbe found useful for others to at least look at to see how some of the magic happens.\nLimited integration testing is done on Travis-CI: \nDatabase schema is in akrherz\/iem-database.\nWhere are processes running\nThe processing load for the IEM is spread over a number of virtual machines.\nThis is an attempt to document what is running where.  The backup shown may not\nbe automated, but another system that could be up and running the service in\nlimited time.\n\n\n\nProcess\nPrimary\nBackup\nMonitor\n\n\n\n\nApache ErrorLog\niem12\nNone\nNone\n\n\nGOES R\/S\niem8-dc\niem19\nNone\n\n\nhads-database\nmetvm4\nNone\ncheck_hads_ingest.py\n\n\niembot\niem13\niem12\nnagios checks for twistd processes running\n\n\niem-web-services\niem14\niem16\nNone\n\n\nLDM\niem12\nNone\nNone\n\n\nLoggerNet\niem12\nNone\nNone\n\n\nmailman\niem12\nNone\nNone\n\n\nnwningest\niem12\nNone\ncron scripts checks SNET sites for being online\n\n\nopenfire\niem12\nNone\nNone\n\n\npostgres\nmetvm6\nmetvm9\nNone\n\n\npostgres2\nmetvm4\nNone\nNone\n\n\npostgres3\nmetvm1\nNone\nNone\n\n\npostgres4\nmetvm7\nNone\nNone\n\n\nsamba\niem12\nNone\ncron scripts check data availability\n\n\nSSH\niem12\nNone\nNone\n\n\nRIDGE\niem13\nNone\ninbound file queue, check latency 7 radars\n\n\nwebalizer\niem19\nNone\nNone\n\n\nWebcam Current\niem13\nNone\ncron script monitors for offline webcams\n\n\nWebcam Lapses\niem13\nNone\nNone\n\n\n\n","41":"ams-ml-python-course\n\nMachine Learning in Python for Environmental Science Problems AMS Short Course Material\nAuthors\n\nDavid John Gagne, National Center for Atmospheric Research (dgagne@ucar.edu)\nRyan Lagerquist, University of Oklahoma (ryan.lagerquist@ou.edu)\nGreg Herman, Amazon\nSheri Mickelson, National Center for Atmospheric Research\n\nRequirements\nThe modules for this short course require Python 3.6 and the following Python libraries:\n\nnumpy\nscipy\nmatplotlib\nxarray\nnetcdf4\npandas\nscikit-learn\ntensorflow-gpu or tensorflow\nkeras\nshapely\ndescartes\njupyter\nipython\njupyterlab\nipywidgets\n\nThe current pre-compiled version of tensorflow-gpu requires your machine to have an NVIDIA GPU, CUDA 9.0, CUDA Toolkit 9.0, and cuDNN 7. If you have different versions of CUDA available, you will have to build Tensorflow from source, which can take a few hours.\nGPUs are recommended for modules 3 and 4 but are not needed for modules 1 and 2.\nData Access\nThe data for the course are stored online. The download_data.py script will download the data to the appropriate location and extract all files. The netCDF data is contained in a 2GB tar file, so make sure you have at least 4GB of storage available and a fast internet connection.\nCourse Videos\n\nModule 1: Data Analysis and Pre-Processing\nModule 2: Machine Learning with Scikit-Learn\nModule 3: Deep Learning with Keras\nModule 4: Model Interpretation\n\nSetup Instructions (Local Install; CPU Only)\nThese instructions assume you have a bash shell running or the Windows command prompt. Conda environments do not work in csh.\n\nInstall the miniconda Python distribution.\nCreate a separate conda environment for the short course: conda create -n mlpy python=3.6\nActivate the enviornment by running source activate mlpy (bash in linux or mac) or activate mlpy (Windows)\nInstall the required base libraries: conda install pip numpy scipy matplotlib scikit-learn netcdf4 xarray pandas ipython jupyter ipywidgets shapely descartes\nInstall tensorflow and keras: pip install tensorflow; pip install keras\nClone the short course repository: git clone https:\/\/github.com\/djgagne\/ams-ml-python-course.git\nChange into the ams-ml-python-course directory.\nDownload the course data to your local machine: python download_data.py\nStart Jupyter lab: jupyter lab\nEach module is in a separate folder. Open the Jupyter notebook in each folder and follow instructions. If you have problems, please create an issue on the Github repository site.\n\nSetup Instructions (Docker)\nThese instructions are for those who want to run the short course Docker image either on their local machine (requires Docker to be installed) or on a single cloud VM.\n\nInstall Docker.\nFrom the command line, pull the appropriate short course Docker container:\n\nCPU only: docker pull djgagne\/ams-ml-python-course:cpu\nGPU (requires NVIDIA GPU, CUDA and nvidia-docker): docker pull djgagne\/ams-ml-python-course:gpu\n\n\nTo start the container: docker run -p 8888:8888 djgagne\/ams-ml-python-course:cpu or :gpu if you are using the CPU or GPU version.\nTo access jupyter lab, open a web browser to localhost:8888 and paste in the token string from the command line.\nIf you are running on a remote server, you will need to forward port 8888 to your local machine. You can do this over ssh if it is a remote server or through the web if you are running on a cloud server with port 8888 opened.\n\nOptional Setting up GPU-enabled short course Jupyter hub containers\nThese instructions are for creating and managing your own short course managed by Jupyterhub on Kubernetes with everything in a Docker container. You do not need to follow these instructions if you are just trying to run the short course modules locally.\nRequirements for architecture\n\nDocker\nGoogle Compute Engine\nGoogle Kubernetes Engine\nNVIDIA CUDA docker images\njupyter docker-stacks\n\nRecipe\n\nStart a Google Compute Engine instance with an NVIDIA GPU and install CUDA and docker. See here.\nClone the jupyter docker-stacks repository\nIn the base-notebook Docker file, change the BASE_CONTAINER to \"nvidia\/cuda:9.0-cudnn7-runtime-ubuntu16.04\"\nBuild base notebook: >> docker build --rm -t username\/base-notebook .\nChange to docker-stacks\/minimal-notebook directory and change the FROM option to username\/base-notebook.\nBuild minimal notebook >> docker build --rm -t username\/minimal-notebook .\nChange to directory containing short course docker file.\nBuild the short course container >> docker build --rm -t username\/ams-ml-short-course:gpu .\nLogin to docker hub with >> docker login\nPush your container to Docker Hub.\nStart a Kubernetes cluster on Google Cloud with 1 CPU node and 1 GPU node. Use preemptible instances to save a lot of money.\nLog into a Kubernetes node and install CUDA here.\nWait until the nvidia drivers have been completely installed. Check status by typing in\nkubectl get pods --all-namespaces and wait for everything to be running.\nSetup Jupyterhub on Google Cloud by following instructions here.\n\n","42":"\nSTC COVID-19 Dataset\nThis data repository stores COVID-19 virus case and related natural and social factors (e.g. environmental observation, policy index) in multi-scale based on ISO standard.\nData Organization\nDatasets are organized by region area ranging from global to countries as shown below. Underneath each folder, multi-scale daily reports and summary reports are provided separately.\nField Description\nDaily Data\nDaily data provides automatically updated information of COVID-19 cases, and related attributes daily.\n\n\n\nAttribute Name\nDescription\nFormat\nExample\n\n\n\n\ndate\nThe date representing the current day in which the data represents. UTC time is used for this dataset, all values will calculated before the end of UTC time of the date.\nDate (YYYY\/MM\/DD) in UTC\n2020\/04\/09\n\n\ncountry_name\nName of the country.\nstring\nUnited States\n\n\niso3\n3 digit ISO country codes.\nvarchar(3)\nUSA\n\n\nadmin1_name\nThe name for admin 1 level.\nstring\nVirginia\n\n\nhasc1\nThis will represent the Hierarchical administrative subdivision codes (HASC) for admin 1 level.\nstring\nUS.VA (for Virginia, United States)\n\n\nlocal_id1\nThis will represent the ID for specific admin 1 level. ID that represents the country's admin 1 level\nstring\nVA (for Virginia, United States)\n\n\nadmin2_name\nThe name for admin 2 level.\nstring\nFairfax County\n\n\nhasc2\nThis will represent the Hierarchical administrative subdivision codes (HASC) for admin 2 level.\nstring\nUS.VA.FX (for Fairfax, Virginia, United States)\n\n\nlocal_id2\nThis will represent the ID for specific admin 2 level. ID that represents the country's admin 2 level.\nstring\n51059 (for Fairfax, Virginia, United States)\n\n\nconfirmed\nThe number of confirmed cases.\ninteger\n777\n\n\ndeath\nThe number of death cases.\ninteger\n19\n\n\nrecovered\nThe number of recovered cases. (might be null for admin 2 level)\ninteger\nnull\n\n\nMiscellaneous\nOther data attributed to our dataset.\nTBD\nTBD\n\n\n\nSummary Data\nSummary data records the COVID-19 cases, and related attributes, to show the timeline of cases.\n\n\n\nAttribute Name\nDescription\nFormat\nExample\n\n\n\n\ncountry_name\nName of the country.\nstring\n\"US\"\n\n\niso3\n3 digit ISO country codes.\nvarchar(3)\nUSA\n\n\nadmin1_name\nThe name for admin 1 level.\nstring\nState for USA\n\n\ndate\nThe date representing the current day in which the data represents. UTC time is used for this dataset, all values will calculated before the end of UTC time of the date.\nUTC\nYYYY\/MM\/DD\n\n\n\nTutorial - Visualize Virus Cases on Map using QGIS\n\nOverall Data Sources by Country\nLegend for data source and operation status\n   \n\n\n\nCountry \/ Region\nContinent\nAdmin level\nData Source\nTemporal Coverage\nOperation Status\n\n\n\n\nGlobal\nGlobal\n0\n \n2020\/1\/22 to current\n\n\n\nUnited States\nNorth America\n1 , 2\n  \nadmin0: 2020\/1\/22 to current, admin1: 2020\/1\/27 to current\n\n\n\nChina\nAsia\n1 , 2\n \nadmin0: 2020\/1\/22 to current, admin1: 2020\/1\/24 to current\n\n\n\nCanada\nNorth America\n1\n \n2020\/1\/26 to current\n\n\n\nAustralia\nOceania\n1\n \n2020\/1\/27 to current\n\n\n\nItaly\nEurope\n1 , 2\n \n2020\/2\/24 to current\n\n\n\nGermany\nEurope\n1\n \n2020\/2\/29 to current\n\n\n\nAustria\nEurope\n1\n \n2020\/3\/4 to current\n\n\n\nBrazil\nSouth America\n1\n \n2020\/2\/26 to current\n\n\n\nChile\nSouth America\n1\n \n2020\/3\/2 to current\n\n\n\nJapan\nAsia\n1\n \n2020\/1\/15 to current\n\n\n\nRussia\nEurope\n1\n \n2020\/3\/22 to current\n\n\n\nSouth Africa\nAfrica\n1\n  \n2020\/3\/5 to current\n\n\n\nCroatia\nEurope\n1\n \n2020\/3\/21 to current\n\n\n\nSweden\nEurope\n1\n \n2020\/3\/16 to current\n\n\n\nIndia\nAsia\n1\n \n2020\/3\/10 to current\n\n\n\nHungary\nEurope\n1\n \n2020\/3\/31 to current\n\n\n\nDenmark\nEurope\n1\n \n2020\/5\/20 to current\n\n\n\nUkraine\nEurope\n1\n \n2020\/4\/5 to current\n\n\n\nLatvia\nEurope\n1\n \n2020\/3\/19 to current\n\n\n\nAlbania\nEurope\n1\n \n2020\/4\/22 to current\n\n\n\nHaiti\nNorth America\n1\n \n2020\/3\/19 to current\n\n\n\nRomania\nEurope\n1\n \n2020\/4\/2 to current\n\n\n\nMexico\nNorth America\n1\n \n2020\/4\/25 to current\n\n\n\nNigeria\nAfrica\n1\n \n2020\/2\/27 to current\n\n\n\nPakistan\nAsia\n1\n \n2020\/3\/10 to current\n\n\n\nBolivia\nSouth America\n1\n \n2020\/6\/4 to 2020\/7\/29\n\n\n\nGuatemala\nNorth America\n1\n \n2020\/3\/15 to 2020\/8\/14\n\n\n\nEl Salvador\nNorth America\n1\n \n2020\/6\/6 to 2020\/7\/4\n\n\n\nSwitzerland\nEurope\n1\n \n2020\/6\/1 to 2020\/8\/10\n\n\n\nBulgaria\nEurope\n1\n \n2020\/6\/6 to 2020\/8\/10\n\n\n\n\nRecommended Citation\n\nLiu, Q., Liu, W., Sha, D., Kumar, S., Chang, E., Arora, V., Lan, H., Li, Y., Wang, Z., Zhang, Y. and Zhang, Z., 2020. An Environmental Data Collection for COVID-19 Pandemic Research. Data, 5(3), p.68.\n\n@article{liu2020environmental,\n  title={An Environmental Data Collection for COVID-19 Pandemic Research},\n  author={Liu, Qian and Liu, Wei and Sha, Dexuan and Kumar, Shubham and Chang, Emily and Arora, Vishakh and Lan, Hai and Li, Yun and Wang, Zifu and Zhang, Yadong and others},\n  journal={Data},\n  volume={5},\n  number={3},\n  pages={68},\n  year={2020},\n  publisher={Multidisciplinary Digital Publishing Institute}\n}\n\nYang, C., Sha, D., Liu, Q., Li, Y., Lan, H., Guan, W.W., Hu, T., Li, Z., Zhang, Z., Thompson, J.H. and Wang, Z., 2020. Taking the pulse of COVID-19: A spatiotemporal perspective. International Journal of Digital Earth, pp.1-26.\n\n@article{yang2020taking,\n  title={Taking the pulse of COVID-19: A spatiotemporal perspective},\n  author={Yang, Chaowei and Sha, Dexuan and Liu, Qian and Li, Yun and Lan, Hai and Guan, Weihe Wendy and Hu, Tao and Li, Zhenlong and Zhang, Zhiran and Thompson, John Hoot and others},\n  journal={International Journal of Digital Earth},\n  pages={1--26},\n  year={2020},\n  publisher={Taylor \\& Francis}\n}\n\nSha, D., Liu, Y, Liu, Q., Li, Y., Tian, Y., Beaini, F., Zhong, C., Hu, T., Wang, Z., Lan, H., Zhou, Y., Zhang, Z. and Yang, C., 2020. A Spatiotemporal Viral Cases Data Collection for COVID-19 Rapid Response. preprint. DOI:10.13140\/RG.2.2.35840.46088\n\nSource Changing Log\n\nGreece from https:\/\/github.com\/iMEdD-Lab\/open-data\/tree\/master\/COVID-19 to https:\/\/eody.gov.gr\/ after 2020\/6\/9\nSlovenia from https:\/\/www.korona.gov.sk\/en\/coronavirus-covid-19-in-the-slovak-republic-in-numbers\/ to https:\/\/www.nijz.si\/sites\/www.nijz.si\/files\/uploaded\/ after 2020\/6\/10\nRomania from https:\/\/instnsp.maps.arcgis.com\/apps\/opsdashboard\/index.html#\/5eced796595b4ee585bcdba03e30c127 to https:\/\/github.com\/gabrielpreda\/covid_19_ro after 2020\/6\/10\nSlovakia from https:\/\/www.korona.gov.sk\/en\/coronavirus-covid-19-in-the-slovak-republic-in-numbers\/ to  https:\/\/apify.com\/davidrychly\/covid-sk-3 after 2020\/6\/11\n\nPeople Contribution & Credit\n\nPhil Yang, PI and supervisor.\nWendy Guan, Co-PI\nShuming Bao, colloborator\nDexuan Sha, project leader, metadata and standard design, crawler and ETL development, operation management.\nYun Li, GitHub management, data report generation and quality control.\nQian Liu, Environmental factor design, acquisition and preprocessing.\nChen Zhong, data crawler and ETL development.\nYou Zhou, policy, news and publication collection, coding, and labelling. Daily operation and data quality control.\nYifei Tian, data crawler and ETL development.\nFayez Beaini, data source collection and evaluation, quality control.\nTao Hu, cooperation leader from Harvard University and China Data Lab.\nZifu Wang and Hai Lan, IT infrastructure and network security support.\nZhiran Zhang, visualization\nWei Liu, data processing\nAkhil Kumar, data validation.\nSwetha Bhattaram, data validation.\nYogya Kalra, data validation.\n\nDisclaimer\nAll data in this repository was collected\/calculated\/calibrated from multiple publicly available data sources that do not always agree. While we'll try our best to keep the information up to date and correct, we make no representations or warranties of any kind, express or implied, about the completeness, accuracy, reliability, with respect to the data. We do not bear any legal responsibility for any consequence caused by the usage of data provided. Reliance on the data for medical guidance or use of the data in commerce is strictly prohibited. NSF STcenter hereby disclaims any and all representations and warranties with respect to the data repository, including accuracy, fitness for use, and merchantability.\nFor countries where there are internal disputes and sensitive region or area, we do not include that part of data in our datasets. If you are interested in this part of data, you can contact us directly.\n","43":"MesoPy\n\n\n\nMesoPy is a small pure python wrapper around the MesoWest (http:\/\/mesowest.utah.edu\/) API which is updated daily with over 4.5 million observations. It is useful for retrieving meteorological data at over 40,000 observation stations in the United States. This project was created with the researcher in mind and we would value feedback on how you are using MesoPy!\nBefore using MesoPy, you will need to obtain an API key\/token by filling out a quick form here. You will receive an email immediately with an API key and a link to generate a token. Click the link and copy the token you just generated when instancing the Meso object like so: m = Meso(token='YOUR API_TOKEN')\nInstallation\nThere are two easy ways to install MesoPy:\n\nRun  pip install mesopy from a command line window\nDownload the source folder and place MesoPy.py into your working directory\n\nVersion 2 Updates\n\nThe requests package dependency no longer exists\nFunction names have been simplified\nAdditional query parameters have been added to each function\nNew functions added to request more services from MesoWest (data latency, statistics, network information)\nLists may be passed to parameters\n\nUsage\nRetrieving data:\nYou can request different types of observations by simply creating a Meso object and calling a function:\nfrom MesoPy import Meso\nm = Meso(token='YOUR API_TOKEN')\nprecip = m.precip(stid='kfnl', start='201504261800', end='201504271200', units='precip|in')\n\nThis returns the following data as a dictionary.\n{  \n   \"UNITS\":{  \n      \"precipitation\":\"Inches\"\n   },\n   \"STATION\":[  \n      {  \n         \"STATUS\":\"ACTIVE\",\n         \"MNET_ID\":\"1\",\n         \"PERIOD_OF_RECORD\":{  \n            \"start\":\"1970-01-01T00:00:00Z\",\n            \"end\":\"2018-03-13T01:56:00Z\"\n         },\n         \"ELEVATION\":\"5016\",\n         \"NAME\":\"Fort Collins\\\/Loveland - Northern Colorado Regional Airport\",\n         \"RESTRICTED\":false,\n         \"STID\":\"KFNL\",\n         \"ELEV_DEM\":\"5000\",\n         \"LONGITUDE\":\"-105.01667\",\n         \"STATE\":\"CO\",\n         \"OBSERVATIONS\":{  \n            \"ob_start_time_1\":\"2015-04-26T18:15:00Z\",\n            \"total_precip_value_1\":0.09,\n            \"ob_end_time_1\":\"2015-04-27T11:55:00Z\",\n            \"count_1\":53\n         },\n         \"LATITUDE\":\"40.45\",\n         \"TIMEZONE\":\"America\\\/Denver\",\n         \"ID\":\"192\"\n      }\n   ],\n   \"SUMMARY\":{  \n      \"DATA_QUERY_TIME\":5.0201416016,\n      \"RESPONSE_CODE\":1,\n      \"RESPONSE_MESSAGE\":\"OK\",\n      \"METADATA_RESPONSE_TIME\":\"0.0920295715332 ms\",\n      \"NUMBER_OF_OBJECTS\":1,\n      \"PRECIP_DATA_TIME\":5.4969787598,\n      \"DATA_PARSE_TIME\":0.4601478577\n   }\n}\nYou can retrieve any of the dictionary keys\/values listed above by merely doing the following:\n# Let's print the total precip accumulation for Fort Collins Airport.\nstation = precip['STATION'][0]['STID'] # remember we stored the dictionary in the precip variable\ntotalPrecip =  precip['STATION'][0]['OBSERVATIONS']['total_precip_value_1'] \nprint('The total accumulated precip at ' + station + ' was ' + str(totalPrecip) + '\"')\n\nWhich prints:\n\nThe total accumulated precip at KFNL was 0.09\"\n\n#####You should note one thing from the above example:\nWhenever the data you're requesting returns ['STATION'], it is necessary to specify which station (index value) in the list you will subsequently be referring to. For example if you pass in stid=kden,kslc, the dictionary will return a list of the two stations' relevant info. So to get to information on KDEN (Denver), you would type ['STATION'][0] because KDEN would be first in the list of stations and ['STATION'][1] for KSLC (Salt Lake City). Remember that {} specifies a dictionary and [] denotes a list and [0] is the first position in a list. It may be useful to store precip['STATION'][i] as a variable to reduce clutter. For example, Denver_PrecipObs = precip['STATION'][0]  and SaltLake_PrecipObs = precip['STATION'][1]. Then, you could write print(Denver_PrecipObs['OBSERVATIONS']['total_precip_value_1']) which returns 0.13 (for the above request). The API was created to always return a list (since a user can request multiple stations at any time) so this will always be a stipulation.\nFunction List:\n\nlatest() -  Get the latest observation data for a particular station(s)\nattime() - Get the latest observation data for a particular station(s) at a specific time\nprecipitation() - Obtain precip totals over a specified period for a station(s)\ntimeseries() - Retrieve observations over a specified period for a station(s)\nclimatology() - Obtain a climatology over a specified period for a station(s)\nmetadata() - Retrieve a list of station metadata based on search parameters\nvariables() - Get a list of sensor variables possible for observing stations\nclimate_stats() - Retrieve aggregated yearly climate statistics for a station(s)\ntime_stats() - Obtain statistics for a specific time frame for a station(s)\nlatency() - Retrieve data latency values for a station(s)\nnetworks() - Obtain metadata concerning the observing networks in the MesoWest repository\nnetworktypes() - Returns the network categories for the observing networks\n\nDocumentation\nEach function is well documented in the docstrings. In an interactive interpreter, simply type help(SOME_FUNC) or in your code, type SOME_FUNC.__doc__\nExample Projects\nThese can be found in the \/examples path.\nVersion and License\n2.0.2 released on 7 Jan 2016 under the MIT license\nSupport and Credits\nMesoPy was designed to be as simple as possible and we hope you enjoy its usage. If you have any questions\/comments, please direct them to support@mesowest.org. The MesoWest group is led by  Dr. John Horel at the University of Utah. Additional facilities were provided by the Western Region of the National Weather Service.\n","44":"Environmental Sound Classification using Deep Learning\n\nA project from Digital Signal Processing course\n\nDependencies\n\nPython 3.6\nnumpy\nlibrosa\npysoundfile\nsounddevice\nmatplotlib\nscikit-learn\ntensorflow\nkeras\n\nDataset\nDataset could be downloaded at Dataverse or Github.\nI'd recommend use ESC-10 for the sake of convenience.\nExample:\n\u251c\u2500\u2500 001 - Cat\n\u2502  \u251c\u2500\u2500 cat_1.ogg\n\u2502  \u251c\u2500\u2500 cat_2.ogg\n\u2502  \u251c\u2500\u2500 cat_3.ogg\n\u2502  ...\n...\n\u2514\u2500\u2500 002 - Dog\n   \u251c\u2500\u2500 dog_barking_0.ogg\n   \u251c\u2500\u2500 dog_barking_1.ogg\n   \u251c\u2500\u2500 dog_barking_2.ogg\n   ...\n\nFeature Extraction\nPut audio files (.wav untested) under data directory and run the following command:\npython feat_extract.py\nFeatures and labels will be generated and saved in the directory.\nClassify with SVM\nMake sure you have scikit-learn installed and feat.npy and label.npy under the same directory. Run svm.py and you could see the result.\nClassify with Multilayer Perceptron\nInstall tensorflow and keras at first. Run nn.py to train and test the network.\nClassify with Convolutional Neural Network\n\nRun cnn.py -t to train and test a CNN. Optionally set how many epochs to train on.\nPredict files by either:\n\nPutting target files under predict\/ directory and running cnn.py -p\nRecording on the fly with cnn.py -P\n\n\n\n","45":"\n\nEarthSim\nPython-based tools for specifying, launching, visualizing, and analyzing environmental simulations, such as those for hydrology modeling.\nEarthSim is designed as a lightweight \"overview\" site and project, relying on core code maintained in other general-purpose PyViz projects:\n\nBokeh: Interactive browser-based plotting\nHoloViews: Easy construction of Bokeh plots for datasets\nDatashader: Rendering large datasets into images for display in browsers\nParam: Specifying parameters of interest, e.g. to make widgets\nGeoViews: HoloViews with earth-specific projections\n\nAs such, this repository primarily consists of three things:\n\nearthsim: A Python package with a small amount of code specific to environmental simulation\nexamples: A set of Jupyter notebooks that show how to use the various PyViz tools to solve earth-science problems\nwebsite: The example notebooks already run and rendered to HTML for simple exploration\n\nIn most cases, the examples (as notebooks or as the website) represent the main form of documentation, even for the Python package, so please see https:\/\/earthsim.pyviz.org for more information, including installation and usage instructions.\n","46":"antelope_contrib\nContributed software for use with the Antelope Environmental Monitoring\nSystem from BRTT, Inc.\nMaintained by members of the Antelope Users Group.\nThe Antelope Contrib source code is available on GitHub\nInclusion in Antelope\nBRTT includes compiled versions of the software in this repository with every\nrelease of Antelope, subject to some basic quality control guidelines. The\nContributing section below contains some guidelines.\nLayout of the antelope_contrib Git repository\nEach directory containing Antelope code is expected to contain a Makefile\nwritten in the antelopemakefile(5) format. The Antelope build process will\nnot build any directory that does not contain a Makefile.\nCode in this repository is laid out in a few top-level dirctories.\n\nfirst - Code that is necessary for antelope_contrib to compile properly.\nBuilt before anything else. Use sparingly.\nlib - C shared libraries, Perl modules, and Python modules\nbin - The bin directory contains executables.\n\nbin\/rt - Code that talks to instruments typically lives under bin\/rt.\nbin\/export - Code that allows other software packages to use Antelope data lives in\nbin\/export.\n\n\ndata - Third-party language bindings for PHP, and Java, plus data-only\nfiles like travel time databases and instrument response curves.\nnobuild - Older code that is abandoned by the author or no longer works with the\ncurrent version of Antelope, but may be interesting to others\n\nUsage\nAll code in this repository requires a working Antelope installation.\nAdditionally, the Antelope environment must be configured in your shell\nenvironment.\nHistorically, this repository was checked out in $ANTELOPE\/src, but can be\nchecked out to any location that the user desires.\nCompilation is handled by the UNIX make command. Most of the Makefiles in\nthis repository make use of the antelopemake(5) mechanism, which is a bit of\nAntelope-specific syntacic sugar and macros.\nInitial setup\nIn the instructions below, make sure to substitute the correct version of\nAntelope.\nYou may also choose to check out the contributed code to another location than\n$ANTELOPE\/src.\nFor Bourne shells:\n. \/opt\/antelope\/5.6\/setup.sh\ncd $ANTELOPE\ngit clone https:\/\/github.com\/antelopeusersgroup\/antelope_contrib.git src\n\nFor C shells:\nsource \/opt\/antelope\/5.6\/setup.csh\ncd $ANTELOPE\ngit clone https:\/\/github.com\/antelopeusersgroup\/antelope_contrib.git src\n\nlocalmake\nSome of the code in this repository needs to link against third party software\napplications and libraries that may not be present on all systems. In order for\nthis code to compile, the Makefiles for some code use the localmake mechanism\nto read a set of pre-defined paths to libraries and other applications. No\ndefaults are provided - you must run the localmake_config command to set up\nthese macros. Basic boot-strapping for localmake looks like this:\n# Install the localmake_config command from source\ncd $ANTELOPE\/src\/first\/localmake_config\nmake Include\n\n# Install the localmake command\ncd ..\/localmake\nmake Include; make; make install\ncd ..\/..\/\n\n# Run localmake_config to define the paths to various third-party software\nlocalmake_config\n\nCompilation\ncd $ANTELOPE\/src # or where ever you checked out the repository\nmake Include\nmake\nmake install\n\nContributing\nCode Contribution Rules\nAs a rule, all code in this repository MUST at a minimum:\n\nCompile cleanly on the supported Antelope platforms (RHEL 6+ and Mac OSX\n10.8+)\nContain a Makefile set up to use the antelopemake(5) rules, and with the\nSUBDIR macro set to \/contrib (See the Example\nMakefile below)\nContain a man page describing how to use the program or library. This can be\nformatted by hand or created with a documentation package like Doxygen,\nsphinx, pod2man, or javadoc.\nContain a file called LICENSE that clearly states the license that program\nis released with. See the Licensing section below for\nacceptable licenses.\n\nDevelopment Process\n\nFork it (https:\/\/github.com\/antelopeusersgroup\/antelope_contrib\/fork)\nCreate your feature branch (git checkout -b my-new-feature)\nCommit your changes (git commit -am 'Add some feature')\nPush to the branch (git push origin my-new-feature)\nCreate a new Pull Request\n\nExample Makefile\nBIN = myprog\nMAN1 = $(BIN).1\n\nSUBDIR=\/contrib\ninclude $(ANTELOPEMAKE)\n\nLicensing\nAll code in this repository is expected to be readily distributed. In order for\npre-compiled versions of your code to be included with the Antelope\ndistribution, it must be accompanied by a LICENSE file, and be of a type that\nlends itself to inclusion in commercial packages. Generally speaking,\nBSD and MIT style licenses are ok, but GNU GPL\nand LGPL are not.\nFor more information on BRTT's rules for code contribution with Antelope, please see\nBRTT's contrib licensing page.\n","47":"ESC: Dataset for Environmental Sound Classification - paper replication data\n\nAbstract:\n\nOne of the obstacles in research activities concentrating on environmental sound classification is the scarcity of suitable and publicly available datasets. This paper tries to address that issue by presenting a new annotated collection of 2 000 short clips comprising 50 classes of various common sound events, and an abundant unified compilation of 250 000 unlabeled auditory excerpts extracted from recordings available through the Freesound project. The paper also provides an evaluation of human accuracy in classifying environmental sounds and compares it to the performance of selected baseline classifiers using features derived from mel-frequency cepstral coefficients and zero-crossing rate.\n\nDataset downloads:\n\nWhole dataset: dx.doi.org\/10.7910\/DVN\/YDEPUT\nESC-50 @ GitHub\nESC-10 @ GitHub\n\nPaper:\n\nAuthor version of the paper: ESC: Dataset for Environmental Sound Classification.\n\nCiting:\n\nK. J. Piczak. ESC: Dataset for Environmental Sound Classification. In Proceedings of the 23rd ACM international conference on Multimedia, pp. 1015-1018, ACM, 2015.\n\n\n[DOI: http:\/\/dx.doi.org\/10.1145\/2733373.2806390]\n\nSupplementary materials:\n\nExploratory analysis of the dataset \/ source code (Jupyter\/IPython notebook)\nPoster:\n\n\nRelated work:\n\nEnvironmental Sound Classification with Convolutional Neural Networks\n\n","48":"Read this in other languages: \u65e5\u672c\u8a9e.\nIoT Asset Tracking using a Hyperledger Blockchain\nIntroduction\nThis repository contains three sections which assemble an IoT Asset Tracking device, Hyperledger Blockchain and a Node-RED Dashboard to implement a perishable network supply chain.  This example can be used to track environmental conditions for a food safety supply chain, refrigerated medical supplies, garden plant shipments or any perishable shipment that are temperature \/ humidity \/ vibration \/ time sensitive.  If a cargo needs to be delivered within safe environmental parameters and time, the use of an IoT Asset Tracking device that combines environmental sensors, calculates its location via GPS, triangulation or beacons, and then reports its location via Cellular, 5G, Sub1GHz, SigFox, WiFi networks is extremely valuable. When multiple participants - farms, manufacturers, processing plants, trucks, ports, ships, distribution centers, consumer retail outlets - are involved in the safe shipment and payment of the cargo, a Hyperledger Blockchain can be used to record immutable transactions as the cargo shipment progresses through its delivery journey.\nWorkshop\nI've arranged this git repository to be read as an IBM Code Pattern workshop tutorial. Follow the steps in the Workshop directory to learn how to build one yourself!\nSection Overviews\nThe first section details how to set up a Particle Electron Asset Tracker v2 to send environmental sensor data and location to the cloud. This implementation uses a Particle Electron but many other IoT Asset Tracking devices that can transmit location and data can be substituted with similar results. Subsequent revisions of this workshop tutorial will add other IoT Asset Tracking boards so check back in the future.\nThe second section implements a Perishable Business Network using Hyperledger Fabric, Hyperledger Composer, Hyperledger Composer REST APIs running in the IBM Cloud Container Service managed by a Kubernetes cluster in the IBM Cloud.\nIn the third section, the power of Where, What and When is best visualized in a dashboard that plots the geo location path, the environmental sensor data and can control triggers and alerts.  I use Node-RED and a Node.js server running in an IBM Cloud hosted Cloud Foundry application to receive the IoT Asset Tracking data and write it to the Hyperledger Fabric using Hyperledger Composer REST APIs.  I also use a Node-RED Dashboard to plot the shipment on a map.\nEnjoy!  Give me feedback if you have suggestions on how to improve this tutorial.\nLicense\nThis code pattern is licensed under the Apache Software License, Version 2. Separate third party code objects invoked within this code pattern are licensed by their respective providers pursuant to their own separate licenses. Contributions are subject to the Developer [Certificate of Origin, Version 1.1 (\u201cDCO\u201d)] (https:\/\/developercertificate.org\/) and the [Apache Software License, Version 2]( (http:\/\/www.apache.org\/licenses\/LICENSE-2.0.txt).\nASL FAQ link: http:\/\/www.apache.org\/foundation\/license-faq.html#WhatDoesItMEAN\n","49":"EE509\nApplied Environmental Statistics course: Boston University, Earth & Environment 509\n","50":"\n\n\nlayout\ntitle\npermalink\n\n\n\n\npage\nWelcome to APES\n\/index.html\n\n\n\nThis is the collection of Advice for Problems in Environmental Statistics (APES) of the Department of Biometry and Environmental System Analysis at the University of Freiburg, and the Professorship for Theoretical Ecology at the University of Regensburg. This website gives some basic intros and links for\n\nStandard topics in statistics\nThe statistical programming language R\n\nWe also provide some \"Hubs\" on special topics and \"Checklists\" for particular situations. If you are a student looking for help, the following pages may be particularly interesting:\n\n\nGetting started with R\n\n\nWhat to do if you get an error from R\n\n\nChecklist planning an experiment\n\n\nChecklist analyzing data\n\n\n","51":"BLEES\n\nBLEES: Bluetooth Low Energy Environment Sensors.\n\nBLEES is a 1 inch round sensor tag for sensing the ambient environment. It monitors\ntemperature, humidity, light, pressure, and movement and reports its readings\nover BLE.\n\nHardware\nThe BLEES hardware is a small, once inch round sensor board that mounts onto a Squall BLE sensor tag. The board\ncurrently has four sensors:\n\nTemperature and Humidity (Si7021)\nPressure (LPS331AP)\nLight (TSL2561)\nAccelerometer (ADXL362)\n\nThe BLEES hardware is located in the hardware directory, where you can find\nthe Eagle design files.\nSoftware\nThe Squall uses the software\nlocated in the software directory. Follow the directions in the [nrf5x-base Readme]\n(http:\/\/github.com\/lab11\/nrf5x-base#program-a-nrf51822) to\nget your machine set up to build and flash the Squall.\nThe primary application is\nsoftware\/apps\/blees.\nThis application samples the\nsensors and makes this data available as both broadcast advertisements and the\nEnvironmental Sensing Service for a connected device.\nData Reference\nAdvertisement data\nBLEES transmits advertisements every 1000 ms containing application data.\nHere's a useful BLE Advertisement\nprimer.\nThe advertisements come in two forms: environmental data and eddystone.\nAdvertisements alternate between the two evenly.\nThe environmental data advertised is same data as is available through the\nenvironmental sensing service, but broadcast so several nearby devices can\naccess it concurrently. The data includes, in order, four bytes for pressure,\ntwo bytes for humidity, two bytes for temperature, two bytes for light\nilluminance, and one byte for acceleration state. An example application that\ncollects BLE advertisements from BLEES devices and displays the data can be\nfound at data_collection\/advertisements\/blees_adv.js\nEddystone is a protocol for connecting\nBLE devices to Internet resources. BLEES advertises the URL of an application\nthat can be interpreted by the Summon framework in order to automatically\ngenerate a user interface. (see next heading)\nEnvironmental Sensing Service\nBLEES is also connectable and supports the Environmental Sensing Service. While\nconnected to, it continues to advertise, but only one connection at a time is\nallowed. The environmental sensing service is defined by the\nBLE SIG.\nSummon App\nSummon is a UI application for BLE devices.\nRather than requiring every user\nto install a new app for every BLE device, Summon allows BLE devices to\npoint to their own HTML\/JS based interface and loads it in a single\napplication. BLEES supports the summon architecture and provides\na Summon application.\nCloning\nTo clone both this repository and the required submodules,\nclone with the --recursive option:\ngit clone --recursive git@github.com:lab11\/blees.git\nOtherwise, you can initialize the submodule and keep submodules up to\ndate by doing git submodule update --init --recursive\nIf you think all of this is ridiculous and git should just handle submodules automatically, use this:\nhttps:\/\/gist.github.com\/brghena\/fc4483a2df83c47660a5\nOther Hardware\nIncluded in this repo are:\nBlink\n\nBlink is a PIR sensor that is also based on Squall. Like BLEES, it supports Summon.\nThe nRF51822 app is here.\n","52":"FORCE\nFramework for Operational Radiometric Correction for Environmental monitoring\nVersion 3.5.2\n\nAbout\nFORCE is an all-in-one processing engine for medium-resolution Earth Observation image archives. FORCE uses the data cube concept to mass-generate Analysis Ready Data, and enables large area + time series applications. With FORCE, you can perform all essential tasks in a typical Earth Observation Analysis workflow, i.e. going from data to information.\nFORCE natively supports the integrated processing and analysis of\n\nLandsat 4\/5 TM,\nLandsat 7 ETM+,\nLandsat 8 OLI and\nSentinel-2 A\/B MSI.\n\nNon-native data sources can also be processed, e.g. Sentinel-1 SAR data or environmental variables.\nRelated Links\nThe documentation is available on ReadtheDocs.\nLearn how to use FORCE. Have a look at my Tutorials. Check regularly for new content.\nGet help, and help others in the FORCE self-help Google group\nFollow the FORCE project at ResearchGate\nStay updated, and follow me on Twitter\nYou are using FORCE? Spread the word, and use the #FORCE_EO hashtag in your tweets!\n","53":"\nRack::Environmental\u00b6 \u2191\nDescription\u00b6 \u2191\nNever again will you accidentally delete production data!  Rack::Environmental adds an indicator badge to your web application so that you can tell whether you're working with the staging, test, development or production version of your web app.\nInstallation\u00b6 \u2191\nFor bundler-managed applications just include Rack::Environmental in your Gemfile:\ngem 'rack-environmental'\n\nAlternatively, you can install Rack::Environmental manually:\n$ gem install rack-environmental\nUsage\u00b6 \u2191\nThis Rack middleware can be used with any Rack application, but here's how you would use it in Rails.  Put the following in config\/application.rb:\nconfig.middleware.use Rack::Environmental,\n                        :staging =>     { :url => \/^staging.+$\/   },\n                        :test =>        { :url => \/^test.+$\/      },\n                        :development => { :url => \/^localhost.+$\/ }\n\nWhen a request comes to your web app, Rack::Environmental compares the URL to the supplied regular expressions.  If the URL matches, the name of the environment is displayed at the top of the web page.\nEach environment can be further configured:\nconfig.middleware.use Rack::Environmental,\n                        :staging =>     { :url => \/^staging.+$\/,\n                                          :color => \"yellow\",\n                                          :size => :large          },\n                        :test =>        { :url => \/^test.+$\/,\n                                          :color => \"purple\",\n                                          :style => :badge         },\n                        :development => { :url => \/^localhost.+$\/,\n                                          :color => \"orange\"       }\n\nHere's the full list of configuration options:\n:url        => a regular expression\n:style      => either :badge (a transparent, floating badge), :banner (default), or :none (ignore this environment)\n:color      => a string that represents a CSS color, such as \"red\", \"rgb(6,70,14)\", or \"#8e6630\"\n:size       => :small, :medium, or :large; defaults to :medium\n:opacity    => a number from 0 (completely transparent) to 1; only works with the badge style\n:top        => distance in pixels from the top; only works with the badge style\n:left       => distance in pixels from the left; only works with the badge style\n:background => true or false; when true, the body's background color is changed\nIgnoring environments\u00b6 \u2191\nIf there's a context where you want Rack::Environmental to specifically ignore your requests, such as a Jasmine test runner which returns essentially empty files to be built on by the test runner, you can \u201cshut off\u201d Rack::Environmental for that context by adding `:style => :none` to its options.\n","54":"\nGismo\nGismo is a free and open source Grasshopper plugin for GIS environmental analysis.\nDescription:\nGismo enables automatic generation of urban environment and terrain geometry based on location's latitude-longitude coordinates and radius. This includes connection with openstreetmap website and generation of buildings, trees, roads, rivers and other map elements. 3d building elements can also be used as a context for further analysis types: isovist (visibility), solar radiation, thermal\/wind comfort, cfd analysis...\n\n\n\n\n\n\n* more screenshots...\nRequirements:\n\nMcNeel Rhino 5 32bit or 64bit \u2265 SR9 or Rhino 6. Rhino 7 WIP is not supported at the moment!\nGrasshopper 0.9.0075 or 0.9.0076.\nGhpython plugin 0.6.0.3\nMapWinGIS 32bit or 64bit any version from 4.9.4.2 to 4.9.6.1 (Gismo still does not support the 5 version!!!)\nActive internet connection.\n\nInstallation\n\n\n\nInstall the upper mentioned requirements (Rhino 5, Grasshopper, Ghpython, MapWinGIS).\n\n\n\n\nDownload the latest Gismo plugin files as a single .zip file from here:\nhttps:\/\/github.com\/stgeorges\/gismo\/zipball\/master\n\n\n\n\nCheck if downloaded .zip file has been blocked: right click on it, and choose Properties. If there is an Unblock button click on it, and then click on OK. If there is no Unblock button, just click on OK.\n\n\n\n\nUnpack the .zip file.\n\n\n\n\nCopy the content from userObjects folder to your Grasshopper's: File->Special Folders->User Object Folder folder.\n\n\n\nAdditional info\n\nDiscussion group\nFacebook\nTwitter\n\nGismo is heavily influenced by Ladybug a free and open source environmental plugin for Grasshopper. It is using its code template, and follows the Labybug code organization. Some methods from Ladybug may have also been copied.\nGismo is licensed under GPL-3.0+ license: <http:\/\/spdx.org\/licenses\/GPL-3.0+\nThe latest version is 0.0.3.\nContributors\nAntonello Di Nunzio\nDjordje Spasic\nGuillaume Meunier\nMathieu Venot\nSupport on various issues and questions has been given by: Alec Bennett, Andrew T. Young, Bojan Savric, Christopher Crosby, Dragan Milenkovic, Even Rouault, Graham Dawson, Izabela Spasic, Jonathan de Ferranti, Jukka Rahkonen, Menno Deij-van Rijswijk, Michal Migurski, Mostapha Sadeghipour Roudsari, Paul Meems, Sergei Leschinsky, Timothy Logan, Ulrich Deuschle, Vladimir Elistratov, OSM and GDAL communities.\n","55":" \nComputing in Civil and Environmental Engineering\nby Xiaofeng Liu, Ph.D., P.E.\nAssociate Professor\nDepartment of Civil and Environmental Engineering\nInstitute of Computational and Data Sciences\nPenn State University\n223B Sackett Building, University Park, PA 16802\nWeb: http:\/\/water.engr.psu.edu\/liu\/\nSee static render on nbviewer\nGitHub does not support certain features in the Jupyter Notebook. You can view a static render on nbviewer.\nWhy another book?\nThere are many many excellent books on the topic computational methods for engineers and scientists, as well as programming. However, through my teaching and research, I increasingly feel that there is a lack of discipline-specific textbook for civil and environmental engineers. Many of the books I used for my study and teaching are very general. They are geared toward a much broader audience, which is good. However, a consequence of this is that the content (description of each numerical method, examples, and exercise problems) may not be so relevant to civil and environmental engineers. This book is specifically designed to fill this hole.\nThis work is far from complete. As of now, it is a collection of lecture notes in the form of Jupyter Notebooks using Python. These lecture notes are for the Computing in Civil and Environmental Engineering course that the author offers at Penn State. It will evolve as time goes by and may not reach completion before several batches of students go through this course.\nAlthough the title of the book sounds like it is ONLY for civil and environmental engineers, it is envisioned that students and practioners from other disciplines, such as agricultural and biological engineering, architectural engineering, earth and mineral sciences, and geological sciences,  can find this work useful.\nOverview and outline\nThis work is still evolving. As time goes by, more content and CEE-relevant examples will be added. The following is the outline and example list:\n\nChapter 1: Basics\n\nText:\n\nWhy computing?\nComputer basics\nPrimer on programming\nIntroduction to Jupyter Notebook\nInstallation of Python and libraries\nIntroduction to Python\nPlotting in Python\nNumerical analysis and errors\nDifference between Python v2 and v3\n\n\nExamples:\n\nManning's equation for discharge calculation\nCalculation of $\\pi$ with Python\n\n\n\n\nChapter 2: Root finding\n\nText:\n\nRoot finding methods:\n\nbracketting methods: bisection method and false position method\nopen methods: Fixed-point iteration method, Newton's method, and Secant method\nPython libraries for root finding\n\n\n\n\nExamples:\n\nGreen-Ampt infiltration\nManning's equation for normal depth calculation\nBeam deflection\nFriction factor using the Colebrook-White formula\nParticle settling in fluid\nA step in open channel flow\n\n\n\n\nChapter 3: Curve fitting\n\nText:\n\nCurve fitting\n\nIntroduction\nLeast-square regression:\n\nlinear regression\nlinearizable nonlinear regression\npolynomial regression\nnonlinear regression\n\n\nInterpolation:\n\nNewton's divided-difference interpolating polynomials\nLagrange interpolating polynomials\n\n\nPython libraries for curve fitting\n\n\n\n\nExamples:\n\nFluid rheological data fitting\nFlow velocity profile in open channel flows\nWeir discharge coefficient\nSaturation growth rate\nSurface area vs storage volume for a reservior\n\n\n\n\nChapter 4: Linear system of equations\n\nText:\n\nLinear equation systems\n\nIntroduction and background\nGraphcial method\nDirect solution methods: Determinant and Cramer's rule, Gauss elimination method, Gauss-Jordan method, LU decomposition method\nIterative solution methods: Jacobi method, Gauss-Seidel method, SOR method\nAppendix: marix and vector operations in Python\n\n\n\n\nExamples:\n\n2D truss\nSteady state chemical reactor\nMaterial mixing\nDimensional analysis\nParabolic vertical road curves\n\n\n\n\nChapter 5: Numerical integration\n\nText:\n\nNumerical integration\n\nNewton-Cotes methods: trapezoidal rule, Simpson's rule, double and multiple integrals\nGauss quadrature\nPython libraries for numerical integration\n\n\n\n\nExamples:\n\nArc length\nCenter of mass\nConvolution integral\nDischarge across a section\nFouries series coefficients\nHydrostatic force and moment on plane surface\nProbability\n\n\n\n\nChapter 6: Numerical differentiation\n\nText:\n\nNumerical differentiation\n\nIntroduction\nDerivations of differential formulas: first-order, second-order, accuracy of numerical derivatives, some practical issues\nPython libraries for numerical differentiation\n\n\n\n\nExamples:\n\nHeat conduction along a rod\nGradient calculation\n\n\n\n\nChapter 7: Ordinary differential equations\n\nText:\n\nIntroduction and background\nInitial value problems\nBoundary value problems\nPython libraries for ODEs\n\n\nExamples:\n\nStreeter-Phelps model for water quality\nBackwater curve in open channels\nUnsteady batch reactor\nMass-spring-damper system\nPrey-predator model\nBeam deflection\nlaminar boundary layer\nConvective cooling\n\n\n\n\nChapter 8: Partial differential equations\n\nText:\nExamples:\n\nUnsteady diffusion\nLaplace equation\nTerzaghi 1D consolidation\nUnsteady advection-diffusion\nWaves\n\n\n\n\nChapter 9: Optimaizations\n\nText:\nExamples:\n\nBest hydraulic section in open channels\nTransportation cost\nOptimizing a 2D truss\n\n\n\n\nChapter 10: Statistics\n\nHow to contribute?\nA project like this will definitely benefit from the community. Contributions in the following categories are welcome:\n\nReport of bugs and errors in the text and code\nCEE-relevant examples (either just an idea or full implementation): my background in water resources engineering may skew the examples more toward what we call the \"wet\" side of CEE. Thus, examples from the \"dry\" side are especially welcome.\nSpecial topic suggestions: any topic not covered in the text but of relevance to the CEE profession.\n\nIf you want to contribute, either create a pull request or simply send an email to: xzl123@psu.edu.\nHow to cite?\nX. Liu (2020). Computing in Civil and Environmental Engineering. GitHub repository, https:\/\/github.com\/psu-efd\/Computing-in-CEE, DOI: 10.5281\/zenodo.3996772\nAcknowledgements\nThis work is partially supported by the Penn State CEE Harry West Teaching Award.\nLicense\nThis work is\nlicensed under a Creative Commons Attribution-NonCommercial 4.0 International License.\nIn essence, this work can be downloaded, used and re-distributed for non-commercial\npurposes. You are free to share and adapt under the terms of attribution and noncommercial.\nAuthor\nDr. Xiaofeng Liu (see web,\ntwitter) is an associate professor in the Department of Civil and Environmental Engineering at the Pennsylvania State University. With background in civil engineering and applied mathematics, his main research interest is computational hydraulics and environmental flows.\n","56":"enviro-dashboard\nDashboard stack for monitoring environment with InfluxDB + Grafana\n\nGrafana with InfluxDB running on Docker\n\nFind out more on the blog:\n\nCreate your very own environmental monitoring dashboard with Docker and the Raspberry Pi\n\n","57":"LoRa Environmental Sensors\n\nArduino based board for a Atmospheric Sensor BME280 LoRaWan Node. The LoRa Node measures barometric pressure, humidity, and temperature every 5 min. After the measurements, the ATtiny85 goes into sleep mode and is awakened by the watchdog timer. The RFM module sends the values to the TTN backend with Activation by Personalization (ABP) a fixed spreading factor and one of the four random channels. This project is based on the TinyLoRa-BME280 project [1].\nBOM\n\n\n\nRef\nValue\nDescription\n\n\n\n\nBT1\n3034\nBattery Cell Holder\n\n\nBT1\nCR2032\nBattery Cell CR2032 (210 \u2013 230 mAh)\n\n\nU1\nBME280\nSparkFun BME280\n\n\nU2\nATtiny85-20SU\nAtmel 8-bit AVR Microcontroller\n\n\nU3\nRFM95W-868S2\nLow Power Long Range Transceiver Module\n\n\n-\nWire\nWire for the antenna, 8.6 cm\n\n\n\nThe ATmega microprocessor needs an arduino bootloader. To burn a bootloader to the blank chip see [2]\nWiring\n\n\n\n\nATtiny85\nRFM95\nBME280\n\n\n\n\nPB3\n\nCS (Slave Select)\n\n\nPB4\nNSS (Slave Select)\n\n\n\nPB2\nSCK\nSCK\n\n\nPB1(DO)\nMOSI\nSDI\n\n\nPB0(DI)\nMISO\nSDO\n\n\n\nInstallation\nThe Arduino IDE has to be properly installed.\nAdd the Libraries to you IDE:\n\n\nInstall the Attiny Baord Manager\n\nUnder Preferences > Additional Boards Manager URLs: https:\/\/raw.githubusercontent.com\/damellis\/attiny\/ide-1.6.x-boards-manager\/package_damellis_attiny_index.json\n\nMultiple managers can be separated with a comma.\n\n\nInstall TinyLoRa-BME280 v1.1\n\nDownload the ZIP archive from TinyLoRa-BME280 v1.1\nInstall the ZIP archive in the Arduino Library Manager\n\n\n\nOpen Examples > TinyLoRa-BME280_v1.1-master > ATtiny_LoRa_BME280\n\nEdit NwkSkey, AppSkey, DevAddr\nChange the Spreading Factor in ATtinyLoRa.cpp\nThe Sleep time can be set with the SLEEP_TOTAL var.\n\n\n\nBurn the sketch to the Chip using an Arduino UNO [2]\n\nBurn a bootloader first to set the fuses correctly\n\n\n\nPayload Format\nThe Payload is encoded as byte array.\n\n\n\nbyte\ncontent\n\n\n\n\n0..1\ntemperature (*100)\n\n\n2..3\nhumidity (*100)\n\n\n4..8\nbarometric pressure\n\n\n\nTo decode the values add this code in the TTM Console as decoder under Paload Formats.\nfunction Decoder(bytes, port) {\n  temp = ((bytes[0]) << 8)\n              + ((bytes[1]));\n  hum = ((bytes[2]) << 8)\n              + ((bytes[3]));\n  pres = ((bytes[4]) << 24)\n              + ((bytes[5]) << 16)\n              + ((bytes[6]) << 8)\n              + ((bytes[7]));\n\n  return {\n    pressure: ( pres \/ 100 ),\n    temperature: ( temp \/ 100 ),\n    humidity: ( hum \/ 100 )\n  };\n}\n\nLinks\n\nTinyLoRa-BME280 v1.1\nProgramming ATtiny85 with Arduino Uno\n\nLicense\nLicense CC BY 4.0 - Attribution 4.0 International\n","58":"Environmentalist\nEnvironmentalist is a CLI utility for viewing the required environmental variables of a given node project.\nInstallation\nnpm install -g environmentalist\n\nJSON Format\nThe Environmentalist JSON format is very simple and is simply an array of objects, where each object is an environmentalist variable declaration.\nHere is what an environmentalist variable looks like:\n{\n\t\u201cname\u201d: \u201cPASSWORD_HASH_SECRET\u201d,\n\t\u201cdescription\u201d: \u201cUsed to compute the password hash of users\u201d,\n\t\u201cdefault\u201d: \u201cABCDEFGHIJKLMOP\u201d,\n\t\u201crequired\u201d: true\n}\nA full environmentalist.json file should look like this.\n[\n\t{\n\t\t\u201cname\u201d: \u201cPASSWORD_HASH_SECRET\u201d,\n\t\t\u201cdescription\u201d: \u201cUsed to compute the password hash of users\u201d,\n\t\t\u201cdefault\u201d: \u201cABCDEFGHIJKLMOP\u201d,\n\t\t\u201crequired\u201d: true\n\t},\n\t{\n\t\t\u201cname\u201d: \u201cLOG_LEVEL\u201d,\n\t\t\u201cdescription\u201d: \u201cSets the level that will be logged by the system\u201d,\n\t\t\u201cdefault\u201d: \u201cinfo\u201d,\n\t\t\u201crequired\u201d: false\n\t},\n\t{\n\t\t\u201cname\u201d: \u201cCRAZY_VARIABLE\u201d \n\t}\n]\nThe fields meanings are as follows:\nNAME IS THE ONLY REQUIRED FIELD, EVERYTHING ELSE IS OPTIONAL\nName: The Environmental variable name. This is what you would put after process.env if you were accessing it in the program. For example process.env.VARIABLE_NAME would have a name property of VARIABLE_NAME.\nDescription: A description of what the variable does in the application. This is just for ease of understanding and can be a string of any length but brevity is advised.\nDefault: A default value that can safely be used. If none is provided it will default to none. Do not include sensitive keys such as a SASS private key in the default, only use it to provide repository safe defaults to provide an easy way to setup environments. A good use case would be for a environmental variable that set the logging level, a bad use case would be a Amazon S3 private key.\nRequired: Required means that the application WILL NOT FUNCTION without the variable. This should only be used for environmental variables without which the system will error or otherwise cease to function correctly.\nCLI Usage\nTo run environmentalist simply run\nenvironmentalist\n\ninside the root directory of your package.\nEnvironmentalist will automatically analyse your package and all of its dependencies and return a table of all the environmental variables required and available from any environmentalist enabled package inside the directory chain.\nIssues and Pull Requests\nGitHub Issues is our issue tracker should any bugs or feature requests arise.\nPull Requests are also welcomed, but try to keep the code clean and well commented.\nLicense\nMIT License, use it, love it, fork it, sell it for ingots, whatever floats your boat.\nJust don\u2019t be evil. Having said that, if you find a way to make environmental variables evil I am impressed. But still don\u2019t do it.\nVersioning\nWe use Semantic Versioning. Yay for not breaking things!\n","59":"Phylogenetics for the Environmental Sciences \nWilliam D. Pearse, Marc W. Cadotte, Jeannine Cavender-Bares, Anthony R. Ives, Caroline Tucker, Steve Walker, and Matthew R. Helmus\n##Overview\nThis is the bleeding edge version of the package. Use at your own risk.\n##Read before submitting a feature request\/bug report\/pull request\nThank you! Please follow the simple rules below - that way everything is easier for everyone.\n\nIf you have a new idea for how the package should be structured, open an issue (tagged 'enhancement') to discuss it first. Many hands make light work, and there could be very good reasons that certain things are done in a certain way. Also, maybe we can all help!\nIf you fundamentally disagree with how a measure is calculated (e.g., you want PSE to be calculated on a square-root transformed phylogeny), then open an issue (tagged 'question') to discuss it. Again, there could be a very good reason for a design decision, and the existing authors of pez do have the right to refuse to implement something if they don't want the package to do it. You are, of course, welcome to fork pez and plough ahead without us :D\nIf you think you've found a bug, open an issue (tagged 'bug') that contains a fully reproducible example (http:\/\/stackoverflow.com\/questions\/5963269\/how-to-make-a-great-r-reproducible-example). We're always greatful for bug reports, and we'll try and get back to you quickly - but we can only realistically do that if you give us an example we can work with, and if you're polite to us in return.\nIf you have a feature request, open an issue (tagged 'enhancement') to discuss it. We're much more likely to be able to do it if you can be clear and concise about what you want. From past experience with programs and feature requests, I would ask that you're respectful of our time commitments - if you want us to write a new kind of analysis technique, it might be nice to bring at least one of us on-board as a collaborator :D\nIf you have written code and about to submit a pull request to have it merged into the main package, make sure:\n\nAll of the code you have written has some form of unit test coverage. WDP is not a massive fan of unit tests (https:\/\/willeerd.wordpress.com\/2014\/04\/07\/kill-your-unit-test-fetish\/), but they are useful in large projects like this.\nMake sure all the unit tests pass! If you re-name an internal function, it will break another part of the code-base. Check the tests using testthat::test_dir.\nIf you fix a bug, make sure there is an issue associated with it. Otherwise, someone else is quite likely to 'fix' it back!\n\n\n\nAgain, thank you for making pez even more awesome :D\n##Licence\nCopyright (c) 2015 William D. Pearse, Marc W. Cadotte, Jeannine Cavender-Bares, Anthony R. Ives, Caroline Tucker, Steve Walker, and Matthew R. Helmus\nThis program is free software: you can redistribute it and\/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\nThis program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.\nYou should have received a copy of the GNU General Public License along with this program.  If not, see http:\/\/www.gnu.org\/licenses\/.\n","60":"sensor.airthings_wave\n\n\n\n\n\n\n\n\n\nhassio support for Airthings Wave, Airthings Wave Plus, and Airthings Wave Mini BLE environmental sensors.\n\nMuch of the code to build this component was inspired by these projects:\n\nhttp:\/\/airthings.com\/raspberry-pi\/\nhttps:\/\/github.com\/marcelm\/radonwave\n\nThe aforementioned radonwave project is especially useful as it describes\nmany of the BLE characteristics specific to this product and has good\ntrouble-shooting tips. The script provided is also very useful in determining\nthe MAC address of your AW device. See here:\nhttps:\/\/github.com\/marcelm\/radonwave\/issues\/3\nGetting started\nDownload\n\/custom_components\/airthings_wave\/\n\ninto\n<config directory>\/custom_components\/airthings_wave\/\n\nExample configuration.yaml:\n# Example configuration.yaml entry\nsensor:\n  - platform: airthings_wave\n    scan_interval: 120\nOptional Configuration Variables\nmac\n(string)(Optional) The airthings_wave mac address, if not provided will scan for all airthings devices at startup\nscan_interval\n(string)(Optional) The interval between polls. Defaults to 300 seconds (5 minutes)\nLimitations\nIt may be possible that the Wave must be connected to the official app at least\nonce before you can use this program, so you will probably not get around\nregistering an account with Airthings.\nThe radon level history stored on the Wave itself cannot be accessed\nwith this component. To get around this, it connects regularly to the radon\ndetector.\nMake sure you install the latest firmware on the device using the official app\nfirst.\nKnown Issues\n\n\nNot yet able to specify the monitored_conditions configuration\n\n\nNo translations available yet\n\n\nHardware Requirements\n\n\nAn Airthings Wave OR Airthings Wave Plus OR Airthings Wave Mini\n\n\nA Raspberry Pi 3\/4 with built-in Bluetooth OR a Bluetooth adapter that supports Bluetooth Low Energy (BLE). such as this\none: https:\/\/www.amazon.com\/dp\/B01N5MGEUS\/ref=cm_sw_r_tw_dp_U_x_ObdNCb03P7QZJ\n\n\nOther Resources\n\nhttps:\/\/github.com\/marcelm\/radonwave\/issues\/1\nhttps:\/\/community.home-assistant.io\/t\/radoneye-ble-interface\/94962\nhttps:\/\/support.airthings.com\/hc\/en-us\/articles\/115002910089-How-to-respond-to-your-radon-levels?mobile_site=true\nhttps:\/\/community.home-assistant.io\/t\/converting-sensor-measurement-units\/98807\nhttp:\/\/certi.us\/Downloads\/Canada_Meas_BW.pdf\n\n","61":"gobrew\ngobrew lets you easily switch between multiple versions of go. It is based on rbenv and pyenv.\n\nInstallation\n\nThe automatic installer\n\nYou can install this via the command line with either curl or wget.\nvia curl\ncurl -L https:\/\/raw.github.com\/grobins2\/gobrew\/master\/tools\/install.sh | sh\nvia wget\nwget --no-check-certificate https:\/\/raw.github.com\/grobins2\/gobrew\/master\/tools\/install.sh -O - | sh\nThe manual way\n\n\n\nCheck out gobrew where you want it installed.\n $ git clone git:\/\/github.com\/cryptojuice\/gobrew.git ~\/.gobrew\n\n\n\nAdd the following to your shell config.\n export PATH=\"$HOME\/.gobrew\/bin:$PATH\"\n eval \"$(gobrew init -)\"\n\nNote:\n\n\nBASH: Add this to \/.bashrc (\/.bash_profile for Ubuntu users).\n\n\nZSH: Add this to ~\/.zshenv\n\n\n\n\nSource your shell config file (or reopen shell session).\n\n\nCommands\n\n: gobrew install\nInstall a specified version of Go.\n    $ gobrew install 1.5\n\n: gobrew uninstall\n    $ gobrew uninstall 1.5\n\n: gobrew use\nSets which version of Go to use globally.\n    $ gobrew use 1.5\n\n: gobrew workspace\nNote: 'gobrew workspace' echos the currently set workspace ($GOPATH). Use 'gobrew workspace set' to set your $GOPATH to the current working directory. Use 'gobrew workspace unset' to remove this setting.\n    $ cd \/path\/to\/workspace\n    $ gobrew workspace set\n    $ gobrew workspace unset\n\nVisit http:\/\/golang.org\/doc\/code.html#Workspaces for more on workspaces.\nUseful\nUpdates\nTo upgrade run update script from .gobrew source with:\n$ cd ~\n$ .\/.gobrew\/tools\/upgrade.sh\nUninstalling\nIf you want to uninstall it, just run\n    $ cd ~\n    $ .\/.gobrew\/tools\/uninstall.sh\n\nfrom the command line and it\u2019ll remove itself.\n","62":"AQUARIUS Examples Repo\n\nThe AQUARIUS Examples repository contains example projects demonstrating various integration techniques with the AQUARIUS Platform of environmental monitoring products.\n\n\nAQUARIUS Time-Series\nAQUARIUS Samples\nAQUARIUS WebPortal\n\nRepo organization\nThis repo is not a standard software git repository, with one branch building the latest-and-greatest version of the software.\nInstead, this repo is organized as a series of stand-alone project folders.\nEach project folder includes a README file that describes how to get started using the project.\nGetting Help\nSee the Wiki for an outline of the example projects.\nContributing\nContributions are always welcome, no matter how large or small. Before contributing, please read the code of conduct.\nSee Contributing.\n","63":"\nenvironmentalist\u00b6 \u2191\n\ngithub.com\/jtrupiano\/environmentalist\/tree\/master\n\nDESCRIPTION\u00b6 \u2191\nProvides an executable that converts a rails app's config structure.  The basic idea is that environments themselves are now first-class citizens, allowing you to create several environments (e.g. staging, prodtest, demo, etc.) in a clean, organized fashion.  Each environment is given its own folder where it can store its own set of configuration files (think mongrel configs, apache configs, etc.) without polluting the top-leve config\/ directory.\nREQUIREMENTS\u00b6 \u2191\n\nnone, but it's really only useful with a rails app\n\nINSTALL\u00b6 \u2191\nsudo gem install environmentalist\n\nUSAGE\u00b6 \u2191\nThis gem is intended to be a \u201cone-time consumption.\u201d  You use it once to alter\/convert the structure of your rails app (works best with a newly-generated app).  It should not be included as a gem dependency for your project.\nenvironmentalize \/path\/to\/rails\/root\n","64":"Environmental\n\nSummary\n\nlink:Cargo.toml[]\n\n\n\nDescription\n\nlink:src\/lib.rs[]\n\n","65":"Environmental\n\nSummary\n\nlink:Cargo.toml[]\n\n\n\nDescription\n\nlink:src\/lib.rs[]\n\n","66":"hydroPSO\n      \nhydroPSO is a global optimisation R package implementing a state-of-the-art version of the Particle Swarm Optimisation (PSO) algorithm (SPSO-2011 and SPSO-2007 capable), with a special focus on the calibration of environmental models.\nhydroPSO is parallel-capable, to alleviate the computational burden of complex models.\nhydroPSO is model-independent, allowing the user to easily interface any model code with the calibration engine (PSO), and includes a series of controlling options and PSO variants to fine-tune the performance of the optimisation engine. An advanced sensitivity analysis function together with user-friendly plotting summaries facilitate the interpretation and assessment of the calibration results.\nBugs \/ comments \/ questions \/ collaboration of any kind are very welcomed.\nArticles using hydroPSO\n\n\n\nYear\nJournal\nModel(s) \/ Application\nArticle\n\n\n\n\n2013\nEMS\nSWAT-2005, MODFLOW-2005\nA model-independent Particle Swarm Optimisation software for model calibration\n\n\n2013\nIEEE\nBenchmark functions\nStandard Particle Swarm Optimisation 2011 at CEC-2013: A baseline for future PSO improvements\n\n\n2013\nJoH\nLISFLOOD\nHydrological evaluation of satellite-based rainfall estimates over the Volta and Baro-Akobo Basin\n\n\n2014\nJCH\nMODFLOW2005-MT3DMS\nParticle Swarm Optimization for inverse modeling of solute transport in fractured gneiss aquifer\n\n\n2014\nJRSE\nSWAT\nSWAT model parameter calibration and uncertainty analysis using the hydroPSO R package in Nzoia Basin, Kenya\n\n\n2014\nGMD\nWALRUS\nThe Wageningen Lowland Runoff Simulator (WALRUS): a lumped rainfall-runoff model for catchments with shallow groundwater\n\n\n2014\nHESS\nWALRUS\nThe Wageningen Lowland Runoff Simulator (WALRUS): application to the Hupsel Brook catchment and the Cabauw polder\n\n\n2014\nHP\nTravel time distributions\nConsequences of mixing assumptions for time\u2010variable travel time distributions\n\n\n2015\nHP\nHBV\nA coupled hydrology-biogeochemistry model to simulate dissolved organic carbon exports from a permafrost\u2010influenced catchment\n\n\n2015\nHESS\nLISFLOOD\nGlobal warming increases the frequency of river floods in Europe\n\n\n2015\nHESS\nLISFLOOD\nA pan-African medium-range ensemble flood forecast system\n\n\n2015\nEE\nMARS-based\nHybrid PSO-MARS-based model for forecasting a successful growth cycle of the Spirulina platensis from experimental data in open raceway ponds\n\n\n2015\nMJ\nMalaria transmission\nPredicting the impact of border control on malaria transmission: a simulated focal screen and treat campaign\n\n\n2016\nSC\nStock Market\nNatural combination to trade in the stock market\n\n\n2016\nEMS\nSWAT-VSA\nCoupling the short-term global forecast system weather data with a variable source area hydrologic model\n\n\n2016\nJoH-RS\nLISFLOOD\nAssessing the role of uncertain precipitation estimates on the robustness of hydrological model parameters under highly variable climate conditions\n\n\n2016\nNHESS\nLISFLOOD\nModelling the socio-economic impact of river floods in Europe\n\n\n2017\nEP\nWALRUS-paddy+PDP\nHydrology and phosphorus transport simulation in a lowland polder by a coupled modeling system\n\n\n2017\nHP\nSWAT\nThe value of remotely sensed surface soil moisture for model calibration using SWAT\n\n\n2017\nIS:CLS\nGenetics\nReconstructing Genetic Regulatory Networks Using Two-Step Algorithms with the Differential Equation Models of Neural Networks\n\n\n2017\nBioener.\nEPIC\nThe greenhouse gas intensity and potential biofuel production capacity of maize stover harvest in the US Midwest\n\n\n2017\nSustain.\nSWAT, GSWAT\nDevelopment of an Evapotranspiration Data Assimilation Technique for Streamflow Estimates: A Case Study in a Semi-Arid Region\n\n\n2017\nCSR\nClustering colors\nClustering colors\n\n\n2017\nPLoS ONE\nPartitioning of color space\nDoes optimal partitioning of color space account for universal color categorization?\n\n\n2017\nHESS\nIsotope analysis\nPesticide fate on catchment scale: conceptual modelling of stream CSIA data\n\n\n2017\nHESS (in review)\nDissolved organic carbon\nHydrological control of dissolved organic carbon dynamics in a rehabilitated Sphagnum-dominated peatland: a water-table based modelling approach\n\n\n2018\nAntrop.\nWALRUS\nHydrologic impacts of changing land use and climate in the Veneto lowlands of Italy\n\n\n2018\nJoH\nSoil moisture model (in R)\nCan next-generation soil data products improve soil moisture modelling at the continental scale? An assessment using a new microclimate package for the R programming environment\n\n\n2018\nAWM\nSWAT\nAssessing the impact of the MRBI program in a data limited Arkansas watershed using the SWAT model\n\n\n2018\nEMA\nAir quality\nAir Quality Modeling Using the PSO-SVM-Based Approach, MLP Neural Network, and M5 Model Tree in the Metropolitan Area of Oviedo (Northern Spain)\n\n\n\nInstallation\nInstalling the latest stable version from CRAN:\ninstall.packages(\"hydroPSO\")\n\nAlternatively, you can also try the under-development version from Github:\nif (!require(devtools)) install.packages(\"devtools\")\nlibrary(devtools)\ninstall_github(\"hzambran\/hydroPSO\")\n\nReporting bugs, requesting new features\nIf you find an error in some function, or want to report a typo in the documentation, or to request a new feature (and wish it be implemented :) you can do it here\nCitation\ncitation(\"hydroPSO\")\n\nTo cite hydroPSO in publications use:\n\nZambrano-Bigiarini, M. and Rojas, R. (2013). A model-independent Particle Swarm Optimisation software for model calibration, Environmental Modelling & Software, 43, 5-25, doi:10.1016\/j.envsoft.2013.01.004.\n\n\nZambrano-Bigiarini, M. and Rojas, R. (2018). hydroPSO: Particle Swarm Optimisation, with Focus on Environmental Models. R package version 0.4-1. URL https:\/\/cran.r-project.org\/package=hydroPSO. DOI:10.5281\/zenodo.1287350.\n\nBibTeX entries for LaTeX users are\n\n@Article{Zambrano-BigiariniRojas2013-hydroPSO_article,\ntitle = {A model-independent Particle Swarm Optimisation software for model calibration},\njournal = {Environmental Modelling & Software},\nauthor = {Zambrano-Bigiarini, M. and Rojas, R.},\nvolume = {43},\npages = {5-25},\nyear = {2013},\ndoi = {10.1016\/j.envsoft.2013.01.004},\nurl = {https:\/\/doi.org\/10.1016\/j.envsoft.2013.01.004},\n}\n\n\n@Manual{Zambrano-BigiariniRojas-hydroPSO_pkg,\ntitle = {hydroPSO: Particle Swarm Optimisation, with Focus on Environmental Models},\nauthor = {Mauricio Zambrano-Bigiarini and Rodrigo Rojas},\nyear = {2018},\nnote = {R package version 0.4-0. doi:10.5281\/zenodo.1287350},\nurl = {https:\/\/CRAN.R-project.org\/package=hydroPSO},\n\nVignettes\n\n\nHere you can find a vignette showing how to use hydroPSO to calibrate parameters of the GR4J hydrological model, which belongs to the airGR family of models.\n\n\nHere you can find a vignette showing how to use hydroPSO to calibrate parameters of TUWmodel.\n\n\nHere you can find a vignette showing how to use hydroPSO to calibrate parameters of SWAT-2005 and MODFLOW-2005.A similar approach can be used to calibrate SWAT-2012 or other models that need to be run from the system console.\n\n\nThe file MF2005.zip, with all the necessary files to run the MODFLOW-2005 examples in the vignette, contains 3 Windows binary files: mf2005.exe, preproc.exe and zonbud_hydroPSO.exe. These binary files are distributed in the hope that they will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  In no event shall the authors be liable for any CLAIM, DAMAGES or other LIABILITY, whether in an action of contract, tort or otherwise, arising from, out of or in connection with the software or the use or other dealings in the software.\n\n\nThe file SWAT2005.zip , with all the necessary files to run the SWAT-2005 examples in the vignette, contains 1 Windows binary file: swat2005.exe and  1 UNIX binary file: swat2005.out. Those binary files are distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  In no event shall the authors be liable for any CLAIM, DAMAGES or other LIABILITY, whether in an action of contract, tort or otherwise, arising from, out of or in connection with the software or the use or other dealings in the software.\n\n\n\n\nRelated Material\n\n\nhydroPSO: A Versatile Particle Swarm Optimisation R Package for Calibration of Environmental Models (EGU-2012) abstract, poster.\n\n\nR: a statistical environment for hydrological analysis (EGU-2010) abstract, poster.\n\n\nSee Also\n\n\nhydroGOF: Goodness-of-fit functions for comparison of simulated and observed hydrological time series.\n\n\nhydroTSM: Time Series Management, analysis and interpolation for hydrological modelling.\n\n\nFeedback\nGive us your opinion !.\n","67":"WorldManager (WAPI)\nWorld Manager (WAPI) is a generic world and environment command and control system for Unity that enables environmental assets to play nicely together.\nIt does this by providing a simple but powerful interface that allows you to control the components that render your environment a generic and coordinated way.\nThe intention is to bridge the gap between assets and make it easier to develop games by plugging them together using a common API. You will still configure your assets individually to your own taste, but coordination and control is generic and centralised.\nAssets can choose which parts of the API they implement and regardless of how much they support, you will get value from this system because of the way it coordinates their behaviour.\nAdditionally, WAPI introduces a global set of shader variables, so that any shader that implements WAPI will automatically be updated when settings change without requiring the overhead associated with the subscription mechanism.\nWAPI is free for you to use any way you like. It will be professionaly maintained, and will also be packaged up as a free unity asset (soon). For more information on WAPI go to http:\/\/www.procedural-worlds.com\/blog\/wapi\/.\nWAPI was created by Adam Goodrich, the author of Gaia, GeNa, CTS - The Complete PBR Terrain Shader, and Pegasus. Adam is a specialist in environmental and procedural generation in Unity, and this project was born out of his frustration with getting things to work nicely together. If you would like access to his free monthly newsletter with tips, tricks, reviews and freebies then sign up on his home page at http:\/\/www.procedural-worlds.com\/.\nBasic Usage Pattern\nTo enable and disable all events, update and lateupdate\nWorldManager.Instance.WorldAPIActive = true\/false;\nTo generate events, and get and set values use the following generic format e.g.\nWorldManager.Instance.Api();\nvar value = WorldManager.Instance.Property;\nWorldManager.Instance.Property = value;\nTo receive events when values are changed implement your own listener via the IWorldApiChangeHandler interface and then connect it up e.g.\npublic class WorldController : MonoBehaviour, IWorldApiChangeHandler\n{\n    .. your stuff..\n\n    void Start()\n    {\n        ConnectToWorldAPI();\n    }\n\n    \/\/Let world manager API know you want to handle events\n    void ConnectToWorldAPI()\n    {\n        WorldManager.Instance.AddListener(this);\n    }\n\n    \/\/Let world manager API know that you are no longer interested\n    void DisconnectFromWorldAPI()\n    {\n        WorldManager.Instance.RemoveListener(this);\n    }\n\n    \/\/If this object has been added as a listener then it will be called whenever an event is fired,\n    \/\/use the changeArgs.HasChanged method to filter for the events you are interested in\n    public void OnWorldChanged(WorldChangeArgs changeArgs)\n    {\n        if (changeArgs.HasChanged(WorldConstants.WorldChangeEvents.GameTimeChanged))\n        {\n            \/\/Grab game time\n            m_timeNow = (float)changeArgs.manager.GetTimeDecimal();\n\n            \/\/Do whatever logic you want\n            m_timeNow += 0.25f;\n\n            \/\/Set it back into world manager -> NOTE you would never do THIS SPECIFIC THING\n            \/\/as this will cause another OnWorldChanged event to be generated, which would in turn\n            \/\/cause this to be executed again in one nasty loop\n            WorldManager.Instance.SetDecimalTime(m_timeNow);\n        }\n    }\n}\n\nTake a look at WorldController.cs for a simple example of how to use the API. It both listens to things\nand also implements a simple user interface that controls it in the editor and at runtime.\nTo use as global variables in shaders the general naming standard is _WAPI_[PropertyName], however in many instances the data has been stored in vectors for efficient transfer to the GPU, so take a peek at the code to get the naming. At the very least however all shader variables are prefixed with _WAPI_.\nAPI Categories\n\nIsActive\nTime\nPlayer Location, Sea Level, Latitude & Longitude\nTemperature and humidity\nWind\nFog\nRain\nHail\nSnow\nThunder\nClouds\nMoon\nSeason\nSound Levels\nExtensions\nSerialisation\n\nSerialisation system\nThe serialisation system allows you to manage the process of saving and loading WAPI data. The choice of when to do this and how to store the serialised data are up to you.\nExtension system\nThe extension system allows you to create your own extension sub classes and add them to WAPI to be managed. You could add additional game state information as well handlers for Update and LateUpdate and have them called on your extensions when World Manager updates. Just derive your class from WorldManagerExtension, and add it to the extensions list.\n","68":"SWEET Ontologies\n on channel #sweetontology\n\nIntroduction\nOfficial repository for Semantic Web for Earth and Environmental Terminology (SWEET) Ontologies.\n\n\n\nView in pyLODE\nView in WebVowl\nView in ESIP COR\n\n\nView in GitHub\nView raw RDF\nDownload RDF\n\n\n\nWhat is SWEET?\nSWEET is a highly modular ontology suite with ~6000 concepts in ~200 separate ontologies covering Earth system science. SWEET is a mid-level ontology and consists of nine top-level concepts that can be used as a foundation for domain-specific ontologies that extend these top-level SWEET components. SWEET\u2019s own domain-specific ontologies, which extend the upper level ontologies, can provide users interested in further developing a particular domain with a solid set of concepts to get started. SWEET ontologies are written in W3C Turtle; the Terse RDF Triple Language and are publicly available under the Apache License v2.0.\nSWEET as Linked Data\nDetails of how HTTP requests against http:\/\/sweetontology.net are processed can be found here.\nSWEET IRI Patterns for Ontologies and their Terms\nSee the relevant wiki documentation.\nCommunity\nSWEET is governed by the ESIP Semantic Technologies Committee (STC) meaning that all proposed changes are evaluated by a number of subject matter experts. If you would like to learn more about SWEET, or are interested in joining the community, please join our community mailing list.\nRecognition of SWEET Contributors\nEnsure you are recognized for your contributions.\nDevelopment\nPlease see the CONTRIBUTING documentation.\nAdditionally, if you wish to discuss SWEET issues with the STC, please contact us via the WG email list.\nUsing local copies of ontology\nThe sweetall.ttl ontology imports all the other sweet components via URL. If you are offline, or working on updates that require using the local copies of the ontology files, copy the catalog-v001.xml file from the root directory of the repository into the src directory before opening sweetAll.ttl in Protege.\nLicense\/Copyright\nSWEET is available under the CC0 1.0 Universal Public Domain Dedication.\n\n\n\n\n\n  To the extent possible under law,\n  \nSWEET Ontology Developers\n  have waived all copyright and related or neighboring rights to the\n  Semantic Web for Earth and Environmental Terminology (SWEET) Ontology Suite.\n\nA copy of the CC0-1.0 ships with this repository.\nPrior to SWEET 3.5.0, SWEET was licensed under the Apache License v2. For more information on the change, see here.\n","69":"GoGreen\nDeprecated\nSee the following projects to see where this code has migrated to...\n\nhttps:\/\/github.com\/leoloobeek\/keyring\nhttps:\/\/github.com\/leoloobeek\/keyserver\n\n","70":"Wheat yield prediction for United States by enviromental features\nThis repository is an example of how to predict winter wheat yield for several counties in the United States.\nSource from https:\/\/github.com\/aerialintel\/data-science-challenge\nA brief description of the problem and how you chose to solve it.\n\nThe problem is we would like to predict the winter weather yield in the United States by a given geolocation (e.g., latitude and longitude). The dataset includes two years 1.) location and time such as county name, state, latitude, and longitude, 2.) and raw weather features such as temperature, precipitation, wind speed, and pressure, and 3.) raw crop physiological features such as NDVI, day in season, and yield (label).\nDue to the natural of data included weather variables, I immediately recalled using weather features to conduct crop modeling by WOFOST model (http:\/\/bit.ly\/2jnY8mw) to produce the predicted yield compared to the actual yield (label). In the model, this is several specific winter wheat modules can be used for yield prediction. Pressure and temperature will be used to calculate the ET demand, and leaf area index (LAI) will be calculated by grows degree days (GDD) accumulation.\nHowever, due to time constraint, I decided to try different machine learning algorithms by scikit learn library includes linear regression, SVM, and DecisionTree etc. to train the model for predicting yield.\n\nA high level timeline telling us what you tried and what the results from that were\n1.Data wrangling:\n\nRead two .csv files and use pandas library to stack them to a single one. The reason is for training the model; it's better to have more yield data. The year variation might be considered due to the weather variability in two years. However, due to high genotype and environment interaction (G x E), the year variation can be ignored.\nSeveral unnecessary columns were dropped. Due to data entry is on a daily base, features such as precipitationType and windBearing are not important. Two types of weather features in the dataset are important, temperature and accumulated precipitation. Because temperatureMax and temperatureMin, which determines the daily accumulated heat (GDD = (temperatureMax + temperatureMin) \/2 - TemperatureBase). This is the key to deciding how fast the wheat will grow. Also, the minimum temperature is important for winter wheat because it needs vernalization (cold temperature) to inducing flowering. Another feature is precipitation, which determines if wheat can get enough water supply. The accumulated precipitation is more important than its form or intensity unless some region gets flooded. DayInSeason determines will wheat can grow longer. The longer it grows, the more biomass (yield) it can accumulate.\nThe kept columns included precipAccumulation,average temperature,temperatureMin,temperatureMax,DayInSeason, NDVI ,Yield.\n\n2.Quality control of the data:\n\nThe accumulated precipitation was 19 inches maximum which makes sense since most of the winter wheat region are relatively dry.\nThe temperatureMax is greater than temperatureMin which is valid.\nThe NDVI values are not in a range of 0 to 1. After plotting NDVI, there is no pattern of increase NDVI in the middle of the season and decrease at the end of the season. Thus, NDVI is not considered.\n\n3.Model selection:\n\nLinear regression. Model: Yield ~ precipAccumulatio + TemperatureAverage + temperatureMin + DayInSeason\nVery low accurary\/score: 0.04 , (accuracy = clf.score(X_test, y_test))\nSVM (polynomy): computer not respond\nDecisionTree: computer crushed\n\n4.Iteration:\nDue to the low accuracy, including dropped weather features in training to see whether the accuracy will increase\n\nRegression. Model: Yield ~ all features except CountyName, State, and Date\nAccracy increased: 0.23 (accuracy = clf.score(X_test, y_test))\nSVM (polynomy): computer not respond\nDecisionTree: 0.48, (scores = cross_val_score(clf, X, y))\n\nWhat your final \/ best approach was and how it performed\n\nDecisionTree returns an 0.48 accuracy score which can barely predict yield. Linear regression is worse.\n\nTechnical choices you made during the project\nAlgorithms:\n\nRegression: simple, avoid overfitting.\nSVM (polynomial): catch interaction weather features\nDecisionTree: when have a lot of \u201cleaves\u201d, in our case the yield values\n\nTools:\n\nPython\npro: easy to test multiple machine learning algorithms (most of time one line of code)\ncon: familiarity not\nR\npro: familiar\ncon: fewer libraries in machine learning compared with python. Later on, not easy to scale up the code.\nTraditional crop model software\npro: robust mechanistic models built in and tested. Can directly generate predicted wheat yield based on weather feature and crop physiological process, and conduct a one vs. one comparison.\ncon: cannot scaling up unless rewrite in python.\n\nWhat challenges or compromises did you face during the project?\nChallenges\n\nTraining: the features are time series data, while the label is time point. The mismatch caused when training the data each time footprint printed to the same yield for the same county. This can cause a problem a label is not directly corresponding to a feature value at one day rather than a set of feature group by a county (geolocation). Also, if the NDVI value is actual true NDVI, It can actually correspond to yield better because NDVI has a strong correlation with leaf area index (LAI), which is a strong indicator of how well the crop conducts photosynthesis during the season and the biomass of the crop.\nMissing feature: The difficulty was weather feature should have a geo-boundary because the environment effect on winter wheat will be different compare the wheat grow in northern to that grow in southern.\nCoding: When conduct cross-validation, I get stuck on the value error of setting an array element with a sequence, which causes unequal X-train and y_train. The potential solution is to add additional values to the missed values in that array to form a 2D array which matches all the 1D array dimensionally.\n\nWhat did you learn along the way?\n\nFounding 1: The more features included in a model may slight improve the accuracy. However, the \"right\" feature included in the model can significantly improve predicting accuracy. For example, when I exclude latitude and longitude from the model, the accuracy score drops to 0.1. While when I include the latitude and longitude, the accuracy score includes to 0.23.\nProblem 1: Use one\/multiple time series features (weather data) to train and predict one label (one yield value) may not be the best way to predict yield. Especially when the yield is strongly related to the cultivar used (missed in the dataset) and environment condition (weather, soil, and geolocation), only use seasonal weather data to train the model to predict yield is inadequate.\nSolution 1: add geolocation related data to the dataset which representative geo-features. Such as soil features, what soil type for the given geolocations. Soil type is very important in yield prediction. For example, Farmers business network, a farmer data platform, has tested the cultivar type and soil type combination are the most important interaction which affects corn yield.\nProblem 2: I haven\u2019t found the right machine learning algorithms.\nSolution 2: Spend more time on exploring other algorithms.\n\nIf you had more time, what would you improve?\nThe part I would improve if I have more time:\n\nUse the deep neural network to predict the yield. The reason the deep learning outperforms many other algorithms. Literature has been reported to use ANN for wheat yield prediction. http:\/\/ieeexplore.ieee.org\/document\/7006239\/?reload=true . Moreover, if the google Deepmind's Neural Programmer-Interpreters (NPIs) algorithm has developed matured, I will choose to use this algorithm https:\/\/arxiv.org\/abs\/1511.06279 . Neural Programmer-Interpreters is a recurrent and compositional neural network that learns to represent and execute programs. It mimics simple models human has learned, and use less training time to get higher accuracy.\n\nAnd I also would like to add additional higher level features.\n\n\n\nEvapotranspiration (ET) (a sample code for calculating ET is uploaded). Use FAO54 Penman-Monteith method to calculate reference ET for wheat. Use the weather features such as solar radiation (pysolar library), temperature, relative humidity, and wind speed to calculate ET. ET describes the water demand of the crop from the environment.\n\n\n\n\nSoil data. Access SSURGO database to get the soil property which can determine how many water the soil can hold and provide to the crop. This part describe the water supply from soil.\n\n\n\n\nThe ratio of ET\/soil water is a good indicator of if crop will have sufficient water during season, thus affect its yield.\n\n\n\n\nUse WOFOST crop model modules to generate higher crop features such as LAI, total above ground biomass, daily dry matter increase rate. Those features may add accuracy to predicting yield.\n\n\n\n","71":"Libaudioverse\n\n\nGitHub\nI'm trying to raise money for this project, so I can put a few months of full-time work into it. Consequently, we have a GoFundMe.\nIntroduction\nLibaudioverse is a highly flexible realtime audio synthesis library designed to be bound to as many languages as possible.\nPotential applications include games, realtime music synthesis, voice chat, implementations of WebAudio, and more.\nLibaudioverse supports the best possible backends it can for each platform, and uses both SSE2 and threads for increased performance.\nAt the core of Libaudioverse is the concept of a node,  a piece of meaningful audio architecture.\nThey can be connected in any acyclic configuration, allowing the creation of much more complex effects.\nIt is possible to schedule property changes and envelopes with sample-perfect accuracy;.\nFor more complex effects, nodes can be connected directly to the properties of other nodes.\nhere is an overview of the offered nodes:\n\nThe environment and source nodes come together to act as a fully functional 3D audio environment, including support for HRTF, surround sound, and reverb.\nThe FDN reverberator is an environmental reverb capable of representing everything from a bathroom to a cathedral.\nIf you want to play with Schroeder Allpass sections, try the nested Allpass Network node.\nA variety of lower-level filters are available: Biquad, first-order, one-pole, and convolution.\nIt is possible to implement any IIR filter, either by cascading lower level filters or by using the IIR filter node directly.\nOscillator options include sine and square, as well as a configurable noise generator.\nthere are several delay line types.  Most delay lines offer support for feedback, and the filtered delay line allows filtering this feedback.\nYou can record audio with the recorder, or intercept audio anywhere in the graph of nodes with the graph listener.\nFinally, if none of these meet your needs, it is possible to create your own node via the custom node.\n\nNOTE: This is pre-alpha and supports Windows and Linux.  Mac is planned.\nLicensing\nSee the file COPYRIGHT for the legalese.  This file is definitive, and the following a summary only.\nThe non-legalese version is that Libaudioverse is dual-licensed under\nGPL V3 or later (see here for GPL V3)\nand MPL2.\nDocumentation and Examples\nThere are two sources of Libaudioverse documentation.\nThe first is the language-agnostic manual, which discusses Libaudioverse from a general perspective.\nThis manual contains the reference for the C API and an overview of Libaudioverse's core concepts.\nMost examples in this manual are in Python.\nThe second source of documentation is the API reference for your language of choice.\nAt the moment, this means the Python API reference.\nThe API references contain installation instructions and any notes specific to the language in question.\nExamples for all supported languages may be found in the GitHub repository.\nThese sets of examples aim to be equivalent and to demonstrate most critical features of Libaudioverse.\nThis library is easy.\nIn many cases, the examples will be enough to get you started.\nGetting Help\nLibaudioverse has a Google Group.\nYou can subscribe directly and without a Gmail address via e-mailing an empty e-mail to libaudioverse+subscribe@camlorn.net and clicking the link in the confirmation e-mail sent to you.\nI prefer questions to come via this avenue, as it results in your answers being searchable in future.\nIf you need to contact me in real-time, you can do so via the Libaudioverse IRC channel: #libaudioverse on chat.freenode.net.\nPlease report bugs and make feature requests using the GitHub issue tracker; this saves me time for issues which I cannot fix immediately.\nBuilding\nSee the info on supported platforms and build instructions.\nBindings\nAt the moment, Python and C are the only supported languages.  You can get the Python bindings via pip on Windows, but Linux currently requires building Libaudioverse yourself.  As more languages become available, Libaudioverse  will attempt to upload binaries to package managers.  The goal is to minimize the number of use cases that require building Libaudioverse.\nLibaudioverse's approach to bindings is such that it is possible to add more languages in short order.  If you are seriously considering using Libaudioverse in a specific language, I wish to talk to you.  The addition of a new language is mostly a one-time process, after which the bindings literally maintain themselves.  Which language I add next is primarily based on interest.\nNote: Your language must support C callbacks, at least 2 levels of pointer indirection and thread primitives in order to be successfully bound to Libaudioverse. The only language I am currently aware of that fails to implement these three things is Angelscript in the BGT scripting environment.\n","72":"sensu-plugins-environmental-checks\n \n\n\n\n\nFunctionality\nPlugin to collect environmental metrics (e.g. temperatures, power draw).\nmetrics-temperature.rb\nparameters\n\n--scheme: The scheme to concatenate the metrics with (default: HOSTNAME.sensors)\n\nmetrics\nMultiple chips are supported and labelled by the chip name (e.g. sensors.coretemp-isa-0000.core0, sensors.i350bb-pci-8100.loc1). Depending on the chip you will get different metrics.\n\nsensors.CHIPNAME.coreCORE_NUMBER: Temperature of the core (Degree Celsius)\nsensors.CHIPNAME.locLOCATION_NUMBER: Temperature of the location (Degree Celsius)\nsensors.CHIPNAME.physicalidCPU_NUMBER: Temperature of the CPU as a whole (Degree Celsius)\nsensors.CHIPNAME.powerNUMBER: Power draw of the machine (Watt)\n\nIf you do not get all of the listed values, your mainboard probably does not support the features. To check, you can query it yourself by running sensors or sensors -A respectively.\ncheck-temperature.rb\nchecks\nMaps high and crit values as reported by lm-sensors to warning and critical status respectivley.\nUsage\nTo collect metrics with the scheme of your choice:\nmetrics-temperature.rb --scheme YOUR_SCHEME_HERE\n\nInstallation\nsensu-install --plugin sensu-plugins-environmental-checks\n\nIn order to use this plugin you will the need sensors installed. Prepackaged versions exist, e.g. the Ubuntu package is named lm-sensors.\nFor more help see Installation and Setup.\n","73":"microbiomeSeq\nAn R package for microbial community analysis in an environmental context\nThis package is developed to enhance the available statistical analysis procedures in R by providing more\nanalysis produre and visualisation of results for microbial communities data obtained from 16S rRNA. See full details of the usage and dependencies at\nmicrobiomeSeq tutorial.\nMain Features\n\nAlpha and Beta diversity\nDifferential abundance analysis.\nEffects of environmental variables on community structure.\nCo-occurence pattern analysis in community data.\n\n\nInstallation\nInstall the package with its associated dependencies and load it for usage in R.\nlibrary(devtools)\ninstall_github(\"umerijaz\/microbiomeSeq\") \nlibrary(microbiomeSeq)\n\nData format\/requirement\nThe data is required to be a phyloseq object (of phyloseq-class) comprising taxa abundance information, taxonomy assignment,\nsample data which is a combination of measured environmental variables together with any categorical variables present in\nthe samples. If the phylogenetic tree is available, it can also be part but not so relevant for most of the functionality\nimplemented here so far.\nWe choose to use this format since we can have enormous options for\nmanipulating the data as we progress with the analysis and\nvisualisations. Details of format and comprehensive manipulations\nof phyloseq objects are available at phyloseq page.\n","74":"ESPlant - Environment Sensor Plant\nWelcome to the linux.conf.au Open Hardware Project.  You can see information about this and other MiniConfs at http:\/\/www.openhardwareconf.org\/wiki\/Main_Page\nThe ESPlant kit is designed to provide an open source platform to transmit environmental data to a central source using the power of wifi.\nAssembled PCB:\n\nPrototype board in action (before significant changes):\n\nCheck out a video of pick-n-placing components of the boards you'll be getting at LCA 2016.\nhttps:\/\/www.youtube.com\/watch?v=282qku2C4xo\nFEATURES\n\nESP8266 WiFi enabled microcontroller. You can program it via the Arduino IDE, or alternatively Espressif SDK or esp-open-rtos.\nSecondary microcontroller (STM32F042) acts as USB\/Serial interface and i2c Analog to Digital Converter\nBattery holder for 16340 sized 3.7V lithium cell\nLithium battery charger interface (solar input friendly)\nBoard automatically switches power source between solar input, battery, and USB power as applicable.\n\nOnboard Sensors (on I2C bus)\n\nBME280 Temperature\/Humidity\/Barometric Pressure sensor\nADXL345 accelerometer\n\nExternal Sensors (all optional, connected to screw terminals)\n\n2x soil moisture sensors (via ADC pins)\nDS18B20 connected to GPIO 12.\nPIR (infrared motion) sensor connected to GPIO 15.\nWS2812B LED strip connected to GPIO 13 (mislabelled as 15 on V1.3 PCB!)\n\nThe 3.3V \"VSens\" power rail is switchable on\/off by the microcontroller. It defaults to unpowered (off). The GPIO to use is 14, and it is active low (ie driving the output low turns VSens on, driving it high turns it off).\nAssembly Steps\nAssembly guide on the wiki.\nUsing with Arduino\nTo add ESP8266 support to the Arduino IDE (1.6.6 or newer) we use the external ESP8266 Arduino project. We need the staging version not the stable version of the ESP8266 support package.\nFollow these steps to install:\n\nInstall Arduino 1.6.6 or newer (1.6.7 is fine) from the Arduino website.\nStart Arduino IDE and open Preferences window.\nEnter http:\/\/arduino.esp8266.com\/staging\/package_esp8266com_index.json into Additional Board Manager URLs field. You can add multiple URLs, separating them with commas.\nFrom the Tools menu choose Board -> Board Manager\nA window will open. Search for ESP8266.\nChoose a version from the drop-down in the bottom right. There will probably only be one shown there.\nClick Install\n\nConnecting ESPLant to your computer\n\nNo drivers required on Linux, OS X, or Windows 10.\nNo manual reset or button pressing dance required to program.\nIn ESP8266 Arduino IDE, under Tools menu, set Board to \"NodeMCU V1.0\" (fully compatible).\nCan set upload speed to 230400. 460800 works in most cases (you might get occasional failures at 460800)\n\nGetting ESPlant\nYou need to clone the ESPlant repo from github, using the --recursive option to pick up submodules. If you download a zip file then the submodule parts will be missing, so we recommend using git to get it.\nThe command is:\ngit clone --recursive https:\/\/github.com\/CCHS-Melbourne\/ESPlant\n\nLibraries you will need\nArduino uses libraries to work with additional hardware or software functionality in an easy way. Normally you can download and install libraries directly inside the Arduino IDE by choosing Sketch menu -> Include Library -> Manage Libraries.\nOne library that you should install this way is the OneWire library. Search for \"OneWire\" and then click the Install button to install it.\nFor the ESPlant the other required libraries are set up as \"git submodules\" inside the \"Libraries\" directory. If you did a \"recursive\" clone then you will have these, otherwise you can add them to a \"normal\" clone by running this command:\ngit submodule update --init\n\nInside the Libraries directory there is a script install_libraries.sh that you can run on Linux or OS X to symlink all of the libraries into your Arduino libraries directory so you can use them.\ncd Libraries\n.\/install_libraries.sh\n\nOn Windows you'll need to copy all the subdirectories of the libraries directory (copy them into the My Documents\/Arduino\/libraries directory).\nThe one Library here that is part of this repo (not a submodule) is the \"ESP_Kwai\" library that acts as a bridge to the peripheral hardware.\nDon't forget OneWire as well (see above).\nUpload your first program (\"sketch\")\nAfter restarting Arduino IDE to pick up the new libraries, you're ready to upload your first program (Arduino calls them \"sketches\"):\n\nChoose File->Open in Arduino and open the Firmware\/ESPlant_serial_sensor from this repository. This is a simple sketch that outputs all the analog values read by the board.\nPress the \"Upload\" button to send it to your board. Watch for messages indicating the upload was successful.\nOpen the serial monitor (under Tools) and set the baud rate to 115200 in order to watch the output from the sketch.\n\nOther Sketches to Try\nThe repo includes the following sketches:\n\n\nESPlant_prodtest is the hardware production test. It tests all the sensors to confirm the hardware is good. There are instructions in a large comment at the top of the sketch. You can run this if you think you're having hardware problems, or to look at example code for any individual point.\n\n\nESPlant_MQTT_sensor uses MQTT to push data to a server. It includes easy provisioning mechanisms for connecting to the WiFi. It has other instructions in its README file for WiFi configuration.\n\n\nWhere to Now?\nCheck out (and contribute to) the wiki. There is a pinout summary, sensor summary, power information, etc.\nOnboard STM32\nThere is an onboard STM32 microcontroller that acts as USB\/Serial converter and an i2c connected ADC (Analog\/Digital Converter) device.\nFor the i2c functionality, the ESP_Kwai library (under Libraries\/ESP_Kwai) acts as a bridge (get it) to the i2c ADC peripherals on the ESPlant. It can automatically read all the values connected to the ADC and return them.\nIf you want more information on how the STM32 works internally, check out the README in the STM_Firmware directory.\nCREDITS\nThis project was designed by the 2016 linux.conf.au Open Hardware Team!\n\nJohn Spencer\nAngus Gratton\nAndy Gelme\nJon Oxer\nMark Wolfe\n\nMade at hackmelbourne.org!\nSPECIAL THANKS\nTo the HackMelbourne (CCHS, http:\/\/hackmelbourne.org) community of Melbourne, Australia.\nTo all other open-source developers whose countless hours supported every other aspect of this design.\nDISTRIBUTION\nThe specific terms of distribution of this project are governed by the\nlicense referenced below. Please contact the copyright owner if you wish to modify the board for distribution. Please utilize this design for personal or research projects. Please acknowledge all contributors.\nLICENSE\nLicensed under the TAPR Open Hardware License (www.tapr.org\/OHL).\nThe \"license\" sub-folder also contains a copy of this license in plain text format.\nCopyright John Spencer, Angus Gratton, Andy Gelme, Jon Oxer 2015\n","75":"Second Environmental Linked Features Interoperability Experiment\nThe SELFIE is complete. The Engineering Report is available here: https:\/\/docs.ogc.org\/per\/20-067.html\nThe initial Environmental Linked Features Interoperability Experiment sought sustainable and automatable solutions to link multi-disciplinary, multi-organization environmental data without the requirement to transfer custody or burden of maintenance of data. It built on W3C best practices, providing guidance and a common approach for encoding environmental feature data and links between and among features and observational data about them. Using these technologies, it bridged the divide between the great flexibility and power of OGC services and the more focused and specific technologies that drive modern web development.\nBuilding on the content-focused outcomes of the first ELFIE, the Second ELFIE (SELFIE) is designing and vetting Web-resource model and network behavior for cross-domain linked feature data that compliments and uses WFS3 as a building block. This aims to answer the question, how do we use linked data in a way that's compatible with W3C best practices and leverages OGC standards? The experiment aims for focused simplicity, representing resources built from potentially complex data for easy use on the Web. While the IE will test a specific resource model and will follow W3C best practices and OGC standards, a wide range of participant-provided domain-use cases will be used for testing. Ultimately, this work is intended to satisfy the needs of many use cases and many kinds of features, from disaster response and resilience to environmental health and the built environment.\nSee the entire activity plan here.\n","76":"Classifying-Environmental-Sounds-with-Image-Networks\nMaster Thesis\nInstructions\nRequired Software\n1. Matlab\n2. CUDA\n3. Caffe\n4. NVIDIA DIGITS\n5. TensorFlow\n6. Keras\nRequired Hardware\n1. 8GB RAM or higher\n2. Graphic card with 4GB memory or higher (NVIDIA GTX 970 is used in this thesis)\n","77":"Enviro+ MQTT Logger\nenviroplus-mqtt is a Python service that publishes environmental data from an Enviro+ via MQTT.\nSetting Up Your Device\n\n\nSet up your RPi as you normally would.\n\n\nConnect the Enviro+ board, and the PMS5003 sensor if you are using one.\n\n\nInstall the Enviro+ library by following the instructions at https:\/\/github.com\/pimoroni\/enviroplus-python\/ (make sure the library is installed for Python 3)\n\n\nClone this repository to \/usr\/src\/enviroplus-mqtt:\nsudo git clone https:\/\/github.com\/hotplot\/enviroplus-mqtt \/usr\/src\/enviroplus-mqtt\n\n\n\nAdd a new file at \/etc\/systemd\/system\/envlogger.service with the following content:\n[Unit]\nDescription=Enviro+ MQTT Logger\nAfter=network.target\n\n[Service]\nExecStart=\/usr\/bin\/python3 \/usr\/src\/enviroplus-mqtt\/src\/main.py <arguments>\nWorkingDirectory=\/usr\/src\/enviroplus-mqtt\nStandardOutput=inherit\nStandardError=inherit\nRestart=always\nUser=pi\n\n[Install]\nWantedBy=multi-user.target\n\nNote that you must replace <arguments> with flags appropriate to your MQTT server.\n\n\nEnable and start the service:\nsudo systemctl enable envlogger.service\nsudo systemctl start envlogger.service\n\n\n\nSupported Arguments\n\n\nThe MQTT host, port, username, password and client ID can be specified.\n\n\nThe update interval can be specified, and defaults to 5 seconds.\n\n\nThe initial delay before publishing readings can be specified, and defaults to 15 seconds.\n\n\nIf you are using a PMS5003 sensor, enable it by passing the --use-pms5003 flag.\n  usage: main.py -h HOST [-p PORT] [-U USERNAME] [-P PASSWORD] [--prefix PREFIX]\n              [--client-id CLIENT_ID] [--interval INTERVAL] [--delay DELAY]\n              [--use-pms5003] [--help]\n\n  optional arguments:\n  -h HOST, --host HOST  the MQTT host to connect to\n  -p PORT, --port PORT  the port on the MQTT host to connect to\n  -U USERNAME, --username USERNAME\n                      the MQTT username to connect with\n  -P PASSWORD, --password PASSWORD\n                      the password to connect with\n  --prefix PREFIX       the topic prefix to use when publishing readings, i.e.\n                      'lounge\/enviroplus'\n  --client-id CLIENT_ID\n                      the MQTT client identifier to use when connecting\n  --interval INTERVAL   the duration in seconds between updates\n  --delay DELAY         the duration in seconds to allow the sensors to\n                      stabilise before starting to publish readings\n  --use-pms5003         if set, PM readings will be taken from the PMS5003\n                      sensor\n  --help                print this help message and exit\n\n\n\nPublished Topics\nReadings will be published to the following topics:\n\n<prefix>\/proximity\n<prefix>\/lux\n<prefix>\/temperature\n<prefix>\/pressure\n<prefix>\/humidity\n<prefix>\/gas\/oxidising\n<prefix>\/gas\/reducing\n<prefix>\/gas\/nh3\n<prefix>\/particulate\/1.0\n<prefix>\/particulate\/2.5\n<prefix>\/particulate\/10.0\n\n","78":"xtractomatic\nxtractomatic R package for accessing environmental data\n***Version 3.4.2 ****\n\n\nChanges to the order of the function arguments and required and option arguments in the functions.\n\n\nSmall fixes in internal operations.\n\n\nSee vignette for lots of examples - https:\/\/rmendels.github.io\/Usingxtractomatic_3.4.0.nb.html\n\n\nxtractomatic is an R package developed to subset and extract satellite and other oceanographic related data from a remote server. The program can extract data for a moving point in time along a user-supplied set of longitude, latitude and time points; in a 3D bounding box; or within a polygon (through time).  The xtractomatic functions were originally developed for the marine biology tagging community, to match up environmental data available from satellites (sea-surface temperature, sea-surface chlorophyll, sea-surface height, sea-surface salinity, vector winds) to track data from various tagged animals or shiptracks (xtracto). The package has since been extended to include the routines that extract data a 3D bounding box (xtracto_3D) or within a polygon (xtractogon).  The xtractomatic  package accesses  data that are served through the ERDDAP (Environmental Research Division Data Access Program) server at the NOAA\/SWFSC Environmental Research Division in Santa Cruz, California. The ERDDAP server can also be directly accessed at http:\/\/coastwatch.pfeg.noaa.gov\/erddap. ERDDAP is a simple to use yet powerful web data service developed by Bob Simons.\nThere are three main data extraction functions in the xtractomatic package:\n\n\nxtracto <- function(dtype, xpos, ypos, tpos = NA, xlen = 0., ylen = 0., verbose=FALSE)\n\n\nxtracto_3D <- function(dtype, xpos, ypos, tpos = NA, verbose=FALSE)\n\n\nxtractogon <- function(dtype, xpos, ypos, tpos = NA,  verbose = FALSE)\n\n\nThere are two information functions in the xtractomatic package:\n\n\n`searchData <- function(searchList= \"varname:chl\")\n\n\ngetInfo <- function(dtype)\n\n\nThe dtype parameter in the data extraction routines specifies a combination of which dataset on the ERDDAP server to access, and as well as which parameter from that dataset.\nThis version also includes the latest version of the cmocean colormaps,  designed by Kristen Thyng (see http:\/\/matplotlib.org\/cmocean\/ and https:\/\/github.com\/matplotlib\/cmocean).  These colormaps were initally developed for Python, and a version of the colormaps is used in the oce package by Dan Kelley and Clark Richards, but the colormaps used here are the version as of late 2017.  The colormaps are loaded automatically as colors, see str(colors). Several of the examples make use of the cmocean colormaps.\nxtractomatic uses the httr, ncdf4, readr and sp packages, and these packages must be installed first or xtractomatic will fail to install.\ninstall.packages(\"httr\", dependencies = TRUE)\ninstall.packages(\"ncdf4\",dependencies = TRUE) \ninstall.packages(\"readr\", dependencies = TRUE)\ninstall.packages(\"sp\", dependencies = TRUE)\n\nThe xtractomatic package is available from CRAN and can be installed by:\ninstall.packages(\"xtractomatic\")\n\nor the development version is available from [Github](https:\/\/github.com\/rmendels\/xtractomatic and can be installed from Github,\ninstall.packages(\"devtools\")\ndevtools::install_github(\"rmendels\/xtractomatic\")\n\nIf the other libraries  (httr, ncdf4, readr and sp) have been installed they will be found and do not need to be explicitly loaded.\nThe vignette uses the packages DT, ggplot2,  lubridate, mapdata, and  reshape2.\nRequired legalese\n\u201cThe United States Department of Commerce (DOC) GitHub project code is provided\non an \u2018as is\u2019 basis and the user assumes responsibility for its use.\nDOC has relinquished control of the information and no longer has responsibility\nto protect the integrity, confidentiality, or availability of the information.\nAny claims against the Department of Commerce stemming from the use of its\nGitHub project will be governed by all applicable Federal law. Any reference to\nspecific commercial products, processes, or services by service mark, trademark,\nmanufacturer, or otherwise, does not constitute or imply their endorsement,\nrecommendation or favoring by the Department of Commerce. The Department of\nCommerce seal and logo, or the seal and logo of a DOC bureau, shall not be used\nin any manner to imply endorsement of any commercial product or activity by DOC\nor the United States Government.\u201d\n","79":"Code and Data for Paper \"Learning to Navigate Unseen Environments: Back Translation with Environmental Dropout\"\nEnvironment Installation\nDownload Room-to-Room navigation data:\nbash .\/tasks\/R2R\/data\/download.sh\n\nDownload image features for environments:\nmkdir img_features\nwget https:\/\/www.dropbox.com\/s\/o57kxh2mn5rkx4o\/ResNet-152-imagenet.zip -P img_features\/\ncd img_features\nunzip ResNet-152-imagenet.zip\n\nPython requirements: Need python3.6 (python 3.5 should be OK since I removed the allennlp dependencies)\npip install -r python_requirements.txt\n\nInstall Matterport3D simulators:\ngit submodule update --init --recursive \nsudo apt-get install libjsoncpp-dev libepoxy-dev libglm-dev libosmesa6 libosmesa6-dev libglew-dev\nmkdir build && cd build\ncmake -DEGL_RENDERING=ON ..\nmake -j8\n\nCode\nSpeaker\nbash run\/speaker.bash 0\n\n0 is the id of GPU. It will train the speaker and save the snapshot under snap\/speaker\/\nAgent\nbash run\/agent.bash 0\n\n0 is the id of GPU. It will train the agent and save the snapshot under snap\/agent\/. Unseen success rate would be around 46%.\nAgent + Speaker (Back Translation)\nAfter pre-training the speaker and the agnet,\nbash run\/bt_envdrop.bash 0\n\n0 is the id of GPU.\nIt will load the pre-trained agent and run back translation with environmental dropout.\nCurrently, the result with PyTorch 1.1 is a little bit lower than my NAACL reported number. It still easily reaches a success rate of 50% (+4% from w\/o back translation).\nImplementation Details\n\nWhen training the speaker and listener, we drop out features as much as we can. It means that the image feature are dropped randomly (with a smaller dropout rate), which has been seen used in multiple vision papers.\nThe ml_weight is increased in using back translation, since the quality of generated sentence is not high and RL would be misled.\nInstead of training with augmented data and fine-tuning with training data, we trained them together.\n\nSemantic Views\nAs shown in Fig.6 of our paper which is the same to\nsemantic_views\/17DRP5sb8fy\/10c252c90fa24ef3b698c6f54d984c5c\/14.png \n\n\n\nin this repo, we rendered semantic views from Matterport3D dataset. We provide a preview of semantic views and rgb views under the forder semantic_views.\nTo access the full rendered data, please first sign the Terms of Use agreement form in https:\/\/github.com\/niessner\/Matterport and cc' the email to us haotan@cs.unc.edu. And we would share a download link.\nThanks to the one who teaches me how to calibrate camera. Note that there would be a small pixel-level disagreement between the RGB view and semantic view, since the semantic view are rendered from 3D annotations while the RGB view are rendered from skyboxes. We are still aiming in solving it.\nTODO's\n\nProvide test script for beam search. (Code is in train.py and agent.py)\nRelease pre-trained snapshots.\nCheck PyTorch 1.1 configurations.\nUpdate pip requirement with version specifications.\n\n","80":"Code and Data for Paper \"Learning to Navigate Unseen Environments: Back Translation with Environmental Dropout\"\nEnvironment Installation\nDownload Room-to-Room navigation data:\nbash .\/tasks\/R2R\/data\/download.sh\n\nDownload image features for environments:\nmkdir img_features\nwget https:\/\/www.dropbox.com\/s\/o57kxh2mn5rkx4o\/ResNet-152-imagenet.zip -P img_features\/\ncd img_features\nunzip ResNet-152-imagenet.zip\n\nPython requirements: Need python3.6 (python 3.5 should be OK since I removed the allennlp dependencies)\npip install -r python_requirements.txt\n\nInstall Matterport3D simulators:\ngit submodule update --init --recursive \nsudo apt-get install libjsoncpp-dev libepoxy-dev libglm-dev libosmesa6 libosmesa6-dev libglew-dev\nmkdir build && cd build\ncmake -DEGL_RENDERING=ON ..\nmake -j8\n\nCode\nSpeaker\nbash run\/speaker.bash 0\n\n0 is the id of GPU. It will train the speaker and save the snapshot under snap\/speaker\/\nAgent\nbash run\/agent.bash 0\n\n0 is the id of GPU. It will train the agent and save the snapshot under snap\/agent\/. Unseen success rate would be around 46%.\nAgent + Speaker (Back Translation)\nAfter pre-training the speaker and the agnet,\nbash run\/bt_envdrop.bash 0\n\n0 is the id of GPU.\nIt will load the pre-trained agent and run back translation with environmental dropout.\nCurrently, the result with PyTorch 1.1 is a little bit lower than my NAACL reported number. It still easily reaches a success rate of 50% (+4% from w\/o back translation).\nImplementation Details\n\nWhen training the speaker and listener, we drop out features as much as we can. It means that the image feature are dropped randomly (with a smaller dropout rate), which has been seen used in multiple vision papers.\nThe ml_weight is increased in using back translation, since the quality of generated sentence is not high and RL would be misled.\nInstead of training with augmented data and fine-tuning with training data, we trained them together.\n\nSemantic Views\nAs shown in Fig.6 of our paper which is the same to\nsemantic_views\/17DRP5sb8fy\/10c252c90fa24ef3b698c6f54d984c5c\/14.png \n\n\n\nin this repo, we rendered semantic views from Matterport3D dataset. We provide a preview of semantic views and rgb views under the forder semantic_views.\nTo access the full rendered data, please first sign the Terms of Use agreement form in https:\/\/github.com\/niessner\/Matterport and cc' the email to us haotan@cs.unc.edu. And we would share a download link.\nThanks to the one who teaches me how to calibrate camera. Note that there would be a small pixel-level disagreement between the RGB view and semantic view, since the semantic view are rendered from 3D annotations while the RGB view are rendered from skyboxes. We are still aiming in solving it.\nTODO's\n\nProvide test script for beam search. (Code is in train.py and agent.py)\nRelease pre-trained snapshots.\nCheck PyTorch 1.1 configurations.\nUpdate pip requirement with version specifications.\n\n","81":"Yamlenv\n \n\nInterpolate YaML files with environmental variables and other YaML\nfiles.\nGiven a YaML string like:\na: ${A}\nb: 2\nand an environmental variable $A with value hello,\nyamlenv.load would return:\n{\n    a: 'hello',\n    b: 2\n}\nIncluding YAML literals as environment variables is also\nsupported - so if the environment variable $A was set to\nfalse, yamlenv.load would return:\n{\n    a: False,\n    b: 2\n}\nDefault values are supported:\nyamlenv.load('''\n    a: ${A:-hello}\n    b: 2\n''') == {\n    'a': 'hello',\n    'b': 2\n}\nAs in Bash, defaulting can be done with either :- (to not allow empty\ndefaults) or with - to allow empty values.\nThe environmental variable can be embedded in a larger string, too:\nyamlenv.load('''\n    a: foo ${A:-bar} baz\n    b: 2\n''') == {\n    'a': 'foo bar baz',\n    'b': 2\n}\nMore than one environmental variable can appear in a string:\nyamlenv.load('''\n    a: foo ${A:-bar} ${B:-baz}\n    b: 2\n''') == {\n    'a': 'foo bar baz',\n    'b': 2\n}\nYaML files can include other YaML files, too. E.g. if b.yaml\ncontains \"2\", then:\nyamlenv.load('''\n    a: 1\n    b: !include b.yaml\n''') == {\n    'a': 1\n    'b': 2\n}\nThe included YaML file can be as complex as necessary.\nMore examples are available in the tests.\n","82":"Students Organizing Against Pollution\nStudents Organizing Against Pollution (SOAP) is an initiative aimed at empowering the average citizen of New Jersey with the ability to learn, share, and\/or contribute knowledge pertaining to pollution in the environment. Find pollution sites near you and take action. Our pollution data comes directly from the US Environmental Protection Agency (www.epa.gov\/). More specifically, we use data from the Toxics Release Inventory. Information regarding politicans and legislation is provided by the New Jersey State Government (http:\/\/www.nj.gov\/).\nThe platforms and technologies that have been incorporated into SOAP include:\n\nHTML5 \/ CSS3\nJavaScript\nPHP5\nPostgreSQL\nCakePHP\nTwitter Bootstrap\n\nDocumentation: https:\/\/www.dropbox.com\/s\/ea7k2wp361hiywx\/Final%20Paper.docx\nWebsite: http:\/\/23.23.190.5\/\n","83":"ncWMS2\n\n\nDocumentation\nSource code\nIssues\nCHANGELOG\n\nncWMS is a Web Map Service for geospatial data that are stored in CF-compliant NetCDF files. The intention is to create a WMS that requires minimal configuration: the source data files should already contain most of the necessary metadata. ncWMS is developed and maintained by the Reading e-Science Centre (ReSC) at the University of Reading, UK.\nncWMS v2 is built on top of the EDAL libraries developed by ReSC\nLicence\nCopyright (c) 2010 The University of Reading\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions\nare met:\n1. Redistributions of source code must retain the above copyright\n   notice, this list of conditions and the following disclaimer.\n2. Redistributions in binary form must reproduce the above copyright\n   notice, this list of conditions and the following disclaimer in the\n   documentation and\/or other materials provided with the distribution.\n3. Neither the name of the University of Reading, nor the names of the\n   authors or contributors may be used to endorse or promote products\n   derived from this software without specific prior written permission.\n4. If you wish to use, with or without modification, the Godiva web\n   interface, the logo of the Reading e-Science Centre must be retained\n   on the web page.\n\nTHIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\nIMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\nOF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\nIN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,\nINCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\nNOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF\nTHIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nAuthors and Contributors\nncWMS is developed by the Reading e-Science Centre and is maintained by @guygriffiths.\nContributors:\n\n@yosoyjay\n@kwilcox\n\n","84":"Environmental Sensor Data Repository (ESDR)\nESDR is an open source data repository intended for storing and retrieving time series environmental data.  Basically, if the data has a timestamp and a value, ESDR can store it and provide ways to retrieve it quickly and securely.  Data is stored in a custom, open source datastore which provides extremely fast data inserts and fetches, making for fast and responsive visualizations.  The ESDR web site (esdr.cmucreatelab.org) provides a REST API interface to the datastore, making it easy to read\/write data. Metadata is stored in a MySQL database.\nESDR is pronounced like the female name, Esther.\nConcepts and Terminology\nIf you're familiar with Xively's API, you'll see a lot of parallels with ESDR.  Our intention is to use ESDR as the data repository not only for our own products and visualizations, but also for anyone else who wants a place to store data and have tools to easily visualize it.\nFirst, some terminology: ESDR has clients, users, products, devices, feeds, channels, and tiles.  Understanding how these entities relate will give a good understanding of how the data and metadata are structured and how the system works.\n\nClient: ESDR uses OAuth2 for authentication, so a client in ESDR is simply an OAuth2 client.\nUser: no real surprise here...simply a person who has registered with ESDR and may own one or more products, devices, or feeds.  When a user logs in, he\/she does so on behalf of an OAuth2 client.\nProduct: a product is simply a certain kind of sensor, for example, the Speck particle sensor.\nDevice: a particular instantiation of a product, i.e. an actual sensor device--something you can put your hands on--typically with a unique serial number.\nFeed: a particular installation of a device.  For example, if I buy a Speck and register it, the behind-the-scenes registration process creates for me both an ESDR device instance (with my Speck's serial number), as well as a feed, for the location I specified during registration.  For example, let's say I purchase a Speck and install it under the awning on my deck.  During registration, I would give the location a name (e.g. \"Deck\"), set the latitude\/longitude to my house, mark the exposure to outdoors, set visibility (public or private), etc. Data recorded and uploaded by the Speck would be associated with that particular feed.  If I then move the Speck to my kitchen, I would re-register the Speck so it is associated with a new feed, because the environment\/location has changed.  If I accidentally drop the Speck in a sink full of water and replace it with a new one, that new one would be registered as a new device (it has a different serial number), but, at my option, could be associated with the existing feed from the old Speck (so that I have one continuous stream of data since it's the environment being measured which matters most, not the actual device doing the measurement).  Similarly, if I sell the Speck, the new owner would register it under her account, and get a new feed for it.\nChannel: a sensor device measures one or more aspects of its environment, such as temperature, humidity, particle count, battery voltage, etc.  Each is considered a different channel.  A feed comprises one or more channels.\nTiles: data from a particular feed's channel can be retrieved from ESDR in small chunks of JSON which we call tiles.  A tile contains at most 512 data points, and is associated with a particular starting timestamp and duration.  For example, a tile could represent a summary of a decade's worth of data, or it could contain the actual recorded data samples spanning, say, only 1 second (e.g. heart rate data).  The grapher we use fetches tiles as the user pans and zooms the timeline--it requests only the small subset of data it needs to render the plot. The most appropriate analogy is panning\/zooming in Google Maps--the browser only requests map tiles for the current small region of the Earth you're exploring at the time.  ESDR also has support for a multi-tile fetch where you can fetch data from multiple channels from multiple feeds with a single GET request.  This is essential for being able to do visualizations of lots of sensors simultaneously, e.g. air quality in cities all over the country.\n\nAgain, the data samples themselves are all stored in the datastore.  Data for the above entities is stored in a MySQL database.  The big win with the datastore is that it works with billions of samples, doing time aggregation upon insert (and yet inserts are still fast), storing the data at a number of different summarization levels.  Thus, it can return a summary of a year's worth (or more!) of data just as quickly as, say, five minutes worth.  No summarization computation is required when fetching tiles, so visualizations remain responsive and fast at any zoom level.\nWe don't yet do spatiotemporal aggregation, but it's on the TODO list.\nPlease see the HOW TO document for more details on how to use ESDR.\nSetup\n\n\nInstall the module dependencies:\n npm install\n\n\n\nInstall the BodyTrack Datastore by doing the following\n\n\nFetch the BodyTrack Datastore. In your terminal window, set your working directory to the root of the ESDR repository and do the following:\n    git clone https:\/\/github.com\/BodyTrack\/datastore.git\n\n\n\nFollow the BodyTrack Datastore's build and install instructions.\n\n\n\n\nInstall MySQL if necessary.  ESDR was tested with and assumes MySQL 5.6 (there are known issues with 5.5).\n\n\nDo the following to create the development MySQL database and user:\n CREATE DATABASE IF NOT EXISTS esdr_dev;\n GRANT ALL PRIVILEGES ON esdr_dev.* To 'esdr_dev'@'localhost' IDENTIFIED BY 'password';\n GRANT SELECT,INSERT,UPDATE,DELETE,CREATE ON esdr_dev.* TO 'esdr_dev'@'localhost';\n\nIf you choose to change the password, make sure it matches the password in config-dev.json.\n\n\nIf you want to be able to run the tests, do the following to create the test database and user:\n CREATE DATABASE IF NOT EXISTS esdr_test;\n GRANT ALL PRIVILEGES ON esdr_test.* To 'esdr_test'@'localhost' IDENTIFIED BY 'password';\n GRANT SELECT,INSERT,UPDATE,DELETE,CREATE ON esdr_test.* TO 'esdr_test'@'localhost';\n\nIf you choose to change the password, make sure it matches the password in config-test.json.\n\n\nIf running in production, do the following:\n\n\nCreate the config-prod.json and mail-config-prod.json files. Just copy from the other configs, but you need only include the parts that differ from config.js.\n\n\nDo the following to create the production database and user:\n CREATE DATABASE IF NOT EXISTS esdr_prod;\n GRANT ALL PRIVILEGES ON esdr_prod.* To 'esdr_prod'@'localhost' IDENTIFIED BY 'USE_A_GOOD_PASSWORD_HERE';\n GRANT SELECT,INSERT,UPDATE,DELETE,CREATE ON esdr_prod.* TO 'esdr_prod'@'localhost';\n\nAgain, make sure the user and password you specify matches those in config-prod.json.\n\n\n\n\nMake sure the datastore data directory defined in the config file exists.\n\n\nRun\nThe NODE_ENV environment variable may be specified when running, and must be one of dev, development, test, prod, or production. Defaults to dev if unspecified.\nTo run the server in development mode, do any of the following:\nnpm start\nNODE_ENV=dev npm start\nNODE_ENV=development npm start\n\nTo run the server in test mode, do:\nNODE_ENV=test npm start\n\nTo run the server in production mode, do either of the following:\nNODE_ENV=prod npm start\nNODE_ENV=production npm start\n\nDevelopment\nTo generate the CSS from the SCSS template, do:\nnpm run-script gen-css\n\nTo compile the handlebars templates, do:\nnpm run-script gen-handlebars\n\n","85":"Python for Data Analysis\nA series of IPython notebooks on Python for data analysis geared towards environmental sciences.\n\nNational Institute for Water and Atmospheric research\nAuckland, New Zealand\nDates and times:\n\nTuesday 28 January 2014, 12:00 - 13:00\nThursday 30 January 2014, 12:00 - 13:00\nMonday 3 February 2014, 14:00 - 15:00\nTuesday 4 February 2014, 14:00 - 15:00\nWednesday 5 February 2014, 12:00 - 13:00\nWednesday 9 April 2014, 12:00 - 13:00\nFriday 11 April 2014, 12:00 - 13:00\n\n\nContact: Nicolas Fauchereau (Nicolas.Fauchereau@gmail.com): My academia web-page\nAll the notebooks in this seminar series are indexed at https:\/\/github.com\/nicolasfauchereau\/NIWA_Python_seminars\nIf you have git installed, the easier is to clone my repository\ngit clone https:\/\/github.com\/nicolasfauchereau\/NIWA_Python_seminars.git\n\nIf you are not a git user, simply download the archive from here or copy the directory NIWA_Python_seminars from my S: drive.\n\nYou can also visualize the material in your web-browser (thanks to nbviewer) by following these links:\n\n0: Introduction\n1: Overview of IPython\n2: Introduction to Python\n3: Numpy and Scipy\n4: Statistical modeling\n5: Introduction to Pandas\n6: Machine Learning\n\nAn alternative way to display the notebooks is to use the github HTML viewer: e.g. in your address bar prepend  http:\/\/htmlpreview.github.io\/? to URL of the HTML versions of the notebooks available in the repository, for example for the Introduction:\nhttp:\/\/htmlpreview.github.io\/?https:\/\/github.com\/nicolasfauchereau\/NIWA_Python_seminars\/blob\/master\/0_Introduction.html\n","86":"checkenv - Check Your Environment\n   \nA modern best-practice is to store your application's configuration in environmental variables.  This allows you to keep all config data outside of your repository, and store it in a standard, system-agnostic location.  Modern build\/deploy\/development tools make it easier to manage these variables per-host, but they're still often undocumented, and can lead to bugs when missing.\nThis module lets you define all the environmental variables your application relies on in an env.json file.  It then provides a method to check for these variables at application launch, and print a help screen if any are missing.\nInstallation\n$ npm i -S checkenv\nUsage\nFirst, define a JSON file called env.json in your project root (see below).  Then, add the following line to the top of your project's entry file:\nrequire('checkenv').check();\nBy default, checkenv will print a pretty error message and call process.exit(1) if any required variables are missing.  It will also print an error message if optional variables are missing, but will not exit the process.\n\nIf you would like to handle errors yourself, check takes an optional pretty argument which causes it to throw errors instead of printing an error message.  This will only result in an error being thrown on missing required variables.\ntry {\n  require('checkenv').check(false);\n} catch (e) {\n  \/\/ Do something with this error\n}\nConfiguration\nYour JSON file should define the environmental variables as keys, and either a boolean (required) as the value, or a configuration object with any of the options below.\nJSON\n{\n  \"NODE_ENV\": {\n    \"description\": \"This defines the current environment\",\n    \"validators\": [{\n      \"name\": \"in\",\n      \"options\": [\"development\", \"testing\", \"staging\", \"production\"]\n    }]\n  },\n  \"PORT\": {\n    \"description\": \"This is the port the API server will run on\",\n    \"default\": 3000\n  },\n  \"NODE_PATH\": true,\n  \"DEBUG\": {\n    \"required\": false,\n    \"description\": \"If set, enables additional debug messages\"\n  }\n}\nOptions\nrequired\nDefines whether or not this variable is required.  By default, all variables are required, so you must explicitly set them to optional by setting this to false\ndescription\nDescribes the variable and how it should be used. Useful for new developers setting up the project, and is printed in the error output if present.\ndefault\nDefines the default value to use if variable is unset. Implicitly sets required to false.\nvalidators\nAn array of validators that the variable must pass.  See validator.js for details about all validators.  Format for each validator is:\n{\n  \/* ... *\/\n  \"validators\": [\n    \"validator name\", \/\/ Option-less validators can be passed as strings\n    { \/\/ Validators w\/ options must be passed as objects\n      \"name\": \"validator name\",\n      \"options\": options \/\/ Option format varies, see below\n    }\n  ]\n  \/* ... *\/\n}\nPossible validators (see validator.js for details):\n\ncontains \u2014 options should be a string with what the value should contain\nequals \u2014 options should be a string of the exact value\nbefore \u2014 options should be a date\nafter \u2014 options should be a date\nalpha\nalphanumeric\nascii\nbase64\nboolean\ndate\ndecimal\nfqdn\nfloat \u2014 options MAY be an object with min or max properties\nhex-color\nhexadecimal\nip4 \u2014 same as ip with \"options\": 4\nip6 \u2014 same as ip with \"options\": 6\nip \u2014 options MAY be number (4 or 6)\niso8601\nenum \u2014 alias for in\nin \u2014 options MUST be an array of possible values\nint \u2014 options MAY be an object with min or max properties\njson\nlength \u2014 options MUST be an object with min, max or both\nlowercase\nmac-address\nnumeric\nurl\nuuid3 \u2014 same as uuid with \"options\": 3\nuuid4 \u2014 same as uuid with \"options\": 4\nuuid5 \u2014 same as uuid with \"options\": 5\nuuid \u2014 options MAY be a number (3, 4 or 5)\nuppercase\nregex \u2014 alias for matches\nregexp \u2014 alias for matches\nmatches \u2014 options MUST be either a string representing a regex, or an array in the format [\"regex\", \"modifiers\"]\n\nSee Also\nIf you like this module, you may also want to check out:\n\ndotenv Load missing environmental variables from .env\napp-root-path Automatically determine\nthe root path for the current application\nenforce-node-path Enforce the usage of\nthe NODE_PATH environmental variable\n\nChange Log\n1.2.2\n\nBetter handling of syntax errors in env.json (thanks yalcindo!)\n\n1.2.0\n\nValidation (via validator.js)\n\n1.1.1\n\nPrints default value in help\n\n1.1.0\n\nAdded support for default values\nAdded support to change filename via setFilename()\n\n1.0.6\n\nBugfix \u2014 please do not use versions before 1.0.6\n\n1.0.5\n\nPasses tests for node 0.10 through 5.1\n\n1.0.0\n\nInitial release\n\n","87":"#FISH546 - Bioinformatics for Environmental Sciences\nWinter 2015\nThis repository serves as the primary framework for the course. Specifically please see the wiki for syllabus, content, etc. Issues will be used as primary means of assessment and communication.\n\n\nCourse Description- This course will teach core computing skills as well as project specific approaches. Each student will be developing and completing a research project targeting journal article submission by the end of the Quarter.  There will be an emphasis on developing habits that increase automation which in turn will facilitate reproducibility. The course primary course platform will be GitHub, with each student creating their own repository.\n\nThe code repository is where example analyses will be provided. \ud83d\udc4d\n###Files and Directory Structure\nCONTRIBUTING.MD- This is simply for the guidelines for contributing to this repository you will see when creating a new issue.\n.gitignore - List of files that are in local repo but not in GitHub because of file size limits\nnotebooks\/ - Directory where IPython notebooks live.\nNotebooks rendered in nbviewer: http:\/\/nbviewer.ipython.org\/github\/sr320\/fish546-2015\/tree\/master\/notebooks\/\ndata\/ - Raw data including fasta files (in data\/fa\/)\nanalyses\/ - Output from analyses performed in IPython notebooks.\nscripts\/ - Scripts call on from notebooks.\n","88":"#FISH546 - Bioinformatics for Environmental Sciences\nWinter 2015\nThis repository serves as the primary framework for the course. Specifically please see the wiki for syllabus, content, etc. Issues will be used as primary means of assessment and communication.\n\n\nCourse Description- This course will teach core computing skills as well as project specific approaches. Each student will be developing and completing a research project targeting journal article submission by the end of the Quarter.  There will be an emphasis on developing habits that increase automation which in turn will facilitate reproducibility. The course primary course platform will be GitHub, with each student creating their own repository.\n\nThe code repository is where example analyses will be provided. \ud83d\udc4d\n###Files and Directory Structure\nCONTRIBUTING.MD- This is simply for the guidelines for contributing to this repository you will see when creating a new issue.\n.gitignore - List of files that are in local repo but not in GitHub because of file size limits\nnotebooks\/ - Directory where IPython notebooks live.\nNotebooks rendered in nbviewer: http:\/\/nbviewer.ipython.org\/github\/sr320\/fish546-2015\/tree\/master\/notebooks\/\ndata\/ - Raw data including fasta files (in data\/fa\/)\nanalyses\/ - Output from analyses performed in IPython notebooks.\nscripts\/ - Scripts call on from notebooks.\n","89":"Sahana Eden\nSahana Eden is an Emergency Development Environment - an Open Source framework to rapidly build powerful applications for Emergency Management.\nIt is a web based collaboration tool that addresses the common coordination problems during a disaster from finding missing people, managing aid, managing volunteers, tracking camps effectively between Government groups, the civil society (NGOs) and the victims themselves.\nPlease see the website for more details:\n\nhttp:\/\/eden.sahanafoundation.org\/\n\nNote to developers -- get started here:\n\nhttp:\/\/eden.sahanafoundation.org\/wiki\/Develop\n\nBefore your first pull request, sign the Contributor's License Agreement, which protects your rights to your code, while allowing it to be distributed and used in Sahana Eden:\n\nhttp:\/\/bit.ly\/SSF-eCLA\n\n","90":"Sahana Eden\nSahana Eden is an Emergency Development Environment - an Open Source framework to rapidly build powerful applications for Emergency Management.\nIt is a web based collaboration tool that addresses the common coordination problems during a disaster from finding missing people, managing aid, managing volunteers, tracking camps effectively between Government groups, the civil society (NGOs) and the victims themselves.\nPlease see the website for more details:\n\nhttp:\/\/eden.sahanafoundation.org\/\n\nNote to developers -- get started here:\n\nhttp:\/\/eden.sahanafoundation.org\/wiki\/Develop\n\nBefore your first pull request, sign the Contributor's License Agreement, which protects your rights to your code, while allowing it to be distributed and used in Sahana Eden:\n\nhttp:\/\/bit.ly\/SSF-eCLA\n\n","91":"Sahana Eden\nSahana Eden is an Emergency Development Environment - an Open Source framework to rapidly build powerful applications for Emergency Management.\nIt is a web based collaboration tool that addresses the common coordination problems during a disaster from finding missing people, managing aid, managing volunteers, tracking camps effectively between Government groups, the civil society (NGOs) and the victims themselves.\nPlease see the website for more details:\n\nhttp:\/\/eden.sahanafoundation.org\/\n\nNote to developers -- get started here:\n\nhttp:\/\/eden.sahanafoundation.org\/wiki\/Develop\n\nBefore your first pull request, sign the Contributor's License Agreement, which protects your rights to your code, while allowing it to be distributed and used in Sahana Eden:\n\nhttp:\/\/bit.ly\/SSF-eCLA\n\n","92":"Conf\n\nCopyright 2018, 2019, 2020, Ardan Labs\ninfo@ardanlabs.com\nLicensing\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nAbout The Project\nPackage conf provides support for using environmental variables and command\nline arguments for configuration.\nAll of the documentation can be found on the go.dev website.\n","93":"Environmental Sound Classification on Microcontrollers using Convolutional Neural Networks\nThesis report\n\nDownload thesis report (PDF)\nErrata\nIn print1 version of report\n\nFig 5.1. DS-Strided-24 result is missing\nFig 5.1. No-information-rate should be 11.5% instead of 10%.\nDid not take class-imbalance into account\nFig 2.10. Labels EffNet and ShuffleNet swapped\nFig 5.3. Missing description of model used. Uses Stride-DS-24\nTable 4.1. Nesterov momentum shows NaN. Should be 0.9\n\nCiting\nYou can use the following BibTeX entry\n@mastersthesis{esc_micro_cnn_nordby2019,\n    title={Environmental Sound Classification on Microcontrollers using Convolutional Neural Networks},\n    author={Jon Nordby},\n    year=2019,\n    month=5,\n    school={Norwegian University of Life Sciences},\n    url={http:\/\/hdl.handle.net\/11250\/2611624}\n}\nKeywords\nWireless Sensor Networks, Embedded Systems\nEdge Computing, Edge Machine Learning\nNoise classification, Environmental Sound Classification (ESC), Urbansounds\nTensorflow, Keras, librosa\n\nAbstract\nNoise is a growing problem in urban areas,\nand according to the WHO is the second environmental cause of health problems in Europe.\nNoise monitoring using Wireless Sensor Networks are\nbeing applied in order to understand and help mitigate these noise problems.\nIt is desirable that these sensor systems, in addition to logging the sound level,\ncan indicate what the likely sound source is.\nHowever, transmitting audio to a cloud system for classification is\nenergy-intensive and may cause privacy issues.\nIt is also critical for widespread adoption and dense sensor coverage that\nindividual sensor nodes are low-cost.\nTherefore we propose to perform the noise classification on the sensor node,\nusing a low-cost microcontroller.\nSeveral Convolutional Neural Networks were designed for the\nSTM32L476 low-power microcontroller using the Keras deep-learning framework,\nand deployed using the vendor-provided X-CUBE-AI inference engine.\nThe resource budget for the model was set at maximum 50% utilization of CPU, RAM, and FLASH.\n10 model variations were evaluated on the Environmental Sound Classification task\nusing the standard Urbansound8k dataset.\nThe best models used Depthwise-Separable convolutions with striding for downsampling,\nand were able to reach 70.9% mean 10-fold accuracy while consuming only 20% CPU.\nTo our knowledge, this is the highest reported performance on Urbansound8k using a microcontroller.\nOne of the models was also tested on a microcontroller development device,\ndemonstrating the classification of environmental sounds in real-time.\nThese results indicate that it is computationally feasible to classify environmental sound\non low-power microcontrollers.\nFurther development should make it possible to create wireless sensor-networks\nfor noise monitoring with on-edge noise source classification.\nRun experiments\nSetting up\nRecommend using miniconda for\nconda env create -f environment.yml\nconda activate microesc\n\nAs an altenative, one can use pip\n#pip install -r requirements.txt\n\nPreprocess audio files into features\npython3 preprocess.py\n\nCheck that the environment is working.\nThis will run training process, but only for a few minutes.\npython3 jobs.py --check\n\nRunning\nTrain the models\npython3 jobs.py\n\nEvaluate the resulting models\npython3 test.py\n\nPlot the results\npython3 report.py\n\n","94":"\n\n\nEnvironmental Reporting BC - Repository List\nIndex of GitHub repositories administered by Environmental Reporting\nBC\nEnvironmental Reporting BC provides access to information about our\nenvironment and how it relates to British Columbians. This information\ncomes in the form of indicators that examine the state and trends of\ndifferent aspects of our environment.\nIndicators\n\nAir\nozone-caaqs-indicator\n\nR scripts to calculate the Canadian Ambient Air Quality Standards\n(CAAQS) for Ozone for B.C. published on Environmental Reporting BC\n\n\npm25-caaqs-indicator\n\nR scripts to calculate the Canadian Ambient Air Quality Standards\n(CAAQS) for fine particulate matter (PM2.5) for B.C. published on\nEnvironmental Reporting BC\n\n\n\n\nClimate Change\nclimate-change-indicators-2015\n\nR scripts for creating data visualizations for climate change\nindicators published on Environmental Reporting BC\n\n\n\n\nLand & Forests\nland-designations-indicator\n\nR scripts for an indicator on land designations that contribute to\nconservation in B.C. published on Environmental Reporting BC\n\n\nprotected-lands-and-waters-indicator\n\nR scripts for an indicator summarising protected lands and waters in\nB.C. published on Environmental Reporting BC\n\n\nroadless-areas-indicator\n\nR scripts for a roads & roadless areas in B.C. indicator published\non Environmental Reporting BC\n\n\nforest-management-indicators\n\nR scripts to creata data visualizations for three forest management\nindicators published on Environmental Reporting BC\n\n\n\n\nPlants & Animals\ninvasive-species-indicator\n\nR scripts for an indicator on status of invasive species in B.C.\npublished on Environmental Reporting BC\n\n\nnative-species-rank-indicator\n\nR scripts to track rank changes in native species for Environmental\nReporting BC\n\n\ngrizzly-bear-status-indicator\n\nR scripts for a grizzly bear status indicator for Environmental\nReporting BC\n\n\n\n\nSustainability\nbc-population-indicator\n\nR scripts for an indicator on trends in B.C.\u2019s population size &\ndistribution published on Environmental Reporting BC\n\n\nghg-emissions-indicator\n\nR scripts for a GHG emissions indicator published on Environmental\nReporting BC\n\n\nmsw-disposal-indicator\n\nR scripts for a municipal solid waste disposal indicator published\non Environmental Reporting BC\n\n\ntire-recycling-indicator\n\nR script for a trends in scrap tire recycling indicator publlished\non Environmental Reporting BC\n\n\nrecycling-indicator\n\nR script to summarize recycling data as part of the EPR program for\nthe State of Environment Reporting\n\n\n\n\nWater\ngroundwater-levels-indicator\n\nR scripts for an indicator on long-term trends in groundwater levels\nin B.C. published on Environmental Reporting BC\n\n\nwater-quality-analysis\n\nR scripts to calculate water quality trends and the water quality\nindex at selected ambient monitoring stations in B.C.\n\n\n\nR & Python Packages\n\nR\nbcdata\n\nAn R package for searching & retrieving data from the B.C. Data\nCatalogue\n\n\nbcgovr\n\nAn R package to automate set up and sharing of R projects in bcgov\nGitHub following bcgov guidelines\n\n\nbcgroundwater\n\nAn R package to facilitate analysis and visualization of groundwater\ndata from the British Columbia groundwater observation well network\n\n\nbcmaps\n\nAn R package of map layers for British Columbia\n\n\nbcmapsdata\n\nMap layers for British Columbia, in R for use with the bcmaps\npackage\n\n\ncanwqdata\n\nR \ud83d\udce6 to download \ud83c\udde8\ud83c\udde6 open water quality data\n\n\ncccharts\n\nAn R package for creating data visualizations for a set of climate\nchange indicators published on Environmental Reporting BC\n\n\nenvreportutils\n\nAn R package with ggplot2 themes & other functions related to\nEnvironmental Reporting BC work flows\n\n\nrcaaqs\n\nAn R package to facilitate the calculation of air quality metrics\naccording to Canadian Ambient Air Quality Standards\n\n\nrems\n\nAn R package to access data from British Columbia\u2019s Environmental\nMonitoring System\n\n\nwqbc\n\nAn R package for water quality thresholds and index calculation for\nBritish Columbia\n\n\nwqindex\n\nAn R package to calculate the CCME Water Quality Index\n\n\nranktrends\n\nSummarize species rankings over time based on common conservation\nranking systems.\n\n\n\n\nPython\ndesignatedlands\n\nPython script to combine conservation related spatial data from many\nsources to create a single \u2018Designated Lands\u2019 layer for British\nColumbia\n\n\n\nSupporting & Other Analyses\n\nInteractive Data Visualizations\nland-designations-shinyapp\n\nR Shiny application for interactive data visualization of land\ndesignations that contribute to conservation in B.C.\n\n\n\n\nSupporting Analyses\nbc-raster-roads\n\nR scripts for generating a raster spatial layer with length of roads\nper hectare for B.C.\n\n\n\n\nOther Stuff\nenvreportbc-snippets\n\nR scripts & snippets supporting Environmental Reporting BC workflows\n\ud83d\udc69\u200d\ud83d\udcbb\ud83d\udc68\u200d\ud83d\udcbb\n\n\n\nGetting Help or Reporting an Issue\nTo report bugs\/issues\/feature requests, please file an\nIssue.\nHow to Contribute\nIf you would like to contribute, please see our\nCONTRIBUTING guidelines.\nLicense\nCreative\nCommons Attribution 4.0 International License.\n","95":"environmental-hackathon\nhttps:\/\/environmentalhack.com\/\n","96":"environmental_monitoring\nData Prediction for environmental monitoring\n","97":"Welcome to the GitHub Pages of the MOOC on \"Data Science for Environmetal Monitoring and Renewables\"\nThese pages contain the data and R code we have used when we produced the MOOC on Data Science for Environmental Monitoring and Renewables on FutureLearn.\n","98":"SDI-12 for Arduino\nIntroduction\nThis is an Arduino library for SDI-12 communication with a wide variety of environmental sensors.\nIt provides a general software solution, without requiring any additional hardware, to implement the SDI-12 communication protocol between an Arduino-based data logger and SDI-12-enabled sensors.\nSDI-12 is an asynchronous, ASCII, serial communications protocol that was developed for intelligent sensory instruments that typically monitor environmental data.\nAdvantages of SDI-12 include the ability to use a single available data channel for many sensors.\nThis work is motivated by the EnviroDIY community vision to create an open source hardware and software stack to deliver near real time environmental data from wireless sensor networks, such as the Arduino-compatible EnviroDIY\u2122 Mayfly Data Logger.\nDocumentation\nExtensive documentation on the SDI-12 functions and classes is available here:  https:\/\/envirodiy.github.io\/Arduino-SDI-12\/index.html\nRenaming Notice\nAs of version 2.0.0 this library was renamed from \"Arduino-SDI-12\" to simply \"SDI-12\" to comply with requirements for inclusion in the Arduino.cc's IDE and Library Manager.\n\nSDI-12 for Arduino\n\nIntroduction\nDocumentation\n\nRenaming Notice\n\n\nGetting Started\nOrigins and Inherited Limitations\nCompatibility Considerations\nVariants and Branches\n\nEnviroDIY_SDI12\nEnviroDIY_SDI12_PCINT3\nEnviroDIY_SDI12_ExtInts\n\n\nContribute\nLicense\nCredits\n\n\n\nGetting Started\nLearn more, below, about this library's:\n\nOrigins and Inherited Limitations;\nCompatibility Considerations;\nVariants and Branches we created to overcome some limitations.\n\nTry running our Example sketches with your Arduino board and SDI-12 sensor.\nFull details on the library functionality can be found on github pages: https:\/\/envirodiy.github.io\/Arduino-SDI-12\/\nOrigins and Inherited Limitations\nThis library was developed from the SoftwareSerial library that is a built-in standard Arduino library.\nIt was further modified to use a timer to improve read stability and decrease the amount of time universal interrupts are disabled using logic from NeoSWSerial.\nThe most obvious \"limitation\" is that this library will conflict with all other libraries that make use of pin change interrupts.\nYou will be unable to compile them together.\nSome other libraries using pin change interrupts include SoftwareSerial, NeoSWSerial, EnableInterrupt, PinChangeInt, Servo, and quite a number of other libraries.\nSee the notes under Variants and Branches below for advice in using this library in combination with such libraries.\nAnother non-trivial, but hidden limitation is that all interrupts are disabled during most of the transmission of each character, which can interfere with other processes.\nThat includes other pin-change interrupts, clock\/timer interrupts, external interrupts, and every other type of processor interrupt.\nThis is particularly problematic for SDI-12, because SDI-12 operates at a very slow baud rate (only 1200 baud).\nThis translates to ~8.3 mS of \"radio silence\" from the processor for each character that goes out via SDI-12, which adds up to ~380-810ms per command!  Interrupts are enabled for the majority of the time while the processor is listening for responses.\nFor most AVR boards, this library will also conflict with the tone function because of its utilization of timer 2.\nThere will be no obvious compile error, but because SDI-12 and the tone library may use different clock-prescaler functions, the results for both might be rather unexpected.\nAll 8MHz AVR boards will also have unresolvable prescaler conflicts with NeoSWSerial.\nThe pre-scaler values needed for the SDI-12 functionality are set in the begin() function and reset to their original values in the end() function.\nCompatibility Considerations\nThis library has been tested with an Arduino Uno (AtMega328p), EnviroDIY Mayfly (AtMega1284p), Adafruit Feather 32u4 (AtMega32u4, identical to Arduino Leonardo), an Adafruit Feather M0 (SAMD21G18, identical to Arduino Zero), the ESP8266, and the ESP32.\nIt should also work on an Arduino Mega (AtMega2560), Gemma\/AtTiny board, and most other AVR processors  running on the Arduino framework.\nThe Arduino Due, Arduino 101, and Teensy boards are not supported at this time.\nIf you are interested in adding support for those boards, please send pull requests.\nDue to the use of pin change interrupts, not all data pins are available for use with this SDI-12 library.\nPin availability depends on the micro-controller.\nThese pins will work on those processors:\nThis library requires the use of pin change interrupts (PCINT).\nNot all Arduino boards have the same pin capabilities.\nThe known compatibile pins for common variants are shown below:\nAtMega328p \/ Arduino Uno:\n\nAny pin\n\nAtMega1284p \/ EnviroDIY Mayfly\n\nAny pin\n\nATmega2560 \/ Arduino Mega or Mega 2560:\n\n0, 11, 12, 13, 14, 15, 50, 51, 52, 53, A8 (62), A9 (63), A10 (64), A11 (65), A12 (66), A13 (67), A14 (68), A15 (69)\n\nAtMega32u4 \/ Arduino Leonardo or Adafruit Feather:\n\n8, 9, 10, 11, 14 (MISO), 15 (SCK), 16 (MOSI)\n\nSAMD21G18 \/ Arduino Zero:\n\nAny pin (except 4 on the zero)\n\nESP8266:\n\nAny GPIO, except GPIO16\n\nESP32:\n\nAny GPIO\n\nNote that not all of these pins are available with our Variants and Branches, below.\nVariants and Branches\nAs we've described, the default \"master\" branch of this library will conflict with SoftwareSerial and any other library that monopolizes all pin change interrupt vectors for all AVR boards.\nTo allow simultaneous use of SDI-12 and SoftwareSerial, we have created additional variants of these libraries that we maintain as separate branches of this repository.\nFor background information, my be helpful to read our Overview of Interrupts wiki page or this Arduino Pin Change Interrupts article.\nEnviroDIY_SDI12\nEnviroDIY_SDI12 is the default master branch of this repository.\nIt controls and monopolizes all pin change interrupt vectors, and can therefore have conflicts with any variant of SoftwareSerial and other libraries that use interrupts.\nEnviroDIY_SDI12_PCINT3\nEnviroDIY_SDI12_PCINT3 is in the Mayfly branch of this repository, and was historically was called \"SDI12_mod\".\nIt's been cropped to only control interrupt vector 3, or PCINT3 (D), which on the Mayfly (or Sodaq Mbili) corresponds to Pins D0-D7.\nIt is designed to be compatible with EnviroDIY_SoftwareSerial_PCINT12 library (which controls interrupt vectors PCINT1 (B) & PCINT2 (C) \/ Mayfly pins D08-D15 & D16-D23) and EnviroDIY PcInt PCINT0 (which controls interrupt vectors PCINT0 (A) \/ Mayfly pins D24-D31\/A0-A7).\nNote that different AtMega1284p boards have a different mapping from the physical PIN numbers to the listed digital PIN numbers that are printed on the board.\nOne of the most helpful lists of pins and interrupts vectors is in the the Pin\/Port Bestiary wiki page for the Enable Interrupt library.\nEnviroDIY_SDI12_ExtInts\nEnviroDIY_SDI12_ExtInts is the ExtInt branch of this repository.\nIt doesn't control any of the interrupts, but instead relies on an external interrupt management library (like EnableInterrupt) to assign the SDI-12 receive data function to the right pin.\nThis is the least stable because there's some extra delay because the external library is involved, but the use of timers in the SDI-12 library greatly increases it's stability.\nIt's also the easiest to get working in combination with any other pin change interrupt based library.\nIt can be paired with the EnviroDIY_SoftwareSerial_ExtInts libraries (which is, by the way, extremely unstable).\nIf you would like to use a different pin change interrupt library, uncomment the line #define SDI12_EXTERNAL_PCINT in SDI12.h and recompile the library.\nThen, in your own code call SDI12::handleInterrupt() as the interrupt for the SDI12 pin using the other interrupt library.\nExample j shows doing this in GreyGnome's EnableInterrupt library.\nContribute\nOpen an issue to suggest and discuss potential changes\/additions.\nFor power contributors:\n\nFork it!\nCreate your feature branch: git checkout -b my-new-feature\nCommit your changes: git commit -am 'Add some feature'\nPush to the branch: git push origin my-new-feature\nSubmit a pull request :D\n\nLicense\nThe SDI12 library code is released under the GNU Lesser Public License (LGPL 2.1) -- See LICENSE-examples.md file for details.\nExample Arduino sketches are released under the BSD 3-Clause License -- See LICENSE-examples.md file for details.\nDocumentation is licensed as Creative Commons Attribution-ShareAlike 4.0 (CC-BY-SA) copyright.\nCredits\nEnviroDIY\u2122 is presented by the Stroud Water Research Center, with contributions from a community of enthusiasts sharing do-it-yourself ideas for environmental science and monitoring.\nKevin M. Smith was the primary developer of the SDI-12 library, with input from S. Hicks and Anthony Aufdenkampe.\nSara Damiano is now the primary maintainer, with input from many other contributors.\nThis project has benefited from the support from the following funders:\n\nNational Science Foundation, awards EAR-0724971, EAR-1331856, ACI-1339834\nWilliam Penn Foundation, grant 158-15\nStroud Water Research Center endowment\n\n","99":"environmental-iotToolkit\n\u6c61\u67d3\u6e90\u5728\u7ebf\u81ea\u52a8\u76d1\u63a7\uff08\u76d1\u6d4b\uff09\u7cfb\u7edf\u6570\u636e\u4f20\u8f93\u6807\u51c6\uff0c\u6570\u636e\u5305\u6a21\u62df\u53d1\u9001\u7a0b\u5e8f\u3001\u68c0\u6d4b\u7a0b\u5e8f\u3002\u652f\u6301\u6c34\u3001\u6c14\u3001TVOC\n","100":"Containers\nThis is a collection of dockerfiles for common environmental software.\n","101":"Environmental-Sound-Classification-ESC-using-neural-networks-and-other-classifiers\n\nAudio feature extraction and classification with the ECS-10 data set audio dataset\nECS-10 audio data is included. It consists of 10 classes of different environmental sounds (sea waves, kids playing, etc.)\nThe main goal is to compare classification accuracies for the 6 tested classifiers.\n\nDependencies\n\nAnaconda 2 with Python 2.7. (Python 3.6 not tested yet)\nLibrosa (audio loading, audio visualization and feature extraction)\nSci-kit learn\nKeras (Theano backend)\nNumpy, Matplotlib\nPandas (data visualization)\n\nJupyter Notebook\nA Jupyter Notebook (Python 2.7 Kernel) is added to illustrate the workflow.\nThe scripts for feature extraction and classification have been added as\n.py files and are all loaded in the Jupyter Notebook sequentally.\nRunning feature_extraction.py creates a numpy array for features (feature.npy) and one for labels (label.npy).\nThese files will be saved in the current directory.\nAudio features extracted\n\nMFCC\nChroma\nMel spectrogram\nTonal centroid feature\nSpectral contrast\n\nClassifiers implemented\n\nSupport Vector Machine (SVM)\nRandom Forest (RF)\nNaive Bayes (NB)\nConvolutional Neural Network (CNN)\nMultilayer Perceptron (MLP)\nRecurrent Neural Network (RNN)\n\nAccuracies obtained\nNote: Direct comparison between classifiers can't be donde yet since their parameters haven't been tuned to optimize\naccuracy yet. Out of 400 audio samples, the test set consisted on the 33% of this.\n\nSVM: 81.7%\nRF: 80%\nNB: 69.7%\nCNN: 71.25% (100 epochs)\nMLP: 63.125 (100 epochs)\nRNN: 66% (100 epochs)\n\nApproaches to improve accuracy\n\nCompute other features: MFCC + ZCR features improve classification\naccuracy\nfor speech, noise and music labels. See if it also works for the 10 classes.\nTune optimization hyperparameters (for every classifier): Weight initialization, decaying learning rate.\nData scaling and feature normalization (MFCC)\n\n","102":"Earth and Environmental Data Science Book\n\nThis is the source repository for https:\/\/earth-env-data-science.github.io.\nTo deploy changes to the site, push to the master branch of this repo.\n","103":"   \nMitemp2_bt\nSupport for Xiaomi Mi Temp 2 BLE environmental sensor based in HA mitemp_bt component and mitemp library of @ratcashdev.\nInstallation\nFor install have three ways:\n\nDownload this repository and extract to \/custom_components\/mitemp2_bt\nAdd custom repository to HACS (Home Assistant Community Store).\nBy HACS (Home Assistant Community Store) -> COMING SOON.\n\nConfigurartion\nThe config it's the samme of mitemp_bt component execpt the platform field, for example:\n\nsensor:\n    - platform: mitemp2_bt\n    mac: 'xx:xx:xx:xx:xx:xx'\n    name: example\n    force_update: true\n    timeout: 60\n    median: 1\n    monitored_conditions:\n        - temperature\n        - humidity\n        - battery\n","104":"D4SG_\u65b0\u7af9\u7e23\u74b0\u4fdd\u5c40-\u4fbf\u5229\u8cc7\u8a0a\u770b\u677f\n\u7576\u5929\u7c21\u5831(https:\/\/www.slideshare.net\/MickeyLai2\/d4sg-81315677)\n<iframe src=\"\/\/www.slideshare.net\/slideshow\/embed_code\/key\/yzTbIGpzWkByHP\" width=\"595\" height=\"485\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" style=\"border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;\" allowfullscreen> <\/iframe>   \u3010D4SG\u3011\u65b0\u7af9\u7e23\u74b0\u4fdd\u5c40-\u4fbf\u5229\u8cc7\u8a0a\u770b\u677f(\u96db\u5f62)  from Mickey Lai \nPower BI(https:\/\/goo.gl\/81wqnm)\n\u4f7f\u7528\u7d93\u9a57\u5206\u4eab\uff1aPowerBIGeneralTips.md\n<iframe width=\"1024\" height=\"768\" src=\"https:\/\/goo.gl\/81wqnm\" frameborder=\"0\" allowfullscreen><\/iframe>\n\u8cc7\u6599\u4f86\u6e90\n\n\u65b0\u7af9\u7e23\u653f\u5e9c\u74b0\u4fdd\u5c40\uff0c\u63d0\u4f9b\u5167\u90e8\u8cc7\u6599\uff1a\u7ba1\u5236\u516c\u53f8\n\u884c\u653f\u9662\u74b0\u5883\u4fdd\u8b77\u7f72\uff0c\u74b0\u5883\u8cc7\u6e90\u8cc7\u6599\u958b\u653e\u5e73\u53f0(https:\/\/opendata.epa.gov.tw\/)\uff1a\u4e0b\u8f09\u65b0\u7af9\u7e23\u76f8\u95dc\u8cc7\u6599\uff1a\u57fa\u672c\u8cc7\u6599\u3001\u88c1\u8655\u8cc7\u6599\u3001\u6cb3\u5ddd\u7ba1\u5236\u5340\u3001\u6cb3\u5ddd\u6c34\u8cea\u76e3\u63a7\u6578\u64da\n\u900f\u660e\u8db3\u8de1(https:\/\/thaubing.gcaa.org.tw)\n\u5168\u570b\u5546\u5de5\u884c\u653f\u670d\u52d9\u5165\u53e3\u7db2(http:\/\/gcis.nat.gov.tw)\n\u516c\u53f8\u540d\u7a31&\u80a1\u7968\u4ee3\u865f\u5c0d\u7167\u8868(D4SG_Environmental-Protection\/\u516c\u53f8\u540d\u7a31&\u80a1\u7968\u4ee3\u865f\u5c0d\u7167\u8868.txt)\n\u80a1\u7968\u7db2\u7ad9\n\n\u7cfb\u7d71\u69cb\u60f3\n\u7532\u3001 \u7531\u65bc\u74b0\u4fdd\u7f72\u63d0\u4f9b\u4e4b\u57fa\u672c\u8cc7\u6599\u8f03\u70ba\u8a73\u7d30\uff0c\u5982\u4e0b\u5716\u6240\u793a\uff0c\u56e0\u6b64\uff0c\u9996\u5148\u7be9\u9078\u5217\u7ba1\u985e\u5225\u70ba\u6c34\u6c59\u67d3\u4e4b\u516c\u53f8\uff0c\u85c9\u7531\u7ba1\u5236\u7de8\u865f\u8996\u70bakey\u503c\uff0c\u5c07\u74b0\u4fdd\u5c40\u5167\u90e8\u8cc7\u6599\u4e4b\u6d41\u57df\u5225\u9032\u884cjoin\u6574\u5408\uff0c\u8ce6\u4e88\u6bcf\u4e00\u5bb6\u7ba1\u5236\u516c\u53f8\u6392\u653e\u6c59\u6c34\u4e4b\u6d41\u57df\u5225\uff0c\u4e26\u9032\u884c\u5730\u5740\u5c0d\u4f4dgeocoding\u3002\n\n\u4e59\u3001\u6211\u5011\u8a2d\u8a08\u4ee5\u5c40\u8655\u6574\u9ad4\u7684\u89d2\u5ea6\u601d\u8003\u8a2d\u8a08\u4e09\u500b\u9801\u9762\uff0c\u77ad\u89e3\u5c40\u8655\u5167\u90e8\u4e4b\u88c1\u8655\u60c5\u5f62\u4ee5\u53ca\u5404\u516c\u53f8\u88c1\u8655\u72c0\u6cc1\u3002\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\ni.\u00a0\n\u5404\u4e8b\u696d\u5225TOP5\u88c1\u7f70\u516c\u53f8\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u4ee5\u5404\u79d1\u5ba4\u4e4b\u7ba1\u5236\u4e8b\u696d\u9032\u884c\u7d71\u8a08\uff0c\u8a08\u7b97\u51fa\u8a72\u6642\u9593\u9ede\u767c\u751f\u88c1\u8655\u4e8b\u5be6\u4e4b\u524d\u4e94\u540d\u516c\u53f8\uff0c\u85c9\u6b64\u7763\u4fc3\u76f8\u95dc\u55ae\u4f4d\u9032\u884c\u76e3\u7763\u3002\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\nii.\u00a0\n\u5404\u516c\u53f8\u88c1\u8655\u60c5\u5f62\u985e\u578b\u5206\u6790\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u540c\u4e00\u9593\u516c\u53f8\u7576\u767c\u751f\u6c34\u6c59\u7136\u6642\u4ea6\u6709\u53ef\u80fd\u540c\u6642\u4f34\u96a8\u7a7a\u6c23\u6c59\u67d3\uff0c\u6b64\u4ecb\u9762\u5e0c\u671b\u95dc\u806f\u5404\u79d1\u5ba4\u9593\u7684\u6a6b\u5411\u6e9d\u901a\uff0c\u7576\u4e00\u55ae\u4f4d\u767c\u751f\u7a7a\u6c23\u6c59\u67d3\u6642\uff0c\u53ef\u7acb\u5373\u5354\u8abf\u53e6\u4e00\u55ae\u4f4d\u9032\u884c\u8a2a\u8996\u3002\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\niii.\u00a0\n\u8ca1\u7f70\u8207\u71df\u904b\u8cc7\u8a0a\u63ed\u9732\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u8207\u5916\u90e8\u7db2\u7ad9\u6574\u5408\u53d6\u5f97\u5404\u516c\u53f8\u7576\u5b63\u7a05\u7d14\u76ca\u8cc7\u8a0a\uff0c\u5e0c\u671b\u85c9\u7531\u6b64\u6578\u64da\u77ad\u89e3\u88c1\u7f70\u91d1\u984d\u8207\u5229\u6f64\u4e4b\u95dc\u4fc2\uff0c\u90e8\u5206\u4f01\u696d\u5c0d\u65bc\u88c1\u7f70\u60c5\u5f62\u4e0d\u75db\u4e0d\u7662\uff0c\u85c9\u7531\u6b64\u90e8\u5206\u5e0c\u671b\u7701\u601d\u88c1\u7f70\u91d1\u984d\u8207\u4f01\u696d\u8cac\u4efb\u4e4b\u9053\u5fb7\u89c0\u3002\n\n\u4e19\u3001 \u6c34\u6c59\u67d3\u70ba\u672c\u5c08\u6848\u4e4b\u91cd\u9ede\uff0c\u7531\u65bc\u4e0d\u540c\u6cb3\u5ddd\u6709\u5176\u6240\u5c6c\u6d41\u57df\u548c\u7ba1\u5236\u7bc4\u570d\uff0c\u6cb3\u5ddd\u6c34\u9ad4\u672c\u8eab\u4ea6\u6709\u4e0d\u540c\u7b49\u7d1a\uff0c\u56e0\u6b64\u5c0d\u65bc\u6bcf\u4e00\u500b\u7ba1\u5236\u6d41\u57df\u63a2\u8a0e\u5176\u5e38\u767c\u751f\u88c1\u8655\u4e4b\u516c\u53f8\u4e8b\u696d\u985e\u5225\uff0c\u4ee5\u53ca\u88c1\u8655\u4e8b\u5be6\u4e4b\u6642\u9593\u5206\u6790\u548c\u6cb3\u5ddd\u6c34\u8cea\u60c5\u5f62\uff0c\u4e00\u5171\u8a2d\u8a08\u4e09\u7a2e\u9801\u9762\uff0c\u5176\u4e2d\u6cb3\u5ddd\u6c34\u8cea\u60c5\u5f62\u53ef\u6709\u4e0d\u540c\u7684\u6c34\u8cea\u6aa2\u6e2c\u9805\u76ee\u9032\u884c\u63a2\u8a0e\u3002\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\ni.\u00a0\n\u6c34\u6c59\u67d3\u88c1\u7f70\u6848\u4ef6\u8207\u4e8b\u696d\u5225\u5206\u6790\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u4f9d\u64da\u516c\u53f8\u5750\u843d\u4f4d\u7f6e\u548c\u6c34\u6c59\u67d3\u6392\u653e\u4e4b\u6d41\u57df\u9032\u884c\u5206\u6790\uff0c\u4ee5\u8996\u89ba\u5316\u65b9\u5f0f\u5448\u73fe\u4e0d\u540c\u6d41\u57df\u5e38\u767c\u751f\u88c1\u7f70\u4e8b\u5be6\u4e4b\u4e8b\u696d\u5225\u548c\u5ea7\u843d\u4f4d\u7f6e\uff0c\u4ee5\u5f37\u5316\u7a3d\u67e5\u6548\u7387\u3002\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\nii.\u00a0\n\u6c34\u6c59\u67d3\u88c1\u7f70\u6848\u4ef6\u8207\u6642\u9593\u5206\u6790\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u4ee5\u8996\u89ba\u5316\u65b9\u5f0f\u5448\u73fe\u5404\u6d41\u57df\u5728\u4e0d\u540c\u6642\u9593\u9ede\u4e4b\u88c1\u8655\u6578\u64da\u548c\u6708\u4efd\u5206\u6790\uff0c\u5c07\u7a3d\u67e5\u91cd\u9ede\u653e\u5728\u904e\u53bb\u5e38\u767c\u751f\u4e4b\u88c1\u8655\u5730\u5340\u548c\u6708\u4efd\uff0c\u63d0\u5347\u7a3d\u67e5\u4eba\u54e1\u4e4b\u6548\u7387\u3002\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\niii.\u00a0\n\u88c1\u7f70\u6848\u4ef6\u8207\u6c34\u8cea\u5206\u6790\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u7531\u65bc\u4e0d\u540c\u6d41\u57df\u4e4b\u6cb3\u5ddd\u6c34\u9ad4\u7b49\u7d1a\u4e0d\u540c\uff0c\u4ee5\u53ca\u6d41\u57df\u4e2d\u5c0d\u65bc\u6c34\u6c59\u67d3\u6392\u653e\u5f8c\u6307\u6578\u4e4b\u654f\u611f\u5ea6\u4e0d\u540c\uff0c\u56e0\u6b64\uff0c\u6b64\u9801\u9762\u4ee5\u5730\u5716\u642d\u914d\u76e3\u6e2c\u9ede\u7684\u65b9\u5f0f\u5448\u73fe\uff0c\u7531\u5167\u90e8\u5177\u6709\u6c34\u8cea\u9ad8\u5ea6\u654f\u611f\u5ea6\u4e4b\u4eba\u54e1\uff0c\u85c9\u7531\u6c34\u8cea\u6ce2\u52d5\u6578\u64da\u89c0\u5bdf\u662f\u5426\u6709\u88c1\u8655\u7684\u60c5\u5f62\uff0c\u5f9e\u4e0a\u4e2d\u4e0b\u6e38\u6578\u64da\u4e4b\u89c0\u5bdf\uff0c\u4ee5\u53ca\u4e0d\u540c\u6d41\u57df\u5e38\u767c\u751f\u88c1\u8655\u4e8b\u5be6\u4e4b\u4e8b\u696d\u5225\u61c9\u8a72\u89c0\u6e2c\u90a3\u4e9b\u6c34\u8cea\u6578\u64da\u3002\n\n\u8cc7\u6599\u8655\u7406\u6b65\u9a5f(\u722c\u7db2\u6642\u8acb\u63a7\u5236\u7a0b\u5f0f\u57f7\u884c\u983b\u7387\uff0c\u4e0d\u8981\u5f71\u97ff\u76ee\u6a19\u7db2\u7ad9\u6b63\u5e38\u71df\u904b!!!)\n\nStep1. \u8655\u7406\u597d\u74b0\u4fdd\u7f72\u958b\u653e\u8cc7\u6599\u5f8c\uff0c\u53d6\u51fa\u516c\u53f8\u540d\u7a31\uff0c\u81f3\u900f\u660e\u8db3\u8de1\u722c\u53d6\u76f8\u95dc\u8cc7\u8a0a(Use R)\nlibrary(RODBC)\nlibrary(httr)\n\nregexp <- function(pattern, data, idx=1L, is.split=FALSE, spt=NULL) {\n  text <- data[idx]\n  v <- regexpr(pattern, text)\n  n <- unlist(lapply(strsplit(pattern, \"\\\\.\\\\+\"), nchar))\n  out <- substr(text, v + n[1], v + attr(v,\"match.length\") - (n[2]+1))\n  if (is.split) unlist(strsplit(out, spt)) else out\n} # end regexp()\n\n\n## \u7d44\u51fa\u722c\u7db2URL\nurl_front <- \"https:\/\/thaubing.gcaa.org.tw\/envmap?facility_name=&corp_id=&industry_name=All&poltype=All&factory_fine=1&id_2=All&page=0&qt-front_content=1&facility_name=\"\nurl_end <- \"&corp_id=&industry_name=All&poltype=All&factory_fine=1&id_2=All\"\nget_url <- paste0(url_front, \"\u5cfb\u6e90\u80a1\u4efd\u6709\u9650\u516c\u53f8\", url_end)\n\n\n## \u81f3\u900f\u660e\u8db3\u8de1\u722c\u53d6\u8cc7\u6599=>\u5148\u53d6\u5f97\u8a72\u516c\u53f8\u5728\u900f\u660e\u8db3\u8de1\u7db2\u5740\nhtml <- GET(get_url)\nweb_content <- content(html, \"text\", encoding = \"UTF-8\")\n\ntarget_path <- regexp(paste0('<div class=\\\"views-field views-field-facility-name factory-name\\\"><span class=\\\"field-content\\\"><a href=\\\".+\\\">', \"\u5cfb\u6e90\u80a1\u4efd\u6709\u9650\u516c\u53f8\", '<\/a>'), web_content)\n\nprint(target_path)\n## [1] \"\/facility\/J5604458\"\ndns <- \"https:\/\/thaubing.gcaa.org.tw\"\ntarget_url <- paste0(dns, target_path)\n\n## \u958b\u59cb\u91dd\u5c0d\u76ee\u6a19\u516c\u53f8\u722c\u53d6\u8cc7\u6599\ntmp <- read_html(target_url, encoding = \"UTF-8\")\n  \nweb_content <- tmp %>% html_nodes('.views-field-corp-id')\ncorp_id <- web_content %>% html_nodes('a') %>% html_text()\n  \nweb_content <- tmp %>% html_nodes('.views-field-facility-name')\ncorp_name <- web_content %>% html_nodes('.field-content') %>% html_text()\n  \nweb_content <- tmp %>% html_nodes('.views-field-facility-address')\naddress <- web_content %>% html_nodes('.field-content') %>% html_text()\n\nweb_content <- tmp %>% html_nodes('.views-field-industry-area-name')\nindustry_area <- web_content %>% html_nodes('.field-content') %>% html_text()\n  \nweb_content <- tmp %>% html_nodes('.views-field-industry-name')\nindustry <- web_content %>% html_nodes('.field-content') %>% html_text()\n  \nweb_content <- tmp %>% html_nodes('.views-field-poltype')\napply_type <- web_content %>% html_nodes('.field-content') %>% html_text()\n  \nweb_content <- tmp %>% html_nodes('.views-field-updatetime')\nsnap_date <- web_content %>% html_nodes('.field-content') %>% html_text()\n\nprint(paste0('\u516c\u53f8\u7d71\u7de8:', corp_id, ';\u516c\u53f8\u540d\u7a31:', corp_name, ';\u516c\u53f8\u5730\u5740:', address))\n## [1] \"\u516c\u53f8\u7d71\u7de8:27873415;\u516c\u53f8\u540d\u7a31:\u5cfb\u6e90\u80a1\u4efd\u6709\u9650\u516c\u53f8;\u516c\u53f8\u5730\u5740:\u65b0\u7af9\u7e23\u95dc\u897f\u93ae\u5357\u65b0\u91cc\u65b0\u57ce\uff11\u4e4b\uff11\u3001\uff11\u4e4b\uff17\u865f\"\nStep2. \u5229\u7528\u81ea\u900f\u660e\u8db3\u8de1\u722c\u53d6\u4e4b\u516c\u53f8\u7d71\u7de8\uff0c\u81f3\u653f\u5e9c\u8cc7\u6599\u958b\u653e\u5e73\u53f0\u722c\u53d6\u516c\u53f8\u5b8c\u6574\u8cc7\u8a0a(Use R)\n\u8a3b:\u653f\u5e9c\u8cc7\u6599\u958b\u653e\u5e73\u53f0\u6709\u63d0\u4f9bAPI\u4ecb\u63a5\u7533\u8acb\uff0c\u6709\u9700\u8981\u5927\u91cf\u722c\u53d6\u8cc7\u6599\u8005\u8a18\u5f97\u4e8b\u5148\u7533\u8acb~~\nlibrary(jsonlite)\n\nURL <- paste(\"http:\/\/data.gcis.nat.gov.tw\/od\/data\/api\/5F64D864-61CB-4D0D-8AD9-492047CC1EA6?$format=json&$filter=Business_Accounting_NO%20eq%20\", corp_id, sep=\"\")\ncorp_content <- readLines(URL, encoding = \"UTF-8\")\n## Warning in readLines(URL, encoding = \"UTF-8\"): \u65bc 'http:\/\/\n## data.gcis.nat.gov.tw\/od\/data\/api\/5F64D864-61CB-4D0D-8AD9-492047CC1EA6?\n## $format=json&$filter=Business_Accounting_NO%20eq%2027873415' \u627e\u5230\u4e0d\u5b8c\u6574\u7684\u6700\n## \u5f8c\u4e00\u5217\ndf <- fromJSON(corp_content)\nprint(df)\n##   Business_Accounting_NO Company_Status_Desc     Company_Name\n## 1               27873415            \u6838\u51c6\u8a2d\u7acb \u5cfb\u6e90\u80a1\u4efd\u6709\u9650\u516c\u53f8\n##   Capital_Stock_Amount Paid_In_Capital_Amount Responsible_Name\n## 1             75550000               75550000            \u55bbO\u82ab\n##                  Company_Location Register_Organization_Desc\n## 1 \u65b0\u7af9\u7e23\u95dc\u897f\u93ae\u5357\u65b0\u91cc9\u9130\u65b0\u57ce1\u4e4b1\u865f           \u7d93\u6fdf\u90e8\u4e2d\u90e8\u8fa6\u516c\u5ba4\n##   Company_Setup_Date Change_Of_Approval_Data Revoke_App_Date Case_Status\n## 1            0940819                 1061026                            \n##   Case_Status_Desc Sus_App_Date Sus_Beg_Date Sus_End_Date\n## 1\n\u8a3b\uff1aCapital_Stock_Amount\uff1a\u8cc7\u672c\u7e3d\u984d(\u5143)\uff1bPaid_In_Capital_Amount\uff1a\u5be6\u6536\u8cc7\u672c\u984d(\u5143)\nStep3. \u5229\u7528\u516c\u53f8\u5b8c\u6574\u540d\u7a31\u6574\u4f75\"\u516c\u53f8\u540d\u7a31&\u80a1\u7968\u4ee3\u865f\u5c0d\u7167\u8868.txt\"\uff0c\u53d6\u5f97\u516c\u53f8\u7d71\u7de8\u5f8c\uff0c\u81f3\u80a1\u7968\u7db2\u7ad9\u722c\u53d6\u8ca1\u5831\u8cc7\u8a0a(Use Python)\n\u6b64\u90e8\u5206\u9700\u900f\u904eSelenium\u5957\u4ef6\u5be6\u73fe\uff0c\u5b8c\u6574\u7a0b\u5f0f\u78bc\u8acb\u53c3\u8003\"stock_scrawler.py\"\n\u6e96\u5099\u4e8b\u9805\n\u5728\u958b\u59cb\u4f7f\u7528python\u722c\u87f2\u524d\uff0c\u8981\u5148\u5b89\u88dd\u597d\u4e0b\u5217\u76f8\u95dc\u5957\u4ef6\u53caWebDriver\u3002\npip3 install selenium pandas\n# for MacOS\nbrew install geckodriver\n\nSelenium \u70ba\u700f\u89bd\u5668\u7684\u81ea\u52d5\u5316\u5de5\u5177\uff0c\u53ef\u4ee5\u81ea\u52d5\u5316\u6a21\u64ec\u700f\u89bd\u5668\u9032\u884c\u52d5\u4f5c\uff0c\u591a\u7528\u65bc\u76f4\u63a5\u64cd\u4f5c\u700f\u89bd\u5668\u9032\u884c\u81ea\u52d5\u5316\u6e2c\u8a66\uff0c\u6b64\u6b21\u85c9\u7531\u700f\u89bd\u5668\u64cd\u4f5c\u6293\u53d6\u80a1\u7968\u7db2\u7ad9\u7684\u8cc7\u6599\u3002\n\n\nPandas \u70ba\u8655\u7406\u6578\u64da\u8cc7\u6599\u7684\u5957\u4ef6\uff0c\u64c5\u9577\u8655\u7406\u4e00\u7dad\u6578\u64da\u53ca\u4e8c\u7dad\u7684\u8868\u683c\u6578\u64da, \u53ef\u4ee5\u76f4\u63a5\u8b80\u53d6\u591a\u7a2e\u683c\u5f0f(HTML, csv, excel, json...)\uff0c\u8f49\u63db\u4e58DataFrame\uff0c\u9032\u884c\u8cc7\u6599\u8655\u7406\u3002\n\n\u958b\u59cb\u722c\u87f2\nfrom selenium import webdriver\nimport pandas as pd\n\ndriver = webdriver.Firefox()      # Open the Firefox browser\ndriver.set_page_load_timeout(10)  # Set the longest loading time for each page\n\n# Read \u516c\u53f8\u540d\u7a31&\u80a1\u7968\u4ee3\u865f\u5c0d\u7167\u8868.txt\nwith open('.\/stock_list.txt', 'r') as fin:\n    company_code_list = fin.read().split(\"\\n\")\n    for company_code in company_code_list:\n        # Assign the URL of target page to url variable\n        url = \"http:\/\/www.cmoney.tw\/finance\/f00041.aspx?s=\" \\\n        + company_code.strip()\n        # Let browser GET the page\n        driver.get(url)\n        # Use css selector to get the elements whose class is \"tb-out\"\n        table = driver.find_element_by_css_selector(\".tb-out\")\n        # Use pandas to read table and convert it to DataFrame\n        df = pd.read_html(table.get_attribute('innerHTML'))\n        # Write out the DataFrame as csv file to stock_table\/ folder\n        df[0].to_csv('stock_table\/'+company_code+'.csv', index=False)\n\u7a0b\u5f0f\u57f7\u884c\u5b8c\u6210\u5f8c\uff0c\u5373\u53ef\u4ee5\u5728.\/stock_table\u770b\u898b\u5982\u4e0b\u7684\u8a31\u591a\u722c\u53d6\u8cc7\u6599\u7684csv\u6a94\u6848\n.\n|____1102.csv\n|____1402.csv\n...\n|____8150.csv\n|____8421.csv\n\u8cc7\u6599\u9650\u5236\u548c\u5efa\u8b70\n\ni.\u00a0\n\u74b0\u4fdd\u7f72\u57fa\u672c\u8cc7\u6599\u63d0\u4f9b\u5730\u5740\u8cc7\u6599\uff0c\u5efa\u8b70\u53ef\u958b\u653e\u5167\u90e8\u5df2\u5b8c\u6210geocoding\u4e4b\u5750\u6a19\u8cc7\u6599\uff0c\u4e26\u52a0\u4e0a\u6d41\u57df\u5225\u6b04\u4f4d\u8b93\u4f7f\u7528\u8005\u5229\u65bc\u8fa8\u8b58\u4f7f\u7528\u3002\n\nii.\u00a0\n\u6c34\u8cea\u6578\u64da\u70ba\u6bcf\u6708\u50c5\u76e3\u6e2c\u4e00\u6b21\u4e14\u6aa2\u6e2c\u6642\u9593\u9593\u683c\u70ba30\u5929\u4e00\u6b21\uff0c\u5c0d\u65bc\u610f\u5716\u6392\u653e\u6c59\u6c34\u4e4b\u4f01\u696d\u4e26\u7121\u5be6\u8cea\u76e3\u63a7\u6548\u679c\uff0c\u4e14\u7576\u6a23\u672c\u6578\u591a\u6642\uff0c\u6c34\u8cea\u6578\u64da\u5c0d\u65bc\u76e3\u6e2c\u60c5\u5f62\u624d\u6709\u986f\u8457\u5e6b\u52a9\u3002\n\n\niii.\u00a0\n\u73fe\u6709\u6c34\u8cea\u76e3\u6e2c\u9ede\u4ee5\u6cb3\u5ddd\u652f\u6d41\u4e2d\u5fc3\u9ede\u8207\u51fa\u6d77\u53e3\u70ba\u4e3b\uff0c\u7121\u6cd5\u6709\u6548\u638c\u63e1\u5373\u6642\u5ee2\u6c34\u6392\u653e\u60c5\u5f62\uff0c\u672a\u4f86\u61c9\u589e\u52a0\u5373\u6642\u76e3\u63a7\u8a2d\u5099\u624d\u6709\u52a9\u65bc\u5687\u963b\u4f01\u696d\u4e4b\u6c59\u6c34\u6392\u653e\u3002\n\u6176\u529f\u5bb4\n\n\n\n\n","105":"Wildlife Tracker\nAn app for the forest service to track animals for an environmental impact study.\nDescription\nThe Forest Service is considering a proposal from a timber company to clearcut a nearby forest of Douglas Fir. Before this proposal may be approved, they must complete an environmental impact study. This application was developed to allow Rangers to track wildlife sightings in the area.\nSetup\nTo create the necessary databases, launch postgres, then psql, and run the following commands:\n\nCREATE DATABASE wildlife_tracker;\n\\c wildlife_tracker;\nCREATE TABLE animals (id serial PRIMARY KEY, name varchar);\nCREATE TABLE endangered_animals (id serial PRIMARY KEY, name varchar, health varchar, age varchar);\nCREATE TABLE sightings (id serial PRIMARY KEY, animal_id int, location varchar, ranger_name varchar);\nCREATE DATABASE wildlife_tracker_test WITH TEMPLATE wildlife_tracker;\n\nLicense\nCopyright (c) 2017 MIT License\n","106":"eesR\nCode and data associated with \"Environmental and Ecological Statistics with R\" (2nd edition)\nExample chapter -- chapter 11\n","107":"Environmental Informatics at UCSB \nFork and clone this repository. Introduce yourself by adding a file per your Github username.json under the _data\/ directory. Here's an example for Github username bbest:\n\/\/ _data\/bbest.json\n{\n\t\"program\": \"lecturer\",\n\t\"interests\": \"marine biology, species distribution modeling, spatial decision-making\",\n\t\"project\": \"route ships around marine mammal hot spots\"\n}\nUsing the format above, replace with your own program, interests and project idea. Create an Rmarkdown document also with your username under the students folder with more details on your project idea, commit and push the changes, and submit a pull request to the original repository.\nAcknowledgements\nThe content on this site draws extensively from these repositories:\n\nhttps:\/\/github.com\/advanced-js\/students\nhttps:\/\/github.com\/datacarpentry\/R-ecology\n\nTesting\ncd ~\/github\/ESM296-3W-2016\/\nbundle exec jekyll serve --baseurl ''\n\/usr\/local\/bin\/jekyll serve --baseurl ''\n","108":"\n\n\n\n\nSome people feel that shipping .json \/ .yml \/ .xml config files is an upgrade over using archaic environment variables.\n\nDon't let your app load its config, inject it instead.\nUnix environment vars are ideal for configuration and I have yet to encounter an application that wouldn't be better off with them. Why?\n\nYou can override a value at near-runtime without having to change\/backup config files: DEBUG=*.* node run.js\nYou can inject environment variables (passwords, API keys) into the memory of a process belonging to a non-privileged user: source envs\/production.sh && sudo -EHu www-data node run.js without having to run \/ write any software for it.\nYou can inherit. Inside staging.sh, just source production.sh, inside kevin.sh source development.sh\nYour operating system is aware and provides tools to inspect, debug, optionally pass on to other processes, etc.\nYou can directly use config across languages, e.g. in supporting BASH scripts\nYou can directly use the config in a terminal yourself, e.g. cd ${MYAPP_DIR}\n\nAnd as with any other type of config:\n\nYou can group\/save them into files and keep them out of version control\n\nOne downside of environment variables is that there is little convention and syntactic sugar in the high-level languages. It doesn't feel atomic and you think it's more likely to let you down. This module attempts to change that.\nEnvironmental doesn't:\n\nBreak 12-factor\nGet in your way\n\nEnvironmental does:\n\nImpose one way of dealing with environment variables\nMake vars available in nested format inside your app (e.g. MYAPP_REDIS_HOST) becomes config.redis.host\n<3 unix\nInterpret multiple inherited bash environment files in an isolated environment to capture them, and prepare them for exporting to Nodejitsu or Heroku.\n\nConventions\nLayout\nEnvironmental tree:\n_default.sh\n\u251c\u2500\u2500 development.sh\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 test.sh\n\u2514\u2500\u2500 production.sh\n\u00a0\u00a0  \u2514\u2500\u2500 staging.sh.sh\nOn disk:\nenvs\/\n\u251c\u2500\u2500 _default.sh\n\u251c\u2500\u2500 development.sh\n\u251c\u2500\u2500 production.sh\n\u251c\u2500\u2500 staging.sh\n\u2514\u2500\u2500 test.sh\nYou could make this super-DRY, but I actually recommend using mainly\ndevelopment.sh and production.sh, and duplicate keys between them\nso you can easily compare side by side.\nThen just use _default.sh, test.sh, staging.sh for tweaks, to keep things\nclear. Read 'Inheritance can be a bitch' to see why.\nInheritance can be a bitch\nOne common pitfall is re-use of variables:\nexport MYSQL_HOST=\"127.0.0.1\"\nexport MYSQL_URL=\"mysql:\/\/user:pass@${MYSQL_HOST}\/dbname\"\nThen when you extend this and only override MYSQL_HOST, obviously the MYSQL_URL will remain unaware of your host change. Ergo: duplication of vars might be the lesser evil here compared to going out of your way to DRY things up.\nInject features\nInstead of having your code make decisions based on environment:\nif process.env.NODE_ENV == \"production\"\n  # Install cronjobs\nKeep that responsibility with your environment files:\n$ cat envs\/_default_.sh\nTLS_CRONJOBS_INSTALL=\"0\"\n\n$ cat envs\/production.sh\nTLS_CRONJOBS_INSTALL=\"1\"\nif config.cronjobs.install == \"1\"\n  # Install cronjobs\nMandatory and unprefixed variables\nThese variables are mandatory and have special meaning. There is no syntactic sugar for them, you are to access them via process.env.<var>:\nexport NODE_APP_PREFIX=\"MYAPP\" # filter and nest vars starting with MYAPP right into your app\nexport NODE_ENV=\"production\"   # the environment your program thinks it's running\nexport DEPLOY_ENV=\"staging\"    # the machine you are actually running on\nexport DEBUG=*.*               # used to control debug levels per module\nAfter getting that out of the way, feel free to start hacking, prefixing all\nother vars with MYAPP - or the actual short abbreviation of your app name. Don't use an underscore _ in this name.\nIn this example, TLS is our app name:\nexport NODE_APP_PREFIX=\"TLS\"\nexport TLS_REDIS_HOST=\"127.0.0.1\"\nexport TLS_REDIS_USER=\"jane\"\nGetting started\nIn a new project, type\n$ npm install --save environmental\nThis will install the node module. Next you'll want to set up an example environment as shown in layout, using these templates:\ncp -Ra node_modules\/environmental\/envs .\/envs\nAdd envs\/*.sh to your project's .gitignore file so they are not accidentally committed into your repository.\nHaving env files in Git can be convenient as you're still protoyping, but once you go live you'll want to change all credentials and sync your env files separately from your code.\nAccessing config inside your app\nStart your app in any of these ways:\nsource envs\/development.sh\nnode myapp.js\nsource envs\/production.sh\nDEBUG=*.* node myapp.js\nsource envs\/staging.sh\n# Following seems weird, but sudo will not preserve $PATH, regardless of -E\nsudo -EHu www-data env PATH=${PATH} node myapp.js\nsource envs\/development.sh && node myapp.js\nstart myapp # see upstart example below\nInside your app you can now obviously already just access process.env.MYAPP_REDIS_HOST, but Environmental also provides some syntactic sugar so you could type config.redis.host instead. Here's how:\nvar config = require('environmental').config();\nconsole.log(config);\n\n\/\/ This will return\n\/\/\n\/\/   { redis: { host: '127.0.0.1' } }\nOr in coffeescript if that's your cup of tea:\nconfig      = require(\"environmental\").config()\nredisClient = redis.createClient(config.redis.port, config.redis.host)\nAs you see\n\nany underscore _ in env var names signifies a new nesting level of configuration\nall remaining keys are lowercased\n\nconfig takes two arguments: flat defaulting to process.env, and filter, defaulting to process.env.NODE_APP_PREFIX. Changing these allow you to inject or reload environment variables.\nCapturing a specific config file\nBy default, environmental code will capture environment variables of the current process. However, you can also use it to capture variables in isolation as produced by a gives shell file (works with inherits too).\nenv = new Environmental\nenv.capture \"#{__dirname}\/envs\/production.sh\", (err, flat) ->\n  expect(err).to.be.null\n  expect(flat.MYAPP_REDIS_HOST, \"127.0.0.1\")\nNotice in does not nest the configuration. You can do that by using the config method and passing it flat environment vars:\nconfig = Environmental.config flat, \"MYAPP\"\n\nexpect(config).to.deep.equal\n  redis:\n    host: \"127.0.0.1\"\nExporting to Nodejitsu\nNodejitsu also works with environment variables. But since those are hard to ship, they want you to bundle them in a json file.\nEnvironmental can create such a temporary json file for you from the command-line. In this example it figures out all vars from envs\/production.sh (even if it inherits from other files):\n.\/node_modules\/.bin\/environmental --file=envs\/production.sh --format=json > \/tmp\/jitsu-env.json\njitsu --confirm env load \/tmp\/jitsu-env.json\njitsu --confirm deploy\nrm \/tmp\/jitsu-env.json\nExporting to Heroku\nheroku config:set $(.\/node_modules\/.bin\/environmental --file=envs\/production.sh --format=space)\nExporting to your own servers\nTo generate a single file that your server can source:\n.\/node_modules\/.bin\/environmental --file=envs\/production.sh --format=newline\nNote that this is different from:\nsource envs\/production.sh && env\nAs the output is cleansed from any environment variable that was not declared in env\/production.sh or one of it's ancestors.\nYou could use this list to inject into a process upon (re)starts, or save as a file so upstart can inject it into a non-privileged process, and use e.g. rsync to distribute it amongst privileged users:\nfor host in `echo ${MYAPP_SSH_HOSTS}`; do\n  rsync \\\n   --recursive \\\n   --links \\\n   --perms \\\n   --times \\\n   --devices \\\n   --specials \\\n   --progress \\\n  .\/envs\/ ${host}:${MYAPP_DIR}\/envs\ndone\nInjecting into a non-privileged user process\nWhen you deploy your app into production and you run the servers yourself, you might want to use upstart to respawn your process after crashes.\nHere's how an upstart file (\/etc\/init\/myapp) could look like, where the root user injects the environment keys into process memory of an unpriviliged user.\nThis has the big security advantage that you own program cannot even read its credentials from disk.\nstop on runlevel [016]\nstart on (started networking)\n\nrespawn\nrespawn limit 10 5\n\nlimit nofile 32768 32768\n\npre-stop exec status myapp | grep -q \"stop\/waiting\" && initctl emit --no-wait stopped JOB=myapp || true\n\nscript\n  exec bash -c \"cd \/srv\/myapp\/current \\\n    && chown root envs\/*.sh \\\n    && chmod 600 envs\/*.sh \\\n    && source envs\/production.sh \\\n    && exec sudo -EHu www-data make start 2>&1\"\nend script\nTodo\n\n Offer better ways for syncing config without Git\n A means of requiring vars for particular environments, and failing hard\/early\n Better (more compact, more consise) API language\n More tests\n Integrate with Heroku as an export target\n\nSponsor Development\nLike this project? Consider a donation.\nYou'd be surprised how rewarding it is for me see someone spend actual money on these efforts, even if just $1.\n\n\n\n\n","109":"\n\n\nlayout\npermalink\n\n\n\n\ndefault\n\/index.html\n\n\n\nGetting Started\nExample\nSparks-bot is modelled after the adafruit open-source esp8266 robot that can be found here\nFeather Line\nAdafuit maintains a bunch of open-source and free libraries you can use because they are a hardware\/education company. For this project, we will be using mostly products available on the Feather line, which allows for a huge catalog of supported devices and guaranteed support.\nEsp8266 Docs\nAdafruit maintains libraries, tutorials, and the actual hardware schematics here\nROS\nRobot Operating System, based on Ubuntu.\nNetworking\nThe ssid is 'sparks-net'.\nThe password is 'sciencerules!'\nRobot Control Software\nAdafruit has a variety of boards with the 'Feather' name. These are boards that play nice with each other by easily sharing data, power, and control pins where appropriate. In many cases, these board stack on top of each other. There are also cheap adapters  that connect these boards side-by-side, supporting up to 3 boards. However, you will have to do a power budget to ensure that you have enough current (measured in mA) to power everything you want to do. If you're very clever, you can power your sensors on at different times and conserve power.\nesp8266-robot\nThis is the software to build a web-controlled robot using the esp8266. It supports the current configuration of the esp-8266 board driving the Feather DC motor board\nData Server Software link\ninterface link\nThis folder contains the html, css, and javascript code that makes a website in a browser that can control your robot. It currently supports, up, down, left, and right, buttons that then send json requests to the hard-coded ip address in the script.js document. Currently, it is set to 192.168.50.138. This can be run on any computer that is connected to the same network as the robot. Style.css is the stylesheet, and demo.html is the webpage that you open in the browser. Either double-click that file or open it in firefox using the command line.\nfirefox demo.html &\n\n","110":"SI7021\nArduino library for SI7020 and SI7021 environmental sensors\n","111":"Classification-of-Environmental-Sound-using-Deep-Learning\nThe ESC-50 dataset is a labeled collection of 2000 environmental audio recordings suitable for benchmarking methods of environmental sound classification.  The dataset consists of 5-second-long recordings organized into 50 semantical classes (with 40 examples per class) loosely arranged into 5 major categories:\nThe ESC-50 dataset is a labeled collection of 2000 environmental audio recordings suitable for benchmarking methods of environmental sound classification.\nThe dataset consists of 5-second-long recordings organized into 50 semantical classes (with 40 examples per class) loosely arranged into 5 major categories:\n\n\n\nAnimals\nNatural soundscapes & water sounds \nHuman, non-speech sounds\nInterior\/domestic sounds\nExterior\/urban noises\n\n\n\n\nDog\nRain\nCrying baby\nDoor knock\nHelicopter\n\n\nRooster\nSea waves\nSneezing\nMouse click\nChainsaw\n\n\nPig\nCrackling fire\nClapping\nKeyboard typing\nSiren\n\n\nCow\nCrickets\nBreathing\nDoor, wood creaks\nCar horn\n\n\nFrog\nChirping birds\nCoughing\nCan opening\nEngine\n\n\nCat\nWater drops\nFootsteps\nWashing machine\nTrain\n\n\nHen\nWind\nLaughing\nVacuum cleaner\nChurch bells\n\n\nInsects (flying)\nPouring water\nBrushing teeth\nClock alarm\nAirplane\n\n\nSheep\nToilet flush\nSnoring\nClock tick\nFireworks\n\n\nCrow\nThunderstorm\nDrinking, sipping\nGlass breaking\nHand saw\n\n\n\nDownload Dataset\nEach sound is 5 second long, this project change it to 10 second long i.e. double the duration of each sound.\nPlease go to this link for more details from here:\nhttps:\/\/github.com\/karoldvl\/ESC-50\nExplain Dataset (Presprocessing)\n\n\naudio\/*.wav\n2000 audio recordings in WAV format (5 seconds, 44.1 kHz, mono) with the following naming convention:\n{FOLD}-{CLIP_ID}-{TAKE}-{TARGET}.wav\n\n{FOLD} - index of the cross-validation fold,\n{CLIP_ID} - ID of the original Freesound clip,\n{TAKE} - letter disambiguating between different fragments from the same Freesound clip,\n{TARGET} - class in numeric format [0, 49].\n\n\n\nmeta\/esc50.csv\nCSV file with the following structure:\n\n\n\nfilename\nfold\ntarget\ncategory\nesc10\nsrc_file\ntake\n\n\n\nThe esc10 column indicates if a given file belongs to the ESC-10 subset (10 selected classes, CC BY license).\n\n\nmeta\/esc50-human.xlsx\nAdditional data pertaining to the crowdsourcing experiment (human classification accuracy).\n\n\nSo from there one can easily create the dataset based on input (.wav) and its corresponding target(class in numeric format[0,49]).\n\n\n[Example]:\n\n1-16746-A-15.wav ~ class 15\n1-18631-A-23.wav ~ class 2 and so on.\n\n\n\nAlso one can get the category name as well as from the meta\/esc50.csv.\nwhere [0,49] are the class in numeric format and there target.\n\n{0: 'dog', 1: 'rooster', 2: 'pig', 3: 'cow', 4: 'frog', 5: 'cat', 6: 'hen', 7: 'insects', 8: 'sheep',\n9: 'crow', 10: 'rain', 11: 'sea_waves', 12: 'crackling_fire', 13: 'crickets',\n14: 'chirping_birds', 15: 'water_drops', 16: 'wind', 17: 'pouring_water', 18: 'toilet_flush',\n19: 'thunderstorm', 20: 'crying_baby', 21: 'sneezing', 22: 'clapping', 23: 'breathing',\n24: 'coughing', 25: 'footsteps', 26: 'laughing', 27: 'brushing_teeth', 28: 'snoring',\n29: 'drinking_sipping', 30: 'door_wood_knock', 31: 'mouse_click', 32: 'keyboard_typing',\n33: 'door_wood_creaks', 34: 'can_opening', 35: 'washing_machine', 36: 'vacuum_cleaner',\n37: 'clock_alarm', 38: 'clock_tick', 39: 'glass_breaking', 40: 'helicopter', 41: 'chainsaw',\n42: 'siren', 43: 'car_horn', 44: 'engine', 45: 'train', 46: 'church_bells', 47: 'airplane', 48: 'fireworks',\n49: 'hand_saw'}\n\n\n\nAlgorithm\n\nA paper I found http:\/\/karol.piczak.com\/papers\/Piczak2015-ESC-ConvNet.pdf, from there itself I follow the steps. So here the author did the same application of CNN is image classification, where a fixed dimension image is fed into a network along with different channels (RGB in the case of a color image) and after various steps of convolution, pooling and fully connected layers, network outputs class probabilities for the image. I want to do the same, but here instead of an image, I have sound clips.\nAlthough deep learning eliminates the need for hand-engineered features, I have to choose a representation model for the data. Instead of directly using the sound file as an amplitude vs time signal authors use a  log scaled mel-spectrograms and their corresponding deltas from a sound clip. Regarding fixed size input, then divide each sound clip into segments of 60x41 (60 bands and 41 frames). Log-scaled mel-spectrograms were extracted from all recordings (resampled to 22050 Hz and normalized) with window size of 1024, hop length of 512 and 60 mel-bands.\nThere is a fact that human ear hears sound on log-scale,and closely scaled frequency are not well distinguished by the human Cochlea. The effect becomes stronger as frequency increases. Hence only take into account power in different frequency bands. The mel-spec and their deltas will become two channels, which will be fed into CNN.\nHere I use \u201clibrosa\u201d is a python package for music and audio analysis. It provides the building blocks necessary to create music information retrieval systems. windows and extract_feature are the two methods we need to prepare the data (both features and labels) for CNN.\nIterate over file the folder but as you mentioned in the description that each sound is 5 second long, I need to replicate it to make 10 second long i.e. double the duration of each sound. That will be taken care by extracte_feature methods and then calculate above-mentioned features along with class labels and append them to arrays.\nNow the audio file is represented as a 60(bands) x 41(frames) x 2(channel) spectrogram image.\n\nBlock diagram\n\nLayers Explain\n\nConvolutional input layer, 32 feature maps with a size of 3\u00d73 and a rectifier activation function.\nDropout layer at 20%.\n\n\n\nConvolutional layer, 32 feature maps with a size of 3\u00d73 and a rectifier activation function.\n\n\nMax Pool layer with size 2\u00d72.\n\n\nConvolutional layer, 64 feature maps with a size of 3\u00d73 and a rectifier activation function.\n\n\nDropout layer at 20%.\n\n\nConvolutional layer, 64 feature maps with a size of 3\u00d73 and a rectifier activation function.\n\n\nMax Pool layer with size 2\u00d72.\n\n\nConvolutional layer, 128 feature maps with a size of 3\u00d73 and a rectifier activation function.\n\n\nDropout layer at 20%.\n\n\nConvolutional layer,128 feature maps with a size of 3\u00d73 and a rectifier activation function.\n\n\nMax Pool layer with size 2\u00d72.\n\n\nFlatten layer.\n\n\nDropout layer at 20%.\n\n\nFully connected layer with 1024 units and a rectifier activation function.\n\n\nDropout layer at 20%.\n\n\nFully connected layer with 512 units and a rectifier activation function.\n\n\nDropout layer at 20%.\n\n\nFully connected output layer with 50 units and a softmax activation function.\n\n\nFit and evaluate this model using A logarithmic loss function is used with the stochastic gradient descent optimization algorithm configured with a large momentum and weight decay start with a learning rate of 0.01.\nEpochs 300 batch size of 50.\n\n\nAfter training if we plot the loss and accuracy curve, we can see that there is a considerable difference between the training and validation loss. This indicates that the network has tried to memorize the training data and thus, is able to get better accuracy on it. This is a sign of Overfitting. But we have already used Dropout in the network, then why is it still overfitting.\n\n\n\nImageDataGenerator\n\nOne of the major reasons for overfitting is that we don't have enough data to train your network. Apart from regularization, another very effective way to counter Overfitting is Data Augmentation. It is the process of artificially creating more images from the images you already have by changing the size, orientation etc of the image. It can be a tedious task but fortunately, this can be done in Keras using the ImageDataGenerator instance.\n\n\n\nThat can be done using the ImageDataGenerator for data augmentation. This includes rotation of the image, shifting the image left\/right\/top\/bottom by some amount, flip the image horizontally or vertically, shear or zoom the image etc.\n\nCreate the model and configure it.\nCreate an ImageDataGenerator object and configure it using parameters for horizontal flip, and image translation.\nThe datagen.flow() function generates batches of data, after performing the data transformations \/ augmentation\nspecified during the instantiation of the data generator.\nThe fit_generator function will train the model using the data obtained in batches from the datagen.flow function.\n\n\n\n","112":"microSoundRecorder\nEnvironmental Sound Recorder for Teensy 3.6. It builds on the BasicAudioLogger, but will be developed into a tool suited for environmental sound monitoring and bio-acoustic research.\nMore information can be found in the build-in Wiki\nThe microSoundRecorder_dev branch contains code the is work in progress (marked below with (dev))\nsupports\nbuild-in Interfaces\n\nADC, ADC_Stereo\nI2S, I2S_32, I2S_QUAD, I2S_32_MONO\nI2S_TYMPAN (dev)\nI2S_TDM (dev)\n\nThe I2S_32 mode allows acquisition of two 24 bit MEMS microphones\nThe I2S_32_MONO mode allows acquisition of one 24 bit MEMS microphone, reducing also used disk space\nThe I2S_TYMPAN mode allows the high quality TYMPAN audio board https:\/\/tympan.org\/ to be used as audio recorder\nThe I2S_TDM mode allows multiple digital(e.g. ICS-52000 ) microphones be used in TDM mode\nimplements\n\nvariable sampling frequency\nscheduled acquisition\naudio-triggered archiving\nsingle file \/ event archiving\nvariable pre-trigger\nstartup menu on demand\nlogging of environmental data (temperature, pressure, humidity, lux)\n\nrequires following non-standard library (in private Arduino\/libraries folder)\n\nSdFat-beta   (Bill Greiman's uSD filing system: https:\/\/github.com\/greiman\/SdFat-beta)\nThe file SdFat.h in src directory must me renamed to SdFat_beta.h\nThe File SdFatConfig.h must be edited to reflect user needs\n\noptional non-standard libraries(in private Arduino\/libraries folder) for environmental logging\n\nBME280 (temperature,pressure, humidity sensor: https:\/\/github.com\/bolderflight\/BME280)\nBH1750 (light sensor: https:\/\/github.com\/claws\/BH1750)\n\ncaveat\nthis code is assumed to be developed further, please check regularily applied changes\nExamples\nthis directory contains examples recorded during testing and in the field\nDataSheets\nthis directory contains useful data sheets\nplanned\n\ndata offload option\n\n","113":"EnvironmentalSetting_Toolkit\nTools supporting the NPS IMD Environmental Setting protocol (https:\/\/irma.nps.gov\/DataStore\/Reference\/Profile\/2244060)\nThe Environmental setting Toolkit is the next iteration of and was forked from the IM_Climate toolkit created in 2016-2017. That toolkit can be found here: (https:\/\/github.com\/IMDProjects\/IM_Climate)\nDevelopment Timeline\nVersion 2.0 - March 2018\n\tBug fixes\n\tParameter date range availability\n\tPeriod of record summary \n\tStation data (day count parameters) - standard and custom AOAs\n\tStation data (departures from normals) - standard and custom AOAs\n\nVersion 2.1 - April 2018\n\tAOA polygon-based metrics (departures from normals gridded metrics using 800m PRISM data)\n\tEnhancements\/bug fixes for station-based metrics\n\nVersion 2.1.1 - June 2018\n  Performance enhancements for gridded metric generation\n\nVersion 2.1.2 - September 2018\n  Bug fixes\n\nVersion 2.1.3 - May 2019\n  Enhancements for FY2019 station metric generation\n\nVersion 2.1.4 - August 2020\n  Switch to DBI\n\nVersion 2.1.5 - August 2020\n  Bug fix\n\nVersion 2.1.6 - Late 2020\n  Enhancements for FY2019 gridded metric generation\n\nVersion 2.2 - Unknown\n  Mirror capabilities for Python version of Toolkit\n\tIndex-based metrics\n\tUpload polygon\n\nVersion 2.3 - Mid 2021\n\tGeneric capabilities: add DayMet\/NASA NEX as sources\n\nRelease 2.1.4 - 20200817\nRelease Notes\nSwitched database access to DBI.\nRelease 2.1.3 - 20190530\nRelease Notes\nEnhancements to run count and departure metrics.  Addition of daily flag data requests. Updates to station response. Implemented testing framework.\nRelease 2.1.2 - 20180924\nRelease Notes\nRelease 2.1 - 20180531\nRelease notes\nRelease 2.0 - 20180322\nRelease notes\nDisclaimer\nThis software is in the public domain because it contains materials from the U.S. National Park Service, an agency of the United States Department of Interior.\nAlthough this software package has been used by the U.S. National Park Service (NPS), no warranty, expressed or implied, is made by the NPS or the U.S. Government as to the accuracy and functioning of the package and related program material nor shall the fact of distribution constitute any such warranty, and no responsibility is assumed by the NPS in connection therewith.\nThis software is provided \"AS IS.\"\n","114":"Statistics notes for environmental modelling\nContents\n\n\nDistributions\nA quick overview of multivariate distributions, with the aim of developing some intuition about the Sum and Product rules as well as how they relate to Bayes' Theorem.\n\n\nModel calibration and likelihood functions\nA discussion of the issues relating to calibrating complex environmental models, which leads us to the concept of the all-important likelihood function.\n\n\nBayesian model calibration and Monte Carlo methods\nA first look at Bayes' Theorem applied to model calibration and an introduction to Monte Carlo (MC) methods.\n\n\nMarkov chain Monte Carlo methods\nAn introduction to basic Markov chain Monte Carlo (MCMC) methods, starting with the classic Metropolis algorithm.\n\n\nA hydrological model\nIn this notebook, we'll build a simple hydrological model from scratch to illustrate the modelling process. \n\n\nBeyond Metropolis\nHow to use real catchment data and a state-of-the-art MCMC algorithm to calibrate the hydrological model from notebook 5. \n\n\nGLUE\nSome comments on Generalised Likelihood Uncertainty Estimation (GLUE). Work in progress \n\n\nGaussian approximations and model comparison\nGaussian approximations of the posterior and an introduction to Bayesian model comparison. Work in progress. \n\n\nSummary\nPractical options for parameter inference and model comparison. Work in progress \n\n\nIntroduction\nThis page links to a series of IPython notebooks introducing statistical concepts for environmental modelling, especially Bayesian Markov chain Monte Carlo (MCMC) methods for model calibration and uncertainty estimation.\nMost of the examples are taken from hydrology or water quality modelling as that is my area of research, but the techniques presented are very general and applicable in a range of different fields.\nAs environmental models become more and more complex, the problems associated with calibration and evaluation become greater. Powerful statistical techniques are available to help, but for many environmental scientists they present a formidably steep learning curve.\nWho are these notes aimed at?\nMy aim is to try to make Bayesian MCMC methods accessible to those with little or no statistical training. If you know what a distribution is and are comfortable with the concept of integration as the area under a curve, you should be able to follow everything here.\nIn most cases I've abandoned mathematical rigour in favour of trying to give some kind of intuition for what's going on. Much of what I've done will probably be horrifying if you're a statistician or a physicist, but if you're just getting to grips with modelling for the first time perhaps this could be a stepping-stone towards better things (see below for some suggestions).\nDisclaimer\nMy background is in geology, not statistics or hydrological modelling. I still have a great deal to learn and I'm sure these pages will contain mistakes and misconceptions. If you spot anything completely wrong (as opposed to just very simplified), I'm always happy to be corrected - you can either send a pull request, or contact james.e.sample@gmail.com.\nThis isn't a course in statistics - it's just a set of personal notes that I'm making available online in the hope that other beginners might find them useful.\nOther resources\nIf you're mathematically inclined, you're unlikely to find anything better than David MacKay's excellent book, Information Theory, Inference and Learning Algorithms, together with the accompanying series of video lectures. If you can follow these without too much difficulty then forget my notes and concentrate your efforts here instead!\nI also thoroughly recommend Jake Vanderplas' series of blog posts as well as his article on arXiv.\nCam Davidson-Pilon's Probabilistic Programming and Bayesian Methods for Hackers is another excellent reference.\nFinally, if you're interested in these topics for work\/research purposes (e.g. if you've just started a PhD in environmental modelling), I'd suggest taking a look at the EAWAG Summer School in Environmental Systems, which I wish I'd attended a couple of years ago.\nMaking the most of the IPython notebooks\nThe links at the top of this page will take you to static versions of my notebooks rendered with nbviewer. However, to get the most of out of them, I recommend downloading each notebook to your computer and running it interactively. The following steps should get you started on Windows:\n\n\nYou'll need an up-to-date IPython installation. If you don't have one already try WinPython, which is a comprehensive and portable Python distribution that won't interfere with anything else on your system.\n\n\nOnce WinPython is installed, go to one of the notebooks above and download the .ipynb file to your computer (the \"download\" icon is at the top-right of the screen).\n\n\nOpen the folder containing your WinPython installation and run the WinPython Command Prompt (not the normal Windows Command Prompt).\n\n\nChange directories to wherever you saved the .ipynb file and then type ipython notebook at the command prompt. Your browser should open to display the IPython dashboard and you'll see a link to the notebook you just downloaded.\n\n\nClick to open the notebook then choose Cell > Run All from the menu bar. Python will import all the necessary modules and run the notebook cells, which might take a few moments.\n\n\nYou can now work through the notebook interactively, modifying the code etc. as you go.\n","115":"CEE600M0002_Fall2020\ncode sprints and research collaboration for Environmental Data Science\n","116":"EI_Capstone_S20\nEnvironmental Informatics Capstone Project Repo\n","117":"EFDC-MPI\nThis repo includes an extended version of the widely used Environmental Fluid Dynamics Code (EFDC) (https:\/\/www.epa.gov\/exposure-assessment-models\/efdc), a state of the art hydro-environmental modelling suite to simulate aquatic systems in one, two, and three dimensions. It serves as the hydrodynamic core of IBM Research asset DeepCurrent, focusing on the prediction of environmental conditions in coastal oceans, rivers and lakes.\nExtensions include capabilities to run in parallel using MPI, netCDF file I\/O and incorporation of modules to simulate impeded flows.\nDetails on the parallel development of the code are provided here\nComputers & Geoscience [pdf]\nand applications here:\n\nGalway Bay [pdf]\nImpeded aquaculture flows [pdf]\nand\ninvestigating marine renewable energy in cobscook Bay [pdf]\n\nQuickstart Guide\nTo build the EFDC model, clone this repository and take a peek at QUICKSTART (installs netCDF and MPI dependencies). You can directly execute it, given you are running a recent Ubuntu\/Debian (and have sudo installed).\n$ git clone https:\/\/github.com\/fearghalodonncha\/EFDC-MPI.git\n$ cd Src\/\n$ sudo .\/Quickstart\n$ make\n\nIf netCDF or MPI libraries are installed in non-standard location, edit makefile to point to the installation path (NCDIR & MPICHDIR respectively).\nIf you are using a different distribution use your package manager to install all dependencies available. A list of dependencies can be viewed in the Dependencies section of this README.\nThe repo contains two sample model applications in the SampleModels\/ directory:\n\na simple harbour channel model\na real-world model of Cobscook Bay, ME, USA\na real-world model of Chesapeake Bay and\na simple harbour channel model with data assimilation\n\nTo run either of these examples, copy the EFDC executable from the Src\/ directory to the directory containing the *.INP files and run the code using .\/EFDC (for serial examples)\nDependencies\nThe dependencies for the EFDC model are NetCDF fortran (details on the installation are provided here https:\/\/www.unidata.ucar.edu\/software\/netcdf\/docs\/building_netcdf_fortran.html along with the associated dependencies) and mpi (e.g. openmpi (https:\/\/www.open-mpi.org\/) or mpich (https:\/\/www.mpich.org\/)). The Quickstart file included in the repo installs these on Ubuntu systems.\nIf one wishes to use the data assimilation libraries included in this repo then blas linear algebra libraries must be installed (e.g. http:\/\/www.openblas.net\/) and edit makefile to point to installation path.\nOnce installed, the makefile included in the Src directory must be edited to point to the path of the MPI and netCDF libraries (MPICHDIR and NCDIR and BLAS_PATH respectively).\nRunning examples\nSample input files are included in the SampleModels\/ directory. EFDC input files are of form *.INP\nTo run these examples in serial, copy the EFDC executable to the directory containing the *.INP files and run the code using .\/EFDC\nTo run in parallel (using MPI), execute of form (across 4 compute cores):\n$ mpirun -np 4 .\/EFDC\nConfigurations for parallel simulations are defined in LORP.INP which describes the size of each sub-domain for distributed computing. This file is not specified by the user but rather a load balancing algorithm. The number of sub-domains specified in LORP.INP must equal the number passed to mpirun\nA key consideration in parallel simulation of coastal ocean applications is distributing load across processors in a well balanced manner. This consists of ensuring that each sub-domain contains a relatively equal distribution of land\/ocean cells (since land cells do not invoke any computational cost).\nThe repo contains a C++ load balancing algorithm that computes a rectilinear decomposition of a global domain into a number of subdomains in a locally optimal manner\nTo build the load balancing module, cd into the Gorp directory and compile using a C++ compiler:\n$ g++ Gorp.cpp GorpMain.cpp -o Gorp\nCopy the Gorp executable into the same directory containing the input files and execute of form\n$ .\/Gorp CELL.INP sc #\n(Note: the CELL.INP header line must accurately specify the I and J extents of the domain as it is read by the load-balancing module).\nWhere # denotes  the number of subdomains to decompose the problem into (i.e. how many compute cores to distribute the problem over) while 'sc' is appended to the generated LORP file as an identifier. The generated files are of form LORP_sc_#_v.INP, LORP_sc_#_h.INP and LORP_sc_#_r.INP where h, v, and r denote decomposing the domain into balanced horizontal or vertical strips or into cartesian rectilinear domains respectively\nDetails on the parallel implementation and load balancing module are provided in:\nO'Donncha, F, Ragnoli, E. and Suits, F. \"Parallelisation study of a three-dimensional environmental flow model.\" Computers & Geosciences 64 (2014): 96-103.\nDetails on the model\nEFDC is a state-of-the-art hydrodynamic model that can be used to simulate aquatic systems in one, two, and three dimensions. It has evolved over the past decades to become one of the most widely used and technically defensible hydrodynamic models in the world. EFDC uses stretched or sigma vertical coordinates and Cartesian or curvilinear, orthogonal horizontal coordinates to represent the physical characteristics of a waterbody. It solves three-dimensional, vertically hydrostatic, free surface, turbulent averaged equations of motion for a variable-density fluid. Dynamically-coupled transport equations for turbulent kinetic energy, turbulent length scale, salinity and temperature are also solved. The EFDC model allows for drying and wetting in shallow areas by a mass conservation scheme.\nExtensions to this version of the code include MPI parallelism described in:\nO'Donncha, F, Ragnoli, E. and Suits, F. \"Parallelisation study of a three-dimensional environmental flow model.\" Computers & Geosciences 64 (2014): 96-103.\nInclusion of modules to represent aquaculture structures described in:\nO'Donncha, F., Hartnett, M., & Plew, D. R. (2015). Parameterizing suspended canopy effects in a three-dimensional hydrodynamic model. Journal of Hydraulic Research, 53(6), 714-727.\nAnd inclusion of modules to represent marine hydrokinetic structures described in:\nO'Donncha, F., James, S. C., & Ragnoli, E. (2017). Modelling study of the effects of suspended aquaculture installations on tidal stream generation in Cobscook Bay. Renewable Energy, 102, 65-76.\nVagrant example\nTo assist users in getting started with the model the repo includes a Vagrantfile that instantiates a Ubuntu machine and installs all required dependencies. To use the Vagrantfile, users must have Virtualbox and Vagrant installed\nInstall Virtualbox:\nhttps:\/\/www.virtualbox.org\/wiki\/Downloads\nInstalling Vagrant:\nDownload from: https:\/\/www.vagrantup.com\/downloads.html\nAfter successfully installing vagrant\nRun: vagrant plugin install vagrant-vbguest\nFor Windows - Run: vagrant plugin install vagrant-share --plugin-version 1.1.8\nTo bring up a Vagrant virtual machine, type:\n$ vagrant up\n$ vagrant ssh\n\nWithin the vagrant VM, users can easily build the model by simply invoking:\n$make\n\nDocumentation\nThe repo contains a set of manuals describing the different components of the EFDC model. The fundamental hydrodynamic model input files and setup are described in the EFDC User manual from the EPA. Also included is a half day tutorial related to the EFDC MPI model and developing parallel model simulation presented at the IEEE Oceans 2017 conference in Anchorage. Further tutorial material related to the development of marine hydrokinetic applications is available from Zenodo.\n","118":"Metalsmith Enviromental Variables Plugin \n\n\n\nMetalsmith plugin to register all environmental variables as metadata.\nInstallation\nnpm install --save metalsmith-env\n\nCLI\nIf you are using the command-line version of Metalsmith, you can install via npm, and then add the metalsmith-env key to your metalsmith.json file:\n{\n  \"plugins\": {\n    \"metalsmith-env\": {}\n  }\n}\nJavaScript\nIf you are using the JS Api for Metalsmith, then you can require the module and add it to your .use() directives:\nvar env = require('metalsmith-env');\n\nmetalsmith.use(env());\nUsage\nOnce installed, all environment variables, from process.env, become available as Metalsmith metadata.\nOptions\nopts.variables\nAn array of default variables that will be available. Environmental variables will then override the default set.\nopts.overrides\nAn array of variables that will completely override the given set of environmental variables.\nopts.env\nThe assumed environmental variables, defaults to process.env.\nExample\nThe following example uses Jade and Metalsmith JSTransformer:\nindex.jade\n---\ntitle: Environmental Variables\n---\ndoctype html\nhtml(lang=\"en\")\n  head\n    title= title\n  body\n    h1= title\n    p This is the environmental variable \"NODE_ENV\":\n    code\n      pre= NODE_ENV\nBuild\n$ NODE_ENV=production node_modules\/.bin\/metalsmith\n\nResult\n<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n    <title>Environmental Variables<\/title>\n  <\/head>\n  <body>\n    <h1>Environmental Variables<\/h1>\n    <p>This is the environmental variable \"NODE_ENV\":<\/p>\n    <code><pre>production<\/pre><\/code>\n  <\/body>\n<\/html>\nLicense\nMIT\n","119":"banzai!\n\ud83c\udfc4\nbanzai is a shell script (bash) that links together the disparate programs needed to process the raw results from an Illumina sequencing run of PCR amplicons into a contingency table of the number of similar sequences found in each of a set of samples.\nContents\n\nIntroduction\nFlow Chart\nUsage\nDependencies\nSequencing Metadata\nBugs and Issues\nNotes\n\nIntroduction\nThe script should run on Unix (Mac OSX) and Linux machines. It makes heavy usage of Unix command line utilities (such as find, grep, sed, awk, and more) and is written for the BSD versions of those programs as found on standard installations of Mac OSX. I tried to use POSIX-compliant commands wherever possible.\nLab Preparation: Samples to sequences\nBanzai was designed for sequencing data that were generated for a target region like so:\nGenomic DNA:    ----------------------------------------------------------------\ntarget region:                   ~~~~~~~~~~~~~~~~~~~~~~~~\n\nPCR:\nPrimers:                   ******                        ******\nSecondary index:        +++                                    +++\nfull primer:            +++******                        ******+++\namplicon:               +++******~~~~~~~~~~~~~~~~~~~~~~~~******+++\n\nThe amplicon contains everything that will show up in the sequence. This is more generally referred to as the 'insert'. Note that the insert size is greater than the size of the region of interest alone.\nLibrary Prep:\nprimary index:       :::                                          :::\nadapter:           aa                                                aa\nfinal fragment:    aa:::+++******~~~~~~~~~~~~~~~~~~~~~~~~******+++:::aa\n\nThis is the fragment that actually goes into the sequencer. Note that it is bigger than the insert (above), and that the adapter and primary indexes shouldn't end up in your sequences.\nSequencing:\nRead 1:            aa:::+++******~~~~~~~~~~~~~~\nRead 2:                                    ~~~~~~~~~~~~~~******+++:::aa\n\nBanzai: Sequences to Samples\nBanzai works backward through the same process:\nDemultiplexing (primary):\nRead 1:                 +++******~~~~~~~~~~~~~~\nRead 2:                                    ~~~~~~~~~~~~~~******+++\n\n(This has probably already been performed by the time you get the data.)\nRead merging:\nmerged reads:           +++******~~~~~~~~~~~~~~~~~~~~~~~~******+++\n\nDemultiplexing (secondary):\n                           ******~~~~~~~~~~~~~~~~~~~~~~~~******\n\nPrimer removal:\n                                 ~~~~~~~~~~~~~~~~~~~~~~~~\n\n(Layout inspired in part by the FROGS documentation.)\nFlow Chart\n\nUsage\nCopy the file 'banzai_params.sh' into a new folder and set parameters as desired. Then run the banzai script, using your newly edited parameter file like so (Mac OSX):\nbash \/Users\/user_name\/path\/to\/the\/file\/banzai.sh   \/User\/user_name\/path\/to\/param_file.sh\nIt's probably important to use bash rather than sh or . to invoke the script. Someday I'll figure out a better workaround, but for now this was the only way I could guarantee the log file was created in the way I wanted.\nDependencies\nAside from the standard command line utilities (awk, sed, grep, etc) that are already included on Unix machines, this script relies on the following tools:\n\nPEAR: merging paired-end reads\ncutadapt: primer removal (I might replace with awk)\nvsearch: sequence quality filtering (requires version 1.4.0 or greater); OTU clustering\nswarm: OTU clustering\nseqtk: reverse complementing entire fastq\/a files\npython: fast consolidation of duplicate sequences (installed by default on Macs)\nblast+: taxonomic assignment\nR: ecological analyses. Requires these packages:\n\ndata.table: data manipulation. Default installation on Mac probably won't enable parallel capabilities; to do so, check these instructions.\ngtools: data manipulation\nreshape2: data manipulation\nvegan: ecological analyses\ntaxize: taxonomic annotation\n\n\n\nFollow the Vagrant-VirtualBox instructions to automatically install your own virtual machine that includes all of these dependencies.\nRecommended\n\n\nCompressing and decompressing files can be slow because standard, built-in utilities (gzip) do not run in parallel. Installing the parallel compression tool pigz can yield substantial speedups. Banzai will check for pigz and use it if available.\n\n\nI recommend that before analyzing data, you check and report basic properties of the sequencing runs using fastqc. I have included a script to do this for all the fastq or fastq.gz files in any subdirectory of a directory (run_fastqc.sh).\n\n\nSequencing Metadata\nThis is a critical component.\nYou must provide a CSV spreadsheet that contains metadata about the samples. Banzai will read some of the parameters from it, like the primers and multiplex index sequences. You need to provide the file path to the spreadsheet, and the relevant column names. Some of the details seem tedious (like listing each file name), but they are inspired by the EMBL\/EBIMetagenomics metadata requirements. That is, you're going to have to do this stuff at some point anyway.\nThis file should be encoded with UNIX newline characters (LF). Banzai will attempt to check for and fix files encoded with Windows newline characters (CRLF), but this is a place to look if you get mysterious errors. Early in the logfile you can check to be sure the correct number of tags and primer sequences were found.\nNo field should contain any spaces. That means row names, column names, and cells. Accommodating this would require an advanced degree in bash-quoting judo, which I do not have.\nBugs and Issues\n\nCurrently awaiting catastrophic finding...\n\n\nbe aware of potential problems between awk versions on Linux and Mac. On a Mac, the output of awk --version is awk version 20070501\n\nNotes\nAn alternate hack to have the pipeline print to terminal AND file, in case logging breaks:\nsh script.sh  2>&1 | tee ~\/Desktop\/logfile.txt\n\n2016-10-22 Began major reorganization. Created v0.1.0-beta for MBON in case anything causes a fire.\n2015-10-19 expected error filtering implemented via vsearch. OTU clustering can be done with swarm or usearch.\n2015-10-09 read length calculated from raw data. Library names are flexible.\n2014-11-12 Noticed that the reverse tag removal step removed the tag label from the sequenceID line of fasta files if the tag sequence is RC-palindromic!\nLibrary Names:\nAs of 2015-10-09, libraries no longer have to be named anything in particular (e.g. A, B, lib1, lib2),\nBUT THEY CANNOT CONTAIN UNDERSCORES or spaces! (This will be moot once library index sequences are required)\nRaw Data:\nYour data (fastq files) can be compressed or not; but banzai currently only works with paired-end Illumina data.\nThus, the bare minimum input is two fastq files corresponding to the first and second read. Banzai will fail if there are files in your library folders that are not your raw data but have 'fastq' in the filename!\nFor example, if your library contains four files: \"R1.fastq\", \"R1.fastq.gz\", \"R2.fastq\", and \"R2.fastq.gz\". banzai will grab the first two (R1.fastq and R1.fastq.gz) and try to merge them, and (correctly) fail miserably. Note that while PEAR 0.9.7 merges compressed (*.gz) files directly, PEAR 0.9.6 does not do so correctly. If given compressed files as input, banzai first decompresses them, which will add a little bit of time to the overall analysis.\n\n","120":"env-and-files\n\nLoad configuration from environmental variables and files.\n\nAccording to The Twelve-Factor App, configuration should come from environmental variables. But since environmental variables can leak easily, some people use secrets for sensitive information. This module is made to support either with minimal set-up.\nInstall\nnpm install env-and-files\n\nOr, with yarn:\n$ yarn add env-and-files\n\nUsage\nconst {loadConfig} = require('env-and-files');\n\nloadConfig({\n  \/\/ A conceptual grouping of configuration properties.  In this case, configuration for the logger.\n  logger: {\n    \/\/ The \"logger.level\" property will be equal to the \"LOG_LEVEL\" environmental variable, or undefined if it is not present.\n    level: 'LOG_LEVEL',\n  },\n  server: {\n    port: {\n      \/\/ Specify that this property is required.  If \"PORT\" is not found, an error will be given.\n      required: true,\n      \/\/ Coerce the value to a number.  If it can't be coerced, an error will be given.\n      type: 'number',\n      variableName: 'PORT',\n    },\n  },\n  sql: {\n    password: {\n      \/\/ The \"sql.password\" property will be equal to the contents of \"\/path\/to\/secret\", or undefined if it could not be read.\n      filePath: '\/path\/to\/secret',\n      required: true,\n    },\n  },\n})\n  .then(config => {\n    \/\/ \"config\" will be an object map of configuration groups.  So, you'd get something like\n    \/\/ { logger: { level: undefined }, server: { port: 8000 }, sql: { password: 'abc123' } }\n    console.log(config);\n  })\n  .catch(error => {\n    \/\/ If any of the required properties cannot be loaded, the Promise will reject.\n    console.error(error);\n  });\nAPI\nloadConfig(configMap)\nLoad configuration. Returns a Promise that will resolve to the loaded configuration, or reject if the configuration was invalid.\nconfigMap\nType: Object\nAn object map of conceptual groupings of necessary configuration and where to find it. By default, all configuration properties are optional, but if one is marked required and is not found, an error will be given. See usage for examples of config maps.\nloadConfigSync(configMap)\nLoad configuration, synchronously. Returns the loaded configuration, or throws if the configuration was invalid.\nconfigMap\nType: Object\nSame as the asynchronous version.\nLicense\nMIT \u00a9 Matthew Fernando Garcia\n","121":"BinSanity v.0.3\n\nPlease see the Wiki for usage and installation requirements:\nhttps:\/\/github.com\/edgraham\/BinSanity\/wiki\nIf an issue arises in the process of utilizing BinSanity please create an issue and we will address is as soon as possible. To expedite a response please provide any associated error messages.\nAs this project is actively being improved any comments or suggestions are welcome.\n\nBinsanity Forum\n\nCitation\nGraham ED, Heidelberg JF, Tully BJ. (2017) BinSanity: unsupervised clustering of environmental microbial assemblies using coverage and affinity propagation. PeerJ 5:e3035 https:\/\/doi.org\/10.7717\/peerj.3035\n","122":"How to run and publish: sensor21\nPrerequisites\nYou will need:\n\nA 21 Bitcoin Computer, or a DIY Bitcoin Computer\nAn Adafruit MPL3115A2 Breakout Board\nA set of female to female jumper wires\n\nFor a full walkthrough, see the sensor21 tutorial here.\nHardware Setup\nConnect your 21BC \/ DIY 21BC to the MPL3115A2 breakout board. See the connection diagrams on the tutorial page for more information.\n\nDIY Connection Diagram\n21 Bitcoin Comptuter Connection Diagram\n\nSoftware Setup\nStep 1: Install\/update 21\nGet the latest version of the 21 software. If you don't have 21 installed yet, run curl https:\/\/21.co | sh. Then, join the 21 marketplace network.\n# Install 21 if required\ncurl https:\/\/21.co | sh\n\n# Run 21 update\n21 update\n\n# Join the `21market` network\n21 join\nStep 2: Clone the repository\nClone the sensor21 repository, and run the setup script. You will be asked for user input multiple times.\ncd ~\/\n\n# Install git to clone the Sensor21 code\nsudo apt-get install git\n\n# git clone the code\ngit clone https:\/\/github.com\/21dotco\/sensor21.git\n\n# run the setup script\ncd sensor21\nsource setup.sh\nStep 3: Start your server and publish your endpoint\nStart the server with the following:\npython3 sensor21-server.py -d\nAfter the server is running, pubish your endpoint with the 21 publish command. Replace the name and email fields with your information.\n21 publish submit manifest.yaml -p 'name=\"Joe Smith\" email=\"joe@example.com\" price=\"5\" host=\"AUTO\" port=\"6002\"'\nStep 4: Verify you are part of the aggregator pool\nAfter a few minutes, you should be able to use 21 publish list\nto see the endpoint you just put up:\n21 publish list\nYou can also use the verify endpoint on the sensor21 aggregator. Load your zerotier ip address, and then query the enpoint to verify you are part of the pool.\n# grab your ZeroTier IP address and save it to shell variable ZT_IP\nZT_IP=$(ifconfig | grep -A2 zt | grep inet | sed 's|[^0-9. ]||g' | sed 's|[^ \\t]*||' | awk 'NR==1{print $1}')\n\n# verify your endpoint is part of the pool\ncurl https:\/\/mkt.21.co\/21dotco\/sensor21_aggregator\/sensor21\/verify?zt_ip=$ZT_IP\nStep 5: View transactions with 21 log\nAfter your server has been online for ~30 minutes, you can start to see transaction logs from the aggregator in your 21 log. You can see your incomes from sensor21 by running 21 log.\n21 log\nTrobuleshooting\nSee the detail on troubleshooting your application here.\nIf you have further support requests, please join our public slack channel #iot here.\n","123":"ZenPacks.community.CiscoEnvMon\n\nAbout\nThis Monitoring ZenPack provides Cisco Environmental monitoring including fans,\ntemperature sensors, power supplies and expansion modules.\n\nRequirements\n\nZenoss\nYou must first have, or install, Zenoss 2.5.2 or later. This ZenPack was tested\nagainst Zenoss 2.5.2, Zenoss 3.2 and Zenoss 4.2. You can download the free Core\nversion of Zenoss from http:\/\/community.zenoss.org\/community\/download.\n\nInstallation\n\nNormal Installation (packaged egg)\nDownload the CiscoEnvMon ZenPack.\nCopy this file to your Zenoss server and run the following commands as the zenoss\nuser.\n\nzenpack --install ZenPacks.community.CiscoEnvMon-1.2.0.egg\nzenoss restart\n\n\n\nDeveloper Installation (link mode)\nIf you wish to further develop and possibly contribute back to the CiscoEnvMon\nZenPack you should clone the git repository,\nthen install the ZenPack in developer mode using the following commands.\n\ngit clone git:\/\/github.com\/epuzanov\/ZenPacks.community.CiscoEnvMon.git\nzenpack --link --install ZenPacks.community.CiscoEnvMon\nzenoss restart\n\n\n\nUsage\nInstalling the ZenPack will add the following items to your Zenoss system.\n\nModeler Plugins\n\ncommunity.snmp.CiscoExpansionCardMap - this modeler plugin, tried to\nidentify Model, Vendor and Serial Number of installed expansion modules.\ncommunity.snmp.CiscoFanMap - Fan modeler plugin.\ncommunity.snmp.CiscoPowerSupplyMap - Power Supply modeler plugin.\ncommunity.snmp.CiscoTemperatureSensorMap - Temperature Sensor modeler\nplugin.\n\n\nMonitoring Templates\n\nDevices\/Network\/Router\/Cisco\/CiscoFan\nDevices\/Network\/Router\/Cisco\/CiscoPowerSupply\nDevices\/Network\/Router\/Cisco\/CiscoTemperatureSensor\n\n\nReports\n\nReports\/Device Reports\/Cisco Reports\/Cisco Devices\nReports\/Device Reports\/Cisco Reports\/Modules\n\n","124":"Monitoring environmental conditions near underwater datacenters using Deep Learning\nLast updated August 29, 2018\nIntroduction\nAt Microsoft, we put our cloud and artificial intelligence (AI) tools in the hands of those working to solve global environmental challenges, through programs such as AI for Earth. We also use these same tools to understand our own interaction with the environment, such as the work being done in concert with Project Natick.\nProject Natick seeks to understand the benefits and difficulties in deploying subsea datacenters worldwide; it is the world's first deployed underwater datacenter and it was designed with an emphasis on sustainability. Phase 2 extends the research accomplished in Phase 1 by deploying a full-scale datacenter module in the North Sea, powered by renewable energy. Project Natick uses AI to monitor the servers and other equipment for signs of failure and to identify any correlations between the environment and server longevity.\nBecause Project Natick operates like a standard land datacenter, the computers inside can be used for machine learning to provide AI to other applications, just as in any other Microsoft datacenter. We are also using AI to monitor the surrounding aquatic environment, as a first step to understanding what impact, if any, the datacenter may have.\nMonitoring marine life using object detection\nThe Project Natick datacenter is equipped with various sensors to monitor server conditions and the environment, including two underwater cameras, which are available as live video streams (check out the livestream on the Project Natick homepage). These cameras allow us to monitor the surrounding environment from two fixed locations outside the datacenter in real time.\nWe want to count the marine life seen by the cameras. Manually counting the marine life in each frame in the video stream requires significant amount of effort. To solve this, we can leverage object detection to automate the monitoring and counting of marine life.\nIn each frame, we count the number of marine creatures. We model this as an object detection problem. Object detection combines the task of classification with localization, and outputs both a category and a set of coordinates representing the bounding box for each object detected in the image.\nHow to Run\nPlease go through the following steps to be able to run natick_OD.py, which will perform Object Detection on a Project Natick livestream and push the data to a Power BI dashboard.\n\nClone this repository into a directory of your choice\nEnsure you have all dependencies installed (see below)\nCreate a Power BI Streaming Dataset (see below)\nAdd your Power BI Streaming Dataset URL to line 139 of natick_OD.py\nRun python natick_OD.py\n\nDependencies\n\npip install cython\npip install pillow\npip install lxml\npip install matplotlib\npip install imutils\npip install opencv-python\npip install --ignore-installed --upgrade tensorflow\n\nCreating a Power BI Streaming Dataset\nCreate a Power BI streaming dataset following this tutorial. When creating your dataset, add the following values.\n\nRunning the Code\nThen edit line 139 of natick_OD.py to use your Power BI Push URL. Finally, navigate to where you cloned the repo and run python natick_OD.py\nNote\nThis repo uses code from the TensorFlow Object Detection repository. We have edited the file utils\\visualization_utils.py so that it displays the fish count in the bottom left corner of the video.\nGetting data\nIf you want to train from scratch, the annotated data is located under the Release Tab\nAdditional Information\nContinue reading for additional information that is not necessary for running the code on your own machine.\nDeploying the model to the Project Natick datacenter\nAnother question we asked was - can we deploy the model to the Natick datacenter to monitor the wildlife teeming around the data center?\nWe chose to use CPUs to process the input videos and tested locally to make sure it works well. However, the default TensorFlow pre-built binary does not have optimizations such as AVX or FMA built-in to fully utilize modern CPUs. To better utilize the CPUs, we built the TensorFlow binary from source code, turning on all the optimization for Intel CPU by following Intel's documentation. With all the optimization, we can increase the processing speed by 50 percent from around two frame per second to three frame per second. The build command is like below:\nbazel build --config=mkl -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mavx512f --copt=-mavx512pf --copt=-mavx512cd --copt=-mavx512er --copt=\"-DEIGEN_USE_VML\"\n\n\/\/tensorflow\/tools\/pip_package:build_pip_package\n\nReal-time environmental monitoring with Power BI\nEnvironmental scientists and aquatic scientists may benefit from a more intuitive way of monitoring the statistics of the underwater datacenter, such that they can quickly gain insight as to what is going on, through powerful visualization via Power BI.\nPower BI has a notion of real-time datasets which provides the ability to accept streamed data and update dashboards in real time. It is intuitive to call the REST API to post data to the Power BI dashboard with a few lines of code:\n# REST API endpoint, given to you when you create an API streaming dataset\n# Will be of the format: https:\/\/api.powerbi.com\/beta\/<tenant id>\/datasets\/< dataset id>\/rows?key=<key id>\nREST_API_URL = ' *** Your Push API URL goes here *** '\n# ensure that timestamp string is formatted properly\nnow = datetime.strftime(datetime.now(), \"%Y-%m-%dT%H:%M:%S%Z\")\n# data that we're sending to Power BI REST API\ndata = '[{{ \"timestamp\": \"{0}\", \"fish_count\": \"{1}\", \"arrow_worm_count\": \"{2}\" }}]'.format(now, fish_count, arrow_worm_count)\nreq = urllib2.Request(REST_API_URL, data)\nresponse = urllib2.urlopen(req)\n\nBecause the animals may move quickly, we need to carefully balance between capturing data for many frames in short succession, sending to the Power BI dashboard, and consuming compute resources. We chose to push the analyzed data (for example, fish count) to Power BI three times per second to achieve this balance.\nSummary\nMonitoring the environmental impact is an important topic, and AI can help make this process more scalable, and automated. In this post, we explained how we developed a deep learning solution for environment monitoring near the underwater data center. In this solution, we show how to ingest and store the data, and train an underwater animal detector to detect the marine life seen by the cameras. The model is then deployed to the machines in the data center to monitor the marine life. At the same time, we also explored how to analyze the video streams and leverage Power BI's streaming APIs to monitor the marine life over time.\nIf you have questions or comments, please leave a message here.\nContributing\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https:\/\/cla.microsoft.com.\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\nThis project has adopted the Microsoft Open Source Code of Conduct.\nFor more information see the Code of Conduct FAQ or\ncontact opencode@microsoft.com with any additional questions or comments.\n","125":"Mixtures.Workshop\nColumbia University, Mailman School of Public Health. Environmental Mixtures Workshop 2018\/2019. Introduction to multiple techniques to analyze exposure to mixtures in environmental health.\nRepository guide\nWithin this repository you will find the code materials used during the Mixtures Workshop 2018\/2019. To help you navigate the repository, below is a description of the repository organization.\nThe repository is organized into two main folders \"Unsupervised\" and \"Supervised\" which contained the materials for the unsupervised and supervised methods correspondingly. The Unsupervised folder is subdivide into three folders: PCA, FA, and Clustering. And the Supervised folder is subdivide into: WQS, Variable Selection, and BKMR. All the materials for each respective method are within its folder. Note, the rmd file titled with the method's name contains the main code.\nIn addition to the Unsupervised and Supervised folders you will find the following folders:\n\nData: contains the data and the data dictionary.\nMitro_et_al_materials: contains the code and data used by Mitro et al.\nworkshop_paper_figures: contains the figures include in the Gibson et al. paper.\n\nWARNING: This repo was created under R version 3.5.3. Results will differ with newer R versions, as R version 3.6.0 changed the default method for generating from a discrete uniform distribution (used in sample()). Additionally, version 3.1-3 of the grpreg package should be used to recreate published results (here).\n","126":"Electric Imp Environmental Data Streaming\nThis is a hub for the Electric Imp Environmental Data Streaming and Electric Imp Nora Motion and Environmental Data Streaming tutorials.\nHere you will find code materials for the tutorials as well as the tutorials themselves in the wiki.\nThere are a lot of Internet-connected devices out there and the price is only going down. But usually the cheaper they are, the harder they are program and make secure. The Electric Imp is a platform paired with hardware that makes connecting to the Internet quickly, securely, and seamlessly a piece of cake. It does all the hard network work for you without you having to change a thing. That way, you can focus on what data you want it to collect and send.\nIt's super cool looking... read more\n","127":"Electric Imp Environmental Data Streaming\nThis is a hub for the Electric Imp Environmental Data Streaming and Electric Imp Nora Motion and Environmental Data Streaming tutorials.\nHere you will find code materials for the tutorials as well as the tutorials themselves in the wiki.\nThere are a lot of Internet-connected devices out there and the price is only going down. But usually the cheaper they are, the harder they are program and make secure. The Electric Imp is a platform paired with hardware that makes connecting to the Internet quickly, securely, and seamlessly a piece of cake. It does all the hard network work for you without you having to change a thing. That way, you can focus on what data you want it to collect and send.\nIt's super cool looking... read more\n","128":"EnvRtype: a tool for envirotyping analysis and genomic prediction considering reaction norms  \nATTENTION: package maintenance between 15th October to 31th October 2020.\n\n\nBackground\n\nEnvironmental typing (envirotyping) has proven useful in identifying the non-genetic drivers of phenotypic adaptation in plant breeding. Combined with phenotyping and genotyping data, the use of envirotyping data may leverage the molecular breeding strategies to cope with environmental changing scenarios. Over the last ten years, this data has been incorporated in genomic-enabled prediction models aiming to better model genotype x environment interaction (GE) as a function of reaction norm. However, there is difficult for most breeders to deal with the interplay between envirotyping, ecophysiology, and genetics.\nHere we present the EnvRtype R package as a new toolkit developed to facilitate the interplay between envirotyping and genomic prediction. This package offers three modules: (1) collection and processing data set, (2) environmental characterization, (3) build of ecophysiological enriched genomic prediction models accounting for three different structures of reaction norm. Here we focus our efforts to present a practical use of EnvRtype package in supporting the genome-wide prediction of reaction norms. We provide a intuitive framework to integrate different reaction norm models in Bayesian Genomic Genotype x Environment Interaction (BGGE) package.\n\n\n\nResources\n\nEnvRtype consists in three modules (sections 2-4), which collectively generate a simple workflow to collect, process and integrates envirotyping data into genomic prediction over multiple environments.\n\n\nMain Functions\n\n1. Install and Required Packages\n2. Environmental Sensing Module\n3. Environmental Characterization Module\n4. Reaction-Norm Module\n\nTutorials\n\nExample of Envirotyping pipeline\n\nInformation\n\nAuthorship\nAcknowledgments\nPublications\n\n\nInstall\nUsing devtools in R\nlibrary(devtools)\ninstall_github('allogamous\/EnvRtype') # current version: 0.1.5\nrequire(EnvRtype)\n\nManually installing\n\nIf the method above doesn't work, use the next lines by downloading the EnvRtype-master.zip file\n\nsetwd(\"~\/EnvRtype-master.zip\") # ~ is the path from where you saved the file.zip\nunzip(\"EnvRtype-master.zip\") \nfile.rename(\"EnvRtype-master\", \"EnvRtype\") \nshell(\"R CMD build EnvRtype\") # or system(\"R CMD build EnvRtype\")\ninstall.packages(\"EnvRtype_0.1.9.tar.gz\", repos = NULL, type=\"source\") # Make sure to use the current verision\n\nRequired packages\n\n\nEnvRtype\nraster\nnasapower\nBGGE\nforeach\ndoParalell\n\n\ninstall.packages(\"foreach\")\ninstall.packages(\"doParallel\")\ninstall.packages(\"raster\")\ninstall.packages(\"nasapower\")\ninstall.packages(\"rgdal\")\ninstall.packages(\"BGGE\")\n              \nor\n              \nsource(\"https:\/\/raw.githubusercontent.com\/gcostaneto\/Funcoes_naive\/master\/instpackage.R\");\n              \ninst.package(c(\"BGGE\",'foreach','doParalell','raster','rgdal','nasapower'));\n\nlibrary(EnvRtype)\n              \n\nMenu\n\n\nAuthorship\nThis package is a initiative from the Allogamous Plant Breeding Lab (University of S\u00e3o Paulo, ESALQ\/USP, Brazil).\nDeveloper\n\n\nGermano Costa Neto, PhD Candidate in Genetics and Plant Breeding\n\n\nMaintence\n\n\nGermano Costa Neto, PhD Candidate in Genetics and Plant Breeding\n\n\n\n\nGiovanni Galli, PhD in Genetics and Plant Breeding\n\n\n\n\nHumberto Fanelli, PhD in Genetics and Plant Breeding\n\n\n\n\nAcknowledgments\n\n\nGiovanni Galli, PhD in Genetics and Plant Breeding\n\n\n\n\nHumberto Fanelli, PhD in Genetics and Plant Breeding\n\n\n\n\nJose Crossa, Biometrics and Statistic Unit at CIMMYT.\n\n\n\n\nRoberto Fritsche-Neto, Professor in Genetics and Plant Breeding, Head of Allogamous Plant Breedig Lab (ESALQ\/USP)\n\n\n\n\nUniversity of S\u00e3o Paulo (ESALQ\/USP)\n\n\n\n\nConselho Nacional de Desenvolvimento Cient\u00edfico e Tecnol\u00f3gico for the PhD scholarship granted to the authors of the package\n\n\n\n\nPedro L. Longhin for additional support in Git Hub\n\n\n\n\nPublications\nCosta-Neto G, Galli G, Fanelli H, Crossa J, Fritsche-Neto R (2020). EnvRtype : a software to interplay enviromics and quantitative genomics in agriculture. bioRxiv in press\nGalli G, Horne DW, Collins SD, Jung J, Chang A, Fritsche\u2010Neto R, et al. (2020). Optimization of UAS\u2010based high\u2010throughput phenotyping to estimate plant health and grain yield in sorghum. Plant Phenome J 3: 1\u201314.\nCosta-Neto G, Fritsche-Neto R, Crossa J (2020). Nonlinear kernels, dominance, and envirotyping data increase the accuracy of genome-based prediction in multi-environment trials. Heredity (Edinb).\n\n\n","129":"EnviroMonitorStation\nEnviroMonitorStation (part of Smogly aka EnviroMonitor project) is an ESP8266 based, outdoor environmental monitoring station. It includes temperature, humidity, barometric pressure and most importantly, PM2.5, PM10 dust monitoring.\nFeatures:\n\nPM1.0, PM2.5, PM10 monitoring\ntemperature, humidity, barometric pressure monitoring\nheater for exsiccating incoming air for better results in humid conditions (e.g. during autumn and winter)\npost data to custom backend\npost data to Wunderground\nOTA updates for software\nWiFi auto configuration\n12V\/5V powered\n\nCurrently EnviroMonitor station is DIY project, we don't provide ability to buy monitoring station, you need to build it yourself.\nWe also designed PCB and enclosure so you can easily build your own sensor. Moreover - every piece of the project is Open Source, so you can modify it for your needs.\nPlease stay tuned, this is work in progress. Prototypes are being tested and we will post usable software and HW design soon.\nHardware\nBill of Materials\nBelow is the list of parts you will need to build monitoring station:\n\nWemos D1 mini ESP8266 based development board (example: https:\/\/goo.gl\/nk0Xvn)\nPMS3003 - Plantower particulate matter sensor detecting PM1.0, PM2.5, PM10 (example: https:\/\/goo.gl\/ZB6P51)\nBME280 - barometric pressure, temperature and humidity sensor (example: https:\/\/goo.gl\/bCfaJp)\nSi7021 temperature and humidity sensors (example: https:\/\/goo.gl\/RCU0Vk)\nDHT22 temperature and humidity sensors (example: https:\/\/goo.gl\/guQqyB)\n12V or 5V heat plate (example: https:\/\/goo.gl\/Pexr5R)\nDC-DC step down power supply module, preferably based on LM2596 (example: https:\/\/goo.gl\/TbNs1Y)\nAC power supply with 12V DC 1A output (example: https:\/\/goo.gl\/fVu5LT)\nN-MOSFET, example: AUIRLZ44Z\n2.54 pitch male pin headers: 2 x 8 pins (Wemos connectors, usually included with Wemos), 1 x 6 pins (PMS3003 connector), 3 x 3 pins (DS, DHT and HEAT DC switch), 1 x 4 pins (I2C bus)\n2.54 ptich female pin headers: 2 x 8 pins for wemos socket, 1 x 6 pin (to solder instead of original PMS3003 plug)\n3 x 3.5 mm pitch 2 pin screw terminals\nresistors: 1 x 4.7 k\u2126, 1 x 47 k\u2126, 1 x 1 k\u2126\nPCB\nenclosure\n\nSoftware\nBackend configuration\nBefore sensor is added to the system, it needs to be registered on the backend side. After registration you will receive couple of parameters:\n\nsensor ID - used to identify the sensor\nAPI key - to be able to post and receive data from backend\n\nSensor configuration\nAfter sensor is connected to power, it start local AccessPoint for initial configuration. User needs to connect to this AccessPoint and as a next step, familiar HotSpot configuration page should be presented. Using this simple page user can configure:\n\nsensor ID (generated during sensor registration)\nAPI access key (generated during sensor registration)\nWiFi network and password to use for sending data\nbackend and OTA server address\n\nOnce you finish configuration, sensor will reboot, and join configured WiFi network. If there was any error , e.g. wrong password, sensor will again reboot into AccessPoint mode, so you are able to correct configuration.\nHow we measure parameters\nIn every cycle device measures couple of parameters and sends them to EnviroMonitorWe backend. In current version of hardware we measure:\n\nPM1.0, PM2.5 and PM10\nexternal temperature and humidity\nexternal barometric pressure\ntemperature and humidity of air incoming to PMS3003 sensor\n\nBefore we start measuring PM* parameters, we ensure that incoming air is of accepted parameters: it's humidity and temperature are acceptable. This is required because humid air particles have size similar to PM1 and PM2.5 and can impact precision of measurement. To overcome this effect one could try to figure out how humidity and temperature impacts the measurement (develop mathematical function) or heat the air. We decided to incorporate heating plate near PMS3003 air intake.\nOnce the air reaches accepted humidity level, we start PM* measurement. Raw data is then sent to backend using simple HTTP GET call. For every monitoring station we can apply individual calibration functions before data is presented.\nSoftware updates\nEvery sensor can be updated over-the-air. Once a day sensor sends special request to backend asking for new compiled software image. Using combination of hardware versions and software version for given hardware backend decides to send new image to sensor over HTTP.\nBefore applying new image we launch pre-update functions ensuring that even if update goes wrong, sensor is safe, e.g. we switch off the heater. Once the update is successful, we use post-update function to get back all sensor features.\nDevelopment\nEnviroMonitor project is developed as a community and open source \/ open hardware project. We use Github for all the development workflow.\nEnviroMonitorStation is Arduino based project, but we use PlatformIO development environment. Please follow PlatformIO getting started guide to set up your environment. We try too keep our code Arduino compatible, so it's possible to use Arduino IDE for development, but we strongly recommend using PlatformIO.\n","130":"Environmental analysis of COVID-19 transmission rates\n\n\nRepository structure\n\/scripts\/ contains bash and python scripts for downloading ERA5 atmospheric reanalysis data and COVID-19 clinical data.\n\/data\/ contains processed data and is a placeholder directory that holds raw data files too large to be version-controlled.\n\/notebooks\/ contains the key python notebooks used for pre-processing, analysis, and plotting.\nNotebook naming conventions\nWe use the following prefix conventions for naming notebooks:\n\n0_  for pre-processing locally-downloaded raw data (large > 10 GB) and producing locally-saved interim data (10 MB < medium < 10 GB)\n1_  for analysis of raw and interim data and producing plot-ready processed data (small < 10 Mb, pushed to github)\n2_  post-processing and making publication-quality plots (saved in \/figures\/)\nT_  testing and code development (avoid using in master branch)\n\n\nProgramming environment\nThe python packages necessary for running the python scripts and jupyter notebooks included here are listed in the environment.yml file. We recommend using conda to install these packages using the command:\nconda env update -f environmental.yml\nand activating the environment with\nconda activate covid-weather\n\nDownloading raw data\nDownloading JHU CSSE COVID-19 epidemiological data\nThe \/scripts\/get_covid19_data.sh script clones the JHU CSSE dataset into the \/data\/ folder.\nDownloading ERA5 reanalysis data\nOur scripts use the Climate Data Store (CDS) API and require an account. These instructions describe how to configure your account key and use the python app, which is installed via pip install cdsapi.\nERA5 documentation\nNear-surface meterological variables in ERA5 (and quality-controlled bias corrected fields through 2018)\nSome variables of interest:\n\n\n\nVariable\nUnits\nAPI name for python script\n\n\n\n\nAltitude\nmeters\ngrid_point_altitude\n\n\nTemperature\nKelvin\nnear_surface_air_temperature\n\n\nSpecific humidity\nkg water \/ kg air\nnear_surface_specific_humidity\n\n\nPressure\nPascals\nsurface_air_pressure\n\n\nRainfall\nkg-meters^2 \/ s\nrainfall_flux\n\n\n\nInstructions for computing the near-surface specific and relative humidities, which are not archived diagnostics, from the near-surface temperature, dew point temperature, and surface pressure.\n\nContributor guidelines\nContributors to this repository should use the following workflow to ease collaboration:\n\nFork the repository\nCreate a new branch with a name that reflects your intended contribution\nMake local changes to your branch, following the repository structure and naming conventions\nAdd, commit, and push the local changes to your branch to your fork\nOpen a pull request and request review from a relevant co-contributor\nCelebrate as your changes are approved by a reviewer and merged into the master branch!\n\n","131":"\nFall 2018\nATMOS 5020\nCode and other information for ATMOS 5020, Environmental Programming, during Fall 2018\nDownload this repository\ngit clone https:\/\/github.com\/johnhorel\/ATMOS_5020_2018\n\nor download the zip file.\n> If you have a Windows PC you will need to download git for Windows.\n\nView Jupyter Notebooks\nNotebooks should render on Github. If they don't, even after refreshing the page, you can copy the notebook URL and and view it with the nbviewer: https:\/\/nbviewer.jupyter.org\/.\n\nAlternatively, download the notebook by right clicking the 'raw' button and selecting 'save as' and then open the notebook in Jupyter Lab.\n\nLast edited by Brian\n","132":"TeHyBug\nWIFI environmental data trackers\nThis repository contains code examples and code updates for TeHyBugs which you can order from Tindie\nYou may have a look at GumCP, a Raspberry Pi Web Control Panel, which now contains a TeHyBug data logging module\nGet a TeHyBug scriptable iOS 14 widget from here https:\/\/gist.github.com\/gumslone\/542ceb3afc6a9977123608f6982c59ad\n","133":"enviGCMS: GC-MS Data Analysis for Environmental Science\n    \nenviGCMS provides functions for GC\/LC-MS data analysis for environmental sciences.\nInstallation\nYou can either use the stable version of enviGCMS from CRAN,\ninstall.packages(\"enviGCMS\")\n\nor the current development snapshot from this GitHub repository:\nremotes::install_github(\"yufree\/enviGCMS\")\n\nUsage\nCheck this vignette for Data analysis of GC-MS and LC-MS in Envrionmental Science.\nCheck this vignette for Pooled QC analysis in Environmental Science.\n\nget the mean and RSD of one sample for 5 technique replicate\n\n# enviGCMS use functions in xcms to import the data, just type the path to your single sample\ndata1 <- enviGCMS:::getmd(\u2018sample1-1\u2019)\ndata2 <- enviGCMS:::getmd(\u2018sample1-2\u2019)\ndata3 <- enviGCMS:::getmd(\u2018sample1-3\u2019)\ndata4 <- enviGCMS:::getmd(\u2018sample1-4\u2019)\ndata5 <- enviGCMS:::getmd(\u2018sample1-5\u2019)\n\n\nget the mean\n\ndata <- (data1+data2+data3+data4+data5)\/5\n\n\nget the standard deviation\n\ndatasd <- sqrt(((data1-data)^2+(data2-data)^2+(data3-data)^2+(data4-data)^2+(data5-data)^2)\/4)\n\n\nget the RSD\n\ndatabrsd <- datasd\/data\n\n\nplot the smooth scatter\n\nplotsms(datarsd)\n\n\nplot the heatmap\n\nplotms(data)\n\n\nplot the mz-rt scatter plot\n\nplotmz(data)\n\n\nplot the boundary model\n\nfindline(data)\n\nDetailed usage of those functions in Environmental analysis could be found in this paper and the vignettes in this package.\n","134":"NEII Viewer\nThis is the repository for http:\/\/neii.gov.au\/viewer\/. It is based on Terria Map, and\nbuilt using the TerriaJS library.\n","135":"niche_modelling\nNiche modelling with biomod2 using 70 environmental variables summarized in PCA Axes\n","136":"MetaPathways 2: A master-worker model for environmental Pathway\/Genome Database construction on grids and clouds\nNiels W. Hanson, Kishori M. Konwar, Shang-Ju Wu, and Steven J. Hallam\n\nUpdates\nJuly 7, 2015: MetaPathways v2.5.2 release has minor bug fixes releated to gbk input processing, sam file RPKM calculations, and rRNA homology search.\nNovember 27, 2014: MetaPathways v2.5 released with upgrades to the pipeline:\n\nLAST homology searches with BLAST-equivalent output and E-values\nReads per kilobase per million mapped (RPKM) coverage measure for Contig annotations calculated from raw reads (.fastq) or mapping files (.SAM) using bwa\nAddition of the CAZy sequence database as a new compatible functional hierachy\nGUI Keyword-search from annotation subsetting and projection onto different functional hierarcies (KEGG, COG, SEED, MetaCyc, and now CAZy)\n\nSee the release page and the wiki for more information.\nAbstract\nThe development of high-throughput sequencing technologies over the past decade has generated a tidal wave of environmental sequence information from a variety of natural and human engineered ecosystems. The resulting flood of infor- mation into public databases and archived sequencing projects has exponentially expanded computational resource requirements rendering most local homology-based search methods inefficient. We recently introduced MetaPathways v1.0, a modular annotation and analysis pipeline for constructing environmental Pathway\/Genome Databases (ePGDBs) from environmental sequence information capable of using the Sun Grid engine for external resource partitioning. However, a command-line interface and facile task management introduced user activation barriers with concomitant decrease in fault tolerance.\nHere we present MetaPathways v2.0 incorporating a graphical user interface (GUI) and refined task management methods. The MetaPathways GUI provides an intuitive display for setup and process monitoring and supports interactive data visualization and sub-setting via a custom Knowledge Engine data structure. A master-worker model is adopted for task management allowing users to scavenge computational results from a number of worker grids in an ad hoc, asynchronous, distributed network that dramatically increases fault tolerance. This model facilitates the use of EC2 instances extending ePGDB construction to the Amazon Elastic Cloud.\nInstallation\nMetaPathways v2.5 requires Python 2.7 or greater and Pathway Tools developed by SRI International for full functionality.\nThe MetaPathways Python codebase as well as the compiled GUI binaries for Mac OSX and Ubuntu are self-contained in this GitHub distro. GUI source code can be obtained here.\nPlease see the MetaPathways v2.5 wiki for more installation details.\nA template MetaPathways_DBs.zip (Updated: October 2014) contains starter protein and taxonomic databases\nCitation\nIf using MetaPathways for reserach work please cite the following:\n\n\nKishori M. Konwar, Niels W. Hanson, Maya P. Bhatia, Dongjae Kim, Shang-Ju Wu, Aria S. Hahn, Connor Morgan-Lang, Hiu Kan Cheung, and Steven J. Hallam. MetaPathways v2.5: Quantitative functional, taxonomic, and usability improvements. Bioinformatics, 1\u20133 (2015). doi:10.1093\/bioinformatics\/btv361\n\n\nNiels W. Hanson, Kishori M. Konwar, Shang-Ju Wu, Steven J. Hallam. MetaPathways v2.0: A master-worker model for environmental Pathway\/Genome Database construction on grids and clouds. Proceedings of the 2014 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB 2014), Honolulu, HI, USA, May 21-24, 2014. doi:10.1109\/CIBCB.2014.6845516\n\n\n","137":"MetaPathways 2: A master-worker model for environmental Pathway\/Genome Database construction on grids and clouds\nNiels W. Hanson, Kishori M. Konwar, Shang-Ju Wu, and Steven J. Hallam\n\nUpdates\nJuly 7, 2015: MetaPathways v2.5.2 release has minor bug fixes releated to gbk input processing, sam file RPKM calculations, and rRNA homology search.\nNovember 27, 2014: MetaPathways v2.5 released with upgrades to the pipeline:\n\nLAST homology searches with BLAST-equivalent output and E-values\nReads per kilobase per million mapped (RPKM) coverage measure for Contig annotations calculated from raw reads (.fastq) or mapping files (.SAM) using bwa\nAddition of the CAZy sequence database as a new compatible functional hierachy\nGUI Keyword-search from annotation subsetting and projection onto different functional hierarcies (KEGG, COG, SEED, MetaCyc, and now CAZy)\n\nSee the release page and the wiki for more information.\nAbstract\nThe development of high-throughput sequencing technologies over the past decade has generated a tidal wave of environmental sequence information from a variety of natural and human engineered ecosystems. The resulting flood of infor- mation into public databases and archived sequencing projects has exponentially expanded computational resource requirements rendering most local homology-based search methods inefficient. We recently introduced MetaPathways v1.0, a modular annotation and analysis pipeline for constructing environmental Pathway\/Genome Databases (ePGDBs) from environmental sequence information capable of using the Sun Grid engine for external resource partitioning. However, a command-line interface and facile task management introduced user activation barriers with concomitant decrease in fault tolerance.\nHere we present MetaPathways v2.0 incorporating a graphical user interface (GUI) and refined task management methods. The MetaPathways GUI provides an intuitive display for setup and process monitoring and supports interactive data visualization and sub-setting via a custom Knowledge Engine data structure. A master-worker model is adopted for task management allowing users to scavenge computational results from a number of worker grids in an ad hoc, asynchronous, distributed network that dramatically increases fault tolerance. This model facilitates the use of EC2 instances extending ePGDB construction to the Amazon Elastic Cloud.\nInstallation\nMetaPathways v2.5 requires Python 2.7 or greater and Pathway Tools developed by SRI International for full functionality.\nThe MetaPathways Python codebase as well as the compiled GUI binaries for Mac OSX and Ubuntu are self-contained in this GitHub distro. GUI source code can be obtained here.\nPlease see the MetaPathways v2.5 wiki for more installation details.\nA template MetaPathways_DBs.zip (Updated: October 2014) contains starter protein and taxonomic databases\nCitation\nIf using MetaPathways for reserach work please cite the following:\n\n\nKishori M. Konwar, Niels W. Hanson, Maya P. Bhatia, Dongjae Kim, Shang-Ju Wu, Aria S. Hahn, Connor Morgan-Lang, Hiu Kan Cheung, and Steven J. Hallam. MetaPathways v2.5: Quantitative functional, taxonomic, and usability improvements. Bioinformatics, 1\u20133 (2015). doi:10.1093\/bioinformatics\/btv361\n\n\nNiels W. Hanson, Kishori M. Konwar, Shang-Ju Wu, Steven J. Hallam. MetaPathways v2.0: A master-worker model for environmental Pathway\/Genome Database construction on grids and clouds. Proceedings of the 2014 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB 2014), Honolulu, HI, USA, May 21-24, 2014. doi:10.1109\/CIBCB.2014.6845516\n\n\n","138":"mit-iap-environment-platform\nEnvironmental Management Platform for Environmental Ministry of Sri Lanka which is developed with collaboration of WSO2 and MIT-IAP Program\n","139":"mit-iap-environment-platform\nEnvironmental Management Platform for Environmental Ministry of Sri Lanka which is developed with collaboration of WSO2 and MIT-IAP Program\n","140":"EnvironmentalCare\nEnvironmental Care atau Kepedulian Lingkungan adalah Sebuah Aplikasi berbasis Website yang bertujuan untuk mengajak seluruh elemen masyarakat untuk peduli terhadap lingkungan sekitar point fokus peduli lingkungan disini adalah sampah plastik organik dan anorganik, dimana aplikasi ini dikembangkan sebagai salah satu bentuk Kampanye kepedulian lingkunan dan untuk memenuhi Tugas Besar Pengembangan Aplikasi Berbasis Web.\n","141":"Environmental Linked Features Interoperability Experiment (ELFIE)\nThis repository is a record of activities of the first ELFIE. It has been made public and should be considered read only and available for reference purposes only. All current activities are taking place under the Second ELFIE and potentially other projects.\nThe ELFIE github.io home page is here: https:\/\/opengeospatial.github.io\/ELFIE\/\nSummary\nThe ELFIE is intended to test existing OGC and W3C standards with the goal of establishing a best practice for exposing links between and among environmental domain and sampling features. The IE is focused on two cross-domain use cases: 1) exposing topological and domain feature model relationships between features and 2) description of sampling data available for and linked to sampled domain features While addressing these use cases, the IE will strive to address issues of encoding data as specific views of a linked data graph that would be passed between systems. These linked data graph views are expected to support archictures involving linked data catalogs and registries. For example, data providers can use the linked data graph views as a way to advertise their monitoring or domain features to catalogs or other applications that want to crawl and index available data. Similarly, integrated catalogs that index and construct links between features can use the views as a linked data response to search queries.\nObjectives\n\nDemonstrate the use of existing and pending OGC standards for the encoding of environmental observation data in an integrated dataset of features linked according to ReSTful and Linked Data principles.\nPrepare an OGC engineering report summarizing the group\u2019s findings with the intention of future development of the relevant policies, best practices or implementation standards.\nProvide draft linked data encodings to be considered by relevant standards working groups.\n\nSee the activity plan for more.\nELFIE Expectations to be Tested\nLong Term Vision\nWe think we can eliminate the need for ad-hoc one-off mappings between non-standard feature types with best practices that entail a well known set of semantics and feature models that allow automated traversal and interpretation of linked information.\nSpecific Near Term Expectations\nWe think we can express connections between features in an ostensibly open world using existing technologies and data models.\nThis includes basic spatio-tempoal topological links, monitoring relationships, and domain feature model connections.\nWe think that use of resources resolved according to a view of a linked data graph will allow us to create documents that could be built from formal linked open data yet are compatible with basic REST\/JSON pattern.\nContributing\nContributions to the ELFIE repository can be made in one of two ways. For users familiar with git and github, contributions can be made through a pull request from a fork of the repository. For users not familiar with git and github, contributions can be made by submitting an issue describing where your contribution can be found and someone will help add the content through a pull request.\nSee this how-to on setting up your local environment over in the wiki.\n","142":"Environmental Linked Features Interoperability Experiment (ELFIE)\nThis repository is a record of activities of the first ELFIE. It has been made public and should be considered read only and available for reference purposes only. All current activities are taking place under the Second ELFIE and potentially other projects.\nThe ELFIE github.io home page is here: https:\/\/opengeospatial.github.io\/ELFIE\/\nSummary\nThe ELFIE is intended to test existing OGC and W3C standards with the goal of establishing a best practice for exposing links between and among environmental domain and sampling features. The IE is focused on two cross-domain use cases: 1) exposing topological and domain feature model relationships between features and 2) description of sampling data available for and linked to sampled domain features While addressing these use cases, the IE will strive to address issues of encoding data as specific views of a linked data graph that would be passed between systems. These linked data graph views are expected to support archictures involving linked data catalogs and registries. For example, data providers can use the linked data graph views as a way to advertise their monitoring or domain features to catalogs or other applications that want to crawl and index available data. Similarly, integrated catalogs that index and construct links between features can use the views as a linked data response to search queries.\nObjectives\n\nDemonstrate the use of existing and pending OGC standards for the encoding of environmental observation data in an integrated dataset of features linked according to ReSTful and Linked Data principles.\nPrepare an OGC engineering report summarizing the group\u2019s findings with the intention of future development of the relevant policies, best practices or implementation standards.\nProvide draft linked data encodings to be considered by relevant standards working groups.\n\nSee the activity plan for more.\nELFIE Expectations to be Tested\nLong Term Vision\nWe think we can eliminate the need for ad-hoc one-off mappings between non-standard feature types with best practices that entail a well known set of semantics and feature models that allow automated traversal and interpretation of linked information.\nSpecific Near Term Expectations\nWe think we can express connections between features in an ostensibly open world using existing technologies and data models.\nThis includes basic spatio-tempoal topological links, monitoring relationships, and domain feature model connections.\nWe think that use of resources resolved according to a view of a linked data graph will allow us to create documents that could be built from formal linked open data yet are compatible with basic REST\/JSON pattern.\nContributing\nContributions to the ELFIE repository can be made in one of two ways. For users familiar with git and github, contributions can be made through a pull request from a fork of the repository. For users not familiar with git and github, contributions can be made by submitting an issue describing where your contribution can be found and someone will help add the content through a pull request.\nSee this how-to on setting up your local environment over in the wiki.\n","143":"HapFlow\nHapFlow is a python application for visualising haplotypes present in sequencing data. It identifies variant profiles present and reads and creates an abstract visual representation of these profiles to make haplotypes easier to identify.\nIt is freely available under the GPLv3 license.\nThe main website for HapFlow is here, it contains downloadable binaries and examples.\nFor installation and usage instructions please consult the manual.\n","144":"ETDOT\nThe Environmental Technologies Design Option Tool (ETDOT) was developed by National Center for Clean Industrial and Treatment Technologies (CenCITT) at Michigan Technological University (MTU).\nVersion 1.0: Copyright 1994\u20132005\n\nDavid R. Hokanson\nDavid W. Hand\nJohn C. Crittenden\nTony N. Rogers\nEric J. Oman\n\nThis GitHub repository includes FORTRAN and VisualBasic Code associated with the suite of programs distributed within ETDOT.\nSoftware that is included:\n\nAdsorption Design Software for Windows (AdDesignS) Version 1.0\nAdvanced Oxidation Process Software (AdOx) Version 1.0.2\nAeration System Analysis Program (ASAP) Version 1.0\nBiofilter Design Software Version 1.0.27\nContinuous Flow Pore Surface Diffusion Model for Modeling Powdered Activated Carbon\nAdsorption Version 1.0\nDye Study Program (DyeStudy) Version 1.0.0\nPredictive Software for the Fate of Volatile Organics in Municipal Wastewater Treatment Plants (FaVOr) Version 1.0.11\nIon Exchange Design Software (IonExDesign) Version 1.0.0\nSoftware to Estimate Physical Properties (StEPP) Version 1.0\n\nIn 2019, MTU signed a software transfer agreement with the United States Environmental Protection Agency (EPA) granting the EPA the rights to maintain and non-commercially and publicly distribute the ETDOT suite of packages.\nDisclaimer:\nThe United States Environmental Protection Agency (EPA) GitHub project code is provided on an \"as is\" basis and the user assumes responsibility for its use. EPA has relinquished control of the information and no longer has responsibility to protect the integrity, confidentiality, or availability of the information. Any reference to specific commercial products, processes, or services by service mark, trademark, manufacturer, or otherwise, does not constitute or imply their endorsement, recommendation or favoring by EPA. The EPA seal and logo shall not be used in any manner to imply endorsement of any commercial product or activity by EPA or the United States Government.\nInstallation Instructions\nThis software requires Administrator Rights to a computer to install and to run. Files are installed directly to a folder X:\\ETDOT10... where X is the system main drive.\n\nDownload zip file ('etdot_1-0.zip') under Releases.\nUnzip\/Unpack zip file\nRun setup.exe and follow prompts\nWhen prompted enter license key: CAADV0-R74JM-QXCNP-7EER9-1AT72\nTo run each module in Windows 7 or newer: Edit properties of the program to be run and select Compatibility Tab and  \"run in compatibility mode\". Select Windows 98\/Me from the Compatibility Mode dropdown menu.\n\nAvailable Users manuals will be located in the modules subfolder within the help folder.\nNotes on current software\nThe ETDOT suite of software packages consists of a FORTRAN engine with a Visual Basic (version 6) graphical user interface. The VB6 portion of the code relies on ActiveX control files which are located in the repository, however, these are an older coding standard and no longer supported with current versions of Visual Studio 20##. Precompiled engine files are included.\n","145":"Satellite Imagery Analysis with Python\nData is the new oil today but what if that data was actually being used to monitor the oil around the world?\nOil is an area which concerns many nations and has been at the center of the storm for quite a long time. It isn\u2019t easy to monitor the oil inventory around the world since nobody has a clear idea about the amount of oil left on the planet.\nOrbital Insight, a Geospatial Big Data company, analyses vast amounts of photos of oil tanks with floating lids. When the level of oil goes down in these tanks, the lid also sinks, and the shadows cast by the sun on the inside of the tank also changes. By detecting patterns in how those shadows change, analysts can estimate how much oil is available in all the tanks it monitors. The company uses techniques like Computer vision and Deep learning to do the analysis which in turn helps to discover information that affects the global economy, like oil surpluses or shortages.\nObjective\nIn this article, we shall study how we can examine the vegetation cover of a region with the help of satellite data. This article aims to familiarise the readers with the concept of satellite imagery data and how it can be analyzed to investigate real-world environmental and humanitarian challenges.\nThis is an excerpt from my Medium article with the same name. For the complete article, refer here\n","146":"Environmental Layers repository overview\nAt the top-level, the repository is split into four main topical domains\n(climate, derived-climate, land-cover, and terrain),\nplus an additional shared directory for general project-level\nmaterials. Each of the topical directories themselves contain up to 6\npredetermined subdirectories as indicated below. See descriptions for\nspecific criteria for determining what goes in each directory.\nAll committed work should fall within this directory structure.\n\nresearch\nScripts, notes, generated summaries\/reports, and possibly additional\nrelevant background information intended to inform and\/or evaluate\nmethodological decisions. The defining criterion is that these\nmaterials are not designed to be used as operational components of\nthe eventual data production workflow itself, but instead serve to\nguide its development. Examples include case studies, statistical\nmodel comparisons, dataset assessments, validation procedures, etc.\nprocedures\nScripts that either have been, could be, or will be executed with the\nexpress purpose of producing data, including acquisition of data\nfrom elsewhere, creation of intermediate datasets, and production of\nfinal layers. Prose (or mixed prose\/text) text documents may be\nsubstituted for executable scripts if absolutely necessary, e.g. to\nexpress procedures that had to be performed manually.\ntests\nScripts intended for testing whether particular data holdings meet\nexpectations (e.g., completeness, consistency, etc), or for testing\nwhether particular scripts produce output as expected given specified\ntest inputs. Although not necessarily the case while in-development,\nultimately all tests should be able to run without intervention,\nreporting either success or failure along with appropriate supporting\ndetails.\ndoc\nDocumentation and associated files (figures, thumbnail images, etc).\nStrong preference should be given to text-based documentation\n(including standard markup formats), and especially reproducible\ndocumentation schemes such as LaTeX\/Sweave.\nlib\nSource code (possibly with supporting materials such as Makefiles)\nthat contains generally useful and reusable bits of functionality that\nare or could be leveraged elsewhere. The idea is that these would be\nimported, included, sourced, etc. by scripts in one or more other\nproject directories.\nextra\nMiscellaneous notes, code snippets, blue-sky scripts, and other\nmaterials that seem worth capturing into this repository, but don't\nfit under any other directories.\n\nDirectory tree:\n.\n\u251c\u2500\u2500 climate\/\n\u2502   \u251c\u2500\u2500 research\/\n\u2502   \u251c\u2500\u2500 procedures\/\n\u2502   \u251c\u2500\u2500 tests\/\n\u2502   \u251c\u2500\u2500 lib\/\n\u2502   \u251c\u2500\u2500 doc\/\n\u2502   \u2514\u2500\u2500 extra\/\n\u251c\u2500\u2500 derived-climate\/\n\u2502   \u251c\u2500\u2500\n\u2502   \u251c\u2500\u2500\n\u2502   \u251c\u2500\u2500 <as above>\n\u2502   \u251c\u2500\u2500\n\u2502   \u251c\u2500\u2500\n\u2502   \u2514\u2500\u2500\n\u251c\u2500\u2500 land-cover\/\n\u2502   \u251c\u2500\u2500\n\u2502   \u251c\u2500\u2500\n\u2502   \u251c\u2500\u2500 <as above>\n\u2502   \u251c\u2500\u2500\n\u2502   \u251c\u2500\u2500\n\u2502   \u2514\u2500\u2500\n\u251c\u2500\u2500 terrain\/\n\u2502   \u251c\u2500\u2500\n\u2502   \u251c\u2500\u2500\n\u2502   \u251c\u2500\u2500 <as above>\n\u2502   \u251c\u2500\u2500\n\u2502   \u251c\u2500\u2500\n\u2502   \u2514\u2500\u2500\n\u2514\u2500\u2500 shared\/\n\n","147":"\n\n\n\nDeep Environmental Configuration\n\ndec\n\n\n\ndec builds arbitrarily nested data structures from simple KV strings.\n\nTiny codebase; tiny name\nFunctionally pure\nComposable\nZero runtime dependencies\n100% test coverage with unit tests & test.check\nFully linted against eastwood &\nkibit\nUp-to-date Change Log\n\nRationale\nEnv vars are constrained to simple key value pairs, yet they are ubiquitous.\nDocker config and 12 Factor Config in particular\nrely on this traditional mechanism. But modern apps often require more complex\ndata structures, to wit: maps and lists.\nUsage\ndec exposes two primary functions: explode and enflat. They are inverses of\neachother, such that identity == (comp explode enflat), i.e.:\n(let [nested {:foo {:bar [:baz :qux]}}]\n  (= nested (explode (enflat nested))))\n;;=> true\nAssume our env looks like:\nexport DEC_HOSTS_0=a.host.com\nexport DEC_HOSTS_1=b.host.com\nexport DEC_LEVEL=debug\nThen we we obtain some env vars via\nenviron, as one does,\nfilter by a known prefix, and explode the results:\n(require\n  '[environ.core :refer [env]]\n  '[dec :refer [explode]])\n\n(explode (into {} (filter (fn [[k v]] (.startsWith (name k) \"dec\")) env)))\n\n{:dec {:hosts [\"a.host.com\" \"b.host.com\"], :level \"debug\"}}\nA little simpler, without the env:\n(explode\n  {:dec-level \"debug\"\n   :dec-hosts-0 \"a.host.com\"\n   :dec-hosts-1 \"b.host.com\"})\n\n{:dec {:hosts [\"a.host.com\" \"b.host.com\"], :level \"debug\"}}\nEnviron is not required, nor is it a dependency of dec; I'm using it as an\nexample of a common way to obtain environmental configuration.\nCustom delimiter\ndec optionally takes a delimiter parameter:\n(explode {:dec.hosts.0 \"a.host.com\"\n          :dec.hosts.1 \"b.host.com\"\n          :dec.level \"debug\"}\n          {:delimiter \".\"})\n\n{:dec {:hosts [\"a.host.com\" \"b.host.com\"], :level \"debug\"}}\nRun tests\nlein test\n\nCalculate code coverage\nlein cloverage\n\nRun linters\nlein kibit\nlein eastwood\n\nLicense\nCopyright \u00a9 2016 Trevor C. Hartman\nDistributed under the Eclipse Public License either version 1.0 or any later\nversion.\n","148":"\n\n\n\n\nThe new version 2.1 of the Bio-Oracle dataset is now available to the sdmpredictors package (2020-09-21). Click here to see the release notes.\n\nsdmpredictors: a compilation of species distribution modelling predictors data\nAn R package to improve the usability of datasets with predictors for species distribution modelling (SDM).\nInstallation:\n \u00a0 \u00a0install.packages(\"sdmpredictors\")\n    # or for the latest dev version\n    devtools::install_github(\"lifewatch\/sdmpredictors\")\nExample 1: Create SDM for Dictyota diemensis in Australia\nNote that this requires the ZOON, ggplot2, cowplot and marinespeed packages to be installed.\n    library(sdmpredictors)\n    library(zoon)\n    \n    # Inspect the available datasets and layers\n    datasets <- list_datasets(terrestrial = FALSE, marine = TRUE)\n    View(datasets)\n    layers <- list_layers(datasets)\n    View(layers)\n    # Load equal area rasters and crop with the extent of the Baltic Sea\n    layercodes <- c(\"MS_biogeo05_dist_shore_5m\", \"MS_bathy_5m\", \n                    \"BO_sstrange\", \"BO_sstmean\", \"BO_salinity\")\n    env <- load_layers(layercodes, equalarea = TRUE)\n    australia <- raster::crop(env, extent(106e5,154e5, -52e5, -13e5))\n    plot(australia)\n    # Compare statistics between the original and the Australian bathymetry\n    View(rbind(layer_stats(\"MS_bathy_5m\"),\n               calculate_statistics(\"Bathymetry Australia\", \n                                    raster(australia, layer = 2))))\n    # Compare correlations between predictors, globally and for Australia\n    prettynames <- list(BO_salinity=\"Salinity\", BO_sstmean=\"SST (mean)\", \n                        BO_sstrange=\"SST (range)\", MS_bathy_5m=\"Bathymetry\",\n                        MS_biogeo05_dist_shore_5m = \"Shore distance\")\n    p1 <- plot_corr(layers_correlation(layercodes), prettynames)\n    australian_correlations <- pearson_correlation_matrix(australia)\n    p2 <- plot_correlation(australian_correlations, prettynames)\n    cowplot::plot_grid(p1, p2, labels=c(\"A\", \"B\"), ncol = 2, nrow = 1)\n    print(correlation_groups(australian_correlations))\n    # Fetch occurrences and prepare for ZOON\n    occ <- marinespeed::get_occurrences(\"Dictyota diemensis\")\n    points <- SpatialPoints(occ[,c(\"longitude\", \"latitude\")],\n                            lonlatproj)\n    points <- spTransform(points, equalareaproj)\n    occfile <- tempfile(fileext = \".csv\")\n    write.csv(cbind(coordinates(points), value=1), occfile)\n    # Create SDM with ZOON\n    workflow(\n      occurrence = LocalOccurrenceData(\n        occfile, occurrenceType=\"presence\",\n        columns = c(\"longitude\", \"latitude\", \"value\")), \n      covariate = LocalRaster(stack(australia)),\n      process = OneHundredBackground(seed = 42),\n      model = LogisticRegression,\n      output = PrintMap)\n    # Layer citations\n    print(layer_citations(layercodes))\nExample 2: view marine datasets, layers and load a few of them by name\n    library(sdmpredictors)\n    \n    # exploring the marine datasets\n    datasets <- list_datasets(terrestrial = FALSE, marine = TRUE)\n    View(datasets)\n    browseURL(datasets$url[1])\n    \n    # exploring the layers\n    layers <- list_layers(datasets)\n    View(layers)\n    \n    # download specific layers to the current directory\n    rasters <- load_layers(c(\"BO_calcite\", \"BO_chlomean\", \"MS_bathy_5m\"), datadir = \".\")\nExample 3: looking up statistics and correlations for marine annual layers:\n    datasets <- list_datasets(terrestrial = FALSE, marine = TRUE)\n    layers <- list_layers(datasets)\n    \n    # filter out monthly layers\n    layers <- layers[is.na(layers$month),]\n    \n    stats <- layer_stats(layers)\n    View(stats)\n    \n    correlations <- layers_correlation(layers)\n    View(correlations)\n    \n    # create groups of layers where no layers in one group \n    # have a correlation > 0.7 with a layer from another group\n    groups <- correlation_groups(correlations, max_correlation=0.7)\n    \n    # inspect groups\n    # heatmap plot for larger groups (if gplots library is installed)\n    for(group in groups) {\n      group_correlation <- as.matrix(correlations[group, group, drop=FALSE])\n      if(require(gplots) && length(group) > 4){\n        heatmap.2(abs(group_correlation)\n                 ,main = \"Correlation\"\n                 ,col = \"rainbow\"      \n                 ,notecol=\"black\"      # change font color of cell labels to black\n                 ,density.info=\"none\"  # turns off density plot inside color legend\n                 ,trace=\"none\"         # turns off trace lines inside the heat map\n                 ,margins = c(12,9)    # widens margins around plot\n                 )\n      } else {\n        print(group_correlation)\n      }\n    }\nSee the quickstart vignette for more information\n    vignette(\"quickstart\", package = \"sdmpredictors\")\n","149":"\n\n\nSLIM is a node.js web app providing an easy Graphical User Interface (GUI) to wrap bioinformatics tools for amplicon sequencing analysis (from illumina paired-end FASTQ to annotated ASV\/OTU matrix).\nAll the pipeline is embedded in a docker.\nInstall and deploy the web app\nSee below for full instructions\nAccessing the webserver\nThe execution of the start_slim_v0.6.1.sh script deploys and start the webserver.\nBy default, the webserver is accessible on the 8080 port.\n\nTo access it on a remote server from your machine, type the server IP address followed by \":8080\" (for example 156.241.0.12:8080) from an internet browser (prefer Firefox and Google Chrome).\nIf SLIM is deployed on your own machine, type localhost:8080\/\n\nIf the server is correctly set, you should see this:\n\n\n\nPrepare and upload your data\nThe \"file uploader\" section allows you to upload all the required files. Usually it consists of:\n\none (or multiple) pair(s) of FASTQ files corresponding to the library(ies) (can be zipped)\na CSV (Comma-separated values) file containing the correspondance between library, tagged-primers pairs and samples (the so-called tag-to-sample file, see below for an example)\na FASTA file containing the tagged primers sequences and name (see below for an example)\na FASTA file containing sequence reference database (see below for an example)\n\nExample of tag-to-sample file:\nThis file must contain at least the four four fields: run, sample, forward and reverse. \"Run\" corresponds to your illumina library identification; \"sample\" corresponds to the names of your samples in the library; \"forward\" and \"reverse\" corresponds to the names of your tagged primers.\nSamples names MUST be unique, even for replicates sequenced in multiples libraries\nrun,sample,forward,reverse\nlibrary_1,sample_1,forwardPrimer-A,reversePrimer-B\nlibrary_1,sample_2,forwardPrimer-B,reversePrimer-C\nlibrary_2,sample_3,forwardPrimer-A,reversePrimer-B\nlibrary_2,sample_4,forwardPrimer-B,reversePrimer-C\n\nExample of primers FASTA file:\nIt contains the names of your tagged primers and their sequences, in a conventional FASTA format. Each primer tag consists of 4 variables nucleotides at the 5' side, prior the template specific part.\nEach primer must contains a specific identifier (by letters in this example). The primers sequences can include IUPAC nucleotide codes, they are taken into account.\n>forwardPrimer-A\nACCTGCCTAGCGTYG\n>forwardPrimer-B\nGAATGCCTAGCGTYG\n>reversePrimer-B\nGAATCTYCAAATCGG\n>reversePrimer-C\nACTACTYCAAATCGG\n\nExample of sequences reference database file\nThis FASTA file contains reference sequences with unique identifier and taxonomic path in the header.\nSuch database can be downloaded for instance from SILVA for both prokaryotes and eukaryotes (16S and 18S), EUKREF or PR2 for eukaryotes (18S), UNITE for fungi (ITS), MIDORI for metazoan (COI).\nEach header include a unique identifier (usually the accession),\na space ' ', and the taxonomic path separated by a semi-colon (without any space, please use \"_\" underscore).\nYou should have the same amount of taxonomic rank for each reference sequences\n>AB353770 Eukaryota;Alveolata;Dinophyta;Dinophyceae;Dinophyceae_X;Dinophyceae_XX;Peridiniopsis;Peridiniopsis_kevei\nATGCTTGTCTCAAAGATTAAGCCATGCATGTCTCAGTATAAGCTTTTACATGGCGAAACTGCGAATGGCTCATTAAAACAGTTACAGTTTATTTGAA\nGGTCATTTTCTACATGGATAACTGTGGTAATTCTAGAGCTAATACATGCGCCCAAACCCGACTCCGTGGAAGGGTTGTATTTATTAGTTACAGAACC\nAACCCAGGTTCGCCTGGCCATTTGGTGATTCATAATAAACGAGCGAATTGCACAGCCTCAGCTGGCGATGTATCATTCAAGTTTCTGACCTATCAGC\nTTCCGACGGTAGGGTATTGGCCTACCGTGGCAATGACGGGTAACGGAGAATTAGGGTTCGATTCCGGAGAGGGAGCCTGA\n>KC672520 Eukaryota;Opisthokonta;Fungi;Ascomycota;Pezizomycotina;Leotiomycetes;Leotiomycetes_X;Leotiomycetes_X_sp.\nTACCTGGTTGATTCTGCCCCTATTCATATGCTTGTCTCAAAGATTAAGCCATGCATGTCTAAGTATAAGCAATATATACCGTGAAACTGCGAATGGC\nTCATTATATCAGTTATAGTTTATTTGATAGTACCTTACTACT\n>AB284159 Eukaryota;Alveolata;Dinophyta;Dinophyceae;Dinophyceae_X;Dinophyceae_XX;Protoperidinium;Protoperidinium_bipes\nTGATCCTGCCAGTAGTCATATGCTTGTCTCAAAGATTAAGCCATGCATGTCTCAGTATAAGCTTCAACATGGCAAGACTGTGAATGGCTCATTAAAA\nCAGTTGTAGTTTATTTGGTGGCCTCTTTACATGGATAGCCGTGGTAATTCTAGAACTAATACATGCGCTCAAGCCCGACTTCGCAGAAGGGCTGTGT\nTTATTTGTTACAGAACCATTTCAGGCTCTGCCTGGTTTTTGGTGAATCAAAATACCTTATGGATTGTGTGGCATCAGCTGGTGATGACTCATTCAAG\nCTT\n\nAnalyse your data\nUsually, a typical workflow would include:\n\nDemultiplexing the libraries (if each library corresponds to a single sample, adapt your tag-to-sample file accordingly, and proceed to the joining step)\nJoining the paired-end reads\nChimera removal\nASVs inference \/ OTUs clustering\nTaxonomic assignement\n\nThe \"Add a new module\" section has a drop-down list containing various modules to pick, set and chain.\nPick one and hit the \"+\" button. This will add the module at the bottom of the first section, and prompting you to fill the required fields. For more informations on the modules, you can refer to their manuals on the wiki or by clicking the (i) button on the module interface.\nThe use of wildcard '*' for file pointing\nThe chaining between module is made through the files names used as input \/ output. To avoid having to select mannually all the samples to be included in an analysis, wildcards '*' (meaning 'all') are generated and used by the application.\nSuch wildcards are generated from the compressed libraries fastq files (tar.gz) and by the tag-to-sample file.\nUsers cannot type on their own wildcards in the file names. Instead, the application has an autocompletion feature and will make wildcards suggestions for the user to select within the GUI.\nTo point to a set of samples (all samples from the tag-to-sample, or all the samples from the library_1 for instance), there will be a '*', and the application adds the processing step as a suffix incrementaly:\n\nall samples from the tag-to-sample file that have been demultiplexed: 'tag_to_sample*_fwd.fastq' and 'tag_to_sample*_rev.fastq'\nall samples from the library_1 that have been demultiplexed: 'tag_to_sample_Library_1*_fwd.fastq' and 'tag_to_sample_Library_1*_rev.fastq'\nall samples from the tag-to-sample file that have been joined: 'tag_to_sample*_merge-vsearch.fasta'\nall samples from the tag-to-sample file that have been joined and chimera filtered: 'tag_to_sample*_merge-vsearch_uchime.fasta'\n\nThe same principle applies for ASV\/OTU matrices, we add the previous processing step as a suffix in the file name.\nsee below for the demultiplexing\n\n\n\nand below for an OTU clustering using vsearch and taxonomic assignement\n\n\n\nOnce your workflow is set, please fill the email field and click on the start button.\nYour job will automatically be scheduled on the server.\nYou will receive an email when your job starts, if you job aborted and when your job is over.\nThis email contains a direct link to your job so that the internet browser tab can be closed once the execution started.\nWhen the job is over, you will have small icons of download on the right of each output field.\nAll the uploaded, intermediate and results files are available to download.\nYour files will remain available on the server during 24h, after what they will be removed for disk usage optimisation\nEach module status is displayed besides its names:\n\nwaiting: the execution started, the module is waiting for files input.\nrunning: the module is busy.\nwarnings: there was some warnings during the execution, but the module is still running.\naborted: the module aborted and the pipeline has stopped its execution.\nended: the module has finnished its task.\n\nFor more details on the app, you can refer to the wiki pages\nInstall, deploy and manage the web app\nFirst of all, docker needs to be installed on the machine. You can find instructions here :\n\ndocker for Debian\ndocker for Ubuntu\ndocker for macOS\n\nTo install SLIM, get the last stable release here or, using terminal :\nsudo apt-get update && apt-get install git curl\ncurl -OL https:\/\/github.com\/trtcrd\/SLIM\/archive\/v0.6.1.tar.gz\ntar -xzvf v0.6.1.tar.gz\ncd SLIM-0.6.1\nBefore deploying SLIM, you need to configure the mailing account that will be used for mailing service.\nWe advise to use gmail, as it is already set in the 'server\/config.js' file.\nThis file need to be updated with your 'user' and 'pass' credentials on the server:\nexports.mailer = {\n\thost: 'smtp.gmail.com',\n    port: 465,\n    secure: true, \/\/ true for 465, false for other ports\n    auth: {\n        user: 'username',\n        pass: 'password'\n    }\n}\n\nAs soon as docker is installed and running, the SLIM archive downloaded and the mailing account set, it can be deployed by using the two scripts get_dependencies_slim_v0.6.1.sh and start_slim_v0.6.1.sh as super user.\n\nget_dependencies_slim_v0.6.1.sh fetches all the bioinformatics tools needed from their respective repositories.\nstart_slim_v0.6.1.sh destroys the current running webserver to replace it with a new one. \/!\\ All the files previously uploaded and the results of analysis will be detroyed during the process.\n\nsudo bash get_dependencies_slim_v0.6.1.sh\nsudo bash start_slim_v0.6.1.sh\nThe server is configured to use up to 8 CPU cores per job. The amount of available cores will determine the amount of job that can be executed in parallel (1-8 -> 1 job, 16 -> 2 jobs, etc.). To admin and access SLIM logs, please refer to the docker command line documentation.\nCreating your own module\nTo contribute by adding new softwares, you will have to know a little bit of HTML and javascript.\nPlease refer to the wiki pages to learn how to create a module.\nCurrent modules by category\nDemultiplexing\n\nDTD: Demultiplex libraries from illumina outputs\n\nPaired-end read joiner\n\nPandaseq\nvsearch mergepair\nCASPER\n\nChimera detection\n\nvsearch uchime\n\nASVs inference \/ OTUs clustering\n\nDADA2\nvsearch uclust\nswarm\n\nSequence assignment\n\nvsearch usearch\nIDTAXA\n\nPost-clustering\n\nLULU\n\nVersion history\nv0.6.1\nDockerfile: updated to DADA2 v1.16 and DECIPHER v2.16.0, cleaned the docker recipe\nv0.6\nBUGFIX: resolved issues with the order of module execution when DADA2 is used.\nBUGFIX: resolved issues with the pipeline.conf file that did not included the checkbox and radio buttons.\nv0.5.3\nDTD: added an option for trimming the primers at the end of the reads in (for fully overlapping pair-end reads) and a contig length filtering\nv0.5.2\nDADA2 beta integration, small fix on IDATAXA\nv0.5.1\nBUGFIX of the IDTAXA module, added wiki for the module\nv0.5\nIntegration of the IDTAXA module\nv0.4.1\nFixed the Dockerfile to fetch the latest R version and CASPER util.c file\nv0.4\nAdded timing checkpoints in the logs of the scheduler; Added the third-party software version infos in the email\nv0.3\nFixed LULU module and the otu table writing is now done by a python script\nv0.2\nUpdated the get_dependencies script.\nv0.1\nFirst release, with third-parties versions handled within the get_dependencies_slim.sh script.\n","150":"EnvironmentalDemogeneticsABC\nStatistical models of coalescent on a graph\nCoalescence in an Approximate Bayesian Computation framework\nModel\nUse askListOfParameters function to precise the model. The function will successively ask for a model, for the prior distribution of each parameter, and finally for values of hyperparameters. Then parameters values are drawn and stored with the model in a list object.\nCoalescent simulations\nUse simSpatialCoal to simulate spatial coalescence.\nRequired objects\nThe model list, a rasterStack of environment variables and a **spatial genetic dataset** :\n\n\n\n\nx\ny\nLocus 1\nLocus 2\n...\nLocus 3\n\n\n\n\n0.5\n1\n287\n180\n242\n136\n\n\n\nFunction\nThe function makes use of mclapply (package parallel) to perform parallel computing. This function relies on forking implementation, but Windows does not support forking. Furthermore, even on Linux, mclapply seems to behave quite weirdly. This will be settled later.\nResults\nsimSpatialCoal function creates a repertory in the current directory, named SimulResults, where are written the simulated genetic values for each locus and individuals.\nABC analysis\nMakes use of abc package functions.\nSummary statistics\nUse pca4abc function to computes summary statistics of simulated genetic dataset. Firstly, PC are computed according to the observed genetic data, then transformation is applied to all simulated genetic data. This function returns a list of three objects that can be used in abc package functions : a vector of observed summary statistics, a matrix of simulated summary statistics, and a matrix of parameters values used for simulations.\nCross validation\nabc package can perform cross validation, using cv4abc\nABC\nabc function of abc package performs a classic analysis\nForward models\n","151":"EMS\nFeatures\n\nHydrodynamic models for structured and unstructured grids\nSediment transport, resuspension and deposition\nSpectrally-resolved semi-empirical optical model\nBiogeochemical (nutrients, plankton, carbon chemistry) and benthic (seagrass, corals) processes\n\nBackground\nThe CSIRO Coastal Environmental Modelling (CEM) team develops, maintains and uses the EMS software that allows investigation of the physical, sediment and biogeochemical processes in marine environments. This is achieved by a \u2018driver\u2019 hydrodynamic code into which are linked various libraries to perform sediment transport and biogeochemistry, all supported by a core library. The \u2018driver\u2019 may be any model that manages the tracers required for sediments and biogeochemistry. The sediment and biogeochemical libraries are stand-alone modules that are linked to the driver via an interface, and in principle may be linked to any hydrodynamic code. Currently the \u2018drivers\u2019 available are a full hydrodynamic mode, a transport model that uses offline data to advect and diffuse sediment \/  biogeochemical variables, and a box model. The hydrodynamic code may further operate in reduced dimensions of 1D, 2D vertically averaged or 2D laterally averaged. A waves and tracer statistic library also exist; the latter allowing various operations to be performed during run-time on any tracers supported by the driver (e.g. means, fluxes, vertical integrals).\nAdditional software exists to generate the complex orthogonal curvilinear grids that are typically used for case studies. These grids allow variable resolution over the domain, useful for representing areas of interest with high resolution and less critical regions with coarser resolution. The curvilinear grid may also allow a dimensionality to be reduced from 3-D to 2-D within the same grid. This is useful when representing rivers or narrow estuaries, since the cross-river coordinate becomes very small in these areas and therefore becomes the defining grid size for setting the model time-step. Eliminating these small grid cells by making rivers or estuaries 2-D laterally averaged allows larger time-steps, hence a faster model. The curvilinear grids require dedicated software for visualizisation of model output, and the CEM supports several visualisation platforms to archive this. These software packages allow publication quality images and animations to be produced, and allow exploration of the data in 4 dimensions for analysis purposes.\nSee more EMS info on the CEM website\nDocumentation\nManuals for all modules are available from this link\nUser registration\nWe strongly encourage all users of EMS to register their details with our group.\nPlease use this form to do so\nGetting Started\nThese instructions will get you a copy of the project up and running on your local machine for development and testing purposes.\nPrerequisites\nThings you need to build EMS applications\nC\/C++ compiler\nmake\nNetCDF library\n\nBuilding\nTo get started, type the following on a Linux command line:\nconf\/configure\nmake\n# This will build all libraries and modules including SHOC & COMPAS\n# SHOC will be available in model\/hd, to check version info type:\nmodel\/hd\/shoc -v\n# COMPAS will be available in model\/hd-us, to check version info type:\nmodel\/hd-us\/compas -v\n\nSee this page for full explaination of the build procedure\nRunning the tests\nThere are many tests available for each module. See model\/tests for a complete list.\nAuthors\nEMS is wrtten and maintained by the Coastal Environmental Modelling team\nSee also the list of contributors who participated in this project.\nLicense\nThis project is licensed under the CSIRO open-source License - see the LICENSE.md file for details\nWebsite\nFurther information about the CSIRO CEM Team may be found by visiting our website.\nContributing\nPlease contact us on ems@csiro.au for details\n","152":"ModularSensors\n\nAn Introduction\nCheck out the Just Getting Started section of the documentation!\nThis Arduino library gives environmental sensors a common interface of functions for use with Arduino-compatible dataloggers, such as the EnviroDIY Mayfly.\nThe ModularSensors library is specifically designed to support wireless, solar-powered environmental data logging applications, that is, to:\n\nRetrieve data from many physical sensors;\nSave that data to a SD memory card;\nTransmit that data wirelessly to a web server; and\nPut the processor, sensors and all other peripherals to sleep between readings to conserve power.\n\nThe ModularSensors library coordinates these tasks by \"wrapping\" native sensor libraries into a common interface of functions and returns.\nThese wrapper functions serve to harmonize and simplify the process of iterating through and logging data from a diverse set of sensors and variables.\nUsing the common sensor and variable interface, the library attempts to optimize measurement timing as much as possible to reduce logger \"on-time\" and power consumption.\nAlthough this library was written primarily for the EnviroDIY Mayfly data logger board, it is also designed to be compatible with a variety of other Arduino-based boards as well.\nThere is extensive documentation available in the ModularSensors github pages including details of the class structures and example code.\n\nModularSensors\n\nAn Introduction\nSupported Sensors\nData Endpoints\nSupported Cellular\/Wifi Modules:\nContributing\nLicense\nAcknowledgments\n\n\n\nSupported Sensors\nFor some generalized information about attaching sensors to an Arduino style board, see the Sensor Notes page\n\nProcessor Metrics: battery voltage, free RAM, sample count\nMaxim DS3231: real time clock\nAOSong AM2315: humidity & temperature\nAOSong DHT: humidity & temperature\nApogee SQ-212: quantum light sensor, via TI ADS1115\nAtlas Scientific EZO Sensors\n\nEZO-CO2: Carbon Dioxide and Temperature\nEZO-DO: Dissolved Oxygen\nEZO-EC: Conductivity, Total Dissolved Solids, Salinity, and Specific Gravity\nEZO-ORP: Oxidation\/Reduction Potential\nEZO-pH: pH\nEZO-RTD: Temperature\n\n\nBosch BME280: barometric pressure, humidity & temperature\nCampbell Scientific OBS-3+: turbidity, via TI ADS1115\nDecagon Devices ES-2: conductivity \nFreescale Semiconductor MPL115A2: barometric pressure and temperature\nExternal Arduino I2C Rain Tipping Bucket Counter: rainfall totals\nKeller Submersible Level Transmitters: pressure and temperature\n\nAcculevel\nNanolevel\n\n\nMaxBotix MaxSonar: water level\nMaxim DS18: temperature\nMeasurement Specialties MS5803: pressure and temperature\nMeter Environmental Soil Moisture Probes: soil Ea and volumetric water content\n\nMeter ECH2O 5TM\nMeter Teros 11\n\n\nMeter Environmental Hydros 21 (formerly Decagon Devices CTD-10): conductivity, temperature & depth\nTI ADS1115: external voltage with support for divided current\nTI INA219: current, voltage, and power draw\nYosemitech: water quality sensors\n\nY502-A or Y504-A: Optical DO and Temperature\nY510-B: Optical Turbidity and Temperature\nY511-A: Optical Turbidity and Temperature\nY514-A: Optical Chlorophyll and Temperature\nY520-A: Conductivity and Temperature\nY532-A: Digital pH and Temperature\nY533: ORP, pH, and Temperature\nY550-B: UV254\/COD, Turbidity, and Temperature\nY4000 Multiparameter Sonde\n\n\nZebra-Tech D-Opto: dissolved oxygen\n\nData Endpoints\nWithin ModularSensors, the \"dataPublisher\" objects add the functionality to send data to remote web services.\nThe currently supported services are the Monitor My Watershed data portal and ThingSpeak.\n\nMonitor My Watershed\/EnviroDIY Data Portal\nThingSpeak\n\nSupported Cellular\/Wifi Modules:\nFor information common to all modems and for tables of the proper class, baud rate, and pins to uses, see the Modem Notes page.\n\nDigi XBee\n\nDigi XBee\u00ae 3 Cellular LTE-M\/NB-IoT\nDigi XBee\u00ae 3 Cellular LTE Cat 1 (AT&T or Verizon)\nDigi XBee\u00ae Cellular 3G\nDigi XBee\u00ae Cellular LTE Cat 1 (Verizon)\nDigi XBee\u00ae Wi-Fi (S6B)\n\n\nESP8266\nQuectelBG96\nSequans Monarch\nSIM7000\nSIM800, including the Sodaq GPRSBee\nu-blox LTE-M R4 and N4 series, including the Sodaq uBee\nu-blox 2G, 3G, and 4G, including the Sodaq 3GBee\n\nContributing\nOpen an issue to suggest and discuss potential changes\/additions.\nFeel free to open issues about any bugs you find or any sensors you would like to have added.\nIf you would like to directly help with the coding development of the library, there are some tips here on how to set up PlatformIO so you can fork the library and test programs while in the library repo.\nPlease take time to familiarize yourself with the terminology, classes and data structures this library uses.\nThis library is built to fully take advantage of Objecting Oriented Programing (OOP) approaches and is larger and more complicated than many Arduino libraries.\nThere is extensive documentation on our github pages and an enormous number of comments and debugging printouts in the code itself to help you get going.\nLicense\nSoftware sketches and code are released under the BSD 3-Clause License -- See LICENSE.md file for details.\nDocumentation is licensed as Creative Commons Attribution-ShareAlike 4.0 (CC-BY-SA) copyright.\nHardware designs shared are released, unless otherwise indicated, under the CERN Open Hardware License 1.2 (CERN_OHL).\nAcknowledgments\nEnviroDIY\u2122 is presented by the Stroud Water Research Center, with contributions from a community of enthusiasts sharing do-it-yourself ideas for environmental science and monitoring.\nSara Damiano is the primary developer of the EnviroDIY ModularSensors library, with input from many other contributors.\nThis project has benefited from the support from the following funders:\n\nWilliam Penn Foundation\nUS Environmental Protection Agency (EPA)\nNational Science Foundation, awards EAR-0724971, EAR-1331856, ACI-1339834\nStroud Water Research Center endowment\n\n","153":"ViroCon: viroconcom\n\n\nViroCon is a software to compute environmental contours.\n\nAbout\nviroconcom is a software package to compute environmental contours. It\nis written in Python 3.7.4 and belongs to the software ViroCon, which also\noffers a GUI for some functionality via the package viroconweb.\nViroCon helps you to design marine structures, which need to withstand\nload combinations based on wave, wind and current. It lets you define\nextreme environmental conditions with a given return period using the\nenvironmental contour method.\nThe following methods are implemented in viroconcom:\n\nDefining a joint probability distributions using a global hierarchical model structure\nEstimating the parameters of a global hierarchical model (\"Fitting\")\nComputing an environmental contour using either the\ninverse first-order reliability method (IFORM),\ninverse second-order reliability method (ISORM),\nthe direct sampling contour method or the\nhighest density contour method.\n\n\n\n\nHow to use viroconcom\n\nRequirements\nMake sure you have installed Python 3.8 by typing\npython --version\nin your shell.\n(Older version might work, but are not actively tested)\nConsider using the python version management pyenv.\n\nInstall\nInstall the latest version of viroconcom from PyPI by typing\npip install viroconcom\nAlternatively, you can install from viroconcom repository\u2019s Master branch\nby typing\npip install https:\/\/github.com\/virocon-organization\/viroconcom\/archive\/master.zip\n\nUsage\nviroconcom is designed as an importable package.\nThe folder examples contains python files that show how one can\nimport and use viroconcom.\nAs an example, to run the file sea_state_iform_contour.py, use\nyour shell to navigate to the folder that contains the file. Make sure\nthat you have installed matplotlib and run the Python file by typing\npython sea_state_iform_contour.py\nOur documentation contains a user guide, with  examples how to\nfit a distribution to measurement data and how to\ncompute environmental contours.\n\nDocumentation\nCode. The code\u2019s documentation can be found here.\nPaper. Our SoftwareX paper \"ViroCon: A software to compute multivariate\nextremes using the environmental contour method.\" provides a concise\ndescription of the software.\n\nContributing\nIssue. If you spotted a bug, have an idea for an improvement or a\nnew feature, please open a issue. Please open an issue in both cases: If\nyou want to work on in yourself and if you want to leave it to us to\nwork on it.\nFork. If you want to work on an issue yourself please fork the\nrepository, then develop the feature in your copy of the repository and\nfinally file a pull request to merge it into our repository.\nConventions. In our Contribution Guide we summarize our\nconventions, which are consistent with PEP8.\n\nCite\nIf you are using viroconcom in your academic work please cite it by referencing\nour SoftwareX paper.\nExample: Environmental contours were computed using the package viroconcom\n(version 1.2.0) of the software ViroCon [1].\n[1] A.F. Haselsteiner, J. Lemkuhl, T. Pape, K.-L. Windmeier, K.-D. Thoben:\nViroCon: A software to compute multivariate extremes using the environmental\ncontour method. Accepted by SoftwareX.\n\nLicense\nThis software is licensed under the MIT license. For more information,\nread the file LICENSE.\n","154":"\u7cfb\u7edf\u7b80\u4ecb\uff1a\n\u8be5\u73af\u5883\u611f\u77e5\u7cfb\u7edf\u91c7\u7528RGB\u76f8\u673a\uff08480P\uff09\u4e0e\u79be\u8d5b20\u7ebf\u6fc0\u5149\u96f7\u8fbe\uff08\u8be5\u7248\u672c\u4e3a\u8ba2\u5236\u7248\u672c\uff09\u4e24\u79cd\u4f20\u611f\u5668\uff0cRGB\u76f8\u673a\u8bc6\u522b\u56fe\u50cf\u8f66\u724c\uff0c\u6fc0\u5149\u96f7\u8fbe\u6d4b\u91cf\u4e0e\u8f66\u724c\u7684\u8ddd\u79bb\uff0c\u5e76\u5c06\u4e24\u79cd\u4f20\u611f\u5668\u6536\u96c6\u5230\u7684\u4fe1\u606f\u8fdb\u884c\u878d\u5408\u3002\u8be5\u7cfb\u7edf\u5f00\u53d1\u73af\u5883\u662fUbuntu 16\u7cfb\u7edf\u4e2d\u5b89\u88c5\u7684ROS kinect\u7248\u672c\u3002\u672c\u7cfb\u7edf\u5206\u4e3a\u56fe\u50cf\u8bc6\u522b\u8282\u70b9\u3001\u6fc0\u5149\u96f7\u8fbe\u8282\u70b9\u548c\u878d\u5408\u8282\u70b9\u4e09\u90e8\u5206\uff0c\u6700\u540e\u7684\u4fe1\u606f\u901a\u8fc7\u878d\u5408\u8282\u70b9\u53d1\u5e03\u5728\/ganzhixinxi\u8bdd\u9898\u4e0a\uff0c\u611f\u77e5\u5f97\u5230\u7684\u4fe1\u606f\u4e3a\uff08t\uff0cx\uff0cy\uff09\u5176\u4e2dt\u4e3a\u8bc6\u522b\u5230\u7269\u4f53\u7684\u79cd\u7c7b\uff0cx\u4e3a\u8f66\u724c\u76f8\u5bf9\u6fc0\u5149\u96f7\u8fbe\u7684x\u5750\u6807\uff0cy\u4e3a\u8f66\u724c\u76f8\u5bf9\u6fc0\u5149\u96f7\u8fbe\u7684y\u5750\u6807\u3002\n\u5b9e\u73b0\u539f\u7406\uff08\u56fe\u50cf\u8bc6\u522bxml\u6587\u4ef6\u8bad\u7ec3\uff09\uff1a\n\u8282\u70b9\u91c7\u7528python\u8bed\u8a00\u7f16\u5199\uff0cpython\u9700\u8981\u5b89\u88c5OpenCV\u5e93\uff0c\u4ee5\u53ca\u8c03\u7528ROS\u7cfb\u7edf\u4e2d\u7684rospy\u5e93\uff0c\u5176\u4e2d\u56fe\u50cf\u8bc6\u522b\u5229\u7528OenCV\u56fe\u50cf\u7684Haar\u7b97\u6cd5\uff0c\u4e3a\u4e86\u4fdd\u8bc1\u8bc6\u522b\u7387\u5148\u5c06\u5f97\u5230\u56fe\u7247\u8fdb\u884c\u4e8c\u503c\u5316\u5904\u7406\uff0c\u8f66\u724c\u666e\u904d\u4e3a\u84dd\u8272\uff0c\u6240\u4ee5\u63d0\u53d6\u51fa\u56fe\u50cf\u4e2d\u84dd\u8272\u90e8\u5206\uff0c\u518d\u5bf9\u6293\u53d6\u56fe\u50cf\u4e2d\u8f66\u724c\u56fe\u7247\u8fdb\u884c\u6b63\u6837\u672c\u91c7\u96c6\u3002\u5b8c\u6210\u540e\u518d\u91c7\u96c6\u4e0d\u542b\u6709\u8f66\u724c\u7684\u4e8c\u503c\u5316\u56fe\u50cf\u4f5c\u4e3a\u8d1f\u6837\u672c\u3002\u6700\u540e\u5c06\u5f97\u5230\u6b63\u3001\u8d1f\u6837\u672c\u5229\u7528OpenCV\u8fdb\u884c\u8bad\u7ec3\uff0c\u6700\u540e\u5f97\u5230xml\u5206\u7c7b\u6587\u4ef6\u3002\n\u6b63\u8d1f\u6837\u672c\u5e93\u56fe\u7247\u5982\u4e0b\uff08\u8be5\u5e93\u5728\u5de5\u7a0b\u5e93\u4e2d\u7684sample\u6587\u4ef6\u5939\u5185\uff09\uff1a\n\n\u5b9e\u73b0\u539f\u7406\uff08\u56fe\u50cf\u8bc6\u522bxml\u8c03\u7528\uff09\uff1a\n\u8bad\u7ec3\u597dxml\u7684\u6587\u4ef6\u653e\u5230catkin_ws\u5de5\u7a0b\u6587\u4ef6\u5939\u4e0b\u4ee5\u4fbf\u56fe\u50cf\u8bc6\u522b\u8282\u70b9\u8c03\u7528\uff08\u82e5\u4e0d\u5728\u8be5\u6587\u4ef6\u5939\u4e0b\u53ef\u7528\u7edd\u5bf9\u5730\u5740\u8c03\u7528xml\u6587\u4ef6\uff09\uff0c\u8be5\u6587\u4ef6\u5939\u4e3aROS\u7cfb\u7edf\u7684\u5de5\u4f5c\u7a7a\u95f4\uff0cROS\u76f8\u5173\u5de5\u4f5c\u6587\u4ef6\u5982node\u3001msg\u90fd\u5728\u8be5\u6587\u4ef6\u4e0b\uff0c\u9700\u8981\u7528\u5728Ubuntu\u547d\u4ee4\u6846\u5185\u8fd0\u884c\uff04 roscore\u6307\u4ee4\u4e4b\u540e\u518d\u542f\u52a8ROS\u8282\u70b9\u3002\u5177\u4f53ROS\u6559\u7a0b\u8bf7\u53c2\u8003http:\/\/wiki.ros.org\/cn \u3002\n\u5b9e\u73b0\u539f\u7406\uff08\u4fe1\u606f\u878d\u5408\uff09\uff1a\n\u672c\u7cfb\u7edf\u4fe1\u606f\u878d\u5408\u5229\u7528\u7684\u662ftan\u03b1\u503c\u8fdb\u884c\u4fe1\u606f\u878d\u5408\uff0cRGB\u76f8\u673a\u4e0e\u6fc0\u5149\u96f7\u8fbe\u4f4d\u7f6e\u56fe\u5982\u4e0b\uff0cRGB\u76f8\u673a\u7684\u53ef\u89c6\u89d2\u5ea6\u7ea6\u4e3a70\u00b0\uff0c\u6240\u4ee5\u5148\u5c06\u6fc0\u5149\u96f7\u8fbe\u6240\u91c7\u96c6\u7684y<0\u7684\u70b9\u4e91\u6ee4\u6389\uff0c\u5269\u4e0b\u7684tan\u503c\u4e0e\u89d2\u5ea6\u552f\u4e00\u5bf9\u5e94\u3002\u5bf9\u5e94\u540e\u6839\u636e\u522b\u8bc6\u522b\u7269\u4f53\u7684\u9ad8\u5ea6\u5339\u914d\u8f83\u4e3a\u5408\u7406\u70b9\u4e91\u70b9z\u503c\uff0c\u518d\u5c06\u8be5\u70b9\u5bf9\u5e94\u7684\uff08x,y\uff09\u503c\u4e0e\u7269\u4f53\u79cd\u7c7bt\u91cd\u65b0\u7ec4\u5408\u4e3a\u65b0\u7684\u4fe1\u606f\uff08t\uff0cx\uff0cy\uff09\n\nROS\u8282\u70b9\u53ca\u8bdd\u9898\u6d4b\u8bd5\u56fe\u5982\u4e0b\uff1a\n\n\u7cfb\u7edf\u8fd0\u884c\u6548\u679c\u56fe\u5982\u4e0b\uff0c\u5176\u4e2d\u7b2c\u4e00\u5217\u4e3a\u8bc6\u522b\u5230\u7684\u7269\u4f53\u79cd\u7c7b\uff081\u4e3a\u8f66\u724c\uff09\uff0c\u7b2c\u4e8c\u5217\u662f\u8f66\u724c\u76f8\u5bf9\u6fc0\u5149\u96f7\u8fbe\u7684x\u5750\u6807\uff0c\u7b2c\u4e09\u5217\u662f\u8f66\u724c\u76f8\u5bf9\u6fc0\u5149\u96f7\u8fbe\u7684y\u5750\u6807\uff1a\n\n\u672c\u7cfb\u7edf\u540e\u671f\u6269\u5c55\uff1a\n\uff081\uff09\u5728ROS\u7cfb\u7edf\u7248\u672c\u7531Python2.7\u6539\u62103.7\u540e\uff0c\u53ef\u4ee5\u6539\u7528\u8c37\u6b4c\u7684tensorflow object_detection API\u8fdb\u884c\u7269\u4f53\u8bc6\u522b\u3002\n\uff082\uff09\u5339\u914d\u7b97\u6cd5\u4f7f\u7528\u7684\u8f83\u4e3a\u7b80\u5355\uff0c\u540e\u671f\u53ef\u4ee5\u91c7\u7528\u77e9\u9635\u8fd0\u7b97\u8fdb\u884c\u4fe1\u606f\u878d\u5408\u3002\n","155":"\u7cfb\u7edf\u7b80\u4ecb\uff1a\n\u8be5\u73af\u5883\u611f\u77e5\u7cfb\u7edf\u91c7\u7528RGB\u76f8\u673a\uff08480P\uff09\u4e0e\u79be\u8d5b20\u7ebf\u6fc0\u5149\u96f7\u8fbe\uff08\u8be5\u7248\u672c\u4e3a\u8ba2\u5236\u7248\u672c\uff09\u4e24\u79cd\u4f20\u611f\u5668\uff0cRGB\u76f8\u673a\u8bc6\u522b\u56fe\u50cf\u8f66\u724c\uff0c\u6fc0\u5149\u96f7\u8fbe\u6d4b\u91cf\u4e0e\u8f66\u724c\u7684\u8ddd\u79bb\uff0c\u5e76\u5c06\u4e24\u79cd\u4f20\u611f\u5668\u6536\u96c6\u5230\u7684\u4fe1\u606f\u8fdb\u884c\u878d\u5408\u3002\u8be5\u7cfb\u7edf\u5f00\u53d1\u73af\u5883\u662fUbuntu 16\u7cfb\u7edf\u4e2d\u5b89\u88c5\u7684ROS kinect\u7248\u672c\u3002\u672c\u7cfb\u7edf\u5206\u4e3a\u56fe\u50cf\u8bc6\u522b\u8282\u70b9\u3001\u6fc0\u5149\u96f7\u8fbe\u8282\u70b9\u548c\u878d\u5408\u8282\u70b9\u4e09\u90e8\u5206\uff0c\u6700\u540e\u7684\u4fe1\u606f\u901a\u8fc7\u878d\u5408\u8282\u70b9\u53d1\u5e03\u5728\/ganzhixinxi\u8bdd\u9898\u4e0a\uff0c\u611f\u77e5\u5f97\u5230\u7684\u4fe1\u606f\u4e3a\uff08t\uff0cx\uff0cy\uff09\u5176\u4e2dt\u4e3a\u8bc6\u522b\u5230\u7269\u4f53\u7684\u79cd\u7c7b\uff0cx\u4e3a\u8f66\u724c\u76f8\u5bf9\u6fc0\u5149\u96f7\u8fbe\u7684x\u5750\u6807\uff0cy\u4e3a\u8f66\u724c\u76f8\u5bf9\u6fc0\u5149\u96f7\u8fbe\u7684y\u5750\u6807\u3002\n\u5b9e\u73b0\u539f\u7406\uff08\u56fe\u50cf\u8bc6\u522bxml\u6587\u4ef6\u8bad\u7ec3\uff09\uff1a\n\u8282\u70b9\u91c7\u7528python\u8bed\u8a00\u7f16\u5199\uff0cpython\u9700\u8981\u5b89\u88c5OpenCV\u5e93\uff0c\u4ee5\u53ca\u8c03\u7528ROS\u7cfb\u7edf\u4e2d\u7684rospy\u5e93\uff0c\u5176\u4e2d\u56fe\u50cf\u8bc6\u522b\u5229\u7528OenCV\u56fe\u50cf\u7684Haar\u7b97\u6cd5\uff0c\u4e3a\u4e86\u4fdd\u8bc1\u8bc6\u522b\u7387\u5148\u5c06\u5f97\u5230\u56fe\u7247\u8fdb\u884c\u4e8c\u503c\u5316\u5904\u7406\uff0c\u8f66\u724c\u666e\u904d\u4e3a\u84dd\u8272\uff0c\u6240\u4ee5\u63d0\u53d6\u51fa\u56fe\u50cf\u4e2d\u84dd\u8272\u90e8\u5206\uff0c\u518d\u5bf9\u6293\u53d6\u56fe\u50cf\u4e2d\u8f66\u724c\u56fe\u7247\u8fdb\u884c\u6b63\u6837\u672c\u91c7\u96c6\u3002\u5b8c\u6210\u540e\u518d\u91c7\u96c6\u4e0d\u542b\u6709\u8f66\u724c\u7684\u4e8c\u503c\u5316\u56fe\u50cf\u4f5c\u4e3a\u8d1f\u6837\u672c\u3002\u6700\u540e\u5c06\u5f97\u5230\u6b63\u3001\u8d1f\u6837\u672c\u5229\u7528OpenCV\u8fdb\u884c\u8bad\u7ec3\uff0c\u6700\u540e\u5f97\u5230xml\u5206\u7c7b\u6587\u4ef6\u3002\n\u6b63\u8d1f\u6837\u672c\u5e93\u56fe\u7247\u5982\u4e0b\uff08\u8be5\u5e93\u5728\u5de5\u7a0b\u5e93\u4e2d\u7684sample\u6587\u4ef6\u5939\u5185\uff09\uff1a\n\n\u5b9e\u73b0\u539f\u7406\uff08\u56fe\u50cf\u8bc6\u522bxml\u8c03\u7528\uff09\uff1a\n\u8bad\u7ec3\u597dxml\u7684\u6587\u4ef6\u653e\u5230catkin_ws\u5de5\u7a0b\u6587\u4ef6\u5939\u4e0b\u4ee5\u4fbf\u56fe\u50cf\u8bc6\u522b\u8282\u70b9\u8c03\u7528\uff08\u82e5\u4e0d\u5728\u8be5\u6587\u4ef6\u5939\u4e0b\u53ef\u7528\u7edd\u5bf9\u5730\u5740\u8c03\u7528xml\u6587\u4ef6\uff09\uff0c\u8be5\u6587\u4ef6\u5939\u4e3aROS\u7cfb\u7edf\u7684\u5de5\u4f5c\u7a7a\u95f4\uff0cROS\u76f8\u5173\u5de5\u4f5c\u6587\u4ef6\u5982node\u3001msg\u90fd\u5728\u8be5\u6587\u4ef6\u4e0b\uff0c\u9700\u8981\u7528\u5728Ubuntu\u547d\u4ee4\u6846\u5185\u8fd0\u884c\uff04 roscore\u6307\u4ee4\u4e4b\u540e\u518d\u542f\u52a8ROS\u8282\u70b9\u3002\u5177\u4f53ROS\u6559\u7a0b\u8bf7\u53c2\u8003http:\/\/wiki.ros.org\/cn \u3002\n\u5b9e\u73b0\u539f\u7406\uff08\u4fe1\u606f\u878d\u5408\uff09\uff1a\n\u672c\u7cfb\u7edf\u4fe1\u606f\u878d\u5408\u5229\u7528\u7684\u662ftan\u03b1\u503c\u8fdb\u884c\u4fe1\u606f\u878d\u5408\uff0cRGB\u76f8\u673a\u4e0e\u6fc0\u5149\u96f7\u8fbe\u4f4d\u7f6e\u56fe\u5982\u4e0b\uff0cRGB\u76f8\u673a\u7684\u53ef\u89c6\u89d2\u5ea6\u7ea6\u4e3a70\u00b0\uff0c\u6240\u4ee5\u5148\u5c06\u6fc0\u5149\u96f7\u8fbe\u6240\u91c7\u96c6\u7684y<0\u7684\u70b9\u4e91\u6ee4\u6389\uff0c\u5269\u4e0b\u7684tan\u503c\u4e0e\u89d2\u5ea6\u552f\u4e00\u5bf9\u5e94\u3002\u5bf9\u5e94\u540e\u6839\u636e\u522b\u8bc6\u522b\u7269\u4f53\u7684\u9ad8\u5ea6\u5339\u914d\u8f83\u4e3a\u5408\u7406\u70b9\u4e91\u70b9z\u503c\uff0c\u518d\u5c06\u8be5\u70b9\u5bf9\u5e94\u7684\uff08x,y\uff09\u503c\u4e0e\u7269\u4f53\u79cd\u7c7bt\u91cd\u65b0\u7ec4\u5408\u4e3a\u65b0\u7684\u4fe1\u606f\uff08t\uff0cx\uff0cy\uff09\n\nROS\u8282\u70b9\u53ca\u8bdd\u9898\u6d4b\u8bd5\u56fe\u5982\u4e0b\uff1a\n\n\u7cfb\u7edf\u8fd0\u884c\u6548\u679c\u56fe\u5982\u4e0b\uff0c\u5176\u4e2d\u7b2c\u4e00\u5217\u4e3a\u8bc6\u522b\u5230\u7684\u7269\u4f53\u79cd\u7c7b\uff081\u4e3a\u8f66\u724c\uff09\uff0c\u7b2c\u4e8c\u5217\u662f\u8f66\u724c\u76f8\u5bf9\u6fc0\u5149\u96f7\u8fbe\u7684x\u5750\u6807\uff0c\u7b2c\u4e09\u5217\u662f\u8f66\u724c\u76f8\u5bf9\u6fc0\u5149\u96f7\u8fbe\u7684y\u5750\u6807\uff1a\n\n\u672c\u7cfb\u7edf\u540e\u671f\u6269\u5c55\uff1a\n\uff081\uff09\u5728ROS\u7cfb\u7edf\u7248\u672c\u7531Python2.7\u6539\u62103.7\u540e\uff0c\u53ef\u4ee5\u6539\u7528\u8c37\u6b4c\u7684tensorflow object_detection API\u8fdb\u884c\u7269\u4f53\u8bc6\u522b\u3002\n\uff082\uff09\u5339\u914d\u7b97\u6cd5\u4f7f\u7528\u7684\u8f83\u4e3a\u7b80\u5355\uff0c\u540e\u671f\u53ef\u4ee5\u91c7\u7528\u77e9\u9635\u8fd0\u7b97\u8fdb\u884c\u4fe1\u606f\u878d\u5408\u3002\n","156":"Community Water Model (CWatM)\nIIASA\n13rd October 2020\nCWatM represents one of the new key elements of IIASA\u00e2\u20ac\u2122s Water program to assess water supply, water demand and environmental needs at global and regional level. The hydrologic model is open source and flexible to link in different aspects of the water energy food nexus. CWATM will be a basis to develop a next-generation global hydro-economic modeling and will be coupled to the existing IIASA models like MESSAGE and GLOBIOM\nhttp:\/\/www.iiasa.ac.at\/cwatm\n\n\n\nModel design and processes included\nThe Community Water Model (CWatM) will be designed for the purpose to assess water availability, water demand and environmental needs. It includes an accounting of how future water demands will evolve in response to socioeconomic change and how water availability will change in response to climate.\n\n\n\nFigure 1: Schematic view of CWatM processes\nModules for hydrological processes e.g. snow, soil, groundwater etc. are located in the folder hydrological_modules.\nThe kinematic routing and the C++ routines (for speeding up the computational time) are in the folder hydrological_modules\/routing_reservoirs.\n\n\n\nFigure 2: Schematic graph of CWatM modules\nNext-generation global hydro-economic modeling framework\nThe Community Water Model will help to develop a next-generation hydro-economic modeling tool that represents the economic trade-offs among water supply technologies and demands.  The tool will track water use from all sectors and will identify the least-cost solutions for meeting future water demands under policy constraints.  In addition, the tool will track the energy requirements associated with the water supply system (e.g., desalination and water conveyance) to facilitate the linkage with the energy-economic tool. The tool will also incorporate environmental flow requirements to ensure sufficient water for environmental needs.\nThe Nexus framework of IIASA\nIn the nexus framework \u00e2\u20ac\u201c water, energy, food, ecosystem - CWatM will be coupled to the existing IIASA models including the Integrated Assessment Model MESSAGE and the global land and ecosystem model GLOBIOM in order to realize an improved assessments of water-energy-food-ecosystem nexus and associated feedback.\n\n\n\nFigure 3: IIASA model nexus\nShort to medium vision\nOur vision for the short to medium term work is to introduce water quality (e.g., salinization in deltas and eutrophication associated with mega cities) into CWatM and to consider qualitative and quantitative measures of transboundary river and groundwater governance into an integrated modelling framework.\nLink to full model documentation\nhttps:\/\/cwatm.iiasa.ac.at\/\n","157":"heroku-selectable-procfile\nUsage\nAdd this buildpack to your Heroku app buildpacks :\n$ heroku buildpacks:add https:\/\/github.com\/cantino\/heroku-selectable-procfile\n\nSpecify your custom Procfile path in the environment variables :\n$ heroku config:add PROCFILE_PATH=Procfile.custom\n\n","158":"\n\n\n\nade4\nAnalysis of Ecological Data : Exploratory and Euclidean Methods in Environmental Sciences\nInstalling ade4\nTo install the development version from github:\n\n\nInstall the release version of devtools from CRAN with install.packages(\"devtools\").\n\n\nMake sure you have a working development environment.\n\nWindows: Install Rtools.\nMac: Install Xcode from the Mac App Store.\nLinux: Install a compiler and various development libraries (details vary across different flavors of Linux).\n\n\n\nThen:\nlibrary(devtools)\ninstall_github(\"sdray\/ade4\")\nThe stable version can be installed from CRAN using:\ninstall.packages(\"ade4\")\nOnce installed, the package can be loaded using:\nlibrary(\"ade4\")\nIf you do not wish to install the development environments Rtools (Windows) \/ XCode (Mac), you can get the binary packages here:\n\n\nWindows\n\n\nmacOS\n\n\n","159":"MetaPathways: A modular pipeline for constructing Pathway\/Genome Databases from environmental sequence information\n\nUpdate: MetaPathways v2.0 is available from its GitHub repository.\nInstallation instructions and tutorials can be found on the wiki\n\nAbstract\nBackground: A central challenge to understanding the ecological and biogeochemical roles of microorganisms in natural and human engineered ecosystems is the reconstruction of metabolic interaction networks from environmental sequence information. The dominant paradigm in metabolic reconstruction is to assign functional annotations using BLAST. Functional annotations are then projected onto symbolic representations of metabolism in the form of KEGG pathways or SEED subsystems.\nResults: Here we present MetaPathways, an open source pipeline for pathway inference that uses the PathoLogic algorithm to construct environmental Pathway\/Genome Databases (ePGDBs) compatible with the editing and navigation features of Pathway Tools. The pipeline accepts assembled or unassembled nucleotide sequences, performs quality assessment and control, predicts and annotates noncoding genes and open reading frames, and produces inputs to PathoLogic. In addition to constructing ePGDBs, MetaPathways uses MLTreeMap to build phylogenetic trees for selected taxonomic anchor and functional gene markers, converts General Feature Format (GFF) files into concatenated GenBank files for ePGDB construction based on third-party annotations and generates useful file formats including Sequin files for direct GenBank submission and gene feature tables summarizing annotations, MLTreeMaps and ePGDB pathway coverage summaries for statistical comparisons.\nConclusions: Metapathways provides users with a modular annotation and analysis pipeline for predicting metabolic interaction networks from environmental sequence information using an alternative to KEGG pathways and SEED subsystems mapping. It is extensible to genomic and transcriptomic datasets from a wide range of sequencing platforms, and generates useful data products for microbial community structure and function analysis. The MetaPathways software package, installation instructions, and example data can be obtained from http:\/\/hallam.microbiology.ubc.ca\/MetaPathways\nKeywords: Environmental Pathway\/Genome Database (ePGDB), metagenome, Pathway Tools, PathoLogic, MetaCyc, microbial community, metabolism, metabolic interaction networks\nPlease cite: Konwar, Kishori M., et al. \"MetaPathways: a modular pipeline for constructing pathway\/genome databases from environmental sequence information.\" BMC bioinformatics 14.1 (2013): 202.\n","160":"Environmental-sound-recognition-using-combination-of-spectrogram-and-acoustic-features\nClassification of environmental sounds using first order statistics and GLCM (Gray-Level Co-Occurrence Matrix ) features of a spectrogram\nPlease refer to the paper below for more information of the algorithm and results\nhttps:\/\/ijret.org\/volumes\/2017v06\/i10\/IJRET20170610015.pdf\nRequirements\nPython 2.7.10\nPython Modules\n\nLibrosa 0.4.3\nnumpy 1.11.3\nsklearn 0.18\nmatplotlib 1.4.3\nSimpleITK 1.0.0\npyradiomics 1.3.0\n\nSteps\nPreprocessing\n\n\n\nFigure 1\n\n\nResampling the audio audio to 24,000 Hz and applying a high pass filter with a cut off frequency of 500Hz to remove the low frequency noise in the audio signals.\nCompute the decibel scaled spectrogram image of the audio. Calculate the spectrogram with an FFT size of 512 which gives a frequency resolution of 46.875 Hz corresponding to the sampling rate of 24,000Hz.\nFor the hanning window,  a window length of 20ms with 75% overlap is used.\nRescale the spectrogram to a maximum value of 255. Figure-1(a) shows a spectrogram of a dog bark rescaled to amplitude in the range [0,255]\nOn the rescaled image, use k-means with ten cluster centers to vector quantize the image to ten levels.\nPerform binary thresholding with the threshold being the second highest value among the cluster centers. Figure-1(b) shows spectrogram image quantized to ten levels.\nCreate a binary mask and retain the part of the image which correspond to two cluster centers with the highest pixel values. Figure-1(c) shows the connected components extracted from the binary mask obtained after thresholding.\nBy considering the left most and right most location of each of the connected component, extract corresponding segments in the time domain. Figure1(d) shows the obtained segments in the time domain\nExtract the prominent part of the signal.  Figure1(e) shows  the extracted prominent part of the signal.\n\nFeature Extraction\nFirst Set of Features\n\nDivide the obtained spectrogram of the image and divide into four equal frequency bands (sub bands).\nCompute first order statistics and glcm features for each of the sub bands.\n\nFirst order statistics\nMinimum,mean, median, variance, energy, entropy, tenth percentile pixel value, ninetieth percentile pixel value, inter quartile range, mean absolute deviation, robust mean absolute deviation, root mean square error, skewness and kurtosis.\nGLCM features (Combination of angles (0,45,90,135), displacement vectors (3,5))\nEnergy, contrast, correlation, sum of squares, inverse of difference moment, sum average, sum entropy, sum variance, entropy, difference variance, difference entropy, and two descriptors of information measure of correlation.\nSecond Set of Features\nExtracted with window length of 20ms and 75% overlap between frames\nMFCCs (Mel Frequency Cepstral Coefficients), Delta MFCCs, ZCR (Zero Crossing Rate), RMSE (Root Mean Square Error), spectral centroid, spectral bandwidth, spectral contrast and spectral rolloff\nClassification\n\n\n\nFigure 2\n\nFour different models\n\nSIF (Spectrogram Image Features) Model\n\nTrained Separately on First Set of Features\n\n\nAF  (Acoustic Features) Model\n\nTrained Separately on Second Set of Features\n\n\nASIF  (Acoustic and Spectrogram Image Features) Model\n\nTrained with both  First Set of Features and Second Set of Features combined in the feature space.\n\n\nMEASIF (Modified Ensemble of Acoustic and Spectrogram Image Features) Model\n\nModified Ensemble of SIF and AF models. Figure-3 shows the architecture of MEASIF Model\n\n\n\nResults\nTo Evaluate the approach, ESC-10 dataset available at https:\/\/github.com\/karoldvl\/ESC-10 was used.\nESC-50 is a dataset with annotated collection of 2,000 short clips comprising 50 classes of various common sound events. Each class consists of 40 sound clips with each sound clip 5-seconds-long reconverted into a unified format (44.1 kHz, single channel, Ogg Vorbis compression at 192 kbit\/s). The labeled datasets were consequently arranged into 5 uniformly sized cross-validation folds.\nThe ESC-10 is a selection of 10 classes from the bigger dataset ESC-50.\nThe Frieburg-106 dataset was collected using a consumer level dynamic cardioid microphone. It contains 1,479 audio based human activities of 22 categories.\nAll the models are trained on SVM classifier with \u201crbf\u201d kernel and the cost parameter \u201cC\u201d set to 1e4.\n\n\n","161":"WordPress Boilerplate for Professional Development\n\nHeadless WordPress Boilerplate to start a new project in WordPress in just 2 minutes, with MVC API generation like any other modern framework like Express, Flask or Slim PHP.\n\nFeatures\n\nDockerfile for a working LAMP environment with PHP 7.2.19 and PHPMyAdmin.\nWordPress CLI (WP CLI).\nSupport for .env file to easily publish into production with environment variables.\nOne commend install with install.sh bash script.\nIt comes with a WordPress Plugin ideal for using headless WordPress API working with typical MVC (Model View Controller) pattern.\nComposer integration to install plugins or PHP packages via package manager.\n\nIf used with Gitpod\n\nEasy access to apache and PHP error log with commcommand: gp open \/var\/log\/apache2\/error.log\n\nInstallation Procedure\n1) Start by installing the boilerplate\nThere are 3 ways of installing this:\n\nUse git to clone re repo\n\n$ git clone git@github.com:4GeeksAcademy\/wordpress-hello.git\n\nJust click here to use it with gitpod.\n\n2) Install the composer packages\n$ composer install\n3) Create a .env file with your database and site information (on the workspace root) and run the run the installator\n$ bash install.sh\nYou are done! Start working!\nCheck your website, you are going to see a \"Hello Rigoberto\" message, you can login into the dashboard with your c9 username and the password you specified.\n- Adding API enpoints\nThis boilerplate comes with a sample API andpoint already, all api enpoints can be added into the setup_api.php file like this:\n\/\/ adding a GET \/courses endpoint handled by the function getDraftCourses in the SampleController.php file\n$api->get([ 'path' => '\/courses', 'controller' => 'SampleController:getDraftCourses' ]);\nHere is more info on how to create the API endpoints.\n- Adding Entities (Post Types)\nAll the Post Types configuration is done in the setup_types.php file like this:\n\/\/ adding Post Type \"Course\" handled by the file Course.php\n$typeManager->newType(['type' => 'course', 'class' => 'Course'])->register();\nHere is more info on how to create the post-types.\n","162":"Environmental-Sound-Classification\nEnvironmental-Sound-Classification using ESC-10 dataset\nDependencies\n\nPython\nKeras\nLibrosa\nsounddevice\nSoundFile\nscikit-learn\n\nDataset\nUses ESC-10 dataset for sound classification.\nIt is a labeled set of 400 environmental recordings (10 classes, 40 clips per class, 5 seconds per clip).\nIt is a subset of the larger ESC-50 dataset.\nSetup\nIn this repository, I trained Convolution Neural Network, Multi Layer Perceptron and SVM for sound classification.\nI achieved classification accuracy of approx ~80%.\nMFCC (mel-frequency cepstrum) feature is used to train models. Other features like short term fourier transform, chroma, melspectrogram can also be extracted.\nThe dataset is downloaded and is kept inside \"dataset\" folder. It has 10 different classes each containing 10 .ogg files.\nYou can visualize the dataset by running visualize_data.py.\nThis script takes a .ogg file as input and converts it into .wav form.\nThe waveform is visualized in the form of a plot.\npython visualize_data.py -o \"dataset\/001 - Dog bark\/1-30226-A.ogg\"\nA sample wav file for each class has been generated and kept within sample_wav folder for reference.\nTo train and classify, execute main.py as -\npython main.py cnn  \/\/ for training CNN\npython main.py mlp  \/\/ for training MLP\npython main.py svm  \/\/ for training SVM\n\nInternally main.py uses extract_features.py and nn.py (or svm.py) to create and train model.\nOnce training is done, the trained models are automatically saved in h5 format.\nWave plot for class - baby\n\nWave plot for class - dog\n\n","163":"BME280\nArduino library for communicating with the BME280 environmental sensor.\nLicense\nThis library is licensed under the GPLV3. Please contact us at support@bolderflight.com to obtain other licenses.\nDescription\nThe Bosch Sensortec BME280 is an integrated environmental sensor, which combines high linearity, high accuracy sensors for pressure, temperature, and humidity in a compact LGA package. The humidity sensor features an extremely fast response time and high accuracy over a wide temperature range. The pressure sensor is an absolute barometric pressure sensor with features exceptionally high accuracy and resolution at very low noise. The integrated temperature sensor has been optimized for very low noise and high resolution. Pressure, temperature, and humidity measurements can be useful for applications involving unmanned vehicles (indicated and true airspeed, altitude, and density altitude), indoor navigation (floor detection), outdoor navigation (altitudes and airspeeds, dead-reckoning, GPS time to first fix improvements) as well as weather monitoring and home automation.\nThe BME280 samples pressure and temperature to 20 bit resolution and humidity to 16 bit resolution. The BME280 features programmable oversampling, IIR filtering, and standby time between samples. The BME280 supports both I2C and SPI communication.\nUsage\nThis library supports both I2C and SPI commmunication with the BME280.\nInstallation\nSimply clone or download this library into your Arduino\/libraries folder.\nFunction Description\nThis library supports both I2C and SPI communication with the BME280. The BME280 object declaration is overloaded with different declarations for I2C and SPI communication. All other functions remain the same.\nI2C Object Declaration\nBME280(TwoWire &bus,uint8_t address)\nA BME280 object should be declared, specifying the I2C bus and the BME280 I2C address. The BME280 I2C address will be 0x76 if the SDO pin is grounded or 0x77 if the SDO pin is pulled high. For example, the following code declares a BME280 object called bme with a BME280 sensor located on I2C bus 0 with a sensor address of 0x76 (SDO grounded).\nBME280 bme(Wire,0x76);\nSPI Object Declaratioon\nBME280(SPIClass &bus,uint8_t csPin)\nA BME280 object should be declared, specifying the SPI bus and the chip select pin used. Multiple BME280 or other SPI objects could be used on the same SPI bus, each with their own chip select pin. The chip select pin can be any available digital pin. For example, the following code declares a BME280 object called bme with a BME280 sensor located on SPI bus 0 with chip select pin 10.\nBME280 bme(SPI,10);\nCommon Setup Functions\nThe following functions are used to setup the BME280 sensor. These should be called once before data collection, typically this is done in the Arduino void setup() function. The begin function should always be used. Optionally, the setPressureOversampling, setTemperatureOversampling, setHumidityOversampling, setIirCoefficient and setStandbyTime functions can be used, following begin, to setup the oversampling, IIR filtering, and standby times. The optional setForcedMode and setNormalMode functions can be used to change the sensor to forced or normal mode. If these optional functions are not used, oversampling, IIR filtering, and standby times are set to default values and normal mode is used, which should be good for a wide range of applications, and are discussed in greater detail below.\nint begin()\nThis should be called in your setup function. It initializes communication with the BME280 and sets up the sensor for reading data. This function returns a positive value on a successful initialization and returns a negative value on an unsuccesful initialization. If unsuccessful, please check your wiring or try resetting power to the sensor. The following is an example of setting up the BME280.\nint status;\nstatus = bme.begin();\nThe BME280 features programmable oversampling, IIR filtering, and standby time between samples. By default, these are set to the following values:\n\n\n\nSettings\n\n\n\n\n\nOversampling\npressure x 16, temperature x 2, humidity x 1\n\n\nIIR Coefficient\n16\n\n\nStandby Time\n0.5 ms\n\n\n\n\n\n\nPerformance\n\n\n\n\n\nData Output Rate\n25 Hz\n\n\nFilter Bandwidth\n0.53 Hz\n\n\nResponse Time\n0.88 s\n\n\n\nOptionally, the setPressureOversampling, setTemperatureOversampling, setHumidityOversampling, setIirCoefficient and setStandbyTime functions can be used, following begin, to change these settings from their default values. For much more information on the settings and performance implications, please refer to the BME280 datasheet.\n(optional) int setPressureOversampling(Sampling pressureSampling)\nThis is an optional function to set the pressure oversampling to values other than the default. The following enumerated oversampling settings are supported:\n\n\n\nOversampling Name\nOversampling Value\n\n\n\n\nSAMPLING_X1\n1\n\n\nSAMPLING_X2\n2\n\n\nSAMPLING_X4\n4\n\n\nSAMPLING_X8\n8\n\n\nSAMPLING_X16\n16\n\n\n\nBelow is an example of selecting an oversampling value of 4 for pressure. This function returns a positive value on success and a negative value on failure.\nint status;\nstatus = bme.setPressureOversampling(BME280::SAMPLING_X4);\n(optional) int setTemperatureOversampling(Sampling temperatureSampling)\nThis is an optional function to set the temperature oversampling to values other than the default. Below is an example of selecting an oversampling value of 2 for temperature. This function returns a positive value on success and a negative value on failure.\nint status;\nstatus = bme.setTemperatureOversampling(BME280::SAMPLING_X2);\n(optional) int setHumidityOversampling(Sampling humiditySampling)\nThis is an optional function to set the humidity oversampling to values other than the default. Below is an example of selecting an oversampling value of 2 for humidity. This function returns a positive value on success and a negative value on failure.\nint status;\nstatus = bme.setHumidityOversampling(BME280::SAMPLING_X2);\n(optional) int setIirCoefficient(Iirc iirCoefficient)\nThis is an optional function to set the IIR filter coefficient to a value other than the default. This filter is applied to all measurements. The filter is given by the following equation:\ndata_filtered = (data_filtered_old * (filter_coefficient - 1) + data) \/ filter_coefficient\nThe following enumerated filter coefficients are supported:\n\n\n\nIIR Filter Coefficient Name\nIIR Filter Coefficient Value\nSamples to reach 75% of step response\n\n\n\n\nIIRC_OFF\n1\n1\n\n\nIIRC_X2\n2\n2\n\n\nIIRC_X4\n4\n5\n\n\nIIRC_X8\n8\n11\n\n\nIIRC_X16\n16\n22\n\n\n\nBelow is an example of selecting an IIR filter coefficient of 4. This function returns a positive value on success and a negative value on failure.\nint status;\nstatus = bme.setIirCoefficient(BME280::IIRC_X4);\n(optional) int setStandbyTime(Standby standbyTime)\nThis is an optional function to set the standby time to a value other than the default. This standby time is applied to all measurements. It is used in normal mode to set the time spent idle between taking measurements.\nThe following enumerated standby times are supported:\n\n\n\nStandby Time Name\nStandby Time\n\n\n\n\nSTANDBY_0_5_MS\n0.5 ms\n\n\nSTANDBY_10_MS\n10 ms\n\n\nSTANDBY_20_MS\n20 ms\n\n\nSTANDBY_62_5_MS\n62.5 ms\n\n\nSTANDBY_125_MS\n125 ms\n\n\nSTANDBY_250_MS\n250 ms\n\n\nSTANDBY_500_MS\n500 ms\n\n\nSTANDBY_1000_MS\n1000 ms\n\n\n\nBelow is an example of selecting a standby time of 10 ms. This function returns a positive value on success and a negative value on failure.\nint status;\nstatus = bme.setStandbyTime(BME280::STANDBY_10_MS);\n(optional) int setForcedMode()\nThis is an optional function to set the operational mode of the sensor to forced mode. The BME280 has two modes of operation, normal and forced. In normal mode, the sensor takes regular measurements at intervals set by the standby time. When the readSensor function is called, detailed below, it simply gets the most recent data values from the sensor. In forced mode, when the readSensor function called, the sensor is commanded to collect data, the microcontroller waits for the data to become available, and then gets the data from the sensor. Forced mode is useful for taking measurements at a very low rate (i.e. taking pressure measurements once per minute for a weather station) and for taking measurements that need to be tightly synchronized with the microcontroller. It is recommended not to use the IIR filtering built in to the BME280 in forced mode. The advantage of normal mode is that it reduces the microcontroller workload.\nNormal mode is set by default. This function switches the BME280 into forced mode. The data collection process remains the same; however, the time necessary for readSensor is significantly greater in forced mode than normal mode. Below is an example of selecting forced mode. This function returns a positive value on success and a negative value on failure.\nint status;\nstatus = bme.setForcedMode();\n(optional) int setNormalMode()\nThis is an optional function to set the operational mode of the sensor to normal mode. Please see the discussion above, in setForcedMode, describing the operational modes of the sensor. Normal mode is set by default. This function would be used after the BME280 is switched to forced mode to set the sensor back to normal mode. Below is an example of selecting normal mode. This function returns a positive value on success and a negative value on failure.\nint status;\nstatus = bme.setNormalMode();\nCommon Data Collection Functions\nThe functions below are used to collect data from the BME280 sensor. Data is returned scaled to engineering units. Pressure data is returned in units of Pascal (Pa), temperature data in units of degrees Celsius (C), and humidity in units of percent relative humidity (%RH). readSensor is used to read the sensor and store the newest data in a buffer, it should be called every time you would like to retrieve data from the sensor. getPressure_Pa, getTemperature_C, and getHumidity_RH return the pressure, temperature, and humidity values from that buffer.\nint readSensor() reads the sensor and stores the newest data in a buffer, it should be called every time you would like to retrieve data from the sensor. This function returns a positive value on success and a negative value on failure.\nbme.readSensor();\nfloat getPressure_Pa() gets the pressure value from the data buffer and returns it in units of Pascal.\nfloat pressure;\npressure = bme.getPressure_Pa();\nfloat getTemperature_C() gets the temperature value from the data buffer and returns it in units of degrees Celsius.\nfloat temperature;\ntemperature = bme.getTemperature_C();\nfloat getHumidity_RH() gets the humidity value from the data buffer and returns it in units of percent relative humidity.\nfloat humidity;\nhumidity = bme.getHumidity_RH();\nExample List\n\nBasic_I2C: demonstrates declaring a BME280 object, initializing the sensor, and collecting data. I2C is used to communicate with the BME280 sensor.\nBasic_SPI: demonstrates declaring a BME280 object, initializing the sensor, and collecting data. SPI is used to communicate with the BME280 sensor.\n\nWiring and Pullups\nPlease refer to the BME280 datasheet and your microcontroller's pinout diagram. This library was developed using the Adafruit Breakout Board. This library should work well for other breakout boards or embedded sensors, please refer to your vendor's pinout diagram.\nI2C\nThe BME280 pins should be connected as:\n\nVDD: this should be a 1.7V to 3.6V power source. The Adafruit breakout includes voltage regulation enabling a 3-5V range.\nGND: ground.\nVDDIO: digital I\/O supply voltage. This should be between 1.2V and 3.6V. The Adafruit breakout board connects VDDIO so this is not broken out to a pin.\nSDI: connect to SDA.\nSCK: connect to SCL.\nSDO: ground to select I2C address 0x76. Pull high to VDD to select I2C address 0x77.\nCSB: connect to VDD.\n\n4.7 kOhm resistors should be used as pullups on SDA and SCL, these resistors should pullup with a 3.3V source.\nSPI\nThe BME280 pins should be connected as:\n\nVDD: this should be a 1.7V to 3.6V power source. The Adafruit breakout includes voltage regulation enabling a 3-5V range.\nGND: ground.\nVDDIO: digital I\/O supply voltage. This should be between 1.2V and 3.6V. The Adafruit breakout board connects VDDIO so this is not broken out to a pin.\nSDI: connect to MOSI.\nSCK: connect to SCK.\nSDO: connect to MISO.\nCSB: connect to chip select pin. Pin 10 was used in the code snippets in this document and the included examples, but any digital I\/O pin can be used.\n\n","164":"Mapping for Environmental Justice\nWelcome to the Mapping for Environmental Justice(MEJ) repo! MEJ aims to create easy-to-use, publicly-available maps that paint a holistic picture of intersecting environmental, social, and health impacts experienced by communities across the US.\nWith guidance from the residents of impacted communities, MEJ combines environmental, public health, and demographic data into an indicator of vulnerability for communities in every state. MEJ\u2019s goal is to fill an existing data gap for individual states without environmental justice mapping tools, and to provide a valuable tool for advocates, scholars, students, lawyers, and policy makers.\nThis repo contains MEJ's code for processing and combining environmental, demographic, and health data into a census-level index of environmental injustice for the State of Colorado.\n","165":"\nCEQR App\nCEQR App is a collection of data tools whose purpose is to improve the accuracy and speed of environmental review.\nGetting Started\nCEQR App runs on a Rails API and Ember frontend.\nThere are two ways to run the app:\n\nRun Locally\nUse Docker\n\nArchitecture\nTODO\n","166":"underwater-glider\nAn autonomous environmental drone using a buoyancy engine\n","167":"ams-2020-ml-python-course\nMachine Learning in Python for Environmental Science Problems AMS 2020 Short Course\nAuthors\n\nAmanda Burke, University of Oklahoma (aburke1@ou.edu)\nBenjamin Toms, Colorado State University (benatoms@rams.colostate.edu)\nKatherine Avery, University of Oklahoma (katherine.avery@ou.edu)\nHamid Kamangir, Texas A&M Corpus Christi (hkamangir@islander.tamucc.edu)\nKarthik Kashinath, Lawrence Berkeley National Laboratory (kkashinath@lbl.gov)\nRyan Lagerquist, University of Oklahoma (ryan.lagerquist@ou.edu)\n\nModules\nIntroduction to Machine Learning\n\nIntroduction to Machine Learning and AI\nData Science Fundamentals\nSupervised Learning Algorithms\nIntroduction to Deep Learning\n\nAdvanced Topics in Machine Learning\n\nUnsupervised Learning Overview\nMachine Learning Model Interpretation\n\nRequirements\nThe modules for this short course require Python 3.6 and the following Python libraries:\n\nnumpy\nscipy\nmatplotlib\nxarray\nnetcdf4\npandas\nscikit-learn\ntensorflow-gpu or tensorflow\nkeras\njupyter\nipython\njupyterlab\nipywidgets\n\nData Access\nThe data for the course are stored online. The download_data.py script will download the data to the appropriate location and extract all files. The netCDF data is contained in a 2GB tar file, so make sure you have at least 4GB of storage available and a fast internet connection.\nCourse Website\nTo run the notebooks on the cloud rather than a local installation, see the short course website\nMachine Learning in Python for Environmental Science.\n","168":"OpenMEE\nOpenMEE\nTo run OpenMEE from source, you'll need to install the corresponding dependencies.\nYou'll need to install the necessary R packages.\nFirst install the dependencies:\nFrom within a (possibly) sudo-ed R session type:\n> install.packages(c(\"metafor\",\"lme4\",\"MCMCpack\",\"igraph\", \"ape\", \"mice\", \"Hmisc\"))\n\nNext, you'll need to build and install the openmetar packages and altered HSROC (NOT THE ONE FROM CRAN) package and install them. For now, these packages are located in the OpenMetaAnalyst Repository. These package are distributed with the source (NOT the OpenMEE source; the OpenMetaAnalyst source!) under the \"src\/R\" directory of the OMA repository.\n> R CMD build HSROC\n> R CMD build openmetar\n> sudo R CMD INSTALL HSROC_2.0.5.tar.gz\n> sudo R CMD INSTALL openmetar_1.0.tar.gz\n\nOnce R is setup for OpenMeta, you'll need to install Python (we use 2.7) and the necessary libraries. You'll need PyQT (and QT: see http:\/\/www.riverbankcomputing.co.uk\/software\/pyqt\/intro) installed -- we use PyQt 4.9; your mileage may vary with other versions.\nNext, install rpy2 (rpy.sourceforge.net\/rpy2.html) in Python. Verify that all is well by executing:\n> import rpy2\n> from rpy2 import robjects \n\nAt the Python console.\nThat should be all you need. Once everything is setup, you can launch the program by typing:\n> python launch.py\n\nAt the console. This should fire up the GUI.\nimportant dependency versions:\nR      : 3.0.1 (2013-05-16) -- \"Good Sport\"\nmetafor: 1.6.0\npyqt4  : 4.10.1\nUnit tests\nSee https:\/\/github.com\/gdietz\/OpenMEE\/wiki\/Unit-Testing.\n","169":"Tutorial: Machine Learning for Environmental and Geosciences (MLEG)\nThis tutorial is split into two practical parts.\n\n\nML_intro provides an introduction to classical Machine Learning approaches with sklearn.\n\n\nDL_tutorial introduces convolutional neural networks (CNNs) with keras and tensorflow.\n\n\nGetting Started\nClone this repository to your local machine with:\ngit clone https:\/\/github.com\/langnico\/MLEG_tutorial.git\n\nDownload the required data for the \"DL_tutorial\" from this link:\n\nhttps:\/\/drive.google.com\/open?id=1KoR9ISddhHsecsZG0lmePNONYKOZns1E\n\nMove the directories into the DL_tutorial\/ directory. The directory tree should look like this:\n\nDL_tutorial\/\n\ndata\/\nmodel_weights\/\npretrained_models_imageNet\/\n\n\n\nPrerequisites\nWe are going to write and execute the code in a jupyter notebook. The DL_tutorial will use keras with a tensorflow backend.\nTherefore, we need to install:\n\npython3\njupyter\ntensorflow\n\nFurther we will need the python packages\/modules:\n\nsklearn\nnumpy\nmatplotlib\npandas\nkeras\n\nInstalling\nWe propose to install python via anaconda.\n\n\nInstall Anaconda and read the Anaconda tutorial (20min)\n\n\nCreate a new environment: conda create --name MLEGenv python=3.6\n\n\nActivate the new environment\n\nWindows: activate MLEGenv\nLinux and macOS: source activate MLEGenv\n\n--> now your terminal prompt should start with (MLEGenv)\n\n\nInstall the following packages in your activated MLEGenv:\nconda install jupyter\nconda install scikit-learn\nconda install pandas\nconda install matplotlib\nconda install keras\n\n\n\nInstall tensorflow following the:\nofficial installation instructions\n\n\nVerify your installation\n\n\nIn the activated MLEGenv type which jupyter. This should point to the python installation in your conda env e.g. \/username\/anaconda3\/envs\/DL_tutorial\/bin\/jupyter\n\n\nOpen a terminal and go to the location of the file: installation_check.ipynb\nThen open the jupyter notebook with: jupyter notebook installation_check.ipynb\nNOTE: If this does not automatically open a browser showing the notebook, then open a browser (Firefox, Chrome) and type: http:\/\/localhost:8888\/notebooks\/installation_check.ipynb\nThen select the first cell containing the imports and click on the > Run Button.\nIf your installation was successful, the output should be like this:\nUsing TensorFlow backend.\nsuccessfully imported\nkeras version:  2.2.4\n\n\n\nCode inspirations\n\nhttps:\/\/github.com\/tgjeon\/Keras-Tutorials\nhttps:\/\/github.com\/flyyufelix\/cnn_finetune\n\nAuthors\n\nRiccardo De Lutio\nMikhail Usvyatsov\nNico Lang\n\n","170":"environmental-conflict-tracker\nDescription\nThis project develops a globally relevant index of environmental conflict at a subnational scale by reading through millions of news articles every day and identifying and locating events. Environmental conflict can occur through conflicts over resources, land, wildlife, or supply chains. Currently, the database contains thousands of conflict events in India, Indonesia, and Brazil.\nInstallation\nNote: The Docker container is not yet released, as the project is still in early stage.\ndocker pull johnbrandtwri\/environmental_conflict_tracker:latest\ndocker run -p 8888:8888 johnbrandtwri\/environmental_conflict_tracker\n\nUsage\nTBD.\nMethodology\nData - Inputs\n\nIdentify all news data in a given country that contains a conflict event from GDELT\nExtract candidate articles from titles of news articles based on regular expression matches to a curated dictionary\nScrape full news media text for candidate articles with NewsPlease\nCoreference resolution and standard text preprocessing, such as stop word removal and lemmatization\n\nThe data is stored as a JSON like so:\n{ \"id\": \"00001\",\n  \"country\": \"IN\",\n  \"url\": \"https:\/\/\",\n  \"date\": \"MM-DD-YYYY\",\n  \"full_text\": string,\n  \"article_title\": string,\n  \"number_actions\": int,\n  \"actions\": {\n      1: {'latitude', 'longitude', 'action_type', \"goldstein\", ...},\n      2: {'latitude', 'longitude', 'action_type', \"goldstein\", ...},\n      3: {'latitude', 'longitude', 'action_type', \"goldstein\", ...},\n          },\n  }\nData - Internal outputs\nThis project identifies the following entities: actor, type, number, action, location, date, which can be disaggregated as follows:\n\nActor: farmer, government, trader, smallholder, etc.\nType: Human-wildlife conflict, land tenure, land appropriation, land use rights, water scarcity, resource scarcity, livelihoods,\nNumber: number of people affected\nAction: Protest, kill, threaten, seize, etc.\nLocation - provided in the data\/metadata\/variables\/$MONTH.csv\nDate: Either listed in the article or date_publish from the text\n\nThe highest priority entity is the type of conflict. Location and Date should be provided by the GDELT metadata data\/metadata\/variables. Action may be provided by the GDELT metadata through the CAMEO codebook but should be verified. Number and Actor are going to be difficult to identify and will likely need an implementation of coreference resolution.\nData - External outputs\nThe external output is a monthly index of environmental conflict by subnational jurisdiction. The methodology for this is TBD.\nMethodology\n\nRoBERTa classifier: Classify articles into conflict \/ no conflict\nCorEx Topic model: For conflict articles, identify type of conflict\nNamed entity recognition: For conflict articles, identify actor, action, date, and location.\n\nValidation\nTBD.\nImportant references\n\nGDELT\nCAMEO codebook\nLand Conflict Watch\nWRI Restoration\nGlobal forest watch\nFlair NER\nSpaCy NER\nCoreference resolution\n\nOrganization\nTBD.\n","171":"IoT Smart Environmental Monitoring\nA IoT Java based project developed for the Raspberry Pi used to participate in The AWS IoT Mega Contest Hackathon\nhttps:\/\/www.hackster.io\/contests\/AWSIoTMegaContest\nSmall and easy to use device to monitor temperature, humidity, noise levels, luminosity and atmospheric pressure.\nIt sends data to the AWS IoT Platform\nScreenshots\nDevice\n\nReading sensors\n\nUsing the AWS IoT platform\n\nCode\n\n\nThe dist folder contains the compiled binaries to deploy to the Raspberry Pi\n\n\nThe read_monitoring_device folder contains the application that reads the\nsensors , logs data and communicates with AWS\n\n\nThe sensors_lib folder contains a Java library coded for this project that\nreads analog and digital data from the sensots and converts it to a known measure unit\n\n\nThe update_AWS_device folder contains a javascript application that uses the\nofficial aws-iot-device-sdk for the raspberry to communicate with AWS\n\n\nUser Guide\nA complete user guide with step by step procedures on how to setup this project\nfrom scratch, including raspberry setup and circuit schematics is found here:\nhttps:\/\/www.hackster.io\/alapisco\/smart-environmental-monitoring-2552bb\n","172":"\nA spatio-temporal analysis of the environmental correlates of COVID-19 incidence in Spain\nAntonio Paez (McMaster University)\nFernando A. Lopez (Universidad Politecnica de Cartagena)\nTatiane Menezes (Universidade Federal de Pernambuco)\nRenata Cavalcanti (Universidade Federal de Pernambuco)\nMaira Galdino da Rocha Pitta (Universidade Federal de Pernambuco)\nGeographical Analysis (Early View)\nhttps:\/\/doi.org\/10.1111\/gean.12241\nPre-print available\nhere\nAbstract\nThe novel SARS-CoV2 has disrupted health systems and the economy, and\npublic health interventions to slow its spread have been costly. How and\nwhen to ease restrictions to movement hinges in part on whether\nSARS-CoV2 will display seasonality due to variations in temperature,\nhumidity, and hours of sunshine. Here, we address this question by means\nof a spatio-temporal analysis in Spain of the incidence of COVID-19, the\ndisease caused by the virus. Use of spatial Seemingly Unrelated\nRegressions (SUR) allows us to model the incidence of reported cases of\nthe disease per 100,000 population as an interregional contagion\nprocess, in addition to a function of temperature, humidity, and\nsunshine. In the analysis we also control for GDP per capita, percentage\nof older adults in the population, population density, and presence of\nmass transit systems. The results support the hypothesis that incidence\nof the disease is lower at higher temperatures and higher levels of\nhumidity. Sunshine, in contrast, displays a positive association with\nincidence of the disease. Our control variables also yield interesting\ninsights. Higher incidence is associated with higher GDP per capita and\npresence of mass transit systems in the province; in contrast,\npopulation density and percentage of older adults display negative\nassociations with incidence of COVID-19.\nKeywords\nSARS-CoV2\nCOVID-19\nSeasonality\nTemperature\nHumidity\nPopulation density\nOlder adults\nSpatial SUR\nContagion\nSpain\nIntroduction\nFrom a small outbreak linked to a live animal market at the end of 2019\nto a global pandemic in a matter of weeks, the SARS-CoV2 virus and\nCOVID-19, the disease it causes, have threatened to overrun health\nsystems around the world. In efforts to contain the spread of the\ndisease, numerous governments in many regions and nations have either\nrecommended or mandated social distancing measures, and as of this\nwriting, millions of people in five continents shelter in place. There\nare encouraging signs that these measures have mitigated the spread of\nthe virus (e.g., Lancastle 2020; Lewnard and Lo 2020; Wilder-Smith and\nFreedman 2020). Even so, this has come at a high cost, and the\nconsequences for all spheres of economic, social, and cultural life have\nbeen dire (e.g., Fernandes 2020; Luo and Tsang 2020). As a result, there\nis a sense of urgency to anticipate the progression of the pandemic, in\norder to plan for progressive lifting of restrictions to movement and\nsocial contact (e.g., Kissler et al. 2020). Needless to say, this has\nbecome a delicate, and politically charged, balancing act between public\nhealth and the economy (Gong et al. 2020).\nA salient question in the debate about how and when to ease social\ndistancing measures is whether the virus will display seasonal\nvariations. Existing research on similar pathogens suggests that the\nvirus could be more stable and potentially easier to transmit in\nconditions of low temperature and low humidity. While this is\nencouraging, it is important to keep in mind that \u201cnot all seasonal\nrespiratory viruses experience the same spatiotemporal patterns\u201d (\u00c1ngel\nSol\u00e1 et al. 2020, sec. 4). This urges caution when extrapolating from\nknown viruses. The evidence in this respect is as yet inconclusive, and\nalthough easing restrictions as the weather warms may appear tempting,\ndoing so prematurely could well undo weeks or possibly months of costly\nmeasures.\nIt is not surprising, given the stakes involved, that this issue has\nalready triggered a lively debate. The current state of knowledge was\nwell-summarized by the National Academy of Sciences, Engineering, and\nMedicine in the U.S. in a recent report (see National Academies of\nSciences, Engineering and Medicine 2020). Engaged by the Office of the\nExecutive for guidance on this matter, this organization concluded that:\n\u201c[some] limited data support a potential waning of cases in warmer and\nmore humid seasons, yet none are without major limitations\u2026Additional\nstudies as the SARS-CoV2 pandemic unfolds could shed more light on the\neffects of climate on transmission\u201d (p.\u00a06). To further complicate\nmatters, much of the relevant work has yet to be peer-reviewed (see for\ninstance the challenge of Harbert, Cunningham, and Tessler 2020; to\nAraujo and Naimi 2020).\nWith the above considerations in mind, our objective with this paper is\nto investigate the influence of environmental factors, concretely\ntemperature, humidity, and sunshine, on the progression of the pandemic.\nWe adopt a population health approach, and report results from a\nspatio-temporal model of the incidence of COVID-19 in the coterminous\nprovinces in Spain, one of the countries hardest hit by the pandemic. We\ncombine data on reported cases of the disease with metereological\ninformation, to create a spatio-temporal dataset covering a period of 30\ndays. We then join this dataset with provincial-level economic and\ndemographic information to act as controls to our key environmental\nvariables. These data are analyzed using a spatial Seemingly Unrelated\nRegressions (SUR) approach, which allows us to model incidence of\nCOVID-19 as a contagion process.\nThe results provide evidence of the effect of temperature, humidity, and\nsunshine on the incidence of COVID-19. The clearest result with respect\nto these variables is a lower incidence of COVID-19 at higher\ntemperatures and levels of humidity, while the opposite happens with\nrespect to hours of sunshine. Our control variables also provide some\nintriguing insights. Higher incidence is associated with higher GDP per\ncapita and presence of mass transit systems in the province; in\ncontrast, population density and percentage of older adults display\nnegative associations with incidence of COVID-19. The results of this\nanalysis provide support to the hypothesis of seasonality of the novel\nSARS-CoV2, and should be of interest to public health officials and\npolicy makers grappling with the question of the trajectory of the\npandemic.\nPlease note that this paper is prepared as a reproducible research\ndocument. The source R markdown document, as well as all data and code\nneeded to reproduce\/review\/extend the analysis can be obtained from a\npublic repository.\nBackground\nThe global emergence of infectious diseases is mostly driven by\nenvironmental, ecological, and socio-economic factors (Jones et al.\n2008). In the case of SARS-CoV2, the ecological factors include the\ninteraction between humans and wildlife. Once transmission of a disease\nbegins to happen between humans, socio-economic and environmental\nfactors become increasingly important. As noted in the introduction, the\nfocus of the paper is on environmental variables, concretely three\nrelated to meteorological conditions: temperature, humidity, and\nsunshine.\nMuch of what is known about the potential seasonality of SARS-CoV2 is a\nresult of research on other pathogens. Earlier, diverse studies have\nshown the effect of temperature and humidity on the incidence of\ninfluenza (e.g., M\u00e4kainen et al. 2009; Jaakkola et al. 2014; Kudo et al.\n2019). Jaakkola et al.\u00a0(2014), for example, found that a decrease of\ntemperature and absolute humidity precedes the onset of symptoms of\ninfluenza A and B viruses by 3 days in places where the temperature is\nlow. After the 2002-2004 outbreak of SARS, researchers also began to\ninvestigate the relationship between these factors and SARS-CoV\n(Casanova et al. 2010; Chan et al. 2011). Casanova et al.\u00a0(2010), for\ninstance, used surrogates to find that virus inactivation was likely\nmore rapid at higher temperatures; in terms of humidity, these\nresearchers reported that survival of the virus was lower at moderate\nrelative humidity levels. Chan et al.\u00a0(2011) also found that viability\nof the virus that causes SARS is also lost at higher temperatures\n(>38\u00b0C) and relative humidity superior to 95%.\nWhether results from laboratory experiments will hold when the virus\ncirculates in the community remains uncertain. At a global scale, de\n\u00c1ngel Sol\u00e1 et al.\u00a0(2020) see less risk from SARS-CoV2 in the Caribean\nBasin; on the other hand, Coelho et al.\u00a0(Coelho et al. 2020) warn that\nat least during the exponential phase, expansion of the virus is not\ndriven by climate. Similarly, whereas Araujo and Naimi (2020) argue that\nspread of SARS-CoV2 will likely be constrained by climate, Harbert et\nal.\u00a0(2020) remain unconvinced that spatial modelling can currently\ndiscriminate the distribution of the disease on the basis of climate, at\nleast in the United States. Yao et al.\u00a0(2020), examined data from China\nand came to the conclusion that neither temperature nor ultraviolet\nindices had an association with transmission of COVID-19. This is\ndespite previous research that has linked less exposure to UVB radiation\nto higher prevalence and severity of acute respiratory tract infections\n(Zittermann et al. 2016; D\u0105browska-Leonik et al. 2018; Dinlen et al.\n2016; Mathyssen et al. 2017; Esposito and Lelii 2015; Jat 2017;\nMoriyama, Hugentobler, and Iwasaki 2020).\nIn addition to the environmental variables above, from a population\nhealth perspective it is also important to account for potential\nsocio-economic and demographic confounders.\nTo account for population-level factors, the first variable that we\nconsider is GDP per capita. Much has been written about globalization\nand the spread of infectious disease. The growth in global connections\nhas presented a challenge to spatial approaches in the initial stages of\ndisease management, when the cause of a disease may still be unclear but\nthe plane has already departed (Zhou and Coleman 2016). In reference to\nthe earlier outbreak of SARS, van Wagner (2008) chronicles how Toronto\u2019s\nstatus as a global city turned out to be a vulnerability in this\nrespect. In our case, we think of GDP per capita as a marker of a\nregion\u2019s relative position in a network of global cities, and its\npotential to be further ahead in the trajectory of the pandemic.\nFurthermore, wealthier regions also tend to concentrate more activities\nthat produce non-traded goods, including building and construction\n(Hallet 2002). Therefore, it is possible that wealthier regions remain\nrelatively more active even during a lockdown. On the other hand, we\ncannot discount the possibility that less wealthy regions have a higher\nproportion of workers in manual occupations who cannot telework, and\ntherefore have more difficulties complying with shelter-in-place orders.\nSecondly, we consider percentage of older adults (over 65) in a region.\nEarly evidence regarding COVID-19 suggests that the case rate mortality\nis higher at older ages (e.g.\u00a0The Novel Coronavirus Pneumonia Emergency\nResponse Epidemiology Team 2020). However, it is not clear that a\nrelatively large population of older adults necessarily translates into\nhigher transmission rates of the infection. The tool of choice in\ncontaining the spread of the disease has been social distancing. In this\nrespect, the evidence from the field of transportation is that older\nadults tend to travel less frequently, for shorter distances, and have\nhigher rates of immobility than most everyone, except the youngest\nmembers of the public (e.g., Roorda et al. 2010; Morency et al. 2011;\nSikder and Pinjari 2012). In other words, many older adults are, whether\nby preference or otherwise, already in a form of social isolation.\nSocial distancing during the pandemic may actually reinforce that\ncondition for them, as suggested by the analysis of age-structured\nsocial contact in India, China, and Italy of Sing and Adhikari (2020).\nSince the age-structured matrix of social contact in Spain is similar to\nItaly (see Prem, Cook, and Jit 2017), our expectation is that\npopulations with higher percentages of older adults will tend to have\nlower levels of social contact and hence of incidence.\nPopulation density is also relevant since it directly affects the\ncontact patterns and contact rates between individuals in a population\n(Hu, Nigmatulina, and Eckhoff 2013). The evidence available suggests a\npositive relationship between the transmission of COVID-19 and\npopulation density (e.g.\u00a0cumulative incidence in urban areas like NYC).\nFor this reason, we anticipate a positive relationship between\npopulation density and the incidence of the disease.\nThe last variable that we consider as a control is the presence of mass\ntransit systems in a province. Every province in Spain offers some form\nof public transportation, but only five provinces have higher order\nsystems of mass mobility (e.g.\u00a0metro or subway), namely Barcelona,\nMadrid, Sevilla, Valencia, and Bizkaia. Public transportation has been\nhypothesized to relate to the spread of contagious disease by some\nresearchers using agent-based approaches and simulation (e.g., Perez and\nDragicevic 2009; Wang et al. 2010), and while we find scant evidence of\na link in the literature, the idea is intuitively appealing. After all,\nunlike the isolation that a car offers to travellers, most mass transit\nsystem are cauldrons of social contact.\nContext and Data\nCovid-19 in Spain\nThe first reported case of COVID-19 in Spain was on January 31st, 2020,\nwhen a German tourist in the Canary Islands tested positive for the\nvirus. After this case, it was still a few weeks before the first\ndomestic case was reported, on February 27th in Sevilla province\n(Andalusia). In a short period of time, as testing started to ramp up,\nit became clear that an outbreak was flaring. By March 11th the World\nHealth Organization (WHO) declared COVID-19 officially a pandemic. This\ndeclaration marked a turning point for the public in Spain too. As of\nMarch 13th, the number of cases of COVID-19 reported in Spain was 4,473,\nwith a majority of cases (1,990) concentrated in Madrid: these numbers\nwere at the time the worst outbreak in Europe after Italy. In response\nto the situation, on March 13th the Spanish National Government declared\na state of emergency, to go into effect on Saturday March 14th. As part\nof the state of emergency restrictions to most activities were imposed,\nwith the exception of essential services (e.g.\u00a0food, health) and some\neconomic subsectors of industry and construction. A few days later, on\nMarch 17th, Spain closed its lands borders to allow entry only to\nreturnee nationals and permanent residents. The lockdown was further\nhardened between March 30th and April 12th (including the Easter weekend\nof April 10th-12th) and during this period only essential activities\nwere allowed. During this period, there was a dramatic reduction in\noverall mobility, both within provinces as between .\nData\nOur dataset includes information about the daily number of cases of\nCOVID-19 reported in Spain at the provincial level (NUTS3 in Eurostat\nterminology) for the period between March 13th and April 11th,\ninclusive. For our purposes, we consider positive cases reported, but\nexclude symptomatic cases diagnosed by a doctor without a Polymerase\nChain Reaction (PCR) test. The Spanish National Government publishes\nperiodic updates at the regional level (NUTS2) and the information is\nalso released at the provincial level as part of a collaborative project\nby geovoluntarios.com, ProvidencialData19, and ESRI Espa\u00f1a. This\ninformation is compiled from several sources, mainly the official web\npages of the Spanish regional goverments, as documented in Centro de\nDatos Covid-19. We consider two sets of explanatory variables. The first\none, and the focus of this research, are the three environmental\nvariables, collected from official sources (i.g., AEMET, the state\nmeteorology agency, and MAPA, the ministry of agriculture, fisheries,\nand food). The second set provides some relevant controls as discussed\nabove, and are also collected from official sources, i.e., INE, the\nnational statistics institute. Table  shows the descriptive statistics\nand the provenance of the data used in this research.\nThe spatial and temporal coverage of the data is as follows. Our dataset\nbegins on March 13, which is the first date when every province had\nreported at least one case of COVID-19, and continues until April 11,\nfor a period of 30 days. The unit of analysis is the province. Provinces\nare the equivalent of states, and are embedded in Autonomous\nCommunities. As an example, Catalu\u00f1a is an Autonomous Community and\nconsists of four provinces, namely Barcelona, Gerona, Lerida, and\nTarragona. The size of the provinces is relatively large, as seen in\nTable . The smallest province is (1,978.12km^2) (this is smaller than\nRhode Island in the U.S.) and the largest province is (21,767.93km^2)\n(slightly smaller than New Jersey in the U.S.). While this is a\nrelatively large degree of spatial aggregation, reporting on COVID-19 is\nnot yet consistent at smaller geographies, or cases are not reported at\nthat level at all.\n\nDescriptive statistics\n\n\n\nVariable\n\n\nNote\n\n\nMin\n\n\nMean\n\n\nMax\n\n\nSD\n\n\nSource\n\n\n\n\n\n\nCOVID-19 Incidence\n\n\nIncidence in reported cases of SARS-19 per 100,000 people\n\n\n0.38\n\n\n153.61\n\n\n1149.36\n\n\n186.23\n\n\nProvidencialData19\n\n\n\n\nArea\n\n\nArea of province in sq.km\n\n\n1978.12\n\n\n10118.79\n\n\n21767.93\n\n\n4.77\n\n\nINE\n\n\n\n\nGDPpc\n\n\nGDP per capita in \u20ac1,000s\n\n\n16.67\n\n\n22.51\n\n\n36.00\n\n\n4805.98\n\n\nINE\n\n\n\n\nOlder\n\n\nPercentage of people aged 65 and older in the province\n\n\n15.16\n\n\n21.03\n\n\n31.36\n\n\n3.95\n\n\nINE\n\n\n\n\nPopulation Density\n\n\nPopulation density in the province in people per sq.km\n\n\n8.60\n\n\n140.04\n\n\n829.76\n\n\n181.25\n\n\nINE\n\n\n\n\nMean Temperature\n\n\nMean temperature in province by date, in \u00b0C\n\n\n1.00\n\n\n12.18\n\n\n23.20\n\n\n3.67\n\n\nAEMET\n\n\n\n\nHumidity\n\n\nRelative humidity in province by date\n\n\n2.00\n\n\n77.82\n\n\n100.00\n\n\n10.37\n\n\nMAPA\n\n\n\n\nSunshine\n\n\nDaily hours of sunshine in province by date\n\n\n0.00\n\n\n5.74\n\n\n12.40\n\n\n3.96\n\n\nAEMET\n\n\n\n\n\n\nNote: \n\n\n\n\n ProvidencialData19:\nhttps:\/\/www.datoscovid.es\/pages\/providencialdata19\n\n\n\n\n INE (Instituto Nacional de Estadistica):\nhttps:\/\/www.ine.es\/\n\n\n\n\n AEMET (Agencia Estatal de Meteorologia):\nhttp:\/\/eportal.mapa.gob.es\n\n\n\n\n MAPA (Ministerio de Agricultura, Pesca y Alimentacion):\nhttp:\/\/eportal.mapa.gob.es\n\n\n\n\nAn important aspect of working with environmental data such as\ntemperature, humidity, and hours of sunshine, is the incubation period\nof the disease. Lauer et al.\u00a0(2020) report for the case of COVID-19 a\nmedian incubation period of 5.7 days (with a confidence interval between\n4.9 to 7.8 days). The vast majority of cases (95%) develop symptoms\nbetween 2.6 days (CI, 2.1 to 3.7 days) and 12.5 days (CI, 8.2 to 17.7\ndays). For this reason, we judge it best to use lagged values of the\nenvironmental variables. We test different time lags as follows. We\nconsider a lagged 8-day average, from date-minus-12 to date-minus-5 days\n(hereafter lag8). Secondly, we consider a lagged 11-day average, from\ndate-minus-12 to date-minus-2 days (hereafter lag11). Finally, to\naccount for the likely duration of incubation, we consider a lagged\n11-day weighted average, from date-minus-12 to date-minus-2 days\n(hereafter lag11w). The weights for this variable are calculated using\nthe parameters of the log-normal distribution reported by Lauer et\nal.\u00a0(2020), i.e., a log-mean of 1.621 and a log-standard deviation of\n0.418. With these weights, the environmental variables at date-minus-2\nand date-minus-12 days are weighted as 0.041 and 0.009 respectively,\nwhereas the environmental variables at date-minus-5 days are weighted as\n0.194. These weights have the effect of changing the contribution of\ndaily values to the lagged moving average. For instance, the temperature\nat date-minus-4-days is weighted more heavily than the temperature at\ndate-minus-10-days, as a closer approximation of the conditions at the\nmost likely time of contagion before the disease became manifest.\nMethods: the Spatial SUR Model\nThe Seemingly Unrelated Regression equations model (SUR hereafter) is a\nmultivariate econometric model used in different fields when the\nstructure of the data consists of cross-sections for different time\nperiods. The basis of this approach is well-known since the initial\nworks of Zellner (1962), and has become a popular methodology included\nin several econometrics textbook (e.g., Greene 2003). To our knowledge,\nAnselin (1988) was the first author to discuss SUR from a spatial\nperspective, in the context of spatio-temporal analysis. In his landmark\ntext, Anselin discussed a model made of \u201can equation for each time\nperiod, which is estimated for a cross section of spatial units\u201d\n(p.\u00a0141). From this milestone, a large body of research has developed\nto extend the classical SUR into a spatial framework (e.g., Rey and\nMontouri 1999; Lauridsen et al. 2010; Le Gallo and Dall\u2019Erba 2006;\nL\u00f3pez, Mart\u00ednez-Ortiz, and Cegarra-Navarro 2017).\nThe classical SUR model without spatial effects (from here, SUR-SIM) is\na stack of equations as follows:\n\nwhere\n\nis an\n\nvector, and in our case\n\nis the incidence ratio in the province\n\nthe day\n;\n\nis a\n\nmatrix of the\n\nindependent variables,\n;\n\nis a vector of coefficients and\n\nis the vector of residuals.\nA key feature of the SUR model is the temporal dependence structure\namong the vectors of residuals, namely:\n\nNote that this specification is very flexible, in that it allows changes\nin the coefficients\n\nin order to modulate the effect of the independent variables on\n.\nThis flexibility can be reduced and it is posible to impose restrictions\nconsidering some\n\ncoefficients as being constant over time. In this case, we can\nreformulate the coefficients expression\n\nto restrict the first\n\ncoefficients to be constant across equations. This is equivalent to\nspecifying some effects to be invariant over time.\nEquation () can be rewriten in compact form:\n\nAs is the case with cross-sectional data, it is possible to test the\nresiduals of Model () for spatial autocorrelation, and several tests\nhave been developed to test the null hypothesis of spatial independence\n(see L\u00f3pez, Mur, and Angulo 2014). When the null hypothesis is rejected,\nseveral alternative specifications have been proposed to include spatial\neffects (Anselin 1988, see also 2016). In this paper we consider a\nspatial SUR model that incorporates a spatial lag of the dependent\nvariable as an explanatory factor. Spatial analytical approaches were\nused to understand contagion-difussion processes in the case of\ninfectious disease in general (e.g., Cliff, Haggett, and Smallman-Raynor\n1998) and the 2003-2004 SARS outbreak in particular (e.g., Meng et al.\n2005; Cao et al. 2010). While we are mindful of the same caveat that the\nnovel SARS-CoV2 may not follow the patterns of previous diseases, there\nis still evidence from the United States that COVID-19 displays spatial\npatterns that are consistent with a diffusion process (Desjardins, Hohl,\nand Delmelle 2020). For this reason, the spatial lag model is\nappropriate to model incidence of COVID-19 geographically, since it\naccounts for potential spatial patterns that result from a process of\ncontagion, as explained next.\nThe stack expresion for the SUR model with a spatially lagged dependent\nvariable (SUR-SLM) is as follows:\n\nwhere\n![(\\bf{A} =I_{TN}-\\bf{\\Gamma} \\otimes W)](https:\/\/render.githubusercontent.com\/render\/math?math=%24%5Cbf%7BA%7D%20%3DI_%7BTN%7D-%5Cbf%7B%5CGamma%7D%20%5Cotimes%20W%24)\nis the spatially lagged dependent variable, and\n.\nThis specification assumes that outcome\n()\nat location\n\nand time\n\nis partially determined by the weighted average\n()\nof the outcome in neighboring provinces, with neighborhood defined by\nmatrix\n\nof spatial weights. In other words, the spatially lagged dependent\nvariable represents a process of contagion, where the disease in\nneighboring provinces can spillover in a spatial way. The coefficients\nof the spatially lagged variable are estimated for each time period\n\nand identify the intensity and the sign of the contagion effect. It is\npossible test the null hypothesis of identical levels of spatial\ndependence\n().\nThe correspond Wald test is available in the R package spsur.\nThe SUR-SLM model can be estimated using maximum likelihood (L\u00f3pez, Mur,\nand Angulo (2014)) or instrumental variables (M\u00ednguez, L\u00f3pez, and Mur\n(2019)).\nA note regarding the interpretation of the model is in order. It is\nwell-known that coefficients in linear regression models are partial\nderivatives of the dependent variable with respect to the independent\nvariables, and therefore directly give the marginal effects or rates of\nchange. Spatially lagged models, however, are no longer linear. The\nintuition behind the non-linearity is that the spatial lag expands the\ninformation set to include information from neighbouring regions: in\nother words, the value of an explanatory variable in a spatial unit can\nhave influence in other spatial units via the spatial lag. This makes\ninterpretation of the coefficients less straightforward but also richer\n(Golgher and Voss 2016). The results of LeSage (2009) for\ncross-sectional spatial lag models can be extended to the spatial SUR\nframework. Note that, according to Elhorst (2014), the partial\nderivatives have the following interpretation: if an explanatory\nvariable ((X_k)) in a particular province changes, not only the\nincidence rate in that province changes, also incidence rates in other\nprovinces change via the contagion effect. Therefore, a change in\n(X_k) in a particular province has a direct effect on that province,\nbut also an indirect effect on neighbouring provinces. In this way,\nthe (i)th diagonal element of the matrix of partial derivatives\nrepresents the direct effect on the (i)th province, whereas the\nnon-diagonal elements of (i)th row of the matrix of partial\nderivatives represent the indirect effects on other provinces. In order\nto obtain a global indicator, the direct effect is calculated as the\nmean of the diagonal elements and captures the average change in\nincidence ratio caused by the change in (X_k). Likewise, a global\nindicator of the indirect effects is calculated as the mean of the\nnon-diagonal elements. The total effect is the sum of direct and\nindirect effects. Finally, note that if (\\rho_k = 0), the indirect\neffects are 0 and the direct effects are equal to (\\beta_kt).\nResults\nExploratory Data Analysis\nFigure  shows the geographical variation in the incidence of COVID-19 in\nSpain, as well as the temporal progression of the disease in weekly\naverages. Our analysis begins on March 13. Albeit still low, the highest\nincidence at this early date was in the provice of \u00c1lava, in the North\nof Spain. \u00c1lava is not the most populous province, with a population of\nonly 331,549, but it has the highest GDP per capita of all provinces.\nVitoria, its main city, is the capital of the Basque Country and has\nbeen the focus of efforts, along with San Sebastian and Bilbao, to\ndevelop a \u201cGlobal Basque City\u201d (Meijers, Hoekstra, and Aguado 2008). The\nother early focus of the pandemic in Spain was Madrid, which is the most\npopulous province in the country and has the second highest GDP per\ncapita after \u00c1lava. The early outbreaks in these two provinces can be\ntraced throughout the progression of the pandemic over time, although by\nthe end of the period under study, other provinces had matched and even\nsurpased their incidence rates, including Segovia and Soria to the north\nof Madrid, and Ciudad Real and Albacete to the south.\n\nFigure  shows the distribution of the environmental variables in Spain.\nFor ease of visualization we aggregate the provinces by Autonomous\nCommunity. Each box-and-whisker in the figure represents the\ndistribution of the variable for a community over the 30-day period. In\nthe plot, the communities have been sorted by latitude, so that\nPrincipado de Asturias is the northernmost community, and Andalucia the\nsouthernmost. As seen in the figure, there is a relatively wide range of\nvalues both within and between provinces over the 30-day period\nexamined. The top panel of the figure shows the distribution of mean\ntemperatures. The lowest mean temperature for a community on any given\nday was approximately 3\u00b0C, and the highest about 20\u00b0C, for a range of\napproximately 17 degrees. Likewise, there is a great deal of variability\nin humidity, as seen in the middle panel of the figure, where the lowest\nmean humidity for any community is approximately 48% and the highest is\nclose to 100%. Finally, the bottom panel displays mean daily hours of\nsunshine in the community. This variable displays the most variability\nwithin communities over time, but remains relatively constant across\ncommunities. It is important to note that these are summaries by\ncommunity, and the actual values of these variables for the provinces\ndisplay somewhat more variability.\n\nFigure  includes three maps that display the spatial variation of our\ncontrol variables, namely GDP per capita, percentage of older adults in\nprovince, population density, and presence of mass transit systems. As\nseen there, GDP per capita is higher in Madrid and the northeast part of\nthe country, mainly in Pais Vasco and Catalu\u00f1a. Percentage of older\nadults is somewhat more checkered, with high values in Madrid and other\nprovinces in the center-west part of the country, but also in some\nprovinces in the north. Outside of provinces with major cities (e.g.,\nMadrid; Bizkaia and Gipuzkoa in Pais Vasco; Pontevedra in Galicia),\npopulation density tends to be higher in provinces along the\nMediterranean coast. The final panel in the figure shows the five\nprovinces in the country that have higher order mass transit systems\n(e.g., metro).\n\nFigure  shows the distribution of daily simple correlations of incidence\nof COVID-19 with the independent variables (with the exception of\nTransit, which is a categorical variable). These correlations are\ncalculated after log-transforming all variables. As previously\ndiscussed, the environmental variables have a temporal lag and were\ncalculated using different time windows.\nIt can be seen in the figure that temperature (in its three forms) has\nthe highest simple correlation with incidence of COVID-19. After\ntemperature, GDP per capita has the highest positive correlation with\nthe dependent variable. The distribution of these correlations is also\nquite tight over the 30-day period of the study. Hours of sunshine tends\nto have a moderately high correlation with incidence of COVID-19, but\nthe distribution of these correlations is more spread, and in some cases\nstrays into negative values. A similar thing happens with humidity,\nwhich also tends to display more day to day variation in the correlation\nwith the dependent variable. The percentage of older adults shows a\nrelatively tight distribution of day-to-day correlations, and is\nnegative. Population density, in contrast, tends to be negative, but is\nrelatively spread, and on some days, the simple correlation between\ndensity and incidence of COVID-19 is weakly positive. Overall for the\nperiod under examination, the pairwise correlations between these\nvariables and incidence are significant at (p<0.05), with the\nexception of the three Sunshine_hours variables.\n\nSUR Models\nCorrelation analysis in the preceding section provides some insights\nabout the potential associations between incidence of COVID-19 and the\nvarious environmental and control variables. In this section we estimate\nthree spatial SUR models to test the differences between the various\ntemporal lags and weighting schemes for the environmental variables.\nAccordingly, we define three models: Model 1, which is estimated using\nthe lagged 8-day averages of the environmental variables (lag8); Model\n2, which is estimated using the lagged 11-day averages of the\nenvironmental variables (lag11); and finally, Model 3, which is\nestimated using the lagged 11-day weighted averages of the\nenvironmental variables (lag11w).\nTo implement the SUR approach, we must define a matrix of spatial\nweights (W). In this case, we consider neighborhoods based on\nadjacency, based on the well-known queen criterion (two provinces are\nadjacent if they share a boundary or touch at a vertex). The analysis is\nof the coterminous provinces.\nFor estimation, we log-transform the dependent and quantitative\nindependent variables. The only variable that is not transformed is the\ncategorical variable for transit systems. A log-log transformation is\nappropriate to capture non-linear relationships between variables and\nprovides a straightforward interpretation of the coefficients as\npercentage change. Furthermore, we introduce restrictions so that the\ncoefficients of two of our control variables are constant over time,\nnamely GDP per capita and percentage of older adults. We do not see an\na priori reason to let those two variables vary across equations, and\nthe correlation analysis in Figure  also suggest little temporal\nvariation. In contrast, we let the spatial autocorrelation parameter, as\nwell as the parameters of the rest of the independent variables\n(including the constant) to vary over time. This will be useful to\ndetect whether there are behavioral adaptations at the population level\nover the course of the period examined. As an example of behavioral\nadaptations, the effect of density might weaken over time, in the\nmeasure that the effects of the lockdown are felt: at full compliance\nwith the lockdown, with people practicing social avoidance, density\nmight matter less than other factors.\nAfter estimation, we compare the goodness of fit of the three SUR\nmodels. Figure  shows the equation-level coefficient of determination\n(R^2), one for each time period\/day. As well, the overall coefficient\nof determination for the system is reported for each model\n(\\text{pooled}-R^2). The general trend is identical for the three\nmodels, with the goodness-of-fit improving over time and plateuing\naround a value of (R^2) of 0.55. Model 1 (lag8) performs somewhat\nbetter in the first few equations\/days, when the goodness-of-fit is\nrelatively poor, and then again in the last few equations\/days. Model 3\n(lag11w), in contrast, does not perform well towards the end of the\nstudy period. The most balanced model in terms of equation-level\ngoodness-of-fit appears to be Model 1 (lag8), and this impression is\nfurther supported by a slightly higher value of the\n(\\text{pooled}-R^2). The analysis using a lagged moving average of the\nenvironmental variables is generally in line with the incubation period\nreported by Lauer et al.\u00a0(2020), although the results do not support the\nuse of a weighted average. For the remainder of the paper, we will adopt\nModel 1 (lag8) as our best model. In the following section we discuss\nthe results of the analysis in more depth.\n\nDiscussion\nTable  presents a summary of the results of Model 1 (lag8). Recall\nthat two coefficients were constrained and are estimated only for the\nfirst equation of the system, and thus are assumed to be constant over\ntime. These are the coefficients corresponding to GDP per capita\n((p\\leq0.10)) and percentage of older adults ((p\\leq0.05)). The sign\nof the coefficient for GDP per capita is positive, which indicates that\nwealthier regions tend to have a higher incidence of COVID-19. This is\nin line with the idea that the epidemic started earlier in wealthier\nplaces due to their connections to a globalized world. The sign of the\ncoefficient for percentage of older adults, on the other hand, is\nnegative. As previously discussed, the level of social contact of older\nadults even under normal circumstances tends to be lower than for\nyounger people. As a consequence, places with larger populations of\nolder adults appear to have a natural level of social distancing in\nplace. It is important to note that this does not detract from evidence\nthat older adults are more vulnerable individually and in institutional\nsettings, where their case mortality rates are perhaps the highest of\nall age groups. Instead, this result indicates that their presence in\nthe community at large tends to depress transmission of the virus.\nOf the two other control variables, the coefficient of population\ndensity is significant at (p\\leq0.05) in 12, at (p\\leq0.10) in 3\nequations, and not significant in 15. The coefficient for transit is\nsignificant at (p\\leq0.10) in 20 equations, and of those, significant\nat (p\\leq0.05) in 18 equations. The next four variables are\nenvironmental factors. The coefficient for humidity is significant at\n(p\\leq0.19) in 20 equations, and of those, significant at\n(p\\leq0.05) in 15 equations. Of the environmental variables,\ntemperature is the only variable that has significant coefficients in\nevery equation at (p\\leq0.05). Finally, sunshine has significant\ncoefficients at (p\\leq0.05) in 24 equations.\n\nSummary of estimation results of best model (lag11: lagged 11-day moving\naverage)\n\n\n\n\n\n\nEstimates\n\n\n\n\nSignificance\n\n\n\n\n\n\n\nVariable\n\n\nMin\n\n\nMean\n\n\nMax\n\n\np > 0.10\n\n\n0.10 <= p < 0.05\n\n\np <= 0.05\n\n\nNote\n\n\n\n\n\n\nIntercept\n\n\n6.172\n\n\n9.441\n\n\n14.071\n\n\n0\n\n\n0\n\n\n30\n\n\nNon-constrained\n\n\n\n\nlog(GDPpc)\n\n\n0.449\n\n\n0.449\n\n\n0.449\n\n\n0\n\n\n1\n\n\n0\n\n\nConstrained\n\n\n\n\nlog(Older)\n\n\n-0.676\n\n\n-0.676\n\n\n-0.676\n\n\n0\n\n\n0\n\n\n1\n\n\nConstrained\n\n\n\n\nlog(Density)\n\n\n-0.212\n\n\n-0.105\n\n\n0.143\n\n\n15\n\n\n3\n\n\n12\n\n\nNon-constrained\n\n\n\n\nTransit\n\n\n0.341\n\n\n0.528\n\n\n0.606\n\n\n10\n\n\n2\n\n\n18\n\n\nNon-constrained\n\n\n\n\nlog(Humidity)\n\n\n-1.935\n\n\n-0.435\n\n\n0.054\n\n\n11\n\n\n4\n\n\n15\n\n\nNon-constrained\n\n\n\n\nlog(Temperature)\n\n\n-1.904\n\n\n-1.236\n\n\n-0.817\n\n\n0\n\n\n0\n\n\n30\n\n\nNon-constrained\n\n\n\n\nlog(Sunshine)\n\n\n-0.187\n\n\n0.099\n\n\n0.189\n\n\n6\n\n\n0\n\n\n24\n\n\nNon-constrained\n\n\n\n\nSpatially lagged y (rho)\n\n\n0.014\n\n\n0.154\n\n\n0.348\n\n\n14\n\n\n3\n\n\n13\n\n\nNon-constrained\n\n\n\n\n\n\nNote: \n\n\n\n\n Significance: This is the number of coefficients with\np-values as indicated\n\n\n\n\n Non-constrained: coefficient was allowed to vary across\nequations\n\n\n\n\n Constrained: coefficient as constant across equations\n\n\n\n\nTo better understand the results, we proceed to plot the coefficients in\ntheir temporal sequence. At this point it is worth recalling that the\nstate of emergency went into effect on March 14. In the following\nfigures, the periods of time indicated in yellow starting on March 14\ncorrespond to the state of emergency, with only essential travel and\nselected industrial activities allowed; the period of time in orange was\nthe stricter lockdown when only essential travel was allowed.\nWe begin our discussion with the evolution of the spatial\nautocorrelation coefficient ((\\rho)) in Figure  (left panel). We\nnotice that the magnitude of the spatial autocorrelation coefficient\n(\\rho) declines over the period under analysis, and is not significant\nfor some days. This is an interesting result: immediately prior to the\ndeclaration of the state of emergency, there appears to have been a\nstrong inter-provincial contagion effect. Keeping in mind that the\nincubation period ranges between 2 and 12 days with a median of 5, it is\nreasonable to expect that the effect of the lockdown will be observed\nwith some delay. Indeed, as seen in the figure, the autocorrelation\ncoefficient remains high for several days, then begins to decline around\nMarch 23, and continues to weaken over time. At the end of the period\nunder examination, the strength of this effect is much diminished and we\nwould expect that under full compliance with strict lockdown conditions\n(meaning no inter-provincial mobility) the spatial contagion effect\nwould be zero - as seems to be the case.\nThe intercept (right panel in Figure ) is indicative of the variation of\nthe incidence of COVID-19, other things being equal. Here we see that at\nthe incidence declines somewhat immediately after the state of\nemergency, only to begin increasing again over time. Then, the incidence\ndeclines again after the stricter lockdown and rebounds to a lower level\nby April 11.\n\nFigure  shows the temporal evolution of the coefficients for the two\ncontrol variables that were not fixed over time, i.e., (\\log(Density))\n(left panel) and (Transit) (right panel).\nIn Section  we had anticipated a positive sign for the coefficient of\ndensity, and indeed, at the beginning of the period the coefficient is\npositive, albeit not significant, and then remains mostly\nnon-significant for the earlier part of the lockdown. We are somewhat\nsurprised by the way this coefficient turns significant and negative\nin the later part of the lockdown, after April 1st. This effect, we\nsurmise, is the result of risk compensation, a situation where people\nadapt their behavior according to the perceived level of risk,\nbecoming more careful when the perceived risk is higher and viceversa\n(e.g., Noland 1995; Richens, Imrie, and Copas 2000; Phillips, Fyhri, and\nSagberg 2011). Consequently, residents in high density regions may\nperceive the risk of infection as being higher, and adapt their behavior\naccordingly - while the opposite may be true of residents in low density\nregions. The coefficient for Transit is positive, as expected, but with\nvery wide confidence intervals, and in fact not significant in the\nearlier part of the period.\n\nThe evolution of the coefficients for the three environmental variables\nis shown in Figure . Despite a mostly positive simple correlation with\nincidence (see Figure ) once that we control for other factors, humidity\nhas a negative association with incidence of COVID-19 in Spain\n(top-right panel). This is in line with the literature that describes\nthe lower viability and transmission of different viruses at higher\nlevels of humidity. The coefficients for temperature (top-right panel)\nare consistently negative and this variable is, besides the intercept,\nthe only one with significant coefficients in all equations. The range\nof variation of this coefficient during the period examined is\napproximately between -1 and -2, although it is important to recall that\nthese values should not be interpreted directly as effects; more on this\nbelow. Finally the plot for the coefficients associated with hours of\nsunshine (bottom panel) is more ambiguous: prior to the lockdown, the\ncoefficient was negative, but not significant. However, five days into\nthe lockdown, the coefficient becomes significant and positive. This\nresult stands in contrast to previous findings regarding influenza,\nwhere more hours of sunlight reduced the strength and duration of\nepidemic durations (Yu et al. 2013). A difference with previous studies\nis the temporal scale of the analysis: where Yu et al.\u00a0(2013) use\nmonthly averages, we use daily data for a much shorter period of time.\nThe positive sign of sunshine may well be another instance of behavioral\nadaptations, whereby compliance with lockdown orders weakens on sunny\ndays.\n\nThe preceding discussion helps to establish the inferential\ncontributions of the analysis, and indicate which variables display\nsignificant statistical associations with incidence of COVID-19. The\nremaining question is, what are the implications.\nAs discussed in Section  the effect of a variable is not clear from its\ncoefficient alone, since a change to a variable in a province\ninfluences, via the contagion effect, its neighbors. For this reason,\nthe appropriate way to estimate the effects is to calculate both the own\neffect and the effect due to contagion, or in other words the direct and\nindirect effects, respectively. The total effect is the sum of the two.\nA summary of the effects appears in Table . All effects in the table are\ninterpreted as percentage change in the incidence of COVID-19 as a\nconsequence of a one percent change in the variable. The exception to\nthis is Transit (which was not log-transformed). This variable instead\nrepresents the percentage change in incidence between provinces without\nand with mass transit systems.\nTwo variables had temporally constrained coefficients. The estimated\neffect of GDP per capita is to increase the incidence of COVID-19 by\n0.449% for each percent increase of this variable (in \u20ac1,000s). In our\nview, this is a measure of inertia, as provinces with higher GDP per\ncapita where among the first to see exponential growth in the pandemic.\nPercentage of older adults has a negative effect, and each percent\nincrease in this variable is associated with a relatively small\nreduction of the incidence of approximately 0.67%.\nThe temporal variation of the effects for the rest of the variables is\nshown in Figure . The largest positive direct effect is Transit, and the\nlargest direct negative effects are temperature and humidity. The direct\neffects of these variables are as follows: for each percent point\nincrease in temperature, there is between a 1% and 2% reduction in the\nincidence of the disease. This effect is compounded via contagion, as\nseen in the central panel in the figure, and the indirect effect can\nfurther reduce the incidence by up to 0.75%. The effect of humidity is\nalso to reduce the incidence: each percent point of increase in humidity\nis associated with a reduction of up to 2% in incidence. With the\naddition of the indirect effect, the total effect of a 1% increase in\nhumidity is to reduce incidence by up to 3%. As seen in the figure, the\nindirect (i.e., contagion) effects are stronger at the before and at the\nbeginning of the lockdown period. Nonetheless, by the end of the period\nunder study, the indirect effects have weakened considerably.\nWhat do these effects mean? Under a situation of lockdown,\ninter-regional contagion is reduced, as expected, and the total effects\nof the variables tend towards their direct effects. In the first few\ndays covered by our analysis the total effect of all variables is\ngreater due to the spatial contagion effect. Contagion makes analysis\nand intervention more complex: the contagion effect essentially acts\nlike a multiplier, whereby developments in each province spill over to\ntheir neighbors. Once the contagion effect has been tamed, each province\ncan be \u201ctreated\u201d independently from its neighbors.\nIt is important, before concluding our discussion, to highlight some\nlimitations of this study.\nFirst, the analysis was conducted mostly under a situation of lockdown,\nand therefore, besides first days of the period examined, one must\nexercise caution when trying to extrapolate the findings to a situations\nwithout lockdown. Secondly, it is well known that there is in many\ncountries substantial underreporting of cases of COVID-19 due to limited\ntesting. In this case we do not suspect systematic provincial bias in\nreporting, and as long as the underreporting is consistent across units\nof analysis, we do not expect biased results; it is still important,\nhowever, to remain aware that the number of true cases is likely higher.\nFinally, we defined neighborhoods based on adjacency. It would be\ninteresting to compare adjacency to other connectivity criteria, for\ninstance based on domestic transportation instrastructure and services.\nWe flag this as a matter for future research.\n\nSummary of direct, indirect, and total effects according to best model\n(lag8: lagged 8-day moving average)\n\n\n\nVariable\n\n\nMin\n\n\nMean\n\n\nMax\n\n\nNote\n\n\n\n\n\n\nDirect Effects\n\n\n\n\nlog(GDPpc)\n\n\n0.457\n\n\n0.457\n\n\n0.457\n\n\nConstrained\n\n\n\n\nlog(Older)\n\n\n-0.689\n\n\n-0.689\n\n\n-0.689\n\n\nConstrained\n\n\n\n\nlog(Density)\n\n\n-0.213\n\n\n-0.106\n\n\n0.145\n\n\nNon-constrained\n\n\n\n\nTransit\n\n\n0.349\n\n\n0.532\n\n\n0.608\n\n\nNon-constrained\n\n\n\n\nlog(Humidity)\n\n\n-1.971\n\n\n-0.440\n\n\n0.054\n\n\nNon-constrained\n\n\n\n\nlog(Temperature)\n\n\n-1.940\n\n\n-1.245\n\n\n-0.825\n\n\nNon-constrained\n\n\n\n\nlog(Sunshine)\n\n\n-0.191\n\n\n0.099\n\n\n0.190\n\n\nNon-constrained\n\n\n\n\nIndirect Effects\n\n\n\n\nlog(GDPpc)\n\n\n0.165\n\n\n0.165\n\n\n0.165\n\n\nConstrained\n\n\n\n\nlog(Older)\n\n\n-0.248\n\n\n-0.248\n\n\n-0.248\n\n\nConstrained\n\n\n\n\nlog(Density)\n\n\n-0.075\n\n\n-0.015\n\n\n0.052\n\n\nNon-constrained\n\n\n\n\nTransit\n\n\n0.008\n\n\n0.097\n\n\n0.239\n\n\nNon-constrained\n\n\n\n\nlog(Humidity)\n\n\n-0.711\n\n\n-0.104\n\n\n0.001\n\n\nNon-constrained\n\n\n\n\nlog(Temperature)\n\n\n-0.700\n\n\n-0.238\n\n\n-0.013\n\n\nNon-constrained\n\n\n\n\nlog(Sunshine)\n\n\n-0.069\n\n\n0.016\n\n\n0.063\n\n\nNon-constrained\n\n\n\n\nTotal Effects\n\n\n\n\nlog(GDPpc)\n\n\n0.622\n\n\n0.622\n\n\n0.622\n\n\nConstrained\n\n\n\n\nlog(Older)\n\n\n-0.937\n\n\n-0.937\n\n\n-0.937\n\n\nConstrained\n\n\n\n\nlog(Density)\n\n\n-0.265\n\n\n-0.121\n\n\n0.198\n\n\nNon-constrained\n\n\n\n\nTransit\n\n\n0.466\n\n\n0.629\n\n\n0.847\n\n\nNon-constrained\n\n\n\n\nlog(Humidity)\n\n\n-2.683\n\n\n-0.543\n\n\n0.055\n\n\nNon-constrained\n\n\n\n\nlog(Temperature)\n\n\n-2.640\n\n\n-1.483\n\n\n-0.870\n\n\nNon-constrained\n\n\n\n\nlog(Sunshine)\n\n\n-0.259\n\n\n0.116\n\n\n0.235\n\n\nNon-constrained\n\n\n\n\n\n\nNote: \n\n\n\n\n Non-constrained: coefficient was allowed to vary across\nequations\n\n\n\n\n Constrained: coefficient as constant across equations\n\n\n\n\n\nConcluding Remarks\nIn this paper we presented a spatio-temporal analysis of incidence of\nCOVID-19 in Spain. The analysis covers a 30-day period that begins\nimmediately before the state of emergency was declared in the country.\nThe focus of the research has been on the environmental correlates of\nincidence of the disease. There is a need for more empirical evidence,\nas policy makers, public health practitioners, and the public begin\nplanning for the months ahead at this early stage of the pandemic.\nOur results offer strong support for the hypothesis that incidence of\nCOVID-19 at the population level is lower at higher temperatures and\nlevels of humidity: the estimated effect is a reduction in the\nneighborhood of 3% percent in incidence per each 1% increase in\ntemperature, and a 3% reduction in incidence per 1% increase in humidity\nunder conditions of contagion. These reductions are lower when\ncontagion has ceased (i.e., due to lockdown conditions). The question\nhere seems to be whether these environmental variables can yield a\nbigger reduction of more cases, or a smaller reduction of fewer\ncases.\nOur control variables also offer some interesting insights. In\nparticular, there is evidence of behavioral adaptations during lockdown\nin the form of risk compensation (density) and compliance with the\nlockdown (sunshine). These results offer a cautionary tale with regards\nto the effectiveness of the lockdown in more dense areas, and also the\nimplications for compliance with stay-at-home orders as the northern\nhemisphere moves towards summer and more hours of sunshine during the\nday. If risk compensation is a factor, then efforts should be made to\nreduce or eliminate risk compensation in less densely populated regions.\nA key aspect of the analysis using spatial SUR models is that we were\nable to model incidence of COVID-19 as an interregional contagion\nprocess. Here, we find that the strength of the contagion effect was\ndramatically reduced by the lockdown.\nNeedless to say, the analysis presented here is at the level of\npopulation health. For this reason, the analysis does not make any\nclaims with respect to the effect of ultraviolet light on the virus, but\nrather about transmission of the virus in the population. For example,\nthe analysis does not imply that the virus moves less effectively in\nplaces where more people live in close proximity to each other, but\nrather that humans are more contagious when they feel safe in less dense\nregions. Similarly, more sunshine does not mean that the virus thrives,\nbut rather that humans are more contagious to each other when their\nbehavior adapts to this environmental condition.\nSome directions for future research include investigating other\nmodelling frameworks, such as geographically and temporally weighted\nregression and\/or space-time conditional autoregressive models. In\naddition, the environmental variables examined here relate to\nmeteorological conditions only, and did not include other environmental\nfactors that may incide in the transmission of the virus, such as\npollution. These other factors should be incorporated in future studies.\nAcknowledgments\nFernando A. L\u00f3pez is supported by the program Groups of Excellence of\nthe Region of Murcia, Fundaci\u00f3n S\u00e9neca, Science and Technology Agency of\nthe region of Murcia project 19884\/GERM\/15. Tatiane Menezes, Renata\nCavalcanti, and Maira Galdino da Rocha Pitta are supported by Brazil\u2019s\nConselho Nacional de Desenvolvimento Cient\u00edfico e Tecnol\u00f3gico (CNPq) and\nCoordena\u00e7\u00e3o de Aperfei\u00e7oamento de Pessoal de N\u00edvel Superior (Funda\u00e7\u00e3o\nCapes). Antonio P\u00e1ez is not supported by Canada\u2019s Research Councils. The\nfollowing R packages were used in the course of this investigation and\nthe authors wish to acknowledge their developers: aemet\n(Rodriguez-Sanchez, Balao, and G\u00e1mez 2018), ggthemes (Arnold 2019),\ngridExtra (Auguie 2017), kableExtra (Zhu 2019), knitr (Xie 2014,\n2015), lubridate (Grolemund and Wickham 2011), plm (Millo 2017),\nrticles (Allaire et al. 2020), sf (Pebesma 2018), spdep (Bivand,\nPebesma, and Gomez-Rubio 2013), spsur (Angulo et al. 2020) tidyverse\n(Wickham et al. 2019), units (Pebesma, Mailund, and Hiebert 2016).\nReferences\n\n\nAllaire, JJ, Yihui Xie, R Foundation, Hadley Wickham, Journal of\nStatistical Software, Ramnath Vaidyanathan, Association for Computing\nMachinery, et al. 2020. Rticles: Article Formats for R Markdown.\nhttps:\/\/CRAN.R-project.org\/package=rticles.\n\n\nAngulo, Ana, Fernando A Lopez, Roman Minguez, and Jesus Mur. 2020.\nSpsur: Spatial Seemingly Unrelated Regression Models.\nhttp:\/\/github.com\/rominsal\/spsur.\n\n\nAnselin, Luc. 1988. Spatial Econometrics: Methods and Models. Studies\nin Operational Regional Science. Dordrecht: Kluwer Academic Publishers.\n\n\n\u2014\u2014\u2014. 2016. \u201cEstimation and Testing in the Spatial Seemingly Unrelated\nRegression (Sur).\u201d Geoda Center for Geospatial Analysis; Computation,\nArizona State University. Working Paper 2016-01.\n\n\nAraujo, Miguel B, and Babak Naimi. 2020. \u201cSpread of Sars-Cov-2\nCoronavirus Likely to Be Constrained by Climate.\u201d Journal Article.\nmedRxiv.\n\n\nArnold, Jeffrey B. 2019. Ggthemes: Extra Themes, Scales and Geoms for\n\u2019Ggplot2\u2019. https:\/\/CRAN.R-project.org\/package=ggthemes.\n\n\nAuguie, Baptiste. 2017. GridExtra: Miscellaneous Functions for \"Grid\"\nGraphics. https:\/\/CRAN.R-project.org\/package=gridExtra.\n\n\n\u00c1ngel Sol\u00e1, David E de, Leyao Wang, Marietta V\u00e1zquez, and Pablo A M\u00e9ndez\nL\u00e1zaro. 2020. \u201cWeathering the Pandemic: How the Caribbean Basin Can Use\nViral and Environmental Patterns to Predict, Prepare and Respond to\nCovid\u201019.\u201d Journal Article. Journal of Medical Virology.\n\n\nBivand, Roger S., Edzer Pebesma, and Virgilio Gomez-Rubio. 2013.\nApplied Spatial Data Analysis with R, Second Edition. Springer, NY.\nhttp:\/\/www.asdar-book.org\/.\n\n\nCao, ZhiDong, DaJun Zeng, XiaoLong Zheng, QuanYi Wang, FeiYue Wang,\nJinFeng Wang, and XiaoLi Wang. 2010. \u201cSpatio-Temporal Evolution of\nBeijing 2003 Sars Epidemic.\u201d Journal Article. Science China Earth\nSciences 53 (7): 1017\u201328. https:\/\/doi.org\/10.1007\/s11430-010-0043-x.\n\n\nCasanova, Lisa M, Soyoung Jeon, William A Rutala, David J Weber, and\nMark D Sobsey. 2010. \u201cEffects of Air Temperature and Relative Humidity\non Coronavirus Survival on Surfaces.\u201d Journal Article. Appl. Environ.\nMicrobiol. 76 (9): 2712\u20137.\n\n\nChan, KH, JS Peiris, SY Lam, LLM Poon, KY Yuen, and WH Seto. 2011. \u201cThe\nEffects of Temperature and Relative Humidity on the Viability of the\nSars Coronavirus.\u201d Journal Article. Advances in Virology 2011.\n\n\nCliff, AD, Peter Haggett, and MR Smallman-Raynor. 1998. \u201cDetecting\nSpace\u2014Time Patterns in Geocoded Disease Data. Cholera in London, 1854\nMeasles in the United States, 1962\u201395.\u201d Book Section. In Geomed\u201997,\n13\u201342. Springer.\n\n\nCoelho, Marco Tulio Pacheco, Joao Fabricio Mota Rodrigues, Anderson\nMatos Medina, Paulo Scalco, Levi Carina Terribile, Bruno Vilela, Jose\nAlexandre Felizola Diniz-Filho, and Ricardo Dobrovolski. 2020.\n\u201cExponential Phase of Covid19 Expansion Is Not Driven by Climate at\nGlobal Scale.\u201d Journal Article. medRxiv.\n\n\nD\u0105browska-Leonik, Nel, Ewa Bernatowska, Ma\u0142gorzata Pac, Wiktor Filipiuk,\nJan Mulawka, Barbara Pietrucha, Edyta Heropolita\u0144ska-Pliszka, Katarzyna\nBernat-Sitarz, Beata Wolska-Ku\u015bnierz, and Bo\u017cena Miko\u0142u\u0107. 2018. \u201cVitamin\nd Deficiency in Children with Recurrent Respiratory Infections, with or\nWithout Immunoglobulin Deficiency.\u201d Journal Article. Advances in\nMedical Sciences 63 (1): 173\u201378.\n\n\nDesjardins, MR, A Hohl, and EM Delmelle. 2020. \u201cRapid Surveillance of\nCovid-19 in the United States Using a Prospective Space-Time Scan\nStatistic: Detecting and Evaluating Emerging Clusters.\u201d Journal Article.\nApplied Geography, 102202.\n\n\nDinlen, Nurdan, Aysegul Zenciroglu, Serdar Beken, Arzu Dursun, Dilek\nDilli, and Nurullah Okumus. 2016. \u201cAssociation of Vitamin d Deficiency\nwith Acute Lower Respiratory Tract Infections in Newborns.\u201d Journal\nArticle. The Journal of Maternal-Fetal & Neonatal Medicine 29 (6):\n928\u201332.\n\n\nElhorst, J Paul. 2014. Spatial Econometrics: From Cross-Sectional Data\nto Spatial Panels. Book. Vol. 479. Springer.\n\n\nEsposito, Susanna, and Mara Lelii. 2015. \u201cVitamin d and Respiratory\nTract Infections in Childhood.\u201d Journal Article. BMC Infectious\nDiseases 15 (1): 487.\n\n\nFernandes, Nuno. 2020. \u201cEconomic Effects of Coronavirus Outbreak\n(Covid-19) on the World Economy.\u201d Journal Article. Available at SSRN\n3557504.\n\n\nGolgher, Andr\u00e9 Braz, and Paul R Voss. 2016. \u201cHow to Interpret the\nCoefficients of Spatial Models: Spillovers, Direct and Indirect\nEffects.\u201d Spatial Demography 4 (3): 175\u2013205.\n\n\nGong, Binlei, Shurui Zhang, Lingran Yuan, and Kevin Z Chen. 2020. \u201cA\nBalance Act: Minimizing Economic Loss While Controlling Novel\nCoronavirus Pneumonia.\u201d Journal Article. Journal of Chinese\nGovernance, 1\u201320.\n\n\nGreene, William H. 2003. Econometric Analysis. Pearson Education\nIndia.\n\n\nGrolemund, Garrett, and Hadley Wickham. 2011. \u201cDates and Times Made Easy\nwith lubridate.\u201d Journal of Statistical Software 40 (3): 1\u201325.\nhttp:\/\/www.jstatsoft.org\/v40\/i03\/.\n\n\nHallet, Martin. 2002. \u201cRegional Specialisation and Concentration in the\nEu.\u201d Book Section. In Regional Convergence in the European Union,\n53\u201376. Springer.\n\n\nHarbert, Robert S, Seth W Cunningham, and Michael Tessler. 2020.\n\u201cSpatial Modeling Cannot Currently Differentiate Sars-Cov-2\nCoronavirus and Human Distributions on the Basis of Climate in the\nUnited States.\u201d Journal Article. medRxiv.\n\n\nHu, Hao, Karima Nigmatulina, and Philip Eckhoff. 2013. \u201cThe Scaling of\nContact Rates with Population Density for the Infectious Disease\nModels.\u201d Journal Article. Mathematical Biosciences 244 (2): 125\u201334.\nhttps:\/\/doi.org\/https:\/\/doi.org\/10.1016\/j.mbs.2013.04.013.\n\n\nJaakkola, Kari, Annika Saukkoriipi, Jari Jokelainen, Raija Juvonen,\nJaana Kauppila, Olli Vainio, Thedi Ziegler, Esa R\u00f6nkk\u00f6, Jouni JK\nJaakkola, and Tiina M Ik\u00e4heimo. 2014. \u201cDecline in Temperature and\nHumidity Increases the Occurrence of Influenza in Cold Climate.\u201d Journal\nArticle. Environmental Health 13 (1): 22.\n\n\nJat, Kana Ram. 2017. \u201cVitamin d Deficiency and Lower Respiratory Tract\nInfections in Children: A Systematic Review and Meta-Analysis of\nObservational Studies.\u201d Journal Article. Tropical Doctor 47 (1):\n77\u201384.\n\n\nJones, Kate E., Nikkita G. Patel, Marc A. Levy, Adam Storeygard, Deborah\nBalk, John L. Gittleman, and Peter Daszak. 2008. \u201cGlobal Trends in\nEmerging Infectious Diseases.\u201d Journal Article. Nature 451 (7181):\n990\u201393. https:\/\/doi.org\/10.1038\/nature06536.\n\n\nKissler, Stephen M., Christine Tedijanto, Edward Goldstein, Yonatan H.\nGrad, and Marc Lipsitch. 2020. \u201cProjecting the Transmission Dynamics of\nSars-Cov-2 Through the Postpandemic Period.\u201d Journal Article. Science,\neabb5793. https:\/\/doi.org\/10.1126\/science.abb5793.\n\n\nKudo, Eriko, Eric Song, Laura J Yockey, Tasfia Rakib, Patrick W Wong,\nRobert J Homer, and Akiko Iwasaki. 2019. \u201cLow Ambient Humidity Impairs\nBarrier Function and Innate Resistance Against Influenza Infection.\u201d\nJournal Article. Proceedings of the National Academy of Sciences 116\n(22): 10905\u201310.\n\n\nLancastle, Neil M. 2020. \u201cIs the Impact of Social Distancing on\nCoronavirus Growth Rates Effective Across Different Settings? A\nNon-Parametric and Local Regression Approach to Test and Compare the\nGrowth Rate.\u201d Journal Article. medRxiv.\n\n\nLauer, Stephen A., Kyra H. Grantz, Qifang Bi, Forrest K. Jones, Qulu\nZheng, Hannah R. Meredith, Andrew S. Azman, Nicholas G. Reich, and\nJustin Lessler. 2020. \u201cThe Incubation Period of Coronavirus Disease 2019\n(Covid-19) from Publicly Reported Confirmed Cases: Estimation and\nApplication.\u201d Journal Article. Annals of Internal Medicine.\nhttps:\/\/doi.org\/10.7326\/m20-0504.\n\n\nLauridsen, Jorgen, Mickael Bech, Fernando L\u00f3pez, and Mariluz Mat\u00e9. 2010.\n\u201cA Spatiotemporal Analysis of Public Pharmaceutical Expenditure.\u201d The\nAnnals of Regional Science 44 (2): 299\u2013314.\n\n\nLe Gallo, Julie, and Sandy Dall\u2019Erba. 2006. \u201cEvaluating the Temporal and\nSpatial Heterogeneity of the European Convergence Process, 1980\u20131999.\u201d\nJournal of Regional Science 46 (2): 269\u201388.\n\n\nLeSage, James, and Robert Kelley Pace. 2009. Introduction to Spatial\nEconometrics. Chapman; Hall\/CRC.\n\n\nLewnard, Joseph A., and Nathan C. Lo. 2020. \u201cScientific and Ethical\nBasis for Social-Distancing Interventions Against Covid-19.\u201d Journal\nArticle. The Lancet. Infectious Diseases, S1473\u20133099(20)30190\u20130.\nhttps:\/\/doi.org\/10.1016\/S1473-3099(20)30190-0.\n\n\nL\u00f3pez, Fernando A, Pedro J Mart\u00ednez-Ortiz, and Juan-Gabriel\nCegarra-Navarro. 2017. \u201cSpatial Spillovers in Public Expenditure on a\nMunicipal Level in Spain.\u201d The Annals of Regional Science 58 (1):\n39\u201365.\n\n\nL\u00f3pez, Fernando A, Jes\u00fas Mur, and Ana Angulo. 2014. \u201cSpatial Model\nSelection Strategies in a Sur Framework. The Case of Regional\nProductivity in Eu.\u201d The Annals of Regional Science 53 (1): 197\u2013220.\n\n\nLuo, Shaowen, and Kwok Ping Tsang. 2020. \u201cHow Much of China and World\nGdp Has the Coronavirus Reduced?\u201d Journal Article. Available at SSRN\n3543760.\n\n\nMathyssen, Carolien, Ghislaine Gayan-Ramirez, Roger Bouillon, and Wim\nJanssens. 2017. \u201cVitamin d Supplementation in Respiratory Diseases:\nEvidence from Randomized Controlled Trials.\u201d Journal Article. Polish\nArchives of Internal Medicine 127 (11): 775\u201384.\n\n\nM\u00e4kainen, Tiina M, Raija Juvonen, Jari Jokelainen, Terttu H Harju, Ari\nPeitso, Aini Bloigu, Sylvi Silvennoinen-Kassinen, Maija Leinonen, and\nJuhani Hassi. 2009. \u201cCold Temperature and Low Humidity Are Associated\nwith Increased Occurrence of Respiratory Tract Infections.\u201d Journal\nArticle. Respiratory Medicine 103 (3): 456\u201362.\n\n\nMeijers, Evert, Joris Hoekstra, and Ricardo Aguado. 2008. \u201cStrategic\nPlanning for City Networks: The Emergence of a Basque Global City?\u201d\nJournal Article. International Planning Studies 13 (3): 239\u201359.\nhttps:\/\/doi.org\/10.1080\/13563470802521440.\n\n\nMeng, B., J. Wang, J. Liu, J. Wu, and E. Zhong. 2005. \u201cUnderstanding the\nSpatial Diffusion Process of Severe Acute Respiratory Syndrome in\nBeijing.\u201d Journal Article. Public Health 119 (12): 1080\u20137.\nhttps:\/\/doi.org\/https:\/\/doi.org\/10.1016\/j.puhe.2005.02.003.\n\n\nMillo, Giovanni. 2017. \u201cRobust Standard Error Estimators for Panel\nModels: A Unifying Approach.\u201d Journal of Statistical Software 82 (3):\n1\u201327. https:\/\/doi.org\/10.18637\/jss.v082.i03.\n\n\nM\u00ednguez, Roman, Fernando L\u00f3pez, and Jes\u00fas Mur. 2019. \u201cML Versus Iv\nEstimates of Spatial Sur Models: Evidence from the Case of Airbnb in\nMadrid Urban Area.\u201d The Annals of Regional Science, 1\u201335.\n\n\nMorency, C., A. P\u00e1ez, M. J. Roorda, R. G. Mercado, and S. Farber. 2011.\n\u201cDistance Traveled in Three Canadian Cities: Spatial Analysis from the\nPerspective of Vulnerable Population Segments.\u201d Journal Article.\nJournal of Transport Geography 19 (1): 39\u201350.\n\n\nMoriyama, Miyu, Walter J Hugentobler, and Akiko Iwasaki. 2020.\n\u201cSeasonality of Respiratory Viral Infections.\u201d Journal Article.\nAnnual Review of Virology 7.\n\n\nNational Academies of Sciences, Engineering and Medicine. 2020. Rapid\nExpert Consultation on Sars-Cov-2 Survival in Relation to Temperature\nand Humidity and Potential for Seasonality for the Covid-19 Pandemic\n(April 7, 2020). Book. Washington, DC: The National Academies Press.\nhttps:\/\/doi.org\/doi:10.17226\/25771.\n\n\nNoland, R. B. 1995. \u201cPerceived Risk and Modal Choice - Risk Compensation\nin Transportation System.\u201d Journal Article. Accident Analysis and\nPrevention 27 (4): 503\u201321.\nhttps:\/\/doi.org\/10.1016\/0001-4575(94)00087-3.\n\n\nPebesma, Edzer. 2018. \u201cSimple Features for R: Standardized Support for\nSpatial Vector Data.\u201d The R Journal 10 (1): 439\u201346.\nhttps:\/\/doi.org\/10.32614\/RJ-2018-009.\n\n\nPebesma, Edzer, Thomas Mailund, and James Hiebert. 2016. \u201cMeasurement\nUnits in R.\u201d R Journal 8 (2): 486\u201394.\nhttps:\/\/doi.org\/10.32614\/RJ-2016-061.\n\n\nPerez, Liliana, and Suzana Dragicevic. 2009. \u201cAn Agent-Based Approach\nfor Modeling Dynamics of Contagious Disease Spread.\u201d Journal Article.\nInternational Journal of Health Geographics 8 (1): 50.\n\n\nPhillips, R. O., A. Fyhri, and F. Sagberg. 2011. \u201cRisk Compensation and\nBicycle Helmets.\u201d Journal Article. Risk Analysis 31 (8): 1187\u201395.\nhttps:\/\/doi.org\/10.1111\/j.1539-6924.2011.01589.x.\n\n\nPrem, Kiesha, Alex R Cook, and Mark Jit. 2017. \u201cProjecting Social\nContact Matrices in 152 Countries Using Contact Surveys and Demographic\nData.\u201d PLoS Computational Biology 13 (9): e1005697.\n\n\nRey, Sergio J, and Brett D Montouri. 1999. \u201cUS Regional Income\nConvergence: A Spatial Econometric Perspective.\u201d Regional Studies 33\n(2): 143\u201356.\n\n\nRichens, J., J. Imrie, and A. Copas. 2000. \u201cCondoms and Seat Belts: The\nParallels and the Lessons.\u201d Journal Article. Lancet 355 (9201):\n400\u2013403. https:\/\/doi.org\/10.1016\/s0140-6736(99)09109-6.\n\n\nRodriguez-Sanchez, Francisco, Francisco Balao, and David G\u00e1mez. 2018.\nAemet: Obtain Climatic and Meteorological Data from Spanish\nMeteorological Agency (Aemet). https:\/\/github.com\/SevillaR\/aemet.\n\n\nRoorda, M. J., A. Paez, C. Morency, R. Mercado, and S. Farber. 2010.\n\u201cTrip Generation of Vulnerable Populations in Three Canadian Cities: A\nSpatial Ordered Probit Approach.\u201d Journal Article. Transportation 37\n(3): 525\u201348. https:\/\/doi.org\/10.1007\/s11116-010-9263-3.\n\n\nSikder, S., and A. R. Pinjari. 2012. \u201cImmobility Levels and Mobility\nPreferences of the Elderly in the United States Evidence from 2009\nNational Household Travel Survey.\u201d Journal Article. Transportation\nResearch Record, no. 2318: 137\u201347. https:\/\/doi.org\/10.3141\/2318-16.\n\n\nSingh, Rajesh, and R Adhikari. 2020. \u201cAge-Structured Impact of Social\nDistancing on the Covid-19 Epidemic in India.\u201d arXiv Preprint\narXiv:2003.12055.\n\n\nThe Novel Coronavirus Pneumonia Emergency Response Epidemiology Team.\n2020. \u201cThe Epidemiological Characteristics of an Outbreak of 2019 Novel\nCoronavirus Diseases (Covid-19)\u2014China, 2020.\u201d Journal Article. China\nCDC Weekly 2 (8): 113\u201322.\n\n\nVan Wagner, Estair. 2008. \u201cToward a Dialectical Understanding of\nNetworked Disease in the Global City: Vulnerability, Connectivity,\nTopologies.\u201d Journal Article. Networked Disease: Emerging Infections in\nthe Global City, 13\u201326.\n\n\nWang, Jiasheng, Jianhong Xiong, Kun Yang, Shuangyun Peng, and Quanli Xu.\n2010. \u201cUse of Gis and Agent-Based Modeling to Simulate the Spread of\nInfluenza.\u201d Conference Proceedings. In 2010 18th International\nConference on Geoinformatics, 1\u20136. IEEE.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy\nD\u2019Agostino McGowan, Romain Fran\u00e7ois, Garrett Grolemund, et al. 2019.\n\u201cWelcome to the tidyverse.\u201d Journal of Open Source Software 4 (43):\n1686. https:\/\/doi.org\/10.21105\/joss.01686.\n\n\nWilder-Smith, A., and D. O. Freedman. 2020. \u201cIsolation, Quarantine,\nSocial Distancing and Community Containment: Pivotal Role for Old-Style\nPublic Health Measures in the Novel Coronavirus (2019-nCoV) Outbreak.\u201d\nJournal Article. Journal of Travel Medicine 27 (2).\nhttps:\/\/doi.org\/10.1093\/jtm\/taaa020.\n\n\nXie, Yihui. 2014. \u201cKnitr: A Comprehensive Tool for Reproducible Research\nin R.\u201d In Implementing Reproducible Computational Research, edited by\nVictoria Stodden, Friedrich Leisch, and Roger D. Peng. Chapman;\nHall\/CRC. http:\/\/www.crcpress.com\/product\/isbn\/9781466561595.\n\n\n\u2014\u2014\u2014. 2015. Dynamic Documents with R and Knitr. 2nd ed. Boca Raton,\nFlorida: Chapman; Hall\/CRC. https:\/\/yihui.org\/knitr\/.\n\n\nYao, Ye, Jinhua Pan, Zhixi Liu, Xia Meng, Weidong Wang, Haidong Kan, and\nWeibing Wang. 2020. \u201cNo Association of Covid-19 Transmission with\nTemperature or Uv Radiation in Chinese Cities.\u201d Journal Article.\nEuropean Respiratory Journal, 2000517.\nhttps:\/\/doi.org\/10.1183\/13993003.00517-2020.\n\n\nYu, H. J., W. J. Alonso, L. Z. Feng, Y. Tan, Y. L. Shu, W. Z. Yang, and\nC. Viboud. 2013. \u201cCharacterization of Regional Influenza Seasonality\nPatterns in China and Implications for Vaccination Strategies:\nSpatio-Temporal Modeling of Surveillance Data.\u201d Journal Article. Plos\nMedicine 10 (11): 16. https:\/\/doi.org\/10.1371\/journal.pmed.1001552.\n\n\nZellner, Arnold. 1962. \u201cAn Efficient Method of Estimating Seemingly\nUnrelated Regressions and Tests for Aggregation Bias.\u201d Journal of the\nAmerican Statistical Association 57 (298): 348\u201368.\n\n\nZhou, Yanqiu Rachel, and William D Coleman. 2016. \u201cAccelerated Contagion\nand Response: Understanding the Relationships Among Globalization, Time,\nand Disease.\u201d Journal Article. Globalizations 13 (3): 285\u201399.\n\n\nZhu, Hao. 2019. KableExtra: Construct Complex Table with \u2019Kable\u2019 and\nPipe Syntax. https:\/\/CRAN.R-project.org\/package=kableExtra.\n\n\nZittermann, Armin, Stefan Pilz, Harald Hoffmann, and Winfried M\u00e4rz.\n2016. \u201cVitamin d and Airway Infections: A European Perspective.\u201d Journal\nArticle. European Journal of Medical Research 21 (1): 14.\n\n\n","173":"SCEE WEBSITE\nThis goal of this repo is to make and maintain the SCEE Website.\nSociety of Civil and Environmental Engineering (SCEE) is the oldest and largest technical society of Delhi Technological University.\nFront-end\nThe front-end will be carried out using Bootstrap.\nA lot of front-end tasks have been done and a lot are still left.\nThis website needs to be completed by the end of October!\nBack-end\nThere is not much backend work here.\nBackend includes counting the number of visitors and an emailer to send emails regarding new updates in the blogs.\nWe are using Flask at our backend.\nBackend needs special attention.\nContributions\nAny and all contributions are welcome! :)\nFor Contributor Guidelines, have a look here\nSCEE Thanks all of them for their valuable contributions!\nList of all the Contributors\nFollow us on Instagram\nprint(\"Happy Coding!\")\n","174":"View this project on CADLAB.io.\nTinySensors\nSee blog articles.\n\nhub: lightweight Raspberry Pi server-side for TinySensor\nsensing: Database viewer\neagle: TinySensor Eagle project\n\nSoftware\n\n\nArduino\n\nIDE version 1.8.9 or uC-Makefile\nATtiny core\nnRF24 library\nDHT22 library, slimmed-down for ATtiny\n\n\n\nRaspberry-Pi\n\nTested on Raspberry Pi 2 and Raspberry Pi 3 Model B\nnRF24 library\nBCM2835 library\nlibmosquitto-dev\nlcdproc\n\n\n\nViewer\n\nLeiningen v2.0, or\nIntelliJ with the\nCursive plugin\n\n\n\n","175":"WorldGrids\nCode documenting generation of global rasters (various environmental layers) published on WorldGrids.org\n","176":"blockCV \n\n\n\n\n\n\n\nSpatial and environmental blocking for k-fold cross-validation\nIn a nutshell, package blockCV provides functions to build train and test data sets using three general strategies: buffers, spatial and environmental blocks. It offers several options for how those blocks are constructed and how blocks are allocated to cross-validation folds. It includes a function that applies geostatistical techniques to investigate the existing level of spatial autocorrelation in the chosen predictor variables to inform the choice of the block and buffer size. In addition, visualization tools further aid the selection of block size and provide an understanding of the spread of species data across generated folds.\nFeatures\nCompared to other available packages, blockCV provides more strategies and control over fold generation including:\n\nThere are three blocking methods: buffers, spatial and environmental blocks\nThe assignment of the spatial blocks to cross-validation folds can be done in three different ways: random, systematic and checkerboard pattern\nThe spatial blocks can be assigned to cross-validation folds to have evenly distributed records for binary (e.g. species presence-absence\/background) or multi-class responses (e.g. land cover classes for remote sensing image classification)\nThe position of the spatial blocks can be modified\nThe buffering function can account for presence-absence and presence-background data types\nThe variables are standardized to avoid wide range variables to dominate the environmental blocks\nUsing geostatistical techniques to inform the choice of a suitable distance band by which to separate the data sets\n\nInstallation\nTo install the package from GitHub use:\nremotes::install_github(\"rvalavi\/blockCV\", dependencies = TRUE)\nOr installing from CRAN:\ninstall.packages(\"blockCV\", dependencies = TRUE)\nVignette\nTo see the vignette of the package use:\nbrowseVignettes(\"blockCV\")\nThe vignette is also available via this link.\nBasic usage\nThe following is an example of using spatial block cross-validation for evaluation of species distribution modelling. You can find a comprehensive tutorial in the vignette of the package.\n# loading the package\nlibrary(blockCV)\n\n# spatial blocking by specified range and random assignment\nsb <- spatialBlock(speciesData = pa_data, # sf or SpatialPoints\n                   species = \"Species\", # the response column (binomial or multi-class)\n                   rasterLayer = myrasters, # a raster for background (optional)\n                   theRange = 70000, # size of the blocks in meters\n                   k = 5, # number of folds\n                   selection = \"random\",\n                   iteration = 100, # find evenly dispersed folds\n                   biomod2Format = TRUE)\n\n\n# investigate spatial autocorrelation in raster covariates\n# this helps to choose a suitable size for spatial blocks\nspatialAutoRange(rasterLayer = myrasters, # rasterStack file\n                 sampleNumber = 5000, # number of cells to be used\n                 doParallel = TRUE,\n                 showPlots = TRUE)\n\n# alternatively, you can manually choose the size of spatial blocks \nrangeExplorer(rasterLayer = myrasters,\n              speciesData = pa_data, # response data (optional)\n              species = \"Species\" # the responcse column (optional)\n              minRange = 30000, # limit the search domain\n              maxRange = 100000)\n\n\nCitation\nTo cite package blockCV in publications, please use:\nValavi R, Elith J, Lahoz-Monfort JJ, Guillera-Arroita G. blockCV: An R package for generating spatially or environmentally separated folds for k-fold cross-validation of species distribution models. Methods Ecol Evol. 2019; 10:225\u2013232. https:\/\/doi.org\/10.1111\/2041-210X.13107\n","177":"TFNet-for-Environmental-Sound-Classification\nby Helin Wang, Yuexian Zou, Dading Chong, Wenwu Wang\nAbstract\nConvolutional neural networks (CNN) are one of the best-performing neural network architectures for environmental sound classification (ESC). Recently, attention mechanisms have been used in CNN to capture the useful information from the audio signal for sound classification, especially for weakly labelled data where the timing information about the acoustic events is not available in the training data, apart from the availability of sound class labels. In these methods, however, the inherent time-frequency characteristics and variations are not explicitly exploited when obtaining the deep features. In this paper, we propose a new method, called time-frequency enhancement block (TFBlock), which temporal attention and frequency attention are employed to enhance the features from relevant frames and frequency bands. Compared with other attention mechanisms, in our method, parallel branches are constructed which allow the temporal and frequency features to be attended respectively in order to mitigate interference from the sections where no sound events happened in the acoustic environments. The experiments on three benchmark ESC datasets show that our method improves the classification performance and also exhibits robustness to noise.\nIntroduction\nThis repository is for the ICME 2020 paper (submitted), 'Learning discriminative and robust time-frequency representations for environmental sound classification'.\nOur network\n\n","178":"LBLRTM\n\nContents\n\nIntroduction\nCloning the Latest Release\nLBLRTM and Docker\nGeneral LNFL\/LBLRTM File Information\n\nPlatforms on which LBLRTM can be run\nIssues relating to unformatted files on UNIX and LINUX systems\nLNFL\/LBLRTM Naming Convention\nLNFL\/LBLRTM Input File (TAPE5) Format\nLBLRTM Output File Format\n\n\nInstructions and Tips for Running LNFL\n\nInput files for LNFL\nOutput files for LNFL\nSequence for running LNFL\n\n\nInstructions and Tips for Compiling and Running LBLRTM\n\nRequired input files for LBLRTM\nLayer numbering scheme\nOutput files for LBLRTM\nSequence for running LBLRTM\n\n\nTests\nFrequently Asked Questions\n\nIntroduction \nLBLRTM (Line-By-Line Radiative Transfer Model) is an accurate and efficient line-by-line radiative transfer model derived from the Fast Atmospheric Signature Code (FASCODE). LBLRTM has been, and continues to be, extensively validated against atmospheric radiance spectra from the ultraviolet to the sub-millimeter.\nThe HITRAN database provides the basis for the line parameters used in LBLRTM. These line parameters, as well as additional line parameters from other sources, are extracted for use in LBLRTM by a line file creation program called LNFL. A line parameter database built from HITRAN and suitable for use with LNFL can be downloaded with the AER Line File retrieval code or directory from the Zenodo repository.\nLBLRTM uses the line parameters and MT-CKD continuum in its calculations. The models and data are thus linked. For the latest release, the relationships are:\n\n\n\nLBLRTM Release\nMT_CKD Release\nLine File\n\n\n\n\nv12.10\nv3.4\nv3.8\n\n\n\nIf any build or run issues occur, please create an issue or contact the AER-RC Group.\n[Add plantUML diagram]\nFor more, please see the Wiki page\nCloning the Latest Release \nAssuming the output directory should be LBLRTM:\n% git clone --recursive git@github.com:AER-RC\/LBLRTM.git\n\n--recursive is important, because this repository is linked with our common FORTRAN modules repository that are required in the model builds. The cross section database is also added as a submodule (it is not required for all model runs). If this keyword is forgotten, one can do:\ngit submodule init\ngit submodule update\n\nin the LBLRTM directory.\nCurrently, the latest release is LBLRTM v12.10, and it is recommended that this be the version that users clone and checkout (rather than the master branch). To do this, one needs to simply checkout the v12.10 tag:\ngit checkout tags\/v12.10\n\nNo releases before v12.9 are available via GitHub, but they can be requested by contacting the AER-RC Group. For information on previous releases, please visit the What's New Wiki page.\nInstead of cloning, users can also download an LBLRTM tarball and unpack it:\ntar xvf lblrtm_v12.10.tar.gz\nmv LBLRTM-12.10\/ lblrtm\n\nThough not necessary, the move to lblrtm is for consistency with previous release packages and the associated documentation.\nLBLRTM and Docker \nMore doc to come, but see the GitHub package page for Docker image pull directions. And to run:\ndocker pull docker.pkg.github.com\/aer-rc\/lblrtm\/lblrtm:latest\n\ndocker tag docker.pkg.github.com\/aer-rc\/lblrtm\/lblrtm:latest lblrtm\n\ndocker run -it --rm -v ~\/Work\/RC\/LBLRTM\/LBL_In:\/LBLRTM\/LBLRTM_In -v ~\/Work\/RC\/LBLRTM\/LBL_Out:\/LBLRTM\/LBLRTM_Out lblrtm\n\nVolume mounts are necessary to provide LBLRTM inputs and for the user to have access to the outputs. Currently, the TAPE3, TAPE5, and cross section database are assumed to be in the LBLRTM input directory. EMISSIVITY and REFLECTIVITY could conceivably work with the correct volume mounts. Cross sections will be their own submodule at some point. The LBLRTM input file naming convention is assumed.\nGeneral LNFL\/LBLRTM File Information \nPlatforms on which LBLRTM can be run \nIt is recommended that LNFL and LBLRTM be compiled in Fortran 90. LBLRTM has previously been run on DEC alpha, Cray, MS-DOS, and HP platforms.\nSome users have ported the code to the Windows\/DOS environment. AER presently does not officially support this implementation; however, the following description of how LBLRTM was used in XP by a user (Christopher Rice, Air Force Institute of Technology [AFIT]):\n\n\nObtain the newest Intel Fortran Compiler (v 9.1) and Visual Studio.net 2003.\nInstall visual studio .net 2003.\nInstall Intel Fortran Compiler (Fortran compiler options will appear in MSVS 2003 after\nthe Intel Fortran Compiler is installed.\nDecompress source codes for LBLRTM and LNFL into their appropriate folders.\nCompile LNFL:\n\nOpen Visual Studio 2003.\nOpen a new project.\nSelect \u201cIntel Fortran Projects\u201d under \u201cProject Types\u201d and choose \u201cConsole Application\u201d from \u201cTemplates\u201d.\nName this project accordingly. (e.g., LNFL_Exe)\nAfter the project is created a \u201cSolution Explorer\u201d will show the solution named as above. Right click on \u201cSource Files\u201d and add the following files:\n\nlnfl.f90\nutil_dos.f90\n\n\nNote that the util_linux_intel makefile can be used as a reference for the files to be included, replacing util_linux.f90 with the file util_dos.f90.\nMake sure the compiler is set to \u201crelease\u201d NOT \u201cdebug\u201d.\nBuild the Project.\nOn successful build find the .exe in the \u201crelease\u201d folder where the project is saved\n\n\nCompile LBLRTM:\n\nOpen Visual Studio 2003.\nOpen a new project.\nSelect \u201cIntel Fortran Projects\u201d under \u201cProject Types\u201d and choose \u201cConsole Application\u201d from \u201cTemplates\u201d.\nName this project accordingly. (e.g., LBLRTM_Exe)\nAfter the project is created a \u201cSolution Explorer\u201d will show a solution named as above. Right click on \u201cSource Files\u201d and add the following files:\n\ncontnm.f90\nfftscn.f90\nlblatm.f90\nlbldum.f90\nlbllow.f90\nlblrtm.f90\nnonlte.f90\noprop.f90\npltlbl.f90\npostsub.f90\nsolar.f90\ntestmm.f90\nutil_dos.f90\nxmerge.f90\n\n\nNote that the util_linux_intel makefile can be used as a reference for the files to be included, replacing util_linux.f90 with the file util_dos.f90.\nMake sure the compiler is set to \u201crelease\u201d NOT \u201cdebug\u201d \u2013 LBLRTM will not operate correctly when compiled in \u201cDebug\u201d mode.\nBuild the Project.\nOn successful build find the exe in the \u201crelease\u201d folder where the project is saved.\n\n\nUse LNFL with TAPE5 to create TAPE3 as described in the documentation,\nUse TAPE3 with LBLRTM to satisfy your requirements as described in documentation.\n\n\nIssues relating to unformatted files on UNIX and LINUX systems \nUnformatted files are often not compatible between systems due to differences in the way the bytes are written to the files (big-endian versus little-endian).  Note that the byteswap option available with most compilers will not work with most LBLRTM unformatted output files because of the mixing of real and integer data within records.\nLNFL\/LBLRTM Naming Convention \nSpecific information on the input\/output files from LNFL and LBLRTM is located in their respective input files, lnfl_instructions and lblrtm_instructions, and the examples provided in the code tar files.\nMost file names are given as TAPEx where x is a one- or two-digit number.  The name is case-sensitive, and is uppercase.  Tape numbers may be same for LNFL and LBLRTM but do not represent identical files. For example, the primary LNFL input file is TAPE5, and the primary LBLRTM input file is TAPE5.  However, they have neither the same input information nor the same formatting. The instruction manual for each code details the input file information.\nLNFL\/LBLRTM Input File (TAPE5) Format \nThe TAPE5 input files are read as formatted FORTRAN. As a consequence of the formatted read, any blank space will be read as \"zero\".  Thus, one may leave blanks for most of the parameters and within the code they will default to an acceptable value.\nReal numbers format input as either E or F format, with the entire number within the range specified in the input instructions.  Integers must be specified exactly in the integer format.  For example, the spectral bandwidth (v1 to v2) in LBLRTM TAPE5 is input as 10 character real numbers. This means that the value can be written anywhere within these 10 characters, as long as there is a decimal point (e.g. \"---600.000\" or \"-600.000--\", where \"-\" is a blank space).\nIntegers are read in with the I format.  For example, the model atmosphere (iatm) in LBLRTM TAPE5 is input as I5, so it must be \"----2\", and not \"2----\" as this will be read as 20000.\nLBLRTM Output File Format \nThe general structure of the files involves the use of panels, which are blocks of output usually containing 2400 points. Each panel contains a header to describe the starting and ending points of the panel (v1 and v2), the spectral spacing of the points (dvp), and the number of points in the panel (npts). The panel header is followed by either one or two (see below) blocks of output, consisting of npts points.\n[this needs work]\nTAPE12: Radiances and transmittances\n(1) file header\n(2,i)-panel header\n(3,i) radiances\n(4,i) transmittances\nLines 2-4 repeat for i=1,N times to cover the entire spectral region.\nTAPE11: Filtered radiance or transmittance (also applies to any user-designated output file which contains radiances, transmittances, or optical depths, such as the \"ODint\" file)\n(1)file header\n(2,i)-panel header\n(3,i) radiances or transmittances\nLines 2-3 repeat for i=1,N times to cover the entire spectral region.\nNote that a limited amount of spectral output information may also be put in the TAPE6 using the MPTS\/NPTS options of TAPE5 record 1.2.\nInstructions and Tips for Running LNFL \nLNFL is used to generate a unformatted file (TAPE3) of all the line parameters required by LBLRTM.\nInput files for LNFL \n\n\nTAPE1: The line parameter database in ASCII format (downloaded with the AER Line File repository or from Zenodo).\n\n\nTAPE5: LNFL input file.\n\n\nOutput files for LNFL \n\nTAPE3: Unformatted LNFL output file containing the line parameters for LBLRTM.\nTAPE6: Informational output file.\nTAPE7: Optional output file containing ASCII version of the parameters contained in TAPE3.\n\nSequence for running LNFL \n\nClone the latest LNFL code  and download the latest line parameter database with the AER Line File repository or from Zenodo.\nCompile LNFL using the makefiles found in the LNFL tar file.  Note: one needs to compile in the build directory.\nLink the line parameter database to TAPE1 in the LNFL working directory.\nRemove TAPE3 file from the LNFL working directory.\nEdit necessary parameters in the TAPE5 input file.  Note that the beginning and ending wavenumber (v1, v2) in TAPE5 must extend at least 25 cm-1 beyond each end of the desired spectral range for the LBLRTM calculations.\nRun the LNFL executable.\n\nInstructions and Tips for Compiling and Running LBLRTM \nLBLRTM is used to generate line-by-line upwelling and downwelling transmittances and radiances.\nRequired input files for LBLRTM \n\nTAPE3: Unformatted file containing line parameter information, generated by LNFL (see above). The TAPE3 file should include lines from at least 25 cm-1 on either end of the calculation region.\nTAPE5: Input file required to run LBLRTM.\n\nThe spectral interval (v1, v2) for any LBLRTM run must not exceed 2000 cm-1 (see instruction manual).\nOther input files are required if you are using the solar source function, cross sections, surface emissivity, etc. See the LBLRTM instruction manual and provide example.\nLayer numbering scheme \nThe LBLRTM convention is that layer 1 is at the highest pressure level (lowest altitude).  The layer information for a given run may be found in TAPE6.\nOutput files for LBLRTM \n\nTAPE6: Informational output file\nTAPE11: Unformatted file containing filtered output, if requested in TAPE5.\nTAPE12: Unformatted file containing transmittances\/radiances.\n\nASCII file of unformatted unformatted files can be requested in the LBLRTM TAPE5 (see pltlbl variable in Record 12).\nUnformatted optical depth files can be requested in the LBLRTM using options specified in TAPE5.\nSequence for running LBLRTM \n\nClone the latest LBLRTM code and download the latest line parameter database with the AER Line File repository or from Zenodo.\nCompile LBLRTM following makefiles in the LBLRTM tar file. Note, one needs to compile in the build directory\nLink the line parameter database (TAPE3 from LNFL) to the LBLRTM working directory.\nEdit any parameters necessary in the input file TAPE5.\nRun the LBLRTM executable.\n\nTests \nAs of LBLRTM v12.10, a run example package is provided separately from the code repository. It can be used to validate building and running of the model for select atmospheric specifications and model configurations. See README.setup in top level of the package for further direction.\nFrequently Asked Questions \n\nWhat is the difference between a line-by-line calculation and a band-model calculation?\n\nAbsorption\/emission spectra are comprised of a complicated array of spectral lines.  The HITRAN 2008 Database (Version 13.0) contains over 2,713,000 lines for 39 different molecules. In order to resolve these individual lines, a nominal spectral sampling rate of less than the mean line half width must be utilized.  Such highly resolved radiative transfer calculations are called line-by-line (LBL) calculations. The computational time associated with calculating broadband fluxes from LBL calculations is formidable.  A band model aims to simplify radiative transfer calculations by using approximations to represent the line-by-line characteristics of a particular spectral interval.  Band models are appropriate for situations where the desired spectral resolution is much smaller than the Lorentz and Doppler widths of the spectral lines. Such approximations are also of use in general circulation models.\n\nWhat are the standard units used in LBLRTM calculations?\n\n\n\n\nOutput Variable\nUnits\n\n\n\n\nWavenumber\ncm-1\n\n\nRadiance\nW cm-2 sr-1 \/  cm-1\n\n\nBrightness Temperature\nK\n\n\nAnalytic Jacobians (dR\/dx)\nmolecules: W cm-2 sr-1 \/ cm-1 \/ log(VMR)temperature: W cm-2 sr-1 \/ cm-1  \/ K\n\n\n\n\nRadiance Derivatives (Jacobians)\n\nThis section describes the Analytical Jacobian capability in LBLRTM, Version 10.0 and later. The results from earlier versions are not reliable and should NOT be used.\nThe implementation of the analytic Jacobians in LBLRTM has been designed to require a minimal amount of setup on the part of the user while exploiting pre-existing LBLRTM calculation options. There are three steps required to obtain layer and level Analytic Jacobians:\n\n\nCreate the ODint_lll files using IMRG=1 and IOD =3; \"lll\" is the layer number.  Following LBLRTM convention, layer 1 is at the highest pressure level (lowest altitude). The spectral grid for the monochromatic calculation is determined by the DV of the highest layer (DVSET is automatically set by the program).\n\n\nCreate the RDDN_lll files which provide the radiances from the top of the profile to level \"lll\" using IMRG=40 and IOD=3.  Note that the RDDNlayer_001 file is the downwelling radiance at the surface. The ODint files from Step 1 are used for this calculation.\n\n\nCreate the layer and level Analytic Jacobian files in directory AJ; RDderivUPW_xx_lll and LEV_RDderivUPW_xx_lll are the layer and level derivatives files of the upwelling radiance at the upper boundary of the profile (IMRG=41 and IOD=3) taken with respect to state parameter xx. Similarly, the files RDderivDNW_xx_lll and LEV_RDderivDNW_xx_lll are obtained for the downwelling radiance at the lower boundary (IMRG=40 and IOD=3) with the Jacobian taken with respect to state vector\ntype xx where:\n\n\n\nxx = -1 surface parameters\nxx = 0 temperature\nxx = mol molecule number (1-38)\n\nMultiple runs of Step 3 may be performed once Step 1 and Step 2 have been run, the radiometric representation for the Jacobians having been established,\nAll the unformatted files resulting from these operations are fully consistent with LBLRTM files. The layer and level Jacobian files have the Radiance Jacobians in the normal radiance panel and the transmittance from the lowest boundary of the problem to the bottom level of the layer lll in the transmittance panel or to the designated level in the case of level Jacobians. These transmittances are included only to retain consistency with the LBLRTM file structures. Consequently, postprocessing including the application of selected instrument functions is accomplished in a manner identical to that for radiances. Note that selecting brightness temperature in the postprocessing will not provide a meaningful result.  In general, the input parameters for AJ calculations is described in the LBLRTM instructions where the required parameter is described, particularly note RECORD 1.2.b.  The scanmrg option (IMRG=42,43 in this case) has not been tested and should be used with extreme caution.\nFinally, a script has been included with ALL necessary files to run a sample set of Jacobian calculations. A second script has been provided to perform symmetric finite difference calculations to check the AJ results.  A PowerPoint document with plots showing the results from the two scripts has been included. The file lblrtm_AJ_readme.txt explains the two scripts.\n\nIs it possible to scale the profile of one or more species?\n\nYes. The instructions for using this capability are provided in the lblrtm instructions. See records 1.3, 1.3.a and 1.3.b.\n\nDoes LBLRTM include heavy molecule parameters (cross-sectional species)?\n\nHeavy molecules (such as CCL4, F11, and others listed in Table II of the lblrtm_instruction manual) can be included in LBLRTM calculations by setting the IXSECT input variable to 1 and adding Record 2.2 or Record 3.7 to the LBLRTM TAPE5  An additional file (FSCDXS) and directory (xs) are required for these calculations and can be obtained from the cross sections repository (which is cloned with LBLRTM if the directions in the [Cloning][#cloning] section are followed) or from the LBLRTM example tar file (available in the LBLRTM v12.10 Release).\n\nFormat of external surface emissivity\/reflectivity files\n\nSea surface spectral emissivity and reflectivity files are provided with the example (available in the LBLRTM v12.10 Release). The files must have the file names of EMISSIVITY and REFLECTIVITY. The format is as follows:\n\n\n\nParameter\nFormat\nDescription\n\n\n\n\nV1EMIS\nE10.3\nInitial emissivity\/reflectivity frequency value [cm-1]\n\n\nV2EMIS\nE10.3\nFinial emissivity\/reflectivity frequency value [cm-1]\n\n\nDVEMIS\nE10.3\nFrequency Increment [cm-1]\n\n\nNLIMEM\nI5\nNumber of spectral emissivity\/reflectivity points in the file\n\n\nZEMIS\nE15.7\nEmissivity at each spectral point\n\n\n\nNOTE: It is assumed that the spectral emissivity\/reflectivity points are equally spaced and there is a maximum number of points (see instructions).\n\nAbsorption due to clouds\/aerosols and LOWTRAN5 routines\n\nAbsorption due to clouds and aerosols can be computed in LBLRTM by setting the IAERSL flag in the input TAPE5 file (refer to instructions).  This flag allows for LBLRTM to utilize the aerosol capabilities of LOWTRAN5.\n\nSolar Radiance\n\nSolar radiance calculations can be performed by utilizing LBLRTM input options such as IEMIT=2 and a particular solar source function file SOLAR.RAD. A SOLAR.RAD file can be generated with program extract_solar available on the AER RT web site and the Kurucz solar source function.  The Kurucz solar source function has been used in AER\u2019s research in shortwave radiation and is based on theoretical radiative transfer calculations for the solar atmosphere. The solar source function is available is at a high spectral resolution (i.e. for monochromatic calculations) and 1 cm-1 resolution.\n\nLine coupling\/mixing\n\nLine coupling parameters are utilized in LBLRTM for O2, CO2 and CH4. The line coupling parameters are provided in the AER line parameter database (available in the AER Line File repository or on Zenodo) and are written to the line parameter input file (TAPE3) by LNFL.\n\nWhat is the appropriate reference for LBLRTM calculations in journal articles and presentations?\n\nClough SA, Shephard MW, Mlawer EJ, Delamere JS, Iacono MJ, Cady-Pereira K, Boukabara S, Brown PD.Atmospheric radiative transfer modeling: a summary of the AER codes \u2022 SHORT COMMUNICATION\u2022 J Quant. Spectrosc. and Radiat Transfer, 91, 233-244 (2005).\nAlso, please refer to the References Wiki Page for the complete list of references.\n\nHow do you calculate fluxes?\n\nSource code and instructions available: RADSUM\n","179":"README\nThe environmental Benefits Mapping and Analysis Program\u2014Community Edition (BenMAP-CE) is used to conduct air pollution benefits assessment, which is the art and science of applying findings from the epidemiological and economics literature to estimate the health impacts and economic value of air pollution changes. The BenMAP-CE software simplifies this practice by applying the algorithms and data that users need to calculate the quantity, and dollar value, of premature deaths and illnesses associated with changes in air pollution.\nThe BenMAP-CE Database file (while under development) will be maintained separately from this main BenMAP-CE code repository due to large file size.  To acquire the most recently released version of the database, please install BenMAP-CE using the install package available at BenMAP-CE Community Edition.\n","180":"Pura Core staging tree 1.0.0\nhttps:\/\/mypura.io\/\nWhat is Pura ?\nPura is an experimental new digital currency that enables anonymous, instant\npayments to anyone, anywhere in the world. Pura uses peer-to-peer technology\nto operate with no central authority: managing transactions and issuing money\nare carried out collectively by the network. Pura Core is the name of the open\nsource software which enables the use of this currency.\nFor more information, as well as an immediately useable, binary version of\nthe Dash Core software, see https:\/\/mypura.io.\nLicense\nPura Core is released under the terms of the MIT license. See COPYING for more\ninformation or see https:\/\/opensource.org\/licenses\/MIT.\nDevelopment Process\nThe master branch is meant to be stable. Development is normally done in separate branches.\nTags are created to indicate new official,\nstable release versions of Pura Core.\nThe contribution workflow is described in CONTRIBUTING.md.\nTesting\nTesting and code review is the bottleneck for development; we get more pull\nrequests than we can review and test on short notice. Please be patient and help out by testing\nother people's pull requests, and remember this is a security-critical project where any mistake might cost people\nlots of money.\nAutomated Testing\nDevelopers are strongly encouraged to write unit tests for new code, and to\nsubmit new unit tests for old code. Unit tests can be compiled and run\n(assuming they weren't disabled in configure) with: make check\nThere are also regression and integration tests of the RPC interface, written\nin Python, that are run automatically on the build server.\nThese tests can be run (if the test dependencies are installed) with: qa\/pull-tester\/rpc-tests.py\nThe Travis CI system makes sure that every pull request is built for Windows\nand Linux, OS X, and that unit and sanity tests are automatically run.\nManual Quality Assurance (QA) Testing\nChanges should be tested by somebody other than the developer who wrote the\ncode. This is especially important for large or high-risk changes. It is useful\nto add a test plan to the pull request description if testing the changes is\nnot straightforward.\nTranslations\nChanges to translations as well as new translations can be submitted to\nPura Core's Transifex page.\nTranslations are periodically pulled from Transifex and merged into the git repository. See the\ntranslation process for details on how this works.\nImportant: We do not accept translation changes as GitHub pull requests because the next\npull from Transifex would automatically overwrite them again.\nTranslators should also follow the forum.\n","181":"PEAS\nPANOPTES Environmental Analysis System\n\n\u26a0\ufe0f This repository has been merged with POCS. No new development will take place here but the repository is left for historical reasons.\n\n","182":"PEAS\nPANOPTES Environmental Analysis System\n\n\u26a0\ufe0f This repository has been merged with POCS. No new development will take place here but the repository is left for historical reasons.\n\n","183":"Environmental Creepers\nA small mod for Minecraft that allows tweaking some aspects of Creeper explosions and other explosions,\nlike the chance to drop the blocks as items or disable damage to item entities.\nFor more information and the downloads (compiled builds), see http:\/\/minecraft.curseforge.com\/projects\/environmental-creepers\nCompiling\n\nClone the repository\nOpen a command prompt\/terminal to the repository directory\nrun 'gradlew build'\nThe built jar file will be in build\/libs\/\n\n","184":"\nThis is a POC and not currently production ready. Your mileage may vary.\n\nRebaked environmental device management system\nEnvironmental inventory(device) management system built for hundreds of entities, thousands environments, and millions of devices.\n\nRebaked environmental device management system\n\nQuick getting started development guide\n\nBuild a cruton container\nStart cruton and cassandra\nCreate keyspace where the tables will be created.\nSync the tables\n\n\nWorking with the API.\n\nDiscovery\nEntities\n\nHEAD all entities\nPUT an entity\nHEAD an entities\nPOST one or many entities (bulk import)\nGET entities\nGET entities and search\nGET entities and search doing a partial match using provided criteria\n\n\nEnvironments\n\nHEAD all environments\nPUT an environment\nHEAD an environment\nPOST one or many environments (bulk import)\nGET environments\nGET environments and search\nGET environments and search doing a partial match using provided criteria\n\n\nDevices\n\nHEAD all devices\nPUT a device\nHEAD a device\nPOST one or many devices (bulk import)\nGET devices\nGET devices and search\nGET devices and search doing a partial matching using provided criteria\nGET an IPXE return for a specific device\n\n\n\n\nUtilities\n\nSynchronizing the table space with the backend store.\n\n\n\n\n\n\nQuick getting started development guide\nThe following guide will result in a running cruton application.\nRequirements:\n\ndocker\ndocker-compose\n\nBuild a cruton container\ndocker-compose build\n\nStart cruton and cassandra\ndocker-compose up\n\nCreate keyspace where the tables will be created.\nThis setup creates a basic cassandra container with no authentication needed. So we don't need to create a user with a password. We do howerver need to createa keyspace.\ndocker exec -ti cassandra_cruton cqlsh localhost -e \"CREATE KEYSPACE IF NOT EXISTS \"cruton\" WITH REPLICATION = {'class': 'NetworkTopologyStrategy', 'datacenter1': 1};\"\nSync the tables\ndocker exec -ti  cruton_cruton_1 cruton-manage --config-file \/etc\/cruton\/cruton.ini sync_tables\n\n\nWorking with the API.\nTo start the API it's recommended that you run the service behind a webserver like NGINX, Apache, using uWSGI, etc.\nThe typical API process can be envoked by running the cruton-api-wsgi --config-file \/etc\/cruton\/cruton.ini command.\nIf you need or want to run the API in debug mode you can do so by invoking the cruton-api-debug --config-file \/etc\/cruton\/cruton.ini\ncommand.\nDiscovery\ncurl 'http:\/\/127.0.0.1:5150\/dicovery'\nThe API endpoints and all available actions are discoverable. The dicovery endpoint allows the a user or an\napplication to discover all available actions for all available versions.\nEntities\nHEAD all entities\ncurl --head 'http:\/\/127.0.0.1:5150\/v1\/entities'\n\nPUT an entity\ncurl -H 'Content-Type: application\/json' -D - -XPUT 'http:\/\/127.0.0.1:5150\/v1\/entities\/Solo1' -d '{\"name\": \"TestEntitySolo\"}'\nHEAD an entities\ncurl --head 'http:\/\/127.0.0.1:5150\/v1\/entities\/Solo1'\n\nPOST one or many entities (bulk import)\ncurl -H 'Content-Type: application\/json'  -D - -XPOST 'http:\/\/127.0.0.1:5150\/v1\/entities' -d '[{\"ent_id\": \"Ent1\", \"tags\": [\"TestEntityTagOne\"], \"contacts\": {\"person1\": \"4155551212\", \"person2\": \"email@person2.example.com\"}, \"name\": \"TestEntityOne\"}, {\"ent_id\": \"Ent2\", \"tags\": [\"TestEntityTagOne\", \"TestEntityTagTwo\"], \"contacts\": {\"person2\": \"email@person2.example.com\"}, \"name\": \"TestEntityTwo\"}]'\nGET entities\ncurl 'http:\/\/127.0.0.1:5150\/v1\/entities'\nGET entities and search\ncurl -D - 'http:\/\/127.0.0.1:5150\/v1\/entities?contact=person1'\nGET entities and search doing a partial match using provided criteria\ncurl -D - 'http:\/\/127.0.0.1:5150\/v1\/entities?name=EntityTag&fuzzy=true'\nYou should be aware that ANY field in the data module can be part of the search criteria.\nEnvironments\nHEAD all environments\n# HEAD environments root\ncurl --head 'http:\/\/127.0.0.1:5150\/v1\/entities\/Ent1\/environments'\nPUT an environment\ncurl -H 'Content-Type: application\/json' -D - -XPUT 'http:\/\/127.0.0.1:5150\/v1\/entities\/Solo1\/environments\/SoloEnv1' -d '{\"name\": \"SoloEnvironmentOne\"}'\nHEAD an environment\n# HEAD environments root\ncurl --head 'http:\/\/127.0.0.1:5150\/v1\/entities\/Ent1\/environments\/SoloEnv1'\nPOST one or many environments (bulk import)\ncurl -H 'Content-Type: application\/json' -D - -XPOST 'http:\/\/127.0.0.1:5150\/v1\/entities\/Ent1\/environments' -d '[{\"env_id\": \"Env1\", \"tags\": [\"TestEnvironmentTagOne\"], \"contacts\": {\"person1\": \"4155551212\", \"person2\": \"email@person2.example.com\"}, \"name\": \"TestEnvironmentOne\"}, {\"env_id\": \"Env2\", \"tags\": [\"TestEnvironmentTagOne\", \"TestEnvironmentTagTwo\"], \"contacts\": {\"person1\": \"4155551212\"}, \"name\": \"TestEnvironmentTwo\"}]'\nGET environments\ncurl -D - 'http:\/\/127.0.0.1:5150\/v1\/entities\/x\/environments\/Env2'\nGET environments and search\ncurl -D - 'http:\/\/127.0.0.1:5150\/v1\/entities\/x\/environments?contact=person1'\nGET environments and search doing a partial match using provided criteria\ncurl -D - 'http:\/\/127.0.0.1:5150\/v1\/entities\/x\/environments?tag=EnvironmentTag&fuzzy=true'\nYou should be aware that ANY field in the data module can be part of the search criteria.\nDevices\nHEAD all devices\ncurl --head http:\/\/127.0.0.1:5150\/v1\/entities\/Solo1\/environments\/SoloEnv1\/devices\nPUT a device\ncurl -H 'Content-Type: application\/json' -D - -XPUT 'http:\/\/127.0.0.1:5150\/v1\/entities\/Solo1\/environments\/SoloEnv1\/devices\/SoloDev1' -d '{\"name\": \"SoloDeviceOne\"}'\nHEAD a device\ncurl --head http:\/\/127.0.0.1:5150\/v1\/entities\/Solo1\/environments\/SoloEnv1\/devices\/SoloDev1\nPOST one or many devices (bulk import)\ncurl -H 'Content-Type: application\/json' -D - -XPOST 'http:\/\/127.0.0.1:5150\/v1\/entities\/Solo1\/environments\/SoloEnv1\/devices' -d '[{\"dev_id\": \"Dev1\", \"tags\": [\"TestEnvironmentTagOne\"], \"access_ip\": {\"drac\": \"172.16.24.1\", \"mgmt\": \"fe80::6656:fc1d:cd1:ddba\"}, \"rack_id\": \"TestRack1\", \"row_id\": \"TestRow1\", \"name\": \"TestDeviceOne\"}, {\"dev_id\": \"Dev2\", \"tags\": [\"TestDeviceTagOne\", \"TestDeviceTagTwo\"], \"access_ip\": {\"drac\": \"172.16.24.2\", \"mgmt\": \"fe80::6656:fc1d:cd1:ddbb\"}, \"rack_id\": \"TestRack2\", \"row_id\": \"TestRow1\", \"name\": \"TestDeviceTwo\"}]'\nGET devices\ncurl 'http:\/\/127.0.0.1:5150\/v1\/entities\/Solo1\/environments\/SoloEnv1\/devices'\nGET devices and search\ncurl 'http:\/\/127.0.0.1:5150\/v1\/entities\/Solo1\/environments\/SoloEnv1\/devices?row_id=TestRow1'\nGET devices and search doing a partial matching using provided criteria\ncurl 'http:\/\/127.0.0.1:5150\/v1\/entities\/Solo1\/environments\/SoloEnv1\/devices?name=Test&fuzzy=true'\nYou should be aware that ANY field in the data module can be part of the search criteria.\nGET an IPXE return for a specific device\ncurl 'http:\/\/127.0.0.1:5150\/v1\/entities\/TestEntity1\/environments\/TestEnvironment1A\/devices\/TestDevice1A\/ipxe\"\nIf a device has an has variable with \"ipxe_\" as the prefix the ipxe endpoint will return an ipxe config using those variables.\n\nUtilities\nAutomated data population can be simply done using an Ansible playbook. More on helpful playbooks can be found here\nSynchronizing the table space with the backend store.\ncruton-manage --config-file \/etc\/cruton\/cruton.ini sync_tables\n\nAdditional documentation:\n\nData Model\nInstallation\nCassandra\n\n","185":"ENVECON-118\nEnvironmental Economics 118\nLink to notebooks for UC Berkeley users\n\n","186":"ENVECON-118\nEnvironmental Economics 118\nLink to notebooks for UC Berkeley users\n\n","187":"Welcome to the rapidInquiryFacility\nOverview\nThe Rapid Inquiry Facility (RIF) is a freely-available software application that supports two types of environmental health activities:\n\ndisease mapping studies\nrisk analysis studies.\n\nIt is designed to help epidemiologists and public health researchers to rapidly investigate potential environmental hazards, especially those related to industrial sites. It uses health, environmental, socio-economic, population and geographic data to calculate risks in relation to sources of exposure and to generate maps.\nDocumentation\nThe documentation is now available as a GitHub Pages site.\nIf you want to contribute to the documentation, the source files are in the \/docs directory in  this project.\nWiki\nThe old wiki-based documentation has been removed. Everything that was in it has been transferred to the GitHub Pages site.\nProblems\nIf you notice any problems with the documentation, please open an issue explaining what is wrong.\n","188":"TrenchR\n\nan R package for transparent environmental and ecological biophysics\n\nAuthor: TrEnCh project, Buckley Lab, Department of Biology, University of Washington\nLicense: MIT\n\n\nPackage website\nDescription\nThe TrenchR package aids in Translating Environmental Change into organismal responses (https:\/\/github.com\/trenchproject\/TrenchR). The package facilitates microclimate modelling to translate weather station data into the environmental conditions experienced by organisms and biophysical modelling to predict organismal body temperatures given the environmental conditions. The package aims to introduce and enable microclimate and biophysical modelling to improve ecological and evolutionary forecasting and includes tutorials and well as a series of educational modules introducing microclimate and biophysical modelling. The package complements and integrates with the NicheMapR package (https:\/\/github.com\/mrke\/NicheMapR).\nInstallation\nYou can install the package from the github repository:\ninstall.packages(\"devtools\")   \nlibrary(\"devtools\")   \ndevtools::install_github(build_vignettes = TRUE,repo = \"trenchproject\/TrenchR\")\nUsing the package\nThe package encompasses simple functions that can be combined to estimate environmental conditions and their impacts on organisms. Many of the functions are adapted from biophysical ecology texts including the following:\n\nGates DM. Biophysical Ecology.\nCampbell GS and Norman JM. An introduction to environmental biophysics.\n\nPackage Vignette\nWe introduce each function in categorically grouped tutorials.  A good place to start is the Allometry and conversions tutorial, which provides tools for preparing data such as estimating additional dimensions of organisms from measured dimensions.\nvignette(\"AllometryAndConversionsTutorial.Rmd\", package=\"TrenchR\")\n\nThe Estimating microclimates tutorial provides resources for estimating the environmental conditions experienced by organisms.  This includes estimating solar radiation and its components, diurnal variation in temperature and radiation, temperature and wind speed profiles, and soil temperatures and profiles.\nvignette(\"MicroclimateTutorial\", package=\"TrenchR\")\n\nFinally, the core biophysical modelling functions are described in a tutorial on Using energy balances to estimate body temperatures. Components of an energy budget can be estimated using individual functions and then operative environmental temperatures, Te, can be solved for using either a generic energy balance or taxa specific biophysical models.\nvignette(\"TeTutorial\", package=\"TrenchR\")\n\nFuture Directions\nWe welcome code contributions, fixes, and comments. Code (scripts and functions) will be accepted in any programming language and thorough commenting will be appreciated.  We would also appreciate your including a header that describes the intent, input, and output of your scripts and functions.\nCitation\nIf you use this package, We would appreciate a citation. You can see an up to date citation information with citation(\"TrenchR\"). You can cite either the package or the accompanying journal article.\nSetup\nIf you are using macOS, you might need to install R package \"rgl\" which indirectly would ask you to install XQuartz. The reason for it is that there is a dependency for package \"ks\".\nDeveloper notes\nUpdate documentation: devtools::document()\n","189":"Grasp Planner based on Environmental Constraint Exploitation\nCAUTION: If you plan on running a specific branch, please read the README.md in that branch. This README.md is only valid for the current branch.\nTable of Contents\n\nOverview\nStructure, Interfaces and Flow of Information\nList of Controllers, Primitives, ECs\nHardware Dependencies\nInstall\n\nMinimal Dependencies\nDependencies For Running the Gazebo Example\nGrasp Planner\n\n\nUsage\nExamples\n\nPlanning Based on PCD Input\nPlanning Based on Continuous RGB-D Input\nKuka Arm in Gazebo Simulation with TRIK Controller\nUsing rosservice call for planner\n\n\n\n\nOverview \nThis planning framework generates contact-rich motion sequences to grasp objects.\nWithin this planning framework, we propose a novel view of grasp planning that centers on the exploitation of environmental contact.\nIn this view, grasps are sequences of constraint exploitations, i.e. consecutive motions constrained by features in the environment, ending in a grasp.\nTo be able to generate such grasp plans, it becomes necessary to consider planning, perception, and control as tightly integrated components.\nAs a result, each of these components can be simplified while still yielding reliable grasping performance.\nThis implementation is based on:\nClemens Eppner and Oliver Brock. \"Planning Grasp Strategies That Exploit Environmental Constraints\"\nProceedings of the IEEE International Conference on Robotics and Automation (ICRA), pp. 4947 - 4952, 2015.\n\nStructure, Interfaces and Flow of Information \nThis is the structure of the planning framework:\n\nIt consists of a visual processing component and a planning module.\nThe visual processing component detects planar surfaces, convex, and concave edges in a point cloud and represents them in a graph structure.\nThis component is based on Ecto, a computation graph framework for C++\/Python.\nThe computations are organized as a directed acyclic graph of computing cells connected by typed edges.\nSingle computing cells do simple operations such as clustering, segmentation, or fitting models.\nThe following diagram shows the computation graph for the grasp planning framework:\n\nHere, a segmentation soup is generated by different segmentation algorithms based on depth and color. For these segments, planes and edges are fitted. The final output is a geometry graph that describes the spatial structure of the environment.\nThe planning module takes this spatial graph as input and combines it with information about the object pose and the type of robotic hand and arm into a planning problem. This planning problem is represented in a STRIPS-like fashion and solved using A* search. The output of the planner is a sequence of motions interspersed with contact sensor events.\nSumming up, the input to the planning framework is given by:\n\nPoint Cloud: This can be provided either by a real RGB-D sensor (see Example 2), a recorded point cloud (see Example 1), or even by a simulated sensor (see Example 3).\nObject Pose: This is optional and can also be provided by the Ecto graph computation using a simple heuristic: select the point cluster that is closest to the largest planar surface in the scene.\nHand and Robot-specific Information: This defines how a particular hand slides across a surface, closes its fingers etc. It also includes robot-specific things such as f\/t sensor thresholds or velocities. For new hands and\/or arms this can be easily extended.\n\nThe usual output of a robot motion planner are joint-configuration trajectories.\nThis planner is different. It outputs so-called hybrid automata. A hybrid automaton is a finite state machine whose states are continuous feedback controllers (based on position, velocity, force, etc.) and transitions are discrete sensor events.\nThis is because position trajectories lack the expressive power that is needed to capture the feedback-driven contact-rich motions considered here.\nHybrid automata are much more suited in this context.\nAs a consequence any entity that wants to execute the generated plans needs to be capable of interpreting those hybrid automata descriptions. We use a C++ library that allows serialization\/desirialization and can be used to wrap robot-specific interfaces as shown in Example 3.\n\nPrimitives, Controllers, and Jump Conditions:\nList of primitives: Positioning, sliding, Caging, EdgeGrasp, WallGrasp, SurfaceGrasp The primitives are based on Clemens Eppner and Oliver Brock. \"Planning Grasp Strategies That Exploit Environmental Constraints\"\nList of controllers: joint controller, operational space controller, sliding controller, RBO-hand controller, Pisa-IIT-hand controller\nList of jump conditions: time based, F\/T measurement based, joint configuration based, frame pose based\nList of ECs: Surface, Edge, Wall\n\n\nHardware Dependencies\nThis table lists the tested hardware dependencies of the planner by SoMa partner:\nT: tested\nS: tested in simulation (gazebo)\nF: failed\n\n\n\n\nTUB\nUNIPI\nIIT\nOcado\nDisney\n\n\n\n\nHand\nRBO Hand2 (T) Pisa IIT Hand\n\n\nRBO Hand2 (T)Pisa\/IIT HandRBO Hand2 v2 (T)                                                                       Pisa\/IIT Hand v2 Pisa\/IIT Softgripper\n\n\n\nArms\nWAM (T) KUKA iiwa (S)\n\n\nKUKA LBR iiwa14 (T) Staubli RX160L\n\n\n\nForce-Torque Sensor\nATI FTN-Gamma Sensors (T)\n\n\nOptoforce HEX-70-XE-200N (T)\n\n\n\nRGB-D Sensor\nASUS Xtion Pro Live (T)\n\n\nPrimesense Carmine 1.08\/9(T)  Kinect v2\n\n\n\nAPI\nROS\/MoveIt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstall \nThis code was tested with ROS indigo under Ubuntu 14.04.5 (LTS). To follow our build instructions you need to build with catkin tools (apt-get install python-catkin-tools)\nMinimal Dependencies \n\nClone this repository\n\ngit clone https:\/\/github.com\/SoMa-Project\/ec_grasp_planner.git \n\n\nBuild the geometry messages (don't build any other projects form this repository yet)\n\ncatkin build geometry_graph_msgs\n\n\nClone the ROS stack ecto_rbo in your catkin workspace and build it:\n\ngit clone https:\/\/github.com\/SoMa-Project\/vision.git\n\nand follow the instructions on https:\/\/github.com\/SoMa-Project\/vision\/blob\/master\/README.md\n\nGet PyDDL:\n\npip install -e git+https:\/\/github.com\/garydoranjr\/pyddl.git#egg=pyddl\n\n\nGet the ROS package hybrid_automaton_msgs:\n\ngit clone https:\/\/github.com\/tu-rbo\/hybrid_automaton_msgs.git\n\nDependencies For Running the Gazebo Example \n\nGet the ROS package hybrid_automaton_manager_kuka if the Kuka interface is needed:\n\ngit clone https:\/\/github.com\/SoMa-Project\/hybrid_automaton_manager_kuka.git\n\n\nGet Gazebo multi-robot simulator, version 2.2.6:\n\n  sudo apt-get install ros-indigo-gazebo-*\n\n\nGet iiwa_stack:\n\n  git clone https:\/\/github.com\/SalvoVirga\/iiwa_stack.git\n  cd iiwa_stack\n  git checkout 94670d70b9bfbf0920c7de539012c805734fdbc5\n  catkin build iiwa\n\n\n\nGet hybrid_automaton_library and install it by following the readme instructions.\n\n\nBuild hybrid_automaton_manager_kuka according to the instructions (do not forget to link the robot files).\n\n\nGrasp Planner \nNow, you can clone this repository into your catkin workspace and build the ROS package:\ngit clone https:\/\/github.com\/SoMa-Project\/ec_grasp_planner.git\ncd ec_grasp_planner\ngit submodule init\ngit submodule update\ncatkin build ec_grasp_planner\n\n\nStarting the planner node \nplanner.py [-h] [--ros_service_call] [--file_output]\n                [--rviz][--robot_base_frame ROBOT_BASE_FRAME]\n                [--object_frame OBJECT_FRAME] [--object_params_file]\n\nFind path in graph and turn it into a hybrid automaton.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --ros_service_call    Whether to send the hybrid automaton to a ROS service\n                        called \/update_hybrid_automaton. (default: False)\n  --file_output         Whether to write the hybrid automaton to a file called\n                        hybrid_automaton.xml. (default: False)\n  --rviz                Whether to send marker messages that can be seen in\n                        RViz and represent the chosen grasping motion.\n                        (default: False)\n  --robot_base_frame ROBOT_BASE_FRAME\n                        Name of the robot base frame. (default: base_link)\n  --object_frame OBJECT_FRAME\n                        Name of the object frame. (default: object)\n  --object_params_file \n                        Name of the file containing parameters for object-EC selection when multiple objects are present\n                        (default: object_param.yaml)\n\n\nThis will start the planner node which then waits for a service call.\nCalling the service \nStep 1: start the planner in the background in simulation:\nrosrun ec_grasp_planner planner.py --rviz --file_output --robot_base_frame world\nfor the real world demo in the RBO lab use instead:\nrosrun ec_grasp_planner planner.py --rviz --file_output\nStep 2, call the rosservice\nrosservice call \/run_grasp_planner \"object_type: 'Apple' grasp_type: 'SurfaceGrasp' handarm_type: 'RBOHand2Kuka' object_heuristic_function: Random\"\nobject_type can be specified to do certain object-specific behaviours. Right now there is only a default behaviour which is the same for all objects.\ngrasp_type should be one of {Any,EdgeGrasp,WallGrasp,SurfaceGrasp}. In this version only SurfaceGrasp and WallGrasp is supported.\nhandarm_type should match your specific robot\/hand combination, i.e. RBOHand2Kuka for the rbo hand mounted omn the KUKA iiwa.  The value must match one of the class names in handarm_parameters.py.\nobject_heuristic_function should be one of {Random, Deterministic, Probabilistic}. This parameter selects one of the three heuristic functions for multi-object and multi-EC selection.\nThe planner assumes that all EC are exploitable for all objects. The multi-object-EC heuristics are:\n\nRandom: select one object-EC-pair randomly, independent of heuristic values\nDeterministic: pick the maximum of a heuristic function: (object,ec) = argmax q(object_i, ec_j) i in 1..n & j in 1..m. q() is taken from a parameter file multi_object_params.py which contains probability values for given objects (use-case relevant) and strategies (Surface-, Wall-, EdgeGrasp). The default parameter file is in .\/data\/object_param.yaml.\nProbabilistic: Use the heuristic function as a prior for sampling random strategies: samples from the pdf given by the Q[n x m] matrix, where Q[i,j] = q(object_i, ec_j)\n\nA simple example of object_params:\napple:\n   SurfaceGrasp: {'success': 1}    # Success rate for Surface grasping an apple is 100%\n   WallGrasp: {'success': 1}       # Success rate for Wall grasping an apple is 100%\n   EdgeGrasp: {'success': 0}       # Success rate for Edge grasping an apple is 0%\n\n\nAdvanced object-ec relational parameter definition:\n\n  cucumber:\n    SurfaceGrasp: {'success': 1, 'min': [-0.14, -0.1], 'max': [0.14, 0.05]}\n    WallGrasp: {'success': [1, 0.8, 0.7, 0] , 'angle': [0, 180, 360], 'epsilon': 20}\n    EdgeGrasp: {'success': 0}\n\n\nObjcet-IFCO relative position\nHere the SurfaceGrasp strategy success is as given (in this case 1) if the object is within a certain area within the IFCO. The min and max aprameters defin a cropbox inside the IFCO, this cropbox helps to exclude grasp that are infeasable due to possible collision or work space limitation. The reference frame is the IFOC Frame and the min vecor is min: [min_x_distance_x, min_y_distance] for which we compare the object frame relative to IFCO frame such that object_x > min_x_distance && object_y > min_y_distance. Similarly done for the max: [max_x_distance_x, max_y_distance] parameter. If the object is not within the cropbox, the success is 0.\nObject-EC relative oriantation\nHere the WallGrasp strategy success depend on the relative orientation of the cucumber to the wall. We define a set of possible grasping angles in degrees [0, 180, 360] and a success rate [1, 0.8, 0.7] for each angle. Important: the last element in the success rate vector gives the success in other cases. epsilon is an upper and lower bound on how exact orientation should be (0 - as precises as given in the angle vector, 10 - 10 deg > |current orientation - reference| )\nExamples  \nPlanning Based on PCD Input  \nThis example shows a planned grasp in RViz based on a PCD file that contains a single colored point cloud of a table-top scene with a banana placed in the middle.\nroscore\n\n# if you want to change which pcd to read, change the file name in the ecto graph yaml\nrosrun ecto_rbo_yaml plasm_yaml_ros_node.py `rospack find ec_grasp_planner`\/data\/geometry_graph_example1.yaml --debug\n\n# start visualization\nrosrun rviz rviz -d `rospack find ec_grasp_planner`\/configs\/ec_grasps_example1.rviz\n\n# select which type of grasp you want\nrosrun ec_grasp_planner planner.py --rviz --robot_base_frame camera_rgb_optical_frame\n\n# execute grasp\nrosservice call \/run_grasp_planner \"object_type: 'Apple' grasp_type: 'SurfaceGrasp' handarm_type: 'RBOHand2Kuka'\"\n\n\nIn RViz you should be able to see the geometry graph and the wall grasp published as visualization_msgs\/MarkerArray under the topic names geometry_graph_marker and planned_grasp_path:\n \nPlanning Based on Continuous RGB-D Input   \nThis example shows how to use the planner with an RGB-Depth sensor like Kinect or Asus Xtion.\nIt uses the camera drivers provided in ROS:\n# plug the camera into your computer\nroslaunch openni2_launch openni2.launch depth_registration:=true\n\n# set camera resolution to QVGA\nrosrun dynamic_reconfigure dynparam set \/camera\/driver ir_mode 7\nrosrun dynamic_reconfigure dynparam set \/camera\/driver color_mode 7\nrosrun dynamic_reconfigure dynparam set \/camera\/driver depth_mode 7\n\nrosrun ecto_rbo_yaml plasm_yaml_ros_node.py `rospack find ec_grasp_planner`\/data\/geometry_graph_example2.yaml --debug\n\n# start visualization\nrosrun rviz rviz -d `rospack find ec_grasp_planner`\/configs\/ec_grasps_example2.rviz\n\n# select an edge grasp and visualize the result in RViz\nrosrun ec_grasp_planner planner.py --robot_base_frame camera_rgb_optical_frame --rviz\n\n# execute grasp\nrosservice call \/run_grasp_planner \"object_type: 'Punnet' grasp_type: 'SurfaceGrasp' handarm_type: 'RBOHand2Kuka'\"\n\n\nDepending on your input the result in RViz could look like this:\n  \nKuka Arm in Gazebo Simulation with TRIK Controller  \nThis example shows the execution of a planned hybrid automaton motion in the Gazebo simulator.\n# Step 1: make sure the simulation time is used\nroslaunch hybrid_automaton_manager_kuka launchGazebo.launch\n\n# Step 2: start the simulation environment and kuka control manager \nrosrun hybrid_automaton_manager_kuka hybrid_automaton_manager_kuka\n\n# Step 3: run vision code\nrosrun ecto_rbo_yaml plasm_yaml_ros_node.py `rospack find ec_grasp_planner`\/data\/geometry_graph_example3.yaml --debug\n\n# Step 4 (optional): to check potential grasps\nrosrun rviz rviz -d `rospack find ec_grasp_planner`\/configs\/ec_grasps.rviz\n\nIn RViz you should be able to see the point cloud simulated in Gazebo and the geometry graph published as visualization_msgs\/MarkerArray under the topic name geometry_graph_marker:\n  \n# Step 5: select a surface grasp, visualize and execute it\nroscd hybrid_automaton_manager_kuka\/test_xmls\/ \nrosrun ec_grasp_planner planner.py --grasp SurfaceGrasp --ros_service_call --rviz --handarm RBOHand2Kuka [need to ctrl-c once done]\n.\/ha_send_xml.sh hybrid_automaton.xml  \n\nStep 6:\nIn RViz you should be able to see the planned surface grasp and in Gazebo the robot moves its hand towards the cylinder until contact (https:\/\/youtu.be\/Q91U9r83Vl0):\n \n","190":"NCEI.jl\nInterface for the National Centers for Environmental Information (NCEI) API\n\n\n\nLicense\nProject Status\nCitation\n\n\n\n\n\n\n\n\n\n\n\n\n\nLatest Release (v1.1.1)\nDevelopment (Master)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","191":"Physical environmental (i.e. geospatial) data harmonization work repository\nWelcome to the Physical environmental (i.e. geospatial) data harmonization work repository! Documenation of DataSchema variables as well as versionning and storage of data harmonization scripts will be saved in this space.\nThis page includes information to get you started.\nTable of Contents\n\nIntroduction to RMarkdown\nDataSchema variable template\nDataSchema variable example\nR scripts\n\nIntroduction to RMarkdown\nAn R Markdown document will be used to define the DataSchema (i.e. variables targeted for harmonization) covering each domain of information targeted by MINDMAP and to write R scripts used to derive common-format (i.e. harmonized) data. RMarkdown is essentially a file which encorporate Markdown - a lightweight markup language with plain text formatting syntax, and R - an open source programming language and software environment for statistical computing.\nMarkdown will be used to document DataSchema variable metadata (e.g. variable labels, descriptions, units, coding for categories) and R scripts will be used to harmonize data. That is, once completed, the RMarkdown file will contain the metadata which describes harmonized variables (in Markdown format) as well the data harmonization scripts that were used to generate common format data (in R language).\nFor more details on using RMarkdown see http:\/\/rmarkdown.rstudio.com. The following links will also help you get familiar with R Markdown:\n\nhttp:\/\/www.rstudio.com\/wp-content\/uploads\/2015\/03\/rmarkdown-reference.pdf\nhttp:\/\/www.rstudio.com\/wp-content\/uploads\/2016\/03\/rmarkdown-cheatsheet-2.0.pdf\n\nDataSchema variable template\nTo begin, each lead harmonizer will need to define DataSchema variables for the domain they were attributed. All fields which should be documented are outlined in the template below. Each MINDMAP harmonization lead will need to fill out this template for each DataSchema variable they define. Since study-specific data will then be mapped to these variables, it is important to give as much detail as possible in the Variable description field.\nDocumentation of DataSchema variable metadata should be done using the following template:\nVariable label -  a short label describing what the variable measures\nVariable name -  a computer-readable name (variable naming guidelines to follow)\nVariable description  - a detailed description of the variable, which might include components such as whether the variable needs to be measured or self-reported, the recall period (current, in the past month, year), or the accepted information source (questionnaire or registries)\nValue type - integer, decimal, date, datetime, or text\nVariable unit - if applicable - e.g. cm, kg, mmol. If not applicable, leave blank\nCategory coding - if applicable fill out table below with correct values. If not applicable (i.e. a continuous variable) delete the table.\n\n\n\nCode\nCategory Label\n\n\n\n\n0\n\n\n\n1\n\n\n\n\nHarmonization status - complete or impossible\nHarmonization comment - if needed, note on methodology or any reference used in the harmonization process\nR script\n#This is where the R-script will be written\n\n\n\nDataSchema variable example\nThis is what the filled out template would look like for the Cigarette smoking status variable\nVariable label: Cigarette smoking status\nVariable name: lsb_smk_status\nVariable description: indicator of whether the participant is never, past, or current smoker. This variable targets cigarette smoking behaviour only and excludes cigar, pipes and other tobaco products\nValue type: integer\nVariable unit: N\/A\nCategory coding:\n\n\n\nCode\nCategory Label\n\n\n\n\n0\nNever smoked\n\n\n1\nPast smoker\n\n\n2\nCurrent smoker\n\n\n\nHarmonization status: complete\nHarmonization comment: N\/A\nR script:\n#This is where the R-script will be written\n\n\n\nR scripts\nAs you see in the template above, Dataschema variable metadata are followed by R code chunks (the section below R scripts:), where data harmonization script will be written. R code chunks are created by three back ticks followed by an r in braces. They end with three back ticks.\nRscripts will be written in RStudio (details to follow).\n","192":"EnvironmentalProject\n","193":"\n\nThis is a web-based version of Robert and Jonas Gifford's \"FISH\", a fish banks simulator for environmental psychology studies.\nMore information on the original FISH here:\nhttp:\/\/web.uvic.ca\/~rgifford\/fish\/\nRequirements\nPlease ensure these requirements are installed before proceeding to the Installation section.\n\nNode (and npm)\nMongodb\nRuby\nSass (through gem install sass)\n\nInstallation\n\nNavigate to the fish directory in a terminal window\nRun the command npm install (install dependencies specified in the package.json file)\n\n\nNote: You may need escalated privileges to run and will get an error. If so, use the command sudo npm install instead.\nNOTE: This will run a script post install as well. See: Usage.\n\n\nRun the command npm start (on Windows or OSX) or nodejs app.js on Linux to start the server.\nNavigate to localhost:8080\n\nUsage\nScripts for Developers\nThese are located in the developer_scripts folder\n\nnpm run populatedb Run post-install.\nThis populates the database with a user \"Admin\" and a password \"123456789\"\nnpm run cleandb This will clean all the collections defined in the file (experimenters, microworlds, and sessions)\nnpm run resetdb runs cleandb then populatedb\nnpm run devreset runs cleandb then populate db and then starts up the server.\nnpm run sass watches for style changes\n\nDocker\nThis project is also dockerized (no official repository available however). This project uses and tested on the following Docker technologies:\n\nDocker for Mac:\n\nClient version: 17.03.1-ce\nServer version: 17.03.1-ce\n\n\nDocker Compose version 3\n\nContainer\nThe node application is run in a container named fish and the MongoDB is run in a container\nnamed mongo-fish. See docker-compose.yml for more details.\nVolumes\nThe following volumes are bound from host to the Docker container\n\nThe whole directory of this repository is mounted on fish to \/fish\/app\nmongo.log is mounted on mongo-fish to \/logs\/mongo.log\n\nYou can see more details on Docer setup\nDocker Setup\nThe following is a diagram of the Docker setup:\n\nFrom the above diagram you can infer several things:\n\nYou can access the Fish application from http:\/\/localhost:8080 from your browser\nSince all Fish files in this repo is mounted on the Fish container, any changes on the repo will be\nreflected onto the Fish container. Therefore if you make changes to the application you don't need to\nre-build the containers. See Building the images for more info\nSince the \/logs\/mongo.log is mounted to mongo.log, you may see all the mongo logs being saved\nto mongo.log so you can check it out in the future\n\nBuilding the images\nBefore trying to run Dockerized application, please run npm run build-docker first beforehand.\nThis command only needs to be run once, unless you want to rebuild the containers due to changes.\nSeveral possible changes that needs rebuilding:\n\nChanging the commands that the containers execute\nChanging the base image of the containers\nAdding things to the containers' Dockerfiles, either Dockerfile-app or Dockerfile-Db\nOther things that modifies the Dockerfiles\n\nUsage\nIn order to use the Dockerized version do the following\n\nnpm run build-docker\nRun the Docker services, one of\n\nnpm run start-docker (standard mode)\nnpm run start-daemon-docker (daemon mode a.k.a Docker detached mode)\n\n\nAfter running one of the above you should run npm run docker-populatedb. It's\nthe populate DB setup but for the docker setup\n\nIf you run in daemon mode then you can do npm run stop-daemon-docker to stop daemon mode\nLogs\nIf Docker was run in non-detached mode then logs will be visible on console stdout.\nThe node application and MongoDB logs may also be found in fish.log and mongo.log respectively.\nIf Docker was run in detached mode you may see logs by running the following commands:\n\nnode application: npm run logs-docker-fish\nMongoDB: npm run logs-docker-mongo-fish\n\nAdministrator\n\n\nNavigate to http:\/\/localhost:8080\/admin\n\n\nLog in with the following credentials:\n\nUsername: Admin\nPassword: 123456789\n\n\n\nYou now have access to the microworlds\n\n\nCreate and activate a microworld if you wish to run an experiment with users\nNote: Look at the Code for the experiment on an active microworld. eg Active Microworld: QQ5HQP\n\n\nUsers (identified by an arbitrary ID#, which is not pre-assigned. Any number will work.)\n\nNavigate to http:\/\/localhost:8080\/\nEnter the Experiment number of an active microworld\nEnter an ID number\nFish!\n\nAttributions\n\nBlack Fish Icon made by Freepik from www.flaticon.com is licensed under CC BY 3.0\nLighthouse Icon made by Icons8 from www.flaticon.com is licensed under CC BY 3.0\nSailboat Icon made by Freepik from www.flaticon.com is licensed under CC BY 3.0\nFishing Icon made by Icons8 from www.flaticon.com is licensed under CC BY 3.0\n\n","194":"environmentalinformatics-marburg.github.io\n","195":"ClosedCube Arduino Library for\nClosedCube BME680 Environment Sensor with 1.8V Output breakout board\nThis is breakout board for Bosch Sensortec BME680\n4-in-1 integrated environment sensor (temperature, humidity, pressure, gas and indoor air quality) that power up with Texas Instruments TPS62743 Ultralow Buck Converter\n\nFeatures:\n\nTemperature, Humidity, Pressure and Gas measurements\nLow Supply Current\nI2C digital interface with address either 0x76 or 0x77\nSupports 3.3V and 5V buses\nWide supply voltage range from 2.2 to 5.5 V\nPower up with Texas Instruments TPS62743 Ultra Low Power Buck Converter\nOptional 1.8V output up to 300mA\n\n\n\n\n\nWhere to Buy?\n\n\n\n\nRegion\nLink for 1 pcs\nLink for 2 pcs (0x76 and 0x77)\n\n\n\n\nUK\nhttps:\/\/www.amazon.co.uk\/ClosedCube-Environment-Temperature-Ultra-Low-Pre-Soldered\/dp\/B07WF56SFJ\nTBD\n\n\nGermany (DE)\nTBD\nTBD\n\n\nFrance (FR)\nTBD\nTBD\n\n\nItaly (IT)\nTBD\nTBD\n\n\nSpain (ES)\nTBD\nTBD\n\n\n\n\n\n\n\nRegion\nLink\n\n\n\n\nEurope,Asia,Oceania\nhttps:\/\/www.ebay.co.uk\/itm\/ClosedCube-BME680-Environment-T-H-P-Gas-Sensor-w-1-8V-Out-Breakout-Board\/182877251201 https:\/\/www.ebay.co.uk\/itm\/182877251201\n\n\nUSA\nTBD\n\n\n\n\nhttps:\/\/www.tindie.com\/products\/10694\/\nhttps:\/\/www.tindie.com\/products\/closedcube\/bme680-environment-sensor-with-ultra-low-18v-out\/\n","196":"HTML5 Environmental Thermometer\nThis repository contains the demo I've developed as a part of an article titled Create Your Own HTML5 Environmental Thermometer written for\nSitePoint. HTML5 Environmental Thermometer is a simple and adaptive environmental thermometer created to show the potentiality of the union of some of the brand new web technologies as HTML5, CSS3, geolocation API and others.\nThis demo uses a semantic and as more as possible detailed HTML5 markup and both CSS3 and JavaScript for styling and positioning the thermometer in order to look like a real environmental thermometer. Since it uses an SVG background image, it can be adapted to different sizes without being stretched. However, in the folder there's also a PNG background image to support the older browsers which don't support SVG.\nThe most interesting part of this demo regards the positioning of the thermometer and its labels. In fact, since the thermometer is 90\u00b0 rotated, CSS3 is not sufficient to center it and JavaScript has to be used. Moreover the latter has been used to set the number of labels dynamically and to evenly space each other.\nWhile for some of these I used just a pinch, to make the thermometer I employ the followings:\n\nHTML5 for the markup\nCSS3 to style the demo\nJavaScript + jQuery to adjust the thermometer position and to set and position its labels\nSVG for the background to be adaptive as much as it can\nPolyfill to support the browsers that don't support the meter element\nGeolocation API to get the user current position\nGoogle Maps API to convert the geolocation into an address\nYahoo! Weather API to retrieve the WOEID code and the temperature\n\nDemo\nA live demo is available here.\nLicense\nHTML5 Environmental Thermometer is dual licensed under MIT and GPL-3.0\nAuthor\nAurelio De Rosa (@AurelioDeRosa)\n","197":"HTML5 Environmental Thermometer\nThis repository contains the demo I've developed as a part of an article titled Create Your Own HTML5 Environmental Thermometer written for\nSitePoint. HTML5 Environmental Thermometer is a simple and adaptive environmental thermometer created to show the potentiality of the union of some of the brand new web technologies as HTML5, CSS3, geolocation API and others.\nThis demo uses a semantic and as more as possible detailed HTML5 markup and both CSS3 and JavaScript for styling and positioning the thermometer in order to look like a real environmental thermometer. Since it uses an SVG background image, it can be adapted to different sizes without being stretched. However, in the folder there's also a PNG background image to support the older browsers which don't support SVG.\nThe most interesting part of this demo regards the positioning of the thermometer and its labels. In fact, since the thermometer is 90\u00b0 rotated, CSS3 is not sufficient to center it and JavaScript has to be used. Moreover the latter has been used to set the number of labels dynamically and to evenly space each other.\nWhile for some of these I used just a pinch, to make the thermometer I employ the followings:\n\nHTML5 for the markup\nCSS3 to style the demo\nJavaScript + jQuery to adjust the thermometer position and to set and position its labels\nSVG for the background to be adaptive as much as it can\nPolyfill to support the browsers that don't support the meter element\nGeolocation API to get the user current position\nGoogle Maps API to convert the geolocation into an address\nYahoo! Weather API to retrieve the WOEID code and the temperature\n\nDemo\nA live demo is available here.\nLicense\nHTML5 Environmental Thermometer is dual licensed under MIT and GPL-3.0\nAuthor\nAurelio De Rosa (@AurelioDeRosa)\n","198":"Elixir Bme680\n  \nAn Elixir library to interface with the BME680 and BME280 environmental sensors. The BME680\nprovides measurements of temperature, pressure, humidity, and gas resistance\n(which is a proxy of indoor air quality). The ME680 is a lower cost device that only\nprovides measurements of temperature, pressure, humidity.\nInstallation\nThe package can be installed\nby adding elixir_bme680 to your list of dependencies in mix.exs:\ndef deps do\n  [\n    {:elixir_bme680, \"~> 0.1.4\"}\n  ]\nend\nThe Linux I2C driver needs to be installed for this library to work (e.g.\nlibi2c-dev on Debian). If using Nerves, the\ndriver should already be installed by default.\nUsage with Bme680\n{:ok, pid} = Bme680.start_link()\n\nmeasurement = Bme680.measure(pid)\n\n# Measurement is like:\n#\n#   %Bme680.Measurement{\n#     temperature: 21.74,\n#     pressure: 1090.52,\n#     humidity: 45.32,\n#     gas_resistance: 10235\n#   }\n#\n# Where temperature is in degrees Celsius, pressure in hPa, humidity in %\n# relative humidity, and gas_resistance in Ohm\nUsage with Bme280\n{:ok, pid} = Bme280.start_link()\n\nmeasurement = Bme280.measure(pid)\n\n# Measurement is like:\n#\n#   %Bme280.Measurement{\n#     temperature: 21.74,\n#     pressure: 30.52,\n#     humidity: 45.32\n#   }\n#\n# Where temperature is in degrees Celsius, pressure in inHg, humidity in %\n# relative humidity\nFor more information, read the API documentation.\nSensor compatibility BME680\nThe default setting has been tested on the Pimoroni\nBME680. The Adafruit\nBME680 requires using a different i2c\naddress. For the Adafruit, pass in the i2c_address option with value 0x77 as\nfollows:\nBme680.start_link(i2c_address: 0x77)\nSensor compatibility BME280\nThe default setting has been tested on the HiLetgo\nBME280.\nNote on gas resistance sensor warm up on the BME680\nNote that, due to the nature of the BME680 gas resistance sensor, the gas\nresistance measurement needs a warm-up in order to give stable measurements. One\npossible strategy is to perform continuous meaurements in a loop until the value\nstabilizes. That might take from a few seconds to several minutes (or more when\nthe sensor is brand new).\nAcknowledgements\nThis project contains low-level code from the BME680 driver by\nBosch and the\nBME280 driver by Bosch\n","199":"OneStop Stack\n\n\nOneStop is a distributed, scalable, event-driven database and search engine for environmental data.\nIt is designed to receive metadata both from automated systems and manual uploads of ISO-19115 XML metadata.\nIt implements generic parsing and analysis of that metadata while also enabling arbitrary processing flows\non it. All metadata entities are retrievable via REST API, exposed as streaming events via Kafka, and\nindexed to support a wide range of search and discovery capabilities via Elasticsearch.\nIt is being developed on a grant by a team of researchers from the University of Colorado (more legal info below).\nDocumentation\nFor Overview, Usage, Deployment, and Development information about this project, check out the docs.\nLegal\nThis software was developed under the OneStop project: 1553647 and MSN project: 1555839,\nNOAA award numbers NA12OAR4320137 and NA17OAR4320101 respectively to the Cooperative Institute\nfor Research in Environmental Sciences at the University of Colorado.\nThis code is licensed under GPL version 2.\n\u00a9 2020 The Regents of the University of Colorado.\nThis program is free software; you can redistribute it and\/or\nmodify it under the terms of the GNU General Public License\nas published by the Free Software Foundation version 2\nof the License.\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.\n","200":"README for contributing lessons to this repository\nIf you are interesting in teaching a specific topic please sing on the google spreadsheet\nWhen adding a lesson, please use a standard naming format NN-lesson-name, where NN is the consecutive lesson number (for lessons 1-9, use two-digit format, i.e. 08).\nPlace all data files used in the workshop in the data directory\nAlso, add a link to the lesson on the index page, using a header four level title and bulleted list of links to the item. e.g.:\nR-markdown workshop by Jeff Oliver\n\nknitr lesson\niris analysis\nReproducible report with knitr full lesson\n\n","201":"NOTICE\n\u26a1 THIS REPOSITORY IS DEPRECEATED: => NEW VERSION <= \u26a1\n","202":"WP-CLI Environmentalize\nWP-CLI package to \"environmentalize\" Wordpress installation.\nMakes wp-config.php to load settings from ENV variables.\nInstallation\nIn your WP-CLI installation run:\nwp package install michaloo\/wp-cli-environmentalize\nUsage\nIn your Wordpress installation run\nwp environmentalize\nIf no wp-config.php file is found, one based on default WP-CLI template is created.\nCreated wp-config.php file has getenv injected into Wordpress  define functions.\nIf you want to replace exisiting wp-config.php, please remove or rename it before\nthe command.\nIn addition to the config, there is .env file with all available ENV variables\ncreated.\nExcept DB_NAME, DB_USER, DB_PASSWORD all ENV variables names match WordPress\nconstants names. DB_CHARSET Wordpress constant value is set from DB_CHARSET ENV variable.\nIn mentioned three cases DB_ prefix is changed to MYSQL_\nto make it compatible with MySQL\/MariaDB Docker images ([refer to ]).\nRelated projects\n\nWP-CLI\nMariaDB Image\n\n","203":"WP-CLI Environmentalize\nWP-CLI package to \"environmentalize\" Wordpress installation.\nMakes wp-config.php to load settings from ENV variables.\nInstallation\nIn your WP-CLI installation run:\nwp package install michaloo\/wp-cli-environmentalize\nUsage\nIn your Wordpress installation run\nwp environmentalize\nIf no wp-config.php file is found, one based on default WP-CLI template is created.\nCreated wp-config.php file has getenv injected into Wordpress  define functions.\nIf you want to replace exisiting wp-config.php, please remove or rename it before\nthe command.\nIn addition to the config, there is .env file with all available ENV variables\ncreated.\nExcept DB_NAME, DB_USER, DB_PASSWORD all ENV variables names match WordPress\nconstants names. DB_CHARSET Wordpress constant value is set from DB_CHARSET ENV variable.\nIn mentioned three cases DB_ prefix is changed to MYSQL_\nto make it compatible with MySQL\/MariaDB Docker images ([refer to ]).\nRelated projects\n\nWP-CLI\nMariaDB Image\n\n","204":"carculator\n\n\n\n\n\n\n\n\n\n\n\nProspective environmental and economic life cycle assessment of vehicles made blazing fast.\nA fully parameterized Python model developed by the Technology Assessment group of the\nPaul Scherrer Institut to perform life cycle assessments (LCA) of vehicles.\nSee the documentation for more detail, validation, etc.\nTable of Contents\n\nBackground\n\nWhat is Life Cycle Assessment\nWhy carculator\n\n\nInstall\nUsage\n\nAs a Python library\nAs a web app\n\n\nSupport\nMaintainers\nContributing\nLicense\n\nBackground\nWhat is Life Cycle Assessment?\nLife Cycle Assessment (LCA) is a systematic way of accounting for environmental impacts along the relevant phases of the life of a product or service.\nTypically, the LCA of a passenger vehicle includes the raw material extraction, the manufacture of the vehicle, its distribution, use and maintenance, as well as its disposal.\nThe compiled inventories of material and energy required along the life cycle of the vehicle is characterized against some impact categories (e.g., climate change).\nIn the research field of mobility, LCA is widely used to investigate the superiority of a technology over another one.\nWhy carculator?\ncarculator allows to:\n\nproduce life cycle assessment (LCA) results that include conventional midpoint impact assessment indicators as well cost indicators\ncarculator uses time- and energy scenario-differentiated background inventories for the future, based on outputs of Integrated Asessment Model REMIND.\ncalculate hot pollutant and noise emissions based on a specified driving cycle\nproduce error propagation analyzes (i.e., Monte Carlo) while preserving relations between inputs and outputs\ncontrol all the parameters sensitive to the foreground model (i.e., the vehicles) but also to the background model\n(i.e., supply of fuel, battery chemistry, etc.)\nand easily export the vehicle models as inventories to be further imported in the Brightway2 LCA framework\n\ncarculator integrates well with the Brightway LCA framework.\ncarculator was built based on work described in Uncertain environmental footprint of current and future battery electric vehicles by Cox, et al (2018).\nInstall\ncarculator is at an early stage of development and is subject to continuous change and improvement.\nThree ways of installing carculator are suggested.\nWe recommend the installation on Python 3.7.\nInstallation of a stable release (1.0.0) from Pypi\npip install carculator\n\nInstallation of a development version from GitHub\npip install git+https:\/\/github.com\/romainsacchi\/carculator.git\n\nUsage\nAs a Python library\nCalculate the fuel efficiency (or Tank to wheel energy requirement) in km\/L of petrol-equivalent of current SUVs for the driving cycle WLTC 3.4\nover 800 Monte Carlo iterations:\n    from carculator import *\n    import matplotlib.pyplot as plt\n    cip = CarInputParameters()\n    cip.stochastic(800)\n    dcts, array = fill_xarray_from_input_parameters(cip)\n    cm = CarModel(array, cycle='WLTC 3.4')\n    cm.set_all()\n    TtW_energy = 1 \/ (cm.array.sel(size='SUV', year=2017, parameter='TtW energy') \/ 42000) # assuming 42 MJ\/L petrol\n\n    l_powertrains = TtW_energy.powertrain\n    [plt.hist(e, bins=50, alpha=.8, label=e.powertrain.values) for e in TtW_energy]\n    plt.xlabel('km\/L petrol-equivalent')\n    plt.ylabel('number of iterations')\n    plt.legend()\n\nCompare the carbon footprint of electric vehicles with that of rechargeable hybrid vehicles for different size categories today and in the future\nover 500 Monte Carlo iterations:\n    from carculator import *\n    cip = CarInputParameters()\n    cip.stochastic(500)\n    dcts, array = fill_xarray_from_input_parameters(cip)\n    cm = CarModel(array, cycle='WLTC')\n    cm.set_all()\n    scope = {\n        'powertrain':['BEV', 'PHEV'],\n    }\n    ic = InventoryCalculation(cm.array, scope=scope)\n\n    results = ic.calculate_impacts()\n    data_MC = results.sel(impact_category='climate change').sum(axis=3).to_dataframe('climate change')\n    plt.style.use('seaborn')\n    data_MC.unstack(level=[0,1,2]).boxplot(showfliers=False, figsize=(20,5))\n    plt.xticks(rotation=70)\n    plt.ylabel('kg CO2-eq.\/vkm')\n\nFor more examples, see examples.\nAs a Web app\ncarculator has a graphical user interface for fast comparisons of vehicles.\nSupport\nDo not hesitate to contact the development team at carculator@psi.ch.\nMaintainers\n\nRomain Sacchi\nChris Mutel\n\nContributing\nSee contributing.\nLicense\nBSD-3-Clause. Copyright 2020 Paul Scherrer Institut.\n","205":"Prius\nEnvironmentally-friendly application config for Ruby.\n\n\nPrius helps you guarantee that your environment variables are:\n\nPresent - an exception is raised if an environment variable is missing,\nso you can hear about it as soon as your app boots.\nValid - an environment variable can be coerced to a desired type\n(integer, boolean or string), and an exception will be raised if the value\ndoesn't match the type.\n\nUsage\nInstalling\n$ gem install prius\n\nQuick Start\n# Load a required environment variable into the Prius registry:\nPrius.load(:github_token)\n\n# Use the environment variable:\nPrius.get(:github_token)\n\n# Load an optional environment variable:\nPrius.load(:might_be_here_or_not, required: false)\n\n# Load and alias an environment variable:\nPrius.load(:alias_name, env_var: \"HORRENDOUS_SYSTEM_VAR_NAME\")\n\n# Load and coerce an environment variable (or raise):\nPrius.load(:my_flag, type: :bool)\nYou probably want to load all your environment variables as your app starts,\nso you catch config issues at boot time.\nLoading Environment Variables\nEnvironment variables need to be loaded into the Prius registry before being\nused. Typically this is done in an initialiser.\nPrius.load(name, options = {})\nIf an environment variable can't be loaded, Prius will raise one of:\n\nMissingValueError if the environment variable was expected to be set but couldn't be found.\nTypeMismatchError if the environment variable wasn't of the expected type (see below).\n\nPrius.load accepts the following options:\n\n\n\nParam\nDefault\nDescription\n\n\n\n\nrequired\ntrue\nFlag to require the environment variable to have been set.\n\n\ntype\n:string\nType to coerce the environment variable to. Allowed values are :string, :int and :bool.\n\n\nenv_var\nname.upcase\nName of the environment variable name (if different from the upcased name).\n\n\n\nReading Environment Variables\nOnce a variable has been loaded into the registry it can be read using:\nPrius.get(name)\nIf the environment variable hasn't been loaded, Prius will raise an UndeclaredNameError.\nTest and development environments\nTo make running your app in test and development environments easier we\nrecommend using Dotenv to automatically\nload a file of dummy config values.\n\nGoCardless \u2665 open source. If you do too, come join us.\n","206":"scs_core\nThe root of all South Coast Science environmental monitoring applications.\nContains library classes only.\nRequired libraries:\n\nThird party: AWSIoTPythonSDK, pytz, tzlocal\n\nBranches:\nThe stable branch of this repository is master. For deployment purposes, use:\ngit clone --branch=master https:\/\/github.com\/south-coast-science\/scs_core.git\n\n","207":"scriptEdDecHackathon\nEnvironmental Awareness Project\nwhat this project does\nthe project simulates  a series of scenarios with a series of questions that determine choices that should be made with a point system\nhow we built it\nwe built project with a system of combinations (css,html,javascript,jquery,bootstrap) which we then put together which then became our project\n##challenges we ran into\nwith an idea of how we were going to run we did run into some difficulties when it came to what platform we were going to be working on (cloud9,sublime etc...)\n ##what we learned?\n  we learned \n\n\n  ## \n\n","208":"Barque v1.7.2\nEnvironmental DNA metabarcoding analysis\n\nDeveloped by Eric Normandeau in\nLouis Bernatchez's\nlaboratory.\nPlease see the licence information at the end of this file.\nDescription\nBarque is an eDNA metabarcoding analysis pipeline that annotates reads,\ninstead of Operational Taxonomic Unit (OTUs), using high-quality barcoding\ndatabases.\nBarque can also produce OTUs, which are then annotated using a database.\nThese annotated OTUs are then used as a database themselves to find read counts\nper OTU per sample, effectively \"annotating\" the reads with the OTUs that were\npreviously found.\nUse cases\nThe approach implemented in Barque is especially useful for species\nmanagement projects:\n\nMonitoring invasive species\nConfirming the presence of specific species\nCharacterizing meta-communities in varied environments\nImproving species distribution knowledge of cryptic taxa\nFollowing loss of species over medium to long-term monitoring\n\nSince Barque depends on the use of high-quality barcoding databases, it is\nespecially useful for COI amplicons used in combination with the Barcode of\nLife Database (BOLD) or 12S amplicons with the mitofish database, although it\ncan also use any database, for example the Silva database for the 18s gene or\nany other custom database.\nInstallation\nTo use Barque, you will need a local copy of its repository. Different\nreleases can be found here.\nIt is recommended to always use the latest release or even the developpment\nversion. You can either download an archive of the latest release at the above\nlink or get the latest commit (recommended) with the following git command:\ngit clone https:\/\/github.com\/enormandeau\/barque\n\nDependencies\nTo run Barque, you will also need to have the following programs installed\non your computer.\n\nBarque will only work on GNU Linux or OSX\nbash 4+\npython 3.5+ (you can use miniconda3 to install python)\nR 3+ (ubuntu\/mint: sudo apt-get install r-base-core)\njava (ubuntu\/mint: sudo apt-get install default-jre)\ngnu parallel\nflash (read merger) v1.2.11+\nvsearch v2.14.2+\n\n\/!\\ v2.14.2+ required \/!\\\nBarque will not work with older versions of vsearch\n\n\n\nPreparation\n\nInstall dependencies\nDownload a copy of the Barque repository (see Installation above)\nEdit 02_info\/primers.csv to provide information describing your primers\nGet or prepare the database(s) (see Formatting database section below) and\ndeposit the fasta.gz file in the 03_databases folder and give it a name\nthat matches the information of the 02_info\/primers.csv file.\nMake a copy of 02_info\/barque_config.sh, modify the parameters for your run\nLaunch Barque, for example with .\/barque 02_info\/barque_config.sh\n\nOverview of Barque steps\nDuring the analyses, the following steps are performed:\n\nFilter and trim raw reads (trimmomatic)\nMerge paired-end reads (flash)\nSplit merged reads by amplicon (Python script)\nLook for chimeras (optional, vsearch --vsearch_global)\nMerge unique reads (Python script)\nFind species associated with each unique read (vsearch)\nSummarize results (Python script)\n\nTables of phylum, genus, and species counts per sample, including multiple hits\nNumber of retained reads per sample at each analysis step with figure\nMost frequent non-annotated sequences to blast on NCBI nt\/nr\nSpecies counts for these non-annotated sequences\nSequence groups for cases of multiple hits\n\n\n\nRunning the pipeline\nFor each new project, get a new copy of Barque from the source listed in\nthe Installation section. In this case, you do not need to modify the\nprimer and config files.\nRunning on the test dataset\nIf you want to test Barque, jump straight to the Test dataset section at\nthe end of this file. Read through the README after to better understand the\nprogram and it's outputs.\nPreparing samples\nCopy your paired-end sample files in the 04_data folder. You need one pair of\nfiles per sample. The sequences in these files must contain the sequences of\nthe primer that you used during the PCR. Depending on the format in which you\nreceived your sequences from the sequencing facility, you may have to proceed\nto demultiplexing before you can use Barque.\nIMPORTANT: The file names must follow this format:\nSampleID_*_R1_001.fastq.gz\nSampleID_*_R2_001.fastq.gz\n\nNotes: Each sample name, or SampleID, must contain no underscore (_) and be\nfollowed by an underscore (_). The star (*) can be any string of text that\ndoes not contain space characters. For example, you can use dashed (-) to\nseparate parts of your sample names, eg: PopA-sample001_ANYTHING_R1_001.fastq.gz.\nFormatting database\nYou need to put a database in gzip-compressed Fasta format, or .fasta.gz, in\nthe 03_databases folder.\nAn augmented version of the mitofish 12S database is already available in\nBarque.\nThe pre-formatted BOLD database can be\ndownloaded here.\nIf you want to use a newer version of the BOLD database, you will need to\ndownload all the animal BINs from this page\n. Put\nthe downloaded Fasta files in 03_databases\/bold_bins (you will need to create\nthat folder), and run the commands to format the bold database:\n# Format each BIN individually (~10 minutes)\n# Note: the `species_to_remove.txt` file is optional\nls -1 03_databases\/bold_bins\/*.fas.gz |\n    parallel .\/01_scripts\/util\/format_bold_database.py \\\n    {} {.}_prepared.fasta.gz species_to_remove.txt\n\n# Concatenate the resulting formatted bins into one file (~10 seconds)\ngunzip -c 03_databases\/bold_bins\/*_prepared.fasta.gz > 03_databases\/bold.fasta\n\nFor other databases, get the database and format it:\n\ngzip-compressed Fasta format (.fasta.gz)\nName lines have 3 informations separated by an underscore (_)\nEx: >Phylum_Genus_species\nEx: >Family_Genus_species\nEx: >Mammal_rattus_norvegicus\n\n\n\nConfiguration file\nMake a copy of the file named 02_info\/barque_config.sh and modify the\nparameters as needed.\nLaunching Barque\nLaunch the barque executable with the name of your configuration file as an\nargument, like this:\n.\/barque 02_info\/MY_CONFIG_FILE.sh\nResults\nOnce the pipeline has finished running, all result files are found in the\n12_results folder.\nAfter a run, it is recomended to make a copy of this folder and name it with the\ncurrent date, ex:\ncp -r 12_results 12_results_PROJECT_NAME_2020-07-27_SOME_ADDITIONAL_INFO\nTaxa count tables, named after the primer names\n\nPRIMER_genus_table.csv\nPRIMER_phylum_table.csv\nPRIMER_species_table.csv\n\nSequence dropout report and figure\n\nsequence_dropout.csv: Listing how many sequences were present in each\nsample for every analysis step. Depending on library and sequencing quality, as\nwell as the biological diversity found at the sample site, more or less\nsequences are lost at each of the analysis steps. The figure\nsequence_dropout_figure.png shows how many sequences are retained for each\nsample at each step of the pipeline.\n\nMost frequent non-annotated sequences\n\nmost_frequent_non_annotated_sequences.fasta: Sequences that are frequent in\nthe samples but were not annotated by the pipeline. This Fasta file should be\nused to query the NCBI nt\/nr database using the online portal found\nhere\nto see what species may have been missed. Use blastn with default parameters.\nOnce the NCBI blastn search is finished, download the results as a text file\nand use the following command (you will need to adjust the input and output\nfile names) to generate a report of the most frequently found species in the\nnon-annotated sequences:\n\nFasta files with sequences from multiple hit groups\n\n12_results\/01_multihits contains fasta file with database and sample\nsequences to help understand why some of the sequences cannot be unambiguously\nassigned to one species. For example, sometimes two different species can have\nidentical reads in the database. At other times sample sequences can have the\nsame distance from the sequences of two species in the database.\n\nSummarize species found in non-annotated sequences\n.\/01_scripts\/10_report_species_for_non_annotated_sequences.py \\\n    12_results\/NCBI-Alignment.txt \\\n    12_results\/most_frequent_non_annotated_sequences_species_ncbi.csv 97 |\n    sort -u -k 2,3 | cut -c 2- | perl -pe 's\/ \/\\t\/' > missing_species_97_percent.txt\nThe first result file will contain one line per identified taxon and the number\nof sequences for each taxon, sorted in decreasing order. For any species of\ninterest found in this file, it is a good idea to download the representative\nsequences from NCBI, add them to the database, and rerun the analysis.\nYou can modify the percentage value, here 97. The\nmissing_species_97_percent.txt file will list the sequence identifiers from\nNCBI so that you can download them from the online database and add them to\nyour own database as needed.\nOne way to do this automatically is to make a file with only the first column,\nthat is: one NCBI sequence identifier per line, and load it on this page:\nhttps:\/\/www.ncbi.nlm.nih.gov\/sites\/batchentrez\nYou will need to rename the sequences to follow the database name format\ndescribed in the Formatting database section and add them to your current\ndatabase.\nLog files and parameters\nFor each Barque run, three files are written in the 99_logfiles folder.\nEach contain a timestamp with the time of the run:\n\nThe exact barque config file that has been used\nThe exact primer file as it was used\nThe full log of the run\n\nLather, Rinse, Repeat\nOnce the pipeline has been run, it is normal to find that unexpected species\nhave been found or that a proportion of the reads have not been identified,\neither because the sequenced species are absent from the database or because\nthe sequences have the exact same distance from two or more sequences in the\ndatabase. In these cases, you will need to remove unwanted species from the\ndatabase or download additional sequences for the non-annotated species from\nNCBI to add them to it. Once the database has been improved, simply run the\nlast part of the pipeline again while using this new database. You can have\nSKIP_DATA_PREP=1 in your config file to avoid repeating the initial data\npreparation steps of Barque. You may need to repeat this step again until\nyou are satisfied with the completeness of the results.\nNOTE: You should provide justifications in your publications if you decide to\nremove some species from the database.\nTest dataset\nA test dataset is available as a sister repository on\nGitHub. It is composed of\n10 mitofish-12S metabarcoding samples, each with 10,000 forward and 10,000\nreverse sequences.\nDownload the repository and then move the data from\nbarque_test_dataset\/04_data to Barque's 04_data folder.\nIf you have git and Barque's dependencies installed, the following commands\nwill download the Barque repository and the test data and put them in the\nappropriate folder.\ngit clone https:\/\/github.com\/enormandeau\/barque\ngit clone https:\/\/github.com\/enormandeau\/barque_test_dataset\ncp barque_test_dataset\/04_data\/* barque\/04_data\/\nTo run the analysis, move to the barque folder and launch:\ncd barque\n.\/barque 02_info\/barque_config.sh\nThe analysis of this test dataset takes 25 seconds on a Linux ThinkPad laptop\nwith 4 core-i7 CPUs from ~2012 and 70 seconds on the same laptop using only one\nCPU.\nLicense\nCC share-alike\nBarque by Eric Normandeau is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.Based on a work at https:\/\/github.com\/enormandeau\/barque.\n","209":"efdcr\n\n\nThe efdcr package is a toolbox in R for pre- and post-processing the model results of the Environmental Fluid Dynamics Code (EFDC).\nIt provides tools to link existing EFDC models (build by EEMS) with your modelling wokflows in R.\nefdcr enables you to set up the model data before you can directly import to the EEMS and to easily visualize the model results exported by EEMS. The central goal of efdcr is to return simulation results in a tidy format to facilitate an easy implementation of EFDC simulations, together with other R packages into clean and efficient R programming workflows. The efdcr pakcage is part of my PhD thesis and was for personal use origninally and the APIs are not stable. Inspired by the SWATplusR package, I decided to continue to develop the package. Any contributions are welcomed and appreciated.\nWhy efdcr?\n\nconcise syntax: easy to memory and use\nwork well with the tidyverse packages\nfeature rich compared to the EEMS\ncareful API lifecycle management\n\nInstallation\nefdcr is still under development and will be constantly updated (more features will be added).\nYou can Install the latest development version of efdcr from GitHub with:\nif (!require(\"devtools\")) {\n  install.packages(\"devtools\")\n}\ndevtools::install_github(\"hxfan1227\/efdcr\")\nInstallation from GitHub does not include the vignettes by default because they take some time to build.\nExample\nThis is a basic example which shows you how to solve a common problem:\nlibrary(efdcr)\n# use has_variable() to check wether the .nc file has variables\n\nhas_variable('water_quality.nc')\n#> The file has 67 variables\n\n# use get_efdc_nc_dt() to extract variables in the .nc file\n\ndye_dt <- get_efdc_nc_dt('G:\/water_quality.nc', var_name = 'DYE')\n\n#> Reading bottom elevation (ZBOT)...\n#> Finish reading bottom elevation (ZBOT)!\n#> Reading water surface elevation (WSEL)...\n#> Finish reading water surface elevation (WSEL)\n#> Reading variables DYE ...\n#> Finish reading variables DYE !\n\n","210":"(c)2014 BITPAY, INC.\nPermission is hereby granted to any person obtaining a copy of this software\nand associated documentation for use and\/or modification in association with\nthe bitpay.com service.\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\nServer environment check script to determine if a merchant's server has the\ncorrect software installed and can communicate with the BitPay network properly.\nInstallation\nDownload this Zip archive and extract the contents. Copy the envcheck.php file onto your web server.\nUsage\nOpen a web browser and navigate to the envcheck.php script on your web server.  It will perform a series of basic environment checks to include a PHP version, extension check and a communication check to determine if your server can send\/receive requests to the BitPay network.  You should see a series of success messages showing that all checks completed and your server passed.  If you have any problems detected, review the error message and contact your web hosting provider.\nBelow is an example script output showing all checks passed:\n===============================================================\nBitPay Merchant Server Environment Check v0.02\n===============================================================\nThe following information has been compiled to help you\nensure your server is ready to use one of our code libraries\nor shopping cart plugins.  Please note that the shopping\ncart you choose may have additional requirements not checked\nhere.  Refer to the cart's documentation for those requirements.\n\nThe results of this check will also be written to a the\nenvcheck.log file located in the same directory as this script\nif the directory is writable.\n===============================================================\n\n******* Check script run date\/time: 21:22:44 04-03-2014 *******\n\nPHP Version: 5.3.10-1ubuntu3.9 - Good!\nExtensions:  Found json - Good!  Found curl - Good!\nBitPay communication check: Good!\nLocal communication check: Good!\n\nSuccess! No problems were found that could prevent you from using a BitPay plugin!\n\nChange Log\nVersion 0.01, rich@bitpay.com\n\nInitial version\n\nVersion 0.02, rich@bitpay.com\n\nAdded check for JSON extension\n\n","211":"Environmental-Data-IoT-Dashboard\nThis is a simple azure website that shows how to visualize data from eventhub as a real-time graph using D3.js.\nAcknowledgements\nThis code was modified from the sample ThingLabs-IoT-Dashboard.\nStream Analytics Job\nWITH ProcessedData as (\n    SELECT\n        MAX(Celsius) MaxTemperature,\n        MIN(Celsius) MinTemperature,\n        AVG(Celsius) AvgTemperature,\n        Geo as location,\n        DeviceId as deviceId,\n        System.Timestamp AS Timestamp\n    FROM\n        [inputdata]\n    GROUP BY\n        TumblingWindow (second, 15), DeviceId, Geo\n)\n\nSELECT * INTO [outputdata] FROM ProcessedData\nStream Analytics Event Queue Output\nNotes.\n\nThe output type for Event hub from the Stream Analytics job must be 'Array'\nThe node.js solutions assumes the event hub name is 'thinglabseventhub'\n\n\n","212":"Env-Module Firmware\nThis repo contains the firmware for the Environmental board.\nTo update your boards, env_firmware.ino and depending on your module change the following:\n\nin env_firmware.ino uncomment one of the following lines, based on the chosen module:\n\n#define TOP1\n\/\/#define MID2\n\/\/#define MID3\n\/\/#define BOTTOM4\n\nExample: for device with number 1, uncomment line #define TOP1 and comment all the others\n\nin the can_module.h change the number for SET_CAN_ID accordingly:\n\n#define SET_CAN_ID 0x100\n\nExample: for module 1, set #define SET_CAN_ID 0x100, for module 2 set it to #define SET_CAN_ID 0x200.\nBefore uploading select the IRNAS-env-module-L072Z board under the Tlera Corp STM32L0 Boards.\nHardware Support\n\nMCU:  CMWX1ZZABZ-091 LoRa\u00ae\/Sigfox\u2122 module (Murata)\nCAN: MCP25625 (integrated transceiver)\nMultiple Feather compatible sensors\n\nSoftware requirements and board definitions\nAdd https:\/\/irnas.github.io\/ArduinoCore-stm32l0\/package_stm32l0_boards_index.json in the ArduinoIDE under File->Preferences->Additional Boards Manager URLs.\nNote: if you had added any previous STM32L0 board definitions, such as https:\/\/github.com\/GrumpyOldPizza\/ArduinoCore-stm32l0\/, you need to remove them to avoid double referencing.\nAfter you added Boards Manager URL, install Tlera Corp STM32L0 Boards, version 0.0.11 via the Boards Manager in ArduinoIDE. Afterwords you will be able to select IRNAS-env-module-L072Z board under the Tlera Corp STM32L0 Boards.\n","213":"\nenvreportutils 0.9.0\n\nOverview\nAn R package with\nggplot2 themes and other functions commonly used\nby the Environmental Reporting\nBC\nteam when developing environmental reporting indicators and related\nproducts.\nFeatures\nPlotting-related functions:\n\ntheme_soe() - default ggplot2 theme for Environmental Reporting\nBC graphs\ntheme_soe_facet() - default ggplot2 theme for Environmental\nReporting BC graphs using facetting\nbgc_colours() - get colour codes for B.C. Biogeoclimatic (BGC)\nZones\nsvg_px() & save_svg_px()- create and save svg for the web,\nspecifying size in pixels\npng_retina() & save_png_retina() - create and save png for\nretina display\n\nData wrangling & sharing functions:\n\nreport_percent() - perform standardized rounding of percentage\nvalues for reporting\nto_titlecase() - simple helper function to convert \"AnY stRanGELy forMaTTed STring\" to \"Title Case\"\nget_data_licence() - get the url, or a markdown or html-formatted\nlink to one of several B.C. or Canadian licences\nsoft() - use ENV SOFT utility from within R\nsoe_path() & set_soe_root() - set path to a folder or file in\nthe ENV State of Evnvironment program network drive\n\nLeaflet-related functions:\n\nadd_bc_home_button() - add a \u2018Zoom to B.C. button\u2019 to a leaflet\nmap\nset_bc_view() - set leaflet map view to B.C.\nset_bc_view_on_close()- re-centre map to B.C. on popup close\npopup_create_row() - create a popup row div for leaflet maps\npopup_combine_rows() - combine popup rows for leaflet maps\ncss_caaqs_copy() - create copy of CAAQS CSS styles for leaflet map\npopup_caaqs() - create popup for CAAQS indicators\n\nDeprecated functions:\n\norder_df() - order a data frame using summary of a specified\ncolumn or specify the order manually (this function is deprecated,\nsee\nforcats::fct_reorder\nfor the same functionality)\nmultiplot() - combine multiple ggplot2 plots into one (this\nfunction is deprecated, see the\ncowplot\nor patchwork packages for\nthe same functionality)\n\nThe package also installs an RStudio\nAddin for adding a custom\nfooter to READMEs for projects maintained by Environmental Reporting\nBC.\nInstallation\nYou can install the package directly from this repository. To do so, you\nwill need the devtools package:\ninstall.packages(\"devtools\")\nNext, install the envreportutils package using\ndevtools::install_github():\nlibrary(\"devtools\")\ninstall_github(\"bcgov\/envreportutils\")\nProject Status\nThis package is under continual development.\nGetting Help or Reporting an Issue\nTo report bugs\/issues\/feature requests, please file an\nissue.\nHow to Contribute\nIf you would like to contribute to the package, please see our\nCONTRIBUTING guidelines.\nPlease note that this project is released with a Contributor Code of\nConduct. By participating in this project you agree\nto abide by its terms.\nLicense\nCopyright 2015 Province of British Columbia\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at \n\n   http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nThis repository is maintained by Environmental Reporting\nBC.\nClick here for a\ncomplete list of our repositories on GitHub.\n","214":"metaBEAT - metaBarcoding and Environmental DNA analysis Tool\nReproducible pipeline for the analysis of metabarcoding data generated by either Sanger or NGS approaches.\nmetaBEAT is using a number of external programs. To make your life easier we have created a self contained environment with all necessary pieces of software in a docker image. This image is building on ReproPhylo. If you want to use it you'll need Docker installed on your machine.\nHow to use the Image:\nRun the metaBEAT script in the container (you can process data in you current working directory or subdirectories of it):\nsudo docker run --rm --net=host --name metaBEAT -v $(pwd):\/home\/working chrishah\/metabeat metaBEAT_global.py -h\nIn a terminal window, mount the docker container to your current working directory and enter the self contained environment using a shell:\nsudo docker run -i -t --net=host --name metaBEAT -v $(pwd):\/home\/working chrishah\/metabeat \/bin\/bash\nOr access the container via a Jupyter notebook, by simply running the start_metaBEAT_nb providing the full path to your desired mounting point to the script, e.g.:\n.\/start_metaBEAT_nb $(pwd) --xt\nThis will open a Jupyter notebook in a new tab in your default browser. First it will notify you that your connection is not private. Click on Advanced on the bottom left and proceed to local host (unsafe). Then you will be asked to provide a password, which is simply password. Entering the password correctly will now open the Jupyter notebook and you are good to go.\nOnce you are done, you should stop the container by simply running:\nstop_metaBEAT_nb\nWithin the environment you can then execute the scripts that come with metaBEAT, e.g.:\nmetaBEAT_global.py\nExecuting a script without any options will usually display the usage, e.g.:\nusage: metaBEAT_global.py [-h] [-Q <FILE>] [-v] [-s] [-f] [-p] [-t] [-b]\n                   [-m <string>] [-n <INT>] [-E] [-e] [--PCR_primer <FILE>]\n                   [--trim_adapter <FILE>] [--trim_qual <INT>]\n                   [--trim_window <INT>] [--trim_minlength <INT>] [--merge]\n                   [--product_length <INT>] [--phred <INT>] [-R <FILE>]\n                   [--gb_out <FILE>] [--rec_check] [--cluster]\n                   [--clust_match <FLOAT>] [--clust_cov <INT>] [--www]\n                   [--min_ident <FLOAT>] [--min_bit <INT>] [--refpkg <DIR>]\n                   [-o OUTPUT_PREFIX] [--metadata METADATA] [--mock_meta_data]\n                   [--version]\n\nmetaBEAT - metaBarcoding and Environmental DNA Analyses tool\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -Q <FILE>, --querylist <FILE>\n                        file containing a list of query files\n  -v, --verbose         turn verbose output on\n  -s, --seqinfo         write out seq_info.csv file\n  -f, --fasta           write out ref.fasta file\n  -p, --phyloplace      perform phylogenetic placement\n  -t, --taxids          write out taxid.txt file\n  -b, --blast           compile local blast db and blast queries\n  -m <string>, --marker <string>\n                        marker ID (default: marker)\n  -n <INT>, --n_threads <INT>\n                        Number of threads (default: 1)\n  -E, --extract_centroid_reads\n                        extract centroid reads to files\n  -e, --extract_all_reads\n                        extract reads to files\n  --version             show program's version number and exit\n\nQuery preprocessing:\n  The parameters in this group affect how the query sequences are processed\n\n  --PCR_primer <FILE>   PCR primers (provided in fasta file) to be clipped\n                        from reads\n  --trim_adapter <FILE>\n                        trim adapters provided in file\n  --trim_qual <INT>     minimum phred quality score (default: 30)\n  --trim_window <INT>   sliding window size (default: 5) for trimming; if\n                        average quality drops below the specified minimum\n                        quality all subsequent bases are removed from the\n                        reads\n  --trim_minlength <INT>\n                        minimum length of reads to be retained after trimming\n                        (default: 50)\n  --merge               attempt to merge paired-end reads\n  --product_length <INT>\n                        estimated length of PCR product (default: 100)\n  --phred <INT>         phred quality score offset - 33 or 64 (default: 33)\n\nReference:\n  The parameters in this group affect the reference to be used in the\n  analyses\n\n  -R <FILE>, --REFlist <FILE>\n                        file containing a list of files to be used as\n                        reference sequences\n  --gb_out <FILE>       output the corrected gb file\n  --rec_check           check records to be used as reference\n\nQuery clustering options:\n  The parameters in this group affect read clustering\n\n  --cluster             perform clustering of query sequences using vsearch\n  --clust_match <FLOAT>\n                        identity threshold for clustering in percent (default:\n                        1)\n  --clust_cov <INT>     minimum number of records in cluster (default: 1)\n\nBLAST search:\n  The parameters in this group affect BLAST search and BLAST based taxonomic\n  assignment\n\n  --www                 perform online BLAST search against nt database\n  --min_ident <FLOAT>   minimum identity threshold in percent (default: 0.95)\n  --min_bit <INT>       minimum bitscore (default: 80)\n\nPhylogenetic placement:\n  The parameters in this group affect phylogenetic placement\n\n  --refpkg <DIR>        PATH to refpkg\n\nBIOM OUTPUT:\n  The arguments in this groups affect the output in BIOM format\n\n  -o OUTPUT_PREFIX, --output_prefix OUTPUT_PREFIX\n                        prefix for BIOM output files (default='metaBEAT')\n  --metadata METADATA   comma delimited file containing metadata (optional)\n  --mock_meta_data      add mock metadata to the samples in the BIOM output\n\nVERSIONS\nv. 0.6:\n\ndocker image for this version is: chrishah\/metabeat:v0.6\nused for Kitson et al. 2015\n\n","215":"\nLong-term Trends in Groundwater Levels in B.C.\nThis repository contains R code that calculates long-term trends in groundwater levels. It supports an indicator published on Environmental Reporting BC.\nThe scripts use the bcgroundwater R package and groundwater monitoring data from the B.C. Observation Well Network to:\n\nanalyze long-term trends of groundwater levels\nproduce provincial-scale and individual well summary statistics\ngenerate supporting data visualizations\n\nUsage\nData\nAll the data sourced for the analysis is provided under the Open Government Licence \u2013 British Columbia.\n\nGroundwater level monitoring data are downloaded from the\nB.C. Data Catalogue via the bcgroundwater R package\nGroundwater well attribute data are downloaded directly from the\nB.C. Data Catalogue\nNatural Resource Regions used in the summaries are sourced from the bcmaps R package\n\nCode\nThere are four core scripts that are required for the analysis, they need to be run in order:\n\n01_clean.R\n02_analysis.R\n03_visualize.R\n04_output.R\n\nGetting Help or Reporting an Issue\nTo report bugs\/issues\/feature requests, please file an issue.\nHow to Contribute\nIf you would like to contribute, please see our CONTRIBUTING guidelines.\nPlease note that this project is released with a Contributor Code of Conduct. By participating in this project you agree to abide by its terms.\nLicense\nCopyright 2018 Province of British Columbia\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at \n\n   http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nThis repository is maintained by Environmental Reporting BC. Click here for a complete list of our repositories on GitHub.\n","216":"\nLong-term Trends in Groundwater Levels in B.C.\nThis repository contains R code that calculates long-term trends in groundwater levels. It supports an indicator published on Environmental Reporting BC.\nThe scripts use the bcgroundwater R package and groundwater monitoring data from the B.C. Observation Well Network to:\n\nanalyze long-term trends of groundwater levels\nproduce provincial-scale and individual well summary statistics\ngenerate supporting data visualizations\n\nUsage\nData\nAll the data sourced for the analysis is provided under the Open Government Licence \u2013 British Columbia.\n\nGroundwater level monitoring data are downloaded from the\nB.C. Data Catalogue via the bcgroundwater R package\nGroundwater well attribute data are downloaded directly from the\nB.C. Data Catalogue\nNatural Resource Regions used in the summaries are sourced from the bcmaps R package\n\nCode\nThere are four core scripts that are required for the analysis, they need to be run in order:\n\n01_clean.R\n02_analysis.R\n03_visualize.R\n04_output.R\n\nGetting Help or Reporting an Issue\nTo report bugs\/issues\/feature requests, please file an issue.\nHow to Contribute\nIf you would like to contribute, please see our CONTRIBUTING guidelines.\nPlease note that this project is released with a Contributor Code of Conduct. By participating in this project you agree to abide by its terms.\nLicense\nCopyright 2018 Province of British Columbia\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at \n\n   http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nThis repository is maintained by Environmental Reporting BC. Click here for a complete list of our repositories on GitHub.\n","217":"\n\n\nPEMA:\na flexible Pipeline for Environmental DNA Metabarcoding Analysis of the 16S\/18S rRNA, ITS and COI marker genes\nPEMA is reposited in Docker Hub as well as in Singularity Hub\nA PEMA tutorial can be found here.\nFor any troubles you may have when running PEMA or for any potential improvevments you would like to suggest, please share on the PEMA Gitter community.\nTable of Contents\n\nPEMA: biodiversity in all its different levels\n A container-based tool\nHow to run PEMA\n\nParameters' file\n\n\nPEMA on HPC\n\nPrerequisites\nInstalling\nRunning PEMA\n\nExample\n\n\n\n\nPEMA on a simple PC\n\nPrerequisites\nInstalling\nRunning PEMA\n\nStep 1 - Build a Docker container\nStep 2 - Run PEMA\n\n\n\n\nphyloseq - for a downstream ecological analysis\nAcknowledgments\nLicense\nCitation\n\n+ convertion of the Illumina raw data is now implemented in the framework of PEMA\n+ PEMA now supports 2 extra marker genes, 18S rRNA and ITS. \n+ PEMA is now available for macOS!\n+ for anything feel free to contact me at: haris-zaf@hcmr.gr\nPEMA: biodiversity in all its different levels\nPEMA supports the metabarcoding analysis of four marker genes, 16S rRNA (Bacteria), ITS (Fungi) as well as COI and 18S rRNA (metazoa). As input, PEMA accepts .fastq.gz files as returned by Illumina sequencing platforms.\nPEMA processes the reads from each sample and returns an OTU- or an ASV-table with the taxonomies of the taxa found and their abundances in each sample. It also returns statistics and a FASTQC diagram about the quality of the reads for each sample. Finally, PEMA supports downstream ecological analysis of the profiles retrieved, facilitated by the phyloseq R package.\nPEMA supports both OTU clustering (thanks to VSEARCH and CROP algorithms) and ASV inference (via SWARM) for all four marker genes.\nFor the case of the 16S rRNA marker gene, PEMA includes two separate approaches for taxonomy assignment: alignment-based and phylogenetic-based. For the latter, a reference tree of 1000 taxa was created using SILVA_132_SSURef, EPA-ng and RaxML-ng.\nPEMA has been implemented in BigDataScript programming language. BDS\u2019s ad hoc task parallelism and task synchronization, supports heavyweight computation. Thus, PEMA inherits such features and it also supports roll-back checkpoints and on-demand partial pipeline execution. In addition, PEMA takes advantage of all the computational power available on a specific machine; for example, if PEMA is executed on a personal laptop with 4 cores, it is going to use all four of them.\nFinally, container-based technologies such as Docker and Singularity, make PEMA easy accessible for all operating systems.\nAs you can see in the PEMA_tutorial.pdf, once you have either Docker or Singularity on your computational environment (see below which suits your case better), running PEMA is cakewalk. You can also find the PEMA tutorial as a Google Slides file.\nA container-based tool\nPEMA can run either on a HPC environment (server, cluster etc) or on a simple PC. However, we definitely suggest to run it on an HPC environment to exploit the full potential of PEMA. Running on a powerful server or a cluster can be time-saving since it would require significantly less computational time than in a common PC. However, for analyses with a small number of samples, a common PC can suffice.\nThere is one major difference between running PEMA on a common PC than running it on a HPC environment. In the first case, PEMA runs through Docker, while in the latter one, it runs through Singularity.\nOn the following chapters, you can find how to install PEMA both in Docker and Singlularity including examples.\nRunning PEMA is exactly the same procedure in both of those cases.\nHow to run PEMA\nAssuming you have either Docker or Singularity on your system (see below how to get them).\nYou need to create a directory where you will have everything PEMA needs - we will call it analysis directory.\nIn this directory, you need to add the following mandatory files:\n\nthe parameters.tsv file (you can download it from this repository and then complete it according to the needs of your analysis)\na subdirectory called mydata where your .fastq.gz files will be located \n\nIf your need to perform phyloseq, in the analysis directory you also need to add the following optionally files:\n\nthe phyloseq_in_PEMA.R which you can also download from this repository and set it the way you want (that is an R script which we have implemented and has some main features that need to stay always the same in order to be executed as part of PEMA and some parts where the user can set what exactly needs to get from the phyloseq package)\nthe metadata.csv file which has to be in a comma separated format (you can find an example of this file on PEMA's GitHub repository).\n\nAttention! \nPEMA will fail unless you name the aforementioned files and directories exactly as described above.\n\nHere is an example of how your analysis directory should be in case you do want a phyloseq analysis:\nuser@home-PC:~\/Desktop\/analysis_directory$ ls\nmydata  parameters.tsv  phyloseq_in_PEMA.R  metadata.csv\n\nand in case you do not:\nuser@home-PC:~\/Desktop\/analysis_directory$ ls\nmydata  parameters.tsv \n\nHere you can find an example of an analysis directory.\nAfter you have prepared this analysis directory you are ready to run PEMA (see below).\nAn extended list with PEMA's ouput can be found here.\nParameters' file\nThe most crucial component in running PEMA is the parameters file. This file must be located in the analysis directory and the user needs to fill it every time PEMA is about to be called. If you need more than one analyses to run, then you need to make copies of the parameters' file and have one of those in eah of the analysis directrories you create.\nSo, here is the parameters.tsv file as it looks like, in a study case of our own.\nPEMA on HPC\nPEMA is best to run on HPC (server, cluster, cloud). Usually environmental data are quite large and the whole process has huge computational demands. To get PEMA running on your HPC you (actually your system administrator) need to install Singularity as described below.\nPrerequisites\nSingularity  is a free, cross-platform and open-source computer program that performs operating-system-level virtualization also known as containerization. One of the main uses of Singularity is to bring containers and reproducibility to scientific computing and the high-performance computing (HPC) world.\nSingularity needs a Linux\/Unix system to run.\nInstalling\nAfter you install Singularity in your environment and open it, you need to download PEMA's image from Singularity Hub, by running the command:\n singularity pull shub:\/\/hariszaf\/pema:v.1.1\n\nNow you have PEMA on your environment. But there is still one really important thing that you need to do! Please download the parameters.tsv file and move it or copy it to the same directory with your raw data.\nNow you are ready to go!\nRunning PEMA\nSingularity permits the use of a job scheduler that allocates computional resources on clusters and at the same time, works as a queuing system, as Slurm. This way you are able to create a job as you usually do in your system and after editing the parameters file as needed, run PEMA as a job on your cluster.\nExample\n#SBATCH --partition=batch\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=20\n#SBATCH --mem=\n# Memory per node specification is in MB. It is optional.\n# The default limit is 3000MB per core.\n#SBATCH --job-name=\"testPema\"\n#SBATCH --output=PEMA.output\n#SBATCH --mail-user=haris-zafr@hcmr.gr\n#SBATCH --mail-type=ALL\n#SBATCH --requeue\n\n\nsingularity run -B \/<path>\/<of>\/<input>\/<directory>\/:\/mnt\/analysis \/<path>\/<of>\/<PEMA_container>\n\n\nIn the above example, we set the cluster \"Zorba\", to run PEMA in 1 node, with 20 cores.\nFor further information, you can always check PEMA's tutorial.\nPEMA on a simple PC\nPrerequisites\nTo run PEMA in a simple PC on your own environment, you first need to install Docker, in case you do not already have it.\nYou should check your software version. A version of Docker is avalable for all Windows, Mac and Linux. If you have Windows 10 Pro or your Mac's hardware in after 2010, then you can insall Docker straightforward. Otherwise, you need to install the Docker toolbox instead. You can check if your System Requirements are according to the ones mentioned below in order to be sure what you need to do.\nSystem Requirements\n**__Windows 10 64bit__**:\nPro, Enterprise or Education (1607 Anniversary Update, Build 14393 or later).\nVirtualization is enabled in BIOS. Typically, virtualization is enabled by default.\nThis is different from having Hyper-V enabled. For more detail see Virtualization must be enabled in Troubleshooting.\nCPU SLAT-capable feature.\nAt least 4GB of RAM.\n\n**__Mac__**\nMac hardware must be a 2010 or newer model, with Intel\u2019s hardware support for memory management unit (MMU)\nvirtualization, including Extended Page Tables (EPT) and Unrestricted Mode. You can check to see if your machine\nhas this support by running the following command in a terminal:\nsysctl kern.hv_support macOS El Capitan 10.11 and newer macOS releases are supported.\nWe recommend upgrading to the latest version of macOS.\nAt least 4GB of RAM\nVirtualBox prior to version 4.3.30 must NOT be installed (it is incompatible with Docker for Mac).\nIf you have a newer version of VirtualBox installed, it\u2019s fine.\n\nInstalling\nAfter you install Docker in your environment and run it, the only thing you need to do, is to download PEMA's image, by running the command:\ndocker pull hariszaf\/pema\n\nThe PEMA image file is a quite large (~3Gb), so it will take a while until it is downloaded in your computer system.\nRunning PEMA\nRunning PEMA has two discrete steps.\nStep 1 - Build a Docker container\nAt first, you need to let Docker have access in your dataset. To provide access you need to run the following command and specifying the path to where your data is stored, i.e. changing the <path_to_analysis_directory> accordingly:\ndocker run -it -v \/<path_to_analysis_directory>\/:\/mnt\/analysis hariszaf\/pema\n\nAfter you run the command above, you have now built a Docker container, in which you can run PEMA!\nStep 2 - Run PEMA\nNow, being inside the PEMA container, the only thing remaining to do, is to run PEMA\n.\/PEMA_v1.bds\n\nPEMA is now running. The runtime of PEMA depends on the computational features of your environment, on the size of your data, as well as the parameters you chose.\nPlease, keep in mind that when you need to copy a whole directory, then you always have to put \"\/\" in the end of the path that describes where the directory is located.\nFinally, you will find the PEMA output in the analysis directory on your computer. \nAs the output directory is mounted into the built Docker container, you can copy its contents wherever you want. However, in case you want to remove it permanently, you need to do this as a sudo user.\nThe \"phyloseq\" R package\nfor a downstream ecological analysis of OTUs\/ASVs retrieved\nPEMA performs all the basic functions of the \"phyloseq\" R package. In addition, it performs certain functions of the vegan R package.\nWhen the user asks for a downstream analysis using the \"phyloseq\" R package, then an extra input file called \"phyloseq_script.R\" needs to be imported in the \"analysis_directory\". In PEMA's main repository, you can find a template of this file; this file needs to be as it would run on your own computer, as you would run phyloseq in any case. PEMA will create the \"phyloseq object\" automatically and then it will perform the analysis as asked. The output will be placed in an extra subfolder in the main output directory of PEMA called phyloseq_analysis.\nIn addition, the metadata.tsv file is also required when the phyloseq option has been selected. An example of this file you can find here.\nAcknowledgments\nPEMA uses a series of tools, datasets as well as Big Data Script language. We thank all the groups that developed them.\nThe tools & databases that PEMA uses are:\n\nBigDataScript programming language - https:\/\/pcingola.github.io\/BigDataScript\/\nFASTQC - https:\/\/www.bioinformatics.babraham.ac.uk\/projects\/fastqc\/\n\u03a4rimmomatic - http:\/\/www.usadellab.org\/cms\/?page=trimmomatic\nCutadapt - https:\/\/cutadapt.readthedocs.io\/en\/stable\/\nBayesHammer - included in SPAdes - http:\/\/cab.spbu.ru\/software\/spades\/\nPANDAseq - https:\/\/github.com\/neufeld\/pandaseq\nOBITools - https:\/\/pythonhosted.org\/OBITools\/welcome.html\nBLAST Command Line Applications - https:\/\/www.ncbi.nlm.nih.gov\/books\/NBK52640\/\nVSEARCH-2.9.1 - https:\/\/github.com\/torognes\/vsearch\/releases\/tag\/v2.9.1\nSWARM - https:\/\/github.com\/torognes\/swarm\nCROP - https:\/\/github.com\/tingchenlab\/CROP\nCREST - https:\/\/github.com\/lanzen\/CREST\nRDPClassifier - https:\/\/github.com\/rdpstaff\/classifier\n(RPDtools are required in order to execute RDPClassifier)\nSILVA db - https:\/\/www.arb-silva.de\/no_cache\/download\/archive\/current\/Exports\/\nMIDORI db - http:\/\/reference-midori.info\/index.html\n\"phat\" algorithm, from the \"gappa\" package - https:\/\/github.com\/lczech\/gappa\/wiki\/Subcommand:-phat\nMAFFT - https:\/\/mafft.cbrc.jp\/alignment\/software\/\nRAxML -ng - https:\/\/github.com\/amkozlov\/raxml-ng\nPaPaRa - https:\/\/cme.h-its.org\/exelixis\/web\/software\/papara\/index.html\nEPA-ng - https:\/\/github.com\/Pbdas\/epa-ng\nphyloseq R package - http:\/\/joey711.github.io\/phyloseq\/index.html\nvegan R package - https:\/\/cran.r-project.org\/web\/packages\/vegan\/index.html\n\nAnd of course the container-based technologies:\n\nDocker - https:\/\/www.docker.com\/\nSingularity - https:\/\/sylabs.io\/singularity\/\n\nLicense\nPEMA is under the GNU GPLv3 license (for 3rd party components separate licenses apply).\nCitation\nHaris Zafeiropoulos, Ha Quoc Viet, Katerina Vasileiadou, Antonis Potirakis, Christos Arvanitidis, Pantelis Topalis, Christina Pavloudi, Evangelos Pafilis, PEMA: a flexible Pipeline for Environmental DNA Metabarcoding Analysis of the 16S\/18S ribosomal RNA, ITS, and COI marker genes, GigaScience, Volume 9, Issue 3, March 2020, giaa022, https:\/\/doi.org\/10.1093\/gigascience\/giaa022\n","218":"WORK IN PROGRESS -- currently under revision\nDIGITAL MORPHOLOGIES: Environmentally-Influenced Generative Forms\nWe present a generative method to grow triangular meshes with organically-shaped features. Through the application of simplified forces, millions of particles develop into complex 3D forms in silico. These forms interact with external environments in a variety of ways, allowing for the integration of the proposed technique with pre-existing 3D objects and scenes. Large simulation sizes were computationally achieved through the massively parallel capabilities of modern Graphics Processing Units (GPUs).\nMore info here.\nImplementation\nUsing C++. Tested on OSX.\nDependencies\n\nEigen3 for Vector3D\nlibigl for viewer\n\nSample Output\n\n\n\n","219":"monitor\nNear real-time monitor of environmental conditions\n","220":"Whisp\nAn Environmental Sound Classifier\nTry it now!\nhttps:\/\/whisp.onrender.com\n(Current works on desktop Firefox and mobile Safari on iOS!)\nI wrote a bit about Whisp, the ESC-50 dataset, training an environmental sound classifier, and some insights I had along the way while testing it in the field on my blog A Quite Life.\nOverview\nThis project comprises of three main parts:\n\n\nSpectrogram generation notebook, which shows you how to make spectrograms from the ESC-50 dataset. It also shows you how to make gifs as well, for fun ;)\n\n\nLearner notebook, which shows how to build our classification model with fastai\n\n\nWeb app, which allows you to predict sound classfication with our model!\n\n\nInstallation\nIts probably a good idea to fork this repo as you may end up working on different machines\nInstall conda:\nbrew install conda\nCreate a new conda environment:\nconda create -n whisp python=3.6\nActivate your environment:\nconda activate whisp\nClone repo, move into the whisp directory and install required libraries:\ngit clone https:\/\/github.com\/aquietlife\/whisp\ncd whisp\npip install -r requirements.txt\nFinally, make sure to get the ESC-50 dataset:\ncurl -LO https:\/\/github.com\/karoldvl\/ESC-50\/archive\/master.zip\nunzip master.zip\nThen you should be good to go!\nStart up Jupyter to play in the notebooks:\njupyter notebook\nSpectrogram Generator\nCats\n\nFireworks\n\nSea Waves\n\nSirens\n\nAll of our pretraining data munging can be found here:\nSpectrogram Generator notebook\nWalk through the notebook, which guides you through creating all the spectrogram data needed for the learner notebook, as well as some bonus code for generating gifs like the ones above.\nWhisp is trained on the ESC-50 dataset\nThe paper on this dataset is short and fun to read :)\nLearner Model\n\nYou can train our environmental sound classifier with this notebook:\nLearner notebook\nBefore running this notebook, please make sure you have generated the spectrograms from the Spectrogram Generator notebook.\nYou will also need to be running this notebook on a GPU machine. I've been using Paperspace. More instructions on setting up your Paperspace machine can be found here.\nSsh into your paperspace machine, clone this repo, and then go through the Spectrogram Generator notebook above to generate your spectrograms for learning.\nssh paperspace@xxx.xxx.xxx.xxx\nFollow the Installation instructions above, but when you get to starting Jupyter notebook, use this command instead:\njupyter notebook --no-browser --port=8889 --NotebookApp.allow_remote_access=True\nOpen up another tab and ssh into your machine again, like so:\nssh -N -L localhost:8888:localhost:8889 paperspace@xxx.xxx.xxx.xxx\nIt appears to hang after enter on password, but its all good.\nBack in the first tab, copy and paste the Jupyter notebook url, but change 8889 to 8888 like so:\nhttp:\/\/localhost:8888\/?token=UNIQUE_TOKEN\nFrom there you should be able to run all the notebooks, so start with the Spectrogram Generator notebook to create your spectrograms for training :)\nAfter creating your spectrograms, you can run through the learner notebook.\nAt the end of our second set of training, we get the following results:\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\n\n\n\n\n1\n1.063904\n1.055990\n0.325000\n\n\n2\n1.036396\n2.332567\n0.562500\n\n\n3\n1.049258\n1.470638\n0.387500\n\n\n4\n1.032500\n1.107848\n0.337500\n\n\n5\n0.924266\n1.392631\n0.417500\n\n\n6\n0.768478\n0.623403\n0.212500\n\n\n7\n0.596911\n0.535597\n0.165000\n\n\n8\n0.446205\n0.462682\n0.160000\n\n\n9\n0.325181\n0.419656\n0.135000\n\n\n10\n0.251277\n0.402070\n0.127500\n\n\n\n0.122500 or 87.25% accuracy!\nAt the end of the notebook, we export our model export.pkl in the app\/model directory to be used in our web app ^_^\nWeb Server\nIf you have errors running the app with errors about 'installing Python as a framework', try runnning conda install matplotlib\nTo run the web server, run:\npython app\/server.py serve\nThe app is served at http:\/\/0.0.0.0:8008\nYou can test uploading files from the field_recordings directory, which has three 5-second recordings that I made.\nDeployment\nThe repo is set up to deploy easily to any number of web hosting services that support Docker.\nI ended up going with Render, but you can use whatever works for you :)\nMisc\nYou can create movies from the spectrograms with the following command:\nffmpeg -i animated.gif -movflags faststart -pix_fmt yuv420p -vf \"scale=trunc(iw\/2)*2:trunc(ih\/2)*2\" video.mp4\nfrom here:\nhttps:\/\/unix.stackexchange.com\/questions\/40638\/how-to-do-i-convert-an-animated-gif-to-an-mp4-or-mv4-on-the-command-line\nHappy listening!\n","221":"Whisp\nAn Environmental Sound Classifier\nTry it now!\nhttps:\/\/whisp.onrender.com\n(Current works on desktop Firefox and mobile Safari on iOS!)\nI wrote a bit about Whisp, the ESC-50 dataset, training an environmental sound classifier, and some insights I had along the way while testing it in the field on my blog A Quite Life.\nOverview\nThis project comprises of three main parts:\n\n\nSpectrogram generation notebook, which shows you how to make spectrograms from the ESC-50 dataset. It also shows you how to make gifs as well, for fun ;)\n\n\nLearner notebook, which shows how to build our classification model with fastai\n\n\nWeb app, which allows you to predict sound classfication with our model!\n\n\nInstallation\nIts probably a good idea to fork this repo as you may end up working on different machines\nInstall conda:\nbrew install conda\nCreate a new conda environment:\nconda create -n whisp python=3.6\nActivate your environment:\nconda activate whisp\nClone repo, move into the whisp directory and install required libraries:\ngit clone https:\/\/github.com\/aquietlife\/whisp\ncd whisp\npip install -r requirements.txt\nFinally, make sure to get the ESC-50 dataset:\ncurl -LO https:\/\/github.com\/karoldvl\/ESC-50\/archive\/master.zip\nunzip master.zip\nThen you should be good to go!\nStart up Jupyter to play in the notebooks:\njupyter notebook\nSpectrogram Generator\nCats\n\nFireworks\n\nSea Waves\n\nSirens\n\nAll of our pretraining data munging can be found here:\nSpectrogram Generator notebook\nWalk through the notebook, which guides you through creating all the spectrogram data needed for the learner notebook, as well as some bonus code for generating gifs like the ones above.\nWhisp is trained on the ESC-50 dataset\nThe paper on this dataset is short and fun to read :)\nLearner Model\n\nYou can train our environmental sound classifier with this notebook:\nLearner notebook\nBefore running this notebook, please make sure you have generated the spectrograms from the Spectrogram Generator notebook.\nYou will also need to be running this notebook on a GPU machine. I've been using Paperspace. More instructions on setting up your Paperspace machine can be found here.\nSsh into your paperspace machine, clone this repo, and then go through the Spectrogram Generator notebook above to generate your spectrograms for learning.\nssh paperspace@xxx.xxx.xxx.xxx\nFollow the Installation instructions above, but when you get to starting Jupyter notebook, use this command instead:\njupyter notebook --no-browser --port=8889 --NotebookApp.allow_remote_access=True\nOpen up another tab and ssh into your machine again, like so:\nssh -N -L localhost:8888:localhost:8889 paperspace@xxx.xxx.xxx.xxx\nIt appears to hang after enter on password, but its all good.\nBack in the first tab, copy and paste the Jupyter notebook url, but change 8889 to 8888 like so:\nhttp:\/\/localhost:8888\/?token=UNIQUE_TOKEN\nFrom there you should be able to run all the notebooks, so start with the Spectrogram Generator notebook to create your spectrograms for training :)\nAfter creating your spectrograms, you can run through the learner notebook.\nAt the end of our second set of training, we get the following results:\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\n\n\n\n\n1\n1.063904\n1.055990\n0.325000\n\n\n2\n1.036396\n2.332567\n0.562500\n\n\n3\n1.049258\n1.470638\n0.387500\n\n\n4\n1.032500\n1.107848\n0.337500\n\n\n5\n0.924266\n1.392631\n0.417500\n\n\n6\n0.768478\n0.623403\n0.212500\n\n\n7\n0.596911\n0.535597\n0.165000\n\n\n8\n0.446205\n0.462682\n0.160000\n\n\n9\n0.325181\n0.419656\n0.135000\n\n\n10\n0.251277\n0.402070\n0.127500\n\n\n\n0.122500 or 87.25% accuracy!\nAt the end of the notebook, we export our model export.pkl in the app\/model directory to be used in our web app ^_^\nWeb Server\nIf you have errors running the app with errors about 'installing Python as a framework', try runnning conda install matplotlib\nTo run the web server, run:\npython app\/server.py serve\nThe app is served at http:\/\/0.0.0.0:8008\nYou can test uploading files from the field_recordings directory, which has three 5-second recordings that I made.\nDeployment\nThe repo is set up to deploy easily to any number of web hosting services that support Docker.\nI ended up going with Render, but you can use whatever works for you :)\nMisc\nYou can create movies from the spectrograms with the following command:\nffmpeg -i animated.gif -movflags faststart -pix_fmt yuv420p -vf \"scale=trunc(iw\/2)*2:trunc(ih\/2)*2\" video.mp4\nfrom here:\nhttps:\/\/unix.stackexchange.com\/questions\/40638\/how-to-do-i-convert-an-animated-gif-to-an-mp4-or-mv4-on-the-command-line\nHappy listening!\n","222":"Figaro Elixir\n\nThis project is based on figaro gem for Rails written by Steve Richert.\nIt's was created to manage ENV configuration for Elixir applications.\nHow does it work?\nFigaro parses a git-ignored YAML file in your application and loads its values into environmental variables.\nThis is very handy for production environments when you don't want to store some of credentials in your repository.\nInstallation\nAdd Figaro Elixir as a dependency in your mix.exs file.\ndefp deps do\n  [\n    # ...\n    {:figaro_elixir, \"~> 1.0.0\"}\n  ]\nend\nYou should also update your applications list to include Figaro:\ndef application do\n  [\n     applications: [\n       # ...\n       :figaro_elixir\n     ]\n  ]\nend\nOnce you've done that, run mix deps.get in your command line to fetch the dependency.\nUsage\nThe basic requirement is to have application.yml file in your project config directory.\nFigaro will read it, parse it and use it to store environmental variables.\nPlease note that ENV is a simple key\/value store with the following features:\n\nall values are converted to strings\ndeeply nested configuration structures are not possible\n\nSimple example\nYou can very easily start using Figaro for Elixir. Just create an appropriate file:\n# config\/application.yml\n\nfoo: bar\nbaz: qux\nAnd run iex -S mix in your terminal. You will have an access to configuration values via FigaroElixir.env or System environmental variables:\niex(1)> FigaroElixir.env\n%{\"baz\" => \"qux\", \"foo\" => \"bar\"}\niex(2)> FigaroElixir.env[\"baz\"]\n\"qux\"\niex(3)> System.get_env(\"foo\")\nnil\niex(4)> System.get_env(\"FOO\")\n\"bar\"\nKeep in mind that system environmental variables keys are uppercased.\nEnvironment-specific configuration\nThe power of Figaro elixir comes from distinguishing environments based on Mix.env property.\nYou may have a file defined like this:\na: a\nb: ~\n\ntest:\n  c: 1\n  d: ~\nAnd then after running MIX_ENV=test iex -S mix you will see:\niex(1)> FigaroElixir.env\n%{\"a\" => \"a\", \"b\" => \"~\", \"c\" => \"1\", \"d\" => \"~\"}\niex(2)> FigaroElixir.env[\"c\"]\n\"1\"\niex(3)> System.get_env(\"C\")\n\"1\"\nThat's it. You don't have to do anything more.\nCaveats\nIf you are using escript build tool, you need to have :mix among your apps in mix.exs file and copy application.yml file to your rel\/project_name\/config directory.\nAbout the author\nMy name is Kamil Lelonek, I'm a full-stack developer and polyglot programmer. I love playing with different languages, technologies and tools. You can visit my website read my blog or follow me on twitter. In case of any problems or suggestions do not hesitate and create a pull request.\n","223":"EnvironmentControllerKata\nWhat is the best way to design a test that needs to check several things about the state of the system? This example is a part of an environmental control system. One test should check that when the temperature is very cold, the alarm, header, and blower are all turned on. There are other tests which check the state of the system in other conditions.\n\n\nLook at the example test cases and decide which design you find easiest to understand and work with.\n\n\nI have a feeling the DSL that Bob chose for his example isn't as readable as he thinks it is. I think you could do better. Re-write the test using Approvals and design a better Printer.\n\n\nRe-evaluate which test cases you find easiest to understand and work with.\n\n\nAcknowledgements\nThis exercise is based on an example in the book \"Clean Code\" by Robert C. Martin, pages 128-129.\n","224":"EnvironmentControllerKata\nWhat is the best way to design a test that needs to check several things about the state of the system? This example is a part of an environmental control system. One test should check that when the temperature is very cold, the alarm, header, and blower are all turned on. There are other tests which check the state of the system in other conditions.\n\n\nLook at the example test cases and decide which design you find easiest to understand and work with.\n\n\nI have a feeling the DSL that Bob chose for his example isn't as readable as he thinks it is. I think you could do better. Re-write the test using Approvals and design a better Printer.\n\n\nRe-evaluate which test cases you find easiest to understand and work with.\n\n\nAcknowledgements\nThis exercise is based on an example in the book \"Clean Code\" by Robert C. Martin, pages 128-129.\n","225":"Anomaly Detection In An IoT-Acquired Environmental Sensor Data\nAbstract\nA demand in monitoring a landfill site is increasing. A landfill site produces methane which is a poisonous gas and harmful for the existence of nature. The monitoring of the landfill sites are made possible using sensors, but the data quality issues arising from sensors persist. This research focusses on solving the problem of anomaly detection, in turn, solving the issues related to Data Quality and giving an indication for the presence of a subtle anomaly. An exhaustive search to solve the problem and to apply the existing techniques is the core idea. This also involved speaking to other researchers from the industry. Basic techniques ranging from Gaussian Mixture Model to an Autoencoder is implemented. Finally, Various problems in finding a perfect solution are reported, and an ensemble approach to solving the problem of anomaly detection in ecological monitoring is proposed.\n","226":"enviro_treaties\n","227":"moveVis \n\n\n\n\n\n\n\nIntroduction\nmoveVis provides tools to visualize movement data (e.g. from GPS tracking) and temporal changes of environmental data (e.g. from remote sensing) by creating video animations. It works with move and raster class inputs and turns them into ggplot2 frames that can be further customized. moveVis uses gifski (wrapping the gifski cargo crate) and av (binding to FFmpeg) to render frames into animated GIF or video files.\nA peer-reviewed open-access paper accompanying moveVis has been published in Methods in Ecology and Evolution.\n\n\nFigure 1: Example movement tracks nearby Lake of Constance on top of a OSM watercolor and a mapbox satellite base map\n\n\n\nFigure 2: Example movement tracks nearby Lake of Constance and a gradient base layer faded over time\nInstallation\nWith version 0.10.0, the package has been rewritten from the ground up with the goal to make it easier to customize the appearance of movement animations. Thus, the logic of the package, its functions and their syntax have changed.\nThe latest stable version of moveVis can be installed from CRAN:\ninstall.packages(\"moveVis\")\nThe development version can be installed from GitHub:\ndevtools::install_github(\"16EAGLE\/moveVis\")\nCode written for moveVis version <=0.9.9 will not work with newer versions, but it is quite simple and thus highly recommended to switch to the new syntax due to a variety of advantages. moveVis version <=0.9.9 can still be downloaded here and installed manually:\nsetwd(\"your\/download\/directory\")\ninstall.packages(\"moveVis-0.9.9.tar.gz\", repos = NULL)\nFunction overview\nmoveVis includes the following functions, sorted by the order they would be applied to create an animation from movement and environmental data:\nPreparing movement tracks\n\ndf2move() converts a data.frame into a move or moveStack object. This is useful if you do not usually work with the move classes and your tracks are present as data.frames.\nalign_move() aligns single and multi-individual movement data to a uniform time scale with a uniform temporal resolution needed for creating an animation from it. Use this function to prepare your movement data for animation depending on the temporal resolution that suits your data.\nsubset_move() subsets a move or moveStack by a given time span. This is useful if you want to create a movement animation of only a temporal subset of your data, e.g. a particular day.\n\nCreating frames\n\nget_maptypes() returns a character vector of available map types that can be used with frames_spatial(). moveVis supports OpenStreetMap and Mapbox basemap imagery. Alternatively, you can provide custom imagery to frames_spatial().\nframes_spatial() creates a list of ggplot2 maps displaying movement. Each object represents a single frame. Each frame can be viewed or modified individually. The returned list of frames can be animated using animate_frames().\nframes_graph() creates a list of ggplot2 graphs displaying movement-environment interaction. Each object represents a single frame. Each frame can be viewed or modified individually. The returned list of frames can be animated using animate_frames().\n\nAdapting frames\n\nadd_gg() adds ggplot2 functions (e.g. to add layers such as points, polygons, lines, or to change scales etc.) to the animation frames created with frames_spatial() or frames_graph(). Instead of creating your own ggplot2 functions, you can use one of the other moveVis `add_``functions:\nadd_labels() adds character labels such as title or axis labels to animation frames created with frames_spatial() or frames_graph().\nadd_scalebar() adds a scalebar to the animation frames created with frames_spatial() or frames_graph().\nadd_northarrow() adds a north arrow to the animation frames created with frames_spatial() or frames_graph().\nadd_progress() adds a progress bar to animation frames created with frames_spatial() or frames_graph().\nadd_timestamps() adds timestamps to animation frames created with frames_spatial() or frames_graph().\nadd_text() adds static or dynamically changing text to the animation frames created with frames_spatial() or frames_graph().\nadd_colourscale() adjusts the colour scales of the animation frames created with frames_spatial() and custom map imagery using the r_list argument.\njoin_frames() side-by-side joins the ggplot2 objects of two or more frames lists of equal lengths into a single list of ggplot2 objects per frame using cowplot::plot_grid. This is useful if you want to side-by-side combine spatial frames returned by frames_spatial() with graph frames returned by frames_graph().\nget_frametimes() extracts the timestamps associated with each frame of a list of frames created using frames_spatial() or frames_graph() and returns them as a vector.\n\nAnimating frames (as GIF or video)\n\nsuggest_formats() returns a selection of suggested file formats that can be used with out_file of animate_frames() on your system.\nanimate_frames() creates an animation from a list of frames computed with frames_spatial(), frames_graph() or  join_frames().\n\nViewing movement tracks\n\nview_spatial() displays movement tracks on an interactive mapview or leaflet map.\n\nProcessing settings\n\nuse_multicore() enables multi-core usage for computational expensive processing steps.\nuse_disk() enables the usage of disk space for creating frames, which can prevent memory overload when creating frames for very large animations.\n\nGet started\nThe following example shows how to make a simple animation using a default base map by first aligning your movement data to a uniform time scale, creating a list of ggplot2 frames and turning these frames into an animated GIF:\nlibrary(moveVis)\nlibrary(move)\n\ndata(\"move_data\", package = \"moveVis\") # move class object\n# if your tracks are present as data.frames, see df2move() for conversion\n\n# align move_data to a uniform time scale\nm <- align_move(move_data, res = 4, unit = \"mins\")\n\n# create spatial frames with a OpenStreetMap watercolour map\nframes <- frames_spatial(m, path_colours = c(\"red\", \"green\", \"blue\"),\n                         map_service = \"osm\", map_type = \"watercolor\", alpha = 0.5) %>% \n  add_labels(x = \"Longitude\", y = \"Latitude\") %>% # add some customizations, such as axis labels\n  add_northarrow() %>% \n  add_scalebar() %>% \n  add_timestamps(m, type = \"label\") %>% \n  add_progress()\n\nframes[[100]] # preview one of the frames, e.g. the 100th frame\n\n# animate frames\nanimate_frames(frames, out_file = \"moveVis.gif\")\n\nExamples\nYou can find code examples on how to use moveVis here:\nExample 1: Creating a simple movement animation\nExample 2: Customizing frames\nExample 3: Using a mapbox satellite base map\nExample 4: View movement tracks\nReal-data example using White Storks (Ciconia ciconia) migration movement data [.docx]\nCode snippets\nThese commented moveVis code snippets, addressing specific issues or questions, could also be helpful to you:\nHow to hold the last frame of an animation for a defined time and make it look good by using path_fade\nHow to display the full traces of each path using trace_show and trace_colour with frames_spatial()\nHow to colour paths based on a continuous variable\nHow to assign multiple path colours per individual, e.g. to indicate behavioral segments\nHow to adapt the path legend of frames created with frames_spatial()\nHow to create a data.frame containing each track coordinate per frame\nHow to overlay frames with additional transparent rasters changing over time (hacky, not a very optimal solution)\nFurther resources\nDetailed code examples explaining how to use specific functions are provided at the function help pages. User contributions such as code examples or tutorials are very welcome and are linked below as soon as they have been spotted somewhere on the web:\nAnimating animal tracks from multiple years over a common year with moveVis: An example with Blue Whale Argos tracks on Movebank by Daniel M. Palacios, Marine Mammal Institute, Oregon State University\nReproducible example of how to combine animal tracking data, tidal water height data and a heightmap to visualize animal movement with moveVis by Henk-Jan van der Kolk, The Netherlands Institute of Ecology (NIOO-KNAW)\nHow to build animated tracking maps using tracking data in Movebank and environmental covariates in track and raster annotations from EnvDATA with moveVis by Sarah C. Davidson, Data Curator at Movebank\nMentions\nBlog post: Featured article in Issue 11.5: Our May issue is now online! by Methods in Ecology and Evolution\nFeatures to be added\nThings and features that should be added in future versions of moveVis (feel free to contribute to this list using a pull request):\nNear future:\n\nfollow population mode\nfollow individual mode\n\nSome day:\n\n3D animations, e.g. for including altitude data\n\nRelated packages\nThe Department of Remote Sensing of the University of W\u00fcrzburg has developed other R packages that might interest you:\n\ngetSpatialData, a package to query, preview and download satellite data,\nRStoolbox, a package providing a wide range of tools for every-day remote sensing processing needs,\nrsMove, a package providing tools to query and analyze movement data using remote sensing.\n\nFor other news on the work at at the Department of Remote Sensing of the University of W\u00fcrzburg, click here.\nAcknowledgements\nThis initiative is part of the Opt4Environment project and was funded by the German Aerospace Center (DLR) on behalf of the Federal Ministry for Economic Affairs and Energy (BMWi) with the research grant 50 EE 1403.\n\n\n\n\n\n\n\n\nCitation\nAn open-access paper accompanying the moveVis R package has been peer-reviewed by and published in 'Methods in Ecology and Evolution' (see https:\/\/doi.org\/10.1111\/2041-210X.13374). Please cite moveVis, e.g. when you use it in publications or presentations, using the output of citation(\"moveVis\") or as follows:\nSchwalb-Willmann, J.; Remelgado, R.; Safi, K.; Wegmann, M. (2020). moveVis: Animating movement trajectories in synchronicity with static or temporally dynamic environmental data in R. Methods Ecol Evol. 2020; 11: 664\u2013669. https:\/\/doi.org\/10.1111\/2041-210X.13374\n","228":"env-config\n\n\n\nThis is a Clojure(Script) library for enabling easy and consistent config map overrides via environment variables.\nThis is useful for library authors who want to add some flexibility how their libraries can be configured.\nIntro\nUsually library configuration is achieved via a config map specifying keywords with individual config values.\nThis config map can be provided directly (e.g. passed via an api call), via a build configuration or by some other means.\nFor example in ClojureScript it could be passed via :compiler > :external-config.\nSometimes for ad-hoc tweaks it would be preferable to be able to override config values\nby defining environment variables instead of touching build tool configuration (which is usually under source control).\nThis library helps you do that consistently:\n\nwe define a naming scheme how env variables map to config keys\nwe define a coercion protocol which determines how strings from env variables are converted to Clojure values\n\nExample\nWe want to support nested config maps. Let's look at example env variables with some nesting:\nOOPS\/COMPILER\/MAX_ITERATIONS=10\nOOPS\/RUNTIME\/DEBUG=true\nOOPS\/RUNTIME\/WELCOME-MESSAGE=hello\nOOPS\/RUNTIME\/DATA=~{:some (str \"data\" \" via\" \" read-string\")}\nOOPS\/RUNTIME\/KEY=:some-keyword\nOOPS\/RUNTIME=something   <= this will cause a naming conflic warning\n\nA call to (env-config.core\/make-config \"oops\" (get-env-vars)) will return:\n{:compiler {:max-iterations 10}\n :runtime {:debug true\n           :welcome-message \"hello\"\n           :key :some-keyword\n           :data {:some \"data via read-string\"}}\n\nYou can observe several properties:\n\nforward slashes are used as separators\nto follow Clojure conventions, names are converted to lower-case and underscores turned into dashes\nprefix \"oops\" is stripped because it was specified as a library prefix\nvalues are naturally coerced to booleans, numbers, keywords, etc.\nyou can use full power of read-string if you prepend value with ~\n\nAlso please note that existence of a variable name which is a prefix of another variable name will cause\nnaming conflict warning and will be ignored (OOPS\/RUNTIME is prefix of OOPS\/RUNTIME\/DEBUG in our example above).\nSome shells like Bash do not allow slashes in variable names, you can use two underscores instead of a slash.\nIntegration\nYou probably want to merge the config coming from env-config over your standard config coming from a build tool.\nFor inspiration look at the commit\nwhich integrated env-config into cljs-oops library.\nPlease note that make-config-with-logging does not read environment directly. You have to pass it a map with variables.\nI used this simple implementation to get them:\n(defn get-env-vars []\n  (-> {}\n      (into (System\/getenv))\n      (into (System\/getProperties))))\n\nLogging\nI needed a way how to report issues with naming conflicts or for example problems when evaluting values via read-string.\nI didn't want to introduce another dependency so I decided to build internal subsystem for collecting \"reports\". It is up\nto you to inspect reports and communicate them somehow.\nFor convenience I have implemented a helper function which dynamically checks for availability of clojure.tools.logging\nand uses it for logging reports.\nTo get standard logging for free include dependency on clojure.tools.logging into your project and use make-config-with-logging\nto obtain your configs.\nCoercion\nWe provide a standard set of coercion handlers.\nAs you can see from the default-coercers list the rules are pretty simple. You might want to provide your own handlers.\nWriting own coercion handlers\nCoercion handlers are asked in the order in which they were specified to make-config.\nEach handler is passed key path in the config map and raw string value coming from environment.\nThe handler should answer either:\n\nnil which means \"I'm not interested, pass it to someone else\"\n:omit which means \"ignore this value due to an error\"\na value wrapped in Coerced instance (to distinguish it from nil and :omit)\n\nIf no handler was interested we use the raw value as-is.\nLook at the example of the most complex standard coercer:\n(defn code-coercer [path val]\n  (if (string-starts-with? val \"~\")\n    (let [code (.substring val 1)]\n      (try\n        (->Coerced (read-string code))\n        (catch Throwable e\n          (report\/report-warning! (str \"unable to read-string from \" (make-var-description (meta path)) \", \"\n                                       \"attempted to eval code: '\" code \"', \"\n                                       \"got problem: \" (.getMessage e) \".\"))\n          :omit)))))\nPlease note that the path vector has attached some metadata with original raw values which may be handy when\nreporting warnings\/errors. You should use env-config.impl.report functionality to report errors in a standard way.\nFAQ\n\nMy shell does not support variable names with slashes. What now?\n\nYou can use two underscores instead of a slash. Or alternatively you might want to use env command to launch your command with\ndefined variables without shell naming restrictions. See this stack overflow answer.\nFor example:\nenv OOPS\/COMPILER\/MAX_ITERATIONS=10 OOPS\/RUNTIME\/DEBUG=true command\n\nI personally use fish shell and prefer slashes to visually communicate the nested config structure.\n\nCan this be used in self-hosted mode?\n\nYes, thanks to arichiardi. Since v0.2.0 you can use this library to configure scripts running\nunder Planck or Lumo.\n","229":"\nUsing drones to find environmentally efficient fracking sites\nInspiration\nWe were inspired to pursue this project after talking to Oxy about carbon emissions caused by fracking. They told us about how their biggest carbon footprint comes from fracking. We feel that this is an area that can use a lot of improvement through technology, ultimately for the benefit of the environment since fracking in the right locations for optimal efficiency is critical. Additionally, runoff from fracking operations can pollute rivers and ultimately go into oceans, which is another factor we considered critical for determining the location of potential fracking sites.\nWhat it does\nWe made a mobile app that allows oil\/natural gas companies to deploy drones over their land to look for the most environmentally optimal fracking site. The app receives livestreams from each registered drone. The drones keep track of potential fracking sites after scoring them using machine learning, and all the potential sites are sorted and then aggregated for the user to see in the application.\nHow we built it\nThe Google Flutter SDK was used with the DJI native platform library using method channels to communicate information from simple UI actions to sending entire native Android views. Keras was used for the Machine Learning.\nChallenges we ran into\nThe DJI API was not easy to use. We had a really hard time getting the live-streaming to work, and there was not much work done on this before so it was difficult to find relevant forum responses online. However, we experimented with different aspects of Flutter to make it eventually work (and it was pretty elegant too!).\nAccomplishments that we're proud of\nGetting the live-stream to work and implementing a machine learning model for scoring fracking sites. Building an all-around beautiful app that can positively impact our beautiful planet.\nWhat we learned\nDrones are amazingly powerful pieces of technology that need to be applied in so many more aspects of our lives!\nWhat's next for FrackFinder\nThe biggest next step for FrackFinder is to incorporate real industry data into the product. Currently, the dataset was curated by the creators (us!) and was thus not professionally validated. With a company dataset, we will have an even more robust model. We also want to make the drones autonomous. One other cool thing we want to do is integrate Virtual Reality into our project so the user can watch the drone live-stream through a VR headset.\n\n\n","230":"OpenObservatory\nA Free and Open Source environmental observation station.\nFor documentation of the project, see http:\/\/www.openobservatory.io \nFor the open source hardware, see https:\/\/workspace.circuitmaker.com\/Projects\/Details\/Yannick-Verbelen\/WeatherStation-3\n","231":"NoiseLevel\n","232":"Environmental Applications of GIS, Winter 2017\nDartmouth\nProf. James Dietrich, james.t.dietrich@dartmouth.edu\n","233":"Employee-Satisfaction-and-Attrition\nAnalysis of attrition based on environmental satisfaction from a Kaggle dataset.\n","234":"Table of Contents generated with DocToc\n\nHow to obtain the library\nOverview\nChanging the defaults\n\nChanging the name of the default properties file\nChanging the extension of the properties file\nChanging the location that configuration is sourced\nChanging the location that environmental overrides are sourced\n\n\nMulti Environmental Variable Configuration\nOperational Overrides\nThread Safety\nMap<String,String>\nProperty Merging Strictness\nProperty values and Placeholder (${}) Replacement\n\nObtaining Resolved and Unresolved properties one at a time\nUsing the environment to resolve placeholders\nTrimming Property Values of whitespace\nThread Safety\n\n\nComposite Builder\nUsing in Spring\n\nHow to obtain the library\n    <dependency>\n       <groupId>org.greencheek<\/groupId>\n       <artifactId>environment-properties-merger-core<\/artifactId>\n       <version>1.0.0<\/version>\n    <\/dependency>\nThe maven repositories are located at:\n   https:\/\/raw.github.com\/tootedom\/tootedom-mvn-repo\/master\/releases\/\n   https:\/\/raw.github.com\/tootedom\/tootedom-mvn-repo\/master\/snapshots\/\n\nOverview\nA simple library that allows for the sourcing of a standard java .properties file\n(http:\/\/docs.oracle.com\/javase\/6\/docs\/api\/java\/util\/Properties.html) for use in application configuration.\nThe properties files are sourced from either the classpath (classpath:) or filesystem (filesystem:) and can be overridden\nbased on either environment variables or system properties.  For example.  Imagine in your architecture, you have defined\nthe environment variable \"${ENV}\", which denotes the environment in which the current server resides.  This\nvariable has a different value for the different environments you have, for example:\n\nci\nintegration\ntest\nloadtest\nstaging\nproduction\n\nThe library by default allows you to have the following structure of files within you project (src\/main\/resources)\n\u2514\u2500\u2500 config\n    \u251c\u2500\u2500 default.properties\n    \u2514\u2500\u2500 environments\n        \u2514\u2500\u2500 ci.properties\n        \u2514\u2500\u2500 integration.properties\n        \u2514\u2500\u2500 test.properties\n        \u2514\u2500\u2500 loadtest.properties\n        \u2514\u2500\u2500 staging.properties\n        \u2514\u2500\u2500 production.properties\n\nAt run time, given the value of \"production\" for the ${ENV} variable, the lib will return a Properties object that is\na combination (merge) of:\n\u2514\u2500\u2500 config\n    \u251c\u2500\u2500 default.properties\n    \u2514\u2500\u2500 environments\n        \u2514\u2500\u2500 production.properties\n\nWhat this gives you is the ability to have different configuration deployed along with your application that has\nvarying configuration based on environmental settings.\nThe above can be achieved with the following:\nPropertiesMergerBuilder mergerBuilder = new EnvironmentSpecificPropertiesMergerBuilder();\np = mergerBuilder.buildProperties();\n\nThe idea of the library is that you distribute along with your application configuration properties.  The default.properties\ncontains a set of properties that contain defaults for the application configuration, lets say something like:\n\u2514\u2500\u2500 config\n    \u251c\u2500\u2500 default.properties\n\ncontains:\n   database.url=jdbc:mysql:\/\/localhost\/admin\n   database.username=user\n   database.password=pass\n\nYou then provide overrides to the defaults within properties files that match the value of the ${ENV} variable as it\nexists on your platform's architecture.  For example on your production environment you provide:\n\u2514\u2500\u2500 config\n\u2514\u2500\u2500 environments\n\u2514\u2500\u2500 production.properties\nthat contains configuration specific to the live environment\n   database.url=jdbc:mysql:\/\/bernard-app.dbw.production\/admin\n   database.username=user\n   database.password=pass\n\nThis way you can have varying configuration for the application that is distributed along with your application.\n\nChanging the defaults\nBy Default the library reads configuration from the classpath, looking for config\/default.properties and then files that\nare override based on the value of the ${ENV} variable from config\/environments\/${ENV}.properties.  This defaults are\nchangable:\nChanging the name of the default properties file\nThe following will change the name of the default properties file that is sourced from default.properties to global.properties:\n  PropertiesMergerBuilder mergerBuilder = new EnvironmentSpecificPropertiesMergerBuilder()\n  .setNameOfDefaultPropertiesFile(\"global\");\n  p = mergerBuilder.buildProperties();\n\nChanging the extension of the properties file\nThe following will change the extension of the properties file from properties to props:\n  PropertiesMergerBuilder mergerBuilder4 = new EnvironmentSpecificPropertiesMergerBuilder()\n  .setNameOfDefaultPropertiesFile(\"global\")\n  .setExtensionForPropertiesFile(\"props\");\n  p = mergerBuilder4.buildProperties();\n\nThe separator character can be changed from \".\" to something else, i.e. \"-\" via the following:\n  .setExtensionSeparatorCharForPropertiesFile('-')\n\nChanging the location that configuration is sourced\nBy default the configuration files is sourced from the classpath location: config\/.  This can be changed to either read\nfrom a different location on the classpath, or can be change to read from the file system:\n\nClasspath\n\nChanges to source from \/app\/config\/ on the classpath\nPropertiesMergerBuilder mergerBuilder = new EnvironmentSpecificPropertiesMergerBuilder()\n.setLocationForLoadingConfigurationProperties(\"classpath:\/app\/config\");\nProperties p = mergerBuilder.buildProperties();\n\n\nFileSystem\n\nChanges to source configuration from \/data\/opsoverrides\/myapp\/config\nPropertiesMergerBuilder mergerBuilder = new EnvironmentSpecificPropertiesMergerBuilder()\n.setLocationForLoadingConfigurationProperties(\"file:\/data\/application\/config\");\nProperties p = mergerBuilder.buildProperties();\n\nChanging to read from C:\/data\/opsoverrides\/myapp\/config on windows\n    PropertiesMergerBuilder mergerBuilder = new EnvironmentSpecificPropertiesMergerBuilder()\n    .setLocationForLoadingConfigurationProperties(\"file:C:\/data\/opsoverrides\/myapp\/config\");\n    Properties p = mergerBuilder.buildProperties();\n\nIt is often helpful for operations teams, or fellow developers not to deploy configuration properties embedded within\n.jar files, but have then distributed to a filesystem location that is on the classpath, i.e WEB-INF\/classess in a web\napplication.  It just helps when troubleshooting issues, and the verification of configuration quickly (over having to\nextract the configuration from a jar - say from within WEB-INF\/lib.  However, there's no strict rule about this; just\na preference.  Often when distributing a library for use by multiple applications, it is not avoidable; and configuration\nneeds to be distributed with the jar.  (See Operational Overrides later on).\n\nChanging the location that environmental overrides are sourced\nBy default the environmental overrides are sourced from the environment directory within the location\nspecified for where configuration is to be sourced.  For example the follow defines the application configuration\nto be read from the classpath at \/data\/config, and the environmental configuration is sourced from \/data\/config\/envs:\n    PropertiesMergerBuilder mergerBuilder = new EnvironmentSpecificPropertiesMergerBuilder()\n    .setLocationForLoadingConfigurationProperties(\"classpath:\/data\/config\")\n    .setRelativeLocationOfFilesOverridingDefaultProperties(\"envs\");\n    Properties p = mergerBuilder.buildProperties();\n\nMulti Environmental Variable Configuration\nThe library goes one step futher and allows you to configure the environmental setting so that you can differ not\njust on one environmental or system property, but on a sequence of environmental variables.  For example, imagine\nyou had both the environmental variable ${ENV} and system property ${os.arch}.  You can configure library to merge configuration in\norder fashion such that it sources:\n\n\/config\/default.properties\n\/config\/environments\/production.properties\n\/config\/environments\/production.x86_64.properties\n\n    PropertiesMergerBuilder resolverEnvAndOsBuilder = new EnvironmentSpecificPropertiesMergerBuilder()\n    .setVariablesUsedForSwitchingConfiguration(new String[] {\"ENV\",\"ENV,os.arch\"});\nRunning the above on a Macbook pro (OSX Snow Leopard\/Lion), with the ENV environment variable set to production\nwould resulting the following files being sourced and merged.\n\u2514\u2500\u2500 config\n    \u251c\u2500\u2500 default.properties\n    \u2514\u2500\u2500 environments\n        \u2514\u2500\u2500 production.properties\n        \u2514\u2500\u2500 production.x86_64.properties\n\n\nOperational Overrides\nThe library also has the concept of \"Operational Overrides\".  This gives the operations department a location on the\nfile system in which they can overwrite a specific property value used by your application without having to modify the\nconfiguration that you distribute with your application.  This can be useful for properties such as passwords, or\ndatabase connection strings etc; that only the operations department might know about.\nBy default the library will look for these overrides within the directory (on the filesystem),\nin \/data\/opsoverrides\/\/config  (the value of appname you need to specify.  On a windows machine the default\nis c:\\data\\opsoverrides**\\config).  For example the following will create a PropertiesMerger that reads\noperational overrides from the directory \/data\/opsoverrides\/bernard\/config (on windows this will be C:)\n    PropertiesMergerBuilder resolverEnvAndOsBuilder = new EnvironmentSpecificPropertiesMergerBuilder();\n    .setVariablesUsedForSwitchingConfiguration(new String[] {\"ENV\",\"ENV,os.arch\"})\n    .setApplicationName(\"bernard\")\n    Properties p = mergerBuilder.buildProperties();\nGiven the above, and a value of production for the ${ENV} variable, the configuration the will be sourced in the\norder top to bottom:\nclasspath:\n|\n\u2514\u2500\u2500 config\n    \u251c\u2500\u2500 default.properties\n    \u2514\u2500\u2500 environments\n        \u2514\u2500\u2500 production.properties\nfilesystem:\n|\n\u2514\u2500\u2500 \/data\n    \u251c\u2500\u2500 opsoverrides\n        \u251c\u2500\u2500 bernard\n            \u251c\u2500\u2500 config\n                \u251c\u2500\u2500 default.properties\n                    \u2514\u2500\u2500 environments\n                                \u2514\u2500\u2500 production.properties\n\nIn otherwords, the files are source in the order:\n\nclasspath:\/config\/default.properties\nclasspath:\/config\/environments\/${ENV}.properties\nfilesystem:\/data\/opsoverrides\/bernard\/config\/default.properties\nfilesystem:\/data\/opsoverrides\/bernard\/config\/environments\/${ENV}.properties\n\nThe location of where the Operational Overrides are loaded from can be changed, via setting a property on\nthe MergerBuilder.  For example, the following defines the operational overrides location to be\n\/data\/ops\/applicationX\/config:\n    PropertiesMergerBuilder mergerBuilder = new EnvironmentSpecificPropertiesMergerBuilder()\n    .setVariablesUsedForSwitchingConfiguration(new String[] {\"ENV\",\"ENV,os.arch\"})\n    .setLocationForLoadingOperationalOverrides(\"file:\/data\/ops\/applicationX\/config\");\n    Properties p = mergerBuilder.buildProperties();\nThe above in essence will result in the following being sourced:\n\nclasspath:\/config\/default.properties\nclasspath:\/config\/environments\/${ENV}.properties\nfilesystem:\/data\/ops\/applicationX\/config\/default.properties\nfilesystem:\/data\/ops\/applicationX\/config\/environments\/${ENV}.properties\n\n\nPlease note it is possible to set the operational overrides to point to a classpath location,\nby changing the file: prefix to classpath: on the resource.  However, the idea behind operational overrides\nis to give the ability to operational teams to adjust application properties quickly and easily.\ntherefore a file: location is probably the preferrable option.\n\nThread Safety\nThe PropertiesMergerBuilder is not thread safe, it is intended to by used by a single thread in order to create a PropertiesMerger\ninstance.  The PropertiesMerger instance is then thread safe for use by multiple threads.  The Builder is responsible for\ncreating the PropertiesMerger, once the PropertiesMerger has been created; it is safe for use by multiple threads.  The\nProperties object that is returned by the following java call, is thread safe:\n   PropertiesMergerBuilder mergerBuilder = new EnvironmentSpecificPropertiesMergerBuilder();\n   Properties p = mergerBuilder.buildProperties();\nThe above is equivalent to:\n   PropertiesMergerBuilder mergerBuilder = new EnvironmentSpecificPropertiesMergerBuilder();\n   PropertiesMerger merger = mergerBuilder.build();\n   Properties p = merger.getMergedProperties();\nObtaining a Map instead of a Properties Object\nRather than a Properties object you can obtain a Map<String,String> of the properties:\n   PropertiesMergerBuilder mergerBuilder = new EnvironmentSpecificPropertiesMergerBuilder();\n   PropertiesMerger merger = mergerBuilder.build();\n   Map<String,String> map = merger.getMergedPropertiesAsMap();\nProperty Merging Strictness\nIt is when the PropertyMerger is constructed; that the properties files are read from the classpath and\/or filesystem.\nDuring the resolution process (merging), the merger will compare the properties in the original Properties file (default.properties)\nand compare them against the properties in the overriding file.  If a property is defined in the overriding file; that\ndid not exist in the default properties; a warning will be logged (Just letting you know that a new property exists; for\nwhich there is no default value).  For example, a spelling mistake exists in the prod.properties:\ndefault.properties\nproduct-inventory.url=http:\/\/localhost:9090\/api\/list\nprod.properties\nproduct-inevntory.url=http:\/\/products.live.xxx:9090\/api\/list\nFor\n   PropertiesMergerBuilder mergerBuilder = new EnvironmentSpecificPropertiesMergerBuilder();\n   PropertiesMerger merger = mergerBuilder.build();\nIn testing you would see:\n\n11:40:24.431 [main] WARN  o.g.u.e.p.m.EnvironmentSpecificPropertiesMerger - NoMatchingPropertyWarning: Property \"product-inevntory.url\" from overriding properties does not exist in original properties\n\nIf you would rather have the PropertiesMerger b strict and throw and exception and fail to be contructed, you can\nset the merger to be strict, as follows:\n   PropertiesMergerBuilder mergerBuilder = new EnvironmentSpecificPropertiesMergerBuilder()\n   .setStrictMergingOfProperties(true);\n   PropertiesMerger merger = mergerBuilder.build();\nThen, during the construction of the PropertiesMerger from the mergerBuilder's build() method, you would receive the runtime exception:\norg.greencheek.utils.environment.propertyplaceholder.resolver.exception.NoMatchingPropertyException:\n\nException in thread \"main\" org.greencheek.utils.environment.propertyplaceholder.resolver.exception.NoMatchingPropertyException: NoMatchingPropertyWarning: Property \"product-inevntory.url\" from overriding properties does not exist in original properties\n\n\nProperty values and Placeholder (${}) Replacement\nAll of the above configuration\/code examples will not replace any variables (placeholder) that are in\nthe values for the properties in the returned Properties object.  For example, given the following property\ncontained within config\/default.properties, lets say,\ndatabase.server.cname=bernard-app.dbw.production\ndatabase.url=jdbc:mysql:\/\/${database.server.cname}\/admin\n\nThe value of database.url when obtained from the Properties object will still contain ${database.server.cname}\n    PropertiesMergerBuilder mergerBuilder = new EnvironmentSpecificPropertiesMergerBuilder();\n    Properties p = mergerBuilder.buildProperties();\n    \/\/\n    \/\/ Results in:\n    \/\/ {database.url=jdbc:mysql:\/\/${database.server.cname}\/admin, database.server.cname=bernard-app.dbw.production}\n    \/\/\nIn order to have placeholder replacement take place you have to use an additional builder that creates a PropertiesResolver.\nThe previous builder (PropertiesMergerBuilder), creates just a PropertiesMerger that is responsible for \"merging\"\nthe varying properties files that differ based on environmental settings.  The PropertiesResolver takes the merged\nproperties from the PropertiesMerger and resolves the variables from the values of the properties\n    PropertiesMergerBuilder mergerBuilder = new EnvironmentSpecificPropertiesMergerBuilder();\n    PropertiesResolverBuilder resolverBuilder = new EnvironmentSpecificPropertiesResolverBuilder();\n    PropertiesMerger merger = mergerBuilder.build();\n    Properties p = resolverBuilder.buildProperties(merger);\nOr to reduce the amount of code, a little, you can pass the PropertiesMergerBuilder directly to the buildProperties\nmethod of the PropertiesResolverBuilder.  The PropertiesResolverBuilder, just calls build on the builder, to obtain the\nPropertiesMerger from which it obtains the merged properties:\n    PropertiesMergerBuilder mergerBuilder = new EnvironmentSpecificPropertiesMergerBuilder();\n    PropertiesResolverBuilder resolverBuilder = new EnvironmentSpecificPropertiesResolverBuilder();\n    Properties p = resolverBuilder.buildProperties(mergerBuilder);\nObtaining Resolved and Unresolved properties one at a time\nEverytime you call resolverBuilder.buildProperties(mergerBuilder); to obtain a Properties object, a new PropertiesResolver\nand a Properties object will be created.  Therefore, you should really only create the Properties object once, and\nuse it in multiple place.  However, if you have a central place (object) to query that will return both a property with\nresolved variable and with unresolved variables; you can create a PropertiesResolver object, and query it for properties.\nThis will query its internal Properties object it obtained from the merger:\n\nCreate the PropertiesResolver\n\n    PropertiesMergerBuilder mergerBuilder = new EnvironmentSpecificPropertiesMergerBuilder();\n    PropertiesResolverBuilder resolverBuilder = new EnvironmentSpecificPropertiesResolverBuilder();\n    PropertiesMerger merger = mergerBuilder.build();\n    PropertiesResolver resolver = resolverBuilder.build(merger);\n\nQuery for Resolved Property\n\n   resolver.getProperty(\"database.url\")\n   \/\/\n   \/\/ Returns: jdbc:mysql:\/\/bernard-app.dbw.production\/admin\n   \/\/\n\nQuery for UnResolved Property\n\n   resolver.getUnResolvedProperty(\"database.url\")\n   \/\/\n   \/\/ Returns: jdbc:mysql:\/\/${database.server.cname}\/admin\n   \/\/\nUsing the environment to resolve placeholders\nBy default the Resolver will also resolve variables (placeholders), within the property values from both\nenvironment varibles available to the java process, and any java system properties (-D) that are set.  If you do not\nwish for this behaviour then you can turn it off by creating a VariablePlaceholderValueResolver and passing it to\nthe PropertiesResolverBuilder via the setPropertyValueResolver method:\n   PropertiesMergerBuilder mergerBuilder = new EnvironmentSpecificPropertiesMergerBuilder();\n   PropertiesResolverBuilder resolverBuilder = new EnvironmentSpecificPropertiesResolverBuilder();\n\n   ValueResolverConfig valueResolver = new VariablePlaceholderValueResolverConfig()\n   .setEnvironmentPropertiesResolutionEnabled(false)\n   .setSystemPropertiesResolutionEnabled(false);\n\n   resolverBuilder.setPropertyValueResolver(new VariablePlaceholderValueResolver(valueResolver));\n   p = resolverBuilder.buildProperties(mergerBuilder);\nTrimming Property Values of whitespace\nBy default the property values returned from the PropertiesResolver are trimmed of whitespace; from the beginning\nand end of the property value (java.lang.String.trim()).  This can be turned off at the PropertiesResolverBuilder level:\n   PropertiesMergerBuilder mergerBuilder = new EnvironmentSpecificPropertiesMergerBuilder();\n   PropertiesResolverBuilder resolverBuilder = new EnvironmentSpecificPropertiesResolverBuilder()\n   .setTrimmingPropertyValues(false);\n   PropertiesResolver resolver = resolverBuilder.build(mergerBuilder.build());\nThread Safety\nLike that of the PropertiesMergerBuilder, the PropertiesResolverBuilder is not thread safe, it is intended to by\nused by a single thread in order to construct a PropertiesResolver, which is then safe to use across multiple threads.\nThis too goes for the ValueResolver, and it's configuration.  The ValueResolver (VariablePlaceholderValueResolver)\nis thread safe after construction.\nLike that of the PropertiesMergerBuilder, you obtain the PropertiesResolver from the builder:\n    PropertiesMergerBuilder mergerBuilder = new EnvironmentSpecificPropertiesMergerBuilder();\n    PropertiesResolverBuilder resolverBuilder = new EnvironmentSpecificPropertiesResolverBuilder();\n    PropertiesMerger merger = mergerBuilder.build();\n    PropertiesResolver resolver = resolverBuilder.build(merger);\nYou can then use the constructed PropertiesResolver in multiple threads.  The Properties obtain returned via a\nresolverBuilder.buildProperties(mergerBuilder); is safe to use across multiple threads too.\n\nComposite Builder\nA Composite Builder is avialable that is a combination of the PropertiesMergerBuilder and the PropertiesResolverBuilder\nthat adds the method Properties buildResolvedProperties();, that returns the set of properties, with all\nembedded property values resolved.  The properties themselves come from a set of combined property files that are\nsource dependent on system or environment properties defined by the merger. Any property value that contain variables\n(placeholders i.e. ${..})  are resolved.    The composite builder was created as a means to reduce the number of lines\nof xml\/code when generating a Properties object to use as a Spring 3.1 PropertySources\nobject.\n    <bean id=\"environmentalProperties\" class=\"org.springframework.core.env.PropertiesPropertySource\">\n        <constructor-arg value=\"myEnvironmentProperties\"\/>\n        <constructor-arg>\n            <bean factory-bean=\"propertiesResolver\" factory-method=\"buildResolvedProperties\"\/>\n        <\/constructor-arg>\n    <\/bean>\n\n    <bean id=\"propertiesResolver\" class=\"org.greencheek.utils.environment.propertyplaceholder.resolver.builder.CompositeResolvedPropertiesBuilder\">\n        <constructor-arg>\n            <bean class=\"org.greencheek.utils.environment.propertyplaceholder.resolver.value.VariablePlaceholderValueResolver\">\n                <constructor-arg value=\"false\"\/> <!-- do not resolve env vars -->\n                <constructor-arg value=\"false\"\/> <!-- do not resolve system properties -->\n            <\/bean>\n        <\/constructor-arg>\n        <property name=\"locationForLoadingConfigurationProperties\" value=\"classpath:\/\"\/>\n        <property name=\"locationForLoadingOperationalOverrides\" value=\"classpath:\/opsoverrides\"\/>\n        <property name=\"relativeLocationOfFilesOverridingDefaultProperties\" value=\"environments\"\/>\n    <\/bean>\n\nUsing in Spring\nPrior to PropertySource introduction in Spring 3 and the associate @Profile(value=\"DEV\"), and autowired\norg.springframework.core.env.Environment.  The way to define a PropertyPlaceholderConfigurer was as follows:\n    <bean class=\"org.springframework.beans.factory.config.PropertyPlaceholderConfigurer\">\n        <property name=\"properties\">\n            <bean factory-bean=\"propertiesResolver\" factory-method=\"buildResolvedProperties\"\/>\n        <\/property>\n    <\/bean>\n\n    <bean id=\"propertiesResolver\" class=\"org.greencheek.utils.environment.propertyplaceholder.resolver.builder.CompositeResolvedPropertiesBuilder\">\n        <constructor-arg>\n            <bean class=\"org.greencheek.utils.environment.propertyplaceholder.resolver.value.VariablePlaceholderValueResolver\">\n                <constructor-arg value=\"false\"\/> <!-- resolve env vars -->\n                <constructor-arg value=\"false\"\/> <!-- resolve system properties -->\n            <\/bean>\n        <\/constructor-arg>\n        <property name=\"locationForLoadingConfigurationProperties\" value=\"classpath:\/\"\/>\n        <property name=\"locationForLoadingOperationalOverrides\" value=\"classpath:\/opsoverrides\"\/>\n        <property name=\"relativeLocationOfFilesOverridingDefaultProperties\" value=\"environments\"\/>\n    <\/bean>\nThis allowed you to register a Property Placeholder that you resolve ${} properties within the application contexts,\nand @Value annotations:\n    @Value(\"${message}\")\n\tprivate String message;\nWith the introduction of Spring 3.1.1, there has been a move to the use of PropertySource implementations and the\nuse of the autowired Environment in order to obtain properties:\n    @Autowired\n\tprivate Environment env;\n\n    @RequestMapping(value=\"\/headers\/{noofheaders}\",method=RequestMethod.GET)\n    public String returnHeaders(final @PathVariable(\"noofheaders\") int noheaders,\n    \t\t\t\t\t\t    Model model,HttpServletRequest request)\n    {\n        String s = env.getProperty(\"message\");\n    }\nThe PropertiesMerger works within this environment, and properties can be made available through the Environment\nobject via the use of a custom ApplicationContextInitializer\nthat is then set on either the DispatcherServlet or the ContextLoaderListener\n\nDispatcherServlet:\n\n    <servlet>\n\t\t<servlet-name>servlet<\/servlet-name>\n\t\t<servlet-class>org.springframework.web.servlet.DispatcherServlet<\/servlet-class>\n\t\t<load-on-startup>1<\/load-on-startup>\n\t\t<init-param>\n\t\t\t<param-name>contextInitializerClasses<\/param-name>\n        \t<param-value>org.greencheek.playground.web.spring.PropertiesMergerApplicationContextInitializer<\/param-value>\n        <\/init-param>\n\t<\/servlet>\n\nContextLoaderListener:\n\n    <context-param>\n        <param-name>contextInitializerClasses<\/param-name>\n        <param-value>org.greencheek.playground.web.spring.PropertiesMergerApplicationContextInitializer<\/param-value>\n    <\/context-param>\n\n    <listener>\n    \t<listener-class>org.springframework.web.context.ContextLoaderListener<\/listener-class>\n\t<\/listener>\nYou would then make a PropertySource that is instance (PropertiesPropertySource)[http:\/\/static.springsource.org\/spring\/docs\/3.1.x\/javadoc-api\/org\/springframework\/core\/env\/PropertiesPropertySource.html]\npopulated from the properties obtain from either the merger or the resolver:\n  public class PropertiesMergerApplicationContextInitializer\n         implements ApplicationContextInitializer<ConfigurableApplicationContext>  {\n\n\t private static final Properties environmentalProperties;\n\t static {\n        PropertiesMerger merger = new EnvironmentSpecificPropertiesMergerBuilder().build();\n        environmentalProperties = merger.getMergedProperties();\n        \/\/ Or have the following for the resolved ${} properties:\n        \/\/ environmentalProperties = new EnvironmentSpecificPropertiesResolverBuilder().buildProperties(merger);\n\n\t }\n\n\t public void initialize(ConfigurableApplicationContext applicationContext) {\n\t\t initialise(applicationContext);\n\t }\n\n\t public static void initialise(ConfigurableApplicationContext applicationContext) {\n\t     \/\/ Add the merged properties to the applicationContext environment\n\t     \/\/ So that the properties are available in the @Autowired Environment object\n\t\t applicationContext.getEnvironment()\n\t\t .getPropertySources()\n\t\t .addFirst(new PropertiesPropertySource(\"p\",environmentalProperties));\n\t }\n  }\nPlease be aware the above DOES NOT register a PropertySourcesPlaceholderConfigurer as a BeanFactory Post Processor\nso the properties will not be made available to @Value annotations, unless you register a PropertySourcesPlaceholderConfigurer\nyourself:\n    <bean class=\"org.springframework.context.support.PropertySourcesPlaceholderConfigurer\">\n           <property name=\"properties\">\n           \t\t<bean factory-bean=\"propertiesResolver\" factory-method=\"buildResolvedProperties\"\/>\n           <\/property>\n    <\/bean>\n\n    <bean id=\"propertiesResolver\" class=\"org.greencheek.utils.environment.propertyplaceholder.resolver.builder.CompositeResolvedPropertiesBuilder\">\n            <constructor-arg>\n                <bean class=\"org.greencheek.utils.environment.propertyplaceholder.resolver.value.VariablePlaceholderValueResolver\">\n                    <constructor-arg value=\"false\"\/> <!-- resolve env vars -->\n                    <constructor-arg value=\"false\"\/> <!-- resolve system properties -->\n                <\/bean>\n            <\/constructor-arg>\n            <property name=\"locationForLoadingConfigurationProperties\" value=\"classpath:\/\"\/>\n            <property name=\"locationForLoadingOperationalOverrides\" value=\"classpath:\/opsoverrides\"\/>\n            <property name=\"relativeLocationOfFilesOverridingDefaultProperties\" value=\"environments\"\/>\n    <\/bean>\nYou could also declare java based @Configuration, and create the PropertySourcesPlaceholderConfigurer as an @Bean.\nIf the PropertySourcesPlaceholderConfigurer is only used for resolving properties for the Web Application Components,\nyou could add @Configuration to the PropertiesMergerApplicationContextInitializer above, for example (a PropertySourcesPlaceholderConfigurer\nhas to be registered in each separate context, i.e. the configurer isn't inherited by the WebApplicationContext from the root ApplicationContext\nlike that of other beans, it only affects the context in which it is registered):\n    import java.util.Properties;\n\n    import org.greencheek.utils.environment.propertyplaceholder.builder.EnvironmentSpecificPropertiesMergerBuilder;\n    import org.greencheek.utils.environment.propertyplaceholder.builder.EnvironmentSpecificPropertiesResolverBuilder;\n    import org.greencheek.utils.environment.propertyplaceholder.merger.PropertiesMerger;\n    import org.springframework.context.ApplicationContextInitializer;\n    import org.springframework.context.ConfigurableApplicationContext;\n    import org.springframework.context.annotation.Bean;\n    import org.springframework.context.annotation.Configuration;\n    import org.springframework.context.support.PropertySourcesPlaceholderConfigurer;\n    import org.springframework.core.env.MutablePropertySources;\n    import org.springframework.core.env.PropertiesPropertySource;\n\n    @Configuration\n    public class AppConfig implements\n    \t\tApplicationContextInitializer<ConfigurableApplicationContext> {\n\n    \tprivate static final Properties environmentalProperties;\n    \tstatic {\n    \t\tPropertiesMerger merger = new EnvironmentSpecificPropertiesMergerBuilder().build();\n    \t\tenvironmentalProperties = new EnvironmentSpecificPropertiesResolverBuilder().buildProperties(merger);\n    \t}\n\n    \tpublic void initialize(ConfigurableApplicationContext applicationContext) {\n    \t\tinitialise(applicationContext);\n    \t}\n\n    \tpublic static void initialise(ConfigurableApplicationContext applicationContext) {\n    \t\tapplicationContext\n    \t\t\t\t.getEnvironment()\n    \t\t\t\t.getPropertySources()\n    \t\t\t\t.addFirst(new PropertiesPropertySource(\"p\",environmentalProperties));\n    \t}\n\n    \t@Bean\n    \tpublic static PropertySourcesPlaceholderConfigurer propertySourcesPlaceholderConfigurer() {\n    \t\tPropertySourcesPlaceholderConfigurer config = new PropertySourcesPlaceholderConfigurer();\n\n    \t\tMutablePropertySources sources = new MutablePropertySources();\n    \t\tsources.addFirst(new PropertiesPropertySource(\"p\",environmentalProperties));\n\n    \t\tconfig.setPropertySources(sources);\n\n    \t\treturn config;\n    \t}\n\n    }\n","235":"OpenStudioProjects_Polimi_EETBS\nThis repository includes the files and presentations of group projects on simulation of Commercial Buildings with OpenStudio (EnergyPlus) in the context of Energy and environmental Technologies for Building Systems (Politecnico di Milano)\nIn order to insert the personal and contact information of members of your group (regular projects), you should fill in the following form:\nRegular Project Group Information Form\nIf instead you would like to ask for a bonus project, you should fill in the following form:\nBonus Project Group Information Form\nImportant note: Only one of the members of the group should fill in the form and should insert the personal and contact information of all members.\n","236":"environmental_factors\ndevelopment of environmental factors at 4 and 6 digit postcode level of the Netherlands. All these factors are developed in line with our research plan, and will be linked to travel behavior variables. It should be mentioned that the environmental factors of pc6 level are calculated given three different buffer sizes (300 meters, 600 meters, 1000 meters and 2000 meters). If you use any of our codes or data for your research, plase cite the following paper:\nXipei Ren, Zhiyong Wang, Carolin Nast, Dick Ettema, and Aarnout Brombacher. 2019. Integrating Industrial Design and Geoscience: a Survey on Data-Driven Research to Promote Public Health and Vitality. In 9th International Digital Public Health Conference (2019) (DPH\u2019 19), November 20\u201323, 2019, Marseille, France. ACM, New York, NY, USA, 5 pages. https:\/\/doi.org\/10.1145\/3357729.3357747\nNumber of crossings (representing street connectivity)\nThe number of crossings witihin the buffers (300, 600, and 1000) around each pc6 centroid. \ncrossing_1: cul-de-sac \ncrossing_3: 3-way crossings \ncrossing_4plus: >=4-way crossings \nNumber of ddresses (representing degree of urbanization)\nThe number of addresses witihin the buffers (300, 600, and 1000) around each pc6 centroid.\nIt is indicated by the attribute addr_num in the datasets.\nStreet density (from OpenStreetMap)\nIt is indicated by the attribute street_density in the datasets. \nFor pc4, its value is the total length of all walking streets divided by the area of pc4. \nFor pc6, its value is the total length of all walking streets divided by the buffer area around the pc6 centroid.\n\nResidential building density (from OpenStreetMap)\nIt is indicated by the attribute res_bldg_density in the datasets.\nFor pc4, its value is the total area of all residential buildings divided by the area of pc4. \nFor pc6, its value is the total length of all residential buildings divided by the buffer area around the pc6 centroid.\nair pollution indicators (from European Environment Agency https:\/\/www.eea.europa.eu\/)\nTotally 4 air pollution indicators are generated: NO2 (1000m x 1000m), PM25 (1000m x 1000m), PM10 (1000m x 1000m), NOx (2000m x 2000m), which are indicated by the attributes no2_avg, pm25_avg,pm10_avg,nox_avg, respectively. \nFor pc4 and each type of air pollution, their values are the average values of all cells in each pc4. \nFor pc6 and each type of air pollution, their values are the average values of all cells in the buffer around pc6 centroid.\n\nnoise pollution\nThe noise pollution data is provided by RIVM (Rijksinstituut voor Volksgezondheid en Milieu), and can be downloaded as GIS file from https:\/\/www.atlasnatuurlijkkapitaal.nl\/kaarten. Some description of the noise data can be found below.\n\n1 = zeer goed \t\tLden<=45 dB \n2 = goed \t\t\t45<Lden<=50 dB \n3 = redelijk \t\t50<Lden<=55 dB \n4 = matig \t\t\t55<Lden<=60 dB \n5 = slecht \t\t\t60<Lden<=65 dB \n6,7,8 = zeer slecht \t\tLden>65 dB \nDe geluidklassen hebben betrekking op de cumulatieve geluidbelasting in Lden (jaar) als veroorzaakt door\n\nrijkswegen (2016)\ngemeentelijke en provinciale wegen (2011)\nrailverkeer (2016)\nluchtvaart (2011)\nindustrie (kentalraming)\nwindturbines (2015)\n\nFor pc4, indicator for noise level 1 is represented by the attribute dn_1, which is the ratio of the area of noise level 1 in the pc4 area. The same for other noise levels 2, 3, 4, 5, 6.\nFor pc6, indicator for noise level 1 is represented by dn_1, which is the ratio of the area of noise level 1 in the buffer area of the pc6 centroid. The same for other noise levels 2, 3, 4, 5, 6.\nLanduse mix entropy (derived from Bestand Bodemgebruik)\nIt is represented by the attribute landuse_idx. \nFor pc4, it is calcuated based on the following three land use classification:\n\nGroup 1, residential, 20\nGroup 2, recreational 40, 41, 42, 43, 44, 50, 51, 60, 61, 62, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83\nGroup 3, other: 10, 11, 12, 21, 22, 23, 24, 30, 31, 32, 33, 34, 35\n\nFor pc6, it is calcuated based on the following five land use classification:\n\nGroup 1, residential, 20\nGroup 2, recreational 40, 41, 42, 43, 44, 50, 51, 60, 61, 62, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83\nGroup 3, other: 10, 11, 12, 22, 23, 30, 31, 32, 33, 34, 35\nGroup 4, commercial, 21\nGroup 5, industrial, 24\n\n\n\nNDVI (Normalized Difference Vegetation Index)\nThe details of ndvi can be found via the following link:\nhttps:\/\/gisgeography.com\/ndvi-normalized-difference-vegetation-index\/. \nFor pc4, their values are the average values of all cells of in each pc4. \nFor pc6, their values are the average values of all cells in the buffer around pc6 centroid.\nNote that negative values are excluded from the calculation.\n\n","237":"EnvironmentalDataAnalytics\nCourse repository from July 2016 held at NCAR Mesa Lab, Boulder, CO\nThis workshop series  ( starting in 2014) is designed to help prepare the next generation of researchers and practitioners to work within, and contribute to, the data-rich era. Each workshop will bring together graduate students and senior scientists in environmental statistics and related fields to explore contemporary topics in applied environmental data modeling.\nAcross scientific fields, researchers face challenges coupling data with imperfect models to better understand variability in their system of interest. Inference garnered through these analyses support decisions with important economic, ecological, and social implications. Increasingly, the bottleneck for researchers is not access to data; rather, it is the need to identify and apply appropriate statistical methods using efficient software.\n#Workshop program and objectives\nThe workshop will consist of hands-on computing and modeling tutorials, presentations from graduate student participants, and invited talks from early career and established leaders in environmental data modeling. Tutorials and invited talks will address useful ideas and tools directly applicable to student participants' current and future research.\n#Workshop participants will:\nDevelop new modeling and computing skills through hands-on analyses and lectures led by quantitative scientists\nShare research findings and explore open questions within and at the interface of environmental, ecological, climatic, and statistical sciences\nLearn about the National Center for Atmospheric Research (NCAR) and National Ecological Observatory Network (NEON) data resources that can facilitate scientific discovery\nWorkshop participants will also have ample time to enjoy the mountains and downtown Boulder.\n#Workshop tutorials:\n\n\nClimate data analytics, Doug Nychka, Institute for Mathematics Applied to Geosciences, NCAR\n\n\nIntroduction to Bayesian statistics and modeling for environmental and ecological data,  Alix Gitelman, Department of Statistics, Oregon State University\n\n\nHierarchical models for spatio-temporal data analysis, Andrew Finley, Department of Forestry, Michigan State University\n\n\nNIMBLE: R software for Bayesian modeling* , Chris Paciorek, Department of Statistics, University of California - Berkeley.\n\n\n","238":"Python4ScientificComputing_Fundamentals\nThis repository includes the guidelines and the exercise files of the first part of my lectures on python for scientific programming which is dedicated to a general introduction to Python  programming language.  These lectures are a part of the \"Energy and Environmental Technologies for Building Systems\"  course offered for M.Sc in Energy Eng. at Politecnico di Milano.\n","239":"changebrackets\nThis is a public repo for our project that uses\nangle brackets to monitor environmental change,\nincluding the scripts we use harvest image metadata, display a slideshow on a\nweb page, download images, and compile movies. We've also included our sign\ndesigns.\nSCRIPTS\nThese are a couple Ruby scripts we use to help automate the process of getting\ninformation about tag usage and making timelapse movies from the images. You\ndon't need to know Ruby to use them, but you should be comfortable with\nrunning scripts from the command line. These instructions presume you're\nrunnign some flavor of *nix, but all the underlying libraries are available\nfor Windows so these scripts should work there too.\nREQUIREMENTS\n\nRuby\nRubygems\nBundler\nTimeLapser (this is an OpenCV-based C++ binary for aligning images, see the repo for installation instructions)\nImageMagick\n\nINSTALL\ngit clone https:\/\/github.com\/nerdsfornature\/changebrackets.git\ncd changebrackets\nbundle\nfireslurp.rb\nThis Ruby script harvests image metadata from social media photos using your\ntags and stores them in local CSV files or a Google Spreadsheet. Run\nruby fireslurp.rb --help to see all the options, but basic usage looks like this:\n# Save info about Instagram photos for two tags in a local CSV file\nbundle exec ruby fireslurp.rb --instagram-key=xxx morganfire01 morganfire02\n\n# Save info about Twitter photos for two tags to a Google Spreadsheet\nbundle exec ruby fireslurp.rb \\\n  --twitter-key=xxx \\\n  --twitter-secret=yyy \\\n  --google-application-credentials=\/path\/to\/your\/key.json \\\n  --google-spreadsheet-id=1234abcd \\\n  morganfire01 morganfire02\n\n# Save info about photos for two tags using config from a YAML file\nbundle exec ruby fireslurp.rb -c fireslurp.yaml morganfire01 morganfire02\nThe last option using a config file is probably the easiest way to go.\nfireslurp.yaml provides an example for the config file. The Google\nSpreadsheet ID is just the unique part of your Google Spreadsheet URL, so if\nthe URL when you're editing it looks like\nhttps:\/\/docs.google.com\/spreadsheets\/d\/1HF1fEF4j69Ny6ng9TZYNLYnnRb4J6mPCqmckyOrsomI\/edit,\nthen the ID is 1HF1fEF4j69Ny6ng9TZYNLYnnRb4J6mPCqmckyOrsomI. Now here's the tricky part: in order to\nwrite to a Google Spreadsheet, you'll need to do these annoying things:\n\nSet up a project in the Google Developer Console and create a Service Account. Painful (but functional) instructions at https:\/\/developers.google.com\/identity\/protocols\/OAuth2ServiceAccount. You don't need to delegate domain-wide authority, but you do need to hold on to that JSON key file you generate as a part of creating the service account\nIn the Google Developer Console, enable the Drive API.\nShare your spreadsheet with the service account's email address and grant it editing permissions.\nSpecify the path to that JSON key file you downloaded as an ENV variable named GOOGLE_APPLICATION_CREDENTIALS, in your configureation YAML, or using --google-application-credentials\n\nNote that this script only retrieves info about recent photos, so it should\nbe run at least daily, more often if your tags get a lot of use.\nWe recommend cron or\nlaunchd.\nmoviemaker.rb\nDownloads the image files referenced in a Google Spreadsheet made by\nfireslurp.rb, aligns them using\nTimeLapser, and stitches them into an\nanimated GIF using ImageMagick. This is really just a little bit of logic on\ntop of some basic shell commands, which should be pretty obvious in the\nscript. Note that you can force it to download the files to a particular\nfolder using the -f flag, and skip the relatively slow processes of\ndownloading and alignment.\n# Basic usage\nbundle exec ruby moviemaker.rb -c fireslurp.yaml morganfire01\n\n# Download all the image files to a folder named myfolder\nbundle exec ruby moviemaker.rb -c fireslurp.yaml -f myfolder morganfire01\n\n# Skip download, just do the alignment based on files in myfolder, and make the movie\nbundle exec ruby moviemaker.rb -c fireslurp.yaml -f myfolder --skip-download morganfire01\nCHANGEOMATIC\nThis is a little jQuery-based tool that sort of does what fireslurp does in\nthe browser by pulling in photo data and creating a slideshow. It will only\nretrieve photos from Flickr and Instagram due to the\nlimitations of Twitter's API\nin a strictly client-side context like this.\nUsing Google Spreadsheet\nIt can also read data from a Google Spreadsheet made by fireslurp, which is\none way of getting around the Twitter thing, though doing so requires that you\npublish your Google Spreadsheet.\nYour spreadsheet must meet the following requirements:\n\nIf there's more than one sheet, the one containing the photo data must be named Data\nIt must have columns just like those made by fireslurp.rb, which means it has the following columns as the first row, in this order:\nprovider\ntag\ndatetime\nusername\nusable_tag\nimage_url\nurl\nimage_url_s\nimage_url_m\nlicense\ntitle\n\nREQUIREMENTS\n\njQuery\ncycle2\ncycle2.center\njQuery-dateFormat\ntabletop\n\nUSAGE\nSee changeomatic.example.html\n","240":"Environmental Sciences Computational Bootcamp\nSeptember 3\u20136, 2019\n9:00 - 11:30 am\nSearle 240A\nSchedule:\n\n\nDay 1. Linux & the bash shell\n\n\nDay 2. Overview of the RCC cluster (midway) and high-performance computing\n\n\nDay 3. Parallel computing (multiprocessing in Python)\n\n\nDay 4. Version control (Git)\n\n\nDay 1: Linux & the bash shell (2.5 hours)\n\nConnecting to Midway2\nCommand line interface\nManipulating files and navigating thhe file system\nShell scripting (Loops, logicals, etc.)\n\nDay 2 Overview of the RCC cluster and high-performance computing (2.5 hours)\n\n\nBasics of high-performance computing.\n\n\nUsing Slurm.\n\n\nDay 3: Parallel computing -- multiprocessing in python (2.5 hours)\n\nOverview of parallelization\nUsing multiprocessing module in python\n\nDay 4: Code repository (2+ hours)\n\n\nBasic concepts.\n\n\nCreating a Git repository, and committing the code.\n\n\nSharing and collaborating on the code using Git.\n\n\n","241":"Environmental extractors\nThis repository contains extractors that process data originating from:\n\nGMP 343 CO2 sensor\nThies Clima environmental sensors\nMaricopa lightning\/irrigation\/weather data\n\nEnvironmental Logger JSON 2 NetCDF extractor\nThis extractor processes environmental logger stream data .JSON files into a netCDF\nInput\n\nEvaluation is triggered whenever a file is added to a dataset\nChecks whether the file is an _environmentlogger.json file\n\nOutput\n\nThe dataset containing the .JSON file will get a corresponding .nc netCDF file\n\nUAMAC\/UIUC Energy Farm DAT parser extractors\nThis extractor extracts metadata from meteorological DAT files into netCDF, as well as creating entries in the Clowder Geostreams database.\nInput\n\nEvaluation is triggered whenever 24 .dat files are added to a dataset\n\nOutput\n\nnetCDF metadata is generated and added to dataset\ndatapoints for each record in the DAT files are added to geostream\n\n","242":"SnowFort: An open source wireless sensor network for infrastructure and environmental monitoring\nTutorial\nPlease see the website tutorial\nWiKi Page:\n\nHow to compile the code? Page\nHow to use Raspberry Pi as the base station? Page\n\nBug Reporting\n\nFor reporting bugs please use the snowfort\/issues page.\nFor generic questions or to share your experience using SnowFort please use the SnowFort User Group\n\nLicense\nLicensed under an Apache-2 license.\n","243":"DinoSwarms\nA simulated dinosaur habitat consisting of dinosaur behavior models and dynamic environmental processes.\n","244":"hydroJSON\nSynopsis\nA JSON based standard for interchanging hydro, meteorological and environmental data. The main goal of this standard is to have a common way of interchanging  and using HydroMet data via web services. Given the ease with importing JSON formatted objects programmatically, this standard has use cases in modeling as well.\nExamples\nRetrieve 7 days of flow from a dam\n\/getjson?query=[\"dwr flow\"]&backward=7d\nFormat time to be seconds past the epoch for use in client side plotting\n\/getjson?query=[\"dwr flow\"]&backward=7d&time_format=%s\nList all available timeseries names for a given site:\n\/getjson?tscatalog=[\"GCL\"]\nAll available sites\/Stations with metadata:\n\/getjson?catalog=[]\nMotivation\nthe purpose of hydroJSON is to standardize the interchange of timeseries data and metadata in a more modern, browser\/mobile friendly format.\nInstallation\nAPI Reference\nTimeseries Query\n{\n  \"timeseries\" : [[\"tsid1\",\"units1\",\"interval1\"], [\"tsid2\",\"units2\",\"interval2\"], [\"tsid3\",\"units3\",\"interval3\"]],\n  \"startdt\":\"ISO-8601\",\n  \"enddt\":\"ISO-8601\",\n  \"forward\":\"ISO-8601\", \/\/referenced from startdt, or datetime.now() if nothing specified\n  \"back\": \"ISO-8601\", \/\/referenced from enddt, or datetime.now() if nothing specified\n  \"query\" : {\"Stations\":[\"BON\",\"12340000\",\"BIGI\"], \"Parameters\":[\"Flow\",\"03065\",\"QD\"]}\n}\n\ngetjson?timeseries=[[\"CHJ Q\",\"cfs\",\"Daily\"], [\"CHJ.Flow.Inst.1Day.0.CBT-REV\",\"kcfs\"], [\"12437990 00060\",\"cfs\"]]\n\nGeneral Abstract Query\nGeneral abstract queries allow the end user to provide keywords. The service will return hydroJSON timeseries objects with the data they want.\ngetjson?query=[\"CHJ Daily Avg Flow\"]\nCatalog Query\ngetjson?catalog=[\"CHJ Daily Avg Flow\"]\nMost Recent Value Query\ngetjson?mostrecent=[[\"12437990\",  \"cfs\"]]\n\nDatabase Structure\nSiteCatalog\n\n\n\nName\nType\nDescription\n\n\n\n\nsiteid\nstring\nidentifier for the site example: LakeMead\n\n\ndescription\nstring\ndescription for this site location\n\n\nstate\nstring\nstate code i.e. ID = Idaho\n\n\nlatitude\nstring\nlatitude of site\n\n\nlongitude\nstring\nlongitude of site\n\n\nelevation\nstring\nelevation of the site (in units of vertical datum description)\n\n\ntimezone\nstring\nfull name example: US\/Pacific\n\n\ninstall\nstring\ndate site was installed\n\n\nhorizontal_datum\nstring\ndatum description for lat\/long. Example: (WGS84)\n\n\nvertical_datum\nstring\ndescription of vertical datum for the site. example(NGVD29)\n\n\nvertical\nfloat\naccuracy accuracy of elevation\n\n\nelevation_method\nstring\nmethod used to determine elevation\n\n\ntz_offset\nstring\noptional hours -08:00\n\n\nactive_flag\nstring\nsite is currently being used T\/F default T if blank\n\n\nresponsibility\nstring\nmaintenance responsibility\n\n\nagency_region\nstring\ngrouping by organization regions\n\n\ntype\nstring\nEX: agrimet, stream, reservoir, weather, canal, diversion, snotel\n\n\n\nSeriesCatalog\n\n\n\nName\nType\nDescription\n\n\n\n\nid\ninteger\nPrimary key\n\n\nparentid\ninteger\nSiteDataTypeID of containing folder\n\n\nisfolder\ninteger\nWhen true this row represents a folder not a series\n\n\nsortorder\ninteger\nSort order within a folder for user interface\n\n\niconname\nstring\nUse to render an icon based on the source of data\n\n\nname\nstring\nDisplay Name and name for equations referencing this Series\/row\n\n\nsiteid\nstring\nReference to site\/location information\n\n\nunits\nstring\nUnits of measurement such as: feet,cfs, or acre-feet\n\n\ntimeinterval\nstring\nOne of : (Instant, Daily, Monthly)\n\n\nparameter\nstring\nDescription for data such as: daily average flow\n\n\ntablename\nstring\nUnique database table name for this Series\/row\n\n\nprovider\nstring\nName of a class derived from Reclamation.TimeSeries.Series (or Series)\n\n\nconnectionstring\nstring\nProvider specific connection information such as a path to an excel file, sheet name, or specific parameter code\n\n\nexpression\nstring\nEquation expression for computed series\n\n\nnotes\nstring\nUser notes\n\n\nenabled\ninteger\nUsed to active or deactive calculations and presentation of data\n\n\n\nTableName\nRefers to the TableName column in SeriesCatalog\n\n\n\nName\nType\n\n\n\n\ndatetime\ndatetime\n\n\nvalue\nfloat\n\n\nflag\nstring\n\n\n\nDatabase Description\n--\nTests\nTBD\nContributors\n\nGunnar Leffler\nKarl Tarbet\nArt Armour\nMike Stanfill\nMike Nielson\nJeremy Kellett\nDave Coyle\n\n","245":"Eternity\nHackrpi environmental track iOS app.\nPitch: iOS app that empowers users to be aware of resource consumption.\nBuilt With: Swift, Xcode, Figma, Google Cloud Firebase, IBM Watson Assistant, Twilio\nVideo Walkthrough\nYoutube link\nStand-Ups \/ Milestones\n\n (UX) Wireframes\n (Team) Sprints and scrum tickets.\n (UI) Instagram-Style view-controllers with respective branches\n (ML) Recognize grecery items.\n (Backend) Real-time upload and download images (GCP)\n (AI) Weekly awareness reminder (Twilio and Heroku)\n (AI) Bot for speech-to-navigation for easier accessibility (Watson)\n\nRoadblocks Overcame\n\nMerge conflicts with differnt pod folders in different branches (SOLVED!!!).\nIntegrating AutoML feature in a dynammic scroll view.\nUsing GPX to test custom locations worldwide.\n\nUseful Links\n\ngit ignore + storyboard merge conflict resolves\nOur Team Slack\npod merge conflict\nApple ML Kit\nTripadvisor API (u \/ p \/ api code in email)\n\nTeam\n\nGit Master\/Project Manager: Yasin Ehsan, Queens College\nFull-Stack: Helal Chowdhury, NYU\nFront-End\/ML: Kevin Chen, NYU\nFront-End: Francis Sy, Queens College (First time working with iOS!)\n\n","246":"For just plaintext you'll want the following in your environmnet, and to block comment out the options involving SSL\nexport HUBOT_MQTT_URL='mqtts:\/\/test.mosquitto.org'\nexport HUBOT_MQTT_PORT='1883'\n\nFor TLS against the mqtt server:\n# export HUBOT_MQTT_HOST='test.mosquitto.org'\n# export HUBOT_MQTT_URL='mqtt:\/\/test.mosquitto.org'\n# export HUBOT_MQTT_PORT='8883'\n# export HUBOT_MQTT_CA_CERT='\/etc\/ssl\/certs\/mosquitto.org.crt'\n\nFor a custom mosquitto server with client cert authentication you'll want (and obviously change them to your mqtt server)\nexport HUBOT_MQTT_HOST='mqtt.hq.thebikeshed.io'\nexport HUBOT_MQTT_URL='mqtts:\/\/mqtt.hq.thebikeshed.io'\nexport HUBOT_MQTT_PORT='8883'\nexport HUBOT_MQTT_CA_CERT='\/etc\/ssl\/certs\/ca.crt'\nexport HUBOT_MQTT_CLIENT_KEY='\/etc\/ssl\/private\/localhost.ckey'\nexport HUBOT_MQTT_CLIENT_CERT='\/etc\/ssl\/certs\/localhost.crt'\n\n","247":"\nRoads & Roadless Areas in B.C.\nThis repository contains R code that summarizes the length of roads and amount of roadless area in B.C. It supports the 'Roads & Roadless Areas' indicator published on Environmental Reporting BC.\nData\nThis analysis uses the British Columbia Digital Road Atlas available from the B.C. Data Catalogue and distributed under the Access Only - B.C. Crown Copyright licence. The Digital Road Atlas is the best available single source of road data for the Province of B.C. Metadata details for the Digital Road Atlas (DRA) are available in PDF format from the B.C. Data Catalogue.\nThe analyses exclude some surface and road types in the Digital Road Atlas. Boat (B), overgrown (O) & decomissioned (D) roads are excluded from TRANSPORT_LINE_SURFACE_CODE and ferry routes (F, FP, FR, RWA), non-motorized trails (T, TD), road proposed (RP), and road pedestrian mall (RPM) are excluded from TRANSPORT_LINE_TYPE_CODE.\nThe road length analysis sources the Digital Road Atlas from the B.C. Data Catalogue. The roadless area analysis is based on rasterized input data, generated with R code that is also available in GitHub.\nUsage\nRoad Length Analysis\nOne script is required for the road length and road length by road type analysis:\n\nroad_summary.R\n\nRoadless Area Analysis\nThere are four core scripts that are required for the roadless area analysis, they need to be run in order:\n\n01_load.R\n02_clean.R\n03_analysis.R\n04_output.R\n\nMost packages used in the analysis can be installed from CRAN using install.packages(), but you will need to install envreportutils and patchwork using devtools:\ninstall.packages(\"devtools\") # if you don't already have it installed\n\nlibrary(devtools)\ninstall_github(\"bcgov\/envreportutils\")\ninstall_github(\"thomasp85\/patchwork\")\nGetting Help or Reporting an Issue\nTo report bugs\/issues\/feature requests, please file an issue.\nHow to Contribute\nIf you would like to contribute, please see our CONTRIBUTING guidelines.\nPlease note that this project is released with a Contributor Code of Conduct.\nBy participating in this project you agree to abide by its terms.\nLicence\nCopyright 2017 Province of British Columbia\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nThis repository is maintained by Environmental Reporting BC. Click here for a complete list of our repositories on GitHub.\n","248":"\nRoads & Roadless Areas in B.C.\nThis repository contains R code that summarizes the length of roads and amount of roadless area in B.C. It supports the 'Roads & Roadless Areas' indicator published on Environmental Reporting BC.\nData\nThis analysis uses the British Columbia Digital Road Atlas available from the B.C. Data Catalogue and distributed under the Access Only - B.C. Crown Copyright licence. The Digital Road Atlas is the best available single source of road data for the Province of B.C. Metadata details for the Digital Road Atlas (DRA) are available in PDF format from the B.C. Data Catalogue.\nThe analyses exclude some surface and road types in the Digital Road Atlas. Boat (B), overgrown (O) & decomissioned (D) roads are excluded from TRANSPORT_LINE_SURFACE_CODE and ferry routes (F, FP, FR, RWA), non-motorized trails (T, TD), road proposed (RP), and road pedestrian mall (RPM) are excluded from TRANSPORT_LINE_TYPE_CODE.\nThe road length analysis sources the Digital Road Atlas from the B.C. Data Catalogue. The roadless area analysis is based on rasterized input data, generated with R code that is also available in GitHub.\nUsage\nRoad Length Analysis\nOne script is required for the road length and road length by road type analysis:\n\nroad_summary.R\n\nRoadless Area Analysis\nThere are four core scripts that are required for the roadless area analysis, they need to be run in order:\n\n01_load.R\n02_clean.R\n03_analysis.R\n04_output.R\n\nMost packages used in the analysis can be installed from CRAN using install.packages(), but you will need to install envreportutils and patchwork using devtools:\ninstall.packages(\"devtools\") # if you don't already have it installed\n\nlibrary(devtools)\ninstall_github(\"bcgov\/envreportutils\")\ninstall_github(\"thomasp85\/patchwork\")\nGetting Help or Reporting an Issue\nTo report bugs\/issues\/feature requests, please file an issue.\nHow to Contribute\nIf you would like to contribute, please see our CONTRIBUTING guidelines.\nPlease note that this project is released with a Contributor Code of Conduct.\nBy participating in this project you agree to abide by its terms.\nLicence\nCopyright 2017 Province of British Columbia\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nThis repository is maintained by Environmental Reporting BC. Click here for a complete list of our repositories on GitHub.\n","249":"react-webpack\nSimplified environmental build processes with react and webpack\nRequirements\nNode >= v4.0.0\nGetting Started\n\nnpm install required packages\nnpm start to start development\n\nDeployment\n\nnpm run build\n\n","250":"DBSCAN\nClustering of sequences from environmental samples. Early C++ implementation. A more recent Python effort is now ongoing (see the MetaDBSCAN repository).\n","251":"THE\neInk mini MQTT Information Display for Time, Headlines and Environmental Data\nFiles to setup an run an eink MQTT Information Display\nSee https:\/\/www.connected-environments.org\/making\/the\/\nFiles are divided into two parts:\nScripts to process data and send to MQTT via cron:\ntimetomqtt.py - gets the time, converts it to words and publishes to the mqtt topic\nrsstomqtt.py - fetches an rss news feed, reads the latest headline and publishes to the mqtt topic\nclientrawmqttwd.py - fetches the feed from Weather Display and converts the data into text to publish - if you have your own personal weather station\nor\ndarkskytomqtt.py - fetches the weather from Dark Sky, converts the wind bearing into text and publishes to your MQTT feed\nMain script to run the eink display and show mqtt feeds:\nVersion for the eink PHAT:\nthe_pi_phat.py\nVersion for the eink WHAT:\nthe_pi_what.py\nTo check - font download, background images\n","252":"TheBabblingBrook\nA talking flower. The beginning of a Environmental Jokes API.\nPYTHON Libraries\n\nrequests\nFlask\nPyMongo\nConfigParser\n\nAPIS\nThe Babbling Brook uses the following APIs:\n\nWunderground Weather API - http:\/\/www.wunderground.com\/weather\/api\/d\/docs\nTTS API - http:\/\/tts-api.com\/\n\nDatabase\n\nMongoDB - http:\/\/docs.mongodb.org\/manual\/installation\/\n\nSetup\n\nSet up cron job to run saveWeatherData.sh every 15 minutes (see HANDY_SNIPPETS for syntax)\n\n","253":"ARTEMIS\nAlmost Real-Time Environmental Monitoring & Information System\nGetting Started\nIf you've already got some environmental sensors, great! You're halfway there.\nCheck Supported Devices to see if your equipment is known to work.\nIf not, for most devices a plugin should not be difficult to write, see Plugin Development\nIf you are starting from scratch either buy some Supported Devices or take a look at Building Sensors.\nPrerequisites\n\nhttpd\nphp\npython 2.6+\npython-rrdtool\nrrdtool\nmoment.js 1.7.2+\npython-sqlalchemy\npython-argparse\n\nInstallation\n\nRun setup.sh to initialise config files and storage directories.\nEdit artemis.conf to your liking.\nRun .\/artemis_collect.py to initialise the data store.\nAdd at least one node using artemis_cli.py add_node.\nRun .\/artemis_collect.py to detect and collect data from probes.\nUpdate positions of probes using artemis_cli.py update_probe.\nIf necessary, modify artemis.cronand copy to \/etc\/cron.d\/.\n\nArchitecture\n{ sensors }->[ thread ]-.    [ crond ]\n{ sensors }->[ thread ]-|        :\n{ sensors }->[ thread ]-|->[ collector ]->\/ json \/->[ javascript ]->( display )\n{ sensors }->[ thread ]-|        |\n{ sensors }->[ thread ]-'  ( rrd files )\n\nSupported Devices\nThis is not an exhaustive list, but devices listed have at least been tested once.\nSome devices may be supported but not yet listed, check the git repository.\n\nManufacturerModelWorksProtocolModule\nSwiftTechCM-2\u2713XMLxml_env_swift\nSwiftTechCM-2\u2713SNMPsnmp_env_swift\nAPCAP7953\u2713SNMPsnmp_pdu_apc\nJacartaUnknown?SNMPsnmp_env_jacarta\n\nPlugin Development\nPlugins for different sensors are implemented as individual modules in plugins\/.\nEach module is expected to define a class of the same name that subclasses node from base.py and as such must define at least one method (fetch()).\nclass node(object):\n    def __init__(self, ip):\n        self.ip = ip\n    def fetch(self):\n        pass\nFor plugins implementing access to SNMP devices, base.py also provides the convenience function getMIB for fetching the contents of MIB trees by walking the tree from a defined point.\ngetMIB(ip, mib, community = \"public\")\nIn addition base.py provides the definitions for unit symbols and a lookup table for 1-Wire device families.\nUNIT_TEMPERATURE\nUNIT_CURRENT\nUNIT_AIRFLOW\nUNIT_HUMIDITY\n\nFAMILY_1WIRE[]\nAdditional unit definitions and 1-wire families should be added as needed.\nReference Platform\n1-Wire Sensors\nMaxim 1-Wire sensors are low-cost, readily available and accurate devices which can easily be interfaced to a computer with USB or other interfaces.\n\nDS1822\n\nTemperature\n\u00b12C\n9-12 bit\n\n\nDS18B20\n\nTemperature\n\u00b10.5C\n9-12 bit\n\n\nDS18S20\n\nTemperature\n\u00b10.5C\n9 bit\n\n\n\nBase Units\nThere is currently an ongoing project to develop a low-cost base unit around the Raspberry Pi which when completed will be our recommended base unit.\nFor the time being, other good options are low cost development boards and systems based around a VIA or Atom CPU, many of which are available for under \u00a3100.\nOr existing commercial units which cost in the region of \u00a3500.\n","254":"Environmental Council\nhttps:\/\/vinaymeldrum.github.io\/Environmental-Council\n","255":"\nR Tools for Synoptic Environmental Spatial Data\nTools for reading, plotting and manipulating spatial data used at the\nAustralian Antarctic Division (AAD).\nA common example is to read an environmental layer as a function of\ndate:\nlibrary(raadtools)\nice <- readice(c(\"2018-06-01\", \"2019-06-01\"))\nplot(ice)\n\nThe available data sources are accessed using read*() functions for\na wide variety of data\nsources.\nThere are data sets from oceanography, topography, meteorology,\naltimetry, sea ice, ocean colour, and many other data sources. These are\nmostly remote sensing but include re-analysis and model output products.\nThe package uses the R raster\npackage and always provides\ndata as a standard raster (RasterLayer, RasterBrick, or RasterStack).\nEach data set is invdividually handled by a function to ensure the\nspatial and temporal registration is correct.\nThe contents of the data library itself is listed in the technical\nconfiguration.\nIf you would like a collection added please make a request via a Github\nissue\nor contact one of the authors directly.\nUsing raadtools\nThere are two main ways to use it.\nThe typical use-cases for raadtools are\n\nread a time series gridded data set as a function of date,\noptionally with spatial subsetting\nmatch a data set of longitude, latitude, time to the corresponding\nvalue in a time series gridded data set\n\nExamples of these workflows are outlined in this rOpenSci blog\npost.\nAccess to raadtools\nThe repository of data used by raadtools is available via the Nectar\nresearch cloud or for local use\nwithin the AAD.\nThere are two main ways to access raadtools. (If neither of 1 or 2 work\nfor you you, see your local raadtools expert.)\n1. RStudio raadtools server\nIf you have access to a \u201craadtools-RStudio-server\u201d then you need only\nload the package to get started:\nlibrary(raadtools)\n2. Local computer, within the AAD network\nIf it\u2019s not installed, trying installing with\ndevtools::install_github(\"AustralianAntarcticDivision\/raadtools\")\nlibrary(raadtools)\nTypically you will be provided with access, and won\u2019t be aware of the\nunderlying details, but the repository of data used by raadtools is\navailable under RDSI\/PUBLIC\/raad and at the AAD in the scientific data\ncollection.\nAnyone with a Nectar account may\nrun this by creating a VM from our raadclient image. Search the public\nimages for raadclient (e.g. \u2019 raadclient06_20181016\u2019 but choose the\nlatest one) and ensure that the SSH and RStudio port (8787) is open. Use\nthe default rstudio\/rstudio account, or create your own.\nYou are welcome to make your own copies of data from the collection for\nyour own use, but please respect the citation and usage requests of the\ndata providers listed in the\nsummary.\n\nPlease note that the \u2018raadtools\u2019 project is released with a Contributor\nCode of Conduct. By contributing to this project,\nyou agree to abide by its terms.\n","256":"\nR Tools for Synoptic Environmental Spatial Data\nTools for reading, plotting and manipulating spatial data used at the\nAustralian Antarctic Division (AAD).\nA common example is to read an environmental layer as a function of\ndate:\nlibrary(raadtools)\nice <- readice(c(\"2018-06-01\", \"2019-06-01\"))\nplot(ice)\n\nThe available data sources are accessed using read*() functions for\na wide variety of data\nsources.\nThere are data sets from oceanography, topography, meteorology,\naltimetry, sea ice, ocean colour, and many other data sources. These are\nmostly remote sensing but include re-analysis and model output products.\nThe package uses the R raster\npackage and always provides\ndata as a standard raster (RasterLayer, RasterBrick, or RasterStack).\nEach data set is invdividually handled by a function to ensure the\nspatial and temporal registration is correct.\nThe contents of the data library itself is listed in the technical\nconfiguration.\nIf you would like a collection added please make a request via a Github\nissue\nor contact one of the authors directly.\nUsing raadtools\nThere are two main ways to use it.\nThe typical use-cases for raadtools are\n\nread a time series gridded data set as a function of date,\noptionally with spatial subsetting\nmatch a data set of longitude, latitude, time to the corresponding\nvalue in a time series gridded data set\n\nExamples of these workflows are outlined in this rOpenSci blog\npost.\nAccess to raadtools\nThe repository of data used by raadtools is available via the Nectar\nresearch cloud or for local use\nwithin the AAD.\nThere are two main ways to access raadtools. (If neither of 1 or 2 work\nfor you you, see your local raadtools expert.)\n1. RStudio raadtools server\nIf you have access to a \u201craadtools-RStudio-server\u201d then you need only\nload the package to get started:\nlibrary(raadtools)\n2. Local computer, within the AAD network\nIf it\u2019s not installed, trying installing with\ndevtools::install_github(\"AustralianAntarcticDivision\/raadtools\")\nlibrary(raadtools)\nTypically you will be provided with access, and won\u2019t be aware of the\nunderlying details, but the repository of data used by raadtools is\navailable under RDSI\/PUBLIC\/raad and at the AAD in the scientific data\ncollection.\nAnyone with a Nectar account may\nrun this by creating a VM from our raadclient image. Search the public\nimages for raadclient (e.g. \u2019 raadclient06_20181016\u2019 but choose the\nlatest one) and ensure that the SSH and RStudio port (8787) is open. Use\nthe default rstudio\/rstudio account, or create your own.\nYou are welcome to make your own copies of data from the collection for\nyour own use, but please respect the citation and usage requests of the\ndata providers listed in the\nsummary.\n\nPlease note that the \u2018raadtools\u2019 project is released with a Contributor\nCode of Conduct. By contributing to this project,\nyou agree to abide by its terms.\n","257":"Utah Turbulence in Environmental Studies Process and Analysis Code (UTESpac)\nCreated by: Derek Jensen and Eric Pardyjak\nderek591@gmail.com\nVersion 4.1\nVersion Date: 15 January 2017\nAbout:\nUTESpac is designed specifically for use with Campbell Scientific dataloggers and accompanying LoggerNet software with\nnative support for\n  Sonic Anemometers:  RMYOUNG 8100, Campbell Sci CSAT3 Open Path Gas Analyzers:  Licor 7500, Campbell Sci EC150 and \n  IRGASON, Krypton Hygrometers Finewire thermocouples for heat flux computations Propeller Anemometers Mean\n  meteorological sensors (e.g. T\/RH, Pressure, Solar, cup anemometers, etc.)\n\nUTESpac expects 24 or 48-hr CSV tables, quality controls the data and then computes means, fluxes, variances and\nderived temperatures (potential temperature, virtual potential temperature) and stores the output in a MatLab\nstructure or NetCDF file.\nSteps for Use:\n\n\nConvert Campbell Binary files to csv files using the Card Convert Program in LoggerNet\nOptions: File Processing - Use Time, set to 2 days 00 h under Time Settings\nFile naming - Use TimeDate Filenames and Append to Last File if multiple site files exist Array CSV Options\nTimestamp Options - Include year, day, hour\/minutes, seconds, don't include midnight is 2400, Array ID,\nArray Datalogger Format = Hour\/Minutes and Seconds\n\n\nCreate a folder for the individual site.  The folder name needs to be preceded by the keyword \"site\".  E.g. for a\nsite named Playa the folder name is sitePlaya.  Place the .csv files within the site folder\n\n\nCreate a subfolder named output, this is where the output data will be stored\n\n\nCreate header files for each data table The syntax is <91>tableName<92>_header.dat (e.g. \"Playa_1HZ_header.dat\",\n\"Playa_20HZ_header.dat).  Note that <91>tableName<92> must be consistent with the .csv tableNames created in step 1.  The\nheader file is a single line .dat, comma delimited file containing variable names and heights for all columns within\nthe respective data table.  The header file is 3 columns shorter than the .csv data file.  This is because UTESpac\nimmediately calculates the serial date numbers from the date vectors (columns 1 <96> 4) contained in the data tables.\nThe serial dates are stored in column 1 and columns 2 <96> 4 are deleted, thus becoming consistent with the header file.\nThe easiest way to create the header file is with Card Convert.  Create an ASCII T0A5 file, there is no need to run\nthe whole binary file, simply stop the conversion immediately and only a few hundred lines will be created.  Open the\nfile in a text editor and delete all lines outside of the variable headers (typically line 5).  The variable names\nwithin the header and the sensor templates (defined on lines 155-169) must be consistent.  The template is used by\nUTESpac to identify specific sensors in the header.  The rules for creating the template and header variable names\nare:\n\n\n\nThe template and variable name are the exact same except the sensor height is replaced with the wildcard '' in\nthe template.  e.g. template = 'Ux_', header variable name = 'Ux_0.5', 'Ux_10'\nThe sensor height must be the last numeric value in the header variable name - All sensors (with exception of\nsolar and battery) need an associated height in meters - Heights within the header variable name at a given tower\nheight need to exactly match. e.g. 'FW_5','Ux_5','RH_5'\n\n\n\nIf a global planar fit is used, a PFinfo structure, containing global planar fit coefficients, will be stored in\nthe site folder.  There is no need to do anything with it.  Note: For the Global Planar Fit, there must be 1 and only\n1 set of 5 minute, local planar fit data.  That is, the global planar fit will fail if there is\n'5minAvg_LPF_linDetrend' and '5minAvg_LPF_constDetrend' in the output folder.  There must be one or the other (it\ndoesn't matter which!).\n\n\nFill out the information section of the code (lines 56 - 116) and run the code.  A full example study is included\nin UTESpac.zip\n\n\nUse getData(), structFill() and structConcat() to produce complete (no missing days) datasets over the full\nexperiment.  See example\n\n\n","258":"Utah Turbulence in Environmental Studies Process and Analysis Code (UTESpac)\nCreated by: Derek Jensen and Eric Pardyjak\nderek591@gmail.com\nVersion 4.1\nVersion Date: 15 January 2017\nAbout:\nUTESpac is designed specifically for use with Campbell Scientific dataloggers and accompanying LoggerNet software with\nnative support for\n  Sonic Anemometers:  RMYOUNG 8100, Campbell Sci CSAT3 Open Path Gas Analyzers:  Licor 7500, Campbell Sci EC150 and \n  IRGASON, Krypton Hygrometers Finewire thermocouples for heat flux computations Propeller Anemometers Mean\n  meteorological sensors (e.g. T\/RH, Pressure, Solar, cup anemometers, etc.)\n\nUTESpac expects 24 or 48-hr CSV tables, quality controls the data and then computes means, fluxes, variances and\nderived temperatures (potential temperature, virtual potential temperature) and stores the output in a MatLab\nstructure or NetCDF file.\nSteps for Use:\n\n\nConvert Campbell Binary files to csv files using the Card Convert Program in LoggerNet\nOptions: File Processing - Use Time, set to 2 days 00 h under Time Settings\nFile naming - Use TimeDate Filenames and Append to Last File if multiple site files exist Array CSV Options\nTimestamp Options - Include year, day, hour\/minutes, seconds, don't include midnight is 2400, Array ID,\nArray Datalogger Format = Hour\/Minutes and Seconds\n\n\nCreate a folder for the individual site.  The folder name needs to be preceded by the keyword \"site\".  E.g. for a\nsite named Playa the folder name is sitePlaya.  Place the .csv files within the site folder\n\n\nCreate a subfolder named output, this is where the output data will be stored\n\n\nCreate header files for each data table The syntax is <91>tableName<92>_header.dat (e.g. \"Playa_1HZ_header.dat\",\n\"Playa_20HZ_header.dat).  Note that <91>tableName<92> must be consistent with the .csv tableNames created in step 1.  The\nheader file is a single line .dat, comma delimited file containing variable names and heights for all columns within\nthe respective data table.  The header file is 3 columns shorter than the .csv data file.  This is because UTESpac\nimmediately calculates the serial date numbers from the date vectors (columns 1 <96> 4) contained in the data tables.\nThe serial dates are stored in column 1 and columns 2 <96> 4 are deleted, thus becoming consistent with the header file.\nThe easiest way to create the header file is with Card Convert.  Create an ASCII T0A5 file, there is no need to run\nthe whole binary file, simply stop the conversion immediately and only a few hundred lines will be created.  Open the\nfile in a text editor and delete all lines outside of the variable headers (typically line 5).  The variable names\nwithin the header and the sensor templates (defined on lines 155-169) must be consistent.  The template is used by\nUTESpac to identify specific sensors in the header.  The rules for creating the template and header variable names\nare:\n\n\n\nThe template and variable name are the exact same except the sensor height is replaced with the wildcard '' in\nthe template.  e.g. template = 'Ux_', header variable name = 'Ux_0.5', 'Ux_10'\nThe sensor height must be the last numeric value in the header variable name - All sensors (with exception of\nsolar and battery) need an associated height in meters - Heights within the header variable name at a given tower\nheight need to exactly match. e.g. 'FW_5','Ux_5','RH_5'\n\n\n\nIf a global planar fit is used, a PFinfo structure, containing global planar fit coefficients, will be stored in\nthe site folder.  There is no need to do anything with it.  Note: For the Global Planar Fit, there must be 1 and only\n1 set of 5 minute, local planar fit data.  That is, the global planar fit will fail if there is\n'5minAvg_LPF_linDetrend' and '5minAvg_LPF_constDetrend' in the output folder.  There must be one or the other (it\ndoesn't matter which!).\n\n\nFill out the information section of the code (lines 56 - 116) and run the code.  A full example study is included\nin UTESpac.zip\n\n\nUse getData(), structFill() and structConcat() to produce complete (no missing days) datasets over the full\nexperiment.  See example\n\n\n","259":"Cloning\nTo clone both this repository and the SQUALL submodule,\nclone with the --recursive option:\ngit clone --recursive git@github.com:BLEES\/BLEES.git\nOtherwise, you can initialize the submodule by doing\ngit submodule init and you can keep the submodule up to\ndate by doing git submodule update.\n","260":"What is Telecoupling?\n\nTelecoupling is a new avenue of research to understand today\u2019s hyper-connected world and achieve a sustainable future. Telecoupling enables natural and social scientists across various disciplines to understand and generate information for managing how humans and nature sustainably coexist.\nThe telecoupling framework gains its distinction by enabling researchers and practitioners to dive deeply into systemic complexities, even if systems are far from each other. To understand the forces affecting sustainability across local to global scales, it is essential to build a comprehensive set of spatially explicit tools for describing and quantifying multiple reciprocal socioeconomic and environmental interactions over distances.\nWhat is the Telecoupling Toolbox?\n\nThe Telecoupling Toolbox, designed at Michigan State University\u2019s Center for Systems Integration and Sustainability, is the first suite of geospatial software tools and apps developed to map and identify the five major interrelated components of the telecoupling framework: systems, flows, agents, causes, and effects. The modular design of the toolbox allows the integration of existing tools and software to assess synergies and tradeoffs associated with policies and other local-to-global interventions.\nWho should use the Telecoupling Toolbox?\n\nThe innovative, free and open-source (see LICENSE for details) toolbox can provide researchers and practitioners a useful platform to address globally important issues, such as land use and land cover change, species invasion, migration, flows of ecosystem services, and trade of goods and products.\nWhat's in the Toolbox?\n\nArcGIS Toolbox\n\nThe ArcGIS Toolbox is a large collection of mapping and analysis tools for use within ESRI's ArcGIS Desktop (version 10.3.1 or later) to systematically study telecoupling. Test the current version of the ArcGIS Toolbox by using your own data or by downloading our sample data. Look inside the ArcGIS Toolbox project folder for code, images, documentation, and detailed instructions on installation and use.\nGeoApp\n\nThe GeoApp offers a dynamic, interactive, online geo-enabled platform along with a large collection of mapping and analysis tools to systematically study telecoupling. Check out and test our brand new GeoApp (beta) by using your own data or by downloading our sample data. Help yourself with our introductory tutorial if you need more time to familiarize yourself with the app widgets and tools. Look inside the GeoApp project folder for source code and images linked to the GeoApp.\nSample Data\n\nArcGIS Toolbox Data\n\nDownload and unzip our sample data folder for use with both our ArcGIS Toolbox and GeoApp. This data repository contains all the tables and spatial data necessary to run the set of telecoupling mapping and analysis tools we developed. For further information on any of the dataset provided, please feel free to contact us.\nGeoApp Data\n\nDownload and unzip our sample data folder for use with both our ArcGIS Toolbox and GeoApp. This data repository contains all the tables and spatial data necessary to run the set of telecoupling mapping and analysis tools we developed. For further information on any of the dataset provided, please feel free to contact us.\nCredits and Contacts\n\n\u00a9 2018 Michigan State University\nFrancesco Tonini: ftonini@msu.edu\nPaul McCord: mccordpa@msu.edu\nJianguo 'Jack' Liu: liuji@msu.edu\nLICENSE\n\nTelecoupling Toolbox (\u201cSoftware\u201d) is the property of Michigan State University (MSU) and is made available solely for educational or non-commercial use. See LICENSE for details.\n\nThis toolbox depends on the R Statistical Computing Software:\n\n\u00a9 2018 The R Foundation for Statistical Computing. R is free software and comes with ABSOLUTELY NO WARRANTY. See the COPYRIGHTS file for details.\n\nThis toolbox depends on ESRI software:\n\n\u00a9 2018 ESRI. See the Software License and Agreement for details.\n\nThis toolbox depends on InVEST - Natural Capital Project software:\n\n\u00a9 2018 NatCap Project. See the Software License and Agreement for details.\n","261":"Environmental-Sound-Classification\nhttps:\/\/esc50.herokuapp.com\/\n","262":"MCP9808 Temperature Logger\n\n\nLog temperature from an MCP9808 sensor\nconnected to a Raspberry Pi.\nSend temperature to Google Cloud IoT Core,\nwhich can then be saved and plotted using the Google App Engine app in the\nweb directory:\nmake\n\n# Example device.json:\n# {\n#   \"project_id\": \"my-gcp-project\",\n#   \"registry_id\": \"my-iot-core-registry\",\n#   \"device_id\": \"my-device\",\n#   \"priv_key_path\": \"my-device.pem\",\n#   \"region\": \"us-central1\"\n# }\n.\/out\/iotcorelogger -device device.json -cacerts roots.pem\n\nSet up a cron job, use it in a daemon, the world's your oyster...as long as the\nworld is temperature values read from the MCP9808.\nChoose a Client\nNOTE: The Python client is unmaintained! It may be deleted in the future.\nPlease use the Go client.\nThis project includes clients \u2014 code that runs on the Raspberry Pi to read the\ntemperature and log it \u2014 written in Go and Python.\nUse the Go client if you're sending temperature data to Google\nCloud IoT Core (it only supports Cloud IoT Core at the moment). It's easier to\nwork with than the Python client because you get a statically-linked binary that\njust works on the Raspberry Pi. You don't have to clone this repository on the\nRaspberry Pi or install dependencies or set up a virtualenv. Just make and run.\nUse the Python client if you want to log directly to Google\nCloud Pub\/Sub, or to Google Sheets. The Python client supports Cloud IoT Core\nas well. Note: This project only supports Python 3. The future is now. The\nfuture was in 2008. Come with\nus into the future.\nPrerequisites\nEach client's README has information about its prerequisites.\nRegardless of your choice of client, you'll need to:\n\nWire up the hardware. Adafruit have a nice tutorial:\nhttps:\/\/learn.adafruit.com\/mcp9808-temperature-sensor-python-library\/overview\nEnable I2C on your board. For Raspberry Pi,\nthis can be done with raspi-config. You'll find the \"I2C\" option under\neither \"Advanced Options\" or \"Interfacing Options\".\n\nSetting up Google Cloud IoT Core logging\nThe scripts at https:\/\/github.com\/mtraver\/provisioning are useful for creating\nthe CA key and cert and device-specific keys and certs described below.\n\nCreate an IoT Core registry.\nThe IoT Core quickstart\nprovides more info. The registry includes:\n\nA Pub\/Sub topic for telemetry (you'll need to create the topic if it\ndoesn't already exist)\nA Pub\/Sub topic for state (you'll need to create the topic if it\ndoesn't already exist)\nA CA cert for verifying device certs. This can be self-signed.\n\n\nAdd devices to the registry. This requires a device-specific cert that chains\nto the CA cert. The key and cert can be made with the scripts in the repo\nlinked above. Heed the information there about key handling and about the\ndevice ID (the device ID you use when making the cert must be the same as the\none you set when adding the device to the registry).\nCreate a subscription to the registry's telemetry topic. Configure it to\npush to the \/_ah\/push-handlers\/telemetry endpoint of the web app.\nThis is how IoT Core is tied to the web app.\n\nThe end-to-end flow is like this:\n\nA device sends a payload (in this case a protobuf; see\nmeasurement.proto) to IoT Core.\nIoT Core publishes the payload as a Pub\/Sub message to the registry's\ntelemetry Pub\/Sub topic.\nPub\/Sub pushes the message to the web app's endpoint, as configured in\nthe subscription to the topic.\nThe web app receives the request, decodes the payload, and writes\nit to the database.\n\nSetting up Google Cloud Pub\/Sub logging\nTODO\nSetting up Google Sheets logging\nGoogle provide a guide to using the Sheets API in Python:\nhttps:\/\/developers.google.com\/sheets\/api\/quickstart\/python.\n\n\nFollow \"Step 1: Turn on the Google Sheets API\" and use the wizard linked\nthere to make a project and set up access credentials. What you want is a\n\"service account\", which is what the wizard will recommend if you say that\nyou want access from a headless device\/crontab\/etc. You'll get an email\naddress that looks something like this:\n<something>@<something>.iam.gserviceaccount.com\nYou'll also get a JSON file containing the key for that service account.\nPut it in a safe place.\n\n\nNow make a Google Sheets spreadsheet and share it with the service account\nemail address, giving edit permissions.\nNote the spreadsheet ID. For the example URL below, the ID is\n1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms:\nhttps:\/\/docs.google.com\/spreadsheets\/d\/1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms\/edit\n\n\nThe JSON key file and spreadsheet ID are the two things you'll need to log to\nthe sheet.\n","263":"spenv\n\n\nspenv - add environmental data to spatial data\nDocs: https:\/\/sckott.github.io\/spenv\/\nPackage API\n\nsp_mutate - get env data for occ data input - not ready yet\nsp_extract_gridded - extract env gridded data\nsp_extract_pt - extract env point data\nsp_query - query for env data - not ready yet\nfind_locs - find locations\/stations\/etc. based on occ data input - internal fxn used in sp_mutate\n\nData sources\n\nHigh priority: There are a set of data sources for environmental data, some of which are high priority as determined by perhaps data quality, coverage, etc.\n\ntemperature, chlorophyll, ...\n\n\nAvailable in R: Then there are a set of data sources that are already available in R.\nWe should identify the set of high priority data sources that are not yet available in R, and make them so.\n\nList of datasources on Google Sheets\nUse cases\nI want data...\n\nfor this bounding box for this temporal range and spatial resolution\nthat is of a certain license, because:\n\nI want only open data, e.g., CC0\nI want data I can redistribute\nI want data that I can purchase or resell\n\n\n\nInstall\nremotes::install_github(\"sckott\/spenv\")\nlibrary(\"spenv\")\nExample: pt env data\nfile <- system.file(\"examples\", \"obis_mola_mola.csv\", package = \"spenv\")\ndat <- read.csv(file)\nhead(dat)\nres <- sp_extract_pt(x = dat[1:10,], radius = 100)\nres[[1]]\nExample: gridded env data\nlibrary(\"spocc\")\nres <- occ(query = 'Mola mola', from = 'obis', limit = 200)\nres_df <- occ2df(res)\nout <- sp_extract_gridded(res_df)\nhead(out)\n#> # A tibble: 6 x 8\n#>   name    longitude latitude prov  date       key                  lon_adj   sst\n#>   <chr>       <dbl>    <dbl> <chr> <date>     <chr>                  <dbl> <dbl>\n#> 1 Mola m\u2026      7.73     43.1 obis  2012-06-02 00001054-19a2-441b-\u2026    7.73  20.5\n#> 2 Mola m\u2026      4.06     43.4 obis  2012-05-25 0000642b-51de-4042-\u2026    4.06  16.2\n#> 3 Mola m\u2026     -2.14     49.2 obis  2001-08-05 000a320e-4e86-4259-\u2026  358.    17.4\n#> 4 Mola m\u2026      4.21     43.2 obis  2012-05-25 001099b7-7a24-4072-\u2026    4.21  16.2\n#> 5 Mola m\u2026     -2.09     44.4 obis  2012-07-03 0018922a-8b1c-4bb2-\u2026  358.    20.0\n#> 6 Mola m\u2026      6.19     42.9 obis  2012-06-27 0018a5aa-d260-4af1-\u2026    6.19  20.5\nMap it\n\"map\"\nContributors\n\nTom Webb\nSamuel Bosch\nScott Chamberlain\n\nMeta\n\nPlease report any issues or bugs.\nLicense: MIT\nGet citation information for spenv in R doing citation(package = 'spenv')\nPlease note that this project is released with a Contributor Code of Conduct.\nBy participating in this project you agree to abide by its terms.\n\n","264":"\n\n\nLoom\n\n  An Internet of Things Rapid Prototyping System for applications in environmental sensing\n  \nProject Page\n  \u00b7\n  Documentation\n  \u00b7\n  Lab Wiki\n  \u00b7\n  Quick Start\n   \u00b7\n  Configuration\n\n\nTable of Contents\n\nTable of Contents\nIntroduction\nObjectives\nKey Features\nInstalling Arduino and Loom\nQuick Start\nCommon Pin Allocations\nHardware Support\nDocumentation\nContributing\nVersioning\nResources\n\nCustom\/Modified Libraries used by Loom\n\n\nLicense\n\nIntroduction\nLoom is an ongoing multidisciplinary collaboration of the OPEnS Lab with a team of 20+ Computer Science and Electrical Engineering students to create a fully open source, modular, user friendly, sensor\/actuator Arduino library and ecosystem. The project enables environmental research and conservation communities to overcome significant technical hurdles for creating new environmental, agricultural, and ecological instrumentation to measure, monitor, automate, and understand our world.\nObjectives\n\nDesign a \"plug and play\" sensor\/actuator system\nSimple enough for K-12 students and non-technical users to use\nExtensible and programmable enough for engineers to customize\nCreate a wide variety of applications by simply connecting modular components\nMake the system wireless, low-power, low latency\nConfigure all sensors and actuators on a wireless network using an intuitive graphical user interface\nInteract with data and control signals on a network in realtime\nMake data transmitted from local and remote locations available instantly from anywhere around the world\n\nKey Features\n\nQuick to setup an entirely new project\nCode contained in an Arduino library\nSystem behavior defined with a configuration specification and minimal code\nExtensive customizability for complex applications\nDesigned for extensibility\nVariety of sensors and actuators supported\nRemote data logging to SD and internet in near real time\n\nInstalling Arduino and Loom\nInstalling Arduino and Loom Quick Setup\nInstalling Arduino and Loom Manual Setup\nQuick Start\nQuick Start Guide\nCommon Pin Allocations\nCommon Pin Allocations\nHardware Support\nHardware Support\nDocumentation\nWiki for general documentation not on GitHub or in Doxygen document\nDoxygen generated documentation Version 1 for more verbose documentation that is designed for developers\nDoxygen generated documentation Version 2 for more user-friendly documenation that is designed for end-users\nNote: The documentation does not currently update automatically, if would want to be sure you have the most up to date version of the documentation, you can run Doxygen to manually generate a local copy of the documentation. See the Doxygen website on how to Install Doxygen and Doxygen Usage.\nOnce installed, the run doxygen Doxyfile from the command line (from Loom directory) to generate the documentation. To view, open the Loom\/html\/index.html file in a browser.\nContributing\nIs there hardware support or other feature you would like to add to Loom? Follow our Guide to contributing to Loom\nVersioning\nLoom aims to follow Semantic Versioning\nResources\n\nProject Page for Loom on OPEnS lab website\nGitHub Organization for all OPEnS Lab projects\nLoomify An npm package to drive the backend Loom Tag Format parsing and Loom Library github interactions.\nLoom Configurator A WebApp designed for designing and exporting loom configurations\nLoom-Network Arduino networking library designed for use with any wireless radio\nLoom-Auxilliary General Loom and lab non-code files\nMax-Loom2 MaxMSP interfaces for Loom interactivity\n\nCustom\/Modified Libraries used by Loom\n\nOPEnS_RTC A modified arduino library for with support for a variety of RTCs\nSSLClient Arduino library to add SSL functionality to any Client class\nEthernetLarge Ethernet Library for Arduino, modified to support larger buffers for SSLClient\n\nLicense\nLoom is licensed under GNU General Public License v3.0\n","265":"Making Sense Onboarding\nThe Marking Sense onboarding. This project is a means to alleviate the issue of abandonment in IOT devices related to citizen science and civil sensing. This onboaridng is being used by Making Sense as a means to test the effectiveness of building communities around these grassroots initiatives. Currently supporting the SmartCitizen API and the new SmartCitizen Kit 1.5.\nThis is a web app that aims to solve key issues in the setup of open data sensors within grassroots smart-city communities through developing cognitive goals, such as fostering ownership, creating context, showing playful animations and simplifying language. This multi-lingual experience helps reduce the bottleneck of non-technical citizens installing IOT devices. This tool is currently being used in an EU Research Project.\nHere is the current link to live-deployment\nUpdates are handled through this fork and then moved down to the master\nPrerequisites\nYou need git to clone the repository. You can get git from\nhttp:\/\/git-scm.com\/.\nWe also use a number of node.js tools to initialize and test the Web App. You must have node.js and\nits package manager (npm) installed. You can get them from http:\/\/nodejs.org\/.\nAlso gulp: npm install -g gulp (with sudo if you are using Mac).\nClone the project\nClone the repository using:\ngit clone https:\/\/github.com\/fablabbcn\/smartcitizen-onboarding.git\ncd smartcitizen-web\n\nInstall dependencies\n\nInstall tools to manage and test the application: npm install.\nNo need of bower install, npm install will take care of it.\n\nUse Gulp tasks\n\ngulp or gulp build to build an optimized version of your application in \/dist\ngulp serve to launch a browser sync server on your source files\ngulp serve:dist to launch a server on your optimized application\ngulp test to launch your unit tests with Karma\ngulp test:auto to launch your unit tests with Karma in watch mode\ngulp protractor to launch your e2e tests with Protractor\ngulp protractor:dist to launch your e2e tests with Protractor on the dist files\ngulp deploy to publish the project to Github pages (gh-pages branch).\n\nNote: in case you see something like:\n\nError: Command failed: fatal: unable to read c6a8d370f3e95d9110eca4a03b704bd8940ca40b\n\nRun:\nrm -Rf $(node -e \"console.log(require('path').join(require('os').tmpdir(), 'tmpRepo'))\")\nThis is a Work in process... Final documentation coming soon!\nSupport and issues\n\nForum forum.smartcitizen.me\n\nCredits\nThis work has received funding from the European Union's Horizon 2020 research and innovation program under the grant agreement No. 688620\n\n","266":"Raspberry Pi Environmental Sensing\nThis project is a personal sensing station that uses Raspberry Pi, HTU21D (indoor temperature\/humidity), AM2306 (outdoor temperature\/humidity) and PMS7003 (particle matter level). It supports logging measured sensory data locally and submit to a MQTT broker and\/or a MySQL database.\n\nRaspberry Pi is a popular open-source hardware. This program is tested on RPi Zero W, but should support all versions of RPi.\nHTU21D is a high precision temperature + humidity sensor and it is connected to RPi via I2C_1.\nAM2306 is an outdoor temperature + humidity sensor, which uses the DHT22 chip. It is connected to RPi via Pin 7.\nPMS7003 is a laser particle matter sensor. It connects to the RPi using the serial port.\nMQTT is a subscribe\/publish message protocol designed for light-weight IoT devices.\nMySQL is a relational SQL database.\n\n\n1. Requirements\n\nPython >= 3.5\nTo use AM2306\/DHT22:\n\nInstall RPi.GPIO: sudo apt-get install python-rpi.gpio\nInstall the Adafruit driver: https:\/\/github.com\/adafruit\/Adafruit_Python_DHT\n\n\nTo report to a MQTT broker: https:\/\/pypi.org\/project\/paho-mqtt\/\nTo report to a MySQL server: sudo apt-get install python3-pymysql\n\n2. Usage\n\nChange to home directory: cd ~\nClone the project: git clone https:\/\/github.com\/automaticdai\/rpi-environmental-sensing\nEdit the configuration file rpi-weather-config.json and save\nCopy the configuration file to \/etc: sudo cp rpi-weather-config.json \/etc\/rpi-weather-config.json\nRun the main script: python3 main.py\n\nYou can run individual python script to test the sensor driver, e.g., python3 dht22.py\n3. System Configuration\nFor the configuration file config.json:\nConfig\n\nsensor_id: assign a sensor ID to the device.\nsensor_name: name of the sensor. Used as the prefix of MQTT publishers.\nlog_on: enable writing to a local log.\nreport_periodic: run the script periodically\/or only once.\nreport_interval_sec: set the sampling and report interval (in second). If 'report_periodic' is false, this parameter will be ignored. Should be no less than 10s, otherwise it is difficult to guarantee.\n\nMQTT\n\nenable: enable report to MQTT.\nserver, port: MQTT broker IP and port.\n\nMySQL\n\nenable: enable report to MySQL server.\nhost, port: database IP and port.\nuser, password: login user information.\ndb, table: database and table name (should be an existed database).\ncharset: character set\n\n4. Credit\n\nAdafruit for the HTU21D and DHT22 drivers.\nEclipse Paho project for the MQTT driver.\n\n","267":"\n\ningestr\nAn R package for reading environmental data from raw formats into\ndata.frames.\n\n\n\n\nThis is project was initiated at the inaugural IMCR\nHackathon hosted by\nthe Environmental Data\nInstitute. The end product of\nthis effort will be an R package on CRAN. The package will primarily\ndeal with reading data from files, though there will be some utilities\nfor initial cleanup of files such as removing blank rows and columns at\nthe end of a CSV file. Our work at the hackathon focused on package\ninfrastructure, standardization, and template construction.\nThe guiding principles of ingestr are that\n\nAll sources of environmental-related data should be easy to read\ndirectly\nReading in data should provide a standard output\nHeader information contained within sensor data files should be\nstored in a standard, easily readable format\nAssociating imported data with its original source is the first step\ntowards good data provenance records and reproducibility\nWe don\u2019t know about every common sensor and love contributions of\ncode or sensors that need support. See\nissues to submit an\nexample data file, and see our contributing\nguide to\ncontribute code.\n\nInstallation\nYou can install ingestr from github with:\n# install.packages(\"devtools\")\ndevtools::install_github(\"jpshanno\/ingestr\")\n\n# or from source\ningestr_source <- file.path(tempdir(), \"ingestr-master.zip\")\ndownload.file(\"https:\/\/github.com\/jpshanno\/ingestr\/archive\/master.zip\",\n              ingestr_source)\nunzip(ingestr_source,\n      exdir = dirname(ingestr_source))\ninstall.packages(sub(\".zip$\", \"\", ingestr_source), \n                 repos = NULL,\n                 type = \"source\")\nIngesting Data\nEach ingestr function to read in data starts with ingest_ to make\nautocomplete easier. We are targetting any source of environmental data\nthat returns data in a standard format: native sensor files, delimited\noutputs, HTML tables, PDF tables, Excel sheets, API returns, \u2026\nRunning any ingest function will read in the data and format the data\ninto a clean R data.frame. Column names are taken directly from the data\nfile, and users have the option to read the header information into a\ntemporary file that can then be loaded using ingest_header().\nAll data and header data that are read in will have the data source\nappended to the data as a column called input_source.\nSensor and Instrument Data\nMany sensors provide their output as delimited files with header\ninformation contained above the recorded data.\ncampbell_file <- \n  system.file(\"example_data\",\n              \"campbell_scientific_tao5.dat\",\n              package = \"ingestr\")\n\ncampbell_data <- \n  ingest_campbell(input.source = campbell_file,\n                  export.header = TRUE,\n                  add.units = TRUE,\n                  add.measurements = TRUE)\n\nstr(campbell_data)\n\ncampbell_header <- \n  ingest_header(input.source = campbell_file)\n\nstr(campbell_header)\nFormatted Non-Sensor Data Sources\nSome environmental data is published online as html elements. This data\ncan be difficult to read directly from the websites where they are\nhosted into R. To facilitate access, we have created functions that\nparse the html so that this data can be directly downloaded in R. To\ntrack the provenance of these data, the column input_source is\npopulated by the URL location from which the data were downloaded.\nPDO_data <- \n  ingest_PDO(input.source = \"http:\/\/jisao.washington.edu\/pdo\/PDO.latest\",  \n             end.year = NULL,\n             export.header = TRUE)\n#> Header info for http:\/\/jisao.washington.edu\/pdo\/PDO.latest has been saved to a temporary file. Run ingest_header('http:\/\/jisao.washington.edu\/pdo\/PDO.latest') to load the header data.\n\nstr(PDO_data)\n#> 'data.frame':    121 obs. of  14 variables:\n#>  $ YEAR        : chr  \"1901\" \"1902\" \"1903\" \"1904\" ...\n#>  $ JAN         : chr  \"0.79\" \"0.82\" \"0.86\" \"0.63\" ...\n#>  $ FEB         : chr  \"-0.12\" \"1.58\" \"-0.24\" \"-0.91\" ...\n#>  $ MAR         : chr  \"0.35\" \"0.48\" \"-0.22\" \"-0.71\" ...\n#>  $ APR         : chr  \"0.61\" \"1.37\" \"-0.50\" \"-0.07\" ...\n#>  $ MAY         : chr  \"-0.42\" \"1.09\" \"0.43\" \"-0.22\" ...\n#>  $ JUN         : chr  \"-0.05\" \"0.52\" \"0.23\" \"-1.53\" ...\n#>  $ JUL         : chr  \"-0.60\" \"1.58\" \"0.40\" \"-1.58\" ...\n#>  $ AUG         : chr  \"-1.20\" \"1.57\" \"1.01\" \"-0.64\" ...\n#>  $ SEP         : chr  \"-0.33\" \"0.44\" \"-0.24\" \"0.06\" ...\n#>  $ OCT         : chr  \"0.16\" \"0.70\" \"0.18\" \"0.43\" ...\n#>  $ NOV         : chr  \"-0.60\" \"0.16\" \"0.08\" \"1.45\" ...\n#>  $ DEC         : chr  \"-0.14\" \"-1.10\" \"-0.03\" \"0.06\" ...\n#>  $ input_source: chr  \"http:\/\/jisao.washington.edu\/pdo\/PDO.latest\" \"http:\/\/jisao.washington.edu\/pdo\/PDO.latest\" \"http:\/\/jisao.washington.edu\/pdo\/PDO.latest\" \"http:\/\/jisao.washington.edu\/pdo\/PDO.latest\" ...\n\nPDO_header <- \n  ingest_header(input.source = \"http:\/\/jisao.washington.edu\/pdo\/PDO.latest\")\n#> Header data was loaded from cached results created when http:\/\/jisao.washington.edu\/pdo\/PDO.latest was ingested previously in this R session.\n\nstr(PDO_header)\n#> 'data.frame':    1 obs. of  2 variables:\n#>  $ header_text : chr \"PDO INDEX If the columns of the table appear without formatting on your browser, use http:\/\/research.jisao.wash\"| __truncated__\n#>  $ input_source: chr \"http:\/\/jisao.washington.edu\/pdo\/PDO.latest\"\nBatch Ingests\nSensor data stored in folders is available for batch import using\ningest_ functions, or any other function that reads in data (i.e.\nread.csv, readr::read_csv. When a directory is read in file names\nare checked for duplicates, and imported data is checked for duplicate\nfile contents. The user is warned and can choose to suppress the warning\nor remove the duplicates. Parallel bath processing is supported for\nlarge batch processing (requires the\nparallel\npackage.\ntemperature_data <- \n  ingest_directory(directory = \"campbell_loggers\",\n                   ingest.function = ingest_campbell,\n                   pattern = \".dat\")\n\ntemperature_data\nIncorporate File Naming Conventions as Data\nFilenames generally include information about the data collected: site,\nsensor, measurement type, date collected, etc. We are working on a\ngeneralized approach (probably just a function or two) that would split\nthe filename into data columns using a template would be very useful.\nFor example if a set of file names read as \u201csite-variable-year\u201d\n(152-soil_moisture-2017.csv, 152-soil_temperature-2017.csv,\n140-soil_moisture_2017.csv, etc), then the function would take an\nargument supplying the template as column headers: \u201csite-variable-year\u201d\nwith either delimiters or the length of each variable to enable\nsplitting. These functions will likely build off of the great work done\non tidyr::separate() and we suggest using that until we have\nincorporated a solution.\nPreliminary Clean-up Utilities\nBasic data cleaning utilities will be included in ingestr. These will\ninclude identifying duplicate rows, empty rows, empty columns, and\ncolumns that contain suspicious entries (i.e. \u201c.\u201d). These utilities will\nbe able to flag or correct the problems depending upon user preference.\nIn keeping with our commitment to data provenance and reproduciblity all\ncleaning utilities will provide a record of identified and corrected\nissues which can be saved by the user and stored with the final dataset.\nQAQCR (quacker)\nWhile ingestr is focused on getting data into R and running preliminary\nchecks, another group at the IMCR Hackathon focused on quality assurance\nchecks for environmental data.\nqaqcr provides a simple,\nstandard way to apply the quality control checks that are applicable to\nyour data.\nThe packages are the start of a larger ecosystem including\nEMLassemblyline for\nenvironmental data management to create a convenient, reproducible\nworkflow moving from raw data to archived datasets with rich EML\nmetadata.\n","268":"MULTIPOLAR:  Multi-Source Policy Aggregation for Transfer Reinforcement Learning between Diverse Environmental Dynamics (IJCAI 2020)\nThis is the original repository for the following paper:\nMohammadamin Barekatain, Ryo Yonetani, Masashi Hamaya. \"MULTIPOLAR: Multi-Source Policy Aggregation for Transfer Reinforcement Learning between Diverse Environmental Dynamics\". To apprear in IJCAI 2020.\nTL;DR\nWe propose MULTIPOLAR, a transfer RL method that leverages a set of source policies collected under unknown diverse environmental dynamics to efficiently learn an optimal target policy in another dynamics. Video of a five-minute presentation of this work.\nSource agents (Roboschool Ants with different leg designs)\n   \nTarget agent trained with MULTIPOLAR (left) vs. trained from scratch (right)\n \nGetting Started\nThis is a TensorFlow-based implementation to reproduce all of our experiments presented in the paper. All subsequent commands in this README should be run from the top-level directory of this repository. The code has been tested on Ubuntu 16.04 as well as Mac OS Mojave 10.14.06.\nInstallation\nPrerequisites\n\npython3 (>=3.5) with the development headers.\nTensorFlow (=1.14.0)\n\nUbuntu\nsudo apt-get update && apt-get install ssh swig cmake libopenmpi-dev python3-dev zlib1g-dev ffmpeg parallel libpcre3-dev libsm6 libxext6 libxrender-dev\n\nMac OS X\nbrew install cmake openmpi ffmpeg parallel\n\nInstall using pip\npip install stable-baselines==2.4.0 box2d box2d-kengz pyyaml==5.1.2 pybullet==2.1.0 box2d-py gym==0.10.9 roboschool==1.0.46 pytablewriter bootstrapped opencv-python\n\nMake sure that gym version is correct: gym==0.10.9.\nPlease see Stable Baselines README\nand RL Baseline Zoo for alternative installations.\nIf you're using Mac OS and have problem installing pybullet, use the following:\nCFLAGS='-stdlib=libc++' pip install pybullet==2.1.0\n\nTesting the installations\nTo test the installations, first install pytest, and then:\npython -m pytest -v tests\/\n\nTraining MULTIPOLAR in Acrobot\nIn this section, we present how to train MULTIPOLAR in Acrobot environment. Since our full experiments are computationally expensive, here we use 10 environment instances instead of 100 for both the baseline and MULTIPOLAR agents. Below commands will execute 3 trainings in parallel. This number must be configured based on the available number of CPUs.\n\nTrain the baseline agents with multi-layer perceptron (MLP) policy network three times (with different random seeds) in 10 randomly sampled environment instances.\n\npython random_env_dynamic_train_cmd_gen.py --num-samples 10 --algo ppo2 --seed 0 --env Acrobot-v1 \\\n--params-ranges LINK_LENGTH_1,0.3,1.3 LINK_LENGTH_2,0.3,1.3 LINK_MASS_1,0.5,1.5 LINK_MASS_2,0.5,1.5 LINK_COM_POS_1,0.05,0.95 LINK_COM_POS_2,0.05,0.95 LINK_MOI,0.25,1.5\n\nparallel -a \/tmp\/out.txt --eta -j 3\n\nWe also use these trained MLPs as a pool of source policy candidates from which we sample to train MULTIPOLAR policies. Using the Source_histogram.ipynb notebook, it's possible to visualize the histogram of final episodic reward (average rewards of the last 100 training episodes) for these candidates similar to the Figure 4 in the paper.\n\nFor each environment instance, train 3 MULTIPOLAR policies with distinct sets of source policies of size 4 selected randomly from the pool of source policy candidates.\n\npython train_multipolar_random_source.py --num-jobs 3 --sources-dir logs\/ppo2\/ --env Acrobot-v1 \\\n--algo multipolar-ppo2 --num-set 3 --num-sources 4 --num-subopt-sources 0 --num-samples 10 \\\n--params-ranges LINK_LENGTH_1,0.3,1.3 LINK_LENGTH_2,0.3,1.3 LINK_MASS_1,0.5,1.5 LINK_MASS_2,0.5,1.5 LINK_COM_POS_1,0.05,0.95 LINK_COM_POS_2,0.05,0.95 LINK_MOI,0.25,1.5\n\n\nRepeat step 2 with one source policy as RPL baseline policy.\n\npython train_multipolar_random_source.py --num-jobs 3 --sources-dir logs\/ppo2\/ --env Acrobot-v1 \\\n--algo multipolar-ppo2 --num-set 3 --num-sources 1 --num-subopt-sources 0 --num-samples 10 \\\n--params-ranges LINK_LENGTH_1,0.3,1.3 LINK_LENGTH_2,0.3,1.3 LINK_MASS_1,0.5,1.5 LINK_MASS_2,0.5,1.5 LINK_COM_POS_1,0.05,0.95 LINK_COM_POS_2,0.05,0.95 LINK_MOI,0.25,1.5\n\n\n\nUsing Sampling_efficiency.ipynb, compare the sample efficiency of MULTIPOLAR(K=4) to the baselines similar to Table 7 in the paper.\n\n\nUsing plot_learning_curves.ipynb, plot the learning curves similar to Figure 3 in the paper.\n\n\nTraining MULTIPOLAR in other environments\nBelow you can find the commands we used for performing our other experiments in 100 environment instance.\na) Roboschool Hopper\npython random_env_dynamic_train_cmd_gen.py --num-samples 100 --algo ppo2 --seed 0 --env RoboschoolHopper-v1 \\\n--params-ranges leg_length,0.35,0.65 foot_length,0.29,0.49 thigh_length,0.35,0.55 torso_length,0.3,0.5 size,0.7,1.1 damping,0.5,4 friction,0.5,2 armature,0.5,2\n\nparallel -a \/tmp\/out.txt --eta -j 40\n\npython train_multipolar_random_source.py --num-jobs 40 --sources-dir logs\/ppo2\/ --env RoboschoolHopper-v1 \\\n--algo multipolar-ppo2 --num-set 3 --num-sources 1 --num-subopt-sources 0 \\\n--params-range leg_length,0.35,0.65 foot_length,0.29,0.49 thigh_length,0.35,0.55 torso_length,0.3,0.5 size,0.7,1.1 damping,0.5,4 friction,0.5,2 armature,0.5,2\n\npython train_multipolar_random_source.py --num-jobs 40 --sources-dir logs\/ppo2\/ --env RoboschoolHopper-v1 \\\n--algo multipolar-ppo2 --num-set 3 --num-sources 4 --num-subopt-sources 0 \\\n--params-range leg_length,0.35,0.65 foot_length,0.29,0.49 thigh_length,0.35,0.55 torso_length,0.3,0.5 size,0.7,1.1 damping,0.5,4 friction,0.5,2 armature,0.5,2\n\nb) Roboschool Ant\npython random_env_dynamic_train_cmd_gen.py --num-samples 100 --algo ppo2 --seed 0 --env RoboschoolAnt-v1 \\\n--params-range length,0.4,1.4\u00a0 size,0.7,1.1\u00a0 damping,0.1,5 friction,0.4,2.5 armature,0.25,3\n\nparallel -a \/tmp\/out.txt --eta -j 40\n\npython train_multipolar_random_source.py --num-jobs 40 --sources-dir logs\/ppo2\/ --env RoboschoolAnt-v1 \\\n--algo multipolar-ppo2 --num-set 3 --num-sources 1 --num-subopt-sources 0 \\\n--params-range length,0.4,1.4\u00a0 size,0.7,1.1\u00a0 damping,0.1,5 friction,0.4,2.5 armature,0.25,3\n\npython train_multipolar_random_source.py --num-jobs 40 --sources-dir logs\/ppo2\/ --env RoboschoolAnt-v1 \\\n--algo multipolar-ppo2 --num-set 3 --num-sources 4 --num-subopt-sources 0 \\\n--params-range length,0.4,1.4\u00a0 size,0.7,1.1\u00a0 damping,0.1,5 friction,0.4,2.5 armature,0.25,3\n\nc) Roboschool InvertedPendulumSwingup\npython random_env_dynamic_train_cmd_gen.py --num-samples 100 --algo ppo2 --seed 0 --env RoboschoolInvertedPendulumSwingup-v1 \\\n--params-range length,0.2,2\u00a0 size,0.4,3\u00a0 damping,0.1,5 friction,0.5,2 armature,0.5,3 gravity,-11,-7\n\nparallel -a \/tmp\/out.txt --eta -j 40\n\npython train_multipolar_random_source.py --num-jobs 40 --sources-dir logs\/ppo2\/ --env RoboschoolInvertedPendulumSwingup-v1 \\\n--algo multipolar-ppo2 --num-set 3 --num-sources 1 --num-subopt-sources 0 \\\n--params-range length,0.2,2\u00a0 size,0.4,3\u00a0 damping,0.1,5 friction,0.5,2 armature,0.5,3 gravity,-11,-7\n\npython train_multipolar_random_source.py --num-jobs 40 --sources-dir logs\/ppo2\/ --env RoboschoolInvertedPendulumSwingup-v1 \\\n--algo multipolar-ppo2 --num-set 3 --num-sources 4 --num-subopt-sources 0 \\\n--params-range length,0.2,2\u00a0 size,0.4,3\u00a0 damping,0.1,5 friction,0.5,2 armature,0.5,3 gravity,-11,-7\n\nd) CartPole\npython random_env_dynamic_train_cmd_gen.py --num-samples 100 --algo ppo2 --seed 0 --env CartPole-v1 \\\n--params-range masscart,0.2,20 masspole,0.1,5 length,0.1,3 force_mag,6,13 gravity,6,14\n\nparallel -a \/tmp\/out.txt --eta -j 40\n\npython train_multipolar_random_source.py --num-jobs 40 --sources-dir logs\/ppo2\/ --env CartPole-v1 \\\n--algo multipolar-ppo2 --num-set 3 --num-sources 1 --num-subopt-sources 0 \\\n--params-range masscart,0.2,20 masspole,0.1,5 length,0.1,3 force_mag,6,13 gravity,6,14\n\npython train_multipolar_random_source.py --num-jobs 40 --sources-dir logs\/ppo2\/ --env CartPole-v1 \\\n--algo multipolar-ppo2 --num-set 3 --num-sources 4 --num-subopt-sources 0 \\\n--params-range masscart,0.2,20 masspole,0.1,5 length,0.1,3 force_mag,6,13 gravity,6,14\n\ne) LunarLanderContinuous\npython random_env_dynamic_train_cmd_gen.py --num-samples 100 --algo sac --seed 0 --env LunarLanderContinuous-v2 \\\n--params-ranges MAIN_ENGINE_POWER,10,40 SIDE_ENGINE_POWER,0.5,2 SCALE,25,50 INITIAL_RANDOM,500,1500 SIDE_ENGINE_HEIGHT,10,20 SIDE_ENGINE_AWAY,8,18\n\nparallel -a \/tmp\/out.txt --eta -j 40\n\npython train_multipolar_random_source.py --num-jobs 40 --sources-dir logs\/sac\/ --env LunarLanderContinuous-v2 \\\n--algo multipolar-sac --num-set 3 --num-sources 1 --num-subopt-sources 0 \\\n--params-ranges MAIN_ENGINE_POWER,10,40 SIDE_ENGINE_POWER,0.5,2 SCALE,25,50 INITIAL_RANDOM,500,1500 SIDE_ENGINE_HEIGHT,10,20 SIDE_ENGINE_AWAY,8,18\n\npython train_multipolar_random_source.py --num-jobs 40 --sources-dir logs\/sac\/ --env LunarLanderContinuous-v2 \\\n--algo multipolar-sac --num-set 3 --num-sources 4 --num-subopt-sources 0 \\\n--params-ranges MAIN_ENGINE_POWER,10,40 SIDE_ENGINE_POWER,0.5,2 SCALE,25,50 INITIAL_RANDOM,500,1500 SIDE_ENGINE_HEIGHT,10,20 SIDE_ENGINE_AWAY,8,18\n\nAblation Study of MULTIPOLAR\nThere exist two degraded versions of MULTIPOLAR, which is explained in Section 4.2 of the paper.\n\n\naggregation parameters fixed to 1: repeat the training commands with an extra flag --SIW False\n\n\nauxiliary network learned independent of the states: repeat the training commands with an extra flag --no-bias True\n\n\nIf you wish to make commercial use of any part of this source code, please contact us at contact@sinicx.com.\n","269":"environmental-impact-tools\nEnvironmental Impact Tools provide analysis and reporting tools for scientists, planners, and other analysts to understand potential impact of development and other projects on the natural environment. Environmental Impact Tools leverage the core ArcGIS Platform to help organizations with analysis and reporting workflows.\n\nFeatures\nThis GitHub repository houses the Environmental Analysis toolset used to analyze data and report the results.  The toolset includes the following tools:\n\nBasic Proximity Analysis\nDistance Analysis\nFeature Comparison Analysis\nAnalysis Summary\nImpact Report\n\nRequirements\nStart using these tools now by downloading this repository as a .zip file and unzipping it to a suitable location; or clone the repository with a git tool.  Requirements for using these tools include:\n\nArcGIS Pro 1.3.1\n\nFor more information on requirements and the use of the tools, see the Environmental Analysis help.\nResources\nLearn more about Esri's ArcGIS for State Government maps and apps.\nShow me a list of other State Government GitHub repositories.\nAdditional information and sample data\nare available for these tools.\nIssues\nFind a bug or want to request a new feature?  Please let us know by submitting an issue.\nContributing\nEsri welcomes contributions from anyone and everyone.\nPlease see our guidelines for contributing.\nLicensing\nCopyright 2016 Esri\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\nhttp:\/\/www.apache.org\/licenses\/LICENSE-2.0\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\nA copy of the license is available in the repository's\nLICENSE.txt file.\n[](Esri Tags: ArcGISSolutions State-Government State Government Environmental Analysis Impact Report)\n[](Esri Language: Python)\n","270":"Environmentalist\n\nConfigure your .Net application via environment variables in a manner where\nyou're not calling Environment.GetEnvironmentVariable all over the place.\nInstallation\nInstall via nuget\nPM> Install-Package Environmentalist\nUsage\nDefine an interface\nDefine your configuration via an interface. E.g.,\npublic interface ITestConfig\n{\n    [FromEnvironment(\"COOL_DICTIONARY\")]\n    IDictionary<string, string> CoolDictionary { get; }\n\n    [FromEnvironment(\"COOL_PROPERTY\")]\n    string CoolProperty { get; }\n}\nHere, we're using the FromEnvironment attribute to tell Environmentalist\nwhich environment variable to use with this property.\nCreate an instance\nCreate an instance of your configuration via\nvar config = Configurator.Create<ITestConfig>(new\n    {\n\tCoolDictionary = new Dictionary<string, string>(),\n        CoolProperty = \"foo\"\n    }\n);\nThe supplied object serves as a set of defaults if Environmentalist can't find\na given variable in the environment. Properties which aren't strings are\nautomatically deserialized from the enviroment as JSON.\n???\nEnvironmentalist doesn't assume anything about how you use your configuration.\nYou can just pop the returned object into your IoC container of choice or wrap\nit in a singleton or static class if you want to use an API closer to the\nstandard way of doing config.\n","271":"Meteobike - Mapping urban heat islands with bikes\n\"Meteobike\" is our educational Raspberry Pi Zero Project at the University of Freiburg, Chair of Environmental Meteorology. In our course \"Tools in Meteorology\" (5th Term of our Minor in \"Meteorology and Climatology\"), we develop a system to measure, analyze and visualize the urban heat island effect. Within a short period (~2 hours), we measure with many systems simultaneously temperature and humidity transcects inside and outside the city and tag measurement locations with GPS. The system is battery operated and light, so it can be mounted on bikes. Communication with the Raspberry Pi Zero to our smartphone is enabled via wireless network.\n\nOverview\nStudents build their own mobile systems. Each system will be assembled using the following components:\n\n\n\nComponent\nModel\nLink to Vendor in Germany\nPrice\n\n\n\n\nMicrocontroller\nRaspberry Pi Zero W\nPimoroni.de\n10 EUR\n\n\nGPS\nAdafruit Ultimate GPS Breakout\nPimoroni.de\n40 EUR\n\n\nTemperature \/ Humidity Sensor\nDHT22 AM2302\nAZ-Delivery (Amazon.de)\n5 EUR\n\n\nMicro SD Card\nNOOBS 16GB microSD\nPimoroni.de\n5 EUR\n\n\nBattery\nPOWERADD Pilot 2GS Powerbank 10000mAh*\nPoweradd (Amazon.de)\n15 EUR\n\n\nJumper Wires\nElegoo Jumper Wire*\nGYE (Amazon.de)\n7 EUR\n\n\nScreen\n2.7inch e-Paper HAT\nReichelt.de\n20 EUR\n\n\n\n\nCan be replaced by any other product\n\n\nWorkshop 1 - Setting up the Raspberry Pi Zero and connecting the sensors\nIn this first workshop you will connect the Raspberry Pi Zero to a mouse, a keyboard and a screen to set it up properly. Then we will connect the temperature\/relative humidiy sensor and a GPS. If they are working, we will install a user-interface to collect automatically your data and store it on the SD card.\nConnecting and starting the Raspberry Pi Zero\nThe Raspberry Pi Zero W is a microcomputer running a full operating system and providing input and output connectivity through a number of interfaces:\n\nSetting-up the SD-card\nYour Raspberry Pi Zero W comes with a micro SD card that contains the operating sysetm (called Raspbian) preinstalled. In some cases, the micro SD card is housed inside the larger regular SD card \"adapter\". Pull the micro-SD card out and insert it carefully into the card slot. Make sure the logo is up and the hand-painted white number (or sticker) on the back.\n\nSetting-up temporary peripherals (mouse, keyboard, screen)\nThe first time you set-up your Raspberry Pi Zero W, you will need a few additional components. The components you need are\n\nScreen (with a HDMI, VGA or DVI connection)\nUSB keyboard\nUSB mouse\nA USB hub and a micro-USB to USB-A convertor.\nA power supply\n\nIn our course, you are provided with a USB Hub, a micro-USB to USB-A. You provide the screen, a USB keyboard and a USB mouse, possibly also a regular HDMI cable.\nLater, once the system is assigned to your wireless networks, you can connect to it without keybord, without mouse and without Screen using RealVNC, so there is no need for a phsyical keyboard, a mouse or a screen in later exercises or during the bike traverses. All can be remotely controlled from your laptop, your smartphone or tablet.\nHere are all connection cables and supplies you need for the initial set-up (specific models may vary, screen is not shown):\n\nFirst, connect the USB mouse and keyboard. Your Raspberry Pi Zero W has two mini-USB ports, one (left) is for the USB devices (mouse, keyboard), one (right) is actually only for supplying power (see below). First connect to the USB devices (left). Because there is only one true USB port, but you need to connect two devices, you must also add initially a USB hub. Here is the set-up:\n\nTo connect your screen to TV during the initial set-up, connect first a mini-HDMI to HDMI coverter. Then you can use a regular HDMI cable to connect it to you screen (In rare cases you need a mini-HDMI to VGA adapter if your screen does not support HDMI and only VGA, or a mini-HDMI to DVI adapter if your screen does not support HDMI and only DVI).\n\nPower-up the system\nFinally connect the power supply to the right mini USB connector. The Raspberry Pi Zero W now starts up, the green inicator light begins to flash, and instructions follow on your screen.\nSetting-up the wireless network\nIn case this is a first-time installation, follow the instructions on-screen to set-up your Raspberry Pi Zero W. It will automatically reboot after resizing. In most cases this is not needed, as your OS is already fully installed and operational.\nThen connect to your home wireless network. Click in the menu-bar on the wireless network icon, select your home network and enter your password. Hover with the mouse over the network icon to read the IP number. Note the IP number on a sheet as you will need it later.\n\nNext, localize the Raspberry Pi Zero W to your language and region. Check if the hostname is \"raspberryXX\" where XX is the number of your system. This is needed to identify your system.\n\nAt this point we recommend to reboot your Raspberry Pi.\nRemote connection via the wireless network\nTest the communication with another device (your laptop or smartphone). First activate VNC. Go to settings, and enable \"VNC\". You can also enable SSH und I2C.\n\nNext, on your laptop or smartphone install the \"VNC Viewer\" from \"RealVNC\":\n\nOn Mac, Windows, or Linux install the desktop version of the VNC Viewer.\nOn iOS devices use the Apple App Store to download the VNC Viewer.\nOn Android devices use  Google Play to download the VNC Viewer.\n\nMake sure your laptop or smartphone is connected to the same wireless as the Raspberry Pi Zero W. Then start your viewer, connect to the IP address you previously noted (likely 192.168.X.Y) and enter the username \"pi\" with the password we have previously set.\nYou should be able to control your Raspberry Pi Zero W and you can use a mouse and keybord remotely.\nInstalling the Sensors\nInstalling the DHT22 temperature \/ relative humidity probe\nThe DHT22 is a low-cost digital temperature and humidity sensor. It contains a capacitive humidity sensor and a thermistor (resistor that changes with temperature). It transfers data digitally to your Raspberry Pi Zero W. You need just three cables to connect the DHT22 to the Raspberry Pi Zero W - one for power (red), one for the signal (orange) and one for the ground (brown).\n\nTo enable communication with the DHT22 for the first time, enter the following commands once into the LXTerminal (the command line) on the Raspberry Pi Zero to install the Adafruit DHT 22 library. Once the library is installed, you can access it from the programming language Python. If your system has been already in use before, then installing the libray can be skipped (someone else has already installed the library before).\n$ sudo apt-get update\n$ sudo apt-get install build-essential python-dev python-openssl git\n$ git clone https:\/\/github.com\/adafruit\/Adafruit_Python_DHT.git\n$ cd Adafruit_Python_DHT\n$ sudo python setup.py install\n\nNext, turn off the Raspberry Pi Zero. Disconnect the power cable from the Raspberry Pi Zero. Connect the DHT22 sensor physically using the pre-soldered wires, while power is off. Never connect any sensors on a live (powered) system as this might damage the board.\nConnect the following color coding on the pins of the Raspberry Pi Zero:\n\n\n\nDHT22 T\/RH Sensor\nCable Color\nRaspberry Pi Zero\n\n\n\n\nPIN 1\nRed Cable\nPIN 1 (3V+)\n\n\nPIN 2\nOrange Cable\nPIN 7 (GPIO4)\n\n\nPIN 3\n(no cable)\n\n\n\nPIN 4\nBrown Cable\nPIN 9 (Ground)\n\n\n\n\nDouble check if the connection is correct. A wrong connection could also damage the sensor and or the Raspberry Pi Zero. Then reconnect the power cable to the Raspberry Pi Zero. The Raspberry Pi Zero restarts, and its green light flashes.\nOnce started, the DHT 22 Sensor can be polled with the following commands in Python Version 2 (not Version 3!). First start the Phython development environment for Python 2.7 in interactive mode. In Python, enter\n>>> import Adafruit_DHT\n>>> humidity, temperature = Adafruit_DHT.read_retry(Adafruit_DHT.DHT22,4)\n>>> print temperature, humidity\n\nThis will display the currently measured values. The system measures temperature and humidity every two seconds.\nNext, as an exercise you can calculate the vapour pressure using the Clausius-Clapeyron equation. First calculate the saturation vapour pressure in kPa, then convert the relative humidity to vapour pressure. Note that temperature needs to be converted to Kelvins first.\n>>> import numpy \n>>> saturation_vappress = 0.6113 * numpy.exp((2501000.0\/461.5)*((1.0\/273.15)-(1.0\/(temperature+273.15))))\n>>> vappress=(humidity\/100.0)*saturation_vappress\n>>> print vappress\n\nCan you also calculate the dewpoint temperature?\nInstalling the GPS Module\nThe Adafruit Ultimate GPS is a 66 channel Global Positioning System using satellites to accurately determine your location, speed and altitude. It digitally communicates with the Raspberry Pi Zero W over four cables:\n\nEnabling serial communication with the GPS Module\nTo enable communication with the Raspberry Pi Zero W for the very first time, you need to enable serial communication. Again, if the system has been used in years before, then the follwing changes might already be implemented and you can skip to section 'Connecting the GPS'.\nIf the serial communication has not been installed, then start the Raspberry's LXTerminal and type:\n$ sudo apt-get install gpsd gpsd-clients python-gps\n$ sudo systemctl stop serial-getty@ttyS0.service \n$ sudo systemctl disable serial-getty@ttyS0.service\n$ sudo systemctl stop gpsd.socket\n$ sudo systemctl disable gpsd.socket\n\nFor the Raspberry Pi Zero we need to enable the serial port on the GPIO pins. This requires us to change the configuration file of the Raspberry Pi Zero W. You can use a texteditor, for example the nano command in LXTerminal and edit the file config.txt\n$ sudo nano \/boot\/config.txt\n\nScroll to the the very bottom of the file (not with a mouse, but with the arrow keys) and then type this on a new line:\nenable_uart=1\n\nSave with Ctrl+0 (German: Strg+O), and then press Enter. Next press Ctrl+X (Strg+X) to exit the nano editor. Finally, reboot the Raspberry Pi Zero.\nOnce rebooted, disable the standard socket, and run this command in the LXTerminal to enable the serial port:\n$ sudo gpsd \/dev\/ttyS0 -F \/var\/run\/gpsd.sock\n\nNext, edit the file \/etc\/rc.local, again using the nano editor:\n$ sudo nano \/etc\/rc.local \n\nAn insert at the very end, but above the line exit 0 the following line:\ngpsd \/dev\/ttyS0 -F \/var\/run\/gpsd.sock\n\nSave with Ctrl+0 (German: Strg+O), and then press Enter. Next press Ctrl+X (Strg+X) to exit the nano command line editor.\nNow, every time the Raspberry Pi Zero is booted, this command will be executed.\nConnecting the GPS\nTurn off the Raspberry Pi Zero. Disconnect the power cable from the Raspberry Pi Zero. Connect the GPS physically using the pre-soldered four wires, with the following color coding on the pins of the Raspberry Pi Zero:\n\n\n\nGPS\nCable Color\nRaspberry Pi Zero\n\n\n\n\nPVIN\nBlack Cable\nPIN 4 (5V+)\n\n\nGND\nWhite Cable\nPIN 6 (Ground)\n\n\nRX\nGrey Cable\nPIN 8 (TXD)\n\n\nTX.\nPurple Cable\nPIN 10 (RXD)\n\n\n\n\nDouble check if the connection is correct. Then reconnect the power cable to the Raspberry Pi Zero. The Raspberry Pi Zero restarts, and the green light flashes.\nTesting the GPS\nOnce the Raspberry PI has been restarted, you can test the GPS using the following command on the command line:\n$ cgps -s\n\nNote: If the GPS is searching for a signal it will flash red 5 times in 10 seconds and if it flashes red once in 15 seconds it has been connected to the satellites. The GPS needs to be outdoors (or at least on a balcony or window sill with partial view of the sky) to connect to satellites. It cannot connect to satellites indoors.\nRunning the recording interface\nWe want the data from the GPS and the DHT22 to be automatically collected and written into a file. We would also benefit from having the system data displayed in real time on screen. This is done with the python program meteobike03.py, which you can download on your Raspberry Pi Zero here - place it on your Raspberry PIs Desktop:\n\nDownload meteobike03.py\n\nYou can start meteobike03.py using LXTerminal (assuming your file has been downloaded to the desktop)\n$ python ~\/Desktop\/meteobike03.py \n\n\nNext, make changes to personalize your copy of meteobike03.py. You can, for example, open the Python Development Environment (Version 2.7) and File > Open.\n\nReplace \"01\" on line 41 raspberryid = to your system's two digit number. If your system has the number \"7\" enter \"07\".\nReplace \"Andreas\" on line 42 studentname = to your first name in quotes with a Capital letter. That way you can idenitify your data when we upload it later.\n\nThen save the modified code File > Save. Close the Python Development Environment.\nEvery time meteobike03.py is started, it will create a new data-file that contains the data sampled. Here is an example:\n\n\n\nID\nRecord\nRaspberry_Time\nGPS_Time\nAltitude\nLatitude\nLongitude\nTemperature\nTemperatureRaw\nRelHumidity\nRelHumidityRaw\nVapourPressure\nVapourPressureRaw\nVelocity\n\n\n\n\n01\n8\n2018-05-06 08:29:03\n2018-05-06T06:29:04.000Z\n281.700\n47.991855\n7.845193\n23.0\n23.1\n41.9\n42.0\n1.196\n1.192\n5.14\n\n\n01\n9\n2018-05-06 08:29:11\n2018-05-06T06:29:12.000Z\n288.000\n47.991375\n7.845212\n22.9\n23.0\n41.9\n42.0\n1.188\n1.185\n6.68\n\n\n01\n10\n2018-05-06 08:29:24\n2018-05-06T06:29:25.000Z\n290.000\n47.991242\n7.845800\n23.0\n23.1\n41.9\n42.0\n1.196\n1.192\n3.56\n\n\n\nYou should also place a link - called bash script on your desktop (meteobike.sh)\n\nDownload meteobike.sh\n\nTo ensure it works, you must change permissions of the file as follows (make it executable). This way, it can be started with a double-click:\n$ chmod +x  ~\/Desktop\/meteobike.sh\n\nNow you can double-click meteobike.sh to start the user interface. Later, we will automate the start-up during the boot process.\nNow the system is ready to be calibrated. Please return the system to our HiWi who will place it for you in the calibration chamber. You are done with the first workshop - congratulations.\nWorkshop 2 - Calibrating the system and finalize the mobile unit\nIn the second practical workshop you will enter the calibration coefficients from our [Sensor-Calibration\/2020\/readme.md](calibration in the weather hut) into your system, then install the system in a protable bike-bag, insert the sensor in a radiation shield and power the system from a battery, so it is mobile.\nEntering the calibration coefficients\nAfter you watched the online lecture on or calibration results, you should enter the calibration coefficients we derived from the intercomparison directly into the python code. Open the file meteobike03.py in the Python 2 editor on the Raspberry Pi Zero W and change the follwing four lines:\n\ttemperature_cal_a1 = 1.00000\n\ttemperature_cal_a0 = 0.00000\n\tvappress_cal_a1 = 1.00000 \n\tvappress_cal_a0 = 0.00000 \n\nReplace the values 1.00000 and 0.00000 for temperature and vapour pressure based on the individual correction coefficients listed in [Sensor-Calibration\/2020\/readme.md](Tables 1 and 3 of the calibration diretory, respecively). Make sure you use a . and not a , as the delimiter.\nAssembly of the protable system\nMaterials needed to complete the assembly of system in this second workshop include:\n\nReflective Tape\nScissors\nSensor Screen\/Radiation Shield\nBag\nGPS\/T&RH Sensor\nVelcro\nScrew & Bolt\nFoam\n\n\nAssembly of the screen (tube)\nTo begin the assembly of the Meteobike system, carefully cut the reflective tape to the length of the plastic tube. Wrap the tube with the tape lengthwise, cut another piece of the same length and repeat this step with minimal overlap of the first piece of tape. The two pieces of tape should cover the entire tube. IN some cases the tape has already been glued on the plastic tube.\nNow that the tube is completely covered with the tape, use the scissors to puncture a hole in the tape where the holes on the tube are located. This is the sensor screen for the temperature and humitidy sensor.\n\nTo connect the temperature and humidity sensor to the radiation shield, you must disconnect the temperature and humidity sensor from the Raspberry Pi, please ensure the sensor is not connected to any source of power.\nYou will use the cirlce hook and loop velcro to attach the sheild and sensor. Place one piece on the inside of the radiaiton shield on the side that has 3 holes. It should be located close to the small hole that is farthest from the large hole. Place the second piece of velcro on the back side of the temperature and humidity sensor.\n\nPass the wires from the sensor through the shield and through the largest hole, then press the sensor to the shield and ensure the velcro will hold the sensor and shield together.\nPlace the shield close to the bag and put the temperature and humidity sensor wires through the large hole in the bag.\nNow you must connect the radiation shield and the sensor to the bag. To do this, you best use a wrench and screwdriver (if available) to insert the bolt and screw through the shields two holes and through the hole that is on the bag. Using the wrench to hold the bolt in place, use the screwdriver to insert the screw into the bolt to hold it secure. Place the\nthin plastic plate with the same holes on the inside of the bag apply the screw through it and the bolt on the inside. You can also tighten it by hand, though.\n\nYou can now reconnect the  the DHT22 sensor physically using the pre-soldered wires to the Raspberry Pi W.\n\n\n\nDHT22 T\/RH Sensor\nCable Color\nRaspberry Pi Zero\n\n\n\n\nPIN 1\nRed Cable\nPIN 1 (3V+)\n\n\nPIN 2\nOrange Cable\nPIN 7 (GPIO4)\n\n\nPIN 3\n(no cable)\n\n\n\nPIN 4\nBrown Cable\nPIN 9 (Ground)\n\n\n\n\nPlease double check to make sure the connection is correct.\nFoam arrangement\nTo ensure the protection of the sensor, a special foam is used. As you can see it is structured into cubical formation that allows you to remove the specific size and pattern you need.\nYou will be given a 20x28 cubical foam sheet, using this you will remove two 7x12 cube pieces, one will be for the base of your sensor and one will be altered to protect the Raspberry Pi system.\nYou should be able to remove 6 different 7x12 sheets from the original 20x28 sheet.\n\n\nWhen sizing the foam for the Raspberry Pi, you will remove the foam cubes from the arrangement found below:\n\nThere is one location in the foam where you must use the scissors to remove only half of the cube. This is where the power cable will be guided and should be faced down in the bag.\nYou will now connect the battery and arrange the foam, battery and sensors to be comfortably situated within the bag.\n\nThe arrangement within the bag will consist of the battery at the base, followed with the unaltered foam, the cable for the battery, the altered foam and the Raspberry Pi within.\n\nPlacement of battery, Raspberry Pi and GPS\nYou must place the Raspberry Pi on top of the altered foam then connect the battery cable to the Raspberry Pi under the altered foam where you cut out the half cubes. This way the Raspberry Pi is not touching the metal surface of the battery (which could lead to shortcuts and ultimately damage).\nThe GPS should be placed into the front pocket. Please make sure the antenna is facing up, this is to ensure a full connection with the satellites and a accurate track recorded.\n\nWhen the system is complete, it should look similar to the image below.\n\nConnecting the Raspberry Pi with your Smartphone\nOnce the system is set up similar to what is arranged above, you can optionally connect your mobile device to the VNC viewer in order to see the progress as you are collecting your data. If you do not have a mobile device, you can skip this step. Next week, we will anyway install an e-Paper.\nYou could place your mobile device in the front pocket behind the GPS.\n\nIn a first step, enable your phone to host a Personal Hotspot. Although you do not need to access the Internet and you will not use any of your data plan capacity, this is required in order to build a network over WiFi to communicate between the Raspberry and your Phone. However, make sure you do not browse the web or download any files while connected to your Personal Hotspot (otherwise charges will apply to your data plan). Also make sure you use a personal, not the course password to protect your connection.\n \nHere is a description (in German) how to enable a personal hotsopt on your iOS smartphone\nHere is a description (in German) how to enable a personal hotsopt on your Android smartphone\nIn both cases, you will now have a WiFi network enabled, and you can connect to the network from the Raspberry Pi Zero.\nBoot the Raspberry Pi Zero, and then change the WiFi network to your Personal Hotspot WiFi name:\n\nEnter your password when promted:\n\nThen read the IP number (hover over the WiFi symbol in the menu bar to see it) e.g. 172.20.10.7 (without the \"\/\", and what comes afterwards).\nGo back to your phone and start the VNC app. In the VNC app create a new connection and enter the local IP number you just read, e.g. 172.20.10.7 (without the \"\/\", and what comes afterwards). When connecting enter the username \"pi\" and the previously set VNC password. You should now be able to control your Raspberry Pi Zero as long as the phone and the raspberry are close together.\nYou can put the phone into the transparent lid of the bag. You can also use the second outlet of the power bank to keep your phone charged during measurements, but in this case, you must bring your own charger-cable.\nNow you are ready to install the system on your bike. Let's go for a test drive. Make sure the indicator changes from red to yellow, as soon as you are outdoors. The recording will only start if you have a good GPS connection. Drive for about 15 - 20 minutes, and come back to see if the data has been recorded.\nDisplay and analyze the recorded GPS track\nThe GPS track is stored by the Raspberry on the desktop as a comma-separated file.\nIf the Raspberry is on the same WLAN as the host computer, then you can easily establish an FTP connection and copy this file to the host (for example with the free CyberDuck or the free FileZilla). You can also use the VNC software to tranfer files.\nA first graphical representation of the track can be done place on the website http:\/\/www.gpsvisualizer.com\/map_input\nAt top left choose \"With: 1400\", then at the top right under \"Upload\" choose your file  and Click on Draw the map.\nColor-coded drawing by temperature: Under \"Track options\" click on \"advanced options\" and make the following settings below:\nColorize by: custom field\nCustom colorization field: temperature\nSpectrum direction: down\nHue 1: 120\nHue 2: 0\n\nThen click on Draw the map. Here is an example\n\nThere are also option to export it into Google Earth.\nWorkshop 3 - Installing an E-Paper display and feedback buttons\nIn this workshop we will finalize the Meteobike by adding an E-Paper display with responsive buttons, so the instrument is independent of any computer or smartphone.\nAn E-Paper uses an imaging display technology called  \"microencapsulated electrophoretic display\" (MED). An E-paper displays patterns by reflecting the ambient light, so it has no background light. This is similar to an e-Reader, it requires little power is readable with full sunlight but also slow to update.\nWiring the e-Paper\nWe are using the Wireframe 2.7inch e-Paper Hat hat that can display black and red color with a resolution of 176 x 264 pixels. Here is how your screen should look like from the back:\n\nFirst, turn off your Raspberry Pi W Zero and disconnect the power cable. There are 8 different wires ready to be connected to your Raspberry Pi as follows:\nPlug the white plastic connection to the back\n\n\n\nE-Paper\nCable Color\nRaspberry Pi Zero\n\n\n\n\nVCC\nGrey Cable\nPIN 17 (3.3V)\n\n\nGND\nBrown Cable\nPIN 20 (Ground)\n\n\nDIN\nBlue Cable\nPIN 19 (GPIO10)\n\n\nCLK\nYellow Cable\nPIN 23 (GPIO11)\n\n\nCS\nOrange Cable\nPIN 24 (GPIO8)\n\n\nDC\nGreen Cable\nPIN 22 (GPIO25)\n\n\nRST\nWhite Cable\nPIN 11 (GPIO17)\n\n\nBUSY\nPurple Cable\nPIN 18 (GPIO24)\n\n\n\nOn the Raspberry Pi W Zero you connect the wires exactly according to this drawing:\n\nPlease doble-check before re-powering and starting the Raspberry Pi W Zero. The connections should look like on this photo:\n\nProgramming and testing the e-Paper\nIf you have double-checked the connection cable, boot up (i.e. re-power) the Raspberry Pi W Zero and connect to it via VNC or alternatively through a screen \/ keyboard \/ mouse.\nInstallation of required libraries\nOpen the LXTerminal and enter the following commands - updating the Python 2 environment and downloading the required libraries. Make sure the Raspberry Pi Zero W has a connection to the internet to download the drivers.\n$ sudo apt-get update\n$ sudo apt-get install python-pip\n$ sudo apt-get install python-pil\n$ sudo apt-get install python-numpy\n$ sudo pip install RPi.GPIO\n$ sudo pip install spidev\n\nNext, download the python e-Paper library from waveshare and its examples:\n$ sudo git clone https:\/\/github.com\/waveshare\/e-Paper\n\nThis will place the e-Paper software into home\/pi\/e-Paper\/ on your Raspberry Pi.\nTest the e-Paper\nGo to the directory to run a factory test:\n$ cd e-Paper\/RaspberryPi\\&JetsonNano\/python\/examples\/\n$ python epd_2in7b_test.py\n\nIf you connected the e-Paper correctly, you should now see a number of fancy tests and visualisations on the e-Paper in black and red.\nFor experts - Further details on the set-up and programming can be found on the [Wireframe webpage] (https:\/\/www.waveshare.com\/wiki\/2.7inch_e-Paper_HAT) under the \"Hardware \/ Software setup\" section.\nUpdate the Meteobike program to the e-Paper version\nFrom now on, you will use the e-Paper version of the Meteobike program called meteobike_epaper.py which can be found here. For students of the University of Freiburg, the python script is also available under Ilias here.\nPlace the file meteobike_epaper.py on the Raspberry Pi's desktop. Open the file and change on lines 41 - 46 the system-specific information (your Meteobike No, your name, and again your calibration coefficients)\nraspberryid = \"52\" # enter your raspberry's number\nstudentname = \"Andreas\" # enter your first name - no spaces and no special characters\ntemperature_cal_a1 = 1.00000 # enter the calibration coefficient slope for temperature\ntemperature_cal_a0 = 0.00000 # enter the calibration coefficient offset for temperature\nvappress_cal_a1 = 1.00000 # enter the calibration coefficient slope for vapour pressure\nvappress_cal_a0 = 0.00000 # enter the calibration coefficient offset for vapour pressure\n\nYou can start the e-Paper version of Meteobike by typing the following command into LXTerminal:\n$ python ~\/Desktop\/meteobike_epaper.py \n\nIn meteobike_epaper.py there is no on-screen window anymore, so you do not see anything on-screen happening, but the program should display all its output on the e-Paper instead:\n\nFirst, the ePaper will display a welcome screen (\"Boot screen\", left), with instructions on how to use the keys below the screen (we will install them next, they do not yet work). After about 10 seconds the e-Paper will refresh and display the latest data (\"Measurement screen\", right). It will refresh every 5 measurements (about every 40 seconds). The arrows next to the measurement values will indicate if a variable is increasing, is unchanged or decreasing. Any information displayed in red will show alerts (for example if the GPS has not found enough satellites yet or if there is no WiFi network).\nNext change the meteobike.sh script to point to meteobike_epaper.py instead of meteobike03.py, so at every start-up of the Raspberry Pi W Zero, the e-Paper version is started instead of the old version.\n\nMake sure the file meteobike.sh has the permissions set (done previously), so it can run:\n$ chmod +x  ~\/Desktop\/meteobike.sh\n\nAs an new feature, meteobike_epaper.py will only write one file per day. If a file already exists for a given date, data will be appended to it. The file will be written to the desktop. there is also a new column called \"speed\" where from the GPS  and the time between measurements the actual speed of the system will be calculated.\nEnabling Keys\nFinally, we will add three feedback buttons as follows:\n\nIf you press Key 1 then the program should pause\nIf you press Key 2 then the program should resume\nIf you press Key 4 then the program should exit\n\nNote Key 3 is currently not assigned to any function.\nTo connect the three keys, you need a 3-wire cable (1 x blue, 1 x green, 1 x yellow) as follows:\n\nConnect the wires as shown in the drawing below:\n\nThe connections should look similar to the following photos:\n\nWhen you are using an e-Paper screen, you can put in in the top flap behind the transparent protection alongside the GPS. There is no need for using a mobile device anymore.\n\nMake sure the GPS does not move under the e-Paper. Also ensure the GPS and e-Paper do not touch their connectors (which could cause a short-cut). You can use tape to tie the cables and GPS in place.\nWell done - you are ready for measurements. Please test the system as follows:\n\nIf you can press Key 4 to exit the program and then reboot\nIf it automatically reboots  measurements if you take power off\nIf it fits your bike\nCan you see data and GPS while you measure?\nIt it records properly data by riding around the block.\n\nAlso make sure you charge the battery in the end for the group exercise to come.\nWorkshop 4 - Detailed analysis in a geographic information system\nYou can use the free and open-source Geographic Information System (GIS) QGIS to perform advanced geographical analysis, including statistics on specific areas of the track or rasterization of many Meteobike traces.\nCheck out the separate page on Visualizing Meteobike data wit QGIS...\n\n\n","272":"Environmental Data Science\nCourse Syllabus\nCourse Summary\nThis course will provide an introduction to the principles of\nenvironmental physics and their application to ecological sciences, with\na focus on programming and data analysis in Python. Course activities\nwill use data analysis to quantify environmental patterns and processes.\nEmphasis will be placed developing coding skills in Python and applying\nthese skills to environmental and biophysical problems.\nCourse Goals\n\n\nTo develop expertise in the Python programming language and the use\nof Python's data science stack to effectively store, manipulate, and\ngain insight into environmental data.\n\n\nTo be able to apply this understanding to characterize data on\nenvironmental patterns and processes at varying spatial and temporal\nscales.\n\n\nTo use data to model environmental processes of energy and mass\ntransfer.\n\n\nCourse Format\nStudents will learn the principles of Python programming and\nenvironmental data science by working largely independently on weekly\ncourse materials conducted in Python. Readings will be assigned for both\nprogramming and disciplinary content related to weekly themes. At least\nonce a week, we will meet as a group to introduce and discuss concepts.\nIn addition, students will have the opportunity to conduct weekly\none-on-one check-ins with the instructional team.\nHow to use this repository.\nIf you are a student in G136:\n\n\nLogin to the G136 JupyterHub Server.\n\n\nOur server is located at https:\/\/g136.lsit.ucsb.edu\/\n\n\nOur server is running JupyterLab, which is an interactive environment for executing python code. Here are a couple of tutorials that introduce JupyterLab:\n\nA Quick Intro (3 minutes)\nA Full Tutorial (25 minutes)\n\n\n\n\n\nClone this repository to your server instance.\n\n\nOpen a Terminal in your JupyterLab instance. (Instructions)\n\n\nType git clone and the the url for this repository, which is https:\/\/github.com\/environmental-data-science\/envdatasci.git.\nThe entire command will look like this:\njovyan@jupyter-USERNAME:~$ git clone https:\/\/github.com\/environmental-data-science\/envdatasci\nNote: In the line above, the jovyan@jupyter-USERNAME:~$ is your terminal prompt, where USERNAME is your ucsb id. On other systems, the command prompt is something like >, or $. To keep these directions more general, I will just use $ to represent the command prompt throughout our docs. The key point is that you don't need to type this as part of the command.\n\n\nPress Enter. A local clone of the class repository will be created in your JupyterLab instance.\n $ git clone https:\/\/github.com\/environmental-data-science\/envdatasci\n > Cloning into envdatasci...\n > remote: Counting objects: 10, done.\n > remote: Compressing objects: 100% (8\/8), done.\n > remove: Total 10 (delta 1), reused 10 (delta 1)\n > Unpacking objects: 100% (10\/10), done.\n\nYou will now have a new local directory in your instance called envdatasci\/, which contains all of the course materials. Before proceeding, we need to make sure that your instance has all the necessary python libraries that the course materials require. We will use a python installation utility called pip to update your instance with the required libraries.\n\n\n\n\nUse pip to install required libraries.\n\n\nIn your open terminal, change directory into the newly-created envdatasci folder.\n$ cd envdatasci\n\n\nThere is a text file called requirements.txt in this folder. You page through this file using the more command.\n$ more requirements.txt\n\n\nThe file contains a list of python modules. We will be using these various modules in the course, and so we need to make sure they are installed in your JupyterLab instance. This is easy to do with the pip command:\n$ pip install -r requirements.txt\n\n\nType the above command and press Enter. You will see a ton of output as the pip command reads each line of the requirements.txt file, determines what library (and library version) is on each line, and then installs the specific version of that library if is needed. The command also tracks down any dependencies that each new library might require and installs those too.\nNote: Most of the libraries in requirements.txt should already be installed, in which case pip will report back Requirement already satisfied for almost every line.\n\n\n\n\nLocal Installation (for Instructors or non-students)\n\n\nInstall Conda & Git.\n\n\nMac OS: Use homebrew\n$ brew install anaconda\n$ brew install git\n\n\nWindows: ??\n\n\nLinux: Use homebrew??\n\n\n\n\nCreate a conda environment.\n$ conda create -n envdatasci python=3.7.3\nNote: We are using python version 3.7.3 in this class. That may change in the future, but for now it matches the python that LSIT is using in their docker images that they use to build JupyterHub deployments.\n\n\nActivate the conda envrionment\n$ conda activate envdatasci\n\n\nInstall pip into the local conda environment.\n$ conda install pip\n\n\nClone the repository to your local machine and cd into the class repo directory\n$ git clone https:\/\/github.com\/environmental-data-science\/envdatasci\n$ cd envdatasci\n\n\nAdd additional libaries to your conda environment using pip.\n$ pip install -r requirements.txt\nNote: We are using pip to manage dependencies within this conda environment. The use of pip and the requirements.txt file ensures consistency with our insallations on the JupyterHub server. This allows us to make sure that the working environment on our local machines matches exactly the working environment on JupyterHub.\nNote: If you add a package to your local environment that is used in any of the course materials, you must use pip freeze > requirements.txt and push the new commit to our repo.\n\n\n","273":"BayeScEnv\nWarning !! The version v1.0 of BayeScEnv had 2 critical bugs. If you were using this version, please update for the v1.1 or later!\nBayeScEnv is a Fst-based, genome-scan method that uses environmental variables to detect local adaptation.\nDocumentation\nFor documentation and instructions, please see our Wiki. If anything is unclear in the Wiki section, please do not hesitate to contact and notify us.\nDownload\nTo download the program, please go to the Release page and download the latest release as a ZIP or TAR\/GZ file.\nIssues\nIf you encounter an issue when using the software, please report it here.\n","274":"\nUrbsville: An Urbanode Odyssey\nUrbsville is the core implementation of the Urbanode project, its goal is world\ndomination by taking control over physical objects and handing the steering\nwheel to web and system developers.\nDesigned around Node.js, Urbsville benefits from sharing nearly all of its\nserver-side code with the client-side, blurring the lines of reality itself.\n\nBasic Usage\nFor those of you who prefer to see code up front, this section is for you, else\nskip on down to the Architecture heading.\n\nThe Default Server\nIf you were to look inside bin\/urbsville you would see something that looks\nsimilar to:\n\/\/ Our main container, it will be named \"Hub\/hub\"\nvar hub = new urb.Hub('hub');\n\n\/\/ Log all hub events to stdout\nhub.on('event', function (event) { console.log(event); });\n\n\/\/ Run an API Server named \"ApiServer\/sio\" using the Socket-IO protocol\nvar sioApiProtocol = new sioServer.SioServerProtocol(8001);\nvar sioApiServer = new api.ApiServer('sio', sioApiProtocol, hub);\n\n\/\/ Run a Device Server named \"DeviceServer\/sio\" using the Socket-IO protocol\nvar sioDeviceProtocol = new sioServer.SioServerProtocol(8002);\nvar sioDeviceServer = new device.DeviceServer('sio', sioDeviceProtocol, hub);\n\n\/\/ Announce our web server via mDNS\n\/\/ NOTE(termie): this currently expects nginx to serve the static content\nvar ad = mdns.createAdvertisement('urbanode-web', 8000);\n\nsioApiServer.listen();\nsioDeviceServer.listen();\nad.start();\n\nMost of those lines are fairly self explanatory, running this leaves you with\nan empty hub waiting for devices to connect to the Device Server at which point\nthey will be accessible via an API Server. It also announces its location on\nthe network.\n\nA Basic API Client\nThe most common client of Urbsville is probably a Socket-IO API client being\naccessed via a web page (one that shows a totally sweet interface for\nexercising your dominance over the physical realm).\nUrbsville makes significant use of Dojo Toolkit for Javascripty stuff, but if\nyou are a jQuery person you should be able to mostly ignore that as they play\ntogether.\nUsing the directory structure in the project you'll end up with:\n<script src=\"\/public\/dojo\/dojo.js\"><\/script>\n<script src=\"\/public\/js\/socket.io.js\"><\/script>\n<script>io.setPath('\/public\/js\/');<\/script>\n<script src=\"\/public\/js\/urb.js\"><\/script>\n<script>\n\n\/\/ \"require\" emulates the Node.js require function using Dojo\nvar sioClient = require('urb\/protocol\/sioClient');\nvar api = require('urb\/api');\n\nvar hostname = window.location.hostname;\n\nvar protocol = new sioClient.sioClient.SioClientProtocol(\n  hostname, {port: 8001}\n);\n\nvar client = new api.ApiClient('admin', protocol);\n\nfunction newDevice(device) {\n  \/\/ do something cool with the device, hook it up to some ui\n}\n\nclient.on('hubAdded', function (hub) {\n  var devices = hub.devices();\n  for (var d in devices) {\n    newDevice(devices[d]);\n  }\n  hub.on('deviceAdded', function (device) {\n    newDevice(device);\n  });\n});\n\n\/\/ or $(document).ready(...) for jQuery types\ndojo.addOnLoad(function () { clent.connect() });\n<\/script>\n\nThis sets up an API client using the Socket-IO protocol and demonstrates the\nbasic events one should be handling to generate your UI.\n\nSo I Have A Device, Now What?\nDevices have a very simple API, they act as EventEmitters in the Node.js sense\nand they are basically just a set of modifiable properties.\nSuppose you had a Device that represents a basic colored light and you wanted\nto make the background of some element change whenever the light's color\nchanges:\nvar light = new ColoredLightDevice('ambientRoom');\n\nfunction setBackgroundColor() { ... }\n\n\/\/ listen for changes to the rgb property\nlight.on('property\/rgb', function (newRgb) {\n  setBackgroundColor(newRgb);\n});\n\n\/\/ change the rgb property\nlight.set('rgb', [255, 200, 100]);\n\nOther types of devices might be event-only, like a sensor, but they operate the\nsame way:\nvar reader = new RfidDevice('badgeReader');\n\nreader.on('rfidAdded', function (rfidObject) {\n  \/\/ do something flashy\n});\n\nAnd they can be easily hooked together to form all sorts of wonderful things:\nreader.on('rfidAdded', function (rfidObject) {\n  light.set('rgb', [255, 0, 0]);\n});\n\nreader.on('rfidRemoved', function (rfidObject) {\n  light.set('rgb', [0, 0, 0]);\n}\n\n\nArchitecture\nUrbsville is designed to allow a few styles of interactions: self-contained,\ndevice control and device publishing. While going through those we'll expand\nthe components of the system and how they relate to each style of interaction.\n\nBeing Self-Contained\nWith Devices and Hubs, Urbsville has enough to operate as a self-contained\ndevice controller, meaning it doesn't provide any interfaces to interact with\nthe system it just listens for events from Devices and responds accordingly\nallowing the developer to script their environment with Javascript.\nFor many simple art installations this is as far as you need go.\n\nThe Device\nIt's why we're all here. A Device represents the basic abstract building block\nfor manipulating objects in Urbsville. Whichever path you go down to the actual\nphysical object, be it talking to a serial port, over a proprietary network\nprotocol or even via http, the Device is the interface that physical object is\nproviding to the world through properties and events.\nDevices, like pretty much everything else in Urbsville are EventEmitters,\nnormal interaction with them involves listening for named events and setting\nproperties that trigger changes that trigger events.\nSee \"So I Have A Device, Now What?\" above for an example.\n\nThe Hub\nA Hub is also an EventEmitter, its main purpose is to keep track of Devices.\nHubs also provide a way to interact with all the Devices tracked by it in\naggregate by forwarding events emitted by them to its own listeners.\nCommon practice is to have just one Hub to track all of your Devices.\n\nBeing A Device Controller\nThe goal of a device controller is to provide an interface to allow a remote\ncontroller (usually a user) to actively manipulate the Devices tracked by a\nHub. Using the ApiServer on the server-side wrapping a Hub and the ApiClient\non the client-side providing a Proxy this is readily accomplished over any\ngiven transport protocol.\n\nThe API Server\nThe ApiServer is the Hub's main face to the world, it provides an interface for\nremotely interacting with the Devices tracked by a Hub via a transport\nprotocol, e.g. Socket-IO or TCP.\nClients connecting to the ApiServer will initially be given the current state\nof the system as a serialized dump of the Hub and its Devices, thereafter any\nevents from the Hub or its Devices will be passed along to the client.\n\nThe API Client\nThe ApiClient creates a local representation of a Hub and the Devices being\nprovided via the ApiServer over a transport protocol and allows them to be\ninteracted with via proxy instances.\n\nThe Proxy\nThere are actually two types of Proxy, DeviceProxy and HubProxy, but they are\neffectively the same, both are simply intended to act exactly like their\nnon-proxy counterpart but to forward write actions across a network boundary\nand to replay events received over that boundary.\nProxies are built behind the scenes by, for example, the ApiClient once it\nreceives the information about a Hub and its Devices from the server. From\nthen on information originating from the Device or Hub being proxied will be\nreplayed for listeners on the client side and any properties being set on the\nclient side will result in an RPC to actually set it on the server side.\n\nBeing A Device Publisher\nHere's where things twist around a bit. The goal of a device publisher is to\nallow remote devices to publish themselves via a local Hub which may in turn\nallow other activities to control them. This is accomplished by the DeviceServer\nproxying devices provided by a DeviceClient.\nBeing both a Device Controller and Device Publisher presents many opportunities\nfor organic environment monitoring and control.\n\nThe Device Server\nThe DeviceServer allows remote devices to be tracked by the local Hub via a\ntransport protocol.\nClients connecting to the DeviceServer are expected to provide a serialized\nDevice at which point a DeviceProxy will be built by the DeviceServer and added\nto the Hub. As with all proxies, events generated by the original device (this\ntime on the client side) will be replayed by the local proxy and actions taken\nwill result in RPCs.\n\nThe Device Client\nThe DeviceClient wraps a local Device and provides it to a server via a\ntransport protocol.\n\nBuilding \/ Running\nUrbsville relies on a decent number of external tools and libraries, some stuff\nyou will need:\n\n\nNode 2.3+ http:\/\/nodejs.org\/\na standard build environment (make, gcc, that sort of stuff)\nTo use the provided nginx config for the demo, you will need nginx http:\/\/nginx.org\/\nTo use the DMX utilities you'll need OLAD http:\/\/www.opendmx.net\/index.php\/Open_Lighting_Architecture\n\n\nIf everything is in order, cloning the repo and running make should get you\nset up.\n\nTODO\nThere is a ton of stuff to do to make Urbsville fitter, happier and more\nproductive. Here's a short list:\n\n\nMake it installable (maybe npm?)\nCommand-line arguments for the urbsville script.\nmDNS-enabled DeviceClient example (to automatically provide a device to\nany DeviceServers on the network)\nMore services advertised over mDNS.\nStatic file serving with Node for simple demos and small projects.\nMore device types.\nMore specific device implementations.\nDefault html representations of devices.\n\n\n","275":"ospPython\nospPython is a no hassle work around to everyone who is having issues with\nsetting up the environmental variables for python. Simply copy the ospPython.exe\nand ospPython.exe.config files from the \"ospPython Release\" folder to your\n\"C:\\Windows\\System32\" folder. Start a new command prompt and type ospPython\nto start a python shell. Python scripts can be run using ospPython [pathTo.py].\nInstillation\n\nDownload the repository\nCopy both ospPython.exe and ospPython.exe.config from the \"ospPython Release\" folder to your\n\"C:\\Windows\\System32\" folder.\nChange the \"pythonPath\" attribute in the ospPython.exe.config to point to your python.exe.\nUse the ospPython command from the command line\n\nLicence\nGNU General Public License, version 3 (GPL-3.0)\nThe user assumes all responsibilities for how this program, its source files, related files, and configuration\nfiles are used. By using this software the user agrees to assume all responsibility for any liabilities,\ndamages, or misuse of this software. The author of this software is not responsible for how this software is used\nor for any results occurring from running this software. Software and program, as used used in this agreement, is defined as\nany source file, configuration file, binary file, or other related file\/resource that is included in this repository or\ncreated as a result of downloading or using this repository.\n","276":"-environemental-modelling.github.io\nEnvironmental modelling courses for RUDN\n","277":"\nREADME.md\nThis repository aims to document the Carceral Ecology project, that is being developed by Professor Nicholas Shapiro, UCLA, and Professor Lindsay Poirier, UCD.\nIncarcerated people are on the frontlines of environmental injustice. This systematic exposure of, at a minimum, tens of thousands of incarcerated individuals results from mass incarceration\u2019s close ties with declining, but very much ongoing, industrialism. Often built atop the brownfields of former manufacturing facilities or mines or on the cheap land next to operating facilities, prisons serve as a \u201crecession-proof\u201d employer to those laid off in deindustrialization beginning in the 1970s. This project seeks to assess the environmental hazards of mass incarceration on a national scale.\nThis project has three main arms:\n\nEnvrionmental monitoring\nItterative study design with stakeholders\nData analysis of datasets that may cast light on the environmental conditions of prisons, jail, and detention centers.\n\nIt is the third compenent, and spesifically work related to ECHO data, is what we will be working on in this repo. We are managing our work flow through the issues function. Thats probably the best place to start contributing.\nProtocols\nSee our protocols for this project here.\nHow to Contribute\n\nExisting issues:\n\nReview this repo's issue queue (and particularly the issues labeled \"Help Wanted\") for opportunities to contribute to open questions and ongoing tasks.\nAssign yourself to issues you are contributing to so that the group knows who to contact in regards to the issue.\nComment on issues with relevant ideas or resources.\nMark your progress on issues in this repo's project board.\n\n\nNew issues\n\nFile a new issue via this repo's issue queue, asking a question, documenting a bug, or suggesting a direction for further research and development.\nAssign yourself or others to issues so that the group knows who to contact in regards to the issue.\nSelect Labels to note whether the issue is a question, bug, or a suggested enhancement. Select the \"Help Wanted\" label to signal that you are looking for collaborators on the issue.\nIf the issue contributes to a project or milestone, be sure to add this label.\nMark your progress on issues in this repo's project board.\n\n\nWhen contributing code, please be sure to:\n\nFork this repository, modify the code (changing only one thing at a time), and then issue a pull request for each change.\nFollow the project's coding style (using K&R-style indentation and bracketing, commenting above each feature, and using snake case for variables).\nTest your code locally before issuing a pull request (not sure how to do this? here's how).\nClearly state the purpose of your change in the description field for each commit.\nAfter your first pull request is approved, please add yourself to the contributors list in the README as is appropriate.\n\n\n\nCode of Conduct\nFor any questions on decorum please see our Code of Conduct.\nContributors\n\n\n\nContributions\nName\n\n\n\n\n\ud83d\udd22 \ud83d\udccb \ud83e\udd14\nNick Shapiro\n\n\n\ud83d\udd22 \ud83d\udccb \ud83e\udd14\nLindsay Poirier\n\n\n\ud83d\udd22 \ud83d\udccb \ud83e\udd14\nMelissa Chimwaza\n\n\n\ud83d\udd22\nKelly Salinas\n\n\n\ud83d\udd22 \ud83e\udd14\nNathan Tran\n\n\n\ud83d\udd22 \ud83d\udccb \ud83e\udd14\nSarah Tan\n\n\n\ud83d\udd22 \ud83d\udcc6 \ud83e\udd14\nRamya Natarajan\n\n\n\ud83d\udcbb \ud83d\ude87 \ud83e\udd14\nBen Millam\n\n\n\ud83d\udd22 \ud83e\udd14\nDerek Sportsman\n\n\n\ud83d\udd22\nIvy Molina\n\n\n\ud83d\udd22\nSavannah Ramirez\n\n\n\ud83d\udd22\nPrasann Ranade\n\n\n\ud83d\udd22\nAlice Lu\n\n\n\ud83d\udd22\nRaymond Ko\n\n\n\n(For a key to the contribution emoji or more info on this format, check out \u201cAll Contributors.\u201d)\nLicense & Copyright\n Carceral Ecologies documentation in this repository is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. See the LICENSE file for details.\n","278":"\nrems 0.5.2\n\n\n\n\n\nOverview\nAn R package to download, import, and\nfilter data from B.C.\u2019s Environmental Monitoring System\n(EMS)\ninto R.\nThe package pulls data from the B.C. Data Catalogue EMS\nResults,\nwhich is licenced under the Open Government Licence - British\nColumbia.\nInstallation\nThe package is not available on CRAN, but can be installed using the\ndevtools package:\n# install.packages(\"devtools\") # if not already installed\n\nlibrary(devtools)\ninstall_github(\"bcgov\/rems\")\n\nUsage\nNOTE: If you are using Windows, you must be running the 64-bit\nversion of R, as the 32-bit version cannot handle the size of the EMS\ndata. In RStudio, click on Tools -> Global Options and ensure the 64\nbit version is chosen in the R version box.\nYou can use the get_ems_data() function to get last two years of data\n(you can also specify which = \"4yr\" to get the last four years of\ndata):\nlibrary(rems)\ntwo_year <- get_ems_data(which = \"2yr\", ask = FALSE)\n#> Downloading latest '2yr' EMS data from BC Data Catalogue (url: https:\/\/pub.data.gov.bc.ca\/datasets\/949f2233-9612-4b06-92a9-903e817da659\/ems_sample_results_current_expanded.csv)\n#> Reading data from file...\n#> Caching data on disk...\n#> Loading data...\nnrow(two_year)\n#> [1] 1497503\nhead(two_year)\n#> # A tibble: 6 x 23\n#>   EMS_ID MONITORING_LOCA\u2026 LATITUDE LONGITUDE LOCATION_TYPE COLLECTION_START   \n#>   <chr>  <chr>               <dbl>     <dbl> <chr>         <dttm>             \n#> 1 01215\u2026 ENGLISHMAN RIVE\u2026     49.3     -124. RIVER,STREAM\u2026 2019-01-07 09:00:00\n#> 2 01215\u2026 ENGLISHMAN RIVE\u2026     49.3     -124. RIVER,STREAM\u2026 2019-01-07 09:00:00\n#> 3 01215\u2026 ENGLISHMAN RIVE\u2026     49.3     -124. RIVER,STREAM\u2026 2019-01-07 09:00:00\n#> 4 01215\u2026 ENGLISHMAN RIVE\u2026     49.3     -124. RIVER,STREAM\u2026 2019-01-07 09:00:00\n#> 5 01215\u2026 ENGLISHMAN RIVE\u2026     49.3     -124. RIVER,STREAM\u2026 2019-01-07 09:00:00\n#> 6 01215\u2026 ENGLISHMAN RIVE\u2026     49.3     -124. RIVER,STREAM\u2026 2019-01-07 09:00:00\n#> # \u2026 with 17 more variables: LOCATION_PURPOSE <chr>, PERMIT <chr>,\n#> #   SAMPLE_CLASS <chr>, SAMPLE_STATE <chr>, SAMPLE_DESCRIPTOR <chr>,\n#> #   PARAMETER_CODE <chr>, PARAMETER <chr>, ANALYTICAL_METHOD_CODE <chr>,\n#> #   ANALYTICAL_METHOD <chr>, RESULT_LETTER <chr>, RESULT <dbl>, UNIT <chr>,\n#> #   METHOD_DETECTION_LIMIT <dbl>, MDL_UNIT <chr>, QA_INDEX_CODE <chr>,\n#> #   UPPER_DEPTH <dbl>, LOWER_DEPTH <dbl>\n\nBy default, get_ems_data imports only a subset of columns that are\nuseful for water quality analysis. This is controlled by the cols\nargument, which has a default value of \"wq\". This can be set to\n\"all\" to download all of the columns, or a character vector of column\nnames (see ?get_ems_data for details).\nYou can filter the data to just get the records you want:\nfiltered_2yr <- filter_ems_data(two_year, emsid = c(\"0121580\", \"0126400\"),\n  parameter = c(\"Aluminum Total\", \"Cadmium Total\",\n    \"Copper Total\", \" Zinc Total\",\n    \"Turbidity\"),\n  from_date = \"2011\/02\/06\",\n  to_date = \"2015\/12\/31\")\n#> Warning: `filter_()` is deprecated as of dplyr 0.7.0.\n#> Please use `filter()` instead.\n#> See vignette('programming') for more help\n#> This warning is displayed once every 8 hours.\n#> Call `lifecycle::last_warnings()` to see where this warning was generated.\n\nYou can also get the entire historic dataset, which has records back to\n1964. This needs to be done in two steps:\n\nFirst download the dataset using download_historic_data, which\ndownloads the data and stores it in a SQLite database:\n\ndownload_historic_data(ask = FALSE)\n\n\nNext, read in the historic data, supplying constraints to only\nimport the records you want:\n\nfiltered_historic <- read_historic_data(emsid = c(\"0121580\", \"0126400\"),\n  parameter = c(\"Aluminum Total\", \"Cadmium Total\",\n    \"Copper Total\", \" Zinc Total\",\n    \"Turbidity\"),\n  from_date = \"2001\/02\/05\",\n  to_date = \"2011\/12\/31\",\n  check_db = FALSE)\n\nYou can also query the sqlite database using dplyr, which ultimately\ngives you more flexibility than using read_historic_data:\nFirst, attach the database to your R session. This creates an object\nwhich behaves like a data frame, which you can query with dplyr. The\nadvantage is that the computation is done in the database rather than\nimporting all of the records into R (which would likely be impossible).\nlibrary(dplyr)\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\nhist_db <- attach_historic_data()\n#> Warning: `src_sqlite()` is deprecated as of dplyr 1.0.0.\n#> Please use `tbl()` directly with a database connection\n#> This warning is displayed once every 8 hours.\n#> Call `lifecycle::last_warnings()` to see where this warning was generated.\n\nYou can then query this object with dplyr:\nfiltered_historic2 <- hist_db %>%\n  select(EMS_ID, PARAMETER, COLLECTION_START, RESULT) %>%\n  filter(EMS_ID %in% c(\"0121580\", \"0126400\"),\n    PARAMETER %in% c(\"Aluminum Total\", \"Cadmium Total\",\n      \"Copper Total\", \" Zinc Total\",\n      \"Turbidity\"))\n\nFinally, to get the results into your R session as a regular data frame,\nyou must collect() it. Note that date\/times are stored in the SQLite\ndatabase as integers, so you must convert them back to POSIXct. There\nis a shortcut function to do this: ems_posix_numeric:\nfiltered_historic2 <- collect(filtered_historic2) %>%\n  mutate(COLLECTION_START = ems_posix_numeric(COLLECTION_START))\nglimpse(filtered_historic2)\n#> Rows: 5,444\n#> Columns: 4\n#> $ EMS_ID           <chr> \"0121580\", \"0121580\", \"0121580\", \"0121580\", \"0121580\u2026\n#> $ PARAMETER        <chr> \"Cadmium Total\", \"Copper Total\", \"Copper Total\", \"Tu\u2026\n#> $ COLLECTION_START <dttm> 2003-08-26 08:15:00, 2003-10-27 11:55:00, 2004-11-0\u2026\n#> $ RESULT           <dbl> 1.00e-05, 9.30e-04, 1.12e-03, 8.40e-01, 3.00e-01, 4.\u2026\n\nYou can combine the previously imported historic and two_year data sets\nusing bind_ems_data:\nall_data <- bind_ems_data(filtered_2yr, filtered_historic)\nnrow(all_data)\n#> [1] 2481\n\nFor more advanced filtering, selecting, and summarizing, I recommend\nusing the dplyr package.\nThen you can plot your data with ggplot2:\nlibrary(ggplot2)\n\nggplot(all_data, aes(x = COLLECTION_START, y = RESULT)) +\n  geom_point() +\n  facet_grid(PARAMETER ~ EMS_ID, scales = \"free_y\")\n\n\nWhen the data are downloaded from the B.C. Data Catalogue, they are\ncached so that you don\u2019t have to download it every time you want to use\nit. If there is newer data available in the Catalogue, you will be\nprompted the next time you use get_ems_data or\ndownload_historic_data.\nIf you want to remove the cached data, use the function\nremove_data_cache. You can remove all the data, or just the\n\u201chistoric\u201d, \u201c2yr\u201d, or \u201c4yr\u201d:\nremove_data_cache(\"2yr\")\n#> Removing 2yr data from your local cache...\n\nDeveloping\nReleasing a new version\nAs of version 0.5.0 the historic data will be provided as a sqlite\ndatabase attached to the GitHub release, as such the release workflow is\nas follows:\n\nCreate a \u2018draft\u2019 release on GitHub with the new version number\nRun the script inst\/create_historic_sqlite.R\nUpload ems_historic.sqlite.zip to the draft release\nEdit release to create full release.\n\nUpdating ems_historic.sqlite without releasing a new version of rems:\n\nRun the script inst\/create_historic_sqlite.R\nUpload ems_historic.sqlite.zip to the latest release, overwriting\nthe old file\n\nProject Status\nUnder development, but stable. Unlikely to break or change\nsubstantially.\nGetting Help or Reporting an Issue\nTo report bugs\/issues\/feature requests, please file an\nissue.\nHow to Contribute\nIf you would like to contribute to the package, please see our\nCONTRIBUTING guidelines.\nPlease note that this project is released with a Contributor Code of\nConduct. By participating in this project you agree\nto abide by its terms.\nLicense\nCopyright 2016 Province of British Columbia\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at \n\n   http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nThis repository is maintained by Environmental Reporting\nBC.\nClick here for a\ncomplete list of our repositories on GitHub.\n","279":"Radi.Cards\n\nNFT eCards for greater fun and greater good. All income goes to charities working to promote Internet freedom and environmental rights. \n\n\n\n\n \n\n\n\nAuthors\n\nD1Labs\nKnownOrigin.io\n\nFeatures\n\nFull ERC-721 Compatibility - Smart Contract is fully ERC-721 compliant\nFull ERC-721 Metadata Compatibility - Each ERC-721 token uses latest standards for ERC-721 metadata\nFull ERC-165 Compatibility - Smart Contract is fully ERC-165 compliant\nIPFS Support - Internally IPFS is used for storing asset files and metadata\n\nSetup\nAdd a local mnemonic.js at the root with your testnet mnemonic (used for deployments)\nThe mnemonic.js should be like so:\nmodule.exports = 'dog alley hunt pen away brew matter frog rural salad educate kebab';\nInstall dependencies:\nnpm install\nStart VueJs Front End:\nnpm run start\nRun Smart Contract tests:\nnpm run test\nFirebase Deployment\n\n\nEnsure you have access to the firebase project radi-cards\n\n\nInstall firebase tools npm install -g firebase-tools\n\n\nYou may need to login and authenticate yourself if you have not done this before\n\nRun this firebase login and follow the instructions\n\n\n\nRun the script .\/firebase_deploy.sh - this will push your current working project to live so be careful\n\n\nFirebase deployment configuration can be found in .\/firebase.json\n\n\nLicense\nMIT\n","280":"Riverstone\nRiverstone is a small Spark Photon that I am building out as an environment sensor. It will soon monitor air quality, environment toxicity, and temperature.\nDevices\n\nHypnos - Particle Photon Wi-Fi board\nPoseidon - Particle Argon Wi-Fi \/ Mesh Gateway\nHades - Particle Xenon Mesh Endpoint\nNemesis - Particle Xenon Mesh Endpoint\n\nTodo\n\nScreen enabled\nTodo: configure CO, Alcohol, and VOC gas sensor\nTodo: configure Digital Temperature and Humidity measure sensor\nTodo: configure Dust sensor\nTodo: configure Solar Panel\n\n\n","281":"  ____   ____    _    ____  _____                          _      _     \n |  _ \\ \/ ___|  \/ \\  \/ ___|| ____|     _ __ ___   ___   __| | ___| |___ \n | | | | |     \/ _ \\ \\___ \\|  _| _____| '_ ` _ \\ \/ _ \\ \/ _` |\/ _ \\ \/ __|\n | |_| | |___ \/ ___ \\ ___) | |__|_____| | | | | | (_) | (_| |  __\/ \\__ \\\n |____\/ \\____\/_\/   \\_\\____\/|_____|    |_| |_| |_|\\___\/ \\__,_|\\___|_|___\/\n                                                                       \n\n\n\nDCASE-models is an open-source Python library for rapid prototyping of environmental sound analysis systems, with an emphasis on deep\u2013learning models. The library has a flat and light design that allows easy extension and integration with other existing tools.\nDocumentation\nSee https:\/\/dcase-models.readthedocs.io for a complete reference manual and introductory tutorials.\nInstallation instructions\nWe recommend to install DCASE-models in a dedicated virtual environment. For instance, using anaconda:\nconda create -n dcase python=3.6\nconda activate dcase\n\nFor GPU support:\nconda install cudatoolkit cudnn\n\nDCASE-models uses SoX for functions related to the datasets. You can install it in your conda environment by:\nconda install -c conda-forge sox\n\nBefore installing the library, you must install only one of the Tensorflow variants: CPU-only or GPU.\npip install \"tensorflow<1.14\" # for CPU-only version\npip install \"tensorflow-gpu<1.14\" # for GPU version\n\nThen to install the package:\npip install DCASE-models\n\nTo include visualization related dependencies, run the following instead:\npip install DCASE-models[visualization]\n\nUsage\nThere are several ways to use this library. In this repository, we accompany the library with three types of examples.\n\nNote that the default parameters for each model, dataset and feature representation, are stored in parameters.json on the root directory.\n\nPython scripts\nThe folder scripts includes python scripts for data downloading, feature extraction, model training and testing, and fine-tuning. These examples show how to use DCASE-models within a python script.\nJupyter notebooks\nThe folder notebooks includes a list of notebooks that replicate scientific experiments using DCASE-models.\nWeb applications\nThe folder visualization includes a user interface to define, train and visualize the models defined in this library.\nGo to DCASE-models folder and run:\npython -m visualization.index\n\nThen, open your browser and navigate to:\nhttp:\/\/localhost:8050\/\n\n","282":"Data-driven_Building_simulation_Polimi_EETBS\nIn this repository, you can find the files, notebooks, and the related dataset of the lessons on Data-driven building behaviour prediction and simulation which have been offered in the context of \"Energy and Environmental Technologies for Building System\" course at Politecnico di Milano (Energy Eng. Program)\nRegarding the first case, the scripts  are a simplified version of a part of implementations that my M.Sc student Manoj Manivannan had developed in his thesis project. The dataset which is employed in this project is the AC consumption data of a residential Building in Austin Texas. The complete results of this study can be found in this paper.\nThe dsetata corresponding to only one building is provided in this repository (considering the Pecan St. Inc' license agreement); in order to have access to the device consumption of several buildings provided by Pecan Street, you should create an account(free for Academic use) on DataPort.\nThe second case (classification of commercial buildings -- in progress) is a simplified version of the notebooks provided by Clayton Miller in This Repository. The results of this work has been published in their recent paper and his PhD thesis. The employed dataset is the Building data Genome Project which is an open dataset provided by their group which includes hourly whole building electrical meter data for one year from 507 non-residential buildings. You can find more detailed infomration in the provided links or the Buds lab's website\n","283":"Data-driven_Building_simulation_Polimi_EETBS\nIn this repository, you can find the files, notebooks, and the related dataset of the lessons on Data-driven building behaviour prediction and simulation which have been offered in the context of \"Energy and Environmental Technologies for Building System\" course at Politecnico di Milano (Energy Eng. Program)\nRegarding the first case, the scripts  are a simplified version of a part of implementations that my M.Sc student Manoj Manivannan had developed in his thesis project. The dataset which is employed in this project is the AC consumption data of a residential Building in Austin Texas. The complete results of this study can be found in this paper.\nThe dsetata corresponding to only one building is provided in this repository (considering the Pecan St. Inc' license agreement); in order to have access to the device consumption of several buildings provided by Pecan Street, you should create an account(free for Academic use) on DataPort.\nThe second case (classification of commercial buildings -- in progress) is a simplified version of the notebooks provided by Clayton Miller in This Repository. The results of this work has been published in their recent paper and his PhD thesis. The employed dataset is the Building data Genome Project which is an open dataset provided by their group which includes hourly whole building electrical meter data for one year from 507 non-residential buildings. You can find more detailed infomration in the provided links or the Buds lab's website\n","284":"Wind Database version 2 (WinDB2)\nOverview\nWinDB2 is a geospatial database and a suite of associated utilities to store geodata in a flexible manner. This code is a work in progress and a partial rewrite of the original WinDB software that Mike Dvorak used for his PhD research in offshore wind resource assessment at Stanford University. The database schema is written for PostgreSQL\/PostGIS. The plotting, analysis, and utility scripts were written in Java, BASH, and Python. The currently implementation, WinDB2 is completely written in Python and PostgreSQL\/PostGIS only.\nCurrent Status\nAs of 2016-06-13, the basic functionality from WinDB1 has been reimplmented using only Postgresql\/PostGIS and Python 3.x, with backwards compatability for Python 2.7.\nDemo\nWinDB2 is current driving the entire backend of the sailing-wind forecasting site Sail Tactics. You an see an example interactive forecast of the forecast output for San Francisco.\nBy using WinDB(1) and WinDB2 on on the Sail Tactics website, it has been possible to keep all 200-m resolution WRF forecast for San Francisco Bay since February 2014 online in a single Amazon RDS PostgreSQL database, queryable on a moments notice.\nVolunteers Wanted\nThe project is seeking volunteers to extend, test, document this code, and document use cases.\nQuick Start\nCreating a new WinDB2\nDependencies\nInstall the following libraries (or similar versions, depending on your operating system):\n\npostegresql-9.5\npostgresql-9.5-postgis-2.2\npython3-psycopg2\npython3-tz\npython3-numpy\n\nAdd the WinDB2 bin to your PATH\nTo run the WinDB2 scripts, all you need to do is add the WinDB2 bin directory to your path. The WinDB2 Python scripts take care of adding the appropriate locations to the PYTHONPATH automatically.\n...\/windb2 $ export PATH=$PWD\/bin:$PATH\nMake sure you don't have conflicting libraries in your PYTHONPATH, which will cause errors when you attempt to execute the scripts. You can easily verify there are no import errors by running interpolate-wrf-file.py without commands. If there are no import errors, you should see instructions printed on the screen about how to use the command. If you have errors trying to run a WinDB2 script, try running unset PYTHONPATH first.\nRunning the create-windb2.py script\nThis assumes that you have a working PostgreSQL 9.x database setup on your system and that you have already created a Postgres user with superuser privileges.\n...\/windb2 $ export $PATH=$PWD\/bin\n\n$ create-windb2.py \nusage: create-windb2.py [-h] [-p PORT] dbhost dbuser dbname\ncreate-windb2.py: error: the following arguments are required: dbhost, dbuser, dbname\n\/data\/pycharm-workspace\/windb2\/schema\/bin $ .\/create-wind-db.sh localhost postgres test-windb2-1 \n\n$ create-windb2.py localhost testuser windb2-testdb-1\nOpening connection using dns: dbname=windb2-testdb-1 host=localhost user=testuser port=5432\ndatabase \"windb2-testdb-1\" does not exist... trying to create it\nsuccessfully created database \"windb2-testdb-1\"\nOpening connection using dns: dbname=windb2-testdb-1 host=localhost user=testuser port=5432\nEncoding for this connection is UTF8\nSuccessfully created your WinDB2. Enjoy!\n...\nIf this command completes without any errors, you will have successfully created an empty WinDB2.\nPostgres authentication\nThe WinDB2 commands require that you have automatic Postgres authentication set up in your account either via a ~\/.pgpass file (preferred) or using the PGUSER and PGPASS environment variables. This way, you never have to type in your password to connect to your WinDB2 nor do you have to leave your password in an unsecured file. Refer to this Postgres documentation on how to set up your ~\/.pgpass file. Once you have successfully set up your Postgres authentication, you should be able to run the command psql -h localhost -U postgres test-windb2-1 or similar without having to enter a password.\nInterpolating WRF wrfout files\nWinDB2 is set up to accept meteorological variables at height above ground level. Because WRF native coordinates are on eta levels, WRF files need to be height-interpolated before inserting them into WinDB2.\nSetting up a configuration file\nYou need a configuration file named windb2-wrf.conf in your WRF directory containing the wrfout file to interpolate and insert the file into a WinDB2. You can find an example of this file in ...\/config\/. This config file states which heights are to be interpolated and inserted. Currently, only the UV (wind) variable is supported. Support for temperature, pressure, and air density is coming soon.\nRunning the interpolation command\nCreating height interpolated files is easy:\n\nSet up your windb2-wrf.conf file as described above. Make sure there is a copy of this file in your directory containing the WRF out files.\nInterpolate the wrfout file(s) using \/tmp\/windb2-example $ interpolate-wrf-file.py wrfout_d01\n\nInserting into the WinDB2\nIn order to configure your WinDB2 with your new WRF domain(s), you have to run a one-time command to set up a new WinDB2 domain. Use the insert-windb2-file.py command with the -n flag to create a new domain in the WinDB2.\n\/tmp\/windb2-example $ insert-windb2-file.py -n localhost postgres test-windb2-1 wrfout_d01_2016-02-14_00\nOpening connection using dns: dbname=test-windb2-1 host=localhost user=postgres port=5432\n...\nProcessing time:  2016-02-14T00:00:00.000Z\nInserted 9216, 10.0 height x,y wind points at 837.8181818181819 I\/s\nInserted 9216, 60.0 height x,y wind points at 418.90909090909093 I\/s\nThis command created a new WinDB2 domain #1 and inserted the wind fields at the 10 and 60 m height from this wrfout file for one time.\nThe ncfile argument is again a wildcard. Note that sometimes Unix\/Linux filenames that contain colons (e.g. WRF files like wrfout_d01_2016-02-14_00:00:00) can get messed up with the shell trying to escape these colons. If you have problems with wrfout files not being found, try using fewer characters in the WRF filename (e.g. wrfout_d01) and let the wildcard functionality in Python script find the filenames.\nYou can verify the interpolated file was created with the ls -ltr command, which should show file(s) named wrfout_d01_*-height-interp.nc.\nWe can verify that WinDB2 domain was created inside the PostgreSQL database by inspecting the domain table:\n$ psql -U postgres test-windb2-1\npsql (9.3.10)\nType \"help\" for help.\n\ntest-windb2-1=# SELECT * FROM domain;\n key |             name              | resolution | units | datasource | mask \n-----+-------------------------------+------------+-------+------------+------\n   1 |  OUTPUT FROM WRF V3.6.1 MODEL |       3000 | m     | WRF        | \n(1 row)\nWe can also see that a table names wind_1 contains all of the wind speed and direction data from the WRF file:\n domainkey | geomkey |           t            | height |  speed   | direction \n-----------+---------+------------------------+--------+----------+-----------\n         1 |       1 | 2016-02-14 00:00:00+00 |     10 |  11.0395 |       336\n         1 |      97 | 2016-02-14 00:00:00+00 |     10 |  11.0583 |       336\n         1 |     193 | 2016-02-14 00:00:00+00 |     10 |   11.086 |       336\n         1 |     289 | 2016-02-14 00:00:00+00 |     10 |  11.1183 |       336\n         1 |     385 | 2016-02-14 00:00:00+00 |     10 |  11.1517 |       336\n         1 |     481 | 2016-02-14 00:00:00+00 |     10 |   11.186 |       336\n         1 |     577 | 2016-02-14 00:00:00+00 |     10 |  11.2256 |       336\n         1 |     673 | 2016-02-14 00:00:00+00 |     10 |  11.2668 |       336\n         1 |     769 | 2016-02-14 00:00:00+00 |     10 |  11.3011 |       336\n         1 |     865 | 2016-02-14 00:00:00+00 |     10 |  11.3215 |       335\n         1 |     961 | 2016-02-14 00:00:00+00 |     10 |  11.3265 |       335\n         1 |    1057 | 2016-02-14 00:00:00+00 |     10 |  11.3272 |       335\n         1 |    1153 | 2016-02-14 00:00:00+00 |     10 |  11.3346 |       335\n         1 |    1249 | 2016-02-14 00:00:00+00 |     10 |  11.3562 |       335\n...\nMore WRF domains can be created in the WinDB2 by issuing the same command. Although it is not a requirement, it makes sense to keep the WinDB2 domain numbers consistent with the WRF domain numbers.\nSupported Models\nMost of the functionality of WinDB(1) was directed at the NCAR's Weather Research and Forecasting Model (WRF). The original WinDB code aimed to rapidly post-process and validate WRF wind fields. The new version aims to be an extensible database for both atmospheric and ocean models.\nLicense\nThis code is licensed under the Gnu Public License version 3 (GPL3). You can read the license in the LICENSE.md file in the root directory of this repository.\n","285":"Enfin Environmental Finance Service\n\nOverview\nThis is an Environmental Finance service that allows individuals to track their carbon footprint. The Enfin team is redefining individuals' methods towards watching their impact on the environment. Using estimations based on the current environmental research, every dollar spent can be mapped to an environmental impact.\nHistory\nEnfin was founded while at the Impact Labs Fellowship. The fellowship is designed for passionate and motivated students to come to together and combine computer science and social good, learning to create the humanitarian software development. The founders had a strong idea regarding the effects individuals can have on Climate Change, and Enfin highlights this belief.\n","286":"Environmental Materials\nThis repo is for issues and localizations.\nFormatting Issues:\nFor Bugs\nTitle:\nBUG: + General Name\/Description of bug\n\nComments Section:\nValkyrieLib Version: \nEnvironmental Materials Version: \nDescription of bug: \nModpack Name: \nHow to reproduce bug: \n\nFor Feature Requests\nTitle:\nFR: + General Name\/Description of feature\n\nComments Section:\nDescription of the feature and how it works\n\n","287":"ESC-50\nClassifiers for the Environmental Sound Classification dataset.\nDirectory Structure\n\/\t\t\t\t(root directory where you want to store data)\n|--audio\/ \t\t\t(contains all 2000 recordings)\n|--category_target.pkl\t\t(Category target dictionary)\n|--pickled\/\t\t\t(Contains pickled dataset after using utils.pickle_dataset())\t\n|--model\/\n\t|--fold1\/\t\t(Contains model trained with fold 1 as validation set. Also has log file of the training process.)\n\t|--fold2\/\n\t|--fold3\/\n\t|--fold4\/\n\t|--fold5\/\n\nEach fold folder has a log.csv file storing training log and weights_best.hdf5 storing trained model's weights.\nSteps to run -\n\nGet the audio files from ESC-50 github. https:\/\/github.com\/karoldvl\/ESC-50.git\nRun pickle_dataset from utils.py. It will compute the features for each clip and store them\nThen run train from main.py for each fold.\nRun evaluate from main.py to evaluate the models.\n\nSource Code -\n\nclip.py - contains class Clip for audio clip. Features such as Phase encoded Mel Filterbank Energies (PEFBEs) and Filterbank Energies (FBEs) are extracted here.\nmodel.py - contains Model class which makes the CNN model's architechture.\nmain.py - contains the functions to train,predict and evaluate the model.\nutils.py - contains functions for saving and loading the dataset.\n\n","288":"user setup & guide\ngithub repository\n(https:\/\/github.com\/previnw\/EnvironmentalAnalysisSoftware)\nwebsite\n(https:\/\/go-environment.herokuapp.com\/) \nsoftware information\ncode structure\n--------------\nfront-end: \n\n  python3.7\n  flask microframework\n  skeleton boilerplate\n  html & css\n  javascript\n  jQuery\n\nback-end:\n\n  sqlite3\n  python\n  json\n\nsetup\/build instructions\n------------------------\n1. clone repo & cd to the correct directory\n\n  pc\/mac command to clone: git clone https:\/\/github.com\/previnw\/EnvironmentalAnalysisSoftware.git\n\n2. setup python\n\n  install python3 or higher (python3.7 recommended) using: https:\/\/www.python.org\/downloads\/\n  \n  pc command to ensure python3 or higher is running: python\n  mac command to ensure python3 or higher is running: python -V\n\n  *** if pip doesn't work follow this guide: https:\/\/pip.pypa.io\/en\/stable\/installing\/\n\n3. activate virtual environment\n  \n  pc command: venvwin\\Scripts\\activate\n  mac command: . venv\/bin\/activate\n\n  *** if there are virtual environment issues follow this guide: http:\/\/flask.pocoo.org\/docs\/1.0\/installation\/#virtual-environments\n\n4. install flask\n\n  follow this installation guide: http:\/\/flask.pocoo.org\/docs\/1.0\/installation\/#install-flask\n\n5. install additional libraries\n\n  pc\/mac commands: pip install Flask-WTF\n                   pip install WTForms\n\n6. run app w\/ local web server (2 ways)\n  \n  1st way:\n     \n    pc\/mac command: python main.py\n  \n  2nd way: \n    \n    pc commands: set FLASK_APP=main.py \n                 set FLASK_ENV=development\n                 flask run\n                 \n    mac commands: export FLASK_APP=main.py\n                  export FLASK_DEBUG=1\n                  flask run\n\n7. to see website\n\t\n  open your internet browser\n  web address: http:\/\/localhost:5000\/\n\n8. to stop web server\n\n  pc\/mac command: ctrl-c\n\n9. to deactivate virtual environment\n\n  pc\/mac command: deactivate\n\nhardware information\n\ncode structure\n--------------\nC++\nArduino Libraries\n\n\nhardware\n--------\narduino mega 2560\nesp8266 nodemcu wifi module\n6 different sensors\n\n\nsetup\/build instructions\n------------------------\n1. hardware\n\n  hook up the sensor as is shown in the diagram in the report and use the that is stored within the github.\n\n2. nodemcu wifi module\n\n  the wifi module is setup to connect to the webapp already and just needs to be connected as is shown in the diagram\n\n3. arduino\n\n  if you want to push new code to the arduino, the sensor libraries must be added to your ide through the manage libraries tool.  simply search the sensor names and press the install button\n  <Adafruit_BMP085.h>\n  <SoftwareSerial.h>\n  <Adafruit_Sensor.h>\n\n","289":"2017 \u5609\u7fa9\u9ed1\u86b5\u677e \u74b0\u5883\u6c61\u67d3\u7d44\n\u968a\u540d\uff1a\u5929\u5927\u5730\u5927\u53f0\u79d1\u5927\n\u968a\u54e1\uff1a\u5f35\u7d61\u921e\u3001\u6797\u7547\u52ad\u3001 \u90ed\u4e5d\u4e00\u3001  \u9673\u74bf\u5b87\n\u554f\u984c\uff1a\u5982\u4f55\u89e3\u6c7a\u6a5f\u8eca\u904e\u91cf\u5e36\u4f86\u7684\u74b0\u5883\u554f\u984c\uff1f\n\n\u6a5f\u8eca\u6578\u91cf\u73fe\u968e\u6bb5\u7121\u6cd5\u5b8c\u5168\u6539\u8b8a\uff0c\u5982\u4f55\u6709\u6548\u7ba1\u6cbb\u624d\u662f\u554f\u984c\uff01\n\n\n\u73fe\u884c\u7684\u6cd5\u898f\u96d6\u7136\u898f\u7bc4\u6a5f\u8eca\u51fa\u5ee0\u6eff\u4e94\u5e74\u5f8c\u6bcf\u5e74\u61c9\u63a5\u53d7\u6392\u6c23\u6aa2\u9a57\u4e00\u6b21\uff0c\u4f46\u5f88\u591a\u653f\u5e9c\u7684\u7d71\u8a08\u6578\u64da\u90fd\u986f\u793a\u76ee\u524d\u7684\u6aa2\u9a57\u7387\u53ea\u670930\uff05~40\uff05\u4e4b\u9593\uff0c\u9019\u4ee3\u8868\u653f\u5e9c\u73fe\u884c\u7684\u65b9\u6cd5\u7121\u6cd5\u6709\u6548\u5730\u63a7\u7ba1\u9f90\u5927\u7684\u6a5f\u8eca\u6240\u884d\u751f\u7684\u6c61\u67d3\uff0c\u56e0\u6b64\u6211\u5011\u6c7a\u5b9a\u64f4\u5927\u6c11\u773e\u7684\u76e3\u7763\u529b\u91cf\uff0c\u81ea\u5df1\u7684\u6c61\u67d3\u554f\u984c\u81ea\u5df1\u89e3\u6c7a\uff01\u5c07\u65e2\u6709\u7684\u6aa2\u8209\u7cfb\u7d71\u6578\u4f4d\u5316\u3001\u96f2\u7aef\u5316\uff0c\u5efa\u7acb\u4e00\u5957\u5b8c\u6574\u4e26\u4e14\u53ef\u57f7\u884c\u7684\u8a08\u756b\uff0c\u8b93\u8cc7\u6e90\u66f4\u6709\u6548\u7387\u5730\u5206\u914d\u3002\n\n\u5b8c\u6574\u8a08\u756b\n\u6211\u5011\u69cb\u60f3\u4e00\u500b\u5b8c\u6574\u7684\u8a08\u756b\uff0c\u6b64\u8a08\u756b\u5206\u70ba\u4e09\u500b\u968e\u6bb5\uff0c\u9010\u6b65\u5728\u6aa2\u9a57\u6548\u7387\u4e0a\u505a\u8cc7\u6e90\u6700\u6709\u6548\u904b\u7528\uff01\n\u7b2c\u4e00\u968e\u6bb5. \u5efa\u7acb\u6578\u4f4d\u5316\u5e73\u53f0\uff1a\u63d0\u9ad8\u6e9d\u901a\u6548\u7387\n\u7b2c\u4e8c\u968e\u6bb5. \u6c11\u773e\u53c3\u8207\u8fa8\u5225\u70cf\u8cca\u8eca\uff1a\u8cc7\u6e90\u914d\u7f6e\u6548\u7387\u5316\n\u7b2c\u4e09\u968e\u6bb5. \u5efa\u7acb\u81ea\u52d5\u5316\u70cf\u8cca\u8eca\u8fa8\u8b58\u7cfb\u7d71\uff1a\u964d\u4f4e\u4eba\u529b\u6210\u672c\n\u7b2c\u4e00\u968e\u6bb5 \u6578\u4f4d\u5316\u5e73\u53f0\u67b6\u69cb\n\n\u7b2c\u4e8c\u968e\u6bb5 \u6578\u4f4d\u5316\u5e73\u53f0\u67b6\u69cb\n\n\u7b2c\u4e09\u968e\u6bb5 \u6578\u4f4d\u5316\u5e73\u53f0\u67b6\u69cb\n\n\u6700\u5c0f\u53ef\u884c\u6027 demo\n\u6b64\u8a08\u756b\u4e2d\uff0c\u6211\u5011\u67b6\u8a2d\u96f2\u7aef\u4f3a\u670d\u5668\uff0c\u5728\u624b\u6a5fapp\u7aef\u53ef\u4ee5\u4e0a\u50b3\u6aa2\u8209\u8cc7\u6599\u4ee5\u53ca\u7167\u7247\u81f3\u8cc7\u6599\u5eab\u4e2d\uff0c\u6211\u4e5f\u53ef\u900f\u904e\u653f\u5e9c\u7684\u6aa2\u9a57\u7ad9\u8cc7\u6599\uff0c\u63d0\u4f9b\u88ab\u6aa2\u8209\u4eba\u5730\u5716\u6aa2\u8996\u7684\u529f\u80fd\u3002\n\n\n\n\u767b\u5165\u756b\u9762\n\n\u4e3b\u9801\u9762\n\n\u6aa2\u8209\u9801\u9762\n\n\u6aa2\u9a57\u7ad9\u5730\u5716\u8cc7\u8a0a\n\n\n\n\n\n\n\n\n\n\n\n\u4f7f\u7528\u7684\u8cc7\u6599\n\n\u653f\u5e9c\u958b\u653e\u5e73\u53f0 \n\n\nhttp:\/\/data.gov.tw\/node\/14208\nhttp:\/\/data.gov.tw\/node\/35726\nhttp:\/\/data.gov.tw\/node\/42225\n\n\n\u884c\u653f\u9662\u74b0\u5883\u4fdd\u8b77\u7f72\n\n\nhttps:\/\/erdb.epa.gov.tw\/DataRepository\/ReportAndStatistics\/StatSceMotors.aspx\n\n","290":"Rate My Plate\nIdentify the environmental impact of food.\nDeveloped for the CSSBristol Boeing Hackathon.\nOverview\nTweet an image of food to our account, and we recognise the food and tweets back the environmental impact of that food.\n\nIcons designed by Madebyoliver from Flaticon\nDevelopment Setup\nDependancies\n\nInstall Python version: 3.5 (required for tensorflow)\nInstall Pip\nMake sure pip is updated pip install --upgrade pip\n\nSetup\n\nClone repo git clone https:\/\/github.com\/harrymt\/boeing-hackathon.git\nNavigate to the directory cd boeing-hackathon\nRun pip install -r requirements.txt to install all Python dependancies\nSetup the Database python db_setup.py\nRun the web server locally by running python application.py\n\nAPI Credentials\n\nCreate your own file 'credentials.py' with a consumer_key, consumer_secret, access_token, and access_token_secret, which you can generate via the Twitter Application Management (https:\/\/apps.twitter.com)\n\n# credentials.py\n\nconsumer_key = ''\nconsumer_secret = ''\naccess_token = ''\naccess_token_secret = ''\nServer Side Extra Setup\nClone the Repo\n\ngit clone https:\/\/github.com\/harrymt\/boeing-hackathon.git\nThen git pull whenever there are changes\n\nSetup a Cron Job\n\ncrontab -e to show the list of cron jobs.\nThen add * * * * * python twitterbot.py to the cronfile.\nThen add crontab -l to check and see if it worked\n\nSetup a GitHook\n\nCreate a pull.php file with 1 line, <?php exec('cd boeing-hackathon && git pull'); ?>\n\nTechnologies used\n\nPython\nFlask\nTweepy\nTensorFlow\nBit.ly\nLeaflet\nWord Net\nMat Plot Lib\nHosted on AWS\n\n","291":"La COOL Board\n\nWhat is La COOL Board?\nLa COOL Board is a connected environmental monitoring and control board. It can be used to build custom weather stations, self-watering plants, hydroponic control systems, pH probes, and many other things. It's also extensible and compatible with numerous external sensors and actuators.\nKey features and benefits\n\n100% Arduino compatible\nSupported by an Espressif's ESP8266, including onboard WiFi\n7 onboard sensors: IR and visible light, UV index, atmospheric pressure, humidity, temperature, soil moisture.\nOnboard RTC Clock\nUSB to serial UART with onboard FTDI chip (female micro-USB port)\nNeoPixel Digital RGB programmable LED\nSolar panel and LiPo battery plug\nFully makeable, hackable and customizable open-hardware\n\nHow to make it?\nHave a look at our Eagle files - but you can also buy it from us! Don't hesitate to contact or check out our website\nWhat is this repository for?\nIt contains a set of Arduino libraries, wrappers and sketches that simplify the access to and usage of the sensors and other hardware features provided by La COOL Board.\nHow does it operates?\nThe default operating mode of La COOL Board is sleep mode, which uses the deep-sleep low-energy consumption mode of the ESP8266 (80\u00b5A). It is on by default and should be enabled whenever your board:\n\nruns on battery power (e.g. in a weather station)\nruns on AC power, but logs data at a very slow rate. It's time to do you part in saving the planet!\n\nIf you need a higher sample rate, you may want to deactivate it.\nWhen in sleep mode, your COOL Board will run the following loop:\n\nread sensors values\nactivate actuators\nlog data (either locally or over the network)\ncheck for updates\ngo to sleep for logInterval seconds\n\nHow can I contribute?\nFor minor fixes of code and documentation, please go ahead and submit a pull request.\nLarger changes (rewriting parts of existing code from scratch, adding new functions to the core, adding new libraries)\nshould generally be discussed by opening an issue first.\nFeature branches with lots of small commits (especially titled \"oops\", \"fix typo\", \"forgot to add file\", etc.) should be squashed before opening a pull request.\nAt the same time, please refrain from putting multiple unrelated changes into a single pull request.\nHow can I reach you guys?\nIf you encounter a problem, have some genius, crazy idea or just want to have a chat with us, please open an issue, a pull request or send us an email at team@lacool.co - we'd absolutely love to hear from you !\nHow do I get set up?\nFirst steps\n\n\nInstall Platform IO core\n\n\nBreak out the sensor board and insert its pins into the main board header\n\n\nConnect the COOL Board to your computer and ensure you that your switch is in the LOAD position\n\n\nOn a terminal, enter\n git clone https:\/\/github.com\/LaCoolCo\/LaCOOLBoard.git`\n cd LaCoolBoard`\n patch\/patch.sh`\n\n\n\nGo to [www.lecool.menu], create an account and choose Join us\n\n\nContact La COOL Co via mail (team@lacool.co) to ask for your certificate and private keys. We'll provide you with two files :\u00a0privateKey.bin\u00a0and\u00a0certificate.bin\n\nSave\u00a0privateKey.bin\u00a0in\u00a0examples\/WeatherStation\/data\/privateKey.bin\nSave\u00a0cerificate.bin\u00a0in examples\/weatherStation\/data\/certificate.bin\n\n\n\nIn your terminal, type\n pio run -e prod -t uploadfs`\n\n\n\nHit the\u00a0RESET\u00a0switch, then type\n pio run -e prod -t upload`\n\n\n\nPut the side switch back in\u00a0RUN\u00a0position & press the\u00a0RESET\u00a0button\n\n\nAfter a few seconds, you COOL Board LED should glow purple to signal that the onboard Wifi access point has started. You'll now need to:\n\n\nconnect your computer (or phone\/tablet) to the Wifi network named CoolBoard-XXXXXXXXXXXX\n\n\nopen\u00a0http:\/\/192.168.4.1 in your browser.\n\n\nclick configure Wifi\n\n\nSelect the Wifi network you want your board to connect to and enter its password\n\n\nConfiguration files\nThe COOL Board embedded software makes heavy use of the SPIFFS for storing its configuration and data files. Here is a description of the configuration files and keys.\ncoolBoardConfig.json\n\nlogInterval: time interval in seconds between two log events.\nireneActive: set this to true if you are using the IRN3000 module\njetpackActive: set this to true if you are using the JetPack module\nexternalSensorsActive: set to true if you are using a supported external sensor\nsleepActive: set to true if you want your COOL Board to enable sleep mode\nuserActive: set this to true if you want your COOL Board to collect userData (userName, macAddress, timeStamp)\nmanual: set this to true to enable MQTT remote-control of onboard actuators, bypassing rule-based configuration. Be extremely careful with this mode: when it is active, the COOL Board will not restart automatically to apply any new configuration sent on the update MQTT topic. Plus, restarting a COOL Board in manual mode will disable all the actuators. Thus, never forget to reset this to false to go back to normal mode!\n\ncoolBoardLedConfig.json\n\nledActive: Put this flag to 1(true) if you want to turn on the onboard LED.\n\ncoolBoardSensorsConfig.json\n\ntemperature: set this to true if you want to sample temperature using the BME280 Sensor\nhumidity: set this to true if you want to sample air humidity using the BME280 Sensor\npressure: set this to true if you want to collect atmospheric pressure using the BME280 Sensor\nvisible: set this to true if you want to collect the visible light index using the SI114X Sensor\nir: set this to true if you want to measure the infrared light using the SI114X Sensor\nuv: set this to true if you want to measure ultraviolet index using the SI114X Sensor\nvbat: set this to true if you want to measure battery voltage\nsoilMoisture: set this to true if you want to activate the soil moisture sensor\nwallMoisture: set this to true if you want to use the moisture sensor for wall\/wood moisture sensing. soilMoisture MUST be false in this case\n\nexternalSensorsConfig.json\n\nsensorsNumber: the number of supported external sensors you connect to the COOL Board\nreference: the reference of a supported external sensor (e.g. NDIR_I2C, Dallas Temperature...)\ntype: the type of measurment you are taking (e.g. CO2, temperature, voltage...)\naddress: the sensor's address, if it has one (e.g. NDIR_I2C CO2 sensor's address is 77)\nkind0...kind4: names of the sensors sensor connected to ADCs models ADS1015 and ADS1115 (kind0 is sensor on A0, kind1 is A1, and so on)\n\nirene3000Config.json\n\nwaterTemp.active: set to true to use the temperature sensor connected to the Irene3000\nphProbe.active: set to true to use the ph sensor connected to the Irene3000\nadc2.active: set to true to use the extra ADC input of the Irene3000\nadc2.gain: this is the value of the gain applied to the extra ADC input of the Irene3000\nadc2.type: the type of measurements you are making (e.g. CO2, temperature,voltage...)\n\njetPackConfig.json and coolBoardActorConfig.json\n\nAct[i].actif: set this to true in order to use the jetpack output #i (0 to 7)\nAct[i].inverted: set this to true if the actor is inverted (e.g. a cooler is turned on when Temp > TempMax)\nAct[i].temporal: set this to true if you want the actor to turn on or off based on time of day.\nAct[i].type: [ <primaryType>, <secondaryType> ]: this array contains the primary type and the secondary type of the actuator\n\nprimaryType : type of the sensor (e.g. if Temperature, actuator is associated to the \"Temperature\" sensor).\nsecondaryType is only used in temporal mode. It can be:\n\n\"\" (empty): the actor will be on for timeHigh ms and off for timeLow ms\n\"hour\": the actor will be on when current hour is greater than or equal to hourHigh. and off when greater than or equal to hourLow.\n\"minute\": the actor will be on when the current minute is greater than or equal to minuteHigh, and off when greater than or equal to minuteLow\n\"hourMinute\": behavior of both \"minute\" and \"hour\"\n\n\n\n\nAct[i].low[rangeLow,timeLow,hourLow,minuteLow]: this array contains the low values of the activation range\n\nrangeLow is the minimum sensor value at which to turn on (or off in inverted mode) the actor\ntimeLow is the time spent off in temporal mode\nhourLow is the hour to turn off the actor when secondaryType is hour or hourMinute\nminuteLow is the minute to turn off the actor when secondaryType is minute or hourMinute\n\n\nAct[i].high[rangeHigh,timeHigh,hourHigh,minuteHigh]: this array contains the high values of the activation range\n\nrangeHigh is the maximum of the range at which to turn off (or on in inverted mode) the actor\ntimeHigh is the time spent on in temporal mode\nhourHigh is the hour to turn on the actor when secondaryType is hour or hourMinute\nminuteHigh is the minute to turn on the actor when secondaryType is minute or hourMinute\n\n\n\nNote that coolBoardActorConfig.json contains only one actor.\nmqttConfig.json\n\nmqttServer: MQTT server IP address or hostname\n\nrtcConfig.json\n\nNTP: set to true if you want the RTC to synchronize with a NTP Pool. Disable this if you don't have an Internet connection!\ntimePool: indicates the NTP Server with the lowest latency in CoolTime.h\ntimeSync: the last time the board updated the RTC (UNIX Time). By default, La COOL Board tries to update once a week.\n\nwifiConfig.json\n\ntimeOut: access point timeout in seconds\n\n","292":"Gwen's awesome green app\nBuilding this app with some ideas of how to increase environmental awareness and show people that everyone can make a difference.\nChecklist of updates:\n\nNeed to create ajax calls to feed in environmental information.\nComplete layouts for tutorials page and information pages.\nBuild out user dashboards.\nPush to heroku.\nAnd much more to come...\n\nMarkdown is fun\ncheatsheet\n","293":"Environmental Health Channel\nThe Environmental Health Channel is an interactive web-based platform for creating and sharing environmental sensing and health data narratives. This data, shared by affected residents and collected by the Environmental Health Project (EHP), includes physical and psychosocial health symptoms, particulate pollution (PM2.5) air measurements, and personal stories from residents. This tool displays this data using visualization and exploratory data analysis techniques. This enables researchers, health professionals, and the public to interactively explore and share compelling scientific evidence of local impacts of oil and gas drilling.\nUsage\nFirst, get a Google Map JavaScript API key, and replace the api key in the folowing line in the \/web\/viz.html file.\n<script src=\"https:\/\/maps.googleapis.com\/maps\/api\/js?key=[YOUR API KEY]\"><\/script>\nThen, obtain the ZCTA5 json file as documented in this project. Then run the following bash commands in the terminal:\ncd [path of the ehp-channel folder]\nmkdir data\ncd data\/\nmkdir geo\ncd geo\/\nmv [path of the ZCTA5 json file] .\nmv [the ZCTA5 json file] zcta5.json\ncd ..\/..\/py\/\npython updateChannelData.py\nThis will create a \"data\" folder in the \"web\" folder for the website. When running the python command, you will need to install all dependencies, see the libraries that I imported in the \"util.py\" file. Because the \"util.py\" file is shared with other projects, there are some libraries that are not used in this project. However, to run the code, please install all of them.\nDeployment\nHere is an example of the apache config file (with https):\n<VirtualHost *:443>\n  ServerName envhealthchannel.org\n  ServerAlias www.envhealthchannel.org\n  SSLEngine on\n  RewriteEngine On\n  RewriteCond %{HTTP_HOST} !^envhealthchannel\\.org [NC]\n  RewriteCond %{HTTP_HOST} !^$\n  RewriteRule ^\/(.*)  http:\/\/envhealthchannel.org\/$1 [L,R=301]\n  Header set Cache-Control \"max-age=0, must-revalidate\"\n  DocumentRoot \/[YOUR_PATH]\/envhealthchannel.org\/www\/web\/\n  <Directory \"\/[YOUR_PATH]\/envhealthchannel.org\">\n    AddOutputFilterByType DEFLATE application\/octet-stream\n    AllowOverride None\n    # Allow listing a directory that doesn't have index.html, and follow symlinks\n    Options Indexes FollowSymLinks\n    Order allow,deny\n    Allow from all\n  <\/Directory>\n  SSLCertificateFile \/etc\/letsencrypt\/live\/envhealthchannel.org\/cert.pem\n  SSLCertificateKeyFile \/etc\/letsencrypt\/live\/envhealthchannel.org\/privkey.pem\n  Include \/etc\/letsencrypt\/options-ssl-apache.conf\n  SSLCertificateChainFile \/etc\/letsencrypt\/live\/envhealthchannel.org\/chain.pem\n<\/VirtualHost>\n\n<VirtualHost *:80>\n  ServerName envhealthchannel.org\n  ServerAlias www.envhealthchannel.org\n  RewriteEngine on\n  RewriteRule ^ https:\/\/%{SERVER_NAME}%{REQUEST_URI} [L,NE,R=permanent]\n<\/VirtualHost>\nTo add https support to the website, please refer to the \"Setup https\" section in the readme of this repository. To periodically update the data on the channel, set a cron job:\ncrontab -e\nThen add the following line to the crontab:\n*\/30 * * * * cd \/[YOUR_PATH]\/envhealthchannel.org\/www\/py; run-one python updateChannelData.py\n","294":"metScanR\nMitigating the \"80\/20 Data Science Dilemma\" in atmospheric \/ environmental sciences\n\n\nSummary\nEvery day thousands of meteorological and environmental data are collected throughout the world. The stations that collect these data are part of many large-, medium-, and small-scale networks throughout the globe.  Some stations are part of multiple networks, have well documented metadata, and their data can be accessed through a handfull of public databases.  Other stations however, have poorly documented metadata and their data are harder to locate and access. The latter makes it difficult and time consuming to answer specific scientific questions (Fig 1).\n\nFIGURE 1 Some metadata are easy to find in many repositories (green box), while other types of metadata are hard to track down (orange box).  This can make searching for environmental monitoring stations of interest painstakingly slow especially if searching for specific criteria.\nInconsistent metadata, documentation, data formats, station names, and station identifiers pose major roadblocks to finding, cleaning, and organizing (collectively known as 'wrangling') meteorological and environmental data among different networks.  This concept is not new.  In fact, many studies have estimated that data 'wrangling' accounts for roughly 80% of data science, allowing data scientists only 20% of their time to actually analyze the data (Forbes (2016); IBM (2017)).\nMitigating the 80\/20 Dilemma:\nWe are pleased to introduce metScanR, an R package that enables users to quickly locate freely available meteorological and environmental data across multiple networks, worldwide. The metScanR package utilizes a continuously growing database (see the metScanR database (DB) section below), that currently contains metadata for 157,676 stations from 219 countries\/territories, worldwide (Fig 2).\n\nFIGURE 2: Plot of all stations within the metScanR database.  Each station is represented by a dot. Station locations are the only items plotted here - no geographical or political boundaries are mapped.  This reveals interesting patterns about environmental station placement, e.g., northern Canada, India, central Australia, etc.\nmetScanR allows a user to search for stations and metadata in a variety of ways via the R functions within the package.  Below is a list of metScanR functions and their use.\nFiltering Functions\nThese functions allow the end-user to filter environmental stations by:\n\nSpecific country - getCountry()\nActive date(s) - getDates()\nStation Elevation - getElevation()\nIdentifier type - getId()\nNearby a Point of Interest (POI) - getNearby()\nNetwork - getNetwork()\nSpecific Station - getStation()\nMeteorological \/ Environmental variables measurered - getVars()\nSpecific US state or territory - getTerritory()\nHybrid search (all of the above) - siteFinder()\n\nUse of any of the above functions will return an R list() object detailing of all meteorological\/environmental stations that meet the search criteria.  Metadata of each station are structured in a standardized format (below) and are returned to the end-user when using the above search functions:\n\n$namez [chr] - Name of the station\n$identifiers [data.frame] - Station identifiers, including idType (i.e., the governing body that supplies the station ID such as the World Meteorological Organization) and the associated id\nplatform [chr] - The primary network or platform that the station belongs to\nelements [data.frame] - The meteorological\/environmental variables measured at the station, includes the start and end dates of active sampling for each variable (if available)\nlocation [data.frame] - Geolocation information, inlcuding lat\/lon, elevation, country, etc., for the site\n\n\nFIGURE 3: Exemplar output of metScanR's getStation() search function for the NRCS SCAN site 2172.  Output from all of metScanR's search functions are structured in this manner.\nMapping Function\nThe metScanR package also comes with a function (mapSiteFinder()) that displays stations from a user-defined search (Figure 4).  When run in R the map is interactive and users can click on stations for more information and\/or toggle different areas by zooming in\/out etc. This is an aesthetic, ancillary feature to compliment the many search functions available within the package.\n\nFIGURE 4: Screenshot example of metScanR's mapSiteFinder() and getNearby() functions.  A total of 803 stations are within 50 km of NEON's NIWO station.  Total run time = 9.2 seconds.\nThe metScanR Database: \nThe current version of the metScanR DB is v2.4.0 and currently contains metadata from 157,676 stations, worldwide. The DB is updated frequently and hosted externally of the metScanR package.  Upon loading the metScanR package via library(metScanR), the DB is accessed via internet connection and installed locally to the user's computer via metScanR's updateDatabase() function.  The provenance of the DB is detailed below:\n\nv1.0.0 2017-01-18 Initial release.  Database was in dataframe format and hosted with the R package.  Database comprised ~13,000 sites from the US and parts of Canada.\nv2.0.0 2017-05-18 Major release.  Database converted to list format with content (below). Database contains 106,933 stations from around the world and is hosted externally and independent from the metScanR package.  The new list format now includes:\n\n\n$namez - station name [character]\n$identifiers - station id(s) and idType(s) [data.frame]\n$platform - Primary platform (network) that the station belongs to [character]\n$elements- element type (e.g., precipitation) and active sampling dates for element [data.frame]\n$location - geolocation metadata, e.g., lat\/lon, elevation, etc. [data.frame]\n\n\n\nv2.1.0 2017-07-03 Minor release. NADP and Ameriflux networks added to DB. Database contains 107,624 stations, worldwide.\n\n\nv2.2.0 2017-11-05 Minor release. Identified 498 stations as duplicate entries, removed from DB.  DB now contains 107,126 worldwide stations.  Attributes (above comment) added to DB.  Will use these as checks to ensure user has most up-to-date version installed\n\n\nv2.3.0 2018-08-27 Minor release.  Over 50,000 mesonet stations added to DB.  Database now contains 157,655 stations, worldwide.\n\n\nv2.4.0 2019-01-29 Minor release.  Mapped mesonet variables to metScanR's terms and traceability data frames.  Added units to many variables.  Added remaining NEON sites, data products and sub terms to database.\n\n\nNovelty of metScanR:\nBecause meteorological\/environmental networks are managed by different governing bodies, an abundance of discrepancies exist within station metadata.  A single station may be part of many networks, can have many associated identifiers, and may have similar data product-types (i.e., variables monitored) stored among many repositories.  Additionally, the same data product may be available at different temporal resolutions among the repositories.\nA user may find themselves searching for a station of interest and depending on the station identifier that they use, may be routed to a repository that contains only a fraction of the available station inforation (see Figure 5). This results in a  \"discrepancy gap\" of data avaiability among the thousands of meteorological\/environmental stations, worldwide.  The metScanR package bridges this  'discrepancy gap.' by organizing all metadata into a standardized database, i.e., the metScanR database.\n\nFIGURE 5: An example of metadata discrepancies for a single station: 'Downtown Charleston' in Charleston, SC, USA.  This station has many associated identifiers which route to repositories managed by different governing bodies with varying metadata standards.\nThis gap extends to the manner in which measured variables (e.g., air temperature, soil moisture, snow depth, etc.) are abbreviated and reported among networks. Some networks use full term names to document their data products, while others use abbreviations or discrete alpha-numeric identifiers.  For instance, \"air temperature\" is denoted as, \"air temperature\", \"TEMP\", \"TAVG, \"temp_avg\", \"NEON.DP1.00002.\" etc. among networks; many terms are used to denote the same atmospheric phenomenon.  To alleviate this discrepancy and make elemets traceable to one another, elements within the metScanR database are structured using a hierarchical n-gram framework that links common terms to network-specific element codes.  This accounts for nomenclature discrepancies and allows users to search for a variety of like-elements in one search, a novel approach for structuing and storing meteorological\/environmental metadata (Figure 5).\n\nFIGURE 6: Linking the many network-specific variable abbreviations to common terms.\nThe standardized databases, n-gram traceability, search features, mapping feature, and ease of use make metScanR a novel tool.  Collectively, these features allow users to greatly reduce the time-sink of finding atmospheric and environmental data.\nA quick Example\nA user wishes to search for environmental \/ meteorological stations nearby a known point of interest (POI).  Using metScanR's getNearby() function this can be done in a matter of seconds.  As an example, let's use the search from Figure 4; it took 9.2 seconds to search for and map the 803 stations nearby NEON's NIWO station.  That's a lot of stations among many networks.  But let's say that the researcher wants to find data from nearby sites that have similar elevations to NEON's NIWO site (3513 m ASL) and measure snow depth. No problem.  Using the siteFinder() function, the user can filter the dataset more specifically to their needs (Figure 7).\n\nFIGURE 7: Screenshot example of metScanR's mapSiteFinder() and siteFinder() functions.  Around a dozen stations are i) within 50 km of NEON's NIWO station, ii) at an elevation between 3200 & 3800 m ASL, that iii) measure snow depth.\nFrom start to finish this entire filtering process took less than 2-minutes.  The user can then utilize other network-specific R packages, such as RNRCS, to quickly download the data.\nGetting Started:\nInstall official releases from CRAN with\n#install metScanR:\ninstall.packages(\"metScanR\")\n#load the package:\nlibrary(metScanR)\n#download and save the most up-to-date database:\nupdateDatabase()\n\n\nIf you encounter a bug, please provide a reproducible example on this package's github issues page.\nTutorial:\nA tutorial is provided at: https:\/\/jaroberti.github.io\/metScanR\/tutorials\/intro.html.\nUpdate (2018-09-21) : Please note, the tutorial is a bit out of date.  We're hoping to update the tutorial in the near future.\nCRAN PDF:\nhttps:\/\/cran.r-project.org\/web\/packages\/metScanR\/metScanR.pdf\nFuture Directions:\nWe're hoping to:\n\nEnable metScanR with functionality for directly downloading meteorological and environmental data via existing APIs.\nBuild a web-based platform for users not familiar with the R programming language.\n\nCitation:\ncitation(\"metScanR\")\n\nJosh Roberti, Cody Flagg, Lee Stanish and Robert Lee (2018). metScanR: Find, Map, and Gather Environmental Data\nand Metadata. R package version 1.2.0. https:\/\/CRAN.R-project.org\/package=metScanR\nMeet the team:\nJosh Roberti\nCody Flagg\nLee Stanish\nRobert Lee\nPresentations:\nClick here to check out our presentation from the American Meteorological Society's (AMS) Annual Meeting (2018-01-10) in Austin, TX.\nContact:\nIf you have any questions, comments, concerns, or if you'd like to see a specific network added to the metScanR database, please email Josh (jaroberti87@gmail.com).\n","295":"air in China \/ Openair\nThis project is to fetch data from the official Silverlight application of Ministry of Environmental Protection of China (http:\/\/106.37.208.233:20035\/), which publish realtime air quality.\n\u672c\u9879\u76ee\u65e8\u5728\u4ece\u56fd\u5bb6\u5b98\u65b9\u7a7a\u6c14\u8d28\u91cf\u53d1\u5e03\u5e73\u53f0(http:\/\/106.37.208.233:20035\/) \u7684Silverlight\u7a0b\u5e8f\u4e2d\u83b7\u53d6\u7a7a\u6c14\u8d28\u91cf\u6570\u636e\uff0c\u4fbf\u4e8e\u5904\u7406\u540e\u8fdb\u884c\u4e8c\u6b21\u5f00\u53d1\u3002\nInstall\nvia pip (recommanded):\npip install openair\n\n\u624b\u52a8\u5b89\u88c5:\ngit clone https:\/\/github.com\/hebingchang\/air-in-china\ncd air-in-china\npython setup.py install\n\nUsage\n#-*- encoding: utf-8 -*-\nfrom openair import air_class\nair = air_class.airChina()\n\n# \u83b7\u53d6\u6240\u6709\u6c14\u8c61\u7ad9\u70b9\u8be6\u7ec6\u6570\u636e\nprint air.getAllStationsData()\n\n# \u83b7\u53d6\u7701\u5185\u6240\u6709\u7ad9\u70b9\u6570\u636e, \u5176\u4e2d:\n# \u81f3\u5c11\u63d0\u4f9b\u4e00\u4e2a\u53c2\u6570, \u5373\u7701\/\u76f4\u8f96\u5e02. type\u53c2\u6570\u53ef\u9009, \u5f53\u4e0d\u63d0\u4f9b\u65f6\u9ed8\u8ba4\u4e3a0.\n# type = 0:\u6309\u7701id\u67e5\u627e(\u5982'9'), 1:\u6309\u7701\u540d\u79f0\u67e5\u627e(\u5982'\u4e0a\u6d77'), 2:\u6309\u7701\u62fc\u97f3\u67e5\u627e(\u5982'shanghai')\n# \u6309\u62fc\u97f3\u67e5\u627e\u65f6\u9700\u6ce8\u610f: \u5c71\u897f=shanxi, \u9655\u897f=shan_xi\nprint air.getProvinceStationsData(\"shanghai\", type=2) \n\n# \u83b7\u53d6\u6240\u6709\u7701\/\u76f4\u8f96\u5e02\nprint air.getAllProvinceName()\n\n# \u83b7\u53d6\u67d0\u7701\u6240\u6709\u57ce\u5e02\n# \u5fc5\u987b\u63d0\u4f9b1\u4e2a\u53c2\u6570: \u7701id; \u53ef\u4ee5\u901a\u8fc7getAllProvinceName()\u65b9\u6cd5\u67e5\u627e\u7701id\nair.getProvinceAllCityName(12)\n\n# \u83b7\u53d6\u67d0\u7701\u6240\u6709\u7ad9\u70b9\u4fe1\u606f\n# \u5fc5\u987b\u63d0\u4f9b1\u4e2a\u53c2\u6570: \u7701id\nair.getProvinceAllStationInfo(10)\n\n# \u83b7\u53d6\u67d0\u5e02\u6240\u6709\u7ad9\u70b9\u4fe1\u606f\n# \u5fc5\u987b\u63d0\u4f9b2\u4e2a\u53c2\u6570: \u7701id, \u5e02\u540d(unicode)\n# \u5e02\u540d\u53ef\u4ee5\u901a\u8fc7getProvinceAllCityName()\u65b9\u6cd5\u83b7\u53d6\nair.getCityAllStationInfo(10, u\"\u82cf\u5dde\u5e02\")\n\n# \u83b7\u53d6\u67d0\u5e02\u5386\u53f2AQI\n# \u5fc5\u987b\u63d0\u4f9b1\u4e2a\u53c2\u6570: \u5e02id \/ \u5e02\u540d\n# \u5982\u4e0b\u4f8b, \u4f20\u9012310000\u4e0e\u4f20\u9012u'\u4e0a\u6d77\u5e02'\u7684\u6548\u679c\u662f\u76f8\u540c\u7684.\nair.getCityHistory(310000)\n\nReturn values\n# \u4e3a\u65b9\u4fbf\u89c2\u5bdf\u6570\u636e\u7ed3\u6784, \u6240\u6709\u8fd4\u56de\u7684JSON\u6570\u636e\u5747\u7ecf\u8fc7\u683c\u5f0f\u5316.\n\n# \u6240\u6709\u6c14\u8c61\u7ad9\u70b9\u8be6\u7ec6\u6570\u636e\n[{\n    \"Area\": \"\u5317\u4eac\u5e02\",\n    \"CO_24h\": \"3.1\",\n    \"Latitude\": \"39.8673\",\n    \"O3\": \"64\",\n    \"PM10_24h\": \"\u2014\",\n    \"NO2\": \"160\",\n    \"O3_24h\": \"2\",\n    \"Unheathful\": \"\u5065\u5eb7\u4eba\u8fd0\u52a8\u8010\u53d7\u529b\u964d\u4f4e\uff0c\u6709\u660e\u663e\u5f3a\u70c8\u75c7\u72b6\uff0c\u63d0\u524d\u51fa\u73b0\u67d0\u4e9b\u75be\u75c5\",\n    \"SO2_24h\": \"41\",\n    \"PM2_5_24h\": \"247\",\n    \"AQI\": \"329\",\n    \"ProvinceId\": \"1\",\n    \"PM2_5\": \"279\",\n    \"CO\": \"4.3\",\n    \"O3_8h\": \"39\",\n    \"Longitude\": \"116.366\",\n    \"O3_8h_24h\": \"29\",\n    \"SO2\": \"53\",\n    \"TimePoint\": \"2017-02-15T22:00:00\",\n    \"StationCode\": \"1001A\",\n    \"OrderId\": \"1\",\n    \"CityCode\": \"110000\",\n    \"PositionName\": \"\u4e07\u5bff\u897f\u5bab\",\n    \"PM10\": \"\u2014\",\n    \"PrimaryPollutant\": \"\u7ec6\u9897\u7c92\u7269(PM2.5)\",\n    \"NO2_24h\": \"120\",\n    \"Measure\": \"\u8001\u5e74\u4eba\u548c\u75c5\u4eba\u5e94\u5f53\u7559\u5728\u5ba4\u5185\uff0c\u907f\u514d\u4f53\u529b\u6d88\u8017\uff0c\u4e00\u822c\u4eba\u7fa4\u5e94\u907f\u514d\u6237\u5916\u6d3b\u52a8\",\n    \"IsPublish\": \"true\",\n    \"Quality\": \"\u4e25\u91cd\u6c61\u67d3\"\n}\n......\n]\n\n# \u83b7\u53d6\u6240\u6709\u7701\/\u76f4\u8f96\u5e02\n{\n    \"1\": [\n        \"\u5317\u4eac\",\n        \"beijing\"\n    ],\n    \"2\": [\n        \"\u5929\u6d25\",\n        \"tianjin\"\n    ],\n    \n    ...\n    \n    \"31\": [\n        \"\u65b0\u7586\",\n        \"xinjiang\"\n    ]\n}\n\n# \u83b7\u53d6\u67d0\u7701\u6240\u6709\u57ce\u5e02\n[\n    \"\u6ec1\u5dde\u5e02\",\n    \"\u9ec4\u5c71\u5e02\",\n    ......\n    \n    \"\u6c60\u5dde\u5e02\"\n]\n\n# \u83b7\u53d6\u67d0\u5e02\u6240\u6709\u7ad9\u70b9\u4fe1\u606f\n[\n    {\n        \"Latitude\": \"31.2472\",\n        \"StationCode\": \"1160A\",\n        \"PositionName\": \"\u4e0a\u65b9\u5c71\",\n        \"Longitude\": \"120.561\"\n    },\n    {\n        \"Latitude\": \"31.2864\",\n        \"StationCode\": \"1161A\",\n        \"PositionName\": \"\u5357\u95e8\",\n        \"Longitude\": \"120.628\"\n    },\n    ......\n    \n    {\n        \"Latitude\": \"31.3708\",\n        \"StationCode\": \"1167A\",\n        \"PositionName\": \"\u76f8\u57ce\u533a\",\n        \"Longitude\": \"120.641\"\n    }\n]\n\n# \u83b7\u53d6\u67d0\u5e02\u5386\u53f2AQI\n[\n    {\n        \"CityCode\": \"310000\",\n        \"Area\": \"\u4e0a\u6d77\u5e02\",\n        \"Unheathful\": \"\u7a7a\u6c14\u8d28\u91cf\u4ee4\u4eba\u6ee1\u610f\uff0c\u57fa\u672c\u65e0\u7a7a\u6c14\u6c61\u67d3\",\n        \"Quality\": \"\u4f18\",\n        \"PM2_5_24h\": \"31\",\n        \"PrimaryPollutant\": \"\u2014\",\n        \"TimePoint\": \"2017-02-01T00:00:00\",\n        \"CO_24h\": \"0.7\",\n        \"PM10_24h\": \"37\",\n        \"NO2_24h\": \"20\",\n        \"SO2_24h\": \"12\",\n        \"Measure\": \"\u5404\u7c7b\u4eba\u7fa4\u53ef\u6b63\u5e38\u6d3b\u52a8\",\n        \"O3_8h_24h\": \"90\",\n        \"AQI\": \"45\",\n        \"Id\": \"386477\"\n    },\n    {\n        \"CityCode\": \"310000\",\n        \"Area\": \"\u4e0a\u6d77\u5e02\",\n        \"Unheathful\": \"\u7a7a\u6c14\u8d28\u91cf\u4ee4\u4eba\u6ee1\u610f\uff0c\u57fa\u672c\u65e0\u7a7a\u6c14\u6c61\u67d3\",\n        \"Quality\": \"\u4f18\",\n        \"PM2_5_24h\": \"21\",\n        \"PrimaryPollutant\": \"\u2014\",\n        \"TimePoint\": \"2017-02-02T00:00:00\",\n        \"CO_24h\": \"0.6\",\n        \"PM10_24h\": \"27\",\n        \"NO2_24h\": \"23\",\n        \"SO2_24h\": \"11\",\n        \"Measure\": \"\u5404\u7c7b\u4eba\u7fa4\u53ef\u6b63\u5e38\u6d3b\u52a8\",\n        \"O3_8h_24h\": \"87\",\n        \"AQI\": \"44\",\n        \"Id\": \"386876\"\n    },\n    ......\n]\n\nThanks to\npython-wcfbin (https:\/\/github.com\/ernw\/python-wcfbin)\nLicense\nThis project is under the MIT License.\nCopyright \u00a9 2017\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and\/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\nAfterword\n\u7531\u4e8e\u56fd\u60c5\uff0c\u6211\u56fd\u5728\u6570\u636e\u516c\u5f00\u65b9\u9762\u7684\u5de5\u4f5c\u7684\u786e\u4e4f\u5584\u53ef\u9648\u3002\n\u4f46\u662f\uff0c\u6bcf\u4e2a\u56fd\u6c11\u90fd\u5e94\u6709\u83b7\u77e5\u6570\u636e\u7684\u6743\u5229\uff0c\u6240\u4ee5\u6211\u5c06\u6b64\u9879\u76ee\u5f00\u6e90\uff0c\u63d0\u4f9b\u4e00\u4e2a\u4ece\u5b98\u65b9\u6e20\u9053\u83b7\u53d6\u7a7a\u6c14\u8d28\u91cf\u6570\u636e\u7684\u9014\u5f84\u3002\n","296":"#DVRSTY\n#This is our entry to the Environmental Hackathon July 12-13, 2019\n#Our project allows specialists to identify anomalies in temperature, CO2, dew point and humidity using artificial neural network known as autoencoders.  In addition to Reactjs as our front end, our back end is python and we are using aws sagemaker (http:\/\/ec2-174-129-187-236.compute-1.amazonaws.com:3000\/) and EC2 system to host.\n","297":"EnvironmentalSoundClassification\nThis project includes some source codes for environmental sound classification using cycle-consistent GAN\n","298":"Environmental Pollution\nMap with world environmental pollution. Project uses Next.js, React.js, Typescript, Leaflet, MongoDB and Styled Components\nLive: env-pollution.nparfen.now.sh\n","299":"Environmental-detection\n\u73af\u5883\u5f71\u54cd\u5728\u7ebf\u8bc4\u4f30\u7cfb\u7edf\n","300":"Sequential decision fusion for environmental classification in assistive walking\n\nThis respiratory includes the code and data of our paper: Sequential decision fusion for environmental classification in assistive walking.\nPowered prostheses are effective for helping amputees walk in a single environment, but these devices are inconvenient to use in complex environments. In order to help amputees walk in complex environments, prostheses need to understand the motion intent of amputees. Recently, researchers have found that vision sensors can be utilized to classify environments and predict the motion intent of amputees. Although previous studies have been able to classify environments accurately in offline analysis, the corresponding time delay has not been considered. To increase the accuracy and decrease the time delay of environmental classification, the present paper proposes a new decision fusion method. The sequential decisions of environmental classification are fused by constructing a hidden Markov model and designing a transition probability matrix. Then the developed method is evaluated by inviting five able-bodied subjects and three amputees to perform indoor and outdoor walking experiments. The results indicate that the proposed method can classify environments with accuracy improvements of 1.01% (indoor) and 2.48% (outdoor) over the previous voting method when a delay of only one frame is incorporated. The present method also achieves higher classification accuracy than the recurrent neural network (RNN), long-short term memory (LSTM), and gated recurrent unit (GRU). When achieving the same classification accuracy, the method of the present paper can decrease time delay by 67 ms (indoor) and 733 ms (outdoor) in comparison to the previous voting method. Besides classifying environments, the proposed decision fusion method is also able to optimize the sequential predictions of the human motion intent and other sequential signals.\nYou can test the present hmm, rnn, lstm, and gru model directly by running the file: main_offline.py\nWe have also uploaded the code and data to the codeocean and prepared the environment to run the code. You can run the code online and reproduce the experiments easily without installing any packages. You can view and run the code on: https:\/\/codeocean.com\/capsule\/5201474\/tree\nRun\npython main_offline.py\nPrepare your own dataset\nThe input of the present method is a 2D time sequence (numpy array). The rows of the array are sorted by the capturing time, and the columns of the array are the classification probability on different categories. For calculating the classification accuracy, you can design a neural network and save the normalized classification scores from the last layer. You can look through my previous project (https:\/\/github.com\/KuangenZhang\/Environmental-classification)  to build a convolutional neural network to classify your signals.\nContact\nFor more related works and codes, please view my homepage: https:\/\/kuangenzhang.github.io\/\nFurther information please contact Kuangen Zhang (kuangen.zhang@alumni.ubc.ca).\nCitation\nIf you find our work useful in your research, please consider citing:\n@article{zhang_sequential_2019,\n\ttitle = {Sequential decision fusion for environmental classification in assistive walking},\n\tissn = {1534-4320},\n\tjournal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},\n\tauthor = {Zhang, K. and Zhang, W. and Xiao, W. and Liu, H. and Silva, C. W. de and Fu, C.},\n\tyear = {2019},\n\tpages = {1--1}\n}\nLicense\nMIT License\n","301":"Contiki \u5d4c\u5165\u5f0f\u73af\u5883\u53c2\u6570\u667a\u80fd\u76d1\u6d4b\u63a7\u5236\u7cfb\u7edf\n\nSTM32 Contiki \u4f20\u611f\u5668 \u667a\u80fd\u519c\u4e1a \u73af\u5883\u76d1\u6d4b\n\u9879\u76ee\u7b80\u4ecb\n\n\u4f5c\u54c1\u603b\u5171\u5206\u4e3a\u4e09\u4e2a\u4e3b\u8981\u90e8\u5206\uff0c\u5206\u522b\u4e3a\u786c\u4ef6\u7aef\u3001\u4e0b\u4f4d\u673a\u8f6f\u4ef6\u7aef\u3001\u4e91\u670d\u52a1\u5668\u7aef\n\u4ee5\u4e0b\u5c06\u4ece\u4e0b\u4f4d\u673a\u8f6f\u4ef6\u7cfb\u7edf\u8fdb\u884c\u8f83\u4e3a\u8be6\u7ec6\u7684\u8bf4\u660e\n\u672c\u8bf4\u660e\u7740\u91cd\u8bb2\u89e3\u5d4c\u5165\u5f0f\u4e0b\u4f4d\u673a\u7a0b\u5e8f\u67b6\u6784\uff0c\u786c\u4ef6\u53ea\u53d9\u8ff0\u6a21\u5757\u63a5\u53e3\uff0c\u4e0d\u8fc7\u591a\u6d89\u53ca\u786c\u4ef6\u67b6\u6784\n\u4e91\u670d\u52a1\u5668\u7aef\u8bf7\u53c2\u89c1 \u7269\u8054\u7f51\u591a\u7ec8\u7aef\u5e73\u53f0 \u9879\u76ee\n\n\u5f00\u53d1\u73af\u5883\n\n\n\n\u540d\u79f0\n\u8bf4 \u660e\n\n\n\n\n\u672c\u9879\u76ee\u5168\u79f0\n\u57fa\u4e8eSTM32 Contiki\u7cfb\u7edf\u7684\u7269\u8054\u7f51\u591a\u4f20\u611f\u5668\u667a\u6167\u519c\u4e1a\u7cfb\u7edf-\u5d4c\u5165\u5f0f\u90e8\u5206\n\n\n\u5f00\u53d1\u7cfb\u7edf\nWindows 7\n\n\nMCU\nSTM32F103\u7cfb\u5217 \u578b\u53f7R8\u4ee5\u4e0a (RAM >= 20K\uff0c\u63a8\u835064K)\n\n\nIDE\nMDK517 (Keil uVision5\u4ee5\u4e0a\u5747\u53ef)\n\n\nLanguage\nC\n\n\nSTM32 Package\nSTM32F103 Lib Package v2.0.0 (2.0\u4ee5\u4e0a\u5747\u53ef)\n\n\n\n\u6587\u4ef6\u7ed3\u6784\n\n.\/  \u9879\u76ee\u4e3b\u76ee\u5f55\n\u251c\u2500\u2500 Documents  \u8bf4\u660e\u6587\u6863\u6587\u4ef6\u5939\uff0c\u5305\u542b\u58f0\u660e\uff0c\u66f4\u65b0\u65e5\u5fd7\uff0clssues\n\u2502\n\u251c\u2500\u2500 Hardware   \u5916\u56f4\u6302\u63a5\u8bbe\u5907\u9a71\u52a8\u6587\u4ef6\u5939\uff0c\u5404\u5916\u8bbe\u9a71\u52a8\u6253\u5305\u5728\u5185\u5404\u81ea\u72ec\u7acb\u6587\u4ef6\u5939\u4e2d\n\u2502\n\u251c\u2500\u2500 Libraries  \u5e93\u6587\u4ef6\u5939\uff0c\u5305\u542bSTM32\u5e93\u4f9d\u8d56\u3001\u7b2c\u4e09\u65b9C\u5e93\n\u2502\n\u251c\u2500\u2500 Listing    \u7f16\u8bd1\u94fe\u63a5\u751f\u6210\u6587\u4ef6\u5939\n\u2502\n\u251c\u2500\u2500 Output     \u7f16\u8bd1\u8f93\u51fa\u6587\u4ef6\u5939\n\u2502\n\u251c\u2500\u2500 Project    \u9879\u76ee\u5de5\u7a0b\u6587\u4ef6\u5939\n\u2502\n\u2514\u2500\u2500 User       \u7528\u6237\u6587\u4ef6\u5939\uff0c\u5305\u542b\u5404Contiki\u7cfb\u7edf\u3001\u5185\u8bbe\u9a71\u52a8\uff0c\u5404\u5185\u8bbe\u9a71\u52a8\u6253\u5305\u5728\u5185\u5404\u81ea\u72ec\u7acb\u6587\u4ef6\u5939\u4e2d\n\n\u914d\u7f6e\u8bf4\u660e\n\n\u59cb\u7ec8\u4ec5\u5c06 USART1 \u505a\u4e3a DEBUG \u8c03\u8bd5\u6253\u5370\u7aef\u53e3\uff0c\u6ce2\u7279\u7387 921600\n\u4e0b\u8f7d\u7a0b\u5e8f\u4e0e\u5728\u7ebf\u4eff\u771f\u4f7f\u7528 ST-LINK \/ JLINK SWD\u63a5\u53e3\nFlash\u5927\u5c0f\u914d\u7f6e\u6587\u4ef6:\n\u3000.\/User\/STM_FLASH\/stm_flash.h \u4e2d STM32_FLASH_SIZE \u914d\u7f6e\u5bf9\u5e94\u82af\u7247 Flash ROM \u5927\u5c0f (\uff01\u5fc5\u8981\uff01)\n\u3000Flash \u6700\u540e\u4e00\u9875\u59344\u4e2a\u5b57\u8282\u505a\u4e3a\u968f\u673a\u6570\u79cd\u5b50\u5b58\u653e\u4f4d\u7f6e\nWIFI\u8fde\u63a5\u914d\u7f6e\u6587\u4ef6:  .\/Hardware\/ESP8266\/ESP8266_Wifi_link_Config.c\n\u4ee5\u592a\u7f51\u8fde\u63a5\u914d\u7f6e\u6587\u4ef6:  .\/Hardware\/W5500\/W5500.c\n\u4f20\u611f\u5668\u88c1\u526a:   .\/User\/Contiki-ProcessTask\/ProcessTask.h \u4e2d\uff0c\n\u3000__TERMINAL_ON__ \u4e0e __TERMINAL_OFF__ \u5b8f\u5b9a\u4e49\u95f4\u88c1\u526a\u6240\u9700\u4f20\u611f\u5668\n\u4f20\u8f93\u5c42\u914d\u7f6e:\n\u672c\u9879\u76ee\u4e2d\u4f20\u611f\u7f51\u5185\u53ca\u4f20\u611f\u7f51\u8fde\u63a5\u670d\u52a1\u5668\u95f4\u4f20\u8f93\u5c42\u5747\u4f7f\u7528\u6b64\u5957\u81ea\u5b9a\u4e49\u534f\u8bae\n\u534f\u8bae\u89c4\u8303\u8bf7\u53c2\u89c1 \u4f20\u611f\u7269\u8054\u7f51\u6570\u636e\u5305\u534f\u8bae\u683c\u5f0f\n\n\u534f\u8bae\u5730\u5740:\n\u3000.\/User\/CommunicationProtocol\/CommunicationConfig.c \u4e2d\u8bbe\u7f6e\u672c\u673a\u4f20\u8f93\u5c42\u9ed8\u8ba4\u5730\u5740\n\u3000.\/User\/Contiki-ProcessTask\/ProcessTask.c \u6587\u4ef6\u4e2d CommunicatProtocol_Send_Sensor_Data() \u51fd\u6570\u8c03\u7528 AssembleProtocolPacketPushSendQueue() \u5904\u914d\u7f6e\u4f20\u8f93\u5c42\u9ed8\u8ba4\u5411\u4e0a\u53d1\u9001\u5730\u5740\n\u534f\u8bae\u901a\u4fe1\u51fa\u53e3:\n\u3000.\/User\/CommunicationProtocol\/CommunicationConfig.h \u4e2d TianProtocolSendBytesDataBuf \u5b9a\u4e49\u5904\u8bbe\u7f6e\u9ed8\u8ba4\u901a\u4fe1\u51fa\u53e3\u8bbe\u5907\n\u8d85\u65f6\u4e0e\u91cd\u53d1:\n\u3000.\/User\/CommunicationProtocol\/CommunicationConfig.h \u914d\u7f6e\u91cd\u53d1\u6b21\u6570\u4e0e\u8d85\u65f6\u65f6\u95f4\n\n\n\u4f20\u611f\u7f51\u94fe\u8def\u5c42\u914d\u7f6e:\n\u4f20\u611f\u7f51\u94fe\u8def\u5c42\u6307\u4e0b\u4f4d\u673a\u5404\u7ec8\u7aef\u548c\u8282\u70b9\u4e4b\u95f4\u4e92\u76f8\u7ec4\u6210\u7684\u7f51\u7edc\uff0c\n\u76ee\u524d\u4f20\u611f\u7f51\u94fe\u8def\u5c42\u4e3b\u8981\u4f7f\u7528 E30TTL100 \u6a21\u5757\u4f20\u8f93\uff0c\n\u5728 .\/Hardware\/E30TTL100\/E30TTLUART.c \u4e2d:\n\n\u76ee\u6807\u9ed8\u8ba4\u5730\u5740\u4e0e\u4fe1\u9053:\n\u3000E30TTLUART_Appoint_Target_Address \u4e0e E30TTLUART_Appoint_Target_Channel \u5b9a\u4e49\u5904\u5206\u522b\u8bbe\u7f6e\u5bf9\u76ee\u6807\u7684\u9ed8\u8ba4\u5730\u5740\u4e0e\u4fe1\u9053\n\u672c\u673a\u5730\u5740\u4e0e\u4fe1\u9053\u4e0e\u5de5\u4f5c\u6a21\u5f0f:\n\u3000E30TTLUART_Config() \u4e0e E30TTLUART_MultiCountConfig() \u51fd\u6570\u8c03\u7528\u5904\u8bbe\u7f6e\u672c\u673a\u5730\u5740\u4fe1\u9053\u4e0e\u662f\u5426\u70b9\u5bf9\u70b9\u6a21\u5f0f\n\u3000\u6b64\u4e24\u51fd\u6570\u901a\u5e38\u5728\u521d\u59cb\u5316\u6a21\u5757\u5904\u88ab\u8c03\u7528 (\u672c\u9879\u76ee\u4e2d\u6a21\u5757\u521d\u59cb\u5316\u5728 main.c BSP_Config() \u4e2d)\n\n\n\u5bf9\u670d\u52a1\u5668\u94fe\u8def\u5c42\u914d\u7f6e:\n\u4f20\u611f\u7f51\u8fde\u63a5\u670d\u52a1\u5668\u94fe\u8def\u5c42\u5fc5\u5b9a\u4f7f\u7528\u4e92\u8054\u7f51\u6a21\u5757 ESP8266 WIFI \u6a21\u5757\u3001 W5500 \u786c\u4ef6\u4ee5\u592a\u7f51\u6a21\u5757\uff0c\n\u56e0\u6b64\u5bf9\u670d\u52a1\u5668\u94fe\u8def\u5c42\u914d\u7f6e\u672c\u8d28\u5c31\u662f\u4ee5\u4e0a\u4e92\u8054\u7f51\u6a21\u5757\u9a71\u52a8\u4e2d\u5bf9\u8fde\u63a5\u670d\u52a1\u5668\u7684 Socket \u914d\u7f6e\n\u4e2d\u65ad\u4f18\u5148\u7ea7:\n\u6240\u6709\u7528\u5230\u7684\u4e2d\u65ad\uff0c\u521d\u59cb\u5316\u5904\uff0c\u8bf7\u4f7f\u7528 .\/User\/NVIC\/NVIC.config.c \u4e2d NVIC_IRQChannel_Configuration_Set() \u51fd\u6570\u6b63\u786e\u5408\u7406\u7684\u8bbe\u7f6e\u4e2d\u65ad\u4f18\u5148\u7ea7\u3002\n\u786c\u4ef6\u6a21\u5757\u63a5\u53e3:\n\u5355\u7247\u673a\u5185\u8bbe\u901a\u4fe1\u63a5\u53e3\u5f15\u811a\u7531\u82af\u7247\u56fa\u5b9a\uff0c\u5177\u4f53\u4fe1\u606f\u8bf7\u81ea\u67e5\u5355\u7247\u673a\u6570\u636e\u624b\u518c\n\u5404\u6302\u63a5\u786c\u4ef6\u6a21\u5757\u4e0e\u5355\u7247\u673a\u63a5\u53e3\u5f15\u811a\u8bf4\u660e\u6587\u4ef6\u5747\u5728 .\/Hardware\/ \u4e0b\u6a21\u5757\u5404\u81ea\u9a71\u52a8\u6587\u4ef6\u5939\u5185\uff0c\u5f15\u811a\u914d\u7f6e\u5728\u540c\u76ee\u5f55\u4e0b .c .h \u6587\u4ef6\u4e2d\n(\u4fee\u6539\u65f6\u52a1\u5fc5\u786e\u4fdd\u5404\u6a21\u5757\u9a71\u52a8 .c .h \u6587\u4ef6\u4ee3\u7801\u4e2d\u914d\u7f6e\u5f15\u811a\u4e0e\u8bf4\u660e\u6587\u4ef6\u4e2d\u4e00\u81f4\uff01)\n\n\u6dfb\u52a0\u4f20\u611f\u6a21\u5757\u6d41\u7a0b\n\u5f53\u9700\u8981\u6dfb\u52a0\u4e00\u4e2a\u6302\u8f7d\u7684\u6a21\u5757\u6216\u8005\u6dfb\u52a0\u4e00\u79cd\u65b0\u7684\u529f\u80fd\u65f6\uff0c\u4e00\u822c\u53ef\u6309\u7167\u4e0b\u5217\u6b65\u9aa4\u64cd\u4f5c\n\n\u5728 .\/Hardware\/ \u6216 .\/User\/ \u4e0b\u5efa\u7acb\u6a21\u5757\u9a71\u52a8\u5bf9\u5e94\u6587\u4ef6\u5939\n\u5728\u6a21\u5757\u9a71\u52a8\u6587\u4ef6\u5939\u4e2d\u5efa\u7acb\u63a5\u53e3\u8bf4\u660e\u6587\u4ef6\uff0c\u58f0\u660e\u9884\u8bbe\u5f15\u811a\u63a5\u53e3\n\u5927\u81f4\u7f16\u5199\u9a71\u52a8\u6587\u4ef6(.c .h)\uff0c\u5b9e\u73b0\u521d\u59cb\u5316\u53ca\u90e8\u5206\u64cd\u4f5c\u4ee3\u7801\uff0c\u6240\u4f7f\u7528\u5f15\u811a\u6309\u7167\u8bf4\u660e\u6587\u4ef6\u5b9a\u4e49\n\u9a71\u52a8\u6587\u4ef6\u53ca\u8bf4\u660e\u6587\u4ef6\u6587\u4ef6\u540d\u5747\u4ee5\u6a21\u5757\u540d\u5f00\u5934\uff0c\u9a71\u52a8\u5934\u6587\u4ef6\u4e2d\u6dfb\u52a0\u9632\u91cd\u590d\u5f15\u7528\u5b8f __\u6a21\u5757\u540d__H\n\u9a71\u52a8\u6587\u4ef6\u6240\u7528\u6a21\u5757\u53d8\u91cf\u53ca\u51fd\u6570\u540d\u5c3d\u53ef\u80fd\u5747\u4f7f\u7528 \u6a21\u5757\u540d_ \u4f5c\u4e3a\u540d\u79f0\u5f00\u5934\n\u65e0\u7279\u6b8a\u60c5\u51b5\u4e0b C \u6587\u4ef6 include \u53ea\u5f15\u7528\u5934\u6587\u4ef6\n\u5728IDE MDK\u4e2d\uff0c\u83dc\u5355\u680f Project --> Option for Target 'xxx' --> c\/c++ --> Include Paths \u6dfb\u52a0\u65b0\u5efa\u7684\u9a71\u52a8\u6587\u4ef6\u5939\u8def\u5f84\n\u5728IDE MDK Project Window \u680f\u4e2d Hardware \u6216 USER \u7ec4\u4e0b\u6dfb\u52a0\u521d\u6b65\u7f16\u5199\u7684\u6a21\u5757 C \u6587\u4ef6\n\u4e3a\u6a21\u5757\u9a71\u52a8\u6587\u4ef6\u6dfb\u52a0\u5177\u4f53\u7684\u4f9d\u8d56\u5934\u6587\u4ef6\u5f15\u7528\uff0c\u5b8c\u5584\u529f\u80fd\u4ee3\u7801\uff0c\u786e\u4fdd\u6587\u4ef6\u80fd\u901a\u8fc7\u7f16\u8bd1\n\u91cd\u542f MDK \u4ee5\u4fdd\u5b58\u5de5\u7a0b\u6587\u4ef6\u7ed3\u6784\n\u5728 main.c \u4e0e ProcessTask.h \u4e2d\u6dfb\u52a0\u9a71\u52a8\u5934\u6587\u4ef6\u5f15\u7528\n\u5728 ProcessTask.h \u5b9a\u4e49\u5f00\u542f\u6a21\u5757\u7684\u5b8f __\u6a21\u5757\u540d_ON__\n\u5728 main.c \u4e2d BSP_Config() \u5185\u6dfb\u52a0\u54cd\u5e94\u6a21\u5757\u5b8f\u65f6\u7684\u6a21\u5757\u521d\u59cb\u5316\u64cd\u4f5c\n\u5728 ProcessTask.h \u4e2d\u58f0\u660e\u6a21\u5757\u64cd\u4f5c\u8fdb\u7a0b\u540d\uff0c\u5728 ProcessTask.c \u4e2d\u5b9a\u4e49\u8fdb\u7a0b\u53ca\u63cf\u8ff0\uff0c\u5e76\u5b9e\u73b0\u8fdb\u7a0b\u64cd\u4f5c\u4ee3\u7801\n\u5728main.c \u4e2d main() \u5185\u6dfb\u52a0\u54cd\u5e94\u6a21\u5757\u5b8f\u65f6\u7684\u5f00\u542f\u8fdb\u7a0b\u64cd\u4f5c\n\u8c03\u8bd5\u4ee3\u7801\u5404\u4f9d\u8d56\u9879\uff0c\u786e\u4fdd\u5de5\u7a0b\u901a\u8fc7\u7f16\u8bd1\n\u6a21\u5757\u9a71\u52a8\u53ca\u6a21\u5757\u8fdb\u7a0b\u4e2d\u6dfb\u52a0\u8c03\u8bd5\u8f93\u51fa\u4ee3\u7801\n\u7f16\u5199\u6a21\u5757\u5355\u5143\u6d4b\u8bd5\u4ee3\u7801\n\u5c06\u7a0b\u5e8f\u4e0b\u8f7d\u5230 MCU \u5b9e\u9645\u6d4b\u8bd5\u9a71\u52a8\u8f93\u51fa\nDEBUG\uff0c\u76f4\u5230\u6a21\u5757\u9a71\u52a8\u529f\u80fd\u6b63\u5e38\n\u5c4f\u853d\u6d4b\u8bd5\u4ee3\u7801\n\u81f3\u6b64\u6dfb\u52a0\u4e00\u4e2a\u6a21\u5757\u5b8c\u6210\n\n\u5929\u732b\u81ea\u5b9a\u901a\u4fe1\u534f\u8bae - \u5b9e\u73b0\u90e8\u5206\n\u53d1\u9001\u6d88\u606f\u6d41\u7a0b\n\u5e94\u7528\u5c42\u4ea7\u751f\u6d88\u606f --> cJSON \u5c01\u88c5\u6d88\u606f --> cJSON \u83b7\u53d6 json \u5b57\u7b26\u4e32 --> \u751f\u6210\u534f\u8bae\u5305 PackBlock \u7ed3\u6784\u4f53 --> \u8f6c\u4e3a\u5f85\u53d1\u9001\u7684\u5b57\u7b26\u6d41 --> \u5b57\u7b26\u6d41\u6dfb\u52a0\u5230\u672a\u53d1\u9001\u7f13\u51b2\u961f\u5217\n--> \u4ece\u672a\u53d1\u9001\u961f\u5217\u53d6\u51fa\u5b57\u7b26\u6d41\u5305 --> \u6307\u5b9a\u901a\u9053\u53d1\u9001\u5b57\u7b26\u6d41 --> \u5c06\u5b57\u7b26\u6d41\u5305\u653e\u5165\u672a\u54cd\u5e94\u961f\u5217\n--> \u904d\u5386\u672a\u54cd\u5e94\u961f\u5217 --> \u8fbe\u5230\u91cd\u53d1\u65f6\u95f4\u7684\u5305\u91cd\u65b0\u53d1\u9001\u4e00\u904d\u5e76\u628a\u91cd\u53d1\u8ba1\u6570 +1 --> \u5220\u9664\u8fbe\u5230\u6700\u5927\u91cd\u53d1\u6b21\u6570\u7684\u5305\n\u63a5\u6536\u6d88\u606f\u6d41\u7a0b\n\u4f20\u8f93\u5c42\u901a\u9053\u63a5\u6536\u5b57\u8282\u6d41 --> \u5b57\u8282\u8f6c FIFO \u8282\u70b9\u7ed3\u6784\u4f53 --> \u653e\u5165\u63a5\u6536 FIFO \u7f13\u5b58\u961f\u5217\n--> \u4ece\u63a5\u6536\u7f13\u5b58\u4e2d\u4f9d\u6b21\u8bfb\u53d6\u5b57\u8282 --> \u5224\u65ad\u534f\u8bae\u5305\u5934\u76f8\u7b49 --> \u8bfb\u53d6\u6574\u4e2a\u9996\u90e8 --> \u6821\u9a8c\u9996\u90e8 --> \u8bfb\u53d6\u6570\u636e\u57df --> \u6821\u9a8c\u6570\u636e\u548c --> \u5b58\u5165\u534f\u8bae\u5305 PackBlock \u7ed3\u6784\u4f53 --> \u5b58\u5165\u63a5\u6536\u5305\u7f13\u51b2\u961f\u5217\n--> \u4ece\u63a5\u6536\u5305\u7f13\u5b58\u4e2d\u53d6\u51fa\u534f\u8bae\u5305 --> \u5224\u65ad\u5305\u76ee\u6807\u5730\u5740 --> \u5220\u9664\u5e94\u7b54\u5305 --> \u53d1\u9001\u56de\u5e94\u5305 --> \u5904\u7406\u5305\n","302":"Environmental Clearances\nThis repository contains data, scripts and figures pertaining to environmental clearances (as obtained from the PARIVESH portal hosted by the MOEF&CC)\nSo what's this repository about?\nWe obtained and analyzed the raw data on clearances from PARIVESH, a portal hosted by the MOEF&CC. A summary of the analysis follows. However, all data, figures and scripts emerging from the exploratory data analysis can be obtained from the respective folders.\nData on Environmental Clearances\nEnvironmental clearance data is organized under three sub-headings on the PARIVESH portal, hosted by the MOEF&CC. These include: Environmental, Forests and Wildlife. The data for Forests and Wildlife are quantifiable, while the data for 'Environmental clearances' does not have any quantifiable information associated with it. In other words, these proposals lack any information on the area of forests stated to be cleared. At present, data for forests are available as an excel file on the portal (albeit, after much digging and searching). Data for Wildlife clearances was not available as an excel file.\nAll analysis was performed through the R programming environment. Please feel free to edit and use the code as you please. The data used for this purpose is available through the 'Data' folder.\nHow did we categorize and analyze the data?\nIn 1994, the Union Ministry of Environment and Forests (MEF), Government of India, under the Environmental (Protection) Act 1986, promulgated an EIA notification making Environmental Clearance (EC) mandatory for expansion or modernisation of any activity or for setting up new projects listed in Schedule 1 of the notification. A decade later, a new EIA legislation was passed in 2006. However, unlike the EIA Notification of 1994, the new legislation has put the onus of clearing projects on the state government depending on the size\/capacity of the project. Click herefor more details.\nBased on the above information, we reran the analyses by binning clearances across three time periods: 2000 to 2006; 2007 to 2014 and 2014 to Present.\nForest Clearances\nThe data on forest clearances has been stored in 5 separate excel files:\n\nAll data prior to 2014\nData post 2014 is subdivided by the MOEF&CC into:\na) Allocation of fresh forest land (Form-A)\nb) Application Under Section 2(iii)\nc) Renewal of lease (Form-B)\nd) Prospecting of Minerals (Form-C)\n\nFor the sake of the analysis, we clubbed the above four categories into a single category on clearances post 2014. Secondly, the analysis only includes area in hectares across those proposals that have been categorized as currently approved \/ pending to be approved (See code for further details).\nBetween 2000 and 2006, 6695 proposals were categorized as approved \/ under one of the pending categories. During the same period, 1198 proposals were rejected.\nProportion of proposals rejected: 15.2%\nBetween 2007 and 2014, 14710 proposals were categorized as approved \/ under one of the pending categories. During the same period, 1396 proposals were rejected.\nProportion of proposals rejected: 8.6%\nBetween 2014 and 2020, 24157 proposals were categorized as approved \/ under one of the pending categories. During the same period, 120 proposals were rejected.\nProportion of proposals rejected: 0.5%!\nIf we look at the above information in terms of area:\n2000 to 2006: Area stated to be cleared \/ potentially cleared - 6,29,638 hectares\n2000 to 2006: Area saved - 2,54,555.6 hectares\n2007 to 2014: Area stated to be cleared \/ potentially cleared - 4,51,676 hectares\n2007 to 2014: Area saved - 41,556.63 hectares\n2014 to Present: Area stated to be cleared \/ potentially cleared - 14,82,247 hectares\n2014 to Present: Area saved - 13,077.03 hectares\nBetween 2000 and 2006, Majority of area stated to be cleared was towards mining projects\n\nA similar trend towards mining projects was seen between 2007 and 2014.\n\nWhen compared to the previous time period, area under mining has ** increased six-fold** between 2014 to 2020.\n\n2006 is an outlier year that has seen large chunks of forested land approved for clearing\n\n\nPost 2014, large chunks of forested land were approved for clearing in the year 2016. Notice, that the amount of forest area approved for clearing in 2016 was more than double the amount of forest area approved for clearing in 2006 alone.\n\nBetween 2000 and 2006, a large area of forests were approved\/pending to be cleared in Madhya Pradesh followed by Arunachal Pradesh - two states that possess an astounding level of biodiversity.\n\nA similar trend was seen between 2007 and 2014 for the state of Arunachal Pradesh\n\nPost 2014, Andhra Pradesh and Telangana are stated to lose the most chunks of forest land.\n\nA map of area of forests approved\/pending to be cleared (post 2014)\n\nThe analysis suggests that there has been a significant increase in the rate of environmental clearances for the forest category alone since 2014. Further, the proportion of proposals rejected since 2014 is less than 1%.\nFor further analysis on area lost by category by state across two time periods, please visit the figures folder\n","303":"HEARTH\nEasily manage what will be loaded in your shell environment\nInstallation\nClone project and source hearth.sh in .*rc, e.g. .bashrc file.\nDirectory Structure\nFunctionality is divided in\n\nenv\npaths\naliases\nfunctions\n\nFor each functionality we have a folder with configurable scripts and a file that will always be loaded.\nFor example for env we have the env.d directory and env.sh script.\nEach *.d directory has three sub-folders\n\navailable\nsecret\nenabled\n\nEvery symbolic link in enabled directory will be sourced on start up. In available we have recipes that will be committed to repository.\nIn secret you can add anything that must be excluded from the repository like tokens.\nESTIA\nCommand Line Application to manage your hearth installation.\nNo configuration needed, it's automatically loaded to your path.\nCommands\nedit\nOpen hearth folder in your $EDITOR for editing.\nestia edit\nlist\nList all recipes, available and enabled.\nestia list\ncreate\nCreate a new recipe\nestia create|create-secret <type> <filename>\nExample creating a new environmental variable script.\nestia create env env-var.sh\nor\nExample creating a new environmental variable script.\nestia create-secret env env-var.sh\nenable\nEnable a recipe\nestia enable <type> <filename>\nExample enabling an environmental variable script.\nestia enable env env-var.sh\ndisable\nDisable a recipe\nestia disable <type> <filename>\nExample disabling an environmental variable script.\nestia disable env env-var.sh\n","304":"Read in GR\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\nEnvironment-ALL\nWe are Environment-All students in the 1st grade of Saint Demetrios High School, Christina, Vassilis, Elias, Nikolas and our teacher Katerina Asimakopoulou. We decided to participate because the combination of open technologies and Climate Change (as a thematic) not only interests us, but causes us to help solve the problem as much as we can.\nOur Suggestion\nAfter robot means work, we wondered if there is a robot to process the results of the climate crisis and presents them in a simpler, more concentrated form by graph so their use in the improvement of agricultural production \/ harvest or green growth in an area, urban or not. After a series of meetings between members of our team, we came to the general functions of our robot. In the beginning we use already existing open source programs and some created by us.\nThe RoboKlimUs is capable of taking measurements through specific sensors available\n\nFor the atmosphere:\n\nTemperature\nHumidity\nQuantity of carbon dioxide\n\n\nFor soil:\n\npH\nTemperature\n\n\n\nAfter each measurement, the data are sent via Bluetooth to a remote computer. The computer holds a large database with information from official sources. The data processed by an application written in Python 3 and with the help of XlsxWriter creating Excel spreadsheets with charts.\nThese are Images of the Wiring:\n\n\nCode\nFor this project we are using Python 3, you can download and the latest version here. Be sure to click \"add Python to PATH\" while installing.\nAfter downloading and install it is time to install the required libraries. So navigate to EnvironmentAll folder, click the address bar and delete everything, write \"cmd\"\nand a new black window will appear.\nIn that window type:\npip install -r requirements.txt\n\nThis should install all required libraries for this project. If an error appears ask for help online.\nNow just click Data_Com.py\nFor more information on how to use the program and how to run a demo visit the Bonus Section\nBonus\nLinks\n\nDemo Video (Description, History, Our Team and more)\n3D Robot Preview 1.1 (newest version)\n3D Robot Preview (older versions)\nData Receive Setup Tutorial\nTimelapse Construction of the Robot\n\nCommunication\n\n\n\nName\nTeam Position\nEmail\n\n\n\n\nAsimakopoulou Aikaterini\nTeam Leader\nkasimako@dad.gr\n\n\nIliopoulos Nikolaos\nTeam Member\nnilioprobots@gmail.com\n\n\nKalliakmanis Elias\nTeam Member\nhliaskalliakmanis@gmail.com\n\n\nKeramaris Vasilios\nTeam Member\ngym1973.2017@gmail.com\n\n\nTournari Christina\nTeam Member\nxristinatournari@gmail.com\n\n\n\n","305":"perenv.macro.js\nA Babel macro to conditionally import something based on environmental variables.\nWhy is this a macro?\nThis prevents the import from ever being part of the application code if the environmental variable is not set at build time.\nPerfect for environmental specific configuration that has side effects.\nThis prevents things like mocks, development settings, whatever... from ever getting into built application code.\nThis was specifically created for msw but has a lot of other applications.\nInstallation\nnpm install --save-dev perenv.macro\n\nor\nyarn add --dev perenv.macro\n\nUsage\nOnce you've\nconfigured babel-plugin-macros\nyou can import perenv.macro.\nloadPerEnv\nString Signature\nloadPerEnv(path, envar, ?value)\n\n\n\nArgument\nDescription\n\n\n\n\npath\nNode resolveable path to import (relative path or package name)\n\n\nenvar\nThe environmental variable to inspect\n\n\nvalue (optional)\nConditionally load the import if the envar is equal to this value\n\n\n\nObject Signature\nloadPerEnv({path, identifier}, envar, ?value)\n\n\n\nArgument\nDescription\n\n\n\n\npath\nNode resolveable path to import (relative path or package name)\n\n\nidentifier\nIdentifier to use if imported (You probably want to use loadPerEnvMap instead of this)\n\n\nenvar\nThe environmental variable to inspect\n\n\nvalue (optional)\nConditionally load the import if the envar is equal to this value\n\n\n\nUsage\nIf the environmental variable ENABLE_MY_CONFIGURATION is set loadPerEnv will transpile like this\n\/\/ export ENABLE_MY_CONFIGURATION=1\n\nimport { loadPerEnv } from \"perenv.macro\";\nloadPerEnv('.\/a_configuration_file.js', 'ENABLE_MY_CONFIGURATION');\n\n      \u2193 \u2193 \u2193 \u2193 \u2193 \u2193\n\nimport \".\/a_configuration_file.js\";\nif it is not set it will transpile like this\n\/\/ unset ENABLE_MY_CONFIGURATION\n\nimport { loadPerEnv } from \"perenv.macro\";\nloadPerEnv('.\/a_configuration_file.js', 'ENABLE_MY_CONFIGURATION');\n\n      \u2193 \u2193 \u2193 \u2193 \u2193 \u2193\n\n\/\/ Intentionally blank\nYou can also conditionally load something based on the value of the environmental variable.\n\/\/ export NODE_ENV=dev\nimport { loadPerEnv } from \"perenv.macro\";\nloadPerEnv('.\/config_dev.js', 'NODE_ENV', \"dev\");\nloadPerEnv('.\/config_prod.js', 'NODE_ENV', \"production\");\n\n      \u2193 \u2193 \u2193 \u2193 \u2193 \u2193\n\nimport \".\/config_dev.js\";\nIf you want to use the exports of a file, you can use an object as the first argument\n\/\/ export NODE_ENV=dev\n\nimport { loadPerEnv } from \"perenv.macro\";\nloadPerEnv({path: '.\/feature.js', identifier: 'feature'}, 'NODE_ENV', \"dev\");\n\n      \u2193 \u2193 \u2193 \u2193 \u2193 \u2193\n\nimport * as feature from \".\/feature.js\";\nloadPerEnvMap\nSignature\nloadPerEnvMap(map, envar, ?nullable = false)\n\n\n\nArgument\nDescription\n\n\n\n\nmap\nA key-value map representing what is to be imported based on the value of the envar\n\n\nenvar\nThe environmental variable to inspect\n\n\nnullable (optional)\nIt is safe to return null if value is not found in map\n\n\n\nUsage\nAllows you to use a map of different imports based on the value of your envars\n\/\/ export NODE_ENV=production\n\nimport { loadPerEnvMap } from \"perenv.macro\";\nloadPerEnvMap({dev: '.\/new_feature.js', production: '.\/feature.js'}, 'NODE_ENV');\n\n      \u2193 \u2193 \u2193 \u2193 \u2193 \u2193\n\nimport \".\/feature.js\";\nUse an assignment to declare the import namespace, handy to keep linters quiet\n\/\/ export NODE_ENV=production\n\nimport { loadPerEnvMap } from \"perenv.macro\";\nconst feature = loadPerEnvMap({dev: '.\/new_feature.js', production: '.\/feature.js'}, 'NODE_ENV');\n\n      \u2193 \u2193 \u2193 \u2193 \u2193 \u2193\n\nimport * as feature from \".\/feature.js\";\nEnable the nullable flag to allow for cases where the envar value may not be in the map.\n\/\/ export NODE_ENV=CI\n\/\/ or\n\/\/ unset NODE_ENV\n\nimport { loadPerEnvMap } from \"perenv.macro\";\nconst feature = loadPerEnvMap({dev: '.\/new_feature.js', production: '.\/feature.js'}, 'NODE_ENV', true);\n\n      \u2193 \u2193 \u2193 \u2193 \u2193 \u2193\n\nconst feature = null\nOr in the case that no assignment is made\n\/\/ export NODE_ENV=CI\n\/\/ or\n\/\/ unset NODE_ENV\n\nimport { loadPerEnvMap } from \"perenv.macro\";\nloadPerEnvMap({dev: '.\/new_feature.js', production: '.\/feature.js'}, 'NODE_ENV', true);\n\n      \u2193 \u2193 \u2193 \u2193 \u2193 \u2193\n\n\/\/ Intentionally blank\nUse Cases\nEnable msw in testing environments without adding it to source at build time\n\/\/ index.js\nimport { loadPerEnv } from \"perenv.macro\";\nloadPerEnv('mocks.js', 'ENABLE_MOCKS');\nMock window objects that will be available in a deployment environment, but not as part of a micro-frontend project\n\/\/ index.js\nimport { loadPerEnv } from \"perenv.macro\";\nloadPerEnv('mocks.js', 'ISOLATED_MICROFRONTEND');\n\n\/\/ mocks.js\n\nwindow.globalStore = {\n    \/\/ a mock implementation\n}\nPrevent polyfills during development\n\/\/ index.js\nimport { loadPerEnv } from \"perenv.macro\";\nloadPerEnv('polyfills.js', 'NODE_ENV', 'production');\nFeature flags at build time\n\/\/ index.js\nimport { loadPerEnv } from \"perenv.macro\";\nloadPerEnv({path: 'new_feature.js', identifier: 'feature'}, 'FEATURE_FLAG_X', 'enabled');\nloadPerEnv({path: 'old_feature.js', identifier: 'feature'}, 'FEATURE_FLAG_X', 'disabled');\nSpecial thanks\n\nimport-all.macro as a template for this readme and demonstation of the import pattern.\nms.macro for the transpile testing function.\nBabel Types documentation because this would be impossible without it.\n\n","306":"Environmental Sensor Manager\nReleased under Apache 2.0 except where the license of a subpart differs.\nA blended hardware\/software project using the Particle.io IoT ecosystem for environmental data collection using an array of devices.\nThis project is intended to introduce the hobbyist to managing multiple sensors as well as collecting and reporting the resultant data.\n","307":"env1005-report\nFinal report on Waste in Aruba, written collectively by 2017 Environmental Science class at University of Aruba, Faculty of Hotel Management and Tourism Studies\n","308":"Image Dehazing via Joint Estimation of Transmittance Map and Environmental Illumination\n\n\n\nInput\nTransmittance Map\nDehazed Image\n\n\n\n\n\n\n\n\n\n\nHaze limits the visibility of outdoor images, due to the existence of fog, smoke and dust in the atmosphere. In this work, we present an end to end system, which takes a hazy image as its input and returns a dehazed image. The proposed method learns the mapping between a hazy image and its corresponding transmittance map and the environmental illumination, by using a multi-scale Convolutional Neural Network. This repository contains a python implementation of the same.\n\nAuthors: Sanchayan Santra, Ranjan Mondal, Pranoy Panda, Nishant Mohanty, Shubham Bhuyan\nPaper : https:\/\/arxiv.org\/abs\/1812.01273\nConference: 9th International Conference on Advances in Pattern Recognition (ICAPR), 2017\n\nRequirements:\n\nPython 2.7+ or 3.5+.\nTensorflow and its requirements.\nNumPy. The pip should work.\nscikit-image.\nKeras\nScipy\nMatplolib\n\nFolders and Files:\nMost important for using the proposed dehazing network in a new project:\n\nFinal_code.py\nnetwork.py\nweights.h5\n\nMost important for (re)training the proposed dehazing network on new data:\n\npreprocess.py\nhelper_functions.py\n\nRunning the program\n$ python src\/final_assembly\/Final_code.py [path\/to\/hazzy_image]\nFor example, running on the mountain image\n$ python src\/final_assembly\/Final_code.py results\/mountain_input.png\nLicense and Citation\nThis software is released under the LGPL.\nPlease cite our paper in your publications if it helps your research:\n@inproceedings{santra2017image,\n  title={Image Dehazing via Joint Estimation of Transmittance Map and Environmental Illumination},\n  author={Santra, Sanchayan and Mondal, Ranjan and Panda, Pranoy and Mohanty, Nishant and Bhuyan, Shubham},\n  booktitle={2017 Ninth International Conference on Advances in Pattern Recognition (ICAPR)},\n  pages={1--6},\n  year={2017},\n  organization={IEEE}\n}\n\n","309":"Environmental-Data\nPDF DOWNLOAD PROJECT\nPython based PDF extraction tool\nPDF download project is a Web Scraping project used to download PDF from HTML webpage.\nWebsite : http:\/\/parivesh.nic.in\/\nENVIRONMENT CLEARANCE > DASHBOARD\nDownload & Installation\n1. Clone the repository.\ngit clone https:\/\/github.com\/Saurabh-kayasth\/Environmental-Data.git Or you can download the zip file \tand Extract the files \tfrom there.\n2. Download dependencies (see below)\n3. Change directory(cd) to \/Environmetal-Data\/Src folder and run python3 \tworkingpdf.py from terminal. (make sure you are using python version \t3.6.x or greater)\nInstallation Guide\n\n>= Python 3.6.x : https:\/\/www.python.org\/downloads\/release\/python-360\/\n\nInstalling Dependencies\nMethod 1 :\nUsing requirements.txt ( pip recommended )\npip install -r requirements.txt                                                                                         \n\nMethod 2 :\nUsing pip ( recommended )\n- BeautifulSoup4: https:\/\/pypi.org\/project\/beautifulsoup4\/\npip install beautifulsoup4                                                                                       \n\nThis allows us to search & extract content from an HTML webpage.\n- Requests: https:\/\/pypi.org\/project\/requests\/\npip install requests                                                                                                \n\nThe requests module allows you to send HTTP requests using Python. The HTTP request returns a Response Object with all the response data (content, encoding, status, etc).\n- Pyinstaller: https:\/\/pypi.org\/project\/PyInstaller\/\npip install pyinstaller                                                                                              \n\nThis allows us to build executable file.\nTo build executable file, run :\npyinstaller --onefile working_pdf.py                                                                        \n\nDocumentation : https:\/\/pyinstaller.readthedocs.io\/en\/stable\/usage.html\n","310":"Welcome to Environ\nThis is an erlang program I wrote that, combined with my 1wire suite, provides\nnear-realtime alerting of sensors going out of state (or just falling off the\nnetwork) so I can know when I need to buy a new air conditioner for my machine\nroom.\nIt also provides a simple TCP mirroring that will show you data as it comes in\non the wire.  For a good time, telnet to lemp.west.spy.net port 8181.\nDon't ask me what lemp stands for.  I forgot pretty much as soon as I wrote it.\n\nThis software is released under the MIT license.  If you like it, great.  If\nyou don't like it, make it better.\n","311":"Sensor\nCode for running a raspberry pi powered sensor platform for monitoring internal and external temperature, light, and humidity.\nLatest branch is SensorPiB - will get round to cleaning up the other branches one day.\nSystem currently consists of two DS18b20 onewire temperature sensors, one DHT22 temperature and humidity sensor, and a light dependent resistor (LDR) hooked up to a capacitor to provide a digital output for sensing light. Also added is an Adafruit ultimate GPS module, partly just for practice, and partly because I had a crazy notion of running the whole thing in my car...or something.\nProgramming for the pis is all in python, graphing is all in R. Currently using Adafruit python driver for DHT22 https:\/\/github.com\/adafruit\/Adafruit_Python_DHT.\nSetting up a raspberry pi\nIn this guide I explain how I set up my most recent raspberry pi, which is an A+ board. I don't have an external monitor, so this setup is completed entirely headlessly.\nRaspbian\nAt present I use the standard raspbian image (available here, not the NOOBS setup), and flash this onto the SD card using disks in Ubuntu. In future it would make sense to switch over to a more minimal install of raspbian (e.g. here).\nWifi support\nAfter installing Raspbian we need to make sure that the raspberry pi A+ is going to connect ok to the WiFi network. Very simply, all I do is copy the config from \/var\/wpa_supplicant\/wpa_supplicant.confon one of my otehr pis, and paste it into the same location on the new pi. In my case it looks something like this (of course I have removed the passkey):\nctrl_interface=DIR=\/var\/run\/wpa_supplicant GROUP=netdev\n\nnetwork={\nssid=\"\"\npsk=\"\"\nproto=RSN\nkey_mgmt=WPA-PSK\npairwise=CCMP\nauth_alg=OPEN\n}\n\nOnce that is sorted, I plug in the WiFi adapter (and be careful if you are using an edimax one - these seem to bethicker than normal usb ports, and for some reason I have bent back the usb port pins twice -- on the first occasion I had to send the pi back for a replacement), switch on the pi and it should connect to your network.\nYou then need to find the IP address of the pi in your router config, then you can ssh to it using ssh pi@192.168.1.255 or equivalent. The password will of course be raspberry by default.\nPackages\nNext thing to do is to install some packages so we can get it working as a sensor.\nFirst we do the standard update:\nsudo apt-get update -y; sudo apt-get upgrade -y\nhere the -y flag will just download everything without asking you again.\nNext python:\nsudo apt-get install python-dev python-rpi.gpio -y\nGPS\nI'm using an Adafruit ultimate GPS module attached over UART. You need to run the following:\nsudo apt-get install gpsd gpsd-clients python-gps\nsudo gpsd \/dev\/ttyAMA0 -F \/var\/run\/gpsd.sock\n\nand then the gps should be visible, in my case on \/dev\/ttyAMA0, which you can cat to see the latest data stream.\nTo make the gps (GPS demon) run at startup, you need to run:\nsudo dpkg-reconfigure gpsd\nand follow the onscreen prompts. Answer NO when it asks you whether you want it to manage USB GPS devices, as we are using UART.\nAttempting to do this caused an error for me relating to the mathkernel. This can be fixed follow the instructions at the forum post here. essentially, you must add:\n### BEGIN INIT INFO\n# Provides:          mathkernel\n# Required-Start:    $local_fs \n# Required-Stop:     $local_fs\n# Default-Start:     2 3 4 5\n# Default-Stop:      0 1 6\n# Short-Description: mathkernel\n### END INIT INFO\n\nto the file \/etc\/init.d\/mathkernel  after the shebang:\n #!bin\/sh \n\nCrontab\nRather than run an infinite python loop, I have started using crontab to run each of the python scripts independently at various intervals. This makes it easier to link up the data collected by varuious raspberry pis, as the timestamps will be the same. The crontab file looks like this:\n# m h  dom mon dow   command\n  *\/3 * * * *     cd ~\/Sensor\/; sudo python sensor.py\n  *\/10 * * * *     cd ~\/Sensor\/; sudo python gpsdData2.py\n  *\/15 * * * *  cd ~\/Sensor\/; sudo python db.py\n  @reboot sudo modprobe w1-gpio\n  @reboot sudo modprobe w1-therm\n  \n\n","312":"FoodTree \ud83c\udf31\ud83d\udcab\n\nAn iOS app made with two coOl girls.\nFoodTree aims to address the problem with food wastage in Singapore. We focus on how F&B companies throw away excess food into the trash daily and make use of this problem to our advantage.\nFind out more about the development here.\nLicense\nSee LICENSE\n","313":"Environmental Monitor\nOverview\nThis is a simple Mongoose OS powered environment monitor consisting of an SSD1306 OLED and BME280 Sensor connected to the controller via a shared I2C bus.\nHow to install this app\n\nInstall and start mos tool\nSwitch to the Project page, find and import this app, build and flash it:\n\n\n\n\nAlternatively, you can build and flash this example from the command line:\n### Build\n$ git clone https:\/\/github.com\/mongoose-os-apps\/example-arduino-adafruit-bme280-js.git && cd example-arduino-adafruit-bme280-js\n$ mos build --platform esp32\n$ mos flash\n\n### Wait for Boot and then set I2C Pins\n$ mos console\n$ mos config-set i2c.scl_gpio=22 i2c.sda_gpio=23\n\n### Verify I2C\n$ mos config-get i2c\n\nUsing this Example\nFor this example to work properly you must ensure your I2C or SPI configuration is correct.  You can check your device's current configuration using mos config-get, look for the \"i2c\" or \"spi\" section.\n$ mos config-get i2c\nUsing port \/dev\/ttyUSB1\n{\n  \"debug\": false,\n  \"enable\": true,\n  \"freq\": 100000,\n  \"scl_gpio\": 22,\n  \"sda_gpio\": 23\n}\n\nWhen your device boots, the output should look like the following, watch carefully for the \"mgos_i2c_create\" (or equivilent SPI) line from the boot up messages to ensure your pins were initialized correctly via the Web UI or mos console:\n[Dec 25 13:25:24.986] mgos_i2c_create      I2C GPIO init ok (SDA: 23, SCL: 22)\n[Dec 25 13:25:24.992] mg_rpc_channel_uart  0x3ffbc478 UART0\n[Dec 25 13:25:25.001] mgos_init            Init done, RAM: 317608 total, 275252 free, 275252 min free\n[Dec 25 13:25:25.098] ====================== Starting =============================\n[Dec 25 13:25:25.424] mongoose_poll        New heap free LWM: 261716\n[Dec 25 13:25:27.426] Temperature: 22.960000 *C\n[Dec 25 13:25:27.433] Humidity: 43.640000 %RH\n[Dec 25 13:25:27.442] Pressure: 1025.687700 hPa\n[Dec 25 13:25:29.426] Temperature: 22.970000 *C\n[Dec 25 13:25:29.433] Humidity: 43.640000 %RH\n[Dec 25 13:25:29.441] Pressure: 1025.714100 hPa\n[Dec 25 13:25:31.425] Temperature: 22.960000 *C\n[Dec 25 13:25:31.433] Humidity: 43.650000 %RH\n[Dec 25 13:25:31.441] Pressure: 1025.692000 hPa\n\nPlease note that on ESP8266 and ESP32 the pins you choose to use for I2C aren't important, just ensure your configuration is on the pins you've selected.\nFor I2C, the Sensor Address is very important, the Adafruit BME280 uses address 0x77, many generic BME280's utilize 0x76.  If you are having trouble, try switching addresses or consult your datasheet.\nIt is well known that BME280's tend to self-warm and report higher than expected temperatures.  The tolerance of the BME280 tensor is +\/-1C, however when added to heating it isn't uncommon to see temperatures as much as 1.8C higher than ambient.  You should add adjustments to your code after testing in the environment you will use the sensor using a reliable thermometer.  Please do not report excessive temps as a Mongoose bug.\n","314":"Coding with Open Data from Environmental Reporting BC\nIn this repo, we'll develop a collection of lessons based on the data and code that Environmental Reporting BC has released.\nContent Guidelines:\n\nSkill focus: each lesson should focus on helping learners gain a skill they'll need to work with the data and code released by BC, and enable learners to transfer those skills to other projects.\nLesson Format: anything goes! But if you're looking for some guidance, consider:\nStudy group lesson: a one hour hands-on tutorial, designed to be led by an instructor\nWorkshop lesson: like the study group, but longer.\nSelf-study curriculum: a tutorial designed to be followed by an independent learner.\nContent Format: keep it as simple and dependency-free as possible. Markdown or plain text for text; IPython Notebooks or knitr scripts are good options, too!\n\nContributing:\nPlease place your lesson in its own folder, and make sure everything needed (scripts, pointers to data or other code etc) are included and clearly labeled in your lesson folder.\nFeel free to start brainstorming lesson ideas in the issue tracker before you begin!\n","315":"Coding with Open Data from Environmental Reporting BC\nIn this repo, we'll develop a collection of lessons based on the data and code that Environmental Reporting BC has released.\nContent Guidelines:\n\nSkill focus: each lesson should focus on helping learners gain a skill they'll need to work with the data and code released by BC, and enable learners to transfer those skills to other projects.\nLesson Format: anything goes! But if you're looking for some guidance, consider:\nStudy group lesson: a one hour hands-on tutorial, designed to be led by an instructor\nWorkshop lesson: like the study group, but longer.\nSelf-study curriculum: a tutorial designed to be followed by an independent learner.\nContent Format: keep it as simple and dependency-free as possible. Markdown or plain text for text; IPython Notebooks or knitr scripts are good options, too!\n\nContributing:\nPlease place your lesson in its own folder, and make sure everything needed (scripts, pointers to data or other code etc) are included and clearly labeled in your lesson folder.\nFeel free to start brainstorming lesson ideas in the issue tracker before you begin!\n","316":"pyLCAIO\nAn object class to hybridize lifecycle assessment (LCA) and environmentally extended input-output (EEIO) databases.\n\nCreate your own LCA-IO hybrid database (e.g. combining ecoinvent and exiobase data)\nAutomates hybridization and correction for double-counting with two available methods (STAM and binary)\nDefault parameters only allow the hybridization of ecoinvent3.5 with EXIOBASE\nCan accept capitals-endogenized version of EXIOBASE\nIncludes extrapolated additional environmental extensions for EXIOBASE (from USEEIO)\nIncludes matching of ecoinvent and EXIOBASE environmental flows to Impact World+\nIncludes regionalized characterization matrices for use with Impact World+\nCan be exported to brightway2\n\nIf you are just interested in the default hybrid database (if you do not want to or cannot run the code) you can find it here: https:\/\/zenodo.org\/record\/3890379\nThis software is still under development.\nSystem requirements\nUnder 8GM of RAM you will most likely run into a MemorryError, making it impossible to generate a database\nDependencies\n\nPython 3\nPandas\nNumpy\nScipy\npymrio\necospold2matrix\npickle\nbrightway2\nbw2agg\n\nRelated publications\n\nMajeau-Bettez, G., Agez, M., Wood, R., S\u00f6dersten, C., Margni, M., Str\u00f8mman, A. H., & Samson, R. (2017). Streamlined Hybridization software: merging Ecoinvent and Exiobase. In Biennial Conference of the International Society for Industrial Ecology.\nAgez, M., Majeau-Bettez, G., Margni, M., Str\u00f8mman, A. H., & Samson, R. (2019). Lifting the veil on the correction of double counting incidents in hybrid Life Cycle Assessment. Journal of Industrial Ecology, 1\u201317. https:\/\/doi.org\/https:\/\/doi.org\/10.1111\/jiec.12945\nAgez, M., Wood, R., Margni, M., Str\u00f8mman, A. H., Samson, R., & Majeau-Bettez, G. (2019). Hybridization of complete LCA and MRIO databases for a comprehensive product system coverage. Journal of Industrial Ecology, 1\u201317. https:\/\/doi.org\/10.1111\/jiec.12979\n\n","317":"Python for earth scientists\nAn introduction to working with data in python for scientists\n\nBasic Info\nWhat you need to join\nWhat will you learn?\nDaily Breakdown\n\ntl;dr\nWHAT:  Python - numpy, scipy, matplotlib, pandas, xarray\nWHEN:  11 - 13 December 2018\nWHERE: CSIR, Rosebank\nWHO:   Beginners with sound knowledge of lists, tuple, for loop, if statement\nCOST:  R150 per day\nHOW:   On your own laptop with Luke and Tommy teaching interactively\n\n\nBasic Info\nThe course will be run by Luke Gregor and Tommy Ryan-Keogh and will be hosted at the CSIR.\nAnyone can join but we are limited to 20 spaces - so first come first serve.\nNote that the course will also cost R150 per day. Note that the days build on each other so I recommend that you only skip days if you've done the course before and you want a refresher. This can be paid to Luke in person (a brother's gotta eat) - details to follow.\nWhat you need to join\n\nA laptop with the Anaconda distribution of Python installed (https:\/\/www.anaconda.com\/download\/)\nA sound understanding of basic python: Part 1  at https:\/\/python101.pythonlibrary.org\/index.html. You will quickly fall behind if you don't understand:\n\ntypes: str, int, float, list, tuple, dict\nfor loops\nif statements\nimport packages\n\n\nKnow how to have packages installed with conda in the command line\n\nconda install pandas scikit-learn netCDF4 xarray\n\n\n\nWhat will you learn?\nWe will cover the tools you need to work with data in python to create plots like this (and many more):\n\n\nHowever, you will not walk away as ninja. This takes time and practice. The course serves as a crash course to working with and plotting data. We will go over example problems, but it will help if you come with your own data so you can learn on the fly.\n\nDaily breakdown\nDAY 1 (numpy)\nCore Python recap, numpy and matplotlib\n\nrecap core Python\nimporting data\nworking with data - indexing, slicing, etc.\nplotting lines and scatter\n\nDAY 2 (pandas)\npandas will change your life (if you work with time series or any other table data).\n\nimporting data\ntime series resampling\nplotting recap with pandas\nlinear regression with sklearn\n\nDAY 3 (xarray)\nxarray is a netCDF tool and probably saved me four months in my PhD\n\nimporting netCDF\ntemporal resampling\ncalculating climatologies\nplotting maps with cartopy\n\n","318":"Website Staging\nA staging area for ffem.io \/ ffem.in where we experiment with design and content.\nstaging.ffem.io\n","319":"CoronaWhy TIES Task Force\n\n\nA worldwide effort by volunteers to fight Coronavirus (COVID-19)\n\n\nUnderstanding the COVID-19 transmission, incubation, and environmental stability.\n\nDocumentation: https:\/\/task-ties.readthedocs.io\/en\/latest\/\nTask Homepage: https:\/\/github.com\/CoronaWhy\/task-ties\nMain Coronawhy Homepage: https:\/\/www.coronawhy.org\/\n\nAbout CoronaWhy\nCoronaWhy is a crowd-sourced team of over 350 engineers, researchers, project managers, and all sorts of other professionals with diverse backgrounds who joined forces to tackle the greatest global problem of today--understanding and conquering the COVID-19 pandemic. This team formed in response to the Kaggle CORD-19 competition to synthesize the flood of new knowledge being generated every day about COVID-19. The goal for the organization is to inform policy makers and care providers about how to combat this virus with knowledge from the latest research at their disposal.\nAbout CoronaWhy TIES Task\nTODO\nAbout CoronaWhy TIES Task Force\nList of collaborators (pending)\nInstall\nAlso, although it is not strictly required, the usage of a virtualenv\nis highly recommended in order to avoid interfering with other software installed in the system.\nThese are the minimum commands needed to create a virtualenv using python3.6 for task-ties:\npip install virtualenv\nvirtualenv -p $(which python3.6) task-ties\nAfterwards, you have to execute this command to activate the virtualenv:\nsource task-ties\/bin\/activate\nRemember to execute it every time you start a new console to work on task-ties!\nWith your virtualenv activated, you can clone the repository and install it from\nsource by running make install-deveop on the stable branch:\ngit clone git@github.com:CoronaWhy\/task-ties.git\ncd task-ties\ngit checkout stable\nmake install-develop\nNow you have the code installed on your local system, and you are ready to help us with your contribution, but first, please have a look at the Contributing Guide.\n","320":"CoronaWhy TIES Task Force\n\n\nA worldwide effort by volunteers to fight Coronavirus (COVID-19)\n\n\nUnderstanding the COVID-19 transmission, incubation, and environmental stability.\n\nDocumentation: https:\/\/task-ties.readthedocs.io\/en\/latest\/\nTask Homepage: https:\/\/github.com\/CoronaWhy\/task-ties\nMain Coronawhy Homepage: https:\/\/www.coronawhy.org\/\n\nAbout CoronaWhy\nCoronaWhy is a crowd-sourced team of over 350 engineers, researchers, project managers, and all sorts of other professionals with diverse backgrounds who joined forces to tackle the greatest global problem of today--understanding and conquering the COVID-19 pandemic. This team formed in response to the Kaggle CORD-19 competition to synthesize the flood of new knowledge being generated every day about COVID-19. The goal for the organization is to inform policy makers and care providers about how to combat this virus with knowledge from the latest research at their disposal.\nAbout CoronaWhy TIES Task\nTODO\nAbout CoronaWhy TIES Task Force\nList of collaborators (pending)\nInstall\nAlso, although it is not strictly required, the usage of a virtualenv\nis highly recommended in order to avoid interfering with other software installed in the system.\nThese are the minimum commands needed to create a virtualenv using python3.6 for task-ties:\npip install virtualenv\nvirtualenv -p $(which python3.6) task-ties\nAfterwards, you have to execute this command to activate the virtualenv:\nsource task-ties\/bin\/activate\nRemember to execute it every time you start a new console to work on task-ties!\nWith your virtualenv activated, you can clone the repository and install it from\nsource by running make install-deveop on the stable branch:\ngit clone git@github.com:CoronaWhy\/task-ties.git\ncd task-ties\ngit checkout stable\nmake install-develop\nNow you have the code installed on your local system, and you are ready to help us with your contribution, but first, please have a look at the Contributing Guide.\n","321":"IncaKoin [INCA]\nSHA256D, Proof of Work+Proof of Stake\nMax 190 million Proof of Work Coins\n9% stake every 5 weeks\n100 coins per block starting september 10th , halving every ~6 months\n1 minute block targets\n1000 blocks to coin maturation\nPublic Address Key: 53 \"N\"\nEpoch (nChainStartTime): 1377538838 (August 26, 2013 @ 11:40 AM)\npszTimestamp: \"Por unos caminos hechos en lineas nacio el oro de Inca\"\nRPCPort = 17420\nP2PPort = 17421\nTransaction Messaging\nConfig File: %appdata%\\IncaKoin\\IncaKoin.conf\n","322":"pyLCAIO\nAn object class that can structure, manipulate, and facilitate the hybridization of lifecycle assessment (LCA) and environmentally  extended input-output (EEIO) matrices.\n\nRead in, combine, organize, manipulate and concatenate LCA foreground and background matrices\nCombine LCA system with EEIO matrices\nAutomate hybridization and correction for double-counting\n\nStill in beta release. With more documentation and demos soon to come.\n","323":"bmp180\nGolang package for reading environmental data from a BMP180 environmental I2C sensor.\n\nPackage stub provides an emulated BMP180 device that can be used to test functionality of the bmp180 package when no I2C bus or physical device is attached or available.\nPressure and temperature calculations are based on a paper called \"Bosch BMP085 Barometer Floating Point Pressure Calculations\".\nSee bmp180_test.go for a working example.\nCopyright 2017 Michael Franzl. All rights reserved.\nUse of this source code is governed by a BSD-style license that can be found in the LICENSE file.\n","324":"pongo-blender\nRenders pongo2 templates from environmental variables.\npongo2 is the successor of pongo, a Django-syntax like templating-language.\nREAD: pongo-blender lets me use jinja2 pongo2 templates inside docker containers and populate the values(secrets and configs) at container run time. One image, many containers, every container can have its own configs.\n##pongo2 examples\nhttps:\/\/github.com\/flosch\/pongo2\/blob\/master\/template_tests\/filters.tpl\nRequirements\n\ngolang\n$GOPATH set\n\nSet your $GOPATH\nmkdir ~\/.go\necho \"GOPATH=$HOME\/.go\" >> ~\/.bashrc\necho \"export GOPATH\" >> ~\/.bashrc\necho \"PATH=\\$PATH:\\$GOPATH\/bin # Add GOPATH\/bin to PATH for scripting\" >> ~\/.bashrc\nsource ~\/.bashrc\n\nFor OSX you will also have to do\nmkdir $GOPATH\/bin\nexport GOBIN=$GOPATH\/bin\n\nDependencies\n\ngopkg.in\/alecthomas\/kingpin.v2\ngithub.com\/flosch\/pongo2\n\nInstall pongo-blender\nInstall pongo-blender and dependencies.\ncd $GOPATH\/src && git clone https:\/\/github.com\/madedotcom\/pongo-blender && cd pongo-blender && go get && go install .\ngo build\n\nYou now have a static binary called pongo-blender, you can run it anywhere.\nYou can even copy it to \/bin\/ .\nYou can also add this binary to your docker image.\nUsing pongo-blender\nTo use pongo blender you need to have a template, pongo-blender will collect the environmental variables and will render the template using those variables. pongo-blender will output the rendered template to stdout. You can try pongo-blender like this:\n\nCreate a vars file\n\nvim vars\n\nwith something like this\nexport SHOES=\"green\"\nexport CATS=\"cute\"\nexport STATE=\"busy\"\n\n\nCreate a template file with something like this\n\nmy shoes are {{ SHOES }}\nmy cats are {{ CATS }}\nmy state is {{ STATE }}\n\n\nRun pongo-blender passing it values for variables you want set\n\n. vars && pongo-blender template > output\n\n\nThe output file is a complete with your variables and template stuff\n\negidijus@ub-sol:\/tmp\/pongos$ cat output \nmy shoes are green\nmy cats are cute\nmy state is busy\n\n\nUsing pongo-blender with docker-compose\nDocker-compose will add crappy affinity env vars to containers, these var are not very parsable because the keys have colons.\n\nTo fix this we unset all affinity vars in our entrypoint.\nHere is an example entrypoint for docker-registry, the var $PROJECT_NAME is set in the Dockerfile.\nGosu let's you change which user the process is run as.\n#!\/bin\/sh\n\nunset `env | grep affinity | awk -F= '\/^\\w\/ {print $1}' | xargs`\n\/usr\/bin\/pongo-blender \/etc\/pongo-blender\/config.yml.tmpl > \/etc\/docker-registry\/config.yml\n\nchown -R $PROJECT_NAME:$PROJECT_NAME \/etc\/docker-registry\ngosu $PROJECT_NAME docker-registry \/etc\/docker-registry\/config.yml\n\n","325":"Introduction to R\nThis repository contains the documentation, background material, scripts, and data for a tutorial on the Introduction to R. This introductory workshop is geared towards people with a interest\/ background in geography and environmental science.\nInstallation requirements\nThis tutorial requires two things to be installed: The language R and the IDE Rstudio. The downloads can be accessed from the following websites. A variety of packages will be used and will be instaled within the R environment using the command install.packages(\"packagename\").\n\nInstall R from https:\/\/cran.rstudio.com\/\n\nNote: The most current version is 3.6.2 (Dark and Stormy Night, 2019-12-12)\n\nInstall Rstudio from https:\/\/www.rstudio.com\/products\/rstudio\/download\/#download\n\nNote: The most current version is 1.2.5033\nMaterials\nPlease download all files in this respository as they will be needed for the workshop\nAn overview of the workshop material is listed here:\n\nTutorial background information (slides)\n\n\nLecture 1 (intro_to_r.pdf)\nLecture 2 (intro_to_r_lecture2.pdf)\n\n\nR Script files\nData files\n\nExternal resources\nTextbooks for general R use:\n\n\nR in a Nutshell\n\n\nR for Data Science\n\n\nStatistics in R:\n\nChapter 9: R Cookbook\nFor more a more in depth background in Statistics please reference material from my [Introduction to Statistics] (https:\/\/github.com\/kristineccles\/introduction_to_stats) course I previously taught.\nThis is a helpful website for understanding PCA\n\nR Cheatsheets:\nThese cheatsheets are provided by the R community and RStudio, describing common procedures and packages. Good cheatsheets to look at are:\n\n\nBase R\n\n\nData Import\n\n\nDates and Times\n\n\nData Visualization with ggplot2\n\n\nCartography\n\n\n","326":"neutrino\nNeutrino environmental monitoring for home HVAC DIY projects\nWHY?\nNeutrino is designed to be an alternative to a zoned HVAC system, or a supplement to a zoned HVAC system that is relatively easy to implement for people who don't want to retrofit to a fully zoned system. In some ways it may even be better than a zoned system, and more cost effective. It also allows the ability to get into the system and have more control over what's going on than commercial systems offer.\nZoned systems don't always work well. Ideally a zoned system heats and cools more efficiently, but unfortunately limitations in the ability for ductwork to supply airflow often cause the system to open a bypass to relieve pressure. This essentially connects the output to the input, short circuiting the system. While the zone that needs air is getting it, capacity is being wasted. In a traditional single zone system this air would go to other rooms that might not need it at the moment, but probably would eventually be called for. This pressure issue is mitigated somewhat by different blower speeds in the furnace, which means a more expensive zoning system. Further, sometimes zone conflicts cause the system to act non-intuitively, like waiting for the blower to stop for one zone before kicking on a request for another zone.\nSometimes a zoned system is overkill for a structure, or needs a boost for higher accuracy, or someone just wants data. There are many reasons, but in the end we do it because we can!\nNeutrino gives the DIY user an ability to go in and change how it works. First, by giving an average user the ability to fine-tune their system. Just having detailed information on each room is a big bonus, it allows the use to adjust their vent covers appropriately, which can sometimes make all the difference. On top of that, users can choose which sensors for the HVAC system to pay attention to, whether it be one particular room or an average of multiple. In 2014 it doesn't make much sense to drive the HVAC off of the hallway temperature, unless of course you enjoy hanging out in your hallway. It also gives advanced users the ability to go in and change how the system works, by providing an open system.\nHOW?\nIt all starts with sensors. Tiny, inexpensive, battery powered sensors are placed wherever it makes sense to sense the surroundings. This can be on a wall with putty or double-sided tape, on a shelf, etc. Next, sensors are grouped together by the user in software, however they see fit. These groups represent zones, but they don't have to match (for example, a sensor in a room driven by HVAC system A could be included in a sensor group that controls HVAC system B).  Finally, users choose the set hot\/cold set points for the group, and toggle which sensors in the group 'count'. The system will average the values of the sensors that count, whether it be a single sensor or ten sensors.\nWHAT?\nSensors consist of a microcontroller, a temperature\/humidity\/pressure sensor, a 2.4GHz radio, and a battery. They use radio, but not WiFi, as it is not power efficient or inexpensive to implement. Sensors report to sensor hubs via radio. Up to six sensors can be assigned to a single hub. Sensors are assigned an ID (0 through 5) via jumpers.\nSensor hubs are responsible for getting the sensor info into a database, but don't necessarily correspond to sensor groups (a group can span hubs). The hubs currently consist of a Raspberry Pi with a 2.4Ghz radio attached, and software (sensor-listener) that listens on the radio and plugs the output into a mysql database. Up to eight sensor hubs are supported per system, each sensor-listener is assigned a hub id (0-7) via config file, and the sensors themselves are told which hub to report to via a second set of jumpers.\nThen there's the controller. Controllers are a computer and some relays, which control the actual HVAC furnace, AC, humidifier, and blower. The controller software looks into the database for its sensor group's readings, checks it's set points via the controller table, and adjusts the HVAC accordingly.\nFinally, there's a web UI for the user to easily see sensor data, create sensor groups, and set the heating\/cooling points.\nCODE?\nrpi\/sensor-listener: A C++ application for Raspberry Pi. It requires you make\/make install the RF24 library (https:\/\/github.com\/mlsorensen\/RF24\/tree\/master\/librf24-rpi\/librf24), as well as apt-get install mysql and libconfig++ libs. It will start up, read the config file you supply via '-c' flag (see example config), and start listening for the six radios assigned to it. When it gets a message, it puts it into mysql, and optionally publishes to Zabbix via \"Zabbix sender\", under the keys 'neutrino.(sensorid).(hubid).temperature', etc..\narduino: This is the code that runs on the sensor microcontrollers. It also contains schematics for the controllers. It requires you have the arduino IDE and import the arduino-version of the RF24 library (https:\/\/github.com\/mlsorensen\/RF24), the BMP180 library (https:\/\/github.com\/mlsorensen\/BMP180.git), and the RocketScream low power library (https:\/\/github.com\/rocketscream\/Low-Power).\ncontroller: This will be the software that controls the controller\nweb: This will be the UI code\nDEPLOYMENT\nDeployment is currently ad-hoc, but the following may help.\nRunning the sensor hub:\n$ sudo apt-get install daemon\n$ cd ~\/neutrino\/hub\n$ sudo daemon --name sensor-listener --respawn --output=daemon.err -- \/home\/pi\/neutrino\/hub\/sensor-listener -c \/etc\/sensor-listener.cfg\n\nStopping the sensor hub:\n$ sudo daemon --name sensor-listener --stop\n\nRunning the controller:\n$ cd ~\/neutrino\/controller\n$ screen -dmS controller sudo .\/controller -c \/etc\/controller.conf\n\nRunning the web UI:\n$ cd ~\/neutrino\/web\n$ sudo hypnotoad neutrino-webapp\n\nStopping the web UI:\n$ sudo hypnotoad neutrino-webapp -stop\n\n","327":"Python-based Data-centric Integrated Modeling Platform (PyDIMS)\nGoals of this project\n\nData as a model\n\n\nTechnology for building coupled models within the water resource domain has been advancing at a rapid pace.  Many modeling framworks have been developed (e.g. OpenMI, CSDMS, OMS, etc) that control the flow of data between model components during a simulation.  These efforts have largely focused on establishing software interfaces for componentizing scientific calculations such that they can receive input data and supply output data during a simulation.  However, there has been a lack of emphasis on closing the gap between observed and simulated data, and component simulations.  One objective of this project is to investigate how observed and simulation data can be integrated seamlessly into component-based model simulations.\n\n\nCoupled modeling workflow\n\n\nCoupled modeling platforms typically rely upon a single data passing workflow which is defined by a coordination mechanism.  Some utilize a feed-forward approach (e.g. OMS, CSDMS) while others use a pull driven approach (e.g. OpenMI).  Each offers its own benefits, however rarely do we ever encounter a set of models for which a single workflow is ideal. For instance, closed-source models can be coupled with other computations via reading and writing input\/output files, but are unable to interact with others at individual time-steps (unless specifically designed to).  Similarly, sometimes model are coupled along shared boundary conditions which require time-step iterations to converge on a solution.  Therefore, a second objective of this work is to investigate methods for utilizing multiple workflows within a single coupling framework as well as within a single simulation.\n\n\nPlatform and Language Compatibility\n\n\nWithin the water resources community several coupled modeling frameworks exist, however they often writen in different languages (e.g. C#, Python, Java, etc).  Scientists are forced to choose the coupling software that is compatible their models and\/or operating system.  Moreover, many legacy models are written in C, C++, and Fortran which make compatibility more difficult.  A third goal of this project is to investigate how these platform and language compatibility issues can be overcome to build a system that can be adopted by the water resources community.\n\n","328":"SciComm Twitter Hashtag Games\n\nAll your favourite SciComm Twitter hashtag games in one place!\nVIEW PAGE AND MORE DETAILS HERE: https:\/\/natbat.github.io\/scicomm-calendar\/\nThis repository consists of:\n\nThe config file and script which runs on Heroku ever 10mins against the Twitter API to automatically retweet the tweets for the various twitter hashtag games to the account @SciCommGames\nThe source for the url listed above which is hosted on Github pages and embeds a calendar of the games in their various timezones, maintained by hand by @natbat\nImage and asset files for the above website and Twitter account. Awesome logo design by @thonoir.\n\nIf we are missing any Twitter hashtag games that should be added to the Twitter bot, feel free contact @natbat on Twitter or edit the code in the repository on Github with a pull request. https:\/\/github.com\/natbat\/scicomm-calendar\/\nTo get games added to the calendar please contact @natbat on Twitter with the times the competition and answer are posted as well as details of the person who runs it, the hashtag and the timezone\/location of the person who runs it.\nCode for the twitter bot, website as well as the assets etc are released under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 United States (CC BY-NC-SA 3.0 US)\nhttps:\/\/creativecommons.org\/licenses\/by-nc-sa\/3.0\/us\/\n\nby @natbat with help from @simonw and @thonoir with original game data collection by \u202a@WildlifeBioGal\u202c\n","329":"X-NUCLEO-IKS01A3\nThe X-NUCLEO-IKS01A3 is a motion MEMS and environmental sensor expansion board for the STM32 Nucleo.\nIt is equipped with Arduino UNO R3 connector layout, and is designed around the LSM6DSO 3D accelerometer and 3D gyroscope,\nthe LIS2DW12 3D accelerometer, the LIS2MDL 3D magnetometer, the HTS221 humidity and temperature sensor, the LPS22HH\npressure and temperature sensor and the STTS751 temperature sensor.\nThe X-NUCLEO-IKS01A3 interfaces with the STM32 microcontroller or the Arduino boards via the I\u00b2C pin.\nExamples\nThere are several examples with the X-NUCLEO-IKS01A3 library.\n\nX_NUCLEO_IKS01A3_HelloWorld: This application provides a simple example of usage of the X-NUCLEO-IKS01A3\nExpansion Board. It shows how to display on a hyperterminal the values of all on-board MEMS and environmental sensors.\nX_NUCLEO_IKS01A3_LIS2DW12_6DOrientation: This application shows how to use X-NUCLEO-IKS01A3 LIS2DW12 accelerometer\nto find out the 6D orientation and display data on a hyperterminal.\nX_NUCLEO_IKS01A3_LIS2DW12_WakeUpDetection: This application shows how to detect the wake-up event using the\nX-NUCLEO-IKS01A3 LIS2DW12 accelerometer.\nX_NUCLEO_IKS01A3_LSM6DSO_6DOrientation: This application shows how to use X-NUCLEO-IKS01A3 LSM6DSO accelerometer\nto find out the 6D orientation and display data on a hyperterminal.\nX_NUCLEO_IKS01A3_LSM6DSO_FreeFallDetection: This application shows how to detect the free fall event using the\nX-NUCLEO-IKS01A3 LSM6DSO accelerometer.\nX_NUCLEO_IKS01A3_LSM6DSO_Pedometer: This application shows how to use X-NUCLEO-IKS01A3 LSM6DSO accelerometer\nto count steps.\nX_NUCLEO_IKS01A3_LSM6DSO_SingleTap: This application shows how to detect the single tap event using the\nX-NUCLEO-IKS01A3 LSM6DSO accelerometer.\nX_NUCLEO_IKS01A3_LSM6DSO_DoubleTap: This application shows how to detect the double tap event using the\nX-NUCLEO-IKS01A3 LSM6DSO accelerometer.\nX_NUCLEO_IKS01A3_LSM6DSO_TiltDetection: This application shows how to detect the tilt event using the X-NUCLEO-IKS01A3\nLSM6DSO accelerometer.\nX_NUCLEO_IKS01A3_LSM6DSO_WakeUpDetection: This application shows how to detect the wake-up event using the\nX-NUCLEO-IKS01A3 LSM6DSO accelerometer.\nX_NUCLEO_IKS01A3_LSM6DSOX_MLC: This application shows how to detect the activity using the MLC of\nLSM6DSOX accelerometer. In order to use this application STEVAL-MKI197V1 board is needed connected to X-NUCLEO-IKS01A3 via DIL24 interface.\nX_NUCLEO_IKS01A3_STTS751_TemeperatureLimit: This application shows how to detect low temperature and high temperature\nevents using the X-NUCLEO-IKS01A3 STTS751 temperature sensor.\n\nDependencies\nThe X-NUCLEO-IKS01A3 library requires the following STM32duino libraries:\n\nSTM32duino LSM6DSO: https:\/\/github.com\/stm32duino\/LSM6DSO\nSTM32duino LIS2DW12: https:\/\/github.com\/stm32duino\/LIS2DW12\nSTM32duino LIS2MDL: https:\/\/github.com\/stm32duino\/LIS2MDL\nSTM32duino HTS221: https:\/\/github.com\/stm32duino\/HTS221\nSTM32duino LPS22HH: https:\/\/github.com\/stm32duino\/LPS22HH\nSTM32duino STTS751: https:\/\/github.com\/stm32duino\/STTS751\nSTM32duino LSM6DSOX: https:\/\/github.com\/stm32duino\/LSM6DSOX\n\nDocumentation\nYou can find the source files at\nhttps:\/\/github.com\/stm32duino\/X-NUCLEO-IKS01A3\nThe X-NUCLEO-IKS01A3 datasheet is available at\nhttps:\/\/www.st.com\/content\/st_com\/en\/products\/ecosystems\/stm32-open-development-environment\/stm32-nucleo-expansion-boards\/stm32-ode-sense-hw\/x-nucleo-iks01a3.html\n","330":"minilora-test\nMiniLora based environmental sensor testbed\n","331":"Environmental-Monitoring-Rover-using-Intel-Edison\nEnvironmental Monitoring Rover using Intel Edison and Python-Flask\nThis project is inspired by the Mars Curiosity Rover , I don't expect this rover to make it to Mars !! but you mimic it and implement some cool features using the Intel Edison. Having said that ,on mother Earth you can find industrial applications for this, to monitor hazardous condition.\nFor a step by step guide to make something similar refer to the instructable at\nhttp:\/\/www.instructables.com\/id\/Environmental-Monitoring-Rover\/\n\n","332":"Sustainable Communities Web\u00a0Challenge\nSaturday and Sunday, January 23 and 24, 2021\n\nWe're combining economic and envronmental data with planning input using the EPA's new environmental indicator models. Choose an area below to compete for $10,000 in awards using new input-output widgets to create interfaces for communities using 24 environmental indicators across 388\u00a0industries.\n\n\nAbout Event\nRegister Online\nSlack Clubs\n\nProject Areas\n\n\nA. Demographics, Industry Analytics, Impacts and Machine Learning\n\nExpand upon county-based results to provide zipcode-based industry lists. - Details\nAdd zipcode demographics using uszipcode.readthedocs.io. (Python and D3)\nCreate and update data visualizations of the interplay between demographics, industries and impacts.\n\nB. Supply Chain Inflow-Outflow Charts\n\nUpdates to Sankey D3 Charts, Leaflet Maps with Maps for Us and Filters for Industry Impact Evaluator\nCreate embeddable charts that use hash parameters (Python and D3, optionally React) - Details\n\nC. Industry Level Estimates for Counties and Zipcodes\n\nFill in gaps when only the number of establishments is provided at the state level - Details\nUpdate Data Processing Script, work with Team A on zipcode industry data prep. (Python)\n\nD. USEEIO Updates for bioecomony and bioproducts\n\nLocal economy inputs and new technology additions to USEEIO - Details\n\nE. Google Sheet Crowdsource Editor\n\nA REST process allowing editors to return and update their own row contributions. (see below)\n\nContact us for additional details and to avoid overlaps.  Document your team's times to help the judges award your contributions and as a basis for you to reward the team members who contribute the most.\nSpecific Coding Areas\nCompliment broad areas above with specific coding area updates.\nHTML and JQuery - JAM Stack Development\n\n\nEmbed and customize chart displays using the EE Input-Output widgets\n\n\nBuild location profiles using the Industry Impact Evaluator.\n\n\nAdd to map search filters, apply industry icons to charts, or integrate map samples.\n\n\nUpdate USEEIO widgets to embed in Resource and Event Calendars for environmental educators.\n\n\nReact and Node.js\n\n\nUpdates to the USEEIO-widgets - React and D3\n\n\nUpdate CSV files on employment and industries for D3 charts using Census industry data and income by zipcode (zcta).\n\n\nWork with our data team to choose a JAMstack Editor to edit CSV files directly on GitHub using social logins.\n\n\nD3 Visualizations and Leaflet Maps\n\n\nVisualizations of material flow and regional input-output.\n\n\nMap starters and Leaflet route maps for driving tours and deliveries.\n\n\nPython and R-Language\n\n\nCreate and update scripts that pull data and pre-process into csv and json files for industry zip code searches and local commodity searchs.\n\n\nWork with the USEEIO API and update Input-Output charts. Widgets are loaded from JSON files generated from\nour API endpoints on AWS for Goods & Services demand vectors (Food System and Full System).\n\n\nUpdate Django Census Reporter by staring with the Python 3 Wazimap fork used in Africa and India. Integrate US demographic data from Python 2 version. Set up Docker to deploy to Heroku using a containerization template. Learn more about using Heroku or AWS.\n\n\nRStudio and USEEIOR - Use LCA methodology to evaluate new technologies including advanced biofuels\n\n\nMicrosoft .NET\nAdd USEEIO widgets to .NET Environmental Education tools for GEEP partner states and countries.\nGoogle REST App\n\nGoogle Sheet Editor for crowdsourcing updates. Code for America Brigades often use Google Sheets to maintain directories, like these maps: Georgia and North Carolina. A social login process is needed to allow contributors to return and update their own Google sheet row data through an online form, without having access to edit rows of other contributors. The set-up needs to take only a minute per sheet, so avoid Zapier or other time-intensive approaches.\n\n\nSpecific Project Tasks\nMaintain a list of your time contributions to increase your award potential!\nLet us know what you're working on to avoid overlaps.\nBubble Chart\nD3 - View Widget\n\nModify so popups still appear when the containing div is set to position:relative.\nScale to size of containing div during browser resize.\nSet the default bubble color to red for more pop.\nOmit red from the scale when other bubbles are highlighted.\nCreate React version.\n\nIndustry-List and Mosaic\nReact - View Widget - Details\n\nWhen column selected, avoid dimming other columns.\n\n  \n- Add [sliders](https:\/\/material-ui.com\/components\/slider\/) to right of rows to adjust levels for multiplier effect - DONE.  \n- Include tabs at top: 20 categories, 388 industry sectors, X selected - [mock up](start\/dataset\/)\n- Show list of selected sectors under \"X selected\" tab. Include duplicate checkboxes in \"X selected\" tab.  \n- Display parent NAICS industry categories that open to reveal subcategories\n- Display the quantity selected after each parent category title in parenthesis\n- Custom sets could use the same csv\/json format.\n\nToggle matrices using a dropdown menu to select a matrix\nList by parent category.\nInclude a 3-dot menu with the options: Sort alphabetical, Change matrix, Show values\nShow values like sortable example\nInclude verticle column name like dataset example\nHighlight an \"Action\" menu when checkboxes are clicked\nActions could include: Display on map, Display bar chart, Generate Report\n\nSlider Details\nThe editable number could appear when clicking the slider.\nThe editable number could disappear after a few seconds of inactivity.\nThe slide bar could replace the bar currently to the right of the rows.\nThe dot could be relative to the other rows, matching how you have the bar length.\nThe bar could turn green when a commodity has been increased from its default.\nThe bar could turn red when a commodity has been decreased from its default.\nThe sliders will be used to show multiplier effects.\nThe hash syntax for a 99% and 300% adjustment could be:\nsectors=311615:99,550000:300\nImpact Bar Chart\nReact - View Widget - Details\n\nCreate an example with three columns and one impact area per colums.\nDisplay sector titles to the left of the first column.\nDisplay sector name over each bar.\nDisplay description of each indicator\nUpdate for use with Darkly bootstrap, similar to bubble chart - click bubble to view impact chart.\n\nLast Airbender\nFor potential use in an elementary school education interface, the EPA indicators could be organized by Air, Water, Land, and Fire (Energy), plus two additional categories: Prosperity (Economy) and Wellness (Health).\nThe Airbender categories have been added as Primary and Secondary columns in LCIA_Indicator_sets.csv and in the Bio-Modeling Branch.\nHere\u2019s an Airbender API for relating the four \u201cnation\u201d categories to characters.\nUse of BEA commodities to estimate null industries\nTo protect the privacy of individual firms, the census omits payroll and empolyee count data for some industries at both the state and county level (like Automobile Manufacturing).  For Georgia, there are 89 industries with only the number of establishments available at both the county and state lever.\nThe estimates for these omitted industry values could be generated using the state BEA commodity data with the crosswalk file, or an average from other states could be used (as long as each industry has at least one payroll value in another state).\n##Data Integration\n\n\nUS Bureau of Economic Analysis - expand on the industry level data in our Community Info Page.\n\n\nUpdates for Farm Fresh - Federal USDA location data on maps - initially merged for Aglanta.\n\n\nPreprocess the uszipcode programmable database (Python) - Github with zip map.\n\n\nInternational Harmonized System (HS) code crosswalk\n\n\n\n\nAbout Event\nRegister Online\nSlack Groups\n\n\n","333":"Environmental monitoring and control\nThis is the software component of a basic system I created for myself\nto monitor and control the pre-season started seedlings I grow. It\nruns on a Raspberry Pi Model B with a camera module and (currently)\ntwo arduino (compatible) things.\nAs it stands, this stuff \"works for me\". The reason I put it here is\nto force myself to clean it up a bit.\nServer\nThis contains a python BaseHTTPServer based web server providing\naccess to the camera as well as the arduino frontends via a simple web\ninterface. It is configured via web.conf. To use\nit, simply run tree.py. By default, it will bind to\nport 8008, enforce Basic Auth and then return nothing but 404s, it\nneeds handlers to be specified in the web.conf to be useful.\ndot-plug\nBits of configuration, templates and pictures. Most of these are for\nthe web server component, but any other config goes in here as well.\nArduinoFrontends\nBoth the arduinos are used by multiple systems outside of the web\nfrontend, so there needed to be a layer between them and those\nclients to avoid serial contention. They're pretty basic.\nSketches\nSpeaking of arduino, the sketches for them are here.\nmrtg\nMy mrtg config and the client script for the sensor which feeds mrtg.\nInstallation\nMinimum requirements for this to be useful are a raspberry pi with a\ncamera module. The web.conf for this setup looks like this:\n[baseconfig]\nparallel: threading\nport: 8008\n\n[auth]\nmodule: Authenticator\nuser: aber\npwd: lour\n\n[handler:camera]\nmodule: CameraHandler\ncamera: Camera\nresolution: 1024x768\nThis lets you access a 1024x768 snapshot at server:8008\/camera\/ with a\ntimestamp on it after authenticating with user \"aber\" and password\n\"lour\".\n","334":"The Open Source Environmental Sensors (OSES) project\nThis project, based on the Arduino and Launchpad \/ Energia platforms, aims to develop an autonomous and modular station able to collect and upload to the web, in real time or near real time, data acquired by a wide range of environmental sensors.\nThe goals of the project are :\n\ncreate a modular station on which may be plugged various environmental sensors such as weather and air quality meters\ndesign an easy to assemble station using low-cost and easy to obtain components and modules\nbuild an energetically autonomous station, powered by the sun or other renewable energies\nbuild a connected station which can upload, in realtime or near realtime via GPRS or other long range wireless technologies, data to a web server\nembed a GPS module and a RTC clock in order to know exactly where the station is, and what time is it, when it uploads its data\n\nHardware and schematics\nThe schematics and bill of materials required to assemble the current prototype can be found in the \"hardware\" directory.\nCode and libraries\nThe code of the station controller can be found in the arduino-sketch directory. Take also a look at the librairies\/librairies-installation.txt for a quick guide on how to download and install the required librairies.\n","335":"UAV-Environmental-Monitoring\n\u65e8\u5728\u5229\u7528\u65e0\u4eba\u673a\u4e3a\u8f7d\u4f53\uff0c\u901a\u8fc7\u673a\u8f7d\u7684\u6e29\u6e7f\u5ea6\u4f20\u611f\u5668\uff0cpm25\u4f20\u611f\u5668\u53ca\u6444\u50cf\u5934\u7b49\u83b7\u53d6\u76ee\u6807\u5730\u70b9\u7684\u73af\u5883\u6570\u636e\uff0c\u4ee5\u65b9\u4fbf\u5b9e\u65f6\u76d1\u6d4b\u73b0\u573a\u73af\u5883\u60c5\u51b5\u3002\nWiKi\n","336":"\ud83d\ude80 Create-Env \ud83d\ude80\n    \n\ncreate-env is an utility to help you create .env files based on CI\/CD environmental values.\nUse case\nYou use Gitlab-CI\/CD or another CI\/CD to perform a build of a software artifact and you want to use the provided CI\/CD secret variables as a .env file. This is where create-env comes to the rescue.\nHow it Works\nYou have defined your secret-variables inside of the CI\/CD, and your variables uses a prefix like DEV_, TEST_, PROD_. create-env will take the current environment for your CI\/CD pipeline, a prefix related to that environment, and the name of the file you want as output.\nThen, it will generate that .env file, and remove the prefix of each secret-variable.\ne.g:\n\nYour secret-variables:\n\nTEST_NODE_ENV=production\nTEST_PORT=8080\n\nYour .env file output:\n\nNODE_ENV=production\nPORT=8080\nInstallation\ncreate-env needs to be installed as a global dependency:\nNPM\nnpm i -g create-env\nYARN\nyarn global add create-env\nCreating a .env file\nTo create a .env file you have to run create-env with the following parameters:\n# Default\ncreate-env --env-file .env --env-prefix TEST_\n\n# NPX\nnpx create-env --env-file .env --env-prefix TEST_\ncreate-env comes with a set of default prefixes (DEV_, TEST_, PROD_), if your secret-variables use those default prefixes, you can run create-env with the following parameters, the only thing your have to pass is the env which can be one of development, testing or production:\n# Default\ncreate-env --env testing --env-file .env --use-default-prefix\n\n# NPX\nnpx create-env --env testing --env-file .env --use-default-prefix\nTODO\n\n Add --from-template option. (In order to support .env generation based on another .env file).\n Add --no-prefix option. (In order to support generate a .env file with all the env variables).\n Add --type option. (In order to support other formats like JSON envs).\n Add --help option.\n\nIssues\nIf you raise a bug, please, open an issue.\nContributing\nPRs are welcome. Any kind of contribution is welcome.\nLicense\ncreate-env is licensed as MIT.\n","337":"homebridge-ble-environmental-sensor\nhomekit environmental sensor via BLE\n","338":"\n\n\n\nEnvStats\nThis is the development place for R-package EnvStats\nAuthor: Steven P. Millard\nMaintainer: Alexander Kowarik\n","339":"CZ Manager\n\nCZ Manager is a Django admin app for Observation Data Model 2 (ODM2). ODM2\nwas created through National Science Foundation Grant\u00a0EAR-1224638.\nSupport for the development of this application comes\nfrom NSF Grant EAR-1331841 Luquillo CZO.\nODM2 can be found here: https:\/\/github.com\/ODM2\nDjango models exist for all ODM2 tables. Forms for ODM2Core and\na number of additional ODM2 tables. Graphing of measurement result\nvalues via highcharts are implemented. Data logger files can be\nimported as long as data logger file columns and results are properly\nsetup.\nOther ODM2 tools can be used in conjunction with CZ Manager, extensive\ntesting has been done using CZ Manager with ODM2PythonAPI and WOFpy.\nThis was developed using a postgresql version of\nODM2 data model, additional modifications may be needed to make this\nwork with MSSQL or another database.\nAn example postgresql database named ODM2AdminExamplePostgresqlDB is\nprovided, this is a custom postgresql format backup which can be\nrestored to an empty database. An extrasql.sql file contains some extra\nviews used for efficiently exporting data as emails.\nPrimary Installation\nSee Docker Folder for dockerhub installation instructions or\nsee http:\/\/odm2.github.io\/CZ-Manager\/ for local installation instructions.\n","340":"CZ Manager\n\nCZ Manager is a Django admin app for Observation Data Model 2 (ODM2). ODM2\nwas created through National Science Foundation Grant\u00a0EAR-1224638.\nSupport for the development of this application comes\nfrom NSF Grant EAR-1331841 Luquillo CZO.\nODM2 can be found here: https:\/\/github.com\/ODM2\nDjango models exist for all ODM2 tables. Forms for ODM2Core and\na number of additional ODM2 tables. Graphing of measurement result\nvalues via highcharts are implemented. Data logger files can be\nimported as long as data logger file columns and results are properly\nsetup.\nOther ODM2 tools can be used in conjunction with CZ Manager, extensive\ntesting has been done using CZ Manager with ODM2PythonAPI and WOFpy.\nThis was developed using a postgresql version of\nODM2 data model, additional modifications may be needed to make this\nwork with MSSQL or another database.\nAn example postgresql database named ODM2AdminExamplePostgresqlDB is\nprovided, this is a custom postgresql format backup which can be\nrestored to an empty database. An extrasql.sql file contains some extra\nviews used for efficiently exporting data as emails.\nPrimary Installation\nSee Docker Folder for dockerhub installation instructions or\nsee http:\/\/odm2.github.io\/CZ-Manager\/ for local installation instructions.\n","341":"Environmental\nSmart environment loading\n","342":"Environmentalist\nCleans up your PHP environment by managing include paths, error handlers, and autoloading\nInstallation\nIf you're using composer simply add the einstein\/environmentalist dependency to your composer.json file.\nOtherwise you can manually install it by cloning the repository somewhere in your php include_path.\ngit clone git@github.com:einstein\/environmentalist.git`\nrequire 'environmentalist\/environmentalist.php';\n\nUsage\nEnabling\/disabling\nEnvironmentalist::enable() is called when loaded. If you'd like to disable its behavior, simply call Environmentalist::disable().\nAutoload extensions\nEnvironmentalist::autoload_extensions()\nEnvironmentalist::append_autoload_extension($extension)\nEnvironmentalist::prepend_autoload_extension($extension)\nEnvironmentalist::set_autoload_extensions($extensions)\n\nError handlers\nEnvironmentalist::error_handlers()\nEnvironmentalist::append_error_handler($handler)\nEnvironmentalist::prepend_error_handler($handler)\nEnvironmentalist::set_error_handlers($handlers)\n\nInclude paths\nEnvironmentalist::include_paths()\nEnvironmentalist::append_include_path($path)\nEnvironmentalist::prepend_include_path($path)\nEnvironmentalist::set_include_paths($paths)\n\nTesting\nEnvironmentalist tests require jaz303\/ztest\nSimply download it to environmentalist\/test\/ztest (or anywhere else in your PHP include_path), then run test\/run\nTodo\n\nUpdate README documentation\nAllow other filename naming conventions to be registered\nStandardize the return values of the set_* methods\nUpdate tests\n\n","343":"Environmental-Data-Analysis\nA Project for Environmental Science and Computer Science.\nFirst Step\nI have a script for Python spider to copy PM2.5 data from a website and store the data into MySQL.\nI also record the daily data of my local weather.\nSecond Step\nUse Android app to upload data.\nUse PHP to upload data.\nUse Qt5, OpenCV and other technologies to analysis the photo and video which was taken by myself.\n\u5929\u77e5\u9053\n\u73af\u7403\u540c\u6b64\u51c9\u70ed\u4e3b\u9898\u66f2\n\u90a3\u65f6\u5019\n\u521a\u6709\u6708\u4eae\n\u7425\u73c0\u91cc\u7684\u8774\u8776\u548c\u873b\u8713\n\u6b63\u98de\u821e\u7fc5\u8180\n\u5954\u8dd1\u7684\u725b\n\u8fd8\u9700\u8981\u5f88\u4e45\n\u624d\u88ab\u753b\u5230\u5899\u58c1\u4e0a\n\u5929\u77e5\u9053\u7b2c\u4e00\u7c92\u7a3b\u8c37\n\u6210\u719f\u5728\u54ea\u4e00\u4e2a\u79cb\u5929\u7684\u665a\u4e0a\n\u5929\u77e5\u9053\u7948\u7977\u4e00\u573a\u96e8\n\u9700\u8981\u628a\u591a\u5c11\u989c\u8272\u6d82\u5728\u8138\u5e9e\n\u5929\u77e5\u9053\u6709\u7ea2\u5c18\u4e07\u4e08\n\u4f1a\u5269\u4e0b\u51e0\u5c3a\u5e18\u5e55\u548c\u6c5f\u5c71\n\u5929\u77e5\u9053\u90a3\u5149\u9634\u4f3c\u7bad\n\u4f1a\u5c04\u4e2d\u8c01\u7684\u80f8\u819b\u548c\u68a6\u60f3\n\u672c\u9879\u76ee\u76ee\u7684\n\u73af\u7403\u540c\u6b64\u51c9\u70ed\uff0c\u4f60\u6211\u5171\u540c\u611f\u53d7\n","344":"ESP8266-Environmental-Monitor\nESP8266 with DHT22\/11 for Environmental Monitoring with data logging to remote web server (PHP) and database (MySQL)\nThis is a repository sharing code used on a series of ESP8266 microcontrollers with DHT22\/11 temperature and humidity sensors, analog sensors and\/or distance sensors which then connect over WiFi to your PHP server and inserts the data into your MySQL server.\nSome more detail on how I used this for fun projects around the house here:\nhttps:\/\/www.freelearner.how\/2017\/09\/24\/environmental-monitoring-cheap-esp8266-temperature-humidity-etc\/\nA note on security with this project - in the example code I use HTTP Get variables and connect unsecured over HTTP.  While this might be okay for a small environment over a secure network it's NOT a good plan for an enterprise solution!  The process to re-use this code for an enterprise solution would be to leverage HTTPS, and use variables that are easier to secure (i.e. Post rather than Get).\n","345":"Westerhoff.Configuration.EnvironmentAliases\n\nA configuration provider for Microsoft.Extension.Configuration that reads configuration values from environment variables according to a mapping to configuration paths. This does essentially the same as Microsoft.Extensions.Configuration.EnvironmentVariables except that not all (prefixed) environments variables are loaded but just the ones that are explicitly mapped to a configuration path. In addition, this allows to use aliases for more complex configuration paths.\nInstructions\nTo use this configuration provider, call the AddEnvironmentAliases extension method on an IConfigurationBuilder. For example, when using ASP.NET Core, call the ConfigureAppConfiguration method on the web host builder to add the provider:\npublic static IWebHostBuilder CreateWebHostBuilder(string[] args) =>\n    WebHost.CreateDefaultBuilder(args)\n        .ConfigureAppConfiguration(config => {\n\n            config.AddEnvironmentAliases(new Dictionary<string, string>\n            {\n                [\"APP_DATABASE\"] = \"ConnectionStrings:Default\",\n                [\"APP_NUMBER\"] = \"Settings:Number\",\n                [\"LOGGING_VERBOSITY\"] = \"Logging:LogLevel:Default\",\n            });\n\n        })\n        .UseStartup<Startup>();\n\nAfterwards, environment variables APP_DATABASE, APP_NUMBER and LOGGING_VERBOSITY can be used to configure the values at the specified configuration paths.\n","346":"Oneshot Learning with Siamese Networks for Environmental Audio\nThe purpose of this reposirory is to provide a working example of a oneshot learning implementation utilizing siamese networks for environmental audio classification. This code was done as part of a BSc thesis at Tampere University and can be found here.\nTable of contents\n\nDependencies\nDataset\nModel\nHow to use\n\nDependencies \n\nKeras\nHyperopt\nLibROSA\nscikit-learn\nMatplotlib\n\nDataset \nFor this example script, the ESC-50 dataset is used. The dataset is available here: ESC-50\nClone the repository to the root of this repository, or alternative change the data path variable in main.py or parameter_optimization.py\nModel \nThe model consists of two convolutional input networks, followed by\na merging layer and a final output layer. The input networks share the same architecture\nand weights in order to act as identical encoding layers for both inputs. This also\nmeans that the weights are updated simultaneously for both networks during training.\nThe basic idea of the model is illustrated below.\n\nHow to use \nDownload ESC-50 and move it to the root of this repository (or change the data path variable in main.py or parameter_optimization.py)\nTrain and evaluate a siamese network\n\nRun main.py. The script should start by setting up the environment, reading audio files and calculating a mel-log scaled spectrogram for each audio sample. The spectra are then saved for future, i.e. the next time the script is run the spectra are not required to be calculated.\nNext, the script will start the training procedure. If a previously saved model is found, the training is continued from that. By default 40 classes are used for training, 5 for validation and 5 for evaluation. Change the split size at the start of the script to experiment with different splits. Batch size is a limiting factor here (change if needed), since a single training sample consists of two spectra. Negative-to-positive ratio refers to the ratio between different pairs and similar pairs, since the number of negative pairs can be made significantly higher than positive pairs. The actual training is done inside a for-loop, where a model is trained for a single epoch and validated with the one-shot task. Early stopping and best model checkpoint are also implemented here.\nFinally, the results for the evaluation are calculated, visualized and saved to results folder.\n\nHyperparameter optimization\nCurrently the default parameters for a siamese network instance are set to previously optimized parameters. If additional optimization is desired (e.g. for new parameters), parameter_optimization.py can be executed.\n\nRun parameter_optimization.py. The script should start fitting a model to parameters chosen from the parameter space defined at the top of the file.\nAfter training, the model is evaluated using validation data. The one-shot classification score is used as the optimized objective. The next parameters will be chosen based on previous iterations. Additionally, the current state of the optimizer is saved. If a saved state is found at the start of a new iteration, it is loaded and continued from.\nThe best parameters so far are saved after each iteration. The optimization can be stopped at any point, and the current best parameters can be loaded from checkpoint folder.\n\n","347":"EPA_Environmental_Dataset_Gateway\nThe EPA Environmental Dataset Gateway (EDG) is an open-source metadata catalog built on Esri's Geoportal Server.\nThis repository contains the code for the core https:\/\/edg.epa.gov\/metadata website as well as several ancillary Tomcat webapps.\nEPA Disclaimer\nThe United States Environmental Protection Agency (EPA) GitHub project code is provided on an \"as is\" basis and the user assumes responsibility for its use. EPA has relinquished control of the information and no longer has responsibility to protect the integrity, confidentiality, or availability of the information. Any reference to specific commercial products, processes, or services by service mark, trademark, manufacturer, or otherwise, does not constitute or imply their endorsement, recomendation or favoring by EPA. The EPA seal and logo shall not be used in any manner to imply endorsement of any commercial product or activity by EPA or the United States Government.\n","348":"Monitoring Environmental Rehabilitation\nCode produced as an outcome of the Perth Hack for Good: Monitoring Environmental Rehabilitation.\nThe purpose of the hack was to produce a skeleton solution that could be evolved over time to include more features with the ultimate aim of submitting the application to the main mobile app stores.\nBuilding an Architecture with a Rainbow Pen!\n\nEvent Detials\nThe Perth Hack for Good is about getting a group of like-minded people together to solve a real world problem and learn some skills in a collaborative way.\nHosted by Microsoft the hackathon will begin on Friday evening where we state the problem, meet our team mates and brainstorm ideas. On Saturday we will spend the day collaborating and coding and by the end we hope to have a skeleton solution that can be open sourced to allow ongoing development.\nWe welcome anyone to the event, some knowledge of coding and web or mobile development is certainly encouraged but the main emphasis is on having fun and learning new skills.\n","349":"Monitoring Environmental Rehabilitation\nCode produced as an outcome of the Perth Hack for Good: Monitoring Environmental Rehabilitation.\nThe purpose of the hack was to produce a skeleton solution that could be evolved over time to include more features with the ultimate aim of submitting the application to the main mobile app stores.\nBuilding an Architecture with a Rainbow Pen!\n\nEvent Detials\nThe Perth Hack for Good is about getting a group of like-minded people together to solve a real world problem and learn some skills in a collaborative way.\nHosted by Microsoft the hackathon will begin on Friday evening where we state the problem, meet our team mates and brainstorm ideas. On Saturday we will spend the day collaborating and coding and by the end we hope to have a skeleton solution that can be open sourced to allow ongoing development.\nWe welcome anyone to the event, some knowledge of coding and web or mobile development is certainly encouraged but the main emphasis is on having fun and learning new skills.\n","350":"\nbinford\nThis package contains datasets used in:\n\nBinford, Lewis R. 2001. Constructing Frames of Reference: An Analytical Method for Archaeological Theory Building Using Ethnographic and Environmental Data Sets University of California Press, Berkeley.\n\nThis package contains three datasets:\n\nLRB: environmental and hunter-gatherer data used in Binford's book\nLRBfact: equal to LRB except code values are represented by their label, rather than the code\nLRBkey: key to the LRB data frame\n\nThe data were obtained from Amber Johnson's website on 31 Jul 2016: http:\/\/ajohnson.sites.truman.edu\/data-and-program\/\n","351":"This package constitutes an interactive R problem set based on the RTutor package (https:\/\/github.com\/skranz\/RTutor).\n--- A RTutor problem set to interactively calculate and analyze environmental damages from driving electric cars, following the article \"Are There Environmental Benefits from Driving Electric Vehicles? The Importance of Local Factors\" By Stephen P. Holland, Erin T. Mansur, Nicholas Z. Muller, and Andrew J. Yates (2016) ---\n1. Installation\nTo install all required packages run the following code in your R console.\ninstall.packages(\"RTutor\",repos = c(\"https:\/\/skranz-repo.github.io\/drat\/\",getOption(\"repos\")))\n\nif (!require(devtools)) install.packages(\"devtools\")\ndevtools::install_github(\"felsti\/RTutorECars\", upgrade_dependencies=FALSE)\n2. Show and work on the problem set\nTo start the problem set first create a working directory in which files like the data sets and your solution will be stored. Then adapt and run the following code.\nlibrary(RTutorECars)\n\n# Adapt your working directory to an existing folder\nsetwd(\"C:\/problemsets\/RTutorECars\")\n# Adapt your user name\nrun.ps(user.name=\"Jon Doe\", package=\"RTutorECars\", \n  auto.save.code = TRUE,clear.user = FALSE)\nIf everything works fine, a browser window should open, in which you can start exploring the problem set.\n","352":"Citywide Dashboard\nThis project was developed as part of the Oberlin Environmental Dashboard. It is an animated display of current electricity use, water use and environmental conditions in the entire community. See the live version\nThere are two components to the Citywide-Dashboard: the front-end animated display, and the back-end customization page.\nInstallation\nTo install the dashboard, simply download this repository and upload to your server. Your sever should be able to run PHP, because it is utilized to store the custom preferences and authenticate users. Navigate to index.php to view the default dashboard.\nCustomization\nFirst, open up prefs\/config.php and set your custom username and password. Then, open prefs\/ in a web browser and log in. You should be presented with a preferences page like this.\nAll the preferences are stored in the prefs.json file once saved. The preferences page is basically just a fancy way to edit the json file. If you feel comfortable editing the prefs.json file directly, you may do so.\nMessages\nThis should be pretty intuitive. These \"messages\" are the text at the top of the dashboard. The dashboard will cycle through each \"message section\" on the left, and will (for example) only display \"Weather\" messages when the \"Weather\" mode is active on the dashboard.\nTiming\nThese options are explained on the preferences page.\nLandscape Components\nThese refer to the images on the dashboard landscape. This will allow you to customize the appearance of the dashboard to match your own community! For example, if you wanted to substitute the big buildings on the center left, you would edit the \"The Town of Oberlin\" component. Try changing the \"Image URL\" to \"cleveland_city.gif\".\nAlternative images for landscape components should be uploaded to the img\/ folder. Then, change the \"Image URL\" to reference them. If you need to tweak the location or size of the new image, use the \"Custom Image\" positioning and sizing fields.\nGauges\nThese gauges are pulled from the buildingos.com \"Building Blocks\" functionality. Once you create your \"building blocks\" on the buildingos.com platform, you should be able to plug their \"Gauge ID\" into here.\nWe currently can't detect how tall a gauge is, so you will have to determine how much space to give it by hand. The live preview should help with this.\nYou can also give some additional description information to display when the user hovers over the gauge.\nDeveloper Notes\nThe Front-end\nThe front-end page (index.php) is run with jQuery and svg.js. It is a giant svg, mostly with pngs and vector shapes animated around inside. To read more about how it works, read this docco page.\nRead the docco page because it has valuable vocab information! ;^)\nThe Back-end\nThis \"prefs page\" is run with React (the javascript library that Facebook uses for user interfaces). I am building the React app in the prefsReactJS\/ folder, and then copying the compiled files into the prefs\/ folder for deployment. I realize this is a clunky process, and I need to figure out a better workflow.\nTo compile the React app from the code in prefsReactJS\/src\/components, navigate to prefsReactJS\/ on a command line. Run \"npm run dist\".\nRelevant reading about React:\nIntro to React:\n\nhttps:\/\/facebook.github.io\/react\/docs\/tutorial.html\nhttp:\/\/facebook.github.io\/react\/docs\/thinking-in-react.html\n\nUsing React with Forms:\n\nhttps:\/\/facebook.github.io\/react\/docs\/forms.html\nhttps:\/\/facebook.github.io\/react\/docs\/two-way-binding-helpers.html\nhttp:\/\/n12v.com\/2-way-data-binding\/\n\nUsing styled form components: (for tabs etc)\n\nhttps:\/\/react-bootstrap.github.io\/\n\nHow I've installed React:\n\nhttps:\/\/github.com\/newtriks\/generator-react-webpack\n\nThis one last one is how I've installed React. I used this \"yeoman generator,\" to initially set up the basic file structure and install the requirements. To view, navigate to \/prefsReactJS in terminal and run \"npm start.\" Then navigate to localhost:8000\/webpack-dev-server\/index.html\nTodo List\nFall 2015:\n\nAdd credits on prefs page (yay)\nFinish prefs data serialization in ReactJS (this is basically the \"Add inverse data flow\" step of \"Thinking in React,\" involves using two-way binding helper valueLink)\n\nMessage probabilities need row key for state tabs (weird bug)\nConvert string data back into ints\nLandscape components tab\nGauges tab\nAdd and remove rows from tables\n\n\nPrefs data saving and connect to CWD front-end\nPackage up and write installation docs\nNon-clunky workflow for bridging React and PHP\n\nThe future:\n\nW Steve: Connect gauge levels API to front-end dashboard\nDevelop extra prefs functionality\n\nMax and min for probabilities\nRename landscape components to \"Landmark Icons\"\nExtra columns for messages\n\nStart date and end date\nDisplay on kiosk\/web\n\n\nLive preview for gauges\nLive preview for landscape components\n\"Button Labels\" settings in Timing Tab\n\n\nMultiple users functionality\nPut within wordpress?\n\nCan the react prefs page be dropped within the wordpress backend?\n\n\nUse webpack with front-end\nModularize front-end\nSmall fixes on front-end\n\nAjax loading for prefs and svg\nSwitch mode to \"none\" by clicking on active state button at the top\n#houseinside hover works with clickables\nFix font display (we want futura!)\n\n\n\n","353":"Environmental\/Economic Electric Power Dispatch by NSGA-II\n1 Algorithm shared Library\n\nDevelpoment Environment: Windows 64, Visual Studio 2015: Visual Studio 2015 Project\n\n1.1 NSGA-II shared Library\n\n\nThis shared  Library is based on the NSGA-II (Non-dominated Sorting Genetic Algorithm) riginal code in C from:\nDr. Kalyanmoy Deb: http:\/\/www.iitk.ac.in\/kangal\/\n\n\n1.2 Environmental-Economic Electric Power Dispatchshared  Library\n\n\nThis shared Library is based our NSGA-II shared  Library for developing the applications\naround Environmental-Economic Electric Power Dispatch\n\n\n2 Example with Python\n\n\nPython 3.5\n\n\nPython packages\uff1a Numpy  Matplotlib Tornado\n\n\nThe standard IEEE six-generator 30-bus test system\n\nM.A. Abido. A novel multiobjective evolutionary algorithm for environmental\/economic power dispatch, Electric Power Systems Research. (65):71-81 , 2003,\uff09\n\nis used to demonstrate the effectiveness of our shared Library\n\n\n2.1 Example of API with Python: PythonExample\n\nRun\n\n>python biobjloaddispatch.py\nfrom ctypes import *\nimport numpy as np\nimport pylab as plt\n\nclass nsga2cfg(Structure):\n    _fields_ = [(\"nreal\",c_int),\n                (\"nobj\",c_int),\n                (\"ncon\",c_int),\n                (\"popsize\",c_int),\n                (\"ngen\",c_int),\n                (\"pcross_real\",c_double),\n                (\"pmut_real\",c_double),\n                (\"eta_c\",c_double),\n                (\"eta_m\",c_double)]\n          \nclass curvecoff(Structure):\n    _fields_ = [(\"c\",c_float*3),\n                (\"e\",c_float*5)]\n\nclass unitload(Structure):\n    _fields_ = [(\"min\",c_float),\n                (\"max\",c_float),\n                (\"coff\",curvecoff)]\n\nclass loadv(Structure):\n    _fields_ = [(\"xreal\",c_float*10),\n                (\"cobj\",c_float),\n                (\"eobj\",c_float)]\n\nload_min =[0.05,0.05,0.05,0.05,0.05,0.05]\nload_max = (c_double*6)()\nload_max =[1.5,1.5,1.15,1.5,1.5,1.5]\n\nc=[[10,200,100],\n   [10,150,120],\n   [20,180,40],\n   [10,100,60],\n   [20,180,40],\n   [10,150,100]]\n\ne = (c_double*6*5)()\ne=[[4.091,-5.554,6.490,2.0e-4,2.857],\n   [2.543,-6.047,5.638,5.0e-4,3.333],\n   [4.258,-5.094,4.586,1.0e-6,8.000],\n   [5.426,-3.550,3.380,2.0e-3,2.000],\n   [4.258,-5.094,4.586,1.0e-6,8.000],\n   [6.131,-5.555,5.151,1.0e-5,6.667]]\n\nmydll=windll.libseu_biobjloaddispatch\nf=mydll.seu_biobjloaddispatch\n\nunitnum=c_int()\ntotalload=c_double()\nga=nsga2cfg()\npopsize=c_int()\nbestC=loadv()\nbestE=loadv()\nbest=loadv()  \n\nunitnum=6\n\nuload=(unitload*unitnum)()\nfor i in range(unitnum):\n   uload[i].min = load_min[i]\n   uload[i].max = load_max[i]\n   for j in range(3):\n     uload[i].coff.c[j]=c[i][j]\n   for j in range(5):\n     uload[i].coff.e[j]=e[i][j] \n\nga.nreal=unitnum\nga.nobj=2\nga.ncon=1\nga.popsize=200\nga.ngen=200\nga.pcross_real=0.9\nga.pmut_real=0.1\nga.eta_c=20\nga.eta_m=15\n\nx = (POINTER(c_double) * ga.popsize)()\nfor i in range(ga.popsize):\n    x[i] = (c_double * ga.nreal)()\n    \nobj = (POINTER(c_double) * ga.popsize)()\nfor i in range(ga.popsize):\n    obj[i] = (c_double *ga.nobj)()\n\ntotalload=2.834\n\nf(ga,unitnum,uload,c_double(totalload),byref(x),byref(obj),byref(popsize),byref(bestC),byref(bestE),byref(best))\n\nprint('--bestC--')\nprint(bestC.cobj)\nprint(bestC.eobj)\nprint('--load--')\nfor i in range(ga.nreal):\n    print(bestC.xreal[i]*100)\n\nprint('--bestE--')\nprint(bestE.cobj)\nprint(bestE.eobj)\nprint('--load--')\nfor i in range(ga.nreal):\n    print(bestE.xreal[i]*100)\n    \nprint('--best--')\nprint(best.cobj)\nprint(best.eobj)\nprint('--load--')\nfor i in range(ga.nreal):\n    print(best.xreal[i]*100)\n\n# print('--pareto--cobj')\nc=np.zeros(shape=(ga.popsize))\nfor i in range(ga.popsize):\n   c[i]=obj[i][0]\n#  print(obj[i][0])\n   \n# print('--pareto--eobj')   \ne=np.zeros(shape=(ga.popsize))\nfor i in range(ga.popsize):\n   e[i]=obj[i][1]\n#   print(obj[i][1])\n\nbc=np.zeros(shape=(1))\nbc[0]=best.cobj\nbe=np.zeros(shape=(1))\nbe[0]=best.eobj\n   \nplt.plot(c,e,'b+',label='Pareto')\nplt.plot(bc,be,'ro',label='Best')\nplt.minorticks_on()\nplt.xlabel('c($\/h)')\nplt.ylabel('e(t\/h)')\nplt.show()\n\n2.2  Example of Web application: WebAppExample](.\/WebAppExample)\nThe simple Web application is based Tornado\n\nRun\n\n>python app.py\n\n3 PPT Chinese\n\n\nThis PPT is designed for introduce our shared  library and it's application\nat Chinese Undergraduate Computer Design Contest 2014\n\n\n4 Award:\n\n\n1st Prize of 7th China Undergraduate Computer Design Contest in Jiangsu Province\n\n\n3rd Prize of 7th China Undergraduate Computer Design Contest\n\n\n5 License\nMIT\n","354":"ecolab-alimentation\nEnvironmental data (14 criteria) from agribalyse DB v3\n","355":"ALog-BottleLogger\nThe ALog BottleLogger is an Arduino-based low-power field environmental data logging platform.\nThis repository contains hardware design files, centered around:\n\nElectronic schematics\nCircuit board layouts\n\nIn addition, the following are supplied, but are not always kept up-to-date in the main branch:\n\nBill of materials (electronic components)\nGerber files for circuit board production\nPick-and-place files\n\nLayout Overview for End-Users\n\n","356":"I want to start gardening, but I knew I wouldn\u2019t keep up the regular schedule of watering the plants and making sure that they remain healthy. So, I recruited a micro-controllers and suite of sensors to help with this tasks.Watering is the most important cultural practice and most labour intensive task in daily gardening operation. Watering systems ease the burden of getting water to plants when they need it. Knowing when and how much to water is two important aspects of watering process. To make the gardener works easy, the automatic plant watering system is created. Smart Garden is a plant environmental monitoring system. It monitors the soil moisture, air temperature, and air humidity of your plant(s) and automatically waters the plant based on the data received by sensors. Other than that functionalties like Artificial Sunlight and Camera to keep view on plants can also be added. Thingspeak and Blynk application is used to view those  sensor data from remote location. With the help of blynk app, notification service can also be added.\n","357":"Open Plantbot\nBecause growing plants is hard work and nobody ain't got no time for that anymore. This project was started after I managed to kill a plant my mother got me for my birthday last year because it was \"unkillable\". Ha.\nThis project aims to build an open source tool that provides environmental sensors for regular house plants as well as hydroponic systems.\nMonitoring can either be done locally or via a \"cloud\" or not at all with add-on ports for pumps and future expansions (or your own?).\nThe goal is to eventually provide a block-based programming interface so that even people who don't enjoy writing C code (tzzz...who doesn't? :P) can customise their plantbot to do what they want.\nCurrent specs\nHere is a list of current specs with notes about how they integrate\/ work\n1x Wifi enabled microprocessor\n\nCan be programmed via RX\/TX serial lines\nUSB\/ OTA programming will be added later\n\n4x Analog sensor mounts (for temperature, soil moisture, light, ...)\n\nVariable gain amplifier can be used on a per-channel basis\nSignal offset results in optimal reading per sensor type\n\n2x I\u00b2C expansion ports for additional sensors or expansions\n16-pin shield header for user (or future) expansion boards\nLow-power sleep mode for the entire board\/ expansion circuitry\nCurrent state\nThe board was re-designed recently in Rev A2. Prototypes were ordered and partially assembled. Further testing on the board layout and circuit design needs to be performed.\nThe firmware is largely unwritten.\nFollowing are some pictures. Enjoy :)\n\n\n\n","358":"Bosch Integrated Environmental Unit\nCommon Unified Sensor API for supported IEU chips.\n\n\n\n\n\n\n\n\nProvides full feature access to all supported chips (bmp280 bme280 bme680 bmp388) while still providing rich chip specific features (multiple heater profiles and fifo access).\nTested with these products:\n\nAdafruit BMP280\nAdafruit BME280\nAdafruit BME680\nAdafruit BMP388\n\n(note: Adafruit no-longer sells the bmp085 or bmp180, donation of legacy chips are welcome to aid in greater product support)\n\ud83d\udcd0 Example Usage\n\ud83d\udd27 API\nThe API is organized around simple sensor class BoschSensor which provides an object interface for manipulating the sensor.  All method return a Promise.\nA simple demo usage follows.\nconst i2c1 = await i2c.openPromisified(1);\nconst addressedI2C1 = new I2CAddressedBus(i2c1, 0x77);\nconst sensor = await BoschIEU.sensor(addressedI2C1);\nawait sensor.detectChip();\nawait sensor.calibration();\nconst result = await sensor.measurement();\n\ud83d\udcd8 BoschIEU\n\ud83d\udcc4 sensor(addressedBus)\nA static factory method to provide access to the BoschSensor class.\n\ud83d\udcd8 BoschIEU Sensor\n\ud83d\udcc4 detectChip()\nAfter constructing a sensor object, the detectChip method is recommended as it will attempt to (get this) detect which version of the chip to use for further register interactions.\nsensor.detectChip()\n   .then(() => { if(sensor.valid()) ... })\nAlternatively, if you are you wish to set the chip during initialization that is also possible\n   \/\/ sensor.chipId = Chip.bmp388\n\ud83d\udcc4 id()\nReturns the chips id as defined by the vendor. This is only valid after a chip has been detected (valid() returns true)\n(note that legacy id() call will internal run detectChip() for now...)\nsensor.id()\n   .then(id => console.log('sensors Id', id);\n\ud83d\udcc4 calibration()\nFetches the calibration constants from the chip.  These values are unique for each chip and needed to perform compensation of the raw data values into temperature and pressure readings.\nNote: This must be called before the measurment call will return valid results.\nNote: The method itself caches results in the class and is not needed externally (though returned for user inspection)\n\ud83d\udcc4 fifo()\nThe fifo getter method returns a static Fifo class implementation. This provides a namespace for fifo functionality.\nsensor.fifo.flush( ... ).then(...)\n\ud83d\udcc4 profile()\nReturns current chip profile from the device.\n\ud83d\udcc4 setProfile(profile)\nSets the profile for the chip.\nNote: This will set the entire profile, if fields are not included in profile they will be set to the defaults for the Chip.\n\ud83d\udcc4 reset()\nWrite a soft-reset to the chip.  Returning it to power-on state.\nsensor.reset().then( ... )\n\ud83d\udcc4 measurement(...)\nReads and calculates related measurement data from the Chip.\nsensor.measurement().then(results => {\n  \/\/ process results\n});\n\ud83d\udcd8 Fifo\n\ud83d\udcc4 flush()\nFlushes the fifo buffer using command register.\n\ud83d\udcc4 read()\nReads the current fifo buffer in full (as specified by size) and parses and compensates frame data.\n\ud83d\udcd8 Converter\nConverter class of common helps are included (ft to meters, altitude from Pa, etc)\n","359":"Aethera\nAethera is a framework for creating DIY environmental sensor networks for awareness and art.\n","360":"UV-badge\nProject site on hackaday.io https:\/\/hackaday.io\/project\/4706-uv-badge\nTwitter: @xLabzNet\n","361":"gfer\n\n\nInstallation\nReleased version from CRAN, for beginners and normal users:\ninstall.packages(\"gfer\")\nDevelopment version from github, for experienced users and those who are interested in investigating:\ninstall.packages(\"devtools\")\n# You can ignore the line above, if you have already installed devtools\ndevtools::install_github(\"Yuanchao-Xu\/gfer\")\nOfficial Website is http:\/\/yuanchao-xu.github.io\/gfer\ngfer is an R package, designed for green finance and environmental risk research. Focuses on data collecting and analyzing in green finance and environmental\nrisk research and analysis. Main function includes environmental data collecting from\nofficial websites like MEP (Ministry of Environmental Protection of China, http:\/\/www.mep.gov.cn), water\nrelated projects identification and environmental data visualization.\nIf you feel gfer is of a little help, please cite it as following:\nYuanchao Xu (2017). gfer: Green Finance and Environmental Risk. R package version 0.1.6.\nhttps:\/\/CRAN.R-project.org\/package=gfer\n","362":"ViroCon: viroconweb\n\n\nViroCon is a software to compute environmental contours.\n\nAbout\nviroconweb is a package belonging to the software ViroCon. Using the web\nframework Django it provides a browser-based graphical user interface.\nViroCon helps you to design marine structures, which need to withstand load\ncombinations based on wave, wind and current. It lets you define extreme\nenvironmental conditions with a given return period using the environmental\ncontour method.\nThe following methods are available in viroconweb (additonal methods are\navailable in viroconcom):\n\nFitting a probabilistic model to measurement data using maximum likelihood\nestimation\nDefining a probabilistic model with the conditonal modeling approach (CMA)\nComputing an environmental contour using either the\n\ninverse first order reliability method (IFORM) or the\nhighest density contour (HDC) method\n\n\n\nViroCon is written in Python 3.6.4. The software is seperated in two main\npackages, viroconweb and viroconcom. This is the repository of viroconweb,\nwhich is a web application written with the web framework Django 1.11.\nThe second package, viroconcom, handles the statistical computations and\nhas its own repository.\nHow to use ViroCon\nRequirements\nMake sure you have installed\n\nPython 3.6.4\n(even Python 3.5 won't work; consider using the python version management pyenv)\ngit and\nLaTeX.\n\nInstall\nTo run a copy of ViroCon locally fist clone the repository by typing\ngit clone https:\/\/github.com\/virocon-organization\/viroconweb\n\nin your shell.\nThen install all required python packages and prepare the web-application. Type\ncd viroconweb\npip install -r requirements.txt\npython manage.py collectstatic\npython manage.py migrate\n\nin your shell.\nUsage\nNow everything should be set up and you can run a local copy by running\nmanage.py and using 'runserver' as the argument. Type\npython manage.py runserver\n\nin your shell. You should reach a local version of ViroCon at\nhttp:\/\/localhost:8000\nIf you don't want to work with viroconweb's graphical userer interface, but\nwant to compute environmental contours with Python, use the package we\nbuilt for the needed statistical computations,\nviroconcom.\nDocumentation\nCode. The code's documentation can be found\nhere.\nMethods. The app has a help page, which describes the implemented methods in\ndetail. If you runt he app it can be found at http:\/\/localhost:8000\/info\/help.\nIts template is located\nhere.\nPaper. Our SoftwareX paper\n\"ViroCon: A software to compute multivariate extremes using the environmental\ncontour method.\" provides a concise description of the software.\nContributing\nThere are various ways you can contribute. You could\n\nimprove the code,\nimprove the documentation,\nadd a feature or\nreport a bug or an improvement and leave it to us to implement it.\n\nIssue. If you spotted a bug, have an idea for an improvement or a new\nfeature please open a issue. Please open an issue in both cases: If you want to\nwork on in yourself and if you want to leave it to us to work on it.\nFork. If you want to work on an issue yourself please fork the repository,\nthen develop the feature in your copy of the repository and finally\nfile a pull request to merge it into our repository.\nConventions. In our Contribution Guide\nwe summarize our conventions, which are consistent with PEP8.\nCite\nIf you are using viroconweb in your academic work please cite it by referencing\nour SoftwareX paper.\nExample long: Environmental contours were computed using the package viroconweb\nof the software ViroCon (viroconweb version 1.0.8, viroconcom version 1.2.0) [1].\nExample short: Environmental contours were computed using the software ViroCon [1].\n[1] A.F. Haselsteiner, J. Lemkuhl, T. Pape, K.-L. Windmeier, K.-D. Thoben:\nViroCon: A software to compute multivariate extremes using the environmental\ncontour method. Accepted by SoftwareX.\nLicense\nThis software is licensed under the MIT license. For more information, read the\nfile LICENSE.\n","363":"SHEDS GIS Data\nThis repository contains scripts used to generate the supporting data used on\nthe Spatial Hydro-Ecological Decision System (SHEDS). The\nproject page describes each of\nthe datasets created in this repository.\n","364":"environmental\n\n\n\n\n\n\n\n\nMap a python configuration from environment variables.\n\nOverview\nenvironmental allows you to map class properties to environment variables.\nBy using  environmental you can keep your configuration in a single class your IDE understands and have convenient\nand safe type conversions between the strings stored in your environment and python types.\nThe created properties are also writable so if you assign to them they will change on your environment and will be\navailable to your child processes.\n\nInstallation\n$ sudo pip3 install --upgrade environmental\n\nExample\nimport environmental\nimport os\n\nclass Configuration:\n    port = environmental.Int('MY_APPLICATION_HTTP_PORT', 80)\n    name = environmental.Str('MY_APPLICATION_NAME', 'Name')\n\nconfig = Configuration()\nconfig.port = 8080\nassert os.environ['MY_APPLICATION_HTTP_PORT'] == '8080'\nassert isinstance(os.environ['MY_APPLICATION_HTTP_PORT'], str)\nassert config.port == 8080\nassert isinstance(config.port, int)\n\nCaveats\nModifying mutable objects in the configuration (like lists) will not work:\nimport os, environmental\nclass Configuration:\n    list = environmental.List('LIST')\n\nos.environ['LIST'] = \"[]\"\nassert config.list == []\nconfig.list.append('test')\nassert config.list == []\nBut doing something that reassigns the variable will:\nconfig.list += ['test']\nassert config.list == ['test']\n\nLicense\nCopyright 2015 Zalando SE\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\nhttp:\/\/www.apache.org\/licenses\/LICENSE-2.0\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n","365":"Environmental\nEnvironmental Proof in Column for Politecnico di Torino\n","366":"Environmental\nEnvironmental Proof in Column for Politecnico di Torino\n","367":"Envizo\nEnvizo is an app to increase visibility of environmental issues as a community in NYC.\nLive-version\n\nMotivation\nWe care about the environment, and we wanted to create an app to encourage users to change their habits by increasing visibility.\nWe believe that if users see their impact, they will be empowered to act and engage with their communities.\nFeatures\n\nInteractive visualization of the environmental issue.\nPersonal impact prediction component.\nJoin your community and subscribe to GreenNYC suggested goals.\nUpload photo as a testament to improved habits (ex. Reusable grocery bag) to reach a target goal.\nPersonal and Community Activity feed.\nSocial media sharing of your progress.\nCommunity progress bar and personal contributions.\n\nTechnologies\nFront-end:\nRedux, React, CSS, HTML, D3, React-materialize, MaterializeCSS, AJAX. \nBack-end:\nexpress, Node.js, Postgres, SQL, AWS, pg-promise, passport, bcrypt.\n","368":"environmental\nProject setup\nnpm install\n\nCompiles and hot-reloads for development\nnpm run serve\n\nCompiles and minifies for production\nnpm run build\n\nLints and fixes files\nnpm run lint\n\nCustomize configuration\nSee Configuration Reference.\nenvironmental\n","369":"\nFine Particulate Matter CAAQS Analysis for B.C. (2014-2016)\nA set of R scripts to calculate the Canadian Ambient Air Quality Standards (CAAQS) for fine particulate matter (PM2.5) for 2014-2016. These scripts reproduce the 2017 analysis presented on Environmental Reporting BC.\nThis analysis makes use of the rcaaqs package, and air quality monitoring data from the B.C. Ministry of Enviornment.\nUsage\nThere are four core scripts that are required for the analysis, they need to be run in order:\n\n01_load.R - downloads the data from DataBC\n02_clean.R - cleans and prepares data for analysis\n03_analysis.R - performs the analysis\n04_output.R - creates maps and graphs and saves outputs\n\nThe run_all.R script can be sourceed to run it all at once.\nMost packages used in the analysis can be installed from CRAN using install.packages(), but you will need to install envreportutils, rcaaqs and bcmaps using devtools:\ninstall.packages(\"devtools\") # If you don't already have it installed\n\nlibrary(devtools)\ninstall_github(\"bcgov\/rcaaqs\")\ninstall_github(\"bcgov\/bcmaps\")\ninstall_github(\"bcgov\/envreportutils\")\nGetting Help or Reporting an Issue\nTo report bugs\/issues\/feature requests, please file an issue.\nHow to Contribute\nIf you would like to contribute, please see our CONTRIBUTING guidelines.\nPlease note that this project is released with a Contributor Code of Conduct. By participating in this project you agree to abide by its terms.\nLicense\nCopyright 2015 Province of British Columbia\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at \n\n   http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nThis repository is maintained by Environmental Reporting BC. Click here for a complete list of our repositories on GitHub.\n","370":"\nFine Particulate Matter CAAQS Analysis for B.C. (2014-2016)\nA set of R scripts to calculate the Canadian Ambient Air Quality Standards (CAAQS) for fine particulate matter (PM2.5) for 2014-2016. These scripts reproduce the 2017 analysis presented on Environmental Reporting BC.\nThis analysis makes use of the rcaaqs package, and air quality monitoring data from the B.C. Ministry of Enviornment.\nUsage\nThere are four core scripts that are required for the analysis, they need to be run in order:\n\n01_load.R - downloads the data from DataBC\n02_clean.R - cleans and prepares data for analysis\n03_analysis.R - performs the analysis\n04_output.R - creates maps and graphs and saves outputs\n\nThe run_all.R script can be sourceed to run it all at once.\nMost packages used in the analysis can be installed from CRAN using install.packages(), but you will need to install envreportutils, rcaaqs and bcmaps using devtools:\ninstall.packages(\"devtools\") # If you don't already have it installed\n\nlibrary(devtools)\ninstall_github(\"bcgov\/rcaaqs\")\ninstall_github(\"bcgov\/bcmaps\")\ninstall_github(\"bcgov\/envreportutils\")\nGetting Help or Reporting an Issue\nTo report bugs\/issues\/feature requests, please file an issue.\nHow to Contribute\nIf you would like to contribute, please see our CONTRIBUTING guidelines.\nPlease note that this project is released with a Contributor Code of Conduct. By participating in this project you agree to abide by its terms.\nLicense\nCopyright 2015 Province of British Columbia\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at \n\n   http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nThis repository is maintained by Environmental Reporting BC. Click here for a complete list of our repositories on GitHub.\n","371":"CAFE_NODE\nTo see detailed information about CAFE, please check the wiki page.\nYou can also see check this paper describing the whole system.\nBefore your Installation\nNotice: This package should be installed on the server-side. Data archives need to be read from this server. As the function of this package is limited by some other external applications, a Linux environment is required. To ensure the node work correctly, following applications have to be installed before your installation:\n1.\tMySQL Server and Client (http:\/\/dev.mysql.com\/downloads\/mysql\/5.6.html#downloads )\nsudo apt-get install mysql-server mysql-client  #For Ubuntu user\nsudo service mysql start #open mysql service\nNote: To ensure the correct connection to the database, you may have to modify the file \/etc\/mysql\/my.cnf and annotate the row starts with bind-address.\nMysql 5.7 added ONLY_FULL_GROUP_BY in sql mode, this may cause failure in filtering data in Home>>Search section. To disable this in sql mode, you can add\nsql_mode = \"STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION\"\n\nunder [mysqld] part in \/etc\/mysql\/my.cnf (or the first .cnf mysql uses) then restart mysql and tomcat service.\n2.\tJDK\nWarning: You may have to configure environment variables as below.\n##java\nexport JAVA_HOME=\/usr\/local\/java\/jdk1.7.0_51\nexport JRE_HOME=${JAVA_HOME}\/jre\nexport CLASSPATH=.:${JAVA_HOME}\/lib:${JRE_HOME}\/lib\nexport PATH=${JAVA_HOME}\/bin:$PATH\n(CAFE_NODE uses javax.annotation, which seemes to be deprecated in jdk9 and 11, and maven has announced to discontinue to support TLS v1.1 in java 1.7. So java 1.8 is good to go now)\n3.\tTomcat 7 (http:\/\/tomcat.apache.org\/download-70.cgi )\nsudo apt-get install tomcat7     #For Ubuntu user\nAfter installing Tomcat, you have to start tomcat by \"sh tomcat\/bin\/startup.sh\"\nand create a tomcat user by modifying the file \"tomcat\/conf\/tomcat-users.xml\"\nNote:You can refer to (http:\/\/tomcat.apache.org\/tomcat-7.0-doc\/manager-howto.html#Configuring_Manager_Application_Access) for more details about configuring Tomcat managers.\n4.\tNCL 6.1.2 or higher version (https:\/\/www.earthsystemgrid.org\/dataset\/ncl.630.html  )\nWarning: To ensure the node work correctly, we highly recommend you to install NCL in the default directory \/usr\/local\/ncl and set the environment variable as NCARG_ROOT=\/usr\/local\/ncl\n5.\tCDO 1.6.4 or higher version (Climate Data Operator, https:\/\/code.zmaw.de\/projects\/cdo\/ )\nsudo apt-get install cdo       #For Ubuntu user\nwe highly recommand you to use annaconda to install the latest version using command \"\u2018conda install -c conda-forge nco\".\n6.\tNCO\uff08NetCDF Operator, http:\/\/nco.sourceforge.net\/ \uff09\nsudo apt-get install nco       #For Ubuntu user\nwe highly recommand you to use annaconda to install the latest version using command \"\u2018conda install -c conda-forge cdo\".\n7.\tnetcdf library (optional, http:\/\/www.unidata.ucar.edu\/downloads\/netcdf\/index.jsp )\nsudo apt-get install netcdf-bin       #For Ubuntu user\nwe highly recommand you to use annaconda to install the latest version of netcdf4 using command \"\u2018conda install -c conda-forge netcdf4\".\n8.\tMaven. \uff08http:\/\/maven.apache.org\/download.cgi \uff09\nsudo apt-get install maven       #For Ubuntu user\nBefore your installation, you could set the parameters in the configuration file to ensure the application work correctly.You could modify this file \/config\/src\/main\/resources\/baseResources\/config.properties and set the values of four parameters. The default setting is as follows:\n1.\tTempFolder=\/usr\/local\/cmip5_tmp\/               #The folder stores temp files\n2.\tncl_path=\/usr\/local\/ncl\/bin\/ncl                #The installation path of NCL\n3.\tncl_env=NCARG_ROOT=\/usr\/local\/ncl              #The environment variable of NCL\n4.\tScriptFolder=\/usr\/local\/nclscripts\/            #The folder stores analytic scripts\nAs a beginner, you need to download default analytic scripts CAFE_SCRIPTS and place all the scripts in nclscripts folder to the ScriptFolder so that you could later make use of these analytic functions.\nPAY ATTENTION: Since this version only support CF-compliant netCDF files, you may have to reorganize the file names and directories of your data to the specific structure. You may have to refer to this site to reorganize your data archive: http:\/\/cmip-pcmdi.llnl.gov\/cmip5\/output_req.html  A software has been provided for reorganization in this web page.\nWhen all the preparations are done, you could begin to set up this package.\nInstallation procedures\n1.\tDatabase preparation.\nYou have to create a user for your database system using mySQL root account, obtain your ip address {jdbc.host},database access port {jdbc.port},database user name {jdbc.user} and password of the database user {jdbc.password}\ne.g. CREATE USER 'username'@'%' IDENTIFIED BY 'password'; \nNote: To ensure the database can be connected using ip and from remote servers, '%' should be used.\n2.\tCreating a database.\nCreate a database then grand privileges to the database user {jdbc.user} created in step 1 and obtain the database name {jdbc.database}\ne.g. # if the name of your database called CAFENODE, then jdbc.database=CAFENODE\n     # if your username is guest, password is '123456', then jdbc.user=geust, jdbc.password=123456\n     # you can enter mySQL using command line 'mysql -u guest -p', then use following codes.\n     GRANT all privileges ON CAFENODE.* TO 'username'@'%'\n     FLUSH PRIVILEGES;\nNote: To ensure the database can be connected using ip and from remote servers, '%' should be used.\n3.  Creating database tables.\nThe path of initiation script is: db-init\/src\/main\/resources\/init.sql\nYou should first enter the directory db-init\/src\/main\/resources of the CAFE-NODE source code folder.\nThen You have to enter mySQL using command line mysql -u {username} -p, use the database in step2 and run this script.\nuse {jdbc.database}\nsource init.sql;\n4.  Packaging.\nYou have to enter the root directory of CAFE_NODE folder.\nThen you could use following command to compile the codes and generate a .war package:\nmvn clean package -Dmaven.test.skip=true -Djdbc.host=${jdbc.host} -Djdbc.port=${jdbc.port} -Djdbc.database=${jdbc.database} -Djdbc.user=${ jdbc.user} -Djdbc.password=${jdbc.password} -DlogDir=${logDir}\nNote:the .war package is under datamanager-web\/target\/\nyou have to replace ${} to the parameters in step1 and step2, for example:\nmvn clean package -Dmaven.test.skip=true -Djdbc.host=101.100.101.100 -Djdbc.port=3306 -Djdbc.database=CAFENODE -Djdbc.user=abc -Djdbc.password=123456 -DlogDir=\/usr\/local\/CAFE\/log \n# ${logDir} is your log directory for CAFE. If this directory does not exit, have to create it first.\n5.  Deploying the war package under the Tomcat.\nYou could rename the .war package and place it under tomcat\/webapps. Then you have to start Tomcat service. The name of the war package will determine the access path of the web application. For example, if the name of the war package is datamanager-worker.war, then after deployment, the access address will be http:\/\/{host}:{port}\/datamanager-worker\nNote:{host} is the ip address of the node, and {port} is tomcat port. You can also use tomcat management webpage to deploy the package.\n6.  Choosing deployment mode.\nYou could access this web page\uff08http:\/\/{host}:{port}\/{war package name}\/web\/deployment\uff09 to choose deployment mode. Generally, in a complete infrastructure, there are one central node and several worker nodes, all the worker nodes are peer-to-peer.\nNote:the root path of your Node is \/{war package name}, for example, if your war name is datamanager-worker.war, the root path will be datamanager-worker. The {port} is the port of Tomcat. Here you can also deploy the worker node as a local node, (then configure server accesss in cafe_portal configuration, change ip address to localhost)\n7.  Data indexing.\nFor worker nodes, you could access the web page http:\/\/{host}: {port}\/{war package name}\/web\/parser, input the root folder of the data archive mounted on the node server and submit the form from the webpage, the data in this node will then be indexed automatically. The information of the data will be synchronously updated locally and remotely. You will be redirected to http:\/\/{your-workernode}\/datamanager-web-worker\/web\/parser\/run and see {\"success\":true} if successful.\n  An example of data path configuration:\n\n\n In this case, you can configure the path as `\/CMOR\/node2`\n\n","372":"CAFE_NODE\nTo see detailed information about CAFE, please check the wiki page.\nYou can also see check this paper describing the whole system.\nBefore your Installation\nNotice: This package should be installed on the server-side. Data archives need to be read from this server. As the function of this package is limited by some other external applications, a Linux environment is required. To ensure the node work correctly, following applications have to be installed before your installation:\n1.\tMySQL Server and Client (http:\/\/dev.mysql.com\/downloads\/mysql\/5.6.html#downloads )\nsudo apt-get install mysql-server mysql-client  #For Ubuntu user\nsudo service mysql start #open mysql service\nNote: To ensure the correct connection to the database, you may have to modify the file \/etc\/mysql\/my.cnf and annotate the row starts with bind-address.\nMysql 5.7 added ONLY_FULL_GROUP_BY in sql mode, this may cause failure in filtering data in Home>>Search section. To disable this in sql mode, you can add\nsql_mode = \"STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION\"\n\nunder [mysqld] part in \/etc\/mysql\/my.cnf (or the first .cnf mysql uses) then restart mysql and tomcat service.\n2.\tJDK\nWarning: You may have to configure environment variables as below.\n##java\nexport JAVA_HOME=\/usr\/local\/java\/jdk1.7.0_51\nexport JRE_HOME=${JAVA_HOME}\/jre\nexport CLASSPATH=.:${JAVA_HOME}\/lib:${JRE_HOME}\/lib\nexport PATH=${JAVA_HOME}\/bin:$PATH\n(CAFE_NODE uses javax.annotation, which seemes to be deprecated in jdk9 and 11, and maven has announced to discontinue to support TLS v1.1 in java 1.7. So java 1.8 is good to go now)\n3.\tTomcat 7 (http:\/\/tomcat.apache.org\/download-70.cgi )\nsudo apt-get install tomcat7     #For Ubuntu user\nAfter installing Tomcat, you have to start tomcat by \"sh tomcat\/bin\/startup.sh\"\nand create a tomcat user by modifying the file \"tomcat\/conf\/tomcat-users.xml\"\nNote:You can refer to (http:\/\/tomcat.apache.org\/tomcat-7.0-doc\/manager-howto.html#Configuring_Manager_Application_Access) for more details about configuring Tomcat managers.\n4.\tNCL 6.1.2 or higher version (https:\/\/www.earthsystemgrid.org\/dataset\/ncl.630.html  )\nWarning: To ensure the node work correctly, we highly recommend you to install NCL in the default directory \/usr\/local\/ncl and set the environment variable as NCARG_ROOT=\/usr\/local\/ncl\n5.\tCDO 1.6.4 or higher version (Climate Data Operator, https:\/\/code.zmaw.de\/projects\/cdo\/ )\nsudo apt-get install cdo       #For Ubuntu user\nwe highly recommand you to use annaconda to install the latest version using command \"\u2018conda install -c conda-forge nco\".\n6.\tNCO\uff08NetCDF Operator, http:\/\/nco.sourceforge.net\/ \uff09\nsudo apt-get install nco       #For Ubuntu user\nwe highly recommand you to use annaconda to install the latest version using command \"\u2018conda install -c conda-forge cdo\".\n7.\tnetcdf library (optional, http:\/\/www.unidata.ucar.edu\/downloads\/netcdf\/index.jsp )\nsudo apt-get install netcdf-bin       #For Ubuntu user\nwe highly recommand you to use annaconda to install the latest version of netcdf4 using command \"\u2018conda install -c conda-forge netcdf4\".\n8.\tMaven. \uff08http:\/\/maven.apache.org\/download.cgi \uff09\nsudo apt-get install maven       #For Ubuntu user\nBefore your installation, you could set the parameters in the configuration file to ensure the application work correctly.You could modify this file \/config\/src\/main\/resources\/baseResources\/config.properties and set the values of four parameters. The default setting is as follows:\n1.\tTempFolder=\/usr\/local\/cmip5_tmp\/               #The folder stores temp files\n2.\tncl_path=\/usr\/local\/ncl\/bin\/ncl                #The installation path of NCL\n3.\tncl_env=NCARG_ROOT=\/usr\/local\/ncl              #The environment variable of NCL\n4.\tScriptFolder=\/usr\/local\/nclscripts\/            #The folder stores analytic scripts\nAs a beginner, you need to download default analytic scripts CAFE_SCRIPTS and place all the scripts in nclscripts folder to the ScriptFolder so that you could later make use of these analytic functions.\nPAY ATTENTION: Since this version only support CF-compliant netCDF files, you may have to reorganize the file names and directories of your data to the specific structure. You may have to refer to this site to reorganize your data archive: http:\/\/cmip-pcmdi.llnl.gov\/cmip5\/output_req.html  A software has been provided for reorganization in this web page.\nWhen all the preparations are done, you could begin to set up this package.\nInstallation procedures\n1.\tDatabase preparation.\nYou have to create a user for your database system using mySQL root account, obtain your ip address {jdbc.host},database access port {jdbc.port},database user name {jdbc.user} and password of the database user {jdbc.password}\ne.g. CREATE USER 'username'@'%' IDENTIFIED BY 'password'; \nNote: To ensure the database can be connected using ip and from remote servers, '%' should be used.\n2.\tCreating a database.\nCreate a database then grand privileges to the database user {jdbc.user} created in step 1 and obtain the database name {jdbc.database}\ne.g. # if the name of your database called CAFENODE, then jdbc.database=CAFENODE\n     # if your username is guest, password is '123456', then jdbc.user=geust, jdbc.password=123456\n     # you can enter mySQL using command line 'mysql -u guest -p', then use following codes.\n     GRANT all privileges ON CAFENODE.* TO 'username'@'%'\n     FLUSH PRIVILEGES;\nNote: To ensure the database can be connected using ip and from remote servers, '%' should be used.\n3.  Creating database tables.\nThe path of initiation script is: db-init\/src\/main\/resources\/init.sql\nYou should first enter the directory db-init\/src\/main\/resources of the CAFE-NODE source code folder.\nThen You have to enter mySQL using command line mysql -u {username} -p, use the database in step2 and run this script.\nuse {jdbc.database}\nsource init.sql;\n4.  Packaging.\nYou have to enter the root directory of CAFE_NODE folder.\nThen you could use following command to compile the codes and generate a .war package:\nmvn clean package -Dmaven.test.skip=true -Djdbc.host=${jdbc.host} -Djdbc.port=${jdbc.port} -Djdbc.database=${jdbc.database} -Djdbc.user=${ jdbc.user} -Djdbc.password=${jdbc.password} -DlogDir=${logDir}\nNote:the .war package is under datamanager-web\/target\/\nyou have to replace ${} to the parameters in step1 and step2, for example:\nmvn clean package -Dmaven.test.skip=true -Djdbc.host=101.100.101.100 -Djdbc.port=3306 -Djdbc.database=CAFENODE -Djdbc.user=abc -Djdbc.password=123456 -DlogDir=\/usr\/local\/CAFE\/log \n# ${logDir} is your log directory for CAFE. If this directory does not exit, have to create it first.\n5.  Deploying the war package under the Tomcat.\nYou could rename the .war package and place it under tomcat\/webapps. Then you have to start Tomcat service. The name of the war package will determine the access path of the web application. For example, if the name of the war package is datamanager-worker.war, then after deployment, the access address will be http:\/\/{host}:{port}\/datamanager-worker\nNote:{host} is the ip address of the node, and {port} is tomcat port. You can also use tomcat management webpage to deploy the package.\n6.  Choosing deployment mode.\nYou could access this web page\uff08http:\/\/{host}:{port}\/{war package name}\/web\/deployment\uff09 to choose deployment mode. Generally, in a complete infrastructure, there are one central node and several worker nodes, all the worker nodes are peer-to-peer.\nNote:the root path of your Node is \/{war package name}, for example, if your war name is datamanager-worker.war, the root path will be datamanager-worker. The {port} is the port of Tomcat. Here you can also deploy the worker node as a local node, (then configure server accesss in cafe_portal configuration, change ip address to localhost)\n7.  Data indexing.\nFor worker nodes, you could access the web page http:\/\/{host}: {port}\/{war package name}\/web\/parser, input the root folder of the data archive mounted on the node server and submit the form from the webpage, the data in this node will then be indexed automatically. The information of the data will be synchronously updated locally and remotely. You will be redirected to http:\/\/{your-workernode}\/datamanager-web-worker\/web\/parser\/run and see {\"success\":true} if successful.\n  An example of data path configuration:\n\n\n In this case, you can configure the path as `\/CMOR\/node2`\n\n","373":"Environmental\nsome web-site page\nsample of this site was one of a plurality of layouts in web-dev resources.\nI implemented the menu, slogan, two-column content and uncomplicated footer in this project.\n","374":"Environmental\nsome web-site page\nsample of this site was one of a plurality of layouts in web-dev resources.\nI implemented the menu, slogan, two-column content and uncomplicated footer in this project.\n","375":"eLENS Miner System\n\n\n\n\nThe eLENS miner system retrieves, processes and analyzes legal documents and maps them to specific geographical areas.\nThe system follows the microservice architecture and is written in Python 3. It consists of the following microservices:\n\n\nDocument Retrieval. The service responsible for providing documents based on the user's query. It leverages query expansion to improve the query results.\n\n\nDocument Similarity. This service calculates the semantic similarity of the documents and can provide a list of most similar documents to a user selected one. Here, we integrate state-of-the-art methods using word and document embeddings to capture the semantic meaning of the documents and use it to compare the documents.\n\n\nText Embeddings. The service is a collection of text embedding methods. For a given text it generates the text embedding which is then used in the previous microservices.\n\n\nEntrypoint. This service is the interface and connects the previous microservices together. It is the entrypoint for the users to access the services.\n\n\nPrerequisites\nYou may want to create separate virtual environments for each of the microservices or you can create one for all of them. We advise to use virtual environments if you are developing multiple projects with Python, due to clashing of dependencies between projects. (Suppose one project only supports numpy < 1.0 and the other needs numpy=1.5).\nTo create a virtual environment navigate to the desired directory (usually the main folder of the project) and write\npython -m venv venv\nTo activate this virtual environment navigate into venv\/Scripts and then execute activate. To deactivate a virtual environment execute deactivate.\nYou can see that your virtual environment is being used if you see (venv) before the command line.\nEach microservice must be run separately. Each service can be used for themself or one can employ the entrypoint microservice that connects all of the microservices together.\nWhat follows is a short description of how to run each microservice. A more detailed description of the microservice can be found in their designated folders.\nText Embeddings Microservice\nCurrently you are able to run only one version of the text embedding so that it will be connected to the main component. But later you will be able to connect more.\n\nActivate virtual environment if you wish to do so\nNavigate into text_embeddings folder\nExecute\npip install -r requirements.txt\n\nRun\npython -m nltk.downloader all\n\nPlace a copy of your word2vec or fasttext word embeddings in the data\/embeddings folder\nNavigate back to the base of the text_embeddings folder and run the service with\n# linux or mac\npython -m text_embedding.main start \\\n       -e production \\\n       -H localhost \\\n       -p 4001 \\\n       -mp (path to the model) \\\n       -ml (language of the model)\n\n# windows\npython -m text_embedding.main start -e production -H localhost -p 4001 -mp (path to the model) -ml (language of the model)\n\n\nDocument Retrieval Microservice\n\nActivate virtual environment if you wish to do so\nNavigate into document_retrieval folder\nExecute\npip install -r requirements.txt\n\nNavigate into microservice\/config folder\nCreate .env file and inside define the following variables:\nPROD_PG_DATABASE=\nPROD_PG_USERNAME=\nPROD_PG_PASSWORD=\nPROD_TEXT_EMBEDDING_HOST=\nPROD_TEXT_EMBEDDING_PORT=\n\nDEV_PG_DATABASE=\nDEV_PG_USERNAME=\nDEV_PG_PASSWORD=\nDEV_TEXT_EMBEDDING_HOST=\nDEV_TEXT_EMBEDDING_PORT=\n\nNavigate to the base of document_retrieval folder and run the service with:\n# linux or mac\npython -m microservice.main start \\\n       -e production \\\n       -H localhost \\\n       -p 4100\n\n# windows\npython -m microservice.main start -e production -H localhost -p 4100\n\n\nIf you want you can also run the service on custom host and port.\nDocument Similarity Microservice\n\nActivate virtual environment if you wish to do so\nNavigate into document_similarity folder\nExecute\npip install -r requirements.txt\n\n\nNavigate into microservice\/config folder\nCreate a .env file with the following variables\nPROD_DATABASE_NAME =\nPROD_DATABASE_USER =\nPROD_DATABASE_PASSWORD =\nPROD_TEXT_EMBEDDING_URL =\n\nDEV_DATABASE_NAME =\nDEV_DATABASE_USER =\nDEV_DATABASE_PASSWORD =\nDEV_TEXT_EMBEDDING_URL =\n\n\nSet the text embedding url to http:\/\/{HOST}:{PORT}\/api\/v1\/embeddings\/create where HOST and PORT are the values used to run text embedding microservice\nNavigate back into the base of the document_similarity folder and run the service with\n# linux or mac\npython -m microservice.main start \\\n       -e production \\\n       -H localhost \\\n       -p 4200\n\n# windows\npython -m microservice.main start -e production -H localhost -p 4200\n\n\nYou can also use custom host and port.\nEntrypoint\n\nActivate virtual environment if you wish to do so\nNavigate into entrypoint folder\nRun\npip install -r requirements.txt\n\n\nNavigate into microservice\/config folder\nCreate .env file with contents\nDEV_DATABASE_USER =\nDEV_DATABASE_HOST =\nDEV_DATABASE_PORT =\nDEV_DATABASE_PASSWORD =\nDEV_DATABASE_NAME =\n\nPROD_DATABASE_USER =\nPROD_DATABASE_HOST =\nPROD_DATABASE_PORT =\nPROD_DATABASE_PASSWORD =\nPROD_DATABASE_NAME =\n\n\nNavigame back into entrypoint folder\nRun the main service with\n# linux or mac\npython -m microservice.main start \\\n       -e production \\\n       -H localhost \\\n       -p 4500\n\n# windows\npython -m microservice.main start -e production -H localhost -p 4500\nHowever if you routed other microservices to different hosts\/ports, you can provide this values in the following way:\n# linux or mac\npython -m microservice.main start -H localhost -p 4500 \\\n  -teh {host of the text embedding microservice} \\\n  -tep {port of the text embedding microservice} \\\n  -drh {host of the document retrieval microservice} \\\n  -drp {port of the document retrieval microservice} \\\n  -dsh {host of the document similarity microservice} \\\n  -dsp {port of the document similarity microservice}\n\n# windows\npython -m microservice.main start -H localhost -p 4500 -teh {host of the text embedding microservice} -tep {port of the text embedding microservice} -drh {host of the document retrieval microservice} -drp {port of the document retrieval microservice} -dsh {host of the document similarity microservice} -dsp {port of the document similarity microservice}\n\n\nUsage:\nAvailable endpoints:\n\n\nGET {HOST}\/{PORT}\/api\/v1\/documents\/search query_params query, m\n\nquery -> your text query\nm -> number of results\n\nExample request:\n{BASE_URL}\/api\/v1\/documents\/search?query=deforestation&m=10\nYou will receive top 10 documents similar to query \"deforestation\".\n\n\nGET {HOST}\/{PORT}\/api\/v1\/documents\/<document_id>\/similar query_params get_k\n\ndocument_id -> id of the document\nget_k -> number of results\n\nExample request:\n{BASE_URL}\/api\/v1\/documents\/123\/similar?get_k=5 \nYou will receive 5 of the most similar documents to document with id 123.\n\n\nPOST {HOST}\/{PORT}\/api\/v1\/documents\/<document_id>\/similarity_update\n\ndocument_id -> id of the document\n\nExample request:\n{BASE_URL}\/api\/v1\/documents\/similarity_update\nRecalculates similarities of the document with the given id to the other documents.\n\n\nGET {HOST}\/{PORT}\/api\/v1\/embeddings\/create query_params text, language\n\ntext -> your text\nlanguage -> language of the text\n\nExample request:\n{BASE_URL}\/api\/v1\/embedding\/create?text=ice cream&language=en\nYou will receive the embedding of the text \"ice cream\" from the english word embedding model.\n\n\nGET {HOST}\/{PORT}\/api\/v1\/documents query_params  document_ids\n\ndocument_ids : (comma separated document ids)\n\nExample request:\n{BASE_URL}\/api\/v1\/documents?document_ids=1,3,17\nWith the GET request at this endpoint you will receive documents data for documents ids 1, 3 and 17.\n\n\nGET {HOST}\/{PORT}\/api\/v1\/documents\/<document_id>\n\ndocument_id : (id of the document)\n\nExample request:\n{BASE_URL}\/api\/v1\/documents\/3\nWith the GET request at this endpoint you will receive documents data for document with id 3.\n\n\nAcknowledgments\nThis work is developed by AILab at Jozef Stefan Institute.\nThe work is supported by the EnviroLENS project,\na project that demonstrates and promotes the use of Earth observation as direct evidence for environmental law enforcement,\nincluding in a court of law and in related contractual negotiations.\n","376":"PyNotes for Environmental Scientists\n\nA hands-on set of python notebooks intended for students that have little or no programming experience and are interested in acquiring basic programming skills. The Python notes focus on understanding programming logic by developing codes for automating and increasing the reproducibility of common tasks in plant and soil sciences.\nInteractive resources\nDocumentation\nInteractive notebooks\n(It make take few seconds to few minutes to load the interactive notebooks. For a quick reference consider exploring the Github repository or the PyNotes documentation.)\nLoading datasets\nThe datasets used along these notebooks can be found in the \/datasets directory of the Github repository. Throughout the examples it is assumed that the Python interpreter of the Jupyter notebook is in the pynotes\/notebooks directory, reason why the directories are relative to this path in the exercises, for example: pd.read_csv(\"..\/datasets\/file.csv\").\nIf you want to follow along an exercise without downloading the entire material, you can always read the data directly from the Github repository, just make sure you get the URL link for the \"Raw\" data. For example, to read the Anscombe's dataset:\npd.read_csv('https:\/\/raw.githubusercontent.com\/andres-patrignani\/pynotes\/master\/datasets\/anscombe_quartet.csv')\nFollow this video to learn how to obtain the link for the raw data.\n\nFeedback\n\n\nFor bug reports, code suggestions, and topic requests please open an issue in the Github repository.\n\n\nFor other related issues feel free to contact me at andrespatrignani@ksu.edu\n\n\nSupport\nThe content of this website is used as a foundation for a gradaute level course in Scientific Programming and Reproducible Research offered every Spring semester within the Department of Agronomy at Kansas State University.\nThis initiative is partially supported by the Kansas State University Open\/Alternative Textbook Initiative\nLicense\nAll the code in these Jupyter notebooks has been written entirely by the author unless noted otherwise. The entire material is available for free under the Creative Commons Attribution-NonCommercial-ShareAlike (CC BY-NC-SA) license\n","377":"\nTrends in B.C.'s Population Size & Distribution\nA set of R scripts to populate an indicator on trends in B.C.'s population size and distribution. These scripts reproduce the analysis and plots published on Environmental Reporting BC.\nUsage\nData\nThe source data for the indicator is publically available from BC Stats, the central statistical agency of the Province of British Columbia.\n(1) The 'Annual population, July 1, 1867-2017 (CSV)' data file is downloaded directly from the BC Stats web page, distributed under the Access Only - B.C. Crown Copyright licence.\n(2) The 'Sub-provincial Population Estimates 1986-2017 (CSV)' data file (Access Only - B.C. Crown Copyright licence)  can be manually downloaded from the BC Stats Sub-provincial Population Estimates search tool following this manual query:\n   + Select region type: Regional District\n   + Select regions: select all\n   + Select sex(es): Totals\n   + Select age group: Totals\n   + Generate output\n   + Export to CSV\n\nCode\nThere are two core scripts that are required for the analysis, they need to be run in order:\n\n01_clean.R - cleans and prepares data for analysis\n02_output.R - creates maps and graphs and saves outputs\n\nThe run_all.R script can be sourceed to run it all at once.\nMost packages used in the analysis can be installed from CRAN using install.packages(), but you will need to install envreportutils and patchwork using devtools:\ninstall.packages(\"devtools\") # if you don't already have it installed\n\nlibrary(devtools)\ninstall_github(\"bcgov\/envreportutils\")\ninstall_github(\"thomasp85\/patchwork\")\nGetting Help or Reporting an Issue\nTo report bugs\/issues\/feature requests, please file an issue.\nHow to Contribute\nIf you would like to contribute, please see our CONTRIBUTING guidelines.\nPlease note that this project is released with a Contributor Code of Conduct. By participating in this project you agree to abide by its terms.\nLicense\nCopyright 2016 Province of British Columbia\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at \n\n   http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nThis repository is maintained by Environmental Reporting BC. Click here for a complete list of our repositories on GitHub.\n","378":"Kahuwai\n2020 UCSB Bren School of Environmental Science and Management GP Project: Kahuwai\nPURPOSE:\nM\u0101lama Maunalua, a community non-profit organization based on the Island of O'ahu, Hawai'i, reached out to the Bren School to collaborate on a management project with the goal of identifying management areas or \u201chotspots\u201d in watersheds surrounding Maunalua Bay in which land-based pollution could be reduced through the use of green infrastructure. This project contributes to their mission of Maunalua Bay\u2019s restoration by modeling the hydrology of the region to predict stormwater runoff and identify hotspots where M\u0101lama Maunalua can target their management efforts.\nWe explore these hotspots with the EPA Stormwater Management Model, 5.1 (SWMM) (https:\/\/www.epa.gov\/water-research\/storm-water-management-model-swmm).\nThese codes will take you through the data process involved with prepping data for use in SWMM, and visualizing the output data. The data are organized in files, which should be run in order. The first three folders involve code for input into SWMM, the last two files provide code for output data visualizations used in our final deliverables.\nM\u0101lama Maunalua: http:\/\/www.malamamaunalua.org\/\nBren School Project Information: http:\/\/bren.ucsb.edu\/research\/current_gp.htm\nProject Website: https:\/\/mauka2makai.weebly.com\/\nGitHub Repository: https:\/\/github.com\/nataliedornan\/Kahuwai\nPlease direct any questions to:\nNatalie Dornan - nataliedornan@gmail.com\nEleonore Durand - eleonoreacdurand@gmail.com\nTara Jagadeesh - tarajagadeesh@gmail.com\nErica Johnson - 3ricaj@gmail.com\n","379":"Data Science for Ecologists and Environmental Scientists\nCourse materials\nThis repository contains all the data needed to complete the tutorials and challenges of the course. Contents are organised according to the three course streams:\n\nStats from Scratch (getting started in R)\nWiz of Data Viz (data visualisation)\nMastering Modelling (advanced data analysis)\n\nIf you intend to complete most or all tutorials within a stream, we recommend cloning the relevant folder to your computer. If you wish to handpick tutorials across streams, each tutorial has a direct link to its material folder.\nCoding Club is a peer-to-peer learning community based at the University of Edinburgh - you can find our website at https:\/\/ourcodingclub.github.io\/\nOur materials are free to share and we welcome feedback at ourcodingclub@gmail.com\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.\n\n","380":"\nFall 2019\nDepartment of Atmospheric Science\nUniversity of Utah\nATMOS 5020: Environmental Programming\nThis repository contains lecture notes, in-class exercises, code, data, and other information. Check the Canvas page for \"Check your understanding\" quizzes, assignments, and homework.\nBelow is some general information.\n\n\nHow to download this repository\nIn the command line, navigate to your Desktop (cd Desktop) and type the following in the command line:\ngit clone https:\/\/github.com\/johnhorel\/ATMOS_5020_2019\n\nor download the zip file.\nTo update the repository, cd into the ATMOS_5020_2019 directory and type\ngit pull\n\n\nNote: If you have a Windows PC you will need to download and install git for Windows and use the command prompt.\n\nHow to view Jupyter Notebooks\nPython Notebooks should render on Github. If they don't, copy the notebook URL and and view it with the nbviewer: https:\/\/nbviewer.jupyter.org\/.\n\nAlternatively, download the notebook by right clicking the 'raw' button and selecting 'save as' and then open the notebook in Jupyter Lab.\nSchedule\n\n\n\nDate\nTopics\n\n\n\n\nAug 20\nIntroduction, Set up computers\n\n\nAug 22\nProgramming concepts, Linux, Shell scripts\n\n\nAug 27\nShell scripts, working on CHPC machine\n\n\nAug 29\nHTML, make your own webpage\n\n\nSep 3\nIntroduction to Python\n\n\nSep 5, Part 2\nPython in Jupyter Lab: Loops, if statements, etc.\n\n\nSep 10\nPython: Functions, Matplotlib\n\n\nSep 12, Supplemental\nPython: Pandas\n\n\nSep 17\nPython: Advanced matplotlib (datetime, 2-D plots, etc.)\n\n\nSep 19\nPyhton: Plotting GOES data -- reading example docs online\n\n\n\nQuick Guides\n\nHow to log onto CHPC computers: ssh -Y uXXXXXXX@meteo07.chpc.utah.edu\nLinux Cheatsheet 1\nLinux Cheatsheet 2\nPython Cheatsheet\n\nNumpy Cheatsheet\nMatplotlib Cheatsheet\nJupyter Notbook Shortcuts\n\n\nMarkdown Formatting (These notes are written in markdown)\nBasic vi commands\nAnother vi cheat sheet\n\n\ud83d\udcbb Setting Up Your Personal Computer\nLog-on to CHPC: If you are a windows user and you want to log onto the CHPC resources, you must install Putty and Xming and follow these instructions for logging in. Mac users can use the terminal like we do in the classroom.\nInstall Python: The recommended way to install Python on your personal computer is with the Anaconda distribution service.\n\nYou can install packages with the Anaconda Navigator tool in the \"Environments\" tab.\nBrian's instructions give a few more details to install Python with Anaconda on your personal computer\nThe Unidata workshop also has some instructions on how to set up your environment.\nWe also recommend you install a good text editor, like VSCode (available for download through the Anaconda Launcher).\n\n\ud83d\udc0d Learn Python\nThe purpose of this class is to introduce you to programming principles. Your programming skill will only improve after hours and hours of practice. If you plan on using Python after this class, it is highly recommended that you learn from other resources, use it for other classes, and use it for a capstone or research project. There are several free Python learning courses that will really help you learn Python, like Codecademy (version 2 has a lot of free stuff and it's pretty close to version 3). The Unidata training is another useful resource.\n","381":"\nFall 2019\nDepartment of Atmospheric Science\nUniversity of Utah\nATMOS 5020: Environmental Programming\nThis repository contains lecture notes, in-class exercises, code, data, and other information. Check the Canvas page for \"Check your understanding\" quizzes, assignments, and homework.\nBelow is some general information.\n\n\nHow to download this repository\nIn the command line, navigate to your Desktop (cd Desktop) and type the following in the command line:\ngit clone https:\/\/github.com\/johnhorel\/ATMOS_5020_2019\n\nor download the zip file.\nTo update the repository, cd into the ATMOS_5020_2019 directory and type\ngit pull\n\n\nNote: If you have a Windows PC you will need to download and install git for Windows and use the command prompt.\n\nHow to view Jupyter Notebooks\nPython Notebooks should render on Github. If they don't, copy the notebook URL and and view it with the nbviewer: https:\/\/nbviewer.jupyter.org\/.\n\nAlternatively, download the notebook by right clicking the 'raw' button and selecting 'save as' and then open the notebook in Jupyter Lab.\nSchedule\n\n\n\nDate\nTopics\n\n\n\n\nAug 20\nIntroduction, Set up computers\n\n\nAug 22\nProgramming concepts, Linux, Shell scripts\n\n\nAug 27\nShell scripts, working on CHPC machine\n\n\nAug 29\nHTML, make your own webpage\n\n\nSep 3\nIntroduction to Python\n\n\nSep 5, Part 2\nPython in Jupyter Lab: Loops, if statements, etc.\n\n\nSep 10\nPython: Functions, Matplotlib\n\n\nSep 12, Supplemental\nPython: Pandas\n\n\nSep 17\nPython: Advanced matplotlib (datetime, 2-D plots, etc.)\n\n\nSep 19\nPyhton: Plotting GOES data -- reading example docs online\n\n\n\nQuick Guides\n\nHow to log onto CHPC computers: ssh -Y uXXXXXXX@meteo07.chpc.utah.edu\nLinux Cheatsheet 1\nLinux Cheatsheet 2\nPython Cheatsheet\n\nNumpy Cheatsheet\nMatplotlib Cheatsheet\nJupyter Notbook Shortcuts\n\n\nMarkdown Formatting (These notes are written in markdown)\nBasic vi commands\nAnother vi cheat sheet\n\n\ud83d\udcbb Setting Up Your Personal Computer\nLog-on to CHPC: If you are a windows user and you want to log onto the CHPC resources, you must install Putty and Xming and follow these instructions for logging in. Mac users can use the terminal like we do in the classroom.\nInstall Python: The recommended way to install Python on your personal computer is with the Anaconda distribution service.\n\nYou can install packages with the Anaconda Navigator tool in the \"Environments\" tab.\nBrian's instructions give a few more details to install Python with Anaconda on your personal computer\nThe Unidata workshop also has some instructions on how to set up your environment.\nWe also recommend you install a good text editor, like VSCode (available for download through the Anaconda Launcher).\n\n\ud83d\udc0d Learn Python\nThe purpose of this class is to introduce you to programming principles. Your programming skill will only improve after hours and hours of practice. If you plan on using Python after this class, it is highly recommended that you learn from other resources, use it for other classes, and use it for a capstone or research project. There are several free Python learning courses that will really help you learn Python, like Codecademy (version 2 has a lot of free stuff and it's pretty close to version 3). The Unidata training is another useful resource.\n","382":"deq-enviro \nDEQ Environmental Data Viewer\nGeneric application for searching, viewing and downloading DEQ GIS data and related tables.\nRequirements\nScope of Work\nOriginal Mockup\nConfig Spreadsheet\nStaging Config Spreadsheet\nMaster Plan\nStage - test.mapserv.utah.gov\/deqenviro\/\nProduction - enviro.deq.utah.gov\nQuery Layer Data Requirements\nIn order for a dataset to be used as a query layer within the application, it must satisfy all of the following requirements:\n\nAccessible from our server (usually requires some firewall requests)\nFor tables that need to be translated into points:\n\nCoordinates stored in either LATITUDE & LONGITUDE or EASTING & NORTHING fields.\n\n\nA row in the configuration spreadsheet that defines mappings for the five main fields (ID, NAME, ADDRESS, CITY, & TYPE). If there is no mapping for a specific field a value of n\/a should be used in the config.\nA unique id field. If the field is not automatically recognized by ArcGIS Pro, then the OID Field column in the config spreadsheet can be used to define it.\n\nTesting\nUnit tests are run via intern.\nTo run tests:\n\ngrunt\nnpx intern serveOnly\nGo to: http:\/\/localhost:9000\/__intern\/\n\nNightly Script\nRuns nightly on test and prod servers.\nBuilds DEQEnviro.json which the web app uses to configure itself. Part of building this json file is getting all of the map service layer indices so it needs to be rerun manually after adding, removing or reordering any of the map service layers.\nMake sure that you have a latest version of pip before pip install -r requirements.txt.\nThis script requires settings\/oauth2key.json. Check out the oauth2 gspread docs to learn how to generate it. Make sure to grant read permission to the email address in client_email to the config spreadsheets.\nUpdates related data in SGID10. Reads sources from the config spreadsheet.\nData Schema Changes\nMost updates are taken care of via the config spreadsheet and updating the schema of data.\nAdding a new field\n\nAdd the field to the \"Identify Attributes\" column in the config spreadsheet. This will make it show up in the identify pane in the app.\nAdd the field to the data in SGID10 (prod & staging).\nAdd the field to the data in staging\/deqquerylayers.gdb.\nDelete the associated dataset in staging\/sgid_stage.gdb if it's there.\n\nAdding a new query layer\n\nAdd the new row in the config spreadsheet\nRun forklift pallet.\nAdd new layer to maps\/MapService.mxd or maps\/Secure.mxd and republish.\nManually run build_json.py to get the layer number from the map service of the newly added layer.\n\nDeploy Steps\n\n\nSet up and install ArcGisServerPermissionsProxy.\n\nImport RavenDB and web.config from previous server.\nUse configs\/permissionproxy.json to create a new application\nMay need to set the AccessRules.EndDate to 5000000000000 for the initial user so that you can log in successfully the first time.\n\n\n\nCreate a deqnightly user in ArcGIS Server and assign it to the deq_admin role.\n\nFill in the credentials in the settings for the pallet.\n\n\n\nBuild and deploy (using web deploy) api\/Search.Api\/Search.Api.sln to the web server (<root>\/deqenviro\/api).\n\nRegister SOE from the same project with ArcGIS Server.\n\n\n\nPublish maps\/MapService.mxd and maps\/Secure.mxd to a DEQEnviro folder in ArcGIS Server.\n\nSecure should be locked down to just the deq_admin and deq_water roles.\nAdd the SOE to each of these services:\n\nsitename: NAME\nmaxrecords: 25000\nreturnFields: ID,NAME,ADDRESS,CITY,TYPE,OBJECTID,ENVIROAPPLABEL,ENVIROAPPSYMBOL\nfacilityust: FACILITYUST\nprogramid: ID\n\n\n\n\n\nPublish ExportWebMap service to the DEQEnviro folder using maps\/PrintTemplates\/Portrait.mxd as the default template.\n\nMake sure that the server can resolve the domain name that the app is hosted on (e.g. test.mapserv.utah.gov). If it can't you will need to edit the hosts file. This is required for the ExportWebMap service.\nsynchronous\n\n\n\nRun and publish scripts\/download\/DeqEnviro.pyt\/download as Toolbox\/download in the same DEQEnviro folder.\n\npip install xlsxwriter on the hosting server fom the python installation that ArcGIS Server uses (x64).\npip install xlsxwriter on the publishing server for the python installation that ArcGIS Desktop uses (x32).\nYou can use these inputs as a test:\n\n{\"BFNONTARGETED\":[\"Pre5\",\"Pre9\",\"Pre8\",\"Pre4\",\"Pre7\",\"Pre10\",\"Pre12\",\"Pre13\",\"Pre14\",\"Pre11\",\"13\",\"14\"],\"BFTARGETED\":[\"2A\",\"3\",\"5\",\"6\",\"4\",\"8\",\"9\",\"10\",\"11\",\"12\",\"1\",\"2\",\"7\"]}\nshp\nC:\\forklift\\data\\production\\deqquerylayers.gdb\n\n\n\nAdd repo to forklift.\n\nCopy scripts\/nightly\/databases & scripts\/nightly\/settings\/__init__.py from old server.\nDownload and install the latest oracle instant client.\nFrom within the forklift environment: pip install -r .\\scripts\\nightly\\requirements.txt\n\n\n\nBuild and deploy the application by running grunt build-prod && grunt deploy-prod.\n\nYou will need to run scripts\/nightly\/build_json.py to generate DEQEnviro.json before you can load the application for the first time.\n\n\n\n","383":"modulefiles\nmodulefiles for Environmental Modules\nhttp:\/\/modules.sourceforge.net\/\nCreated by Dongjin Kwon\n","384":"\n\nOverview of package\nThis package allows you to simulate time series of environmental health data and perform simulation-based power analyses and other measures of model performance. The package includes four main parts:\n\nGeneration of exposure data (simulated or from real data);\nGeneration of simulated outcome data;\nFitting models to generated data; and\nEvaluating model performance on generated data.\n\nThe user has the option to customize different aspects of the simulation at each of these steps.\nThe package creates simulated time series data that are relevant for environmental epidemiology studies of ambient exposures (e.g., studies of acute mortality risks associated with daily air pollution concentration, daily temperature, or occurance of a community-wide extreme event like a heat wave). Simulated environmental datasets like those created by the package can be used in to assess the performance of statistical models meant to estimate the association between exposure level and outcome risk, to estimate power for a planned study, and to develop a better understanding of the data generating processes behind observed environmental datasets. Such time series are often characterized by both seasonal and long-term trends in both the exposure of interest and the outcome. For example, the following plot shows time series of daily ozone concentration (in parts per billion [ppb]) and cardiovascular deaths in Chicago, IL (1996--2000), with smoothed lines overlaid on the raw data to show patterns over time.\n\nBasic example of using the package\nThe main function of this package is the eesim function. You can use the eesim function to conduct all four steps of the simulation process at once (generate exposure data, generate outcome data, fit models to simulated data, and evaluate model performance).\nThe eesim function requires inputs on:\n\nn: The desired number of observations per simulated dataset (for a daily time series, this is the desired number of days in the simulated dataset)\nn_reps: The desired number of simulated datasets\nexposure_type: Whether the exposure is binary (e.g., occurence of an extreme event like a heat wave or wildfire) or continuous (e.g., concentration of a pollutant)\nrr: The relative rate of the outcome associated with the exposure. For a binary exposure, this is the relative rate associated with the exposure compared to a similar day without the exposure. For a continuous exposure, this is the relative rate associated with a one-unit increase in the exposure.\nmodel: The model to be used to estimate the association between exposure and outcome in the simulated datasets, either to estimate power of a planned analysis or to otherwise evaluate the performance (e.g., coverage, bias) of a model on the simulated datasets.\n\nA number of optional inputs can also be specified, including arguments to adjust the shape of seasonal or long-term trends in the exposure or outcome data or custom arguments to use at different steps of the data generation.\nThe function returns a list with three elements. The first element is a list with all the simulated datasets. The second element gives simulation-specific results for each simulated dataset: the estimated effect, standard error, t- and p-values, and upper and lower 95% confidence bounds when a model was applied to each of the simulated datasets. The third element gives some measures of model assessment, assessed over all simulations, including the mean beta and relative risk estimates across simulations.\nFor example, in the observed data from Chicago, IL, shown in the plots above, daily ozone concentrations have a mean of about 20 ppb and standard deviation of about 7 ppb after removing seasonal and long-term trends. The average number of cardiovascular deaths per day is around 50. Here is the code, and a plot of the resulting data, for generating a dataset with similar characteristics for use in a power analysis or to evaluate model performance (later in the vignette, we will show how to use customization to further improve the simulation of data for this example, including avoiding negative values of ozone concentration in simulated data):\nsim_chicago <- create_sims(n_reps = 1, n = 365 * 5, central = 20, sd = 7,\n                           exposure_type = \"continuous\", exposure_trend = \"cos1\",\n                           exposure_amp = -.6, average_outcome = 50,\n                           outcome_trend = \"cos1\", outcome_amp = 0.2, \n                           rr = 1.0005, start.date = \"1996-01-01\")\nhead(sim_chicago[[1]])\n#>         date          x outcome\n#> 1 1996-01-01 14.8541083      64\n#> 2 1996-01-02  3.1952265      78\n#> 3 1996-01-03  0.4101124      72\n#> 4 1996-01-04 10.4824504      69\n#> 5 1996-01-05 18.9213207      58\n#> 6 1996-01-06  7.8855542      56\n\nThis simulated data can also be visualized using the calendar_plot function that comes with the package:\na <- calendar_plot(sim_chicago[[1]] %>% select(date, outcome), type = \"continuous\", \n                   legend_name = \"Outcome\") + \n  ggtitle(\"Outcome\")\nb <- calendar_plot(sim_chicago[[1]] %>% select(date, x), type = \"continuous\") + \n  ggtitle(\"Exposure\")\ngrid.arrange(a, b, ncol = 1)\n\nYou can use the eesim function to generate multiple similar simulated datasets and investigate the performance of a specified model in estimating the association between ozone concentration and the risk of cardiovascular death in 20 simulated datasets. You must write a function with the code to fit the model you desire to fit to the simulated data (more details for writing this function are provided later in the vignette), and then you can use the eesim function to generate lots of simulated datasets, fit that model, and assess its performance using a call like:\nex_sim <- eesim(n_reps = 100, n = 365 * 5, central = 20, sd = 7,\n                exposure_type = \"continuous\", exposure_trend = \"cos1\",\n                exposure_amp = -.6, average_outcome = 50,\n                outcome_trend = \"cos1\", outcome_amp = 0.2, \n                rr = 1.2, start.date = \"1996-01-01\",\n                custom_model = spline_mod, custom_model_args = list(df_year = 7))\nThe eesim function returns a list with three elements:\nnames(ex_sim)\n#> [1] \"simulated_datasets\"  \"indiv_performance\"   \"overall_performance\"\nThe first element of the returned object is a list with all of the simulated datasets. For example, you can create a calendar plot of exposure in the first simulated dataset using the call:\ncalendar_plot(ex_sim[[\"simulated_datasets\"]][[1]] %>% select(date, x), type = \"continuous\")\n\nThe second element of the returned object gives the results of fitting the model to each of the simulated datasets. It can be used to explore the behavior of individual simulations:\nhead(ex_sim[[\"indiv_performance\"]])\n#>    Estimate    Std.Error  t.value p.value  lower_ci  upper_ci\n#> 1 0.1827175 0.0002469170 739.9956       0 0.1822335 0.1832014\n#> 2 0.1825011 0.0002090035 873.1962       0 0.1820914 0.1829107\n#> 3 0.1821313 0.0002323444 783.8852       0 0.1816760 0.1825867\n#> 4 0.1821526 0.0002287805 796.1893       0 0.1817042 0.1826010\n#> 5 0.1823460 0.0002251761 809.7930       0 0.1819047 0.1827874\n#> 6 0.1823111 0.0002364797 770.9377       0 0.1818476 0.1827746\nAfter running the simulation, you can look at the relative risk point estimate and 95% confidence interval from each of the 100 simulations, as well as which 95% confidence intervals include the true relative rate, using the coverage_plot function that comes with the package:\ncoverage_plot(ex_sim[[\"indiv_performance\"]], true_param = 1.2)\n\nThe third element of the list returned by a call to eesim gives the following overall summaries of model performance across all simulations:\n\n\n\nVariable\nDescription\n\n\n\n\nbeta_hat\nMean estimate: The mean of the estimated log relative rate over all simulations.\n\n\nrr_hat\nMean estimated relative rate: The mean of the estimated relative rate over all simulations.\n\n\nvar_across_betas\nVariance across estimates: Variance of the point estimates (estimated log relative risk) over all simulations.\n\n\nmean_beta_var\nMean variance of estimate: The mean of the variances of the estimated effect (estimated log relative risk) across all simulations.\n\n\npercent_bias\nRelative bias: Difference between the estimated log relative risk and true log relative risk as a proportion of the true log relative risk.\n\n\ncoverage\n95% confidence inverval coverage: Percent of simulations for which the 95% confidence interval estimate of log relative risk includes the true value of log relative risk.\n\n\npower\nPower: Percent of simulations for which the null hypothesis that the log relative risk equals zero is rejected based on a p-value of 0.05.\n\n\n\nFor example, here are the overall results for the simulation fit above:\nex_sim[[\"overall_performance\"]]\n#>    beta_hat   rr_hat var_across_betas mean_beta_var percent_bias coverage\n#> 1 0.1823186 1.199996     4.880753e-08  5.593839e-08  0.000296735     0.95\n#>   power\n#> 1     1\nIn later sections of this vignette, we will show how to customize steps in the generation of the simulated data to further improve this example simulation.\nAs another basic example, here is a plot of the dates of extreme heat days (defined as a day with temperature at or above the 98 percentile temperature in Chicago between 1987 and 2000) in the observed Chicago dataset (points are jittered along the y-axis to limit overlapping):\n\nIn this observed data, there is (unsurprisingly) a strong seasonal trend in this binary exposure of extreme heat days. The percent of days that are extreme heat days is 0% for all months expect June (about 5% of days in observed data were extreme heat days), July (about 12% of days), and August (about 2% of days). Similar exposure time series can be simulated with the call:\nsim_chicago2 <- create_sims(n_reps = 1, n = 365 * 5, sd = 1,\n                            central = c(0, 0, 0, 0, 0, 0.05, 0.12, 0.02, 0, 0, 0, 0),\n                            exposure_type = \"binary\", exposure_trend = \"monthly\",\n                            exposure_amp = -.6, average_outcome = 50,\n                            outcome_trend = \"cos1\", outcome_amp = 0.2, \n                            rr = 1.05, start.date = \"1996-01-01\")\nHere is an example of the simulated exposure data:\n\nAgain, both the observed and simulated exposure data can also be plotted using the calendar_plot function:\na <- chicagoNMMAPS %>% \n  mutate(temp = temp >= quantile(temp, probs = 0.98)) %>% \n  tbl_df() %>% \n  filter(year >= 1996) %>% \n  select(date, temp) %>% \n  calendar_plot(type = \"discrete\", labels = c(\"Extreme heat day\", \"Other day\")) + \n  ggtitle(\"Observed exposure data\")\nb <- sim_chicago2[[1]] %>% \n  select(date, x) %>% \n  calendar_plot(type = \"discrete\", labels = c(\"Extreme heat day\", \"Other day\")) + \n  ggtitle(\"Simulated exposure data\")\ngrid.arrange(a, b, ncol = 1)\n\nThe comparison of the observed and simulated data in this case suggests some clustering in the observed data that is not evident in the simulated data, suggesting that the probability of exposure may be higher on a day near other extreme heat days.\nThe eesim function can be used to assess the performance of a GLM in estimating relative risk of cardiovascular mortality for extreme heat days compared to other days using:\nex_sim2 <- eesim(n_reps = 100, n = 365 * 5, \n                 central = c(0, 0, 0, 0, 0, 0.05, 0.12, 0.02, 0, 0, 0, 0),\n                 exposure_type = \"binary\", exposure_trend = \"monthly\",\n                 exposure_amp = -.6, average_outcome = 50,\n                 outcome_trend = \"cos1\", outcome_amp = 0.2, \n                 rr = 1.05, start.date = \"1996-01-01\",\n                 custom_model = spline_mod, custom_model_args = list(df_year = 7))\n#> This function may take a minute or two to run, especially if you\n#> are creating lots of replications (`n_reps`).\nAs before, a plot of CI coverage can be created with coverage_plot:\ncoverage_plot(ex_sim2[[\"indiv_performance\"]], true_param = 1.05)\n\nHere are the overall estimates in this case for model performance:\nex_sim2[[\"overall_performance\"]]\n#>     beta_hat   rr_hat var_across_betas mean_beta_var percent_bias coverage\n#> 1 0.04617133 1.047885      0.001214473  0.0009170105    0.2014185     0.92\n#>   power\n#> 1  0.34\nIn this case, the expected power is low.\nThe power_calc function in the package allows you to extend on this simulation functionality to create power curves for an analysis given an anticipated underlying process of data generation. This function will create simulations for several different values of number of days in the study (n), average daily outcome counts (average_outcome), or expected association between exposure and outcome (rr).\nFor example, the following call generates a power curve that explores how expected power changes with an increasing number of days for the heat wave analysis example just presented (as a warning, this call takes a few minutes to run, since it's simulating many datasets):\nex_power_calc <- power_calc(varying = \"n\", values = floor(365.25 * seq(1, 20, by = 5)),\n                            n_reps = 100, rr = 1.05,\n                            central = c(0, 0, 0, 0, 0, 0.05, 0.12, 0.02, 0, 0, 0, 0),\n                            exposure_type = \"binary\", exposure_trend = \"monthly\", \n                            exposure_amp = -.6, average_outcome = 50,\n                            outcome_trend = \"cos1\", outcome_amp = 0.2, \n                            custom_model = spline_mod, custom_model_args = list(df_year = 7),\n                            plot = FALSE)\n#> This function may take a minute or two to run, especially with\n#> lots of replications (`n_reps`) or options for `values`.\nex_power_calc %>% \n  ggplot(aes(x = values, y = power)) + \n  geom_line() + \n  ylim(0, 1) + \n  labs(x = \"Number of days in the study\", y = \"Power\") + \n  theme_bw()\n\nPiece-by-piece breakdown of package utility\nTo demonstrate how the eesim function works, here is a breakdown of each of the four main parts: generating exposure data, generating outcome data, fitting models, and evaluating models. The helper functions used for each step are described in detail in this section.\nGenerating exposure data\nThe first task of the package is generating exposure data. This can be done with the sim_exposure function. In this function, the user can specify whether he or she would like to generate exposure data that is binary or continuous (exposure_type). For continuous exposure data, the user must specify the mean (central) and standard deviation (sd) of the exposure data. For example, the following call simulates a dataframe of exposure data for an exposure that is normally distributed, with a mean value of 50, a standard deviation of 5, and no long-term or seasonal trends:\nx_cont <- sim_exposure(n = 1000, central = 50, sd = 5, exposure_type = \"continuous\") \nx_cont %>% slice(1:5)\n#>         date        x\n#> 1 2001-01-01 51.79315\n#> 2 2001-01-02 51.69743\n#> 3 2001-01-03 50.91866\n#> 4 2001-01-04 51.84013\n#> 5 2001-01-05 53.22749\nggplot(x_cont, aes(x = date, y = x)) + geom_point(alpha = 0.2) + \n  theme_classic()\n\nYou can plot a calendar plot of this simulated exposure time series using the calendar_plot function that comes with the package. Within this function, the type of data (\"continuous\" or \"discrete\") must be specified:\ncalendar_plot(x_cont, type = \"continuous\")\n\nYou can similarly use the sim_exposure function to simulate a binary exposure (e.g., occurence of an extreme event). For binary exposure data, the central argument of sim_exposure must also be expressed, but in this case it gives the probability of exposure on a study day:\nx_bin <- sim_exposure(n = 1000, central = 0.05, exposure_type = \"binary\")\nx_bin %>% slice(1:5)\n#>         date x\n#> 1 2001-01-01 0\n#> 2 2001-01-02 0\n#> 3 2001-01-03 0\n#> 4 2001-01-04 0\n#> 5 2001-01-05 0\nAgain, the calendar_plot function can be used to visualize the generated time series. In the case of binary exposure data, the labels to be used in the legend for each outcome level must also be specified using the labels argument:\ncalendar_plot(x_bin, type = \"discrete\", labels = c(\"Not exposed\", \"Exposed\"))\n\nSo far, these sim_exposure calls have been used to simulate basic exposure data, without long-term or seasonal trends. However, for environmental epidemiology applications, exposure data often has a seasonal trend and \/ or long-term trend, and these temporal trends can serve as confounders in assessing the association between time-varying environmental exposures and health outcomes. The sim_exposure function therefore includes options to generate exposure data with long-term and seasonal trends relevant to environmental time series studies, through the trend argument.\nThe default for sim_exposure is to simulate the exposure data without a time trend (trend = \"no trend\"). However, we have also built in several time trends from which a user can to choose to simulate exposure data with a time trend, either seasonal or long-term or both, based on trend patterns used in a simulation study of case-crossover studies as a method of controlling for seasonal and long-term trends in environmental epidemiology studies (Bateson and Schwartz 1999). These trend patterns differ slightly depending on whether the user is simulating binary or continuous data. Below are plots of the built-in trends for continuous exposure data from which the user may choose. \nYou can use the amp argument to adjust the seasonal trend in any of the patterns with a seasonal trend. For example, here are plots of trends using tren = \"cos1linear\" for different values of amp:\n\nThe long-term trend in expected values can be changed in a similar way with the exposure_trend argument in eesim.\nHere is an example of generating continuous exposure data with a \"cos1linear\" trend for an exposure with a mean value of 50 and a standard deviation of 10:\ntestexp <- sim_exposure(n = 365 * 3, central = 50, sd = 10, trend = \"cos1linear\",\n                        exposure_type = \"continuous\")\na <- ggplot(testexp, aes(x = date, y = x)) +  \n  geom_point(alpha = 0.5, size = 0.8) + \n  coord_cartesian(ylim = c(0,110)) + \n  labs(title = \"Exposure with a 'cos1linear' trend\", x = \"Date\", y=\"Exposure\") + \n  theme_classic()\nb <- calendar_plot(testexp, type = \"continuous\") + \n  ggtitle(\"Calendar plot of simulated exposure data\") + \n  theme(legend.position = \"bottom\")\ngrid.arrange(a, b, ncol = 1)\n\nHere is an example of changing the seasonal trend by changing the value for amp (the default value is 0.6) to simulate exposure data for an exposure with a smaller seasonal trend and with higher exposures typical in the summer than the winter:\nsmall_amp <- sim_exposure(n = 365 * 3, central = 50, sd = 10, trend = \"cos1linear\",\n                        amp = -0.3, exposure_type = \"continuous\")\na <- ggplot(small_amp, aes(x = date, y = x)) +  \n  geom_point(alpha = 0.5, size = 0.8) + \n  coord_cartesian(ylim = c(0,110)) + \n  labs(title = \"Exposure with a 'cos1linear' trend\", x = \"Date\", y=\"Exposure\") + \n  theme_classic()\nb <- calendar_plot(small_amp, type = \"continuous\") + \n  ggtitle(\"Calendar plot of simulated exposure data\") + \n  theme(legend.position = \"bottom\")\ngrid.arrange(a, b, ncol = 1)\n\nThe trend options are similar for binary exposure, but exclude \"curvilinear\" and \"cos1linear\". Further, binary exposures can also be simulated using a \"monthly\" trend (trend = \"monthly\"), in which the probability of exposure can vary by month. When using this \"monthly\" trend option, the cental argument to sim_exposure should include a vector with 12 separate probabilities (the first is for January, the second for February, etc.) rather than a single probability. Here is an example of generating binary exposure data with a monthly trend, starting from June 1, 2002, with higher probability of the exposure in summer months than in winter months:\ntestbin <- sim_exposure(n=1000, central = c(.05, .05, .1, .2, .4, .4, .5, .7, .5, .2, .1, .05),\n                        trend = \"monthly\", exposure_type = \"binary\", \n                        start.date = \"2002-06-01\")\na <- testbin %>% \n  mutate(x = factor(x, levels = c(0, 1), labels = c(\"Not exposed\", \"Exposed\"))) %>% \n  ggplot(aes(x = date, y = x)) + \n  geom_jitter(alpha = 0.5, size = 0.7, fill = NA, width = 0, height = 0.1) + \n  theme_classic() + \n  labs(x = \"Date\", y = \"Exposure\")\nb <- calendar_plot(testbin, type = \"discrete\", labels = c(\"Not exposed\", \"Exposed\")) + \n  ggtitle(\"Calendar plot of simulated exposure data\") + \n  theme(legend.position = \"bottom\")\ngrid.arrange(a, b, ncol = 1)\n\nThe sim_exposure function works by first calculating the expected exposure on any date in the simulated time series (figure below, left). This expected value is a mean for a continuous exposure and a probability for a binary exposure. The sim_exposure function then draws random values from the appropriate distribution (normal distribution for a continuous exposure, binomial distribution for a binary exposure) based on this day-specific expected exposure value and, in the case of continuous exposure, the standard deviation of the exposure (figure below, right). For continuous exposure data, the standard deviation specified in the call to eesim should measure the standard deviation of each point from its expected value (i.e., from the expected line shown on the left below), not the overall standard deviation of exposure values across all days in the simulated data.\n\nLater in this vignette, we show how you can further customize this step of generating exposure data through the use of a user-created function, allowing extensive further flexibility in simulating exposure data.\nGenerating outcome data\nNext, the sim_outcome function simulates outcome data. The health data can have an underlying seasonal and \/ or long term trend in its baseline value, and then that baseline is adjusted for the risk associated with exposure, based on the generated exposure data for that day. The baseline outcome count for a given day (Bt) are based on a user-specified trend and user-specified average outcome per day over the simulated time period. Further, the expected outcome count on a given day is adjusted for exposure-related risk through a user-specified relative rate per unit increase in exposure (R**R) and the simulated exposure for that day (Xt). The eesim function then uses the following equation to calculate the expected outcome count (\u03bb) on a given day in the simulated time series, based on the expected baseline rate and exposure-related risk for that day:\nlog(\u03bbt)=log(Bt)\u2005+\u2005log(R**R)\u2005*\u2005Xt\nFor a binary outcome, the baseline count on a given day (Bt) is the expected outcome count for the day if there is not an event (e.g., in a heat wave study, a non-heat wave day). For a continuous exposure, the baseline count on a given day (Bt) is the expected outcome count for the day if exposure is at its mean value.\nOnce the expected count (\u03bbt) on each day of the simulated time series is calculated using this equation, the simulated count on each day is drawn as a random variable from a Poisson distribution with mean \u03bbt. Later we describe how customization can be used to simulate output counts in other ways.\nHere is an example of generating health outcome data with an upward linear trend using exposure data with a \"cos1\" trend. In this case, there is a steady increase in the baseline outcome count over time, as well as a seasonal trend linked to the risk associated with the seasonally-varying exposure:\ntestexp2 <- sim_exposure(n = 1000, central = 100, sd = 10, trend = \"cos1\",\n                         exposure_type = \"continuous\")\ntestout <- sim_outcome(exposure = testexp2, average_outcome = 22,\n                       trend = \"linear\", rr = 1.01)\nHere are plots of the resulting output:\n\nAs with the exposure simulation step, this step can also be extensively customized by using a user-created function. This customization will be demonstrated in a later section of the vignette.\nFitting models\nNext, the eesim package uses this process to generate many simulated data sets and then to fit statistical models to these generated datasets. This step allows tests of model performance. You must create an R function that fits the model you'd like to fit to the simulated dataset. This function needs to follow certain input \/ output rules to work correctly in the eesim framework. First, it must input the simulated dataframe with the argument df. When writing the function, you should assume that this simulated dataframe has at least the columns date (in a Date format), x (numeric class, this gives a daily value for exposure, with 0 for unexposed and 1 for exposed in the case of binary exposure), and outcome (non-negative integer, this gives the simulated outcome count each day). Other arguments can also be passed to this function if desired. The function should fit a desired model to the simulated dataframe and then should return a numeric vector of length 6 with values, in this order, for the log relative risk point estimate from the model (Estimate), the standard error for this point estimate (Std. Error), the t-statistic for a hypothesis test with the null hypothesis that this estimate is zero (t value), a p-value for that test (Pr(>|t|)), and the lower and upper 95% confidence intervals for the point estimate (2.5 % and 97.5 %).\nThe spline_mod function that comes with the package is an example of such a function. In this case, the function fits a GLM to the simulated data, with a natural cubic spline used to control for long-term and seasonal trends in mortality. The function, in addition to inputing the dataframe of simulated data (df), also allows an argument to use to set the smoothness of the time spline (df_year). Since the function is included in the package, you can see its code by running the bare function name at the console:\nspline_mod\n#> function(df, df_year = 7){\n#>   dgrs_free <- df_year * as.numeric(diff(df[c(1, nrow(df)), \"date\"])) \/ 365.4\n#>   df$time <- scale(df$date, center = TRUE, scale = FALSE)\n#>   mod <- stats::glm(outcome ~ x + splines::ns(time, round(dgrs_free)),\n#>                    data = df,\n#>                    family = stats::quasipoisson(link = \"log\"))\n#> \n#>   out_1 <- summary(mod)$coef[2, ]\n#>   out_2 <- stats::confint.default(mod)[2, ]\n#>   out <- c(out_1, out_2)\n#>   return(out)\n#> }\n#> <bytecode: 0x7f850b294f08>\n#> <environment: namespace:eesim>\nHere are examples of applying this function to a simulated dataframe:\n# Create simulated data\nsims <- create_sims(n_reps = 10, n = 100, central = 100, sd = 10,\n             exposure_type=\"continuous\", exposure_trend = \"cos1\",\n             exposure_amp = .6, average_outcome = 22,\n             outcome_trend = \"no trend\", outcome_amp = .6, rr = 1.01)\nhead(sims[[1]])\n#>         date        x outcome\n#> 1 2000-01-01 120.9115      37\n#> 2 2000-01-02 107.8687      17\n#> 3 2000-01-03 124.0501      35\n#> 4 2000-01-04 108.2165      21\n#> 5 2000-01-05 126.2719      21\n#> 6 2000-01-06 121.5310      21\n# Apply `spline_mod` to the data\nspline_mod(df = sims[[1]])\n#>     Estimate   Std. Error      t value     Pr(>|t|)        2.5 % \n#> 1.263067e-02 2.419841e-03 5.219626e+00 1.035524e-06 7.887866e-03 \n#>       97.5 % \n#> 1.737347e-02\nspline_mod(df = sims[[1]], df_year = 6)\n#>     Estimate   Std. Error      t value     Pr(>|t|)        2.5 % \n#> 1.263067e-02 2.419841e-03 5.219626e+00 1.035524e-06 7.887866e-03 \n#>       97.5 % \n#> 1.737347e-02\nThe format_function function can be used within the modeling function to get the output in the correct format if running a GLM or similar model.\nOnce you've created the function, you can input it in a call to eesim using the custom_model argument. You can pass any additional arguments (df_year in our example) through to the function using the custom_model_args argument. This argument takes a list with the argument name and value for each argument you wish to pass to the modeling function. For example, the following call passes the spline_mod function shown above as the function to use for modeling the simulated data as well as a value for its df_year argument:\nex_sim2 <- eesim(n_reps = 100, n = 365 * 5, \n                 central = c(0, 0, 0, 0, 0, 0.05, 0.12, 0.02, 0, 0, 0, 0),\n                 exposure_type = \"binary\", exposure_trend = \"monthly\",\n                 exposure_amp = -.6, average_outcome = 50,\n                 outcome_trend = \"cos1\", outcome_amp = 0.2, \n                 rr = 1.05, start.date = \"1996-01-01\",\n                 custom_model = spline_mod, custom_model_args = list(df_year = 7))\nThe eesim function does this by applying the modeling function across all simulated datasets using a function called fit_mods. If you'd like, you can run that function independently. The fit_mods function outputs a data frame with estimates of the log relative risk, p-values, and upper and lower 95% confidence bounds for each simulated data set.\nHere is an example of fitting the spline model coded in the spline_mod function, with 7 degrees of freedom per year used to model long-term and seasonal trends (df_year = 7 passed in a list to the model with the custom_model_args argument):\nfits <- fit_mods(data = sims, custom_model = spline_mod, \n                 custom_model_args = list(df_year = 7))\nfits\n#>       Estimate   Std.Error  t.value      p.value    lower_ci   upper_ci\n#> 1  0.012630668 0.002419841 5.219626 1.035524e-06 0.007887866 0.01737347\n#> 2  0.010528717 0.002431733 4.329717 3.666742e-05 0.005762608 0.01529483\n#> 3  0.012012149 0.002481787 4.840121 4.953470e-06 0.007147936 0.01687636\n#> 4  0.010157661 0.002184751 4.649346 1.062203e-05 0.005875628 0.01443969\n#> 5  0.008278299 0.002196057 3.769619 2.823851e-04 0.003974105 0.01258249\n#> 6  0.007332724 0.001902623 3.854009 2.099684e-04 0.003603652 0.01106180\n#> 7  0.007587459 0.002298507 3.301038 1.353268e-03 0.003082468 0.01209245\n#> 8  0.011544261 0.002355257 4.901486 3.862050e-06 0.006928041 0.01616048\n#> 9  0.013659555 0.002084708 6.552264 2.816820e-09 0.009573603 0.01774551\n#> 10 0.011693386 0.002347295 4.981643 2.783172e-06 0.007092772 0.01629400\nAs a note, the output of the fit_mods function is the output given as the second element of the list returned by a call to eesim.\nEvaluating the models\nThe final step of the eesim function is to evaluate model performance across all simulations with several different measures. Within the eesim function, the check_sims function takes as inputs the true relative risk as well as the results from fitting the modeling function to all the simulations using the fim_mods function. It returns values for the mean effect estimate (log relative risk) and relative risk estimates across all simulated data sets, variance of the estimates of beta, the mean of the variances of each estimated log relative risk, the relative bias of the mean of the log relative risks, the percent coverage confidence intervals of the true log relative risk, and the power of the test at the 5% significance level (see the table near the beginning of the vignette).\nHere is an example of the use of the check_sims function:\ncheck_sims(fits, true_rr = 1.01)\n#>     beta_hat rr_hat var_across_betas mean_beta_var percent_bias coverage\n#> 1 0.01054249 1.0106     4.763804e-06  5.183017e-06  -0.05944768        1\n#>   power\n#> 1     1\nIn a run of eesim, this output is given in the third element of the returned list.\nInternally, the functions used for this model assessment are:\n\nbeta_bias\nbeta_var\ncoverage_beta\nmean_beta\npower_beta\n\nA few more details about how some of these assessments are measured are given below.\nVariance across estimated log relative risk and mean variance of estimates\nTwo values are measured by the beta_var function. First, the variance across all estimates of log relative risk is measured across all the simulations, using the equation:\n$$\n\\text{variance of estimates} = E\\left[\\left(\\hat{\\beta_i} - \\frac{1}{n}\\sum_{i = 1}^n{\\hat{\\beta_i}}\\right)\\right]\n$$\nwhere $\\hat{\\beta_i}$ is the estimated log relative risk for a single simulation out of n total simulations and E represents the expected value.\nSecond, the function measures the mean value of the variance estimated for $\\hat{\\beta}$ for each simulation:\n$$\n\\text{mean of estimate variances} = \\frac{1}{n}\\sum_{i = 1}^{n}{var(\\hat{\\beta_i})}\n$$\nwhere $var(\\hat{\\beta_i})$ is the estimated variance of the estimated log relative risk for a single simulation out of n total simulations.\nRelative bias\nHere is the equation used by the beta_bias function to estimate relative bias in estimates from the simulated data:\n$$\n\\text{relative bias} = 100*\\frac{\\beta - \\frac{1}{n}\\sum_{i = 1}^{n}{\\hat{\\beta}}}{\\beta}\n$$\nwhere \u03b2 is the true log relative risk used to simulate the data and $\\hat{\\beta}$ is the estimated log relative risk from simulation i (out of a total of n simulations).\nGenerating power curves\nThe other main functionality of the eesim package is to run through simulations under varying data generating scenarios to estimate expected power of an analysis under different scenarios. For example, you can explore how expected power varies for different expected effect sizes (relative risk of the outcome associated with a change in exposure) or for different average daily number of outcomes. This is run using the power_calc function in the package.\nThe power_calc function allows you to put in varying values for one of the following three specifications in the simulations:\n\nRelative risk (rr): How you strongly expect the exposure and outcome to be associated\nNumber of days in the study (n): How long you expect the study to last (or how many days of historical data you expect to be able to collect)\nAverage daily count of outcomes (average_outcome): For the outcome of interest, how common it is on average on days in the study (this will usually be strongly associated with the size of the population being studied)\n\nFor whichever of these you choose to vary, you can specify different values to test. The power_calc function then loops through those values and runs eesim for each of them. From this, it can estimate the power for each value of the varying parameter.\nHere is an example of running a power calculation with varying number of days in the study (n). The values argument is used to specify different values of n we would like to test (here, it's testing power for studies with daily data for between 1 and 21 years):\npow <- power_calc(varying = \"n\", values = floor(365.25 * seq(1, 21, by = 5)), n_reps = 20,\n                  central = 100, sd = 10, rr = 1.001, exposure_type = \"continuous\",\n                  exposure_trend = \"cos1\", exposure_amp = .6, average_outcome = 22,\n                  outcome_trend = \"no trend\", outcome_amp = .6,\n                  custom_model = spline_mod, plot = TRUE)\n#> This function may take a minute or two to run, especially with\n#> lots of replications (`n_reps`) or options for `values`.\n\nThis call returns a dataframe with the estimated power for each of the values of n tested:\npow\n#>   values power\n#> 1    365  0.15\n#> 2   2191  0.60\n#> 3   4017  0.85\n#> 4   5844  0.90\n#> 5   7670  1.00\nBecause the argument plot is set to TRUE, it also generates a power curve plot as a side effect, as shown above.\nHere is another example, but this time we assume that the study will have 4,000 days of daily data, but we explore estimated power as the average daily outcome count varies:\npow2 <- power_calc(varying = \"average_outcome\", values = c(1, 5, 10, 20, 30, 40),\n                   n_reps = 20,\n                   central = 100, sd = 10, rr = 1.001, exposure_type = \"continuous\",\n                   exposure_trend = \"cos1\", exposure_amp = .6, n = 4000,\n                   outcome_trend = \"no trend\", outcome_amp = .6,\n                   custom_model = spline_mod, plot = TRUE)\n#> This function may take a minute or two to run, especially with\n#> lots of replications (`n_reps`) or options for `values`.\n\npow2\n#>   values power\n#> 1      1  0.20\n#> 2      5  0.25\n#> 3     10  0.35\n#> 4     20  0.70\n#> 5     30  0.90\n#> 6     40  0.95\nBecause these power curves and calculations are based on simulated data, there will be some randomness to results. Curves will be smoother as more simulations are used for each run (n_reps), although this will also increase the time needed to run the simulation.\nUsing custom functions\nAn important feature of eesim is that the user can create and use custom functions for any part of the simulation process. For example, the user may wish to generate exposure data with a custom trend, then automate the process of generating outcomes, fitting models, and evaluating performance using the built-in features of eesim. Functions the user has the option to customize within the eesim framework are:\n\nThe underlying expected exposure value on each day. Through this, the user can use customized long-term and seasonal trend patterns or can build a simulation starting from a running mean of observed exposure data.\nHow exposure values are randomized from the underlying trend. This allows a user to, for example, use a distribution other than normal (for continuous exposure data) or binomial (for binary data) as the underlying distribution of the exposure data.\nThe underlying pattern in the expected outcome baseline, before the influence of the exposure is added. Through this, the user can use a custom pattern of long-term and seasonal trends in expected health outcome rates in the simulated data. This functionality can also be used to include any expected influence on the baseline outcome rate from daily-varying values other than the exposure of interest.\nHow exposure influences the expected outcome rate. The user can create a function that inputs the expected baseline outcome count and simulated exposure levels for each day and outputs the expected outcome rate on each day, including any added or reduced risks caused by the exposure. This functionality can be used, for example, to simulate outcomes with a non-linear relationship with the exposure or with lagged exposure effects.\nHow outcome counts are randomized from the underlying expected outcome rate. This allows users to, for example, use a negative binomial or overdispersed Poisson distribution as the underlying distribution of the outcome counts.\n\nTo use custom functions within eesim, the user must input the name of the custom function as well as a list of all arguments for the custom function and their values (examples shown below). This allows the user to pass the function and required arguments directly within a call to the main eesim function. When a custom function is used, many inputs that are otherwise required for the eesim function may no longer be necessary, in which case they can simply be left out of the eesim call. As a note, if extensive customize is required for several steps of the simulation process, it may make more sense to code the full simulation by hand rather than using the eesim framework.\nCustomizing the exposure trend\nTo take advantage of any of the customization options, you need to write a function that follows certain input and output (i.e., interface) rules. First, you can use a custom function for the underlying trend in expected exposure. This function must take the inputs:\n\nn (the number of days to simulate)\nEither mean for a continuous exposure (the average value of the outcome) or prob for a binary exposure (the average probability of exposure)\n\nThe function can take any other additional inputs, as well, but any such extra arguments (as well as mean) will need to be input to the eesim function in a list for the cust_expdraw_args argument (example below). The value for n will pass through directly from the n value specified for the call to eesim. The function must output a numeric vector that gives the simulated exposure values for each day in the simulated data.\nFor example, the following function creates a custom exposure trend with a long-term and seasonal trend, similar to trends available through the default package options. However, this function specifies a minimum value that the exposure trend cannot fall below-- if the base exposure value is every set below this minimum within the algorithm, the value is reset to the minimum before the final values are output. This function can be useful in cases where the exposure cannot fall below a certain value (for example, a pollution concentration could not be lower than 0). This custom exposure function can also be used to customize how values are simulated from the expected exposure on each day (based on the expected distribution of the exposure). In the case of the example ozone concentration data from Chicago shown earlier in this vignette, we may want to simulate exposure based on the assumption that the square root of exposure is normally distributed, which will prevent negative values and may also help to simulate occasional very high values.\nabove_min_trend <- function(n, mean, sd_of_sqrt, minimum = 0){\n  day <- c(1:n)\n  \n  ## Calculate a baseline exposure for each day\n  base <- mean + -10 * cos(2 * pi * (day \/ 365))\n  base[base < minimum] <- minimum            # Reset any values below 0 to 0\n  \n  ## Simulate exposure values from the baseline\n  sqrt_base <- sqrt(base)                   # Transform to square root\n  sqrt_sim <- rnorm(n, mean = sqrt_base, sd = sd_of_sqrt)\n  sqrt_sim ^ 2                              # Transform back\n}\nHere is an example of running this custom exposure simulation function over 5 years, with a smooth line added to the plot to help show the seasonal trend included:\nabove_min_trend(n = 365.25 * 5, mean = 20, minimum = 0, sd_of_sqrt = 0.9) %>% \n  tbl_df() %>% \n  mutate(day = 1:n()) %>% \n  ggplot(aes(x = day, y = value)) + \n  geom_point(alpha = 0.5, size = 0.8) + \n  theme_classic() + \n  geom_smooth(se = FALSE, span = 0.1, method = \"loess\", color = \"red\")\n\nYou can then pass this custom function into the eesim function using the cust_exp_func argument. The value for n input to the custom function will be the value you input to eesim for n. For any other arguments you want to pass to the function (in the function we just created, you'll want to pass values for mean, minimum, and sd_of_sqrt), you can include specifications for these as a list for the cust_exp_args argument of eesim. For example, the following call would run a simulation using this custom function for exposure:\nex_sim2 <- eesim(n_reps = 1, n = round(365.25 * 5), \n                 exposure_type = \"continuous\",\n                 cust_exp_func = above_min_trend,\n                 cust_exp_args = list(mean = 20, minimum = 0, sd_of_sqrt = 0.9),\n                 average_outcome = 50, rr = 1.01, \n                 custom_model = spline_mod, custom_model_args = list(df_year = 7))\nCustomizing the outcome simulation\nThere are three ways to customize the simulated outcome data: creating a custom baseline for outcome values, customizing the relationship between outcome and exposure, and, as with the exposure values, customizing the randomization of the outcome values.\nThe outcome baseline (Bt) is comprised of the values the user expects the outcomes to have on each day of the simulated dataset without risk associated with the exposure factored in. The user may write a function to specify the trend of the baseline, then use it as an input in sim_outcome or eesim. Here is an example of creating a custom baseline function and using it in the eesim function:\ncustombase <- function(n, slope, intercept){\n  day <- c(1:n)\n  baseline <- day * slope + intercept\n  return(baseline)\n}\n\n#Example:\ncustombase(n=5, slope = .3, intercept = 55)\n#> [1] 55.3 55.6 55.9 56.2 56.5\n\nex_sim3 <- eesim(n_reps = 3, n = 1000, central = 100, sd = 10,\n                exposure_type = \"continuous\", exposure_trend = \"cos1\",\n                exposure_amp = .6, average_outcome = 22, rr = 1.01, \n                cust_base_func = custombase,\n                cust_base_args = list(n=1000, slope = 5, intercept = 12),\n                custom_model = spline_mod, custom_model_args = list(df_year = 2))\n#> This function may take a minute or two to run, especially if you\n#> are creating lots of replications (`n_reps`).\nggplot(ex_sim3$simulated_datasets[[1]], aes(x=date, y=outcome))+ geom_point() + geom_point(alpha = 0.5, size = 0.8) + \n  theme_classic() + \n  geom_smooth(se = FALSE, span = 0.1, method = \"loess\", color = \"red\")\n\nThe second way of customizing the outcome simulation is to use a custom function to incorporate the added risk from the exposure when calculating the expected daily outcome count for a day, \u03bbt, from the inputs of exposure (Xt) and outcome baseline (Bt) for the day. Here is an example of creating a custom lambda, meaning a custom function relating relative risk and exposure to outcomes, and using it in eesim with the custom baseline function created above. The custom lambda function must input arguments exposure, rr, and baseline and output a vector of lambda values.\ncustomlambda <- function(exposure, rr, constant, baseline){\n  log_lambda <- log(baseline) + log(rr) * exposure + constant\n  lambda <- exp(log_lambda)\n  return(lambda)\n}\n\nex_sim4 <- eesim(n_reps = 3, n = 1000, central = 100, sd = 10,\n                exposure_type = \"continuous\", exposure_trend = \"cos1\",\n                exposure_amp = .6, average_outcome = 22, rr = 1.01, \n                cust_base_func = custombase,\n                cust_base_args = list(n=1000, slope = .5, intercept = 12),\n                cust_lambda_func = customlambda, cust_lambda_args = list(constant=10),\n                custom_model = spline_mod, custom_model_args = list(df_year = 2))\n#> This function may take a minute or two to run, especially if you\n#> are creating lots of replications (`n_reps`).\nThe third way to customize the outcome simulation is to customize the randomization of the outcome values from the trend created by relating the baseline outcomes and the exposure (what we have called lambda). When the cust_outdraw argument is not specified in the eesim function, the function draws outcome values from a Poisson distribution with mean lambda. A custom function for outcome draws must input values called n and lambda, and any other arguments must be included in the cust_outdraw_args argument. Here is an example of using the custom functions to specify a negative binomial distribution for outcome randomization:\ncustnbinom <- function(n, lambda, prob){\n  out <- rnbinom(n=n, size=lambda, prob=prob)\n  return(out)\n}\n\nex_sim5 <- eesim(n_reps = 3, n = 1000, central = 100, sd = 10,\n                exposure_type = \"continuous\", exposure_trend = \"cos1\",\n                exposure_amp = .6, average_outcome = 22, rr = 1.01, \n                cust_base_func = custombase,\n                cust_base_args = list(n=1000, slope = .5, intercept = 12),\n                cust_lambda_func = customlambda, cust_lambda_args = list(constant=10),\n                cust_outdraw = custnbinom, cust_outdraw_args = list(prob=.3), \n                custom_model = spline_mod, custom_model_args = list(df_year = 2))\n#> This function may take a minute or two to run, especially if you\n#> are creating lots of replications (`n_reps`).\nReferences\nBateson, Thomas F, and Joel Schwartz. 1999. \u201cControl for Seasonal Variation and Time Trend in Case-Crossover Studies of Acute Effects of Environmental Exposures.\u201d Epidemiology 10 (5): 539\u201344.\n","385":"\n\nOverview of package\nThis package allows you to simulate time series of environmental health data and perform simulation-based power analyses and other measures of model performance. The package includes four main parts:\n\nGeneration of exposure data (simulated or from real data);\nGeneration of simulated outcome data;\nFitting models to generated data; and\nEvaluating model performance on generated data.\n\nThe user has the option to customize different aspects of the simulation at each of these steps.\nThe package creates simulated time series data that are relevant for environmental epidemiology studies of ambient exposures (e.g., studies of acute mortality risks associated with daily air pollution concentration, daily temperature, or occurance of a community-wide extreme event like a heat wave). Simulated environmental datasets like those created by the package can be used in to assess the performance of statistical models meant to estimate the association between exposure level and outcome risk, to estimate power for a planned study, and to develop a better understanding of the data generating processes behind observed environmental datasets. Such time series are often characterized by both seasonal and long-term trends in both the exposure of interest and the outcome. For example, the following plot shows time series of daily ozone concentration (in parts per billion [ppb]) and cardiovascular deaths in Chicago, IL (1996--2000), with smoothed lines overlaid on the raw data to show patterns over time.\n\nBasic example of using the package\nThe main function of this package is the eesim function. You can use the eesim function to conduct all four steps of the simulation process at once (generate exposure data, generate outcome data, fit models to simulated data, and evaluate model performance).\nThe eesim function requires inputs on:\n\nn: The desired number of observations per simulated dataset (for a daily time series, this is the desired number of days in the simulated dataset)\nn_reps: The desired number of simulated datasets\nexposure_type: Whether the exposure is binary (e.g., occurence of an extreme event like a heat wave or wildfire) or continuous (e.g., concentration of a pollutant)\nrr: The relative rate of the outcome associated with the exposure. For a binary exposure, this is the relative rate associated with the exposure compared to a similar day without the exposure. For a continuous exposure, this is the relative rate associated with a one-unit increase in the exposure.\nmodel: The model to be used to estimate the association between exposure and outcome in the simulated datasets, either to estimate power of a planned analysis or to otherwise evaluate the performance (e.g., coverage, bias) of a model on the simulated datasets.\n\nA number of optional inputs can also be specified, including arguments to adjust the shape of seasonal or long-term trends in the exposure or outcome data or custom arguments to use at different steps of the data generation.\nThe function returns a list with three elements. The first element is a list with all the simulated datasets. The second element gives simulation-specific results for each simulated dataset: the estimated effect, standard error, t- and p-values, and upper and lower 95% confidence bounds when a model was applied to each of the simulated datasets. The third element gives some measures of model assessment, assessed over all simulations, including the mean beta and relative risk estimates across simulations.\nFor example, in the observed data from Chicago, IL, shown in the plots above, daily ozone concentrations have a mean of about 20 ppb and standard deviation of about 7 ppb after removing seasonal and long-term trends. The average number of cardiovascular deaths per day is around 50. Here is the code, and a plot of the resulting data, for generating a dataset with similar characteristics for use in a power analysis or to evaluate model performance (later in the vignette, we will show how to use customization to further improve the simulation of data for this example, including avoiding negative values of ozone concentration in simulated data):\nsim_chicago <- create_sims(n_reps = 1, n = 365 * 5, central = 20, sd = 7,\n                           exposure_type = \"continuous\", exposure_trend = \"cos1\",\n                           exposure_amp = -.6, average_outcome = 50,\n                           outcome_trend = \"cos1\", outcome_amp = 0.2, \n                           rr = 1.0005, start.date = \"1996-01-01\")\nhead(sim_chicago[[1]])\n#>         date          x outcome\n#> 1 1996-01-01 14.8541083      64\n#> 2 1996-01-02  3.1952265      78\n#> 3 1996-01-03  0.4101124      72\n#> 4 1996-01-04 10.4824504      69\n#> 5 1996-01-05 18.9213207      58\n#> 6 1996-01-06  7.8855542      56\n\nThis simulated data can also be visualized using the calendar_plot function that comes with the package:\na <- calendar_plot(sim_chicago[[1]] %>% select(date, outcome), type = \"continuous\", \n                   legend_name = \"Outcome\") + \n  ggtitle(\"Outcome\")\nb <- calendar_plot(sim_chicago[[1]] %>% select(date, x), type = \"continuous\") + \n  ggtitle(\"Exposure\")\ngrid.arrange(a, b, ncol = 1)\n\nYou can use the eesim function to generate multiple similar simulated datasets and investigate the performance of a specified model in estimating the association between ozone concentration and the risk of cardiovascular death in 20 simulated datasets. You must write a function with the code to fit the model you desire to fit to the simulated data (more details for writing this function are provided later in the vignette), and then you can use the eesim function to generate lots of simulated datasets, fit that model, and assess its performance using a call like:\nex_sim <- eesim(n_reps = 100, n = 365 * 5, central = 20, sd = 7,\n                exposure_type = \"continuous\", exposure_trend = \"cos1\",\n                exposure_amp = -.6, average_outcome = 50,\n                outcome_trend = \"cos1\", outcome_amp = 0.2, \n                rr = 1.2, start.date = \"1996-01-01\",\n                custom_model = spline_mod, custom_model_args = list(df_year = 7))\nThe eesim function returns a list with three elements:\nnames(ex_sim)\n#> [1] \"simulated_datasets\"  \"indiv_performance\"   \"overall_performance\"\nThe first element of the returned object is a list with all of the simulated datasets. For example, you can create a calendar plot of exposure in the first simulated dataset using the call:\ncalendar_plot(ex_sim[[\"simulated_datasets\"]][[1]] %>% select(date, x), type = \"continuous\")\n\nThe second element of the returned object gives the results of fitting the model to each of the simulated datasets. It can be used to explore the behavior of individual simulations:\nhead(ex_sim[[\"indiv_performance\"]])\n#>    Estimate    Std.Error  t.value p.value  lower_ci  upper_ci\n#> 1 0.1827175 0.0002469170 739.9956       0 0.1822335 0.1832014\n#> 2 0.1825011 0.0002090035 873.1962       0 0.1820914 0.1829107\n#> 3 0.1821313 0.0002323444 783.8852       0 0.1816760 0.1825867\n#> 4 0.1821526 0.0002287805 796.1893       0 0.1817042 0.1826010\n#> 5 0.1823460 0.0002251761 809.7930       0 0.1819047 0.1827874\n#> 6 0.1823111 0.0002364797 770.9377       0 0.1818476 0.1827746\nAfter running the simulation, you can look at the relative risk point estimate and 95% confidence interval from each of the 100 simulations, as well as which 95% confidence intervals include the true relative rate, using the coverage_plot function that comes with the package:\ncoverage_plot(ex_sim[[\"indiv_performance\"]], true_param = 1.2)\n\nThe third element of the list returned by a call to eesim gives the following overall summaries of model performance across all simulations:\n\n\n\nVariable\nDescription\n\n\n\n\nbeta_hat\nMean estimate: The mean of the estimated log relative rate over all simulations.\n\n\nrr_hat\nMean estimated relative rate: The mean of the estimated relative rate over all simulations.\n\n\nvar_across_betas\nVariance across estimates: Variance of the point estimates (estimated log relative risk) over all simulations.\n\n\nmean_beta_var\nMean variance of estimate: The mean of the variances of the estimated effect (estimated log relative risk) across all simulations.\n\n\npercent_bias\nRelative bias: Difference between the estimated log relative risk and true log relative risk as a proportion of the true log relative risk.\n\n\ncoverage\n95% confidence inverval coverage: Percent of simulations for which the 95% confidence interval estimate of log relative risk includes the true value of log relative risk.\n\n\npower\nPower: Percent of simulations for which the null hypothesis that the log relative risk equals zero is rejected based on a p-value of 0.05.\n\n\n\nFor example, here are the overall results for the simulation fit above:\nex_sim[[\"overall_performance\"]]\n#>    beta_hat   rr_hat var_across_betas mean_beta_var percent_bias coverage\n#> 1 0.1823186 1.199996     4.880753e-08  5.593839e-08  0.000296735     0.95\n#>   power\n#> 1     1\nIn later sections of this vignette, we will show how to customize steps in the generation of the simulated data to further improve this example simulation.\nAs another basic example, here is a plot of the dates of extreme heat days (defined as a day with temperature at or above the 98 percentile temperature in Chicago between 1987 and 2000) in the observed Chicago dataset (points are jittered along the y-axis to limit overlapping):\n\nIn this observed data, there is (unsurprisingly) a strong seasonal trend in this binary exposure of extreme heat days. The percent of days that are extreme heat days is 0% for all months expect June (about 5% of days in observed data were extreme heat days), July (about 12% of days), and August (about 2% of days). Similar exposure time series can be simulated with the call:\nsim_chicago2 <- create_sims(n_reps = 1, n = 365 * 5, sd = 1,\n                            central = c(0, 0, 0, 0, 0, 0.05, 0.12, 0.02, 0, 0, 0, 0),\n                            exposure_type = \"binary\", exposure_trend = \"monthly\",\n                            exposure_amp = -.6, average_outcome = 50,\n                            outcome_trend = \"cos1\", outcome_amp = 0.2, \n                            rr = 1.05, start.date = \"1996-01-01\")\nHere is an example of the simulated exposure data:\n\nAgain, both the observed and simulated exposure data can also be plotted using the calendar_plot function:\na <- chicagoNMMAPS %>% \n  mutate(temp = temp >= quantile(temp, probs = 0.98)) %>% \n  tbl_df() %>% \n  filter(year >= 1996) %>% \n  select(date, temp) %>% \n  calendar_plot(type = \"discrete\", labels = c(\"Extreme heat day\", \"Other day\")) + \n  ggtitle(\"Observed exposure data\")\nb <- sim_chicago2[[1]] %>% \n  select(date, x) %>% \n  calendar_plot(type = \"discrete\", labels = c(\"Extreme heat day\", \"Other day\")) + \n  ggtitle(\"Simulated exposure data\")\ngrid.arrange(a, b, ncol = 1)\n\nThe comparison of the observed and simulated data in this case suggests some clustering in the observed data that is not evident in the simulated data, suggesting that the probability of exposure may be higher on a day near other extreme heat days.\nThe eesim function can be used to assess the performance of a GLM in estimating relative risk of cardiovascular mortality for extreme heat days compared to other days using:\nex_sim2 <- eesim(n_reps = 100, n = 365 * 5, \n                 central = c(0, 0, 0, 0, 0, 0.05, 0.12, 0.02, 0, 0, 0, 0),\n                 exposure_type = \"binary\", exposure_trend = \"monthly\",\n                 exposure_amp = -.6, average_outcome = 50,\n                 outcome_trend = \"cos1\", outcome_amp = 0.2, \n                 rr = 1.05, start.date = \"1996-01-01\",\n                 custom_model = spline_mod, custom_model_args = list(df_year = 7))\n#> This function may take a minute or two to run, especially if you\n#> are creating lots of replications (`n_reps`).\nAs before, a plot of CI coverage can be created with coverage_plot:\ncoverage_plot(ex_sim2[[\"indiv_performance\"]], true_param = 1.05)\n\nHere are the overall estimates in this case for model performance:\nex_sim2[[\"overall_performance\"]]\n#>     beta_hat   rr_hat var_across_betas mean_beta_var percent_bias coverage\n#> 1 0.04617133 1.047885      0.001214473  0.0009170105    0.2014185     0.92\n#>   power\n#> 1  0.34\nIn this case, the expected power is low.\nThe power_calc function in the package allows you to extend on this simulation functionality to create power curves for an analysis given an anticipated underlying process of data generation. This function will create simulations for several different values of number of days in the study (n), average daily outcome counts (average_outcome), or expected association between exposure and outcome (rr).\nFor example, the following call generates a power curve that explores how expected power changes with an increasing number of days for the heat wave analysis example just presented (as a warning, this call takes a few minutes to run, since it's simulating many datasets):\nex_power_calc <- power_calc(varying = \"n\", values = floor(365.25 * seq(1, 20, by = 5)),\n                            n_reps = 100, rr = 1.05,\n                            central = c(0, 0, 0, 0, 0, 0.05, 0.12, 0.02, 0, 0, 0, 0),\n                            exposure_type = \"binary\", exposure_trend = \"monthly\", \n                            exposure_amp = -.6, average_outcome = 50,\n                            outcome_trend = \"cos1\", outcome_amp = 0.2, \n                            custom_model = spline_mod, custom_model_args = list(df_year = 7),\n                            plot = FALSE)\n#> This function may take a minute or two to run, especially with\n#> lots of replications (`n_reps`) or options for `values`.\nex_power_calc %>% \n  ggplot(aes(x = values, y = power)) + \n  geom_line() + \n  ylim(0, 1) + \n  labs(x = \"Number of days in the study\", y = \"Power\") + \n  theme_bw()\n\nPiece-by-piece breakdown of package utility\nTo demonstrate how the eesim function works, here is a breakdown of each of the four main parts: generating exposure data, generating outcome data, fitting models, and evaluating models. The helper functions used for each step are described in detail in this section.\nGenerating exposure data\nThe first task of the package is generating exposure data. This can be done with the sim_exposure function. In this function, the user can specify whether he or she would like to generate exposure data that is binary or continuous (exposure_type). For continuous exposure data, the user must specify the mean (central) and standard deviation (sd) of the exposure data. For example, the following call simulates a dataframe of exposure data for an exposure that is normally distributed, with a mean value of 50, a standard deviation of 5, and no long-term or seasonal trends:\nx_cont <- sim_exposure(n = 1000, central = 50, sd = 5, exposure_type = \"continuous\") \nx_cont %>% slice(1:5)\n#>         date        x\n#> 1 2001-01-01 51.79315\n#> 2 2001-01-02 51.69743\n#> 3 2001-01-03 50.91866\n#> 4 2001-01-04 51.84013\n#> 5 2001-01-05 53.22749\nggplot(x_cont, aes(x = date, y = x)) + geom_point(alpha = 0.2) + \n  theme_classic()\n\nYou can plot a calendar plot of this simulated exposure time series using the calendar_plot function that comes with the package. Within this function, the type of data (\"continuous\" or \"discrete\") must be specified:\ncalendar_plot(x_cont, type = \"continuous\")\n\nYou can similarly use the sim_exposure function to simulate a binary exposure (e.g., occurence of an extreme event). For binary exposure data, the central argument of sim_exposure must also be expressed, but in this case it gives the probability of exposure on a study day:\nx_bin <- sim_exposure(n = 1000, central = 0.05, exposure_type = \"binary\")\nx_bin %>% slice(1:5)\n#>         date x\n#> 1 2001-01-01 0\n#> 2 2001-01-02 0\n#> 3 2001-01-03 0\n#> 4 2001-01-04 0\n#> 5 2001-01-05 0\nAgain, the calendar_plot function can be used to visualize the generated time series. In the case of binary exposure data, the labels to be used in the legend for each outcome level must also be specified using the labels argument:\ncalendar_plot(x_bin, type = \"discrete\", labels = c(\"Not exposed\", \"Exposed\"))\n\nSo far, these sim_exposure calls have been used to simulate basic exposure data, without long-term or seasonal trends. However, for environmental epidemiology applications, exposure data often has a seasonal trend and \/ or long-term trend, and these temporal trends can serve as confounders in assessing the association between time-varying environmental exposures and health outcomes. The sim_exposure function therefore includes options to generate exposure data with long-term and seasonal trends relevant to environmental time series studies, through the trend argument.\nThe default for sim_exposure is to simulate the exposure data without a time trend (trend = \"no trend\"). However, we have also built in several time trends from which a user can to choose to simulate exposure data with a time trend, either seasonal or long-term or both, based on trend patterns used in a simulation study of case-crossover studies as a method of controlling for seasonal and long-term trends in environmental epidemiology studies (Bateson and Schwartz 1999). These trend patterns differ slightly depending on whether the user is simulating binary or continuous data. Below are plots of the built-in trends for continuous exposure data from which the user may choose. \nYou can use the amp argument to adjust the seasonal trend in any of the patterns with a seasonal trend. For example, here are plots of trends using tren = \"cos1linear\" for different values of amp:\n\nThe long-term trend in expected values can be changed in a similar way with the exposure_trend argument in eesim.\nHere is an example of generating continuous exposure data with a \"cos1linear\" trend for an exposure with a mean value of 50 and a standard deviation of 10:\ntestexp <- sim_exposure(n = 365 * 3, central = 50, sd = 10, trend = \"cos1linear\",\n                        exposure_type = \"continuous\")\na <- ggplot(testexp, aes(x = date, y = x)) +  \n  geom_point(alpha = 0.5, size = 0.8) + \n  coord_cartesian(ylim = c(0,110)) + \n  labs(title = \"Exposure with a 'cos1linear' trend\", x = \"Date\", y=\"Exposure\") + \n  theme_classic()\nb <- calendar_plot(testexp, type = \"continuous\") + \n  ggtitle(\"Calendar plot of simulated exposure data\") + \n  theme(legend.position = \"bottom\")\ngrid.arrange(a, b, ncol = 1)\n\nHere is an example of changing the seasonal trend by changing the value for amp (the default value is 0.6) to simulate exposure data for an exposure with a smaller seasonal trend and with higher exposures typical in the summer than the winter:\nsmall_amp <- sim_exposure(n = 365 * 3, central = 50, sd = 10, trend = \"cos1linear\",\n                        amp = -0.3, exposure_type = \"continuous\")\na <- ggplot(small_amp, aes(x = date, y = x)) +  \n  geom_point(alpha = 0.5, size = 0.8) + \n  coord_cartesian(ylim = c(0,110)) + \n  labs(title = \"Exposure with a 'cos1linear' trend\", x = \"Date\", y=\"Exposure\") + \n  theme_classic()\nb <- calendar_plot(small_amp, type = \"continuous\") + \n  ggtitle(\"Calendar plot of simulated exposure data\") + \n  theme(legend.position = \"bottom\")\ngrid.arrange(a, b, ncol = 1)\n\nThe trend options are similar for binary exposure, but exclude \"curvilinear\" and \"cos1linear\". Further, binary exposures can also be simulated using a \"monthly\" trend (trend = \"monthly\"), in which the probability of exposure can vary by month. When using this \"monthly\" trend option, the cental argument to sim_exposure should include a vector with 12 separate probabilities (the first is for January, the second for February, etc.) rather than a single probability. Here is an example of generating binary exposure data with a monthly trend, starting from June 1, 2002, with higher probability of the exposure in summer months than in winter months:\ntestbin <- sim_exposure(n=1000, central = c(.05, .05, .1, .2, .4, .4, .5, .7, .5, .2, .1, .05),\n                        trend = \"monthly\", exposure_type = \"binary\", \n                        start.date = \"2002-06-01\")\na <- testbin %>% \n  mutate(x = factor(x, levels = c(0, 1), labels = c(\"Not exposed\", \"Exposed\"))) %>% \n  ggplot(aes(x = date, y = x)) + \n  geom_jitter(alpha = 0.5, size = 0.7, fill = NA, width = 0, height = 0.1) + \n  theme_classic() + \n  labs(x = \"Date\", y = \"Exposure\")\nb <- calendar_plot(testbin, type = \"discrete\", labels = c(\"Not exposed\", \"Exposed\")) + \n  ggtitle(\"Calendar plot of simulated exposure data\") + \n  theme(legend.position = \"bottom\")\ngrid.arrange(a, b, ncol = 1)\n\nThe sim_exposure function works by first calculating the expected exposure on any date in the simulated time series (figure below, left). This expected value is a mean for a continuous exposure and a probability for a binary exposure. The sim_exposure function then draws random values from the appropriate distribution (normal distribution for a continuous exposure, binomial distribution for a binary exposure) based on this day-specific expected exposure value and, in the case of continuous exposure, the standard deviation of the exposure (figure below, right). For continuous exposure data, the standard deviation specified in the call to eesim should measure the standard deviation of each point from its expected value (i.e., from the expected line shown on the left below), not the overall standard deviation of exposure values across all days in the simulated data.\n\nLater in this vignette, we show how you can further customize this step of generating exposure data through the use of a user-created function, allowing extensive further flexibility in simulating exposure data.\nGenerating outcome data\nNext, the sim_outcome function simulates outcome data. The health data can have an underlying seasonal and \/ or long term trend in its baseline value, and then that baseline is adjusted for the risk associated with exposure, based on the generated exposure data for that day. The baseline outcome count for a given day (Bt) are based on a user-specified trend and user-specified average outcome per day over the simulated time period. Further, the expected outcome count on a given day is adjusted for exposure-related risk through a user-specified relative rate per unit increase in exposure (R**R) and the simulated exposure for that day (Xt). The eesim function then uses the following equation to calculate the expected outcome count (\u03bb) on a given day in the simulated time series, based on the expected baseline rate and exposure-related risk for that day:\nlog(\u03bbt)=log(Bt)\u2005+\u2005log(R**R)\u2005*\u2005Xt\nFor a binary outcome, the baseline count on a given day (Bt) is the expected outcome count for the day if there is not an event (e.g., in a heat wave study, a non-heat wave day). For a continuous exposure, the baseline count on a given day (Bt) is the expected outcome count for the day if exposure is at its mean value.\nOnce the expected count (\u03bbt) on each day of the simulated time series is calculated using this equation, the simulated count on each day is drawn as a random variable from a Poisson distribution with mean \u03bbt. Later we describe how customization can be used to simulate output counts in other ways.\nHere is an example of generating health outcome data with an upward linear trend using exposure data with a \"cos1\" trend. In this case, there is a steady increase in the baseline outcome count over time, as well as a seasonal trend linked to the risk associated with the seasonally-varying exposure:\ntestexp2 <- sim_exposure(n = 1000, central = 100, sd = 10, trend = \"cos1\",\n                         exposure_type = \"continuous\")\ntestout <- sim_outcome(exposure = testexp2, average_outcome = 22,\n                       trend = \"linear\", rr = 1.01)\nHere are plots of the resulting output:\n\nAs with the exposure simulation step, this step can also be extensively customized by using a user-created function. This customization will be demonstrated in a later section of the vignette.\nFitting models\nNext, the eesim package uses this process to generate many simulated data sets and then to fit statistical models to these generated datasets. This step allows tests of model performance. You must create an R function that fits the model you'd like to fit to the simulated dataset. This function needs to follow certain input \/ output rules to work correctly in the eesim framework. First, it must input the simulated dataframe with the argument df. When writing the function, you should assume that this simulated dataframe has at least the columns date (in a Date format), x (numeric class, this gives a daily value for exposure, with 0 for unexposed and 1 for exposed in the case of binary exposure), and outcome (non-negative integer, this gives the simulated outcome count each day). Other arguments can also be passed to this function if desired. The function should fit a desired model to the simulated dataframe and then should return a numeric vector of length 6 with values, in this order, for the log relative risk point estimate from the model (Estimate), the standard error for this point estimate (Std. Error), the t-statistic for a hypothesis test with the null hypothesis that this estimate is zero (t value), a p-value for that test (Pr(>|t|)), and the lower and upper 95% confidence intervals for the point estimate (2.5 % and 97.5 %).\nThe spline_mod function that comes with the package is an example of such a function. In this case, the function fits a GLM to the simulated data, with a natural cubic spline used to control for long-term and seasonal trends in mortality. The function, in addition to inputing the dataframe of simulated data (df), also allows an argument to use to set the smoothness of the time spline (df_year). Since the function is included in the package, you can see its code by running the bare function name at the console:\nspline_mod\n#> function(df, df_year = 7){\n#>   dgrs_free <- df_year * as.numeric(diff(df[c(1, nrow(df)), \"date\"])) \/ 365.4\n#>   df$time <- scale(df$date, center = TRUE, scale = FALSE)\n#>   mod <- stats::glm(outcome ~ x + splines::ns(time, round(dgrs_free)),\n#>                    data = df,\n#>                    family = stats::quasipoisson(link = \"log\"))\n#> \n#>   out_1 <- summary(mod)$coef[2, ]\n#>   out_2 <- stats::confint.default(mod)[2, ]\n#>   out <- c(out_1, out_2)\n#>   return(out)\n#> }\n#> <bytecode: 0x7f850b294f08>\n#> <environment: namespace:eesim>\nHere are examples of applying this function to a simulated dataframe:\n# Create simulated data\nsims <- create_sims(n_reps = 10, n = 100, central = 100, sd = 10,\n             exposure_type=\"continuous\", exposure_trend = \"cos1\",\n             exposure_amp = .6, average_outcome = 22,\n             outcome_trend = \"no trend\", outcome_amp = .6, rr = 1.01)\nhead(sims[[1]])\n#>         date        x outcome\n#> 1 2000-01-01 120.9115      37\n#> 2 2000-01-02 107.8687      17\n#> 3 2000-01-03 124.0501      35\n#> 4 2000-01-04 108.2165      21\n#> 5 2000-01-05 126.2719      21\n#> 6 2000-01-06 121.5310      21\n# Apply `spline_mod` to the data\nspline_mod(df = sims[[1]])\n#>     Estimate   Std. Error      t value     Pr(>|t|)        2.5 % \n#> 1.263067e-02 2.419841e-03 5.219626e+00 1.035524e-06 7.887866e-03 \n#>       97.5 % \n#> 1.737347e-02\nspline_mod(df = sims[[1]], df_year = 6)\n#>     Estimate   Std. Error      t value     Pr(>|t|)        2.5 % \n#> 1.263067e-02 2.419841e-03 5.219626e+00 1.035524e-06 7.887866e-03 \n#>       97.5 % \n#> 1.737347e-02\nThe format_function function can be used within the modeling function to get the output in the correct format if running a GLM or similar model.\nOnce you've created the function, you can input it in a call to eesim using the custom_model argument. You can pass any additional arguments (df_year in our example) through to the function using the custom_model_args argument. This argument takes a list with the argument name and value for each argument you wish to pass to the modeling function. For example, the following call passes the spline_mod function shown above as the function to use for modeling the simulated data as well as a value for its df_year argument:\nex_sim2 <- eesim(n_reps = 100, n = 365 * 5, \n                 central = c(0, 0, 0, 0, 0, 0.05, 0.12, 0.02, 0, 0, 0, 0),\n                 exposure_type = \"binary\", exposure_trend = \"monthly\",\n                 exposure_amp = -.6, average_outcome = 50,\n                 outcome_trend = \"cos1\", outcome_amp = 0.2, \n                 rr = 1.05, start.date = \"1996-01-01\",\n                 custom_model = spline_mod, custom_model_args = list(df_year = 7))\nThe eesim function does this by applying the modeling function across all simulated datasets using a function called fit_mods. If you'd like, you can run that function independently. The fit_mods function outputs a data frame with estimates of the log relative risk, p-values, and upper and lower 95% confidence bounds for each simulated data set.\nHere is an example of fitting the spline model coded in the spline_mod function, with 7 degrees of freedom per year used to model long-term and seasonal trends (df_year = 7 passed in a list to the model with the custom_model_args argument):\nfits <- fit_mods(data = sims, custom_model = spline_mod, \n                 custom_model_args = list(df_year = 7))\nfits\n#>       Estimate   Std.Error  t.value      p.value    lower_ci   upper_ci\n#> 1  0.012630668 0.002419841 5.219626 1.035524e-06 0.007887866 0.01737347\n#> 2  0.010528717 0.002431733 4.329717 3.666742e-05 0.005762608 0.01529483\n#> 3  0.012012149 0.002481787 4.840121 4.953470e-06 0.007147936 0.01687636\n#> 4  0.010157661 0.002184751 4.649346 1.062203e-05 0.005875628 0.01443969\n#> 5  0.008278299 0.002196057 3.769619 2.823851e-04 0.003974105 0.01258249\n#> 6  0.007332724 0.001902623 3.854009 2.099684e-04 0.003603652 0.01106180\n#> 7  0.007587459 0.002298507 3.301038 1.353268e-03 0.003082468 0.01209245\n#> 8  0.011544261 0.002355257 4.901486 3.862050e-06 0.006928041 0.01616048\n#> 9  0.013659555 0.002084708 6.552264 2.816820e-09 0.009573603 0.01774551\n#> 10 0.011693386 0.002347295 4.981643 2.783172e-06 0.007092772 0.01629400\nAs a note, the output of the fit_mods function is the output given as the second element of the list returned by a call to eesim.\nEvaluating the models\nThe final step of the eesim function is to evaluate model performance across all simulations with several different measures. Within the eesim function, the check_sims function takes as inputs the true relative risk as well as the results from fitting the modeling function to all the simulations using the fim_mods function. It returns values for the mean effect estimate (log relative risk) and relative risk estimates across all simulated data sets, variance of the estimates of beta, the mean of the variances of each estimated log relative risk, the relative bias of the mean of the log relative risks, the percent coverage confidence intervals of the true log relative risk, and the power of the test at the 5% significance level (see the table near the beginning of the vignette).\nHere is an example of the use of the check_sims function:\ncheck_sims(fits, true_rr = 1.01)\n#>     beta_hat rr_hat var_across_betas mean_beta_var percent_bias coverage\n#> 1 0.01054249 1.0106     4.763804e-06  5.183017e-06  -0.05944768        1\n#>   power\n#> 1     1\nIn a run of eesim, this output is given in the third element of the returned list.\nInternally, the functions used for this model assessment are:\n\nbeta_bias\nbeta_var\ncoverage_beta\nmean_beta\npower_beta\n\nA few more details about how some of these assessments are measured are given below.\nVariance across estimated log relative risk and mean variance of estimates\nTwo values are measured by the beta_var function. First, the variance across all estimates of log relative risk is measured across all the simulations, using the equation:\n$$\n\\text{variance of estimates} = E\\left[\\left(\\hat{\\beta_i} - \\frac{1}{n}\\sum_{i = 1}^n{\\hat{\\beta_i}}\\right)\\right]\n$$\nwhere $\\hat{\\beta_i}$ is the estimated log relative risk for a single simulation out of n total simulations and E represents the expected value.\nSecond, the function measures the mean value of the variance estimated for $\\hat{\\beta}$ for each simulation:\n$$\n\\text{mean of estimate variances} = \\frac{1}{n}\\sum_{i = 1}^{n}{var(\\hat{\\beta_i})}\n$$\nwhere $var(\\hat{\\beta_i})$ is the estimated variance of the estimated log relative risk for a single simulation out of n total simulations.\nRelative bias\nHere is the equation used by the beta_bias function to estimate relative bias in estimates from the simulated data:\n$$\n\\text{relative bias} = 100*\\frac{\\beta - \\frac{1}{n}\\sum_{i = 1}^{n}{\\hat{\\beta}}}{\\beta}\n$$\nwhere \u03b2 is the true log relative risk used to simulate the data and $\\hat{\\beta}$ is the estimated log relative risk from simulation i (out of a total of n simulations).\nGenerating power curves\nThe other main functionality of the eesim package is to run through simulations under varying data generating scenarios to estimate expected power of an analysis under different scenarios. For example, you can explore how expected power varies for different expected effect sizes (relative risk of the outcome associated with a change in exposure) or for different average daily number of outcomes. This is run using the power_calc function in the package.\nThe power_calc function allows you to put in varying values for one of the following three specifications in the simulations:\n\nRelative risk (rr): How you strongly expect the exposure and outcome to be associated\nNumber of days in the study (n): How long you expect the study to last (or how many days of historical data you expect to be able to collect)\nAverage daily count of outcomes (average_outcome): For the outcome of interest, how common it is on average on days in the study (this will usually be strongly associated with the size of the population being studied)\n\nFor whichever of these you choose to vary, you can specify different values to test. The power_calc function then loops through those values and runs eesim for each of them. From this, it can estimate the power for each value of the varying parameter.\nHere is an example of running a power calculation with varying number of days in the study (n). The values argument is used to specify different values of n we would like to test (here, it's testing power for studies with daily data for between 1 and 21 years):\npow <- power_calc(varying = \"n\", values = floor(365.25 * seq(1, 21, by = 5)), n_reps = 20,\n                  central = 100, sd = 10, rr = 1.001, exposure_type = \"continuous\",\n                  exposure_trend = \"cos1\", exposure_amp = .6, average_outcome = 22,\n                  outcome_trend = \"no trend\", outcome_amp = .6,\n                  custom_model = spline_mod, plot = TRUE)\n#> This function may take a minute or two to run, especially with\n#> lots of replications (`n_reps`) or options for `values`.\n\nThis call returns a dataframe with the estimated power for each of the values of n tested:\npow\n#>   values power\n#> 1    365  0.15\n#> 2   2191  0.60\n#> 3   4017  0.85\n#> 4   5844  0.90\n#> 5   7670  1.00\nBecause the argument plot is set to TRUE, it also generates a power curve plot as a side effect, as shown above.\nHere is another example, but this time we assume that the study will have 4,000 days of daily data, but we explore estimated power as the average daily outcome count varies:\npow2 <- power_calc(varying = \"average_outcome\", values = c(1, 5, 10, 20, 30, 40),\n                   n_reps = 20,\n                   central = 100, sd = 10, rr = 1.001, exposure_type = \"continuous\",\n                   exposure_trend = \"cos1\", exposure_amp = .6, n = 4000,\n                   outcome_trend = \"no trend\", outcome_amp = .6,\n                   custom_model = spline_mod, plot = TRUE)\n#> This function may take a minute or two to run, especially with\n#> lots of replications (`n_reps`) or options for `values`.\n\npow2\n#>   values power\n#> 1      1  0.20\n#> 2      5  0.25\n#> 3     10  0.35\n#> 4     20  0.70\n#> 5     30  0.90\n#> 6     40  0.95\nBecause these power curves and calculations are based on simulated data, there will be some randomness to results. Curves will be smoother as more simulations are used for each run (n_reps), although this will also increase the time needed to run the simulation.\nUsing custom functions\nAn important feature of eesim is that the user can create and use custom functions for any part of the simulation process. For example, the user may wish to generate exposure data with a custom trend, then automate the process of generating outcomes, fitting models, and evaluating performance using the built-in features of eesim. Functions the user has the option to customize within the eesim framework are:\n\nThe underlying expected exposure value on each day. Through this, the user can use customized long-term and seasonal trend patterns or can build a simulation starting from a running mean of observed exposure data.\nHow exposure values are randomized from the underlying trend. This allows a user to, for example, use a distribution other than normal (for continuous exposure data) or binomial (for binary data) as the underlying distribution of the exposure data.\nThe underlying pattern in the expected outcome baseline, before the influence of the exposure is added. Through this, the user can use a custom pattern of long-term and seasonal trends in expected health outcome rates in the simulated data. This functionality can also be used to include any expected influence on the baseline outcome rate from daily-varying values other than the exposure of interest.\nHow exposure influences the expected outcome rate. The user can create a function that inputs the expected baseline outcome count and simulated exposure levels for each day and outputs the expected outcome rate on each day, including any added or reduced risks caused by the exposure. This functionality can be used, for example, to simulate outcomes with a non-linear relationship with the exposure or with lagged exposure effects.\nHow outcome counts are randomized from the underlying expected outcome rate. This allows users to, for example, use a negative binomial or overdispersed Poisson distribution as the underlying distribution of the outcome counts.\n\nTo use custom functions within eesim, the user must input the name of the custom function as well as a list of all arguments for the custom function and their values (examples shown below). This allows the user to pass the function and required arguments directly within a call to the main eesim function. When a custom function is used, many inputs that are otherwise required for the eesim function may no longer be necessary, in which case they can simply be left out of the eesim call. As a note, if extensive customize is required for several steps of the simulation process, it may make more sense to code the full simulation by hand rather than using the eesim framework.\nCustomizing the exposure trend\nTo take advantage of any of the customization options, you need to write a function that follows certain input and output (i.e., interface) rules. First, you can use a custom function for the underlying trend in expected exposure. This function must take the inputs:\n\nn (the number of days to simulate)\nEither mean for a continuous exposure (the average value of the outcome) or prob for a binary exposure (the average probability of exposure)\n\nThe function can take any other additional inputs, as well, but any such extra arguments (as well as mean) will need to be input to the eesim function in a list for the cust_expdraw_args argument (example below). The value for n will pass through directly from the n value specified for the call to eesim. The function must output a numeric vector that gives the simulated exposure values for each day in the simulated data.\nFor example, the following function creates a custom exposure trend with a long-term and seasonal trend, similar to trends available through the default package options. However, this function specifies a minimum value that the exposure trend cannot fall below-- if the base exposure value is every set below this minimum within the algorithm, the value is reset to the minimum before the final values are output. This function can be useful in cases where the exposure cannot fall below a certain value (for example, a pollution concentration could not be lower than 0). This custom exposure function can also be used to customize how values are simulated from the expected exposure on each day (based on the expected distribution of the exposure). In the case of the example ozone concentration data from Chicago shown earlier in this vignette, we may want to simulate exposure based on the assumption that the square root of exposure is normally distributed, which will prevent negative values and may also help to simulate occasional very high values.\nabove_min_trend <- function(n, mean, sd_of_sqrt, minimum = 0){\n  day <- c(1:n)\n  \n  ## Calculate a baseline exposure for each day\n  base <- mean + -10 * cos(2 * pi * (day \/ 365))\n  base[base < minimum] <- minimum            # Reset any values below 0 to 0\n  \n  ## Simulate exposure values from the baseline\n  sqrt_base <- sqrt(base)                   # Transform to square root\n  sqrt_sim <- rnorm(n, mean = sqrt_base, sd = sd_of_sqrt)\n  sqrt_sim ^ 2                              # Transform back\n}\nHere is an example of running this custom exposure simulation function over 5 years, with a smooth line added to the plot to help show the seasonal trend included:\nabove_min_trend(n = 365.25 * 5, mean = 20, minimum = 0, sd_of_sqrt = 0.9) %>% \n  tbl_df() %>% \n  mutate(day = 1:n()) %>% \n  ggplot(aes(x = day, y = value)) + \n  geom_point(alpha = 0.5, size = 0.8) + \n  theme_classic() + \n  geom_smooth(se = FALSE, span = 0.1, method = \"loess\", color = \"red\")\n\nYou can then pass this custom function into the eesim function using the cust_exp_func argument. The value for n input to the custom function will be the value you input to eesim for n. For any other arguments you want to pass to the function (in the function we just created, you'll want to pass values for mean, minimum, and sd_of_sqrt), you can include specifications for these as a list for the cust_exp_args argument of eesim. For example, the following call would run a simulation using this custom function for exposure:\nex_sim2 <- eesim(n_reps = 1, n = round(365.25 * 5), \n                 exposure_type = \"continuous\",\n                 cust_exp_func = above_min_trend,\n                 cust_exp_args = list(mean = 20, minimum = 0, sd_of_sqrt = 0.9),\n                 average_outcome = 50, rr = 1.01, \n                 custom_model = spline_mod, custom_model_args = list(df_year = 7))\nCustomizing the outcome simulation\nThere are three ways to customize the simulated outcome data: creating a custom baseline for outcome values, customizing the relationship between outcome and exposure, and, as with the exposure values, customizing the randomization of the outcome values.\nThe outcome baseline (Bt) is comprised of the values the user expects the outcomes to have on each day of the simulated dataset without risk associated with the exposure factored in. The user may write a function to specify the trend of the baseline, then use it as an input in sim_outcome or eesim. Here is an example of creating a custom baseline function and using it in the eesim function:\ncustombase <- function(n, slope, intercept){\n  day <- c(1:n)\n  baseline <- day * slope + intercept\n  return(baseline)\n}\n\n#Example:\ncustombase(n=5, slope = .3, intercept = 55)\n#> [1] 55.3 55.6 55.9 56.2 56.5\n\nex_sim3 <- eesim(n_reps = 3, n = 1000, central = 100, sd = 10,\n                exposure_type = \"continuous\", exposure_trend = \"cos1\",\n                exposure_amp = .6, average_outcome = 22, rr = 1.01, \n                cust_base_func = custombase,\n                cust_base_args = list(n=1000, slope = 5, intercept = 12),\n                custom_model = spline_mod, custom_model_args = list(df_year = 2))\n#> This function may take a minute or two to run, especially if you\n#> are creating lots of replications (`n_reps`).\nggplot(ex_sim3$simulated_datasets[[1]], aes(x=date, y=outcome))+ geom_point() + geom_point(alpha = 0.5, size = 0.8) + \n  theme_classic() + \n  geom_smooth(se = FALSE, span = 0.1, method = \"loess\", color = \"red\")\n\nThe second way of customizing the outcome simulation is to use a custom function to incorporate the added risk from the exposure when calculating the expected daily outcome count for a day, \u03bbt, from the inputs of exposure (Xt) and outcome baseline (Bt) for the day. Here is an example of creating a custom lambda, meaning a custom function relating relative risk and exposure to outcomes, and using it in eesim with the custom baseline function created above. The custom lambda function must input arguments exposure, rr, and baseline and output a vector of lambda values.\ncustomlambda <- function(exposure, rr, constant, baseline){\n  log_lambda <- log(baseline) + log(rr) * exposure + constant\n  lambda <- exp(log_lambda)\n  return(lambda)\n}\n\nex_sim4 <- eesim(n_reps = 3, n = 1000, central = 100, sd = 10,\n                exposure_type = \"continuous\", exposure_trend = \"cos1\",\n                exposure_amp = .6, average_outcome = 22, rr = 1.01, \n                cust_base_func = custombase,\n                cust_base_args = list(n=1000, slope = .5, intercept = 12),\n                cust_lambda_func = customlambda, cust_lambda_args = list(constant=10),\n                custom_model = spline_mod, custom_model_args = list(df_year = 2))\n#> This function may take a minute or two to run, especially if you\n#> are creating lots of replications (`n_reps`).\nThe third way to customize the outcome simulation is to customize the randomization of the outcome values from the trend created by relating the baseline outcomes and the exposure (what we have called lambda). When the cust_outdraw argument is not specified in the eesim function, the function draws outcome values from a Poisson distribution with mean lambda. A custom function for outcome draws must input values called n and lambda, and any other arguments must be included in the cust_outdraw_args argument. Here is an example of using the custom functions to specify a negative binomial distribution for outcome randomization:\ncustnbinom <- function(n, lambda, prob){\n  out <- rnbinom(n=n, size=lambda, prob=prob)\n  return(out)\n}\n\nex_sim5 <- eesim(n_reps = 3, n = 1000, central = 100, sd = 10,\n                exposure_type = \"continuous\", exposure_trend = \"cos1\",\n                exposure_amp = .6, average_outcome = 22, rr = 1.01, \n                cust_base_func = custombase,\n                cust_base_args = list(n=1000, slope = .5, intercept = 12),\n                cust_lambda_func = customlambda, cust_lambda_args = list(constant=10),\n                cust_outdraw = custnbinom, cust_outdraw_args = list(prob=.3), \n                custom_model = spline_mod, custom_model_args = list(df_year = 2))\n#> This function may take a minute or two to run, especially if you\n#> are creating lots of replications (`n_reps`).\nReferences\nBateson, Thomas F, and Joel Schwartz. 1999. \u201cControl for Seasonal Variation and Time Trend in Case-Crossover Studies of Acute Effects of Environmental Exposures.\u201d Epidemiology 10 (5): 539\u201344.\n","386":"envirosense\nCrowdsourced Environmental Sensing\n\nThe pm (particulate measure) depends on Paul Van Haastrecht's\nSPS30 library at https:\/\/github.com\/paulvha\/sps30. Sensirion's\nlibrary doesn't work, though I imagine they'll fix that.\n","387":"\n\n\nElectronic prototype to monitor several environmental magnitudes through self-implemented sensors. Field data collection at your fingertips!\nTABLE OF CONTENTS\n\nMotivation\nTechnologies and Frameworks\nSystem Design\nFunctionalities and Features\nDocumentation\nAcknowledgements\n\nMOTIVATION\nThis project is a team effort for our first semester class CDIO. It aims to optimize all agricultural activity, providing meaningful realtime data.\nTECHNOLOGIES AND FRAMEWORKS\nElectronic Devices and Components\n\nSparkfun ESP8266 Thing Dev Board.\nAdafruit ADS1115 16-bit ADC.\nDFROBOT SEN0193 Soil Moisture Sensor.\nLantronix A2235-H GPS Receiver.\nInvenSense MPU-9250 Accelerometer.\nAdafruit BMP280 Barometric Pressure & Altitude Sensor.\nHC-SR04 Ultrasonic Distance Sensor.\nOperational amplifier.\nPhotodiode.\nAND logic gate.\nNTC thermistor.\nResistors.\n\nREST APIs\n\nThingSpeak - IoT Analytics and integration with MATLAB.\nDweet - Simple messaging and alerts.\n\nSoftware Development\n\nArduino IDE.\nThird-party text editors.\n\nSYSTEM DESIGN\nSofware Architecture\nCheck the documentation (spanish) for a detailed breakdown of both the overall design and the dependencies it relies on.\nHardware Architecture\n\nRefer to the documentation (spanish) for further details and schematics.\nFUNCTIONALITIES AND FEATURES\n\n Salinity sensor (electrical conductivity).\n Soil Moisture sensor.\n Temperature sensor.\n Luminosity sensor.\n Barometric pressure and altitute sensor.\n Anti-theft system (Wake on Motion).\n Hibernation mode (Deep Sleep).\n Rain Gauge (experimental).\n GPS receiver.\n REST server.\n PCB Design.\n\nDOCUMENTATION\nIt can be found in the form of a PDF file for each and every Sprint, accordingly. Those of previous Sprints may and do, in fact, contain errors (schematics, pins, etc.). Please, refer to the technical documentation (spanish).\nACKNOWLEDGEMENTS\nI would like to express my sincere gratitude to my teacher M\u00aa Asunci\u00f3n P\u00e9rez Pascual for her invaluable support, feedback and encouragement throughout the development of this project, and to Universitat Polit\u00e8cnica de Val\u00e8ncia for providing us with both the knowledge and the tools needed to complete it.\n","388":"environment\nThis is the repository for the study of how the quenching parameters derived using starpy are correlated with the environmental properties of group galaxies.\nUse of any of the materials are requested to cite Smethurst et al. 2017.\n\nSubmitted to MNRAS on 22 Feb 2017.\nReceived referee report; re-submitted on 07 Apr 2017.\nAccepted by MNRAS on 20 Apr 2017. Preprint is available on arXiv: https:\/\/arxiv.org\/abs\/1704.06269\n\nContact Becky Smethurst (@rjsmethurst) if you have any questions, or please submit a pull request or issue of your own!\n","389":"Sustainable Living (sustainable-living)\nDescription\nSustainable Living is designed to help students live more sustainable lives, even if they don\u2019t want to. It offers sustainable living suggestions for a variety of user interests such as saving money, saving time and social networking. Sustainable Living incorporates gamification, awarding points in order to encourage users to participate. Points are given to users, for creating tips and events, completing tips, attending events and moderating content. Once users have earned points they can even compare their scores to other users via a leaderboard.\nImplemented Features\n\nCreate an event - Users can submit an event into the system for approval by moderators. If the event is approved, the user will host the even with a QR code and users can attend for points.\nComplete a tip - Users can browse tips in the system and work on completing them. When users complete a tip, they receive points.\nAttend an event - When users as phyiscally at events and find the QR code, they can scan it to prove they attended, and receive points.\nModerate Content - All tips and events that are created in the system need to be moderated before they can be public facing. Moderators have the task of approving and denying tips and events one by one, giving feedback whenever they deny a tip or event.\nCompare scores on the leaderboard - As users get points they can see how their points stack up to other users on the leaderboard page.\n\nUsabilty and Quality Attributes\n\nSupports small screen devices\nTypical use time is a few minutes\nProvides quick access (less than 3 clicks) to most frequently used features\nLimits awkward and fatiguing movements by making all buttons large and grouped\nUse of color to help user choose the right action\nGive Feedback after every finished interaction\nThe Browser \u201cback\u201d button can be used for undo, it is always available\n\nRunning the project\nThe project includes a live-reloading static server on port 8080 (you can change the port in the gulpfile.js config), which will build, launch, and rebuild the app whenever you change application code. To start the server, run:\n$ npm start\nIf you prefer to just build without the live reload and build-on-each-change watcher, run:\n$ npm run build\nGenerating Additional Code\nYou can add additional functionality to your application by invoking the subgenerators included in the Flux Generator. You can add components using the following commands:\nComponents\n$ yo flux:component ComponentName\nActions\n$ yo flux:action ActionCreatorName\nStores\n$ yo flux:store StoreName\n","390":"ejanalysis package\nThis environmental justice analysis tools package provides tools for R that simplify some basic tasks related to environmental justice (EJ) analysis.\nIt provides tools for exploring and analyzing a dataset in a matrix or data.frame that contains data on demographics (e.g., counts of residents in poverty) and local environmental indicators (e.g., an air quality index), with one row per spatial location (e.g., Census block group).\nKey functions help to find relative risk or similar ratios of means in demographic groups, etc.\nInstallation\nThis package is not on CRAN yet, but you can install it from Github:\nif (!require('devtools')) install.packages('devtools')\ndevtools::install_github('ejanalysis\/ejanalysis')\nDocumentation\nIn addition to documentation in the package, the help in pdf format is here:\nhttp:\/\/ejanalysis.github.io\/ejanalysis\/ejanalysis.pdf\nRelated Packages\nThis package is one of a series of R packages related to environmental justice (EJ) analysis, as part of ejanalysis.com.\nThis and related packages, once each is made available as a public repository on GitHub, until available on cran, can be installed using the devtools package:\nif (!require('devtools')) install.packages('devtools')\ndevtools::install_github(\"ejanalysis\/analyze.stuff\")  \ndevtools::install_github(\"ejanalysis\/countyhealthrankings\")  \ndevtools::install_github(\"ejanalysis\/UScensus2010blocks\")  \ndevtools::install_github(\"ejanalysis\/ACSdownload\")  \ndevtools::install_github(c(\"ejanalysis\/proxistat\", \"ejanalysis\/ejanalysis\"))\ndevtools::install_github(\"ejanalysis\/ejscreen\")\n","391":"variationpartitioning\nVariation partitioning among environmental and spatial components considering the most recent approaches (Bauman et al. 2018 and Clappe et al. 2018).\n","392":"WAVED\nWeb App for Visualizing Environmental Data\nhttp:\/\/kshsk.github.io\/WAVED\nInstallation\nThe Basics\nWhile all a client needs to use WAVED is a web browser, server side actions require a running web server. The requirements for the server include serving both static content (HTML, JavaScript, CSS, Images) as well as dynamic pages (PHP).\nThis setup can be accomplished with various setups on most operating systems, however, this document has been written for and tested against a fresh installation of Ubuntu 12.04 LTS (Precise Pangolin).\nNecessary Packages\nIn order to get the WAVED server running we will be using Apache with the PHP module, including sqlite. The other packages provide the command line tools required for the standard deployment of WAVED. The packages can be installed as follows:\napt-get update\napt-get install apache2 php5-common php5-sqlite libapache2-mod-php5\napt-get install make sqlite3 acl\n\nContent\nAll the content that needs to be served by the web server can be found in the WAVED git repository. We'll clone this content to the DocumentRoot of the Apache server, which is \/var\/www by default.\ncd \/var\/www\ngit clone https:\/\/github.com\/KSHSK\/WAVED.git\n\nInitial Setup\nAfter all the content has been brought over to the web server there are a few initialization actions that need to be performed.  This includes setting up the directories and permissions for persisting project state and data files. All of these actions are handled by a Makefile. After everything is set up the Apache server is restarted to ensure everything will be served correctly.\ncd WAVED\nmake\nservice apache2 restart\n\nVerifying the Server\nAt this point the WAVED server should be up and running and clients should be able to point their web browsers to the WAVED folder of your web server. There are, however, a few easy things that you can do from the web server to verify functionality.\nIndex Page\nVerify that you can get to the index page of WAVED. You should not get a 404 error, or a short HTML page displaying some generic message, but rather over 500 lines of HTML.\ncurl -sXPOST localhost\/WAVED\/\nProject Listing\nVerify that you can get a listing of the currently existing projects as a JSON response. The success field should be true, and the projects array empty.\ncurl -sXPOST localhost\/WAVED\/PHP\/getExistingProjectDetails.php\nCreate Project\nVerify that you can create a project. Each command should display a JSON response, both of which with success as true. The projects array should contain the newly created project.\ncurl -sXPOST localhost\/WAVED\/PHP\/createProject.php -d project=test_project\ncurl -sXPOST localhost\/WAVED\/PHP\/getExistingProjectDetails.php\n\nDelete Project\nVerify that you can delete a project. Each command should display a JSON response, both of which with success as true.  The projects array should be empty once again.\ncurl -sXPOST localhost\/WAVED\/PHP\/deleteProject.php -d project=test_project\ncurl -sXPOST localhost\/WAVED\/PHP\/getExistingProjectDetails.php\n\nDeveloper Instructions\n\nDownload Eclipse IDE for Java Developers\nImport Project:\nFile -> Import... -> Exiting Projects into Workspace\nSelect WAVED directory\nFinish\nInstall JSHint Plugin\nHelp -> Install New Software -> Work with: http:\/\/github.eclipsesource.com\/jshint-eclipse\/updates\/\nCheck JSHint and click through until finished\n\n","393":"WAVED\nWeb App for Visualizing Environmental Data\nhttp:\/\/kshsk.github.io\/WAVED\nInstallation\nThe Basics\nWhile all a client needs to use WAVED is a web browser, server side actions require a running web server. The requirements for the server include serving both static content (HTML, JavaScript, CSS, Images) as well as dynamic pages (PHP).\nThis setup can be accomplished with various setups on most operating systems, however, this document has been written for and tested against a fresh installation of Ubuntu 12.04 LTS (Precise Pangolin).\nNecessary Packages\nIn order to get the WAVED server running we will be using Apache with the PHP module, including sqlite. The other packages provide the command line tools required for the standard deployment of WAVED. The packages can be installed as follows:\napt-get update\napt-get install apache2 php5-common php5-sqlite libapache2-mod-php5\napt-get install make sqlite3 acl\n\nContent\nAll the content that needs to be served by the web server can be found in the WAVED git repository. We'll clone this content to the DocumentRoot of the Apache server, which is \/var\/www by default.\ncd \/var\/www\ngit clone https:\/\/github.com\/KSHSK\/WAVED.git\n\nInitial Setup\nAfter all the content has been brought over to the web server there are a few initialization actions that need to be performed.  This includes setting up the directories and permissions for persisting project state and data files. All of these actions are handled by a Makefile. After everything is set up the Apache server is restarted to ensure everything will be served correctly.\ncd WAVED\nmake\nservice apache2 restart\n\nVerifying the Server\nAt this point the WAVED server should be up and running and clients should be able to point their web browsers to the WAVED folder of your web server. There are, however, a few easy things that you can do from the web server to verify functionality.\nIndex Page\nVerify that you can get to the index page of WAVED. You should not get a 404 error, or a short HTML page displaying some generic message, but rather over 500 lines of HTML.\ncurl -sXPOST localhost\/WAVED\/\nProject Listing\nVerify that you can get a listing of the currently existing projects as a JSON response. The success field should be true, and the projects array empty.\ncurl -sXPOST localhost\/WAVED\/PHP\/getExistingProjectDetails.php\nCreate Project\nVerify that you can create a project. Each command should display a JSON response, both of which with success as true. The projects array should contain the newly created project.\ncurl -sXPOST localhost\/WAVED\/PHP\/createProject.php -d project=test_project\ncurl -sXPOST localhost\/WAVED\/PHP\/getExistingProjectDetails.php\n\nDelete Project\nVerify that you can delete a project. Each command should display a JSON response, both of which with success as true.  The projects array should be empty once again.\ncurl -sXPOST localhost\/WAVED\/PHP\/deleteProject.php -d project=test_project\ncurl -sXPOST localhost\/WAVED\/PHP\/getExistingProjectDetails.php\n\nDeveloper Instructions\n\nDownload Eclipse IDE for Java Developers\nImport Project:\nFile -> Import... -> Exiting Projects into Workspace\nSelect WAVED directory\nFinish\nInstall JSHint Plugin\nHelp -> Install New Software -> Work with: http:\/\/github.eclipsesource.com\/jshint-eclipse\/updates\/\nCheck JSHint and click through until finished\n\n","394":"private-notes\nJava, Linux, Algorithm, Environmental configuration, etc.\n\nContent\nJava\n\u6846\u67b6\n\u6570\u636e\u5e93\n\u7f16\u7a0b\u5de5\u5177\nLinux\nJava\u9762\u8bd5\u95ee\u9898\n\u73af\u5883\u914d\u7f6e\n\u7f51\u7edc\u57fa\u7840\n\u64cd\u4f5c\u7cfb\u7edf\n\u5404\u79cd\u9519\u8bef\n\u6570\u636e\u7ed3\u6784\n\u5206\u5e03\u5f0f\n\u8bbe\u8ba1\u539f\u5219\u4e0e\u8bbe\u8ba1\u6a21\u5f0f\nJava\n\nJava\u57fa\u7840\nJava\u5bb9\u5668\u7c7b\nJDBC\n\nJDBC\u8fde\u63a5\u6570\u636e\u5e93\n\n\nJSP\u57fa\u7840\nJVM\n\nJava\u8fd0\u884c\u65f6\u6570\u636e\u533a\u57df\n\u5185\u5b58\u7ba1\u7406\u53c2\u6570\n\u5224\u65ad\u5bf9\u8c61\u4f55\u65f6\u56de\u6536\n\u5783\u573e\u6536\u96c6\u7b97\u6cd5\n\u7a7a\u95f4\u5206\u914d\u62c5\u4fdd\n\u5185\u5b58\u5206\u914d\u4e0e\u56de\u6536\n\u7c7b\u52a0\u8f7d\u673a\u5236\n\u9759\u6001\u5206\u914d\u548c\u52a8\u6001\u5206\u914d\n\u53cc\u4eb2\u59d4\u6d3e\u6a21\u578b\n\u5185\u5b58\u6cc4\u6f0f\n\u5185\u5b58\u6ea2\u51fa\nJava\u5185\u5b58\u6a21\u578b\n\n\n\n\u6846\u67b6\n\nHibernate\nSpring\nStruts2\n\n\u6570\u636e\u5e93\n\n\u6570\u636e\u5e93\u57fa\u7840\n\nsql\u7684\u51e0\u79cd\u8fde\u63a5\u65b9\u5f0f\n\n\nmongodb\nmysql\n\n\u7f16\u7a0b\u5de5\u5177\n\ngit\nMaven\n\nLinux\n\n\u786c\u94fe\u63a5\u548c\u8f6f\u94fe\u63a5\nshell\u4e2d\u7684\u6761\u4ef6\u5224\u65ad\n\nJava\u9762\u8bd5\u95ee\u9898\n\nJ2EE\n\n\u4e5d\u79cd\u57fa\u672c\u6570\u636e\u7c7b\u578b\u7684\u5927\u5c0f\uff0c\u4ee5\u53ca\u4ed6\u4eec\u7684\u5c01\u88c5\u7c7b\nSwitch\u80fd\u5426\u7528String\u505a\u53c2\u6570\uff1f\nequal\u4e0e==\u7684\u533a\u522b\njava\u4e2d\u7684\u7f13\u51b2\u6c60\nObject\u6709\u54ea\u4e9b\u516c\u7528\u65b9\u6cd5\nJava\u7684\u56db\u79cd\u5f15\u7528\nJava\u4e2dhashCode\u7684\u4f5c\u7528\nArrayList\u3001LinkedList\u3001Vector\u7684\u533a\u522b\nHashMap\u548cConcurrentHashMap\u7684\u533a\u522b\uff0cHashMap\u7684\u5e95\u5c42\u6e90\u7801\nTreeMap\u3001HashMap\u3001LindedHashMap\u7684\u533a\u522b\nCollection\u5305\u7ed3\u6784\uff0c\u4e0eCollections\u7684\u533a\u522b\ntry catch finally\uff0ctry\u91cc\u6709return\uff0cfinally\u8fd8\u6267\u884c\u4e48\uff1f\nException\u4e0eError\u5305\u7ed3\u6784\nJava\u9762\u5411\u5bf9\u8c61\u7684\u4e09\u4e2a\u7279\u5f81\u4e0e\u542b\u4e49\nOverride\u548cOverload\u7684\u542b\u4e49\u4e0e\u533a\u522b\nInterface\u4e0eabstract\u7c7b\u7684\u533a\u522b\nStatic class \u4e0enon static class\u7684\u533a\u522b\nJava\u591a\u6001\u7684\u5b9e\u73b0\u539f\u7406\njava\u5b9e\u73b0\u591a\u7ebf\u7a0b\u7684\u4e24\u79cd\u65b9\u6cd5\n\u7ebf\u7a0b\u540c\u6b65\u7684\u65b9\u6cd5\n\u9501\u7684\u7b49\u7ea7\uff1a\u65b9\u6cd5\u9501\u3001\u5bf9\u8c61\u9501\u3001\u7c7b\u9501\nJava\u9501\u7684\u5206\u7c7b\n\n\nJVM\n\n\u73af\u5883\u914d\u7f6e\n\nHibernate-idea\u914d\u7f6e\nUbuntu\u642d\u5efazookeeper\u96c6\u7fa4\nmysql\u8fdc\u7a0b\u8fde\u63a5\u914d\u7f6e\nnginx+mysql+redis\u914d\u7f6e\nUbuntu\u5b89\u88c5Tomcat\nUbuntu\u5b89\u88c5redis\n\n\u7f51\u7edc\u57fa\u7840\n\nget\u548cpost\nTCP\u4e09\u6b21\u63e1\u624b\nTCP\u56db\u6b21\u6325\u624b\n\u62d3\u6251\u7ed3\u6784\n\n\u64cd\u4f5c\u7cfb\u7edf\n\n\u6b7b\u9501\n\u5b58\u50a8\u7ba1\u7406\u6280\u672f\n\u9875\u9762\u8c03\u5ea6\u7b97\u6cd5\n\u78c1\u76d8\u8c03\u5ea6\u7b97\u6cd5\n\u4f5c\u4e1a\u8c03\u5ea6\u7b97\u6cd5\n\n\u5404\u79cd\u9519\u8bef\n\nidea\n\nweb.xml\u62a5\u9519 Servlet should have a mapping\n\n\nmybatis\n\nMybatis\u4e2dresultType\u4e2a\u522b\u5b57\u6bb5\u83b7\u53d6\u6570\u636e\u4e3anull\n\n\n\n\u6570\u636e\u7ed3\u6784\n\n\u6570\u636e\u7ed3\u6784\u516b\u5927\u6392\u5e8f\u7b97\u6cd5\n\u6700\u5c0f\u751f\u6210\u6811\n\u51e0\u79cd\u5e38\u89c1\u7684\u67e5\u627e\u7b97\u6cd5\n\n\u5206\u5e03\u5f0f\n\nzookeeper\n\nzookeeper\u7b80\u4ecb\nzookeeper\u4e3a\u4ec0\u4e48\u6700\u597d\u914d\u7f6e\u5947\u6570\u53f0\n\n\nnginx\n\nnginx\u7684\u8d1f\u8f7d\u5747\u8861\nlocation\u5339\u914d\u89c4\u5219\n\n\n\n\u8bbe\u8ba1\u539f\u5219\u4e0e\u8bbe\u8ba1\u6a21\u5f0f\n\n6\u5927\u8bbe\u8ba1\u539f\u5219\n\n\u5f00\u95ed\u539f\u5219\n\u91cc\u6c0f\u66ff\u6362\u539f\u5219\n\u5355\u4e00\u804c\u8d23\u539f\u5219\n\u4f9d\u8d56\u5012\u7f6e\u539f\u5219\n\u63a5\u53e3\u9694\u79bb\u539f\u5219\n\u8fea\u7c73\u7279\u6cd5\u5219\n\n\n23\u79cd\u8bbe\u8ba1\u6a21\u5f0f\n\n\u521b\u5efa\u578b\u6a21\u5f0f\n\n\u5355\u4f8b\u6a21\u5f0f\n\u5de5\u5382\u6a21\u5f0f\n\u62bd\u8c61\u5de5\u5382\u6a21\u5f0f\n\n\n\u7ed3\u6784\u6027\u6a21\u578b\n\n\u4ee3\u7406\u6a21\u5f0f\n\n\n\u884c\u4e3a\u6a21\u5f0f\n\n\n\n","395":"OpenTHC Raspberry Pi Toolkit\nA collection of documentation, scripts and tools for using Raspberry Pi in cannabis operations.\nScale Support\nOne or more scales can be connected to a RPi via Serial->USB adapters, you may need a high-speed USB hub if more than four scales are used.\nSensor Support\n\nCO2: X\nCH4 (Methane):\nHumidity\/Temperature: DHT11, DHT22\nLumens:\nLight Cycle (on\/off)\nWind Speed\nWind Direction\nSolar?\npH (Soil & Liquid)?\nVPD (Vapor Pressure Deficit)\nFlood\/Moisture Sensor: EK1361, TE215\nWater Level Sensor?\n\nSoil Moisture\n\nhttps:\/\/www.amazon.com\/XCSOURCE-Moisture-Automatic-Watering-TE215\/dp\/B00ZR3B60I\/ref=pd_sim_86_13?_encoding=UTF8&pd_rd_i=B00ZR3B60I&pd_rd_r=c3b5e56b-9b65-11e8-800d-291f7dc96a5e&pd_rd_w=8Nsu8&pd_rd_wg=YE39n&pf_rd_i=desktop-dp-sims&pf_rd_m=ATVPDKIKX0DER&pf_rd_p=a180fdfb-b54e-4904-85ba-d852197d6c09&pf_rd_r=Y61ESTA6T2N3AX4A6QTB&pf_rd_s=desktop-dp-sims&pf_rd_t=40701&psc=1&refRID=Y61ESTA6T2N3AX4A6QTB\nhttps:\/\/www.amazon.com\/Kuman-Moisture-Compatible-Raspberry-Automatic\/dp\/B071F4RDHY\/ref=pd_sim_86_4?_encoding=UTF8&pd_rd_i=B071F4RDHY&pd_rd_r=520fcfc7-9b65-11e8-8a22-f3d4eee18e06&pd_rd_w=UXO65&pd_rd_wg=AR8oD&pf_rd_i=desktop-dp-sims&pf_rd_m=ATVPDKIKX0DER&pf_rd_p=a180fdfb-b54e-4904-85ba-d852197d6c09&pf_rd_r=XP2YX5BB9H3R8MWECG8C&pf_rd_s=desktop-dp-sims&pf_rd_t=40701&psc=1&refRID=XP2YX5BB9H3R8MWECG8C&dpID=51roaVQO3XL&preST=_SY300_QL70_&dpSrc=detail\nhttps:\/\/www.amazon.com\/Gikfun-Moisture-Sensor-arduino-EK1361\/dp\/B00RK1VYTI\/ref=sr_1_1?ie=UTF8&qid=1533771952&sr=8-1&keywords=soil+moisture+sensor\nhttps:\/\/www.amazon.com\/CTYRZCH-Moisture-Sensor-Automatic-Watering\/dp\/B01ESSMLQU\/ref=sr_1_19?ie=UTF8&qid=1533771976&sr=8-19&keywords=soil+moisture+sensor\nhttps:\/\/www.amazon.com\/DFROBOT-Gravity-Capacitive-Corrosion-Resistant\/dp\/B01GHY0N4K\/ref=sr_1_20?ie=UTF8&qid=1533771976&sr=8-20&keywords=soil+moisture+sensor\nhttps:\/\/www.amazon.com\/DFROBOT-Gravity-Capacitive-Corrosion-Resistant\/dp\/B01GHY0N4K\/ref=pd_sim_86_2?_encoding=UTF8&pd_rd_i=B01GHY0N4K&pd_rd_r=520fcfc7-9b65-11e8-8a22-f3d4eee18e06&pd_rd_w=UXO65&pd_rd_wg=AR8oD&pf_rd_i=desktop-dp-sims&pf_rd_m=ATVPDKIKX0DER&pf_rd_p=a180fdfb-b54e-4904-85ba-d852197d6c09&pf_rd_r=XP2YX5BB9H3R8MWECG8C&pf_rd_s=desktop-dp-sims&pf_rd_t=40701&psc=1&refRID=XP2YX5BB9H3R8MWECG8C&dpID=41W7vqM6GxL&preST=_SY300_QL70_&dpSrc=detail\nhttps:\/\/www.amazon.com\/WINGONEER-Sensor-Droplet-Detection-Arduino\/dp\/B06XHDZ3Q4\/ref=pd_sim_86_3?_encoding=UTF8&pd_rd_i=B06XHDZ3Q4&pd_rd_r=520fcfc7-9b65-11e8-8a22-f3d4eee18e06&pd_rd_w=UXO65&pd_rd_wg=AR8oD&pf_rd_i=desktop-dp-sims&pf_rd_m=ATVPDKIKX0DER&pf_rd_p=a180fdfb-b54e-4904-85ba-d852197d6c09&pf_rd_r=XP2YX5BB9H3R8MWECG8C&pf_rd_s=desktop-dp-sims&pf_rd_t=40701&psc=1&refRID=XP2YX5BB9H3R8MWECG8C\nhttps:\/\/www.amazon.com\/Phantom-YoYo-compatible-Sensitivity-Moisture\/dp\/B00AFCNR3U\/ref=pd_sim_86_50?_encoding=UTF8&pd_rd_i=B00AFCNR3U&pd_rd_r=520fcfc7-9b65-11e8-8a22-f3d4eee18e06&pd_rd_w=UXO65&pd_rd_wg=AR8oD&pf_rd_i=desktop-dp-sims&pf_rd_m=ATVPDKIKX0DER&pf_rd_p=a180fdfb-b54e-4904-85ba-d852197d6c09&pf_rd_r=XP2YX5BB9H3R8MWECG8C&pf_rd_s=desktop-dp-sims&pf_rd_t=40701&psc=1&refRID=XP2YX5BB9H3R8MWECG8C\nhttps:\/\/www.amazon.com\/dp\/B01N7NA3HP\/ref=sxbs_sxwds-stppvp_1?pf_rd_m=ATVPDKIKX0DER&pf_rd_p=6297546923292665688&pd_rd_wg=n1jTP&pf_rd_r=Z9TKR6JWBXESK34WWSZE&pf_rd_s=desktop-sx-bottom-slot&pf_rd_t=301&pd_rd_i=B01N7NA3HP&pd_rd_w=vhI9n&pf_rd_i=soil+moisture+sensor&pd_rd_r=46cb234e-c987-4ef6-8c13-b213336fca55&ie=UTF8&qid=1533771976&sr=1\nhttps:\/\/www.amazon.com\/dp\/B00TMD43BS\/ref=psdc_3480689011_t4_B00ZR3B60I\n\nControl Support\n\nOn\/Off AC Power\nOn\/Off DC Power\n\n\nHardware\nYou'll need misc resistors and capacators and stuff.\n\nhttps:\/\/www.amazon.com\/dp\/B076LH75JQ\/ref=sspa_dk_detail_12?psc=1&pd_rd_i=B076LH75JQ&pd_rd_wg=7hA91&pd_rd_r=DT8WEQMJTHSWBH952Y2Y&pd_rd_w=pdYiE\nhttps:\/\/www.amazon.com\/dp\/B07BVTFCHP\/ref=sspa_dk_detail_3?psc=1&pd_rd_i=B07BVTFCHP&pd_rd_wg=tdERY&pd_rd_r=6K5P8YTEFM594RDCM0V6&pd_rd_w=aaHEC\nhttps:\/\/www.amazon.com\/24Value-Electrolytic-Capacitor-Assortment-0-1uF%EF%BC%8D1000uF\/dp\/B01MSQOX0Q\/ref=pd_bxgy_328_3?_encoding=UTF8&pd_rd_i=B01MSQOX0Q&pd_rd_r=6K5P8YTEFM594RDCM0V6&pd_rd_w=Zmcy1&pd_rd_wg=tdERY&psc=1&refRID=6K5P8YTEFM594RDCM0V6&dpID=51lVgJM9IuL&preST=_SY300_QL70_&dpSrc=detail\n\n","396":"InfoAmazonia Colombia\nColombia deforestation data dashboard and environmental news.\nDependencies\n\nnode v0.12.x or v4.x\nnpm 2.15.x\n\nInstallation\n$ sudo npm install -g grunt-cli bower\n$ git clone https:\/\/github.com\/InfoAmazonia\/infoamazonia-colombia.git\n$ cd infoamazonia-colombia\n$ npm install && bower install\n$ grunt build\n\nRunning the app\nApp files are built into the public\/ directory, which can be linked or copied to a web server (apache\/nginx).\nFor development you can use python's http server:\n$ cd public\n$ python -m SimpleHTTPServer\n\nAccess http:\/\/localhost:8000\nDeploy on Github Pages\nForking the repository allows you to automatically deploy the app into Gihub Pages.\n$ grunt deploy\n\nAccess http:\/\/[user].github.io\/infoamazonia-colombia\/\nLearn more about Github Pages\n","397":"02456-deep-learning-project12\nThis repository contains the code and paper for project 12 in the 02456 deep learning course at DTU. The authors are Rasmus Arpe Fogh Jensen (s134843) and Thomas Pethick (s144448).\nFirst stepping stone of the project was to implement and obtain similar results as the article Piczak: Environmental sound classification with convolutional neural networks on the urbanSound-8K dataset. The implemntation and results are displayed in notebook Step1_piczak-urbansound-8K.ipynb, but ommitted from the paper, since they seemed irrelevant for the final paper. Considerable amount of work was however also put into this, which is why they are included in the repository.\nThe second step was to implement a semi-supervised learning approach for environmental sound classification utilizing unlabeled data. Specifically, the results were obtained using the datasets ESC-US (250.000 unlabeled sounds for pretraining) and ESC-50 (2000 labeled sounds, 50 different classes). A display of code is shown in the jypyter notebook Step2_ESC-semi-supervised-learning.ipynb. Note that the data-processing is ommitted from the notebook and instead implemented as its own class in DataHandler.py. The DataHandler class allows dynamically loading batches into memory used for training.\nNote: To run the jupyter notebooks, you will need to include a folder '\/datasets\/' and download the relevant datasets into the folder. The datasets are found at these locations: UrbandSound-8K, ESC-50 and ESC-US.\nThe end goal was a paper with the proposed method and results. The paper can be found in paper\/arpethick-CAE.pdf. The abstract is included below.\nTitle of paper: Environmental sound classification with semi-supervised learning\nAbstract\nIn this paper, we provide preliminary work on a semi-supervised learning approach for environmental sound classification. A convolutional autoencoder is used for pre-training the weights in the network. Two different methods for the invertions of the max-pooling layers are examined in the decoder; upsampling and unpooling. The semi-supervised approach is benchmarked against a supervised approach with similar architecture on the public available dataset ESC-50. The ESC-US dataset is used for unsupervised pre-training. The results show that the autoencoder learns useful features leading to semi-supervised learning yielding slightly better performance utilizing the unlabeled data.\nSetup\nRun the following commands to setup the conda environment.\nmake init\nsource activate arpethick-cae\n\nHaving the environment activated jupyter notebook can be started the usual way.\njupyter notebook\n\nTo test the custom unpooling layer use the following command.\nmake test\n\n","398":"\n\n\n\n\n\n\nMA - UTILS\nTools, utilties and libraries for environmental meteorology\nin use at ARPAE-SIMC\nContact and copyright information\nMa-utils is Copyright (C) 2020  ARPAE-SIMC urpsim@arpae.it\nMa-utils is licensed under the terms of the GNU General Public License version\n2.  Please see the file LICENSE for details.\nContact informations for ARPAE-SIMC (formerly ARPA-SIM):\nAgenzia Regionale Prevenzione Ambiente e Energia dell'Emilia-Romagna (ARPAE)\nServizio Idro-Meteo-Clima (SIMC)\nAddress: Viale Silvani 6, 40122 Bologna, Italy\nTel: + 39 051 6497511\nFax: + 39 051 6497501\nEmail: urpsim@arpae.it\nWebsite: https:\/\/arpae.it\/sim\/\n","399":"\n\n\n\n\n\n\nMA - UTILS\nTools, utilties and libraries for environmental meteorology\nin use at ARPAE-SIMC\nContact and copyright information\nMa-utils is Copyright (C) 2020  ARPAE-SIMC urpsim@arpae.it\nMa-utils is licensed under the terms of the GNU General Public License version\n2.  Please see the file LICENSE for details.\nContact informations for ARPAE-SIMC (formerly ARPA-SIM):\nAgenzia Regionale Prevenzione Ambiente e Energia dell'Emilia-Romagna (ARPAE)\nServizio Idro-Meteo-Clima (SIMC)\nAddress: Viale Silvani 6, 40122 Bologna, Italy\nTel: + 39 051 6497511\nFax: + 39 051 6497501\nEmail: urpsim@arpae.it\nWebsite: https:\/\/arpae.it\/sim\/\n","400":"Indicatorator\nTurns environmental parameter data into indicators, by adding text!\nRunning it\n\nnpm install\n\nDevelopment\n\nnpm start\n\nProduction\n\nnode index.js\n\nInstalling in Windows as a service:\nInstall the application on Windows as a service using\nNSSM. Configure NSSM as such:\nApplication:\n\nPath: C:\\Path\\To\\node.exe\nStartup Directory: C:\\Path\\To\\Indicatorator\nOptions: .\\index.js\n\nI\/O\nPort all your IO to Indicatorator\\logs\\service.log to be able to read\nSTDOUT\/ERR messages\nEnvironment Variables\nNODE_ENV=production\nPORT=3002\n\nIndicator definitions\nIndicator definitions are stored in .\/definitions\/indicators.json. These\nfiles are responsible for listing the indicator and the ranges for the\nindicator's threshold. Examples are stored in .\/definitions\/examples\/\nOriginally, we have different types for different indicators, for\nexample 'esri', 'cartodb' etc. Now, we're pushing attributes towards a\nconsistent type named 'standard', and instead handling differences using\nthe 'source' attribute described below.\nIndicator 'sources'\nIndicators must specify a 'source' attribute. This attribute tells the\nindicatorator where to query the data from, and how to format it.\nEach 'source' has a corresponding 'getter' module (responsible for\nfetching the data) and a 'formatter' module (responsible for formatting\nthe queried responses).\nPossible Source values\nesri\nFor indicator data stored in ESRI services and served over their REST JSON API.\nIt is required to specify (in addition to source: 'esri'):\n\nesriConfig:\n\nserverUrl: The root of the URl of the server, e.g. http:\/\/myserver.net\/rest\/services\nserviceName: The of the service, e.g. NRT_AD_AirQuality\nfeatureServer: The feature server ID, e.g. 1\n\n\n\nThese 3 components can be extracted from an esri rest URL, like so:\nhttp:\/\/myserver.net\/rest\/services\/NRT_AD_AirQuality\/FeatureServer\/2\n< serverUrl --------------------> < serviceName -->               <featureServer>\n\ngdocs\nFor indicator data stored in 'google' docs, your indicator definitions need to\ninclude a spreadsheet_key attribute. The spreadsheet in question must be\npublic and 'published for web' from the 'File -> publish for web' in google\ndocs.\nThe columns for the table are:\nTheme, Indicator, SubIndicator, <date>, <date>, <date>\n\nThe first three are simply strings, name is matched on in the indicator\ndefinition. The date columns should be dates, which will be converted to epochs\ncartodb\nFor indicator data stored in CartoDB tables, your indicator definitions\nneed to include table_name and CartoDB username attributes. The\nCartoDB table must be publicly available.\nYou can also use CartoDB\nSync\nto read spreadsheets into cartodb which will automatically collected (in formats such as XLS, CSV,\netc.) up to every hour.\nThe format for data is a little constrained due to the fact postgres can't\nhandle integers column names. You must use column names field_1 through field_n,\nand instead put the column headers in as the first row in the table, like so:\n\n\n\nfield_1\nfield_2\nfield_3\nfield_4\nfield_5\nfield_n\n\n\n\n\nTheme\nIndicator\nSubIndicator\n1998\n1999\nn\n\n\nAir\nNO2\n-\n0.4\n0.9\nn\n\n\nAir\nO2\n-\n0.8\n0.8\nn\n\n\n\nThe first 3 values should always be Theme, Indicator and SubIndicator, followed\nby your date fields in order.\nThere is an\nexample\ndata table available on Google\nDocs.\nOptional standard indicator features\napplyRanges: (true)\nBy default, indicatoration applies text values to raw indicator data, using the\nranges specified in the 'range' attribute. If you don't want this to happen,\nspecify applyRanges: false\nreduceField: (null)\nBasic sub indicator support is implemented by allowing grouping on a text field.\nFor example, if you had a collection of data for the same year but for different\nmonitoring stations, specify the group field here, e.g. 'station' to have the\ndata grouped on the station, by periodStart\n","401":"ecocrop\nThis is an R package that implements the ecocrop algorithm.\nYou can install it with:\ninstall.packages(c(\"meteor\", \"terra\"))\nremotes::install_github(\"cropmodels\/Recocrop\")\n\nNote that you need to have the remotes package installed, and if you are on windows, you must also have Rtools installed to be able to compile and install this package.\n","402":"iot-environmental\n","403":"Environmental Layers repository overview\nAt the top-level, the repository is split into four main topical domains\n(climate, derived-climate, land-cover, and terrain),\nplus an additional shared directory for general project-level\nmaterials. Each of the topical directories themselves contain up to 6\npredetermined subdirectories as indicated below. See descriptions for\nspecific criteria for determining what goes in each directory.\nAll committed work should fall within this directory structure.\n\nresearch\nScripts, notes, generated summaries\/reports, and possibly additional\nrelevant background information intended to inform and\/or evaluate\nmethodological decisions. The defining criterion is that these\nmaterials are not designed to be used as operational components of\nthe eventual data production workflow itself, but instead serve to\nguide its development. Examples include case studies, statistical\nmodel comparisons, dataset assessments, validation procedures, etc.\nprocedures\nScripts that either have been, could be, or will be executed with the\nexpress purpose of producing data, including acquisition of data\nfrom elsewhere, creation of intermediate datasets, and production of\nfinal layers. Prose (or mixed prose\/text) text documents may be\nsubstituted for executable scripts if absolutely necessary, e.g. to\nexpress procedures that had to be performed manually.\ntests\nScripts intended for testing whether particular data holdings meet\nexpectations (e.g., completeness, consistency, etc), or for testing\nwhether particular scripts produce output as expected given specified\ntest inputs. Although not necessarily the case while in-development,\nultimately all tests should be able to run without intervention,\nreporting either success or failure along with appropriate supporting\ndetails.\ndoc\nDocumentation and associated files (figures, thumbnail images, etc).\nStrong preference should be given to text-based documentation\n(including standard markup formats), and especially reproducible\ndocumentation schemes such as LaTeX\/Sweave.\nlib\nSource code (possibly with supporting materials such as Makefiles)\nthat contains generally useful and reusable bits of functionality that\nare or could be leveraged elsewhere. The idea is that these would be\nimported, included, sourced, etc. by scripts in one or more other\nproject directories.\nextra\nMiscellaneous notes, code snippets, blue-sky scripts, and other\nmaterials that seem worth capturing into this repository, but don't\nfit under any other directories.\n\nDirectory tree:\n.\n\u251c\u2500\u2500 climate\/\n\u2502   \u251c\u2500\u2500 research\/\n\u2502   \u251c\u2500\u2500 procedures\/\n\u2502   \u251c\u2500\u2500 tests\/\n\u2502   \u251c\u2500\u2500 lib\/\n\u2502   \u251c\u2500\u2500 doc\/\n\u2502   \u2514\u2500\u2500 extra\/\n\u251c\u2500\u2500 derived-climate\/\n\u2502   \u251c\u2500\u2500\n\u2502   \u251c\u2500\u2500\n\u2502   \u251c\u2500\u2500 <as above>\n\u2502   \u251c\u2500\u2500\n\u2502   \u251c\u2500\u2500\n\u2502   \u2514\u2500\u2500\n\u251c\u2500\u2500 land-cover\/\n\u2502   \u251c\u2500\u2500\n\u2502   \u251c\u2500\u2500\n\u2502   \u251c\u2500\u2500 <as above>\n\u2502   \u251c\u2500\u2500\n\u2502   \u251c\u2500\u2500\n\u2502   \u2514\u2500\u2500\n\u251c\u2500\u2500 terrain\/\n\u2502   \u251c\u2500\u2500\n\u2502   \u251c\u2500\u2500\n\u2502   \u251c\u2500\u2500 <as above>\n\u2502   \u251c\u2500\u2500\n\u2502   \u251c\u2500\u2500\n\u2502   \u2514\u2500\u2500\n\u2514\u2500\u2500 shared\/\n\n","404":"EEFA_App\nEnvironmental Film Festival 2014 Android App\nori gj\n","405":"\necosia-plugin-react\nAn easy to use tool that makes planting trees even easier\nAbout\nThis is boilerplate code for making a search extension for Ecosia, most of which is forked from kryptokinght's react-extension-boilerplate. It allows developers to easily create cool features like DuckDuckGo's password generation feature (more info) or Google(\ud83e\udd22)'s timer feature with React.\nMy example plugin just echos \"Hello world\" if you search it in Ecosia... but the possibilities are truly endless! The idea is that cool new features will help reel in new users to Ecosia, and new Ecosia users === more trees planted \ud83c\udf33\ud83d\udc9e.\n\nInstallation\n# clone the repo\n$ git clone git@github.com:nbennett320\/ecosia-plugin-react.git\n\n# not sure what does but it seems to work\n$ cd ecosia-plugin-react\/\n\n# install dependencies with yarn\n$ yarn install\n\nUsage\n# open a development window in firefox \n$ yarn run start:firefox\n\n# open a development window in (\ud83e\udd22) chrome \n$ yarn run start:chrome\n\n# build files to '.\/extension'\n$ yarn run build\n\n# compress build folder to {manifest.name}.zip and crx\n$ npm run build\n$ npm run compress -- [options]\n\nMore info and details can be found on kryptokinght's repo.\n","406":"\necosia-plugin-react\nAn easy to use tool that makes planting trees even easier\nAbout\nThis is boilerplate code for making a search extension for Ecosia, most of which is forked from kryptokinght's react-extension-boilerplate. It allows developers to easily create cool features like DuckDuckGo's password generation feature (more info) or Google(\ud83e\udd22)'s timer feature with React.\nMy example plugin just echos \"Hello world\" if you search it in Ecosia... but the possibilities are truly endless! The idea is that cool new features will help reel in new users to Ecosia, and new Ecosia users === more trees planted \ud83c\udf33\ud83d\udc9e.\n\nInstallation\n# clone the repo\n$ git clone git@github.com:nbennett320\/ecosia-plugin-react.git\n\n# not sure what does but it seems to work\n$ cd ecosia-plugin-react\/\n\n# install dependencies with yarn\n$ yarn install\n\nUsage\n# open a development window in firefox \n$ yarn run start:firefox\n\n# open a development window in (\ud83e\udd22) chrome \n$ yarn run start:chrome\n\n# build files to '.\/extension'\n$ yarn run build\n\n# compress build folder to {manifest.name}.zip and crx\n$ npm run build\n$ npm run compress -- [options]\n\nMore info and details can be found on kryptokinght's repo.\n","407":"Hero-Of-Recycle\nThis is the game about environmental protection\nUI\u4ecb\u7ecd\n1.\u4e3b\u83dc\u5355menu\n\u00a0 play\u6309\u94ae\u4e3a\u5f00\u59cb\u6e38\u620f\u6309\u94ae\uff0c\u6309\u4e0b\u8f6c\u53bbSceneIntroduction01\uff0c\u5373\u7b2c\u4e00\u5173\u7684\u4ecb\u7ecdUI\uff0c\u53ef\u5728\u6309\u94ae\u7ec4\u4ef6\u4e2d\u7684TargetScene\u66f4\u6539\u52a0\u8f7d\u7684\u573a\u666f\uff1b\nhelp\u6309\u94ae\u4e3a\u6e38\u620f\u64cd\u4f5c\u8bf4\u660e\uff1b\n2.\u5173\u5361\u4ecb\u7ecdSceneIntroduction\n\u00a0 continue\u4e3a\u8fdb\u5165\u6e38\u620f\uff0cback\u9000\u56de\u83dc\u5355\uff0c\u53ef\u5728\u76f8\u5e94\u6309\u94ae\u7ec4\u4ef6\u4e2d\u7684TargetScene\u66f4\u6539\u52a0\u8f7d\u7684\u573a\u666f\uff1b\n","408":"Hero-Of-Recycle\nThis is the game about environmental protection\nUI\u4ecb\u7ecd\n1.\u4e3b\u83dc\u5355menu\n\u00a0 play\u6309\u94ae\u4e3a\u5f00\u59cb\u6e38\u620f\u6309\u94ae\uff0c\u6309\u4e0b\u8f6c\u53bbSceneIntroduction01\uff0c\u5373\u7b2c\u4e00\u5173\u7684\u4ecb\u7ecdUI\uff0c\u53ef\u5728\u6309\u94ae\u7ec4\u4ef6\u4e2d\u7684TargetScene\u66f4\u6539\u52a0\u8f7d\u7684\u573a\u666f\uff1b\nhelp\u6309\u94ae\u4e3a\u6e38\u620f\u64cd\u4f5c\u8bf4\u660e\uff1b\n2.\u5173\u5361\u4ecb\u7ecdSceneIntroduction\n\u00a0 continue\u4e3a\u8fdb\u5165\u6e38\u620f\uff0cback\u9000\u56de\u83dc\u5355\uff0c\u53ef\u5728\u76f8\u5e94\u6309\u94ae\u7ec4\u4ef6\u4e2d\u7684TargetScene\u66f4\u6539\u52a0\u8f7d\u7684\u573a\u666f\uff1b\n","409":"Environmental-monitoring\nArduino code for the Fablab Torino activity regarding monitoring devices.\n","410":"\u73af\u4fdd\u4e0a\u4f20\n\u8fc7\u7a0b\u6570\u636e\u72b6\u6001\nASM\n0:5025\u52a0\u901f\n1:5025\u51c6\u5907\n2:5025\u5feb\u901f\n3:5025\n4:2540\u52a0\u901f\n5:2540\u51c6\u5907\n6:2540\u5feb\u901f\n7:2540\n\nSDS\n0-\u9884\u70ed \n1-\u9ad8\u6020\u901f\u51c6\u5907\n2 \u9ad8\u6020\u901f\n3 \u6020\u901f\u51c6\u5907\n4 \u6020\u901f\n\nVMAS\n\nLD\n0\u52a0\u901f\n1 \u626b\u63cf\u8fc7\u7a0b \n2 100%\u7a33\u5b9a\u8fc7\u7a0b\n3 100%\u5e73\u5747\u6570\u636e\n4 80%\u7a33\u5b9a\u8fc7\u7a0b \n5 80%\u5e73\u5747\u6570\u636e\n6 \u51cf\u901f\u6216\u964d\u901f\u81f3\u6020\u901f\u8fc7\u7a0b\n7 90%\u7a33\u5b9a\u8fc7\u7a0b\n8 90%\u5e73\u5747\u6570\u636e\n9 100% \u7a33\u5b9a3\u79d2\n10 80%\u7a33\u5b9a3\u79d2\n11 90%\u7a33\u5b9a3\u79d2\n12 \u6020\u901f6\u79d2\u8fc7\u7a0b\n\nZYJS\n1\uff1a\u7b2c\u4e00\u7ec4\n2\uff1a\u7b2c\u4e8c\u7ec4\n3\uff1a\u7b2c\u4e09\u7ec4\n......\n....\n\n\u626d\u529b\uff08N\uff09\n\u626d\u77e9 \uff08N.m\uff09\n","411":"RoadAccidentsPODS\nPrinciples of Data Science coursework project investigating relationships between environmental conditions and traffic accidents in the UK.\n\n\nRoadSafety.py - Main data analysis script. Should run in any IDE, but was written in Spyder and contains cell breaks.\n\n\nrefData.py - Script to run on the original data to convert reference data codes in to text values. The data in this repo is a product of this script (so it doesn't need to be run again).\n\n\nEnvironmental Conditions and Road Traffic Collisions in the UK v1.2.pdf - Project report.\n\n\nAcc_2016_Tidy.csv - All traffic accidents reported to police in 2016 involving injury.\n\n\nCas_2016_Tidy.csv - Details of all casulaties involved in accidents.\n\n\nVeh_2016_Tidy.csv - Details of all vehicles involved in accidents.\n\n\nI have also written an article in Towards Data Science based on this work, which is available here:\nhttps:\/\/towardsdatascience.com\/car-crashes-and-the-weather-an-exploratory-analysis-of-environmental-conditions-impact-on-traffic-12bcb7f9afed\n","412":"This project was bootstrapped with Create React App.\nAvailable Scripts\nIn the project directory, you can run:\nnpm start\nRuns the app in the development mode.\nOpen http:\/\/localhost:3000 to view it in the browser.\nThe page will reload if you make edits.\nYou will also see any lint errors in the console.\nnpm test\nLaunches the test runner in the interactive watch mode.\nSee the section about running tests for more information.\nnpm run build\nBuilds the app for production to the build folder.\nIt correctly bundles React in production mode and optimizes the build for the best performance.\nThe build is minified and the filenames include the hashes.\nYour app is ready to be deployed!\nSee the section about deployment for more information.\nnpm run eject\nNote: this is a one-way operation. Once you eject, you can\u2019t go back!\nIf you aren\u2019t satisfied with the build tool and configuration choices, you can eject at any time. This command will remove the single build dependency from your project.\nInstead, it will copy all the configuration files and the transitive dependencies (Webpack, Babel, ESLint, etc) right into your project so you have full control over them. All of the commands except eject will still work, but they will point to the copied scripts so you can tweak them. At this point you\u2019re on your own.\nYou don\u2019t have to ever use eject. The curated feature set is suitable for small and middle deployments, and you shouldn\u2019t feel obligated to use this feature. However we understand that this tool wouldn\u2019t be useful if you couldn\u2019t customize it when you are ready for it.\nLearn More\nYou can learn more in the Create React App documentation.\nTo learn React, check out the React documentation.\nCode Splitting\nThis section has moved here: https:\/\/facebook.github.io\/create-react-app\/docs\/code-splitting\nAnalyzing the Bundle Size\nThis section has moved here: https:\/\/facebook.github.io\/create-react-app\/docs\/analyzing-the-bundle-size\nMaking a Progressive Web App\nThis section has moved here: https:\/\/facebook.github.io\/create-react-app\/docs\/making-a-progressive-web-app\nAdvanced Configuration\nThis section has moved here: https:\/\/facebook.github.io\/create-react-app\/docs\/advanced-configuration\nDeployment\nThis section has moved here: https:\/\/facebook.github.io\/create-react-app\/docs\/deployment\nnpm run build fails to minify\nThis section has moved here: https:\/\/facebook.github.io\/create-react-app\/docs\/troubleshooting#npm-run-build-fails-to-minify\n","413":"Environmental Stressor\n\nThis is an ASP.NET Core web application for test environment (like a server or cluster).\nIt provides operations to simulate:\n\nLong running startup\nLong running request\nHigh CPU usage\nMemory leak\nOut of memory\nHigh throughput\n\nRunning\nDocker image available at: https:\/\/hub.docker.com\/r\/matheusneder\/environmental-stressor\n# docker run matheusneder\/environmental-stressor:v1.0-alpha.4\n\n","414":"Environmental Stressor\n\nThis is an ASP.NET Core web application for test environment (like a server or cluster).\nIt provides operations to simulate:\n\nLong running startup\nLong running request\nHigh CPU usage\nMemory leak\nOut of memory\nHigh throughput\n\nRunning\nDocker image available at: https:\/\/hub.docker.com\/r\/matheusneder\/environmental-stressor\n# docker run matheusneder\/environmental-stressor:v1.0-alpha.4\n\n","415":"Environmental Stressor\n\nThis is an ASP.NET Core web application for test environment (like a server or cluster).\nIt provides operations to simulate:\n\nLong running startup\nLong running request\nHigh CPU usage\nMemory leak\nOut of memory\nHigh throughput\n\nRunning\nDocker image available at: https:\/\/hub.docker.com\/r\/matheusneder\/environmental-stressor\n# docker run matheusneder\/environmental-stressor:v1.0-alpha.4\n\n","416":"Swiss Environmental Data (BAFU Umwelt Basisdaten) \nThis repoistory contains some sample datasets from Swiss Federal Office for the Environment FOEN which are transformed to RDF and made available at the LINDAS-Platform SPARQL endpoint.\n\n\/input: the raw data\n\/target: generated RDF (will be generated)\n\/config: the configuration of the transformers\n\/scripts: shell scripts to run the transformation\n\/lib: binary libaries used\n\nExample queries in YasGUI\n\nPivot Table\nSimple Barchart\nLine Chart per Station\nLine Chart per Pollutant (Table bar Chart, Heatmap)\nPoC of Map\n\nParticulate matter immissions\nOzone immissions\n\n","417":"Swiss Environmental Data (BAFU Umwelt Basisdaten) \nThis repoistory contains some sample datasets from Swiss Federal Office for the Environment FOEN which are transformed to RDF and made available at the LINDAS-Platform SPARQL endpoint.\n\n\/input: the raw data\n\/target: generated RDF (will be generated)\n\/config: the configuration of the transformers\n\/scripts: shell scripts to run the transformation\n\/lib: binary libaries used\n\nExample queries in YasGUI\n\nPivot Table\nSimple Barchart\nLine Chart per Station\nLine Chart per Pollutant (Table bar Chart, Heatmap)\nPoC of Map\n\nParticulate matter immissions\nOzone immissions\n\n","418":"This repo hosts kaspermarstal.github.io.\n","419":"This repo hosts kaspermarstal.github.io.\n","420":"Environmental Prediction\nDeveloping Data Products Course Project.\nIt can be viewed online at shinyapps\nInstructions\nThis app predicts the radiation, temperature or wind values using the ozone as a predictor.\nSelect an outcome variable from the dropdown list (radiation, temperature or wind) and move the slider to change the ozone parts per billion.\nThe results of the prediction are shown on the right panel.\nA graph is displayed on the right panel with the outcome values in the y-axis and the ozone parts per billion in the x-axis.\nThe orange mark is placed at the predicted value on the regression line.\nYou may change your outcome variable and\/or the ozone parts per billion value to see how the predicted value and the graph are updated.\n","421":"Environmental\n","422":"\n    \nBlueant\nBlueant provides a set of data source configurations to use with the bowerbird package. These data sources are themed around Antarctic and Southern Ocean data, and include a range of oceanographic, meteorological, topographic, and other environmental data sets. Blueant will allow you to download data from these external data providers to your local file system, and to keep that data collection up to date.\nInstalling\ninstall.packages(\"remotes\")\nremotes::install_github(\"AustralianAntarcticDivision\/blueant\", build_vignettes = TRUE)\nUsage overview\nConfiguration\nBuild up a configuration by first defining global options such as the destination on your local file system. Usually you would choose this destination data directory to be a persistent location, suitable for a data library. For demonstration purposes here we'll just use a temporary directory:\nlibrary(blueant)\nmy_data_dir <- tempdir()\ncf <- bb_config(local_file_root = my_data_dir)\nAdd data sources from those provided by blueant. A summary of these sources is given at the end of this document. Here we'll use the \"George V bathymetry\" data source as an example:\nmysrc <- sources(\"George V bathymetry\")\ncf <- cf %>% bb_add(mysrc)\nThis data source is fairly small (around 200MB, see mysrc$collection_size). Be sure to check the collection_size parameter of your chosen data source before running the synchronization. Some of these collections are quite large (see the summary table at the bottom of this document).\nSynchronization\nOnce the configuration has been defined and the data source added to it, we can run the sync process. We set verbose = TRUE here so that we see additional progress output:\nstatus <- bb_sync(cf, verbose = TRUE)\n## \n## Thu May 23 03:19:49 2019\n## Synchronizing dataset: George V bathymetry\n## Source URL https:\/\/data.aad.gov.au\/eds\/file\/4494\/\n## --------------------------------------------------------------------------------------------\n## \n##  this dataset path is: c:\\tmp\\data\/data.aad.gov.au\/eds\/file\/4494\n##  building file list ... done.\n##  downloading file 1 of 1: https:\/\/data.aad.gov.au\/eds\/file\/4494\/ ...  done.\n##   decompressing: c:\\tmp\\data\/data.aad.gov.au\/eds\/file\/4494\/download.zip ... extracting 4 files into c:\/tmp\/data\/data.aad.gov.au\/eds\/file\/4494 ... done.\n## \n## Thu May 23 03:20:23 2019 dataset synchronization complete: George V bathymetry\n\nCongratulations! You now have your own local copy of this data set. The files in this data set have been stored in a data-source-specific subdirectory of our local file root, with details given by the returned status object:\nmyfiles <- status$files[[1]]\nmyfiles\n## # A tibble: 5 x 3\n##   url                      file                                   note     \n##   <chr>                    <chr>                                  <chr>    \n## 1 https:\/\/data.aad.gov.au~ \"c:\\\\tmp\\\\data\\\\data.aad.gov.au\\\\eds\\~ download~\n## 2 <NA>                     c:\/tmp\/data\/data.aad.gov.au\/eds\/file\/~ decompre~\n## 3 <NA>                     c:\/tmp\/data\/data.aad.gov.au\/eds\/file\/~ decompre~\n## 4 <NA>                     c:\/tmp\/data\/data.aad.gov.au\/eds\/file\/~ decompre~\n## 5 <NA>                     c:\/tmp\/data\/data.aad.gov.au\/eds\/file\/~ decompre~\nThe data sources provided by blueant can be read, manipulated, and plotted using a range of other R packages, including RAADTools and raster. In this case the data files are netcdf, which can be read by raster:\nlibrary(raster)\nx <- raster(myfiles$file[grepl(\"gvdem500m_v3\", myfiles$file)])\nplot(x)\n\nNuances\nChoosing a data directory\nIt's up to you where you want your data collection kept, and to provide that location to bowerbird. A common use case for bowerbird is maintaining a central data collection for multiple users, in which case that location is likely to be some sort of networked file share. However, if you are keeping a collection for your own use, you might like to look at https:\/\/github.com\/r-lib\/rappdirs to help find a suitable directory location.\nAuthentication\nSome data providers require users to log in. These are indicated by the authentication_note column in the configuration table. For these sources, you will need to provide your user name and password, e.g.:\nsrc <- sources(name=\"CMEMS global gridded SSH reprocessed (1993-ongoing)\")\nsrc$user <- \"yourusername\"\nsrc$password <- \"yourpassword\"\ncf <- bb_add(cf, src)\n\n## or, using the pipe operator\nmysrc <- bb_example_sources(\"CMEMS global gridded SSH reprocessed (1993-ongoing)\") %>%\n  bb_modify_source(user = \"yourusername\", password = \"yourpassword\")\ncf <- cf %>% bb_add(mysrc)\nWriting and modifying data sources\nThe bowerbird documentation is a good place to start to find out more about writing your own data sources or modifying existing ones.\nReducing download sizes\nSometimes you might only want part of a data collection. Perhaps you only want a few years from a long-term collection, or perhaps the data are provided in multiple formats and you only need one. If the data source uses the bb_handler_rget method, you can restrict what is downloaded by modifying the arguments passed through the data source's method parameter, particularly the accept_follow, reject_follow, accept_download, and reject_download options.\nFor example, the CERSAT SSM\/I sea ice concentration data are arranged in yearly directories, and so it is fairly easy to restrict ourselves to, say, only the 2017 data:\nmysrc <- sources(\"CERSAT SSM\/I sea ice concentration\")\n\n## first make sure that the data source doesn't already have an accept_follow parameter defined\n\"accept_follow\" %in% names(mysrc$method[[1]])\n\n## nope, so we can safely go ahead and impose our own\nmysrc$method[[1]]$accept_follow <- \"\/2017\"\ncf <- cf %>% bb_add(mysrc)\nAlternatively, for data sources that are divided into subdirectories, one could replace the whole-data-source source_url with one or more that point to specific yearly (or other) subdirectories. For example, the default source_url for the CERSAT sea ice data above is ftp:\/\/ftp.ifremer.fr\/ifremer\/cersat\/products\/gridded\/psi-concentration\/data\/antarctic\/daily\/netcdf\/ (which has yearly subdirectories). So e.g. for 2016 and 2017 data we could do:\nmysrc <- sources(\"CERSAT SSM\/I sea ice concentration\")\nmysrc$source_url[[1]] <- c(\n  \"ftp:\/\/ftp.ifremer.fr\/ifremer\/cersat\/products\/gridded\/psi-concentration\/data\/antarctic\/daily\/netcdf\/2016\/\",\n  \"ftp:\/\/ftp.ifremer.fr\/ifremer\/cersat\/products\/gridded\/psi-concentration\/data\/antarctic\/daily\/netcdf\/2017\/\")\ncf <- cf %>% bb_add(mysrc)\nDefining new data sources\nIf the blueant data sources don't cover your needs, you can define your own using the bb_source function. See the bowerbird documentation.\nData source summary\nThese are the data source definitions that are provided as part of the blueant package.\nData group: Altimetry\nCMEMS global gridded SSH near-real-time\nFor the Global Ocean - Multimission altimeter satellite gridded sea surface heights and derived variables computed with respect to a twenty-year mean. Previously distributed by Aviso+, no change in the scientific content. All the missions are homogenized with respect to a reference mission which is currently Jason-3. The acquisition of various altimeter data is a few days at most. VARIABLES\n\n\nsea_surface_height_above_sea_level (SSH)\n\n\nsurface_geostrophic_eastward_sea_water_velocity_assuming_sea_level_for_geoid (UVG)\n\n\nsurface_geostrophic_northward_sea_water_velocity_assuming_sea_level_for_geoid (UVG)\n\n\nsea_surface_height_above_geoid (SSH)\n\n\nsurface_geostrophic_eastward_sea_water_velocity (UVG)\n\n\nsurface_geostrophic_northward_sea_water_velocity (UVG)\n\n\nAuthentication note: Copernicus Marine login required, see http:\/\/marine.copernicus.eu\/services-portfolio\/register-now\/\nApproximate size: 3 GB\nDocumentation link: http:\/\/marine.copernicus.eu\/services-portfolio\/access-to-products\/?option=com_csw&view=details&product_id=SEALEVEL_GLO_PHY_L4_NRT_OBSERVATIONS_008_046\nCMEMS global gridded SSH reprocessed (1993-ongoing)\nFor the Global Ocean - Multimission altimeter satellite gridded sea surface heights and derived variables computed with respect to a twenty-year mean. Previously distributed by Aviso+, no change in the scientific content. All the missions are homogenized with respect to a reference mission which is currently OSTM\/Jason-2. VARIABLES\n\n\nsea_surface_height_above_sea_level (SSH)\n\n\nsurface_geostrophic_eastward_sea_water_velocity_assuming_sea_level_for_geoid (UVG)\n\n\nsurface_geostrophic_northward_sea_water_velocity_assuming_sea_level_for_geoid (UVG)\n\n\nsea_surface_height_above_geoid (SSH)\n\n\nsurface_geostrophic_eastward_sea_water_velocity (UVG)\n\n\nsurface_geostrophic_northward_sea_water_velocity (UVG)\n\n\nAuthentication note: Copernicus Marine login required, see http:\/\/marine.copernicus.eu\/services-portfolio\/register-now\/\nApproximate size: 310 GB\nDocumentation link: http:\/\/marine.copernicus.eu\/services-portfolio\/access-to-products\/?option=com_csw&view=details&product_id=SEALEVEL_GLO_PHY_L4_REP_OBSERVATIONS_008_047\nCNES-CLS2013 Mean Dynamic Topography\nCNES-CLS2013 Mean dynamic topography over the 1993-2012 period of the sea surface height above geoid. The MDT_CNES-CLS13 is an estimate of the ocean MDT for the 1993-2012 period. Since April 2014 (Duacs 2014, v15.0 version), the Ssalto\/Duacs (M)SLA products are computed relative to 1993-2012 period that is consistent with this new MDT CNES-CLS13. Based on 2 years of GOCE data, 7 years of GRACE data, and 20 years of altimetry and in-situ data (hydrologic and drifters data).\nAuthentication note: AVISO login required, see https:\/\/www.aviso.altimetry.fr\/en\/data\/data-access\/endatadata-accessregistration-form.html\nApproximate size: 0.1 GB\nDocumentation link: https:\/\/www.aviso.altimetry.fr\/en\/data\/products\/auxiliary-products\/mdt.html\nDelayed-time finite size Lyapunov exponents\nThe maps of Backward-in-time, Finite-Size Lyapunov Exponents (FSLEs) and Orientations of associated eigenvectors are computed over 21-year altimetry period and over global ocean within the SALP\/Cnes project in collaboration with CLS, LOcean and CTOH. These products provide the exponential rate of separation of particle trajectories initialized nearby and advected by altimetry velocities. FSLEs highlight the transport barriers that control the horizontal exchange of water in and out of eddy cores.\nAuthentication note: AVISO login required, see https:\/\/www.aviso.altimetry.fr\/en\/data\/data-access\/endatadata-accessregistration-form.html\nApproximate size: 1200 GB\nDocumentation link: https:\/\/www.aviso.altimetry.fr\/en\/data\/products\/value-added-products\/fsle-finite-size-lyapunov-exponents\/fsle-description.html\nNear-real-time finite size Lyapunov exponents\nThe maps of Backward-in-time, Finite-Size Lyapunov Exponents (FSLEs) and Orientations of associated eigenvectors are computed over 21-year altimetry period and over global ocean within the SALP\/Cnes project in collaboration with CLS, LOcean and CTOH. These products provide the exponential rate of separation of particle trajectories initialized nearby and advected by altimetry velocities. FSLEs highlight the transport barriers that control the horizontal exchange of water in and out of eddy cores.\nAuthentication note: AVISO login required, see https:\/\/www.aviso.altimetry.fr\/en\/data\/data-access\/endatadata-accessregistration-form.html\nApproximate size: 100 GB\nDocumentation link: https:\/\/www.aviso.altimetry.fr\/en\/data\/products\/value-added-products\/fsle-finite-size-lyapunov-exponents\/fsle-description.html\nData group: Biology\nSEAPODYM Zooplankton & Micronekton weekly potential and biomass distribution\nThe zooplankton & micronekton biomass distributions are outputs of the SEAPODYM Low and Mid-Trophic Levels (LMTL) model (Lehodey et al., 1998; 2010; 2015). SEAPODYM-LMTL model simulates the spatial and temporal dynamics of six micronekton and one zooplankton functional groups between the sea surface and ~1000m. The model is driven by ocean temperature, horizontal currents, primary production and euphotic depth. Primary production can be outputs from biogeochemical models or derived from ocean color satellite data using empirical optical models (e.g., Behrenfeld and Falkowski 1997).\nAuthentication note: Requires registration, see http:\/\/www.mesopp.eu\/data\/registration\/\nApproximate size: not specified\nDocumentation link: http:\/\/www.mesopp.eu\/catalogue\/seapodym-zooplankton-micronekton-weekly-potential-and-biomass-distribution-2016\/#dataset\nSouthern Ocean Continuous Plankton Recorder\nContinuous Plankton Recorder (CPR) surveys from the Southern Ocean. Zooplankton species, numbers and abundance data are recorded on a continuous basis while vessels are in transit\nApproximate size: 0.1 GB\nDocumentation link: https:\/\/data.aad.gov.au\/metadata\/records\/AADC-00099\nData group: Meteorological\nAntarctic Mesoscale Prediction System grib files\nThe Antarctic Mesoscale Prediction System - AMPS - is an experimental, real-time numerical weather prediction capability that provides support for the United States Antarctic Program, Antarctic science, and international Antarctic efforts.\nApproximate size: not specified\nDocumentation link: http:\/\/www2.mmm.ucar.edu\/rt\/amps\/\nData group: Modelling\nSouthern Ocean marine environmental data\nA collection of gridded marine environmental data layers suitable for use in Southern Ocean species distribution modelling. All environmental layers have been generated at a spatial resolution of 0.1 degrees, covering the Southern Ocean extent (80 degrees S - 45 degrees S, -180 - 180 degrees). The layers include information relating to bathymetry, sea ice, ocean currents, primary production, particulate organic carbon, and other oceanographic data.\nApproximate size: 0.1 GB\nDocumentation link: https:\/\/doi.org\/10.26179\/5b8f30e30d4f3\nData group: Ocean colour\nOceandata MODIS Aqua Level-3 binned daily RRS\nDaily remote-sensing reflectance from MODIS Aqua. RRS is used to produce standard ocean colour products such as chlorophyll concentration\nApproximate size: 800 GB\nDocumentation link: http:\/\/oceancolor.gsfc.nasa.gov\/\nOceandata MODIS Aqua Level-3 mapped daily 4km chl-a\nDaily remote-sensing chlorophyll-a from the MODIS Aqua satellite at 4km spatial resolution\nApproximate size: 40 GB\nDocumentation link: http:\/\/oceancolor.gsfc.nasa.gov\/\nOceandata MODIS Aqua Level-3 mapped monthly 9km chl-a\nMonthly remote-sensing chlorophyll-a from the MODIS Aqua satellite at 9km spatial resolution\nApproximate size: 8 GB\nDocumentation link: http:\/\/oceancolor.gsfc.nasa.gov\/\nOceandata SeaWiFS Level-3 binned daily RRS\nDaily remote-sensing reflectance from SeaWiFS. RRS is used to produce standard ocean colour products such as chlorophyll concentration\nApproximate size: 130 GB\nDocumentation link: http:\/\/oceancolor.gsfc.nasa.gov\/\nOceandata SeaWiFS Level-3 mapped monthly 9km chl-a\nMonthly remote-sensing chlorophyll-a from the SeaWiFS satellite at 9km spatial resolution\nApproximate size: 7.2 GB\nDocumentation link: http:\/\/oceancolor.gsfc.nasa.gov\/\nOceandata VIIRS Level-3 binned daily RRS\nDaily remote-sensing reflectance from VIIRS. RRS is used to produce standard ocean colour products such as chlorophyll concentration\nApproximate size: 180 GB\nDocumentation link: http:\/\/oceancolor.gsfc.nasa.gov\/\nOceandata VIIRS Level-3 mapped 32-day 9km chl-a\nRolling 32-day composite remote-sensing chlorophyll-a from the VIIRS satellite at 9km spatial resolution\nApproximate size: 4 GB\nDocumentation link: http:\/\/oceancolor.gsfc.nasa.gov\/\nOceandata VIIRS Level-3 mapped daily 4km chl-a\nDaily remote-sensing chlorophyll-a from the VIIRS satellite at 4km spatial resolution\nApproximate size: 1 GB\nDocumentation link: http:\/\/oceancolor.gsfc.nasa.gov\/\nOceandata VIIRS Level-3 mapped monthly 9km chl-a\nMonthly remote-sensing chlorophyll-a from the VIIRS satellite at 9km spatial resolution\nApproximate size: 1 GB\nDocumentation link: http:\/\/oceancolor.gsfc.nasa.gov\/\nOceandata VIIRS Level-3 mapped seasonal 9km chl-a\nSeasonal remote-sensing chlorophyll-a from the VIIRS satellite at 9km spatial resolution\nApproximate size: 0.5 GB\nDocumentation link: http:\/\/oceancolor.gsfc.nasa.gov\/\nSouthern Ocean summer chlorophyll-a climatology (Johnson)\nClimatological summer chlorophyll-a layer for the Southern Ocean south of 40S, following the OC3M algorithm of Johnson et al. (2013)\nApproximate size: 0.05 GB\nDocumentation link: https:\/\/doi.org\/doi:10.4225\/15\/5906b48f70bf9\nData group: Oceanographic\nArgo ocean basin data (USGODAE)\nArgo float data from the Global Data Access Centre in Monterey, USA (US Global Ocean Data Assimilation Experiment). These are multi-profile netcdf files divided by ocean basin.\nApproximate size: not specified\nDocumentation link: http:\/\/www.argodatamgt.org\/Documentation\nArgo profile data (USGODAE)\nArgo profile data from the Global Data Access Centre in Monterey, USA (US Global Ocean Data Assimilation Experiment).\nApproximate size: not specified\nDocumentation link: http:\/\/www.argodatamgt.org\/Documentation\nCSIRO Atlas of Regional Seas 2009\nCARS is a digital climatology, or atlas of seasonal ocean water properties.\nApproximate size: 2.8 GB\nDocumentation link: http:\/\/www.marine.csiro.au\/~dunn\/cars2009\/\nWorld Ocean Atlas 2009\nWorld Ocean Atlas 2009 (WOA09) is a set of objectively analyzed (1 degree grid) climatological fields of in situ temperature, salinity, dissolved oxygen, Apparent Oxygen Utilization (AOU), percent oxygen saturation, phosphate, silicate, and nitrate at standard depth levels for annual, seasonal, and monthly compositing periods for the World Ocean. It also includes associated statistical fields of observed oceanographic profile data interpolated to standard depth levels on both 1 degree and 5 degree grids\nApproximate size: 6 GB\nDocumentation link: http:\/\/www.nodc.noaa.gov\/OC5\/WOA09\/pr_woa09.html\nWorld Ocean Atlas 2013 V2\nWorld Ocean Atlas 2013 version 2 (WOA13 V2) is a set of objectively analyzed (1 degree grid) climatological fields of in situ temperature, salinity, dissolved oxygen, Apparent Oxygen Utilization (AOU), percent oxygen saturation, phosphate, silicate, and nitrate at standard depth levels for annual, seasonal, and monthly compositing periods for the World Ocean. It also includes associated statistical fields of observed oceanographic profile data interpolated to standard depth levels on 5 degree, 1 degree, and 0.25 degree grids\nApproximate size: 57 GB\nDocumentation link: https:\/\/www.nodc.noaa.gov\/OC5\/woa13\/\nData group: Reanalysis\nNCEP-DOE Reanalysis 1 monthly averages\nThe NCEP\/NCAR Reanalysis 1 project is using a state-of-the-art analysis\/forecast system to perform data assimilation using past data from 1948 to the present. Monthly averages are calculated from the 6-hourly model output.\nApproximate size: 2 GB\nDocumentation link: https:\/\/www.esrl.noaa.gov\/psd\/data\/gridded\/data.ncep.reanalysis.html\nNCEP-DOE Reanalysis 2 monthly averages\nNCEP-DOE Reanalysis 2 is an improved version of the NCEP Reanalysis I model that fixed errors and updated paramterizations of of physical processes. Monthly averages are calculated from the 6-hourly model output.\nApproximate size: 2 GB\nDocumentation link: http:\/\/www.esrl.noaa.gov\/psd\/data\/gridded\/data.ncep.reanalysis2.html\nData group: Sea ice\nArtist AMSR-E sea ice concentration\nPassive microwave estimates of daily sea ice concentration at 6.25km spatial resolution, from 19-Jun-2002 to 2-Oct-2011.\nApproximate size: 25 GB\nDocumentation link: https:\/\/icdc.cen.uni-hamburg.de\/1\/daten\/cryosphere\/seaiceconcentration-asi-amsre.html\nArtist AMSR-E supporting files\nGrids and other support files for Artist AMSR-E passive microwave sea ice data.\nApproximate size: 0.01 GB\nDocumentation link: http:\/\/icdc.zmaw.de\/1\/daten\/cryosphere\/seaiceconcentration-asi-amsre.html\nArtist AMSR2 near-real-time 3.125km sea ice concentration\nNear-real-time passive microwave estimates of daily sea ice concentration at 3.125km spatial resolution (full Antarctic coverage).\nApproximate size: 100 GB\nDocumentation link: https:\/\/seaice.uni-bremen.de\/sea-ice-concentration\/\nArtist AMSR2 near-real-time sea ice concentration\nNear-real-time passive microwave estimates of daily sea ice concentration at 6.25km spatial resolution, from 24-July-2012 to present.\nApproximate size: 11 GB\nDocumentation link: https:\/\/seaice.uni-bremen.de\/sea-ice-concentration\/\nArtist AMSR2 supporting files\nGrids and landmasks for Artist AMSR2 passive microwave sea ice data.\nApproximate size: 0.02 GB\nDocumentation link: https:\/\/seaice.uni-bremen.de\/sea-ice-concentration\/\nCERSAT SSM\/I sea ice concentration\nPassive microwave sea ice concentration data at 12.5km resolution, 3-Dec-1991 to present\nApproximate size: 2.5 GB\nDocumentation link: http:\/\/cersat.ifremer.fr\/data\/tools-and-services\/quicklooks\/sea-ice\/ssm-i-sea-ice-concentration-maps\nCERSAT SSM\/I sea ice concentration supporting files\nGrids for the CERSAT SSM\/I sea ice concentration data.\nApproximate size: 0.01 GB\nDocumentation link: http:\/\/cersat.ifremer.fr\/data\/tools-and-services\/quicklooks\/sea-ice\/ssm-i-sea-ice-concentration-maps\nMODIS Composite Based Maps of East Antarctic Fast Ice Coverage\nMaps of East Antarctic landfast sea-ice extent, generated from approx. 250,000 1 km visible\/thermal infrared cloud-free MODIS composite imagery (augmented with AMSR-E 6.25-km sea-ice concentration composite imagery when required). Coverage from 2000-03-01 to 2008-12-31\nApproximate size: 0.4 GB\nDocumentation link: https:\/\/data.aad.gov.au\/metadata\/records\/modis_20day_fast_ice\nNational Ice Center Antarctic daily sea ice charts\nThe USNIC Daily Ice Edge product depicts the daily sea ice pack in red (8-10\/10ths or greater of sea ice), and the Marginal Ice Zone (MIZ) in yellow. The marginal ice zone is the transition between the open ocean (ice free) and pack ice. The MIZ is very dynamic and affects the air-ocean heat transport, as well as being a significant factor in navigational safety. The daily ice edge is analyzed by sea ice experts using multiple sources of near real time satellite data, derived satellite products, buoy data, weather, and analyst interpretation of current sea ice conditions. The product is a current depiction of the location of the ice edge vice a satellite derived ice edge product.\nApproximate size: not specified\nDocumentation link: http:\/\/www.natice.noaa.gov\/Main_Products.htm\nNimbus Ice Edge Points from Nimbus Visible Imagery\nThis data set (NmIcEdg2) estimates the location of the North and South Pole sea ice edges at various times during the mid to late 1960s, based on recovered Nimbus 1 (1964), Nimbus 2 (1966), and Nimbus 3 (1969) visible imagery.\nAuthentication note: Requires Earthdata login, see https:\/\/urs.earthdata.nasa.gov\/. Note that you will also need to authorize the application 'NSIDC_DATAPOOL_OPS' (see 'My Applications' at https:\/\/urs.earthdata.nasa.gov\/profile)\nApproximate size: 0.1 GB\nDocumentation link: http:\/\/nsidc.org\/data\/nmicedg2\/\nNSIDC passive microwave supporting files\nGrids and other support files for NSIDC passive microwave sea ice data.\nApproximate size: 0.1 GB\nDocumentation link: http:\/\/nsidc.org\/data\/nsidc-0051.html\nNSIDC SMMR-SSM\/I Nasateam near-real-time sea ice concentration\nNear-real-time passive microwave estimates of sea ice concentration at 25km, daily resolution. For older, quality-controlled data see the \"NSIDC SMMR-SSM\/I Nasateam sea ice concentration\" source\nApproximate size: 0.6 GB\nDocumentation link: http:\/\/nsidc.org\/data\/nsidc-0081.html\nNSIDC SMMR-SSM\/I Nasateam sea ice concentration\nPassive microwave estimates of sea ice concentration at 25km spatial resolution. Daily and monthly resolution, available from 1-Oct-1978 to present. Data undergo a quality checking process and are updated annually. More recent data if required are available via the \"NSIDC SMMR-SSM\/I Nasateam near-real-time sea ice concentration\" source.\nApproximate size: 10 GB\nDocumentation link: http:\/\/nsidc.org\/data\/nsidc-0051.html\nData group: Sea surface temperature\nGHRSST Level 4 MUR Global Foundation SST v4.1\nA Group for High Resolution Sea Surface Temperature (GHRSST) Level 4 sea surface temperature analysis produced as a retrospective dataset (four day latency) at the JPL Physical Oceanography DAAC using wavelets as basis functions in an optimal interpolation approach on a global 0.011 degree grid. The version 4 Multiscale Ultrahigh Resolution (MUR) L4 analysis is based upon nighttime GHRSST L2P skin and subskin SST observations from several instruments including the NASA Advanced Microwave Scanning Radiometer-EOS (AMSRE), the Moderate Resolution Imaging Spectroradiometer (MODIS) on the NASA Aqua and Terra platforms, the US Navy microwave WindSat radiometer and in situ SST observations from the NOAA iQuam project. The ice concentration data are from the archives at the EUMETSAT Ocean and Sea Ice Satellite Application Facility (OSI SAF) High Latitude Processing Center and are also used for an improved SST parameterization for the high-latitudes. This data set is funded by the NASA MEaSUREs program (http:\/\/earthdata.nasa.gov\/our-community\/community-data-system-programs\/measures-projects), and created by a team led by Dr. Toshio Chin from JPL.\nApproximate size: 2000 GB\nDocumentation link: https:\/\/podaac.jpl.nasa.gov\/Multi-scale_Ultra-high_Resolution_MUR-SST\nNOAA Extended Reconstructed SST V3b\nA global monthly SST analysis from 1854 to the present derived from ICOADS data with missing data filled in by statistical methods\nApproximate size: 0.3 GB\nDocumentation link: http:\/\/www.esrl.noaa.gov\/psd\/data\/gridded\/data.noaa.ersst.html\nNOAA Extended Reconstructed SST V5\nA global monthly sea surface temperature dataset derived from the International Comprehensive Ocean-Atmosphere Dataset (ICOADS)\nApproximate size: 0.3 GB\nDocumentation link: https:\/\/www.ncdc.noaa.gov\/data-access\/marineocean-data\/extended-reconstructed-sea-surface-temperature-ersst-v5\nNOAA OI 1\/4 Degree Daily SST AVHRR\nSea surface temperature at 0.25 degree daily resolution, from 1-Sep-1981 to present\nApproximate size: 140 GB\nDocumentation link: http:\/\/www.ngdc.noaa.gov\/docucomp\/page?xml=NOAA\/NESDIS\/NCDC\/Geoportal\/iso\/xml\/C00844.xml&view=getDataView&header=none\nNOAA OI SST V2\nWeekly and monthly mean and long-term monthly mean SST data, 1-degree resolution, 1981 to present. Ice concentration data are also included, which are the ice concentration values input to the SST analysis\nApproximate size: 0.9 GB\nDocumentation link: http:\/\/www.esrl.noaa.gov\/psd\/data\/gridded\/data.noaa.oisst.v2.html\nOceandata MODIS Aqua Level-3 mapped monthly 9km SST\nMonthly remote-sensing SST from the MODIS Aqua satellite at 9km spatial resolution\nApproximate size: 7 GB\nDocumentation link: http:\/\/oceancolor.gsfc.nasa.gov\/\nOceandata MODIS Terra Level-3 mapped monthly 9km SST\nMonthly remote-sensing sea surface temperature from the MODIS Terra satellite at 9km spatial resolution\nApproximate size: 7 GB\nDocumentation link: http:\/\/oceancolor.gsfc.nasa.gov\/\nData group: Topography\nBedmap2\nBedmap2 is a suite of gridded products describing surface elevation, ice-thickness and the sea floor and subglacial bed elevation of the Antarctic south of 60S.\nApproximate size: 3.3 GB\nDocumentation link: https:\/\/www.bas.ac.uk\/project\/bedmap-2\/\nCryosat-2 digital elevation model\nA New Digital Elevation Model of Antarctica derived from 6 years of continuous CryoSat-2 measurements\nApproximate size: 0.2 GB\nDocumentation link: https:\/\/doi.org\/10.5194\/tc-2017-223\nETOPO1 bathymetry\nETOPO1 is a 1 arc-minute global relief model of Earth's surface that integrates land topography and ocean bathymetry.\nApproximate size: 1.3 GB\nDocumentation link: http:\/\/www.ngdc.noaa.gov\/mgg\/global\/global.html\nETOPO2 bathymetry\n2-Minute Gridded Global Relief Data (ETOPO2v2c)\nApproximate size: 0.3 GB\nDocumentation link: http:\/\/www.ngdc.noaa.gov\/mgg\/global\/etopo2.html\nGEBCO 2019 bathymetry\nThe GEBCO_2019 Grid is the latest global bathymetric product released by the General Bathymetric Chart of the Oceans (GEBCO). The GEBCO_2019 product provides global coverage, spanning 89d 59' 52.5\"N, 179d 59' 52.5\"W to 89d 59' 52.5\"S, 179d 59' 52.5\"E on a 15 arc-second grid. It consists of 86400 rows x 43200 columns, giving 3,732,480,000 data points. The data values are pixel-centre registered i.e. they refer to elevations at the centre of grid cells.\nApproximate size: 13 GB\nDocumentation link: https:\/\/www.gebco.net\/data_and_products\/gridded_bathymetry_data\/gebco_2019\/gebco_2019_info.html\nGeorge V bathymetry\nThis dataset comprises Digital Elevation Models (DEMs) of varying resolutions for the George V and Terre Adelie continental margin, derived by incorporating all available singlebeam and multibeam point depth data.\nApproximate size: 0.2 GB\nDocumentation link: https:\/\/data.aad.gov.au\/metadata\/records\/GVdem_2008\nGeoscience Australia multibeam bathymetric grids of the Macquarie Ridge\nThis is a compilation of all the processed multibeam bathymetry data that are publicly available in Geoscience Australia's data holding for the Macquarie Ridge.\nApproximate size: 0.4 GB\nDocumentation link: https:\/\/doi.org\/10.4225\/25\/53D9B12E0F96E\nGSHHG coastline data\nA Global Self-consistent, Hierarchical, High-resolution Geography Database\nApproximate size: 0.6 GB\nDocumentation link: http:\/\/www.soest.hawaii.edu\/pwessel\/gshhg\nIBCSO bathymetry\nThe International Bathymetric Chart of the Southern Ocean (IBCSO) Version 1.0 is a new digital bathymetric model (DBM) portraying the seafloor of the circum-Antarctic waters south of 60S. IBCSO is a regional mapping project of the General Bathymetric Chart of the Oceans (GEBCO). The IBCSO Version 1.0 DBM has been compiled from all available bathymetric data collectively gathered by more than 30 institutions from 15 countries. These data include multibeam and single-beam echo soundings, digitized depths from nautical charts, regional bathymetric gridded compilations, and predicted bathymetry. Specific gridding techniques were applied to compile the DBM from the bathymetric data of different origin, spatial distribution, resolution, and quality. The IBCSO Version 1.0 DBM has a resolution of 500 x 500 m, based on a polar stereographic projection, and is publicly available together with a digital chart for printing from the project website (www.ibcso.org) and at http:\/\/dx.doi.org\/10.1594\/PANGAEA.805736.\nApproximate size: 4.3 GB\nDocumentation link: http:\/\/www.ibcso.org\/\nIBCSO chart for printing\nThe IBCSO Poster, 2013, is a polar stereographic view of the Southern Ocean displaying bathymetric contours south of 60S at a scale of 1:7,000,000. The poster size is 39.25 x 47.125 inches.\nApproximate size: 0.2 GB\nDocumentation link: http:\/\/www.ibcso.org\/\nKerguelen Plateau bathymetric grid 2010\nThis data replaces the digital elevation model (DEM) for the Kerguelen Plateau region produced in 2005 (Sexton 2005). The revised grid has been gridded at a grid pixel resolution of 0.001-arc degree (about 100 m). The new grid utilised the latest data sourced from ship-based multibeam and singlebeam echosounder surveys, and satellite remotely-sensed data. Report Reference: Beaman, R.J. and O'Brien, P.E., 2011. Kerguelen Plateau bathymetric grid, November 2010. Geoscience Australia, Record, 2011\/22, 18 pages.\nApproximate size: 0.7 GB\nDocumentation link: http:\/\/pid.geoscience.gov.au\/dataset\/ga\/71670\nNatural Earth 10m physical vector data\nNatural Earth is a public domain map dataset available at 1:10m, 1:50m, and 1:110 million scales.\nApproximate size: 0.2 GB\nDocumentation link: http:\/\/www.naturalearthdata.com\/downloads\/10m-physical-vectors\/\nNew Zealand Regional Bathymetry 2016\nThe NZ 250m gridded bathymetric data set and imagery, Mitchell et al. 2012, released 2016.\nApproximate size: 1.3 GB\nDocumentation link: https:\/\/www.niwa.co.nz\/our-science\/oceans\/bathymetry\/further-information\nRadarsat Antarctic digital elevation model V2\nThe high-resolution Radarsat Antarctic Mapping Project (RAMP) digital elevation model (DEM) combines topographic data from a variety of sources to provide consistent coverage of all of Antarctica. Version 2 improves upon the original version by incorporating new topographic data, error corrections, extended coverage, and other modifications.\nApproximate size: 5.3 GB\nDocumentation link: http:\/\/nsidc.org\/data\/nsidc-0082\nReference Elevation Model of Antarctica mosaic tiles\nThe Reference Elevation Model of Antarctica (REMA) is a high resolution, time-stamped digital surface model of Antarctica at 8-meter spatial resolution. REMA is constructed from hundreds of thousands of individual stereoscopic Digital Elevation Models (DEM) extracted from pairs of submeter (0.32 to 0.5 m) resolution DigitalGlobe satellite imagery. Version 1 of REMA includes approximately 98% of the contiguous continental landmass extending to maximum of roughly 88 degrees S. Output DEM raster files are being made available as both 'strip' files as they are output directly from SETSM that preserve the original source material temporal resolution, as well as mosaic tiles that are compiled from multiple strips that have been co-registered, blended, and feathered to reduce edge-matching artifacts.\nApproximate size: 1.2 GB\nDocumentation link: https:\/\/www.pgc.umn.edu\/data\/rema\/\nRTOPO-1 Antarctic ice shelf topography\nSub-ice shelf circulation and freezing\/melting rates in ocean general circulation models depend critically on an accurate and consistent representation of cavity geometry. The goal of this work is to compile independent regional fields into a global data set. We use the S-2004 global 1-minute bathymetry as the backbone and add an improved version of the BEDMAP topography for an area that roughly coincides with the Antarctic continental shelf. Locations of the merging line have been carefully adjusted in order to get the best out of each data set. High-resolution gridded data for upper and lower ice surface topography and cavity geometry of the Amery, Fimbul, Filchner-Ronne, Larsen C and George VI Ice Shelves, and for Pine Island Glacier have been carefully merged into the ambient ice and ocean topographies. Multibeam survey data for bathymetry in the former Larsen B cavity and the southeastern Bellingshausen Sea have been obtained from the data centers of Alfred Wegener Institute (AWI), British Antarctic Survey (BAS) and Lamont-Doherty Earth Observatory (LDEO), gridded, and again carefully merged into the existing bathymetry map.\nApproximate size: 4.1 GB\nDocumentation link: http:\/\/epic.awi.de\/30738\/\nShuttle Radar Topography Mission elevation data SRTMGL1 V3\nGlobal 1-arc-second topographic data generated from NASA's Shuttle Radar Topography Mission. Version 3.0 (aka SRTM Plus or Void Filled) removes all of the void areas by incorporating data from other sources such as the ASTER GDEM.\nAuthentication note: Requires Earthdata login, see https:\/\/urs.earthdata.nasa.gov\/\nApproximate size: 620 GB\nDocumentation link: https:\/\/lpdaac.usgs.gov\/dataset_discovery\/measures\/measures_products_table\/srtmgl1_v003\nSmith and Sandwell bathymetry\nGlobal seafloor topography from satellite altimetry and ship depth soundings\nApproximate size: 1.4 GB\nDocumentation link: http:\/\/topex.ucsd.edu\/WWW_html\/mar_topo.html\n","423":"environmental\n\n\n\n\n\n\n\n\nMap a python configuration from environment variables.\n\nOverview\nenvironmental allows you to map class properties to environment variables.\nBy using  environmental you can keep your configuration in a single class your IDE understands and have convenient\nand safe type conversions between the strings stored in your environment and python types.\nThe created properties are also writable so if you assign to them they will change on your environment and will be\navailable to your child processes.\n\nInstallation\n$ sudo pip3 install --upgrade environmental\n\nExample\nimport environmental\nimport os\n\nclass Configuration:\n    port = environmental.Int('MY_APPLICATION_HTTP_PORT', 80)\n    name = environmental.Str('MY_APPLICATION_NAME', 'Name')\n\nconfig = Configuration()\nconfig.port = 8080\nassert os.environ['MY_APPLICATION_HTTP_PORT'] == '8080'\nassert isinstance(os.environ['MY_APPLICATION_HTTP_PORT'], str)\nassert config.port == 8080\nassert isinstance(config.port, int)\n\nCaveats\nModifying mutable objects in the configuration (like lists) will not work:\nimport os, environmental\nclass Configuration:\n    list = environmental.List('LIST')\n\nos.environ['LIST'] = \"[]\"\nassert config.list == []\nconfig.list.append('test')\nassert config.list == []\nBut doing something that reassigns the variable will:\nconfig.list += ['test']\nassert config.list == ['test']\n\nLicense\nCopyright 2015 Zalando SE\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\nhttp:\/\/www.apache.org\/licenses\/LICENSE-2.0\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n","424":"environmental\nWhen I'm working in a Python virtual environment, I am too lazy to\n\nOpen a new terminal window\/tab with some hotkeys and\nType conda activate my-environment.\n\nSo I created two shell commands, window and tab.\nSupported environments\nmacOS\nI have developed and tested this tool on macOS mojave.\nThe tool is available for conda environments.\nLinux\nI have developed and tested this tool on Ubuntu 18.04 with GNOME 3.28.2.\nThe tool is available for conda and virtualenv environments.\nInstall\nInstall on macOS\n\nClone the repo.\nSet permission to run commands.\nCopy the files so that you can run the commands.\n\ngit clone https:\/\/github.com\/thebarbershop\/environmental.git\nsudo chmod +x environmental\/mac\/conda\/*\nsudo cp environmental\/mac\/conda\/* \/usr\/local\/bin\/\nNow you may delete the downloaded files, if you don't want to keep them around.\nrm -r environmental\/\nThe script emulates \u2318 Command+N and \u2318 Command+T to open a new window\/terminal. You have to fix line 8 of each script, if you use a different combination of keys.\nInstall on Linux\nTo use this tool, you need to install the three extra tools, xdotool, xclip, and wmctrl.\nsudo apt install xdotool xclip wmctrl\nThen,\n\nClone the repo.\nSet permission to run commands.\nCopy the files so that you can run the commands.\n\ngit clone https:\/\/github.com\/thebarbershop\/environmental.git\nsudo chmod +x environmental\/linux\/conda\/*\nsudo cp environmental\/linux\/conda\/* \/usr\/local\/bin\/\nIf you use virtualenv instead of conda, replace the path accordingly for the last two commands.\nNow you may delete the downloaded files, if you don't want to keep them around.\nrm -r environmental\/\nThe script emulates Control+Shift+N and Control+Shift+T to open a new window\/terminal. You have to fix line 10 of window and line 11 of tab, if you use a different combination of keys.\nHow to use\nwindow\nTo open a new terminal window with the same environment at the same directory,\n(my-environment) current-directory $ window\ntab\nTo open a new terminal tab with the same environment at the same directory,\n(my-environment) current-directory $ tab\nLicense\nThis software is Unlicenced. Do whatever you want with it, and I am not liable for any consequences. For more, read LICENSE.\nNote\nI don't have any plan to import this tool for any other OS or environment manager than the ones I am using. (But I may someday, whenever I feel like it.)\nSo feel free to fork and modify to fit your own system. I would deeply appreciate if you send me a pull request with your addition.\n","425":"environmental\nWhen I'm working in a Python virtual environment, I am too lazy to\n\nOpen a new terminal window\/tab with some hotkeys and\nType conda activate my-environment.\n\nSo I created two shell commands, window and tab.\nSupported environments\nmacOS\nI have developed and tested this tool on macOS mojave.\nThe tool is available for conda environments.\nLinux\nI have developed and tested this tool on Ubuntu 18.04 with GNOME 3.28.2.\nThe tool is available for conda and virtualenv environments.\nInstall\nInstall on macOS\n\nClone the repo.\nSet permission to run commands.\nCopy the files so that you can run the commands.\n\ngit clone https:\/\/github.com\/thebarbershop\/environmental.git\nsudo chmod +x environmental\/mac\/conda\/*\nsudo cp environmental\/mac\/conda\/* \/usr\/local\/bin\/\nNow you may delete the downloaded files, if you don't want to keep them around.\nrm -r environmental\/\nThe script emulates \u2318 Command+N and \u2318 Command+T to open a new window\/terminal. You have to fix line 8 of each script, if you use a different combination of keys.\nInstall on Linux\nTo use this tool, you need to install the three extra tools, xdotool, xclip, and wmctrl.\nsudo apt install xdotool xclip wmctrl\nThen,\n\nClone the repo.\nSet permission to run commands.\nCopy the files so that you can run the commands.\n\ngit clone https:\/\/github.com\/thebarbershop\/environmental.git\nsudo chmod +x environmental\/linux\/conda\/*\nsudo cp environmental\/linux\/conda\/* \/usr\/local\/bin\/\nIf you use virtualenv instead of conda, replace the path accordingly for the last two commands.\nNow you may delete the downloaded files, if you don't want to keep them around.\nrm -r environmental\/\nThe script emulates Control+Shift+N and Control+Shift+T to open a new window\/terminal. You have to fix line 10 of window and line 11 of tab, if you use a different combination of keys.\nHow to use\nwindow\nTo open a new terminal window with the same environment at the same directory,\n(my-environment) current-directory $ window\ntab\nTo open a new terminal tab with the same environment at the same directory,\n(my-environment) current-directory $ tab\nLicense\nThis software is Unlicenced. Do whatever you want with it, and I am not liable for any consequences. For more, read LICENSE.\nNote\nI don't have any plan to import this tool for any other OS or environment manager than the ones I am using. (But I may someday, whenever I feel like it.)\nSo feel free to fork and modify to fit your own system. I would deeply appreciate if you send me a pull request with your addition.\n","426":"README\nThis README would normally document whatever steps are necessary to get the\napplication up and running.\nThings you may want to cover:\n\n\nRuby version\n\n\nSystem dependencies\n\n\nConfiguration\n\n\nDatabase creation\n\n\nDatabase initialization\n\n\nHow to run the test suite\n\n\nServices (job queues, cache servers, search engines, etc.)\n\n\nDeployment instructions\n\n\n...\n\n\n","427":"Environmental features recognition for lower limb prostheses toward predictive walking\n\nWe present a robust environmental features recognition system (EFRS) for lower limb prosthesis,\nwhich can assist the control of prosthesis by predicting locomotion modes of amputees and estimating environmental features in the following steps. A depth sensor and an inertial measurement unit (IMU) are combined to stabilize\nthe point cloud of environments. Subsequently, the 2D point cloud is extracted from origin 3D point cloud and is classified through a neural network. Environmental features, including slope of road, width,\nand height of stair, were also estimated via the 2D point cloud. Finally, EFRS is evaluated through classifying and recognizing five kinds of common environments in simulation, indoor experiments and outdoor\nexperiments by six healthy subjects and three transfemoral amputees, and databases of five healthy subjects and\nthree amputees are used to validate without training. The classification accuracy of five kinds of common environments reach up to 99.3% and 98.5% for the amputees in the indoor and outdoor experiments, respectively. The locomotion modes are predicted at least 0.6 s before the switch of actual locomotion modes. Most estimation errors\nof indoor and outdoor environments features are lower than 5% and 10%, respectively. The overall process of EFRS takes less than 0.023 s. The promising results demonstrate the robustness and the potential application of the presented EFRS to help control of lower limb prostheses.\nThis repository includes 2D binary image dataset and a CNN model based on Keras.  You can test and train the model directly by running the file: classification.py.\nRun\npython classification.py\nI just uploaded the environmental classification algorithm because I think it should be the most useful part. If you want me to upload the image preprocessing and environmental parameter estimation part, please leave a message in the issue or send an email to me directly.\nContact\nFor more related works and codes, please view my homepage: https:\/\/sites.google.com\/view\/kuangenzhang\nFurther information please contact Kuangen Zhang (kuangen.zhang@alumni.ubc.ca).\nCitation\nIf you find our work useful in your research, please consider citing:\n@article{zhang_environmental_2019,\n\ttitle = {Environmental features recognition for lower limb prostheses toward predictive walking},\n\tvolume = {27},\n\tissn = {1534-4320},\n\tnumber = {3},\n\tjournal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},\n\tauthor = {Zhang, K. and Xiong, C. and Zhang, W. and Liu, H. and Lai, D. and Rong, Y. and Fu, C.},\n\tmonth = mar,\n\tyear = {2019}\n}\nLicense\nMIT License\n","428":"enviRonmental\nInterface to the creation, saving and loading of R environments\n","429":"shinystan_test\nshinystan tests\n","430":"various installation instructions\n","431":"Smart Windows\n\n\n\n\nAbout\nSmart Windows is a proof of concept IoT system that detects environmental information about windows and allows you to control them.\nThis project was developed Brandon Ye, Evan Kilburn, Callum Kippin, Marc Kevin Quijalvo, Jimmy Lu, and Steven Wen at the 2020 L-Spark Secure IoT Hackathon, and was awarded the Solace Prize for Best Overall Implementation of Secure IoT Dev Kit. It features a web application, web server, and API to connect to IoT hardware that can gather data from real world surroundings.\nTech Stack\n\nReact\nNode.js\nFlask\nRaspberry Pi\nPrecipitation sensor\n\nLearn More\nhttps:\/\/www.queensu.ca\/partnershipsandinnovation\/first-queens-hosted-secure-iot-hackathon-all-around-success\nhttps:\/\/yebrandon.com\/#projects\n","432":"\ncccharts\n\nOverview\ncccharts is an R package to plot climate change indicator data for\nBritish Columbia. It is essentially a wrapper on top of ggplot2 code.\nThe package was developed and used to generate supporting data\nvisualizations for a set of climate change indicators published on\nEnvironmental Reporting BC\nin 2017.\nInstallation\nThe package is not available on CRAN, but can be installed from GitHub\nusing the devtools package:\n# install.packages(\"devtools\")\ndevtools::install_github(\"bcgov\/cccharts\")\n\nFeatures\nThree Plot Types\ncccharts produces three types of plots:\n\nColor-coded point (or bar chart) estimates with upper and lower\nconfidence intervals (if available) (plot_estimates).\nColor-coded maps of B.C. with the estimates for Ecoprovinces or\nStations (map_estimates).\nRaw data with estimated trend lines (plot_fit).\n\nExamples of the three types of plots are presented below.\nTo get more information on the arguments that a function takes type for\nexample ?plot_estimates.\nPNG Files and ggplot Objects\nThe three base functions return ggplot objects which can be modified\nprior to plotting. The higher level wrappers plot_estimates_pngs,\nmap_estimates_pngs etc automatically save the plots to png files in a\nsubdirectory of the folder cccharts in the working directory. They\nalso return a list of the ggplot objects in case the users wishes to\nmanipulate them further.\nColor Scheme\nThe default color scheme is a diverging BrBG Brewer\npalette. The\nuser can override the color scheme for the plot_estimates or\nmap_estimates functions by setting the low, mid, and high\narguments. To switch to a sequential color scheme simply set mid = NULL. To make all points the same color (and suppress a color legend)\nsimply set low and high at the same value.\nData\nccchartspulls climate change indicator data from the BC Data\nCatalogue.\nThe source data sets are licensed under the Open Government License -\nBritish\nColumbia.\nType data() to see the available datasets or for example type ?snow\nfor more information on the snow data.\nUsage\nlibrary(cccharts)\n#> Loading required package: ggplot2\nplot_estimates(data = cccharts::sea_surface_temperature_station, x = \"Season\", facet = \"Station\")\n\nmap_estimates(data = cccharts::sea_level_station, station = TRUE, bounds = c(0.1,0.7,0,0.55))\n#> Warning in seq.default(.limits[1], .limits[2], length = guide$nbin):\n#> partial argument match of 'length' to 'length.out'\n\nplot_fit(data = dplyr::filter(cccharts::flow_station_discharge, Term == \"Medium\", Statistic == \"Mean\", Season == \"Annual\"), observed = cccharts::flow_station_discharge_observed, free_y = TRUE, facet = \"Station\")\n\nTo generate the plot files (creates a folder in the working directory\ncalled cccharts).\nlibrary(cccharts)\ndemo(\"cccharts\", ask = FALSE)\n\nGetting Help or Reporting an Issue\nTo report bugs\/issues\/feature requests, please file an\nissue.\nHow to Contribute\nIf you would like to contribute to the package, please see our\nCONTRIBUTING guidelines.\nPlease note that this project is released with a Contributor Code of\nConduct. By participating in this project you agree\nto abide by its terms.\nLicense\nCopyright 2016 Province of British Columbia\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at \n\n   http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nThis repository is maintained by Environmental Reporting\nBC.\nClick here for a complete list\nof our repositories on GitHub.\n","433":"\ncccharts\n\nOverview\ncccharts is an R package to plot climate change indicator data for\nBritish Columbia. It is essentially a wrapper on top of ggplot2 code.\nThe package was developed and used to generate supporting data\nvisualizations for a set of climate change indicators published on\nEnvironmental Reporting BC\nin 2017.\nInstallation\nThe package is not available on CRAN, but can be installed from GitHub\nusing the devtools package:\n# install.packages(\"devtools\")\ndevtools::install_github(\"bcgov\/cccharts\")\n\nFeatures\nThree Plot Types\ncccharts produces three types of plots:\n\nColor-coded point (or bar chart) estimates with upper and lower\nconfidence intervals (if available) (plot_estimates).\nColor-coded maps of B.C. with the estimates for Ecoprovinces or\nStations (map_estimates).\nRaw data with estimated trend lines (plot_fit).\n\nExamples of the three types of plots are presented below.\nTo get more information on the arguments that a function takes type for\nexample ?plot_estimates.\nPNG Files and ggplot Objects\nThe three base functions return ggplot objects which can be modified\nprior to plotting. The higher level wrappers plot_estimates_pngs,\nmap_estimates_pngs etc automatically save the plots to png files in a\nsubdirectory of the folder cccharts in the working directory. They\nalso return a list of the ggplot objects in case the users wishes to\nmanipulate them further.\nColor Scheme\nThe default color scheme is a diverging BrBG Brewer\npalette. The\nuser can override the color scheme for the plot_estimates or\nmap_estimates functions by setting the low, mid, and high\narguments. To switch to a sequential color scheme simply set mid = NULL. To make all points the same color (and suppress a color legend)\nsimply set low and high at the same value.\nData\nccchartspulls climate change indicator data from the BC Data\nCatalogue.\nThe source data sets are licensed under the Open Government License -\nBritish\nColumbia.\nType data() to see the available datasets or for example type ?snow\nfor more information on the snow data.\nUsage\nlibrary(cccharts)\n#> Loading required package: ggplot2\nplot_estimates(data = cccharts::sea_surface_temperature_station, x = \"Season\", facet = \"Station\")\n\nmap_estimates(data = cccharts::sea_level_station, station = TRUE, bounds = c(0.1,0.7,0,0.55))\n#> Warning in seq.default(.limits[1], .limits[2], length = guide$nbin):\n#> partial argument match of 'length' to 'length.out'\n\nplot_fit(data = dplyr::filter(cccharts::flow_station_discharge, Term == \"Medium\", Statistic == \"Mean\", Season == \"Annual\"), observed = cccharts::flow_station_discharge_observed, free_y = TRUE, facet = \"Station\")\n\nTo generate the plot files (creates a folder in the working directory\ncalled cccharts).\nlibrary(cccharts)\ndemo(\"cccharts\", ask = FALSE)\n\nGetting Help or Reporting an Issue\nTo report bugs\/issues\/feature requests, please file an\nissue.\nHow to Contribute\nIf you would like to contribute to the package, please see our\nCONTRIBUTING guidelines.\nPlease note that this project is released with a Contributor Code of\nConduct. By participating in this project you agree\nto abide by its terms.\nLicense\nCopyright 2016 Province of British Columbia\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at \n\n   http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nThis repository is maintained by Environmental Reporting\nBC.\nClick here for a complete list\nof our repositories on GitHub.\n","434":"Environmental\nBootstrap a (web) development environment on Linux, macOS, or Windows+WSL\nIt's opinionated in that it's maintained solely for myself based on what I'm\nneeding at the moment. But, it's broken up into bits, and doesn't trample on\nconfiguration. So, anyone with similar needs might find something of use.\n","435":"\nStatus of Ground-Level Ozone in B.C.\nA set of R scripts to calculate the Canadian Ambient Air Quality Standards (CAAQS) for  Ground-Level Ozone for British Columbia. These scripts reproduce the analysis and data visualizations supporting the Status of Ground-Level Ozone in B.C. indicator presented on Environmental Reporting BC.\nThis analysis makes use of the rcaaqs package, and verified air quality monitoring data from the B.C. Ministry of Environment.\nUsage\nThere are four core scripts that are required for the analysis, they need to be run in order:\n\n01_load.R - downloads the data from DataBC\n02_clean.R - cleans and prepares data for analysis\n03_analysis.R - performs the analysis\n04_output.R - creates maps and graphs and saves outputs\n\nThe run_all.R script can be sourceed to run it all at once.\nMost packages used in the analysis can be installed from CRAN using install.packages(), but you will need to install envreportutils and rcaaqs using remotes:\ninstall.packages(\"remotes\") # If you don't already have it installed\n\nlibrary(remotes)\ninstall_github(\"bcgov\/rcaaqs\")\ninstall_github(\"bcgov\/envreportutils\")\nGetting Help or Reporting an Issue\nTo report bugs\/issues\/feature requests, please file an issue.\nHow to Contribute\nIf you would like to contribute, please see our CONTRIBUTING guidelines.\nPlease note that this project is released with a Contributor Code of Conduct. By participating in this project you agree to abide by its terms.\nLicense\nCopyright 2015 Province of British Columbia\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at \n\n   http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nThis repository is maintained by Environmental Reporting BC. Click here for a complete list of our repositories on GitHub.\n","436":"dotfiles\nSetup\nexport PATH=\/opt\/local\/bin:$PATH\ngit clone https:\/\/github.com\/bahamat\/dotfiles\/ .dotfiles\ncd .dotfiles\n.\/setup\nsource ~\/.zshrc\n\nEnvironmental Control\nRequires the following git repositories to be checked out in the same parent\ndirectory as dotfiles.\ngit clone https:\/\/github.com\/bling\/vim-airline.git\ngit clone https:\/\/github.com\/tpope\/vim-fugitive.git\ngit clone https:\/\/github.com\/elzr\/vim-json.git\ngit clone https:\/\/github.com\/plasticboy\/vim-markdown.git\ngit clone https:\/\/github.com\/vim-scripts\/Cfengine-version-3-syntax\ngit clone https:\/\/github.com\/altercation\/solarized.git\n\nLicensing\nEach file in this repository is individually licensed. Unless otherwise specified\nall files are Copyright 2002-2018 Brian Bennett with all rights reserved.\nI release all right, title and interest (if I ever had any) of  machine files\n(including symlinks and the .git directory).\nCopyright 2018 Brian Bennett\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\nhttp:\/\/www.apache.org\/licenses\/LICENSE-2.0\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n","437":"environmental\nA simple java program that spits out the environment variables\n","438":"custom_efdc\nCustomized Environmental Fluid Dynamics Code\n","439":"Single and Multi-Label Environmental Sound Classification Using Convolutional Neural Networks\nA master thesis project by Santiago \u00c1lvarez-Buylla Puente, carried out at Chalmers University of Technology between January and June 2018, for the Sound and Vibration MSc.\nContent of the repository\nIn the repository, four Jupyter notebooks can be found:\n\nDataset_processing.ipynb\nDataset_processing_Multilabel.ipynb\nAudio_Classification_Softmax_mine_260318.ipynb\nAudio_Classification_Multilabel_mine_170518.ipynb\n\nAnd three Python modules:\n\nsantiago_data_preprocessing.py\nsantiago_my_modules_v3_160418.py\nsantiago_my_modules_v3_17_05_18_Multilabel.py\n\nIn the two first Jupyter notebooks, the processing of the dataset is performed and explained, both for the single and the multi-label classification tasks. These two files make use of the Python module santiago_data_preprocessing.py\nThe two following Jupyter notebooks are the notebooks where the two models are implemented, making use of the two Python modules santiago_my_modules_v3_160418.py and santiago_my_modules_v3_17_05_18_Multilabel.py\nHope you find it useful.\nAny suggestion is always welcomed!\n","440":"serverless-environmental-monitor\nAn environmental monitor built with AWS and the Arduino MKR ENV SHIELD sensor board.\n\nArduino device sends data to IoT Core, and from there the data is placed into DynamoDB. A react app in an S3 bucket is then used to view the data, which is retrieved from DynamoDB using Lambda.\n","441":"Welcome\nThis is a repository to share and develop code. Please read the collaboration documentation and how to use Github.\n","442":"Welcome\nThis is a repository to share and develop code. Please read the collaboration documentation and how to use Github.\n","443":"\u57fa\u7840\u5f00\u53d1\nDescription\n{When you're done, you can delete the content in this README and update the file with details for others getting started with your repository}\nSoftware Architecture\nSoftware architecture description\nInstallation\n\nxxxx\nxxxx\nxxxx\n\nInstructions\n\nxxxx\nxxxx\nxxxx\n\nContribution\n\nFork the repository\nCreate Feat_xxx branch\nCommit your code\nCreate Pull Request\n\nGitee Feature\n\nYou can use Readme_XXX.md to support different languages, such as Readme_en.md, Readme_zh.md\nGitee blog blog.gitee.com\nExplore open source project https:\/\/gitee.com\/explore\nThe most valuable open source project GVP\nThe manual of Gitee https:\/\/gitee.com\/help\nThe most popular members  https:\/\/gitee.com\/gitee-stars\/\n\n","444":"environmental-codefest-api\napi for our codefest app\nSetting Up\nIn order to get everything set up, run\n$ make install\n\nThis will install all requirements and initialize the database\nHow To Run\nTo start serving the api, run\n$ make run\n\nYou can then navigate to http:\/\/127.0.0.1:5000\/ to view the documentation\n","445":"\nGEMET\n\n\n\n\nContents\n\nGEMET\nProject Name\nPrerequisites - System packages\nDebian based systems\nRHEL based systems\n\n\nProduct directory\nInstall dependencies\nBuild production\nBuild staging\nConfiguration\nData Import\nOther commands\nDocumentation\nDocs contents\n\n\n\n\nDevelopment hints\nRequirements\nConfigure deploy\nRunning unit tests\n\n\nSentry settings\nContacts\nResources\nHardware\nSoftware\n\n\nCopyright and license\n\n\n\nProject Name\nThe Project Name is GEMET - GEneral Multilingual Environmental Thesaurus\nhttp:\/\/www.eionet.europa.eu\/gemet\n\nPrerequisites - System packages\nThese packages should be installed as superuser (root).\n\nDebian based systems\nInstall these before setting up an environment:\napt-get install python-setuptools python-dev libmysqlclient-dev \\\nlibldap2-dev python-virtualenv mysql-server git\n\n\nRHEL based systems\nInstall Python2.7 with PUIAS: https:\/\/gist.github.com\/nico4\/9616638\nRun these commands:\ncurl https:\/\/raw.github.com\/pypa\/pip\/master\/contrib\/get-pip.py | python2.7 -\npip2.7 install virtualenv\nyum install mysql-server mysql git mysql-devel\n\n\nProduct directory\nCreate the product directory:\nmkdir -p \/var\/local\/gemet\nmkdir \/var\/local\/gemet\/logs\n\nCreate a new user:\nadduser edw\n\nChange the product directory's owner:\nchown edw:edw \/var\/local\/gemet -R\n\n\nInstall dependencies\nWe should use Virtualenv for isolated environments. The following commands will\nbe run as an unprivileged user in the product directory:\n\nClone the repository:\ngit clone https:\/\/github.com\/eea\/gemet -o origin gemet\ncd gemet\n\n\n\n2.1. Create & activate a virtual environment:\nvirtualenv --no-site-packages sandbox\necho '*' > sandbox\/.gitignore\nsource sandbox\/bin\/activate\n\n2.2 Make sure setuptools >= 0.8 is installed:\npip install -U setuptools\n\n\nInstall dependencies:\npip install -r requirements-dep.txt\n\n\nCreate a local configuration file:\ncd gemet\ncp local_settings.py.example local_settings.py\n\n# Follow instructions in local_settings.py to adapt it to your needs.\n\n\n\n\nSet up the MySQL database:\n# Replace [user] and [password] with your MySQL credentials and [db_name]\n# with the name of the database:\n\nmysql -u[user] -p[password] -e 'create database [db_name] CHARACTER SET utf8 COLLATE utf8_general_ci;'\n\nThe database charset MUST be utf8.\n\nUpdate local configuration file with database credentials and database name\n\ndefault section in DATABASES dict.\n\n\nCreate initial database structure:\n.\/manage.py migrate\n\n\nLoad fixtures data into the database:\n.\/manage.py loaddata gemet\/thesaurus\/fixtures\/data.json\n\n\nGenerate EIONET static templates:\n.\/manage.py fetchtemplates\n\n\nImport data, see Data Import below.\n\n\n\nBuild production\nSetup production environment using an unprivileged user:\ncd \/var\/local\/gemet\nsource sandbox\/bin\/activate\n\nChange the local_settings.py file by setting debug mode off:\nDEBUG = False\nALLOWED_HOSTS = ['localhost']  # Add allowed hosts to the list as needed\n\nConfigure supervisord and set the WSGI server port:\ncp gemet\/supervisord.conf.example supervisord.conf\nsupervisorctl reload 1>\/dev\/null || .\/bin\/supervisord\n\n\nBuild staging\nSetup staging environment using an unprivileged user:\ncd \/var\/local\/gemet\nsource sandbox\/bin\/activate\n\nChange the local_settings.py file by setting debug mode off:\nDEBUG = False\nALLOWED_HOSTS = ['localhost']  # Add allowed hosts to the list as needed\n\nConfigure supervisord and set the WSGI server port (a different one from the\nproduction, for example 8010):\ncp gemet\/supervisord.conf.example supervisord.conf\nsupervisorctl reload 1>\/dev\/null || .\/bin\/supervisord\n\n\nConfiguration\nDetails about configurable settings can be found in settings.py.\n\nData Import\n1. Considering you have a dump of the old database (gemet.sql), import it in a\nseparate database:\nmysql -u[user] -p[password] -e 'create database [db_name] CHARACTER SET utf8 COLLATE utf8_general_ci;'\nmysql -u[user] -p[password] [db_name] < gemet.sql\n\n2. Update the import section from DATABASES dict in the local\nconfiguration file with the name of the database used for import\n(gemet_old from the previous example).\n\nRun the management command for data import:\n.\/manage.py import\n\n\nFix romanian characters:\n.\/manage.py fix_romanian\n\n\nInsert data that enables search to work properly:\n.\/manage.py insertdata\n\n\nCreate reversed relations for all concepts:\n.\/manage.py fixrelations\n\n\nImport new terms from the spreadsheet:\n.\/manage.py importspreadsheet [spread_sheet_name]\n\n\n\n\nOther commands\n1. Some romanian terms, definitions etc. are written with the wrong diacritical marks (cedillas instead of commas).\nThe following custom management command fixes those characters and prints the number of objects changed:\n.\/manage.py fix_romanian\n\n\nCheck the consistency of an excel file (.xlsx extension) containing new terms.\n\nThe custom command assures:\n\nOld terms used in the file are defined in the database.\nNew terms used in broader, narrow relations etc. of other terms are also defined in the file.\nAn error containing the cell of the term is printed if it does not respect those rules.\n\nRun the command providing a valid excel file:\n.\/manage.py check_spreadsheet file_name.xlsx\n\n\nDocumentation\nThe documentation has been created using Sphinx. The source directories for the three sections of documentation can be found in the docs directory.\nIn order to get the HTML output, you should run the following command inside one of the documentation directories (api, new_api or overview):\nmake html\n\nThese static HTML files can be served via a web server (Apache, Nginx, etc).\n\nDocs contents\n\napi - old version of the API user guide, kept for reference;\nnew_api - current documentation for the GEMET API; duplicated in this file and published on Web services page;\noverview - quick overview of the technical solution;\n\n\nDevelopment hints\n\nRequirements\nThese packages should be installed as superuser(root):\napt-get install libxml2-dev libxslt1-dev\n\nUse requirements-dev.txt instead of requirements-dep.txt:\npip install -r requirements-dev.txt\n\n\nConfigure deploy\n\ncopy fabfile\/env.ini.example to fabfile\/env.ini\nconfigure staging and production settings\nrun fab staging deploy or fab production deploy\n\n\nRunning unit tests\n0. Before running the tests make sure you have configured the test database\nparameters:\ncd gemet\/\ncp test_settings.py.example test_settings.py\n\n# Parameters values should match the ones used for the 'default' database\n# entry in local_settings.py\n\n\nFor the GEMET web application:\n.\/manage.py test\n\n\nFor the API:\npython apitests\/main.py\n\n\n\nTwo optional parameters exist:\n\n--public, which runs the tests against the production website;\n--get, which calls the API methods through GET requests.\n\n\nRunning tests with coverage measurement\n\nAdd to your local_settings.py TEST_RUNNER and NOSE_ARGS from\nlocal_settings.example and run:\n.\/manage.py test\n\n\nSentry settings\nSentry is used to track errors in real-time.\nCreate an account and a project on Sentry .\nInstall the proper version of raven used by sentry:\npip install -r requirements-dep.txt\n\nConfigure local settings with your project's dsn.\n\nContacts\nThe project owner is S\u00f8ren Roug (soren.roug at eaa.europa.eu)\nOther people involved in this project are:\n\nIulia Chiriac (iulia.chiriac at eaudeweb.ro)\nAndrei Melis (andrei.melis at eaudeweb.ro)\nDiana Boiangiu (diana.boiangiu at eaudeweb.ro)\nCornel Ni\u021bu (cornel.nitu at eaudeweb.ro)\nAlex Eftimie (alex.eftimie at eaudeweb.ro)\nMihai Tab\u0103r\u0103 (mihai.tabara at eaudeweb.ro)\nMihai Zamfir (mihai.zamfir at eaudeweb.ro)\n\n\nResources\n\nHardware\n\nMinimum requirements:\n\n2048MB RAM\n2 CPU 1.8GHz or faster\n4GB hard disk space\n\n\nRecommended:\n\n4096MB RAM\n4 CPU 2.4GHz or faster\n8GB hard disk space\n\n\n\n\nSoftware\nAny recent Linux version, apache2, MySQL server, Python 2.7\n\nCopyright and license\nThis project is free software; you can redistribute it and\/or modify it under\nthe terms of the EUPL v1.1.\nMore details under LICENSE.txt.\n","446":"SEEM\n\nSpatial Evaluation of Environmental Models\n\nKeywords:\n\nSpatial Patterns\nModel Evaluation\nRemote Sensing\nSpatial Statistics\nHuman Perception\nVisual Comparison\n\n\nThis repository contains methodologies that can be incorporated as spatial performance metrics to evaluate spatial model output. Simulated patterns are compared with reference patterns (e.g. remote sensing observations) and the spatial performance is quantified by a skill score.\n14\/06\/2016\nThe EOF example is up and running. Detailed documentation will be added. In the meantime please check Koch et al. (2015) in the documentation folder for reference.\n23\/06\/2016\nThe Connectivity analysis example is up and running. Detailed documentation will be added. The first example focus on the illustration of the methodology where the connectivity analysis is applied on a single map comparison. The second example applies the connectivity analysis on a series of maps and gives a similarity score for each timestep. Here the connectivity is assessed individually for the high and the low phase. In the meantime please check Koch et al. (2016) in the documentation folder for reference.\n22\/07\/2016\nBased on Koch et al. (2015), located in the literature folder, we have uploaded the 12 synthetic land-surface-temperature maps and the corresponding reference map. The 12 maps are perturbation from the reference map and a detailed description of the perturbations strategies can be found in the paper. A web-based survey of the human perception was set up (https:\/\/kwiksurveys.com\/s.asp?sid=05a50l3t1jb4eyp326466#\/) to employ the well trained human perception to rate the pattern similarity between the 12 maps and the reference. Data is located under the \"HumanPerceptionSurvey_I\" folder and the file ranking.txt contains the final results for each map; a value of 1 indicates complete similarity. The ranking can be utilized to evaluate spatial performance in their ability to mimic the human perception.\n29\/07\/2016\nThe Fractions Skill Score (FSS) analysis has been added to the repository. The code follows the description by Roberts and Lean (2008). The first example FSS_example_single_day computes and plots FSS for various scales and percentile thresholds at a single day. The second example calculates FSS at critical pairs of threshold and scale for every year in a one year period. The calculation is limited to specified pairs in order to reduce computational time.\n22\/02\/2017\nWe have uploaded the data obtained from our zooniverse project Pattern Perception (https:\/\/www.zooniverse.org\/projects\/jukoch\/pattern-perception\/home). The data is placed in the folder \"HumanPerceptionSurvey_II\". For each variable, the maps are made available as .mat files, where the four dimensions refer to X, Y, nday, nscenario. nscenario=1 refers to the baseline map which is used as reference. The resulting similarity scores for the six scenarios (nscenario=2-7) states the spatial similarity of that respective scenario to the baseline given for each of the 365 days.\nWork in progress!!\n","447":"SEEM\n\nSpatial Evaluation of Environmental Models\n\nKeywords:\n\nSpatial Patterns\nModel Evaluation\nRemote Sensing\nSpatial Statistics\nHuman Perception\nVisual Comparison\n\n\nThis repository contains methodologies that can be incorporated as spatial performance metrics to evaluate spatial model output. Simulated patterns are compared with reference patterns (e.g. remote sensing observations) and the spatial performance is quantified by a skill score.\n14\/06\/2016\nThe EOF example is up and running. Detailed documentation will be added. In the meantime please check Koch et al. (2015) in the documentation folder for reference.\n23\/06\/2016\nThe Connectivity analysis example is up and running. Detailed documentation will be added. The first example focus on the illustration of the methodology where the connectivity analysis is applied on a single map comparison. The second example applies the connectivity analysis on a series of maps and gives a similarity score for each timestep. Here the connectivity is assessed individually for the high and the low phase. In the meantime please check Koch et al. (2016) in the documentation folder for reference.\n22\/07\/2016\nBased on Koch et al. (2015), located in the literature folder, we have uploaded the 12 synthetic land-surface-temperature maps and the corresponding reference map. The 12 maps are perturbation from the reference map and a detailed description of the perturbations strategies can be found in the paper. A web-based survey of the human perception was set up (https:\/\/kwiksurveys.com\/s.asp?sid=05a50l3t1jb4eyp326466#\/) to employ the well trained human perception to rate the pattern similarity between the 12 maps and the reference. Data is located under the \"HumanPerceptionSurvey_I\" folder and the file ranking.txt contains the final results for each map; a value of 1 indicates complete similarity. The ranking can be utilized to evaluate spatial performance in their ability to mimic the human perception.\n29\/07\/2016\nThe Fractions Skill Score (FSS) analysis has been added to the repository. The code follows the description by Roberts and Lean (2008). The first example FSS_example_single_day computes and plots FSS for various scales and percentile thresholds at a single day. The second example calculates FSS at critical pairs of threshold and scale for every year in a one year period. The calculation is limited to specified pairs in order to reduce computational time.\n22\/02\/2017\nWe have uploaded the data obtained from our zooniverse project Pattern Perception (https:\/\/www.zooniverse.org\/projects\/jukoch\/pattern-perception\/home). The data is placed in the folder \"HumanPerceptionSurvey_II\". For each variable, the maps are made available as .mat files, where the four dimensions refer to X, Y, nday, nscenario. nscenario=1 refers to the baseline map which is used as reference. The resulting similarity scores for the six scenarios (nscenario=2-7) states the spatial similarity of that respective scenario to the baseline given for each of the 365 days.\nWork in progress!!\n","448":"\nEIS Document Database Search\nThis app makes an archive of the EPA's Environmental Impact Statements (EIS) searchable, linking results back to EIS documents on epa.gov\nTry the EIS Search Tool (demo): https:\/\/eis-search.herokuapp.com\nNotes\n\nThe current version of the web app is configured to make requests as the user types, but does not have any auto-complete functionality, so you may have zero results showing up when you are halfway through typing a given word.\nThe database currently used by this tool is a non-updating snapshot of records found on the EPA's EIS Database\n\nFuture Enhancements\n\n pagination (currently you only access the first 10 results in the gui--though the remainder can currently be accessed via the api)\n adding facets to the search index (to help filter results on axes like date range and specific metadata fields such as the geography for which the document is relevant\n better text-pre-processing and tokenization tuning\n improved document mappings to include more relevant metadata fields and with appropriate weighting\n add more info to search page\n\nFor Developers\nTools used\n\nThe app is written in go\nThe search index is built with bleve (similar to a light-weight elasticsearch and written in golang) using metadata extracted from every reachable EIS url (including text extracted with OCR from attached\/associated PDFs)\n\nDeveloper setup\n\nInstall Go, (make sure your GOPATH ends up in the right PATH profile)\n\nTo run locally (without cloning):\n\nInstall this repo's dependencies with go get github.com\/edgi-govdata-archiving\/eis-search, (run this from any directory)\ncd into $HOME\/go\/bin and run .\/eis-search\nServer is running at http:\/\/localhost:8094 (or other port as specified in command line output)\n\nTo clone & run:\n\nClone this repo into your go directory (typically $HOME\/go\/src)\nFrom inside that cloned directory, go build. This should make a file called eis-search\nRun: .\/eis-search\nServer is running at http:\/\/localhost:8094 (or other port as specified in command line output)\n\nLicense & Copyright\nCopyright (C) 2019 Environmental Data and Governance Initiative (EDGI)\nThis program is free software: you can redistribute it and\/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, version 3.0.\nThis program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\nSee the LICENSE file for details.\n","449":"\nEIS Document Database Search\nThis app makes an archive of the EPA's Environmental Impact Statements (EIS) searchable, linking results back to EIS documents on epa.gov\nTry the EIS Search Tool (demo): https:\/\/eis-search.herokuapp.com\nNotes\n\nThe current version of the web app is configured to make requests as the user types, but does not have any auto-complete functionality, so you may have zero results showing up when you are halfway through typing a given word.\nThe database currently used by this tool is a non-updating snapshot of records found on the EPA's EIS Database\n\nFuture Enhancements\n\n pagination (currently you only access the first 10 results in the gui--though the remainder can currently be accessed via the api)\n adding facets to the search index (to help filter results on axes like date range and specific metadata fields such as the geography for which the document is relevant\n better text-pre-processing and tokenization tuning\n improved document mappings to include more relevant metadata fields and with appropriate weighting\n add more info to search page\n\nFor Developers\nTools used\n\nThe app is written in go\nThe search index is built with bleve (similar to a light-weight elasticsearch and written in golang) using metadata extracted from every reachable EIS url (including text extracted with OCR from attached\/associated PDFs)\n\nDeveloper setup\n\nInstall Go, (make sure your GOPATH ends up in the right PATH profile)\n\nTo run locally (without cloning):\n\nInstall this repo's dependencies with go get github.com\/edgi-govdata-archiving\/eis-search, (run this from any directory)\ncd into $HOME\/go\/bin and run .\/eis-search\nServer is running at http:\/\/localhost:8094 (or other port as specified in command line output)\n\nTo clone & run:\n\nClone this repo into your go directory (typically $HOME\/go\/src)\nFrom inside that cloned directory, go build. This should make a file called eis-search\nRun: .\/eis-search\nServer is running at http:\/\/localhost:8094 (or other port as specified in command line output)\n\nLicense & Copyright\nCopyright (C) 2019 Environmental Data and Governance Initiative (EDGI)\nThis program is free software: you can redistribute it and\/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, version 3.0.\nThis program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\nSee the LICENSE file for details.\n","450":"Principle-Component-Pursuit\nPCP for environmental health \/ epidemiology.\n","451":"environmental_mega_robotic_systems\nSoftware for controlling mega robotic systems to deal with environmental problems - such as excess CO2 (pre-alpha)\nWhy build Environmental Mega Robotic Systems\nBlog posts:\n\n2017-06-12 Constraints on Self Replicating Robots to Solve Climate Change\n\n","452":"Haenfling_et_al_2016\nData processing workflow and supplementary data for Haenfling et al. 2016 - Environmental DNA metabarcoding of lake fish communities reflects long-term data from established survey methods. Molecular Ecology. DOI: 10.1111\/mec.13660.\nRelease 1.0 of this repository has been archived: \n##Contents\n\nSupplementary data:\nreference sequences (curated reference databases) used in analyses in Genbank format (here)\nadapter sequences used for 12S fragment (here)\nSRA accession numbers for raw Illumina data (here)\nPer sample read counts (here)\nTaxonomic assignment results (here)\nR scripts used to produce the figures in the paper (here)\nInstructions on how to set up all dependencies for data processing\/analyses\nData processing workflow as Jupyter notebooks\n\n##Introduction\nTo facilitate full reproducibility of our analyses we provide Jupyter notebooks illustrating our workflow and all necessary supplementary data in this repository.\nIllumina data was processed (from raw reads to taxonomic assignments) using the metaBEAT pipeline (version 0.8). The pipeline relies on a range of open bioinformatics tools, which we have wrapped up in a self contained docker image which includes all necessary dependencies here.\n##Setting up the environment\nIn order to retrieve supplementary data (reference sequences etc.) start by cloning this repository to your current directory:\ngit clone --recursive https:\/\/github.com\/HullUni-bioinformatics\/Haenfling_et_al_2016.git\n\nIn order to make use of our self contained analysis environment you will have to install Docker on your computer. Docker is compatible with all major operating systems. See the Docker documenation for details. On Ubuntu installing Docker should be as easy as:\nsudo apt-get install docker.io\n\nOnce Docker is installed you can enter the environment by typing, e.g.:\ndocker run -i -t --net=host --name metaBEAT -v $(pwd):\/home\/working chrishah\/metabeat:v0.8 \/bin\/bash\n\nThis will download the metaBEAT v0.8 image (if it's not yet present on your computer) and enter the 'container', i.e. the self contained environment (Note that sudo may be necessary in some cases). With the above command the container's directory \/home\/working will be mounted to your current working directory (as instructed by $(pwd)), in other words, anything you do in the container's \/home\/working directory will be synced with your current working directory on your local machine.\n##Data processing workflow\nRaw illumina data has been deposited with Genbank (BioProject: PRJNA313432; BioSample accessions: SAMN04530423-SAMN04530510; SRA accessions: SRR3359939-SRR3360124) - see sample specific accessions here. Before following the workflow below, you'll need to download the raw reads from SRA. To download the raw read data you can follow the steps in this notebook.\nWith the data in place you should be able to fully rerun\/reproduce our analyses by following the steps outlined in the Jupyter notebooks that we provide for the 12S and CytB datasets.\nThe workflow illustrated in the notebooks assumes that the raw Illumina data is present in a directory raw_reads at the base of the repository structure and that the files are named according to the following convention:\n'sampleID-marker', followed by '_1' or '_2' to identify the forward\/reverse read file respectively. sampleID must corresponds to the first column in the file Sample_accessions.tsv here, marker is either '12S' or 'CytB'.\n","453":"\n  \nOverview\nThe goal of manager is to provide a set of tools to simplify plotting and analyzing environmental data that is in a tidy format. Manager also provides functions to read data from external sources such as MANAGES and gINT.\nExample\nlibrary(manager)\n\n# reading data from external sources\ndata <- read_manages3(\"C:\/path\/to\/Site.mdb\")\n# load example data and plot time series of selected wells and constituents\ndata(\"gw_data\")\n\nwells <- c(\"MW-1\", \"MW-2\")\n\nparams <- c(\"Magnesium, dissolved\", \n            \"Sodium, dissolved\", \n            \"Chloride, total\", \n            \"Sulfate, total\", \n            \"Potassium, dissolved\")\n\ngw_data %>%\n  filter(location_id %in% wells, param_name %in% params) %>%\n  ts_plot(., facet_var = \"param_name\", group_var = \"location_id\")\n\n# create boxplots filled by gradient\ngw_data %>%\n  filter(param_name == \"Chloride, total\", \n         location_id %in% c(\"MW-1\", \"MW-2\", \"MW-3\", \"MW-4\", \"MW-5\", \"MW-6\", \"MW-7\", \"MW-8\")) %>%\n  mutate(gradient = if_else(location_id %in% wells, \"upgradient\", \"downgradient\")) %>% \n  boxplot(., fill = \"gradient\")\n\nPiper Diagrams and more...\ngw_data %>%\n  piper_plot()\n\nInstallation\nTo install the manager package you must first make sure you have a working development environment.\n\nWindows: Install Rtools.\nMac: Install Xcode from the Mac App Store.\nLinux: Install a compiler and various development libraries (details vary across differnet flavors of Linux).\n\nThen, install the devtools package from CRAN with\ninstall.packages(\"devtools\")\nAfter you have devtools installed you can install manager using the command\ndevtools::install_github(\"jentjr\/manager\")\nEventually, the package might be submitted to CRAN, but until then you'll have to install with devtools.\nShiny App\nA shiny app is included with the package. It can be launched locally by running manager::manager(), or you can browse to the shinyapps.io website for manager. In order to read a MANAGES, or gINT database you must be running a local server with RODBC installed. R must either be in 32-bit, or 64-bit mode depending on which drivers are installed for microsoft access. MANAGER has only been tested in 32-bit mode.\n","454":"PHP dotenv\nA .env file parsing and loading library for PHP.\nAutomatically loads variables into a number of contexts:\n\ngetenv() (default)\n$_ENV (default)\n$_SERVER (default)\napache_getenv (optional)\nPHP constants (optional)\nGlobal variables (optional)\nA custom config array (optional)\n\nWhy?\nYou should never store sensitive credentials in your code. Storing configuration in the environment is one of the tenets of a twelve-factor app. Anything that is likely to change between deployment environments \u2013 such as database credentials or credentials for 3rd party services \u2013 should be extracted from the code into environment variables.\nRequirements\n\nPHP 5.4\n\nInstallation\nUsing Composer, run composer require wpscholar\/phpdotenv.\nMake sure you have a line in your code to handle autoloading:\n<?php\n\nrequire __DIR__ . '\/vendor\/autoload.php';\nUsage\nCreate a new loader and use any of the available methods to help customize your configuration:\n<?php\n\n$loader = new wpscholar\\phpdotenv\\Loader(); \/\/ Can also do wpscholar\\phpdotenv\\Loader::create() \n$loader\n    ->config([ \/\/ Must be used to customize adapters, can also be used to set defaults or required variables.\n        'adapters' => [\n            'apache',   \/\/ Uses apache_setenv() \n            'array',    \/\/ Uses a custom array\n            'define',   \/\/ Uses define() to set PHP constants\n            'env',      \/\/ Uses $_ENV\n            'global',   \/\/ Sets global variables\n            'putenv',   \/\/ Uses putenv()\n            'server'    \/\/ Uses $_SERVER\n        ], \n        'defaults' => [\n            'foo' => 'bar' \/\/ Set a default value if not provided in .env  \t\n        ],\n        'required' => [\n            'bar', \/\/ Require that a variable be defined in the .env file. Throws an exception if not defined.\n            'baz',\n        ],\n    ])\n    ->required([ \/\/ Another way to define required variables\n        'bar',\n        'baz',\n        'quux',    \t\n    ])\n    ->setDefaults([ \/\/ Another way to set defaults\n        'foo' => 'bar',\t\n    ])\n    ->parse([ __DIR__ . '\/.env', dirname( __DIR__ ) . '\/.env' ]) \/\/ Array of file paths to check for a .env file. Parses found file and loads vars into memory.\n    ->set( 'qux', $loader->get('foo') ); \/\/ Override variables after loading, but with access to existing variables before they are loaded into the environment.\n    \n\/\/ Validate variable values after parsing the .env file, but before loading the results into the environment.\n$loader->validate('foo')->notEmpty();\n$loader->validate('bar')->isBoolean();\n$loader->validate('baz')->isInteger();\n$loader->validate('qux')->notEmpty()->allowedValues( [ 'bar', 'baz' ] ); \/\/ Validations can be chained together.\n$loader->validate('quux')->assert(function( $value ) { \/\/ Apply your own custom validation assertions.\n    return is_int($value) && $value > 0 && $value <= 10;\t\n});\n\n\/\/ Call load() to load variables into the environment without overwriting existing variables.\n$loader->load();\n\n\/\/ Call overload() to load variables into the environment, overwriting any existing variables.\n$loader->overload();\nIt is possible to create multiple instances of the loader, each loading a different .env file and loading variables into different contexts.\nCustom Configuration Array Example Usage\n<?php\n\n$loader = wpscholar\\phpdotenv\\Loader::create();\n$loader\n    ->config([ 'adapters' => 'array'] ) \/\/ All values are self-contained in an array within the loader.\n    ->required([ 'bar', 'baz', 'quux', ])\n    ->setDefaults([ 'foo' => 'bar' ])\n    ->parse( __DIR__ . '\/.env' )\n    ->set( 'qux', $loader->get('foo') )\n    ->load();\n\n$config = $loader->all(); \/\/ Get an array containing the final values.\n\n$bar = $loader->get('bar'); \/\/ Get a single value.\nWordPress wp-config.php Example Usage\n<?php\n\nrequire __DIR__ . '\/vendor\/autoload.php';\n\nuse wpscholar\\phpdotenv\\Loader;\n\n$loader = new Loader();\n$loader\n\t->config( [ 'adapters' => 'define' ] ) \/\/ Will only set PHP constants\n\t->required( [ \/\/ Requires these be set in the .env file\n\t\t'DB_NAME',\n\t\t'DB_USER',\n\t\t'DB_PASSWORD',\n\t] )\n\t->setDefaults( [ \/\/ Defaults to use if not defined in .env file\n\t\t'ABSPATH'         => __DIR__ . '\/wp',\n\t\t'DB_CHARSET'      => 'utf8',\n\t\t'DB_COLLATE'      => '',\n\t\t'DB_HOST'         => 'localhost',\n\t\t'WP_DEBUG'        => false,\n\t\t'WP_TABLE_PREFIX' => 'wp_',\n\t] )\n\t->parse( __DIR__ . '\/.env' ) \/\/ Parse the .env file\n\t->set( 'WP_HOME', 'https:\/\/' . $_SERVER['HTTP_HOST'] )\n\t->set( 'WP_SITEURL', $loader->get( 'WP_HOME' ) . '\/wp' ) \/\/ Use previously defined values to set other values.\n\t->set( 'WP_CONTENT_DIR', __DIR__ . '\/content' )\n\t->set( 'WP_CONTENT_URL', $loader->get( 'WP_HOME' ) . '\/content' )\n\t->set( 'DISALLOW_FILE_EDIT', true )\n\t->load(); \/\/ We could use overload() here, but we can't overwrite constants in PHP either way.\n\n$table_prefix = WP_TABLE_PREFIX;\n\nrequire_once( ABSPATH . 'wp-settings.php' );\nCreating a .env File\nSample .env file for the wp-config.php example:\nDB_NAME=local\nDB_USER=root\nDB_PASSWORD=root\nWP_DEBUG=true\nSCRIPT_DEBUG=true\nExplore all the features of the .env file parser.\nRules to Follow\nWhen using phpdotenv, you should strive to follow these rules:\n\nAdd your .env file to a .gitignore file to prevent sensitive data from being committed to the project repository.\nUse a .env.example to set a default configuration for your project. This allows your development team to override defaults in a method that works for their local environment.\nAlways set sane defaults when possible.\nWhere necessary, add comments to credentials with information as to what they are, how they are used, and how one might procure new ones.\nAs phpdotenv uses more lax procedures for defining environment variables, ensure your .env files are compatible with your shell. A good way to test this is to run the following:\n\n# Source in your .env file\nsource .env\n# Check an environmental variable\nfoo\n\nWhen possible, avoid running phpdotenv in production settings. Instead, set environment variables in your webserver, process manager or in bash before your app loads.\n\n","455":"\nWifi and Bluetooth environmental sensors built with ESP32 dev boards.\nThese firmwares are providing both a WiFi web inteface and a documented BLE API to use with WatchFlower.\nThey use standard libraries and are easy to customize to your own needs.\nProjects\nHiGrow\nCustom firmware for HiGrow ESP32 boards. Check it out!\n\nGeiger Counter\nESP32 board with a \"CAJOE\" Geiger Counter module. Check it out!\n\nAir Quality Monitor\nESP32 board with a handful of sensors for air quality monitoring. Check it out!\nGet involved!\nDevelopers\nYou can browse the code on the GitHub page, submit patches and pull requests! Your help would be greatly appreciated ;-)\nUsers\nYou can help us find and report bugs, suggest new features, help with translation, documentation and more! Visit the Issues section of the GitHub page to start!\n","456":"\nWifi and Bluetooth environmental sensors built with ESP32 dev boards.\nThese firmwares are providing both a WiFi web inteface and a documented BLE API to use with WatchFlower.\nThey use standard libraries and are easy to customize to your own needs.\nProjects\nHiGrow\nCustom firmware for HiGrow ESP32 boards. Check it out!\n\nGeiger Counter\nESP32 board with a \"CAJOE\" Geiger Counter module. Check it out!\n\nAir Quality Monitor\nESP32 board with a handful of sensors for air quality monitoring. Check it out!\nGet involved!\nDevelopers\nYou can browse the code on the GitHub page, submit patches and pull requests! Your help would be greatly appreciated ;-)\nUsers\nYou can help us find and report bugs, suggest new features, help with translation, documentation and more! Visit the Issues section of the GitHub page to start!\n","457":"Environmental\nEnvironmental quickly build\n\u4f18\u79c0\u7684\u7a0b\u5e8f\u5458\u4e0d\u4ec5\u4ec5\u53ea\u662f\u4f7f\u7528\u5de5\u5177\n","458":"Mapping Environmental Action\nThis code is associated with a scholarly paper \"Mapping Environmental Action\" (currently unpublished). In the paper, I draw on original data gathered from my research with Eco-groups in Scotland (2013-2017) in order to do comparative geospatial analysis of the coincidence of these groups with a number of standard demographics. You can read (an unpublished version of) the paper at (http:\/\/mapenvcom.jeremykidwell.info\/mapping_draft.html).\nWhy Reproducible Research?\nIf you're new to github and reproducible research, welcome! It's nice to have you here. Github is ordinarily a place where software developers working on open source software projects deposit their code as they write software collaboratively. However, in recent years a number of scholarly researchers, especially people working on research that involves a digital component (including me!) have begun to deposit their papers in these same software repositories. The idea is that you can download all of the source-code and data used in this paper alongside the actual text, run it yourself and \"reproduce\" the results. This can serve as a useful safeguard, a layer of research transparency, and a cool teaching tool for other persons interested in doing similar work. Particularly when, as is the case in subject areas that are only just starting to get involved in the digital humanities, like religious studies, there is a dearth of work of this nature, it can be helpful to have examples of practice which can be reused, or at least used as an example.\nEschewing proprietary, expensive and unreliable software like Microsoft Word, I write in a combination of two languages: (1) Markdown which is intended to be as close as possible to plain text while still allowing for things like boldfaced type, headings and footnotes; and (2) a programming language called R to do all the data analysis. R is an object oriented language that was specifically designed for statistical analysis. It's also great fun to tinker with. As you look through this paper, you'll see that R code is integrated into the text of the document. This is indicated by a series of three backticks (```). There is a formal specification now at a mature stage of development, which is RMarkdown. You can read semi-official specification for this here.\nTo read a bit more on these things and start on your own path towards plain text reproducible research, I highly recommend:\n\nKarl Broman's guide, \"Initial Steps Toward Reproducible Research\"\nKieran Healy's guide, \"The Plain Person\u2019s Guide to Plain Text Social Science\"\n\nThe other advantage of putting this paper here is that readers and reviewers can suggest changes and point out errors in the document. To do this, I recommend that you create a github issue by clicking on the green \"New issue\" button here. If you must, you can also send me emails. More stuff about me can be found here.\nTo skip ahead and start reading the actual paper in raw format, click on mapping_draft.rmd above. If you were looking for the article (without code) you can also find a working draft here: (http:\/\/mapenvcom.jeremykidwell.info\/mapping_draft.html).\nNow for...\nThe technical version\nThis repository contains the code and writing towards a (working draft of a) scholarly paper that presents my analysis of the geospatial footprint of eco-groups in the UK. This is based on research I have been conducting since 2013 and that is ongoing. The paper is written in R Markdown and for the most part, I'm using the conventions outlined by Kieran Healy here and is best viewed (I think) in R Studio though it will be reasonably comprehensible to anyone using a Markdown editor. If I'm not working in RStudio, I'm probably in Sublime text, FYI. Co-authors and collaborators take note, generally, I use Hadley Wickham's venerable R Style Guide.\nI'd be extremely happy if someone found errors, or imagined a more efficient means of analysis and either reported them as an issue on this github repository or sent me an email.\nThe actual article is in mapping_draft.Rmd and can be compiled using knitr (assuming you have R installed as well as required packages) using the Makefile provided.\nNote: actual execution may take over an hour, as calls to st_buffer and st_within under wilderness_data_prep are computationally intensive. To compile more briskly, I recommend you comment out this final section and knit the markdown\/html files. I have been relying on the University of Birmingham supercomputing cluster for execution, which has resulted in a parallel version of this script mapping_draft-hpc_optimised.Rmd. The latter will only run on the BlueBEAR cluster at UOB, though other scholars may want to consult this script to get a sense of how geospatial operations can be parallelised for more efficient execution.\nPaths in this folder are used mostly for R processing. I'm using a \"project\" oriented workflow, on which you can read more in a blog by Jenny Bryan here. This uses the R package here.\nTowards this end folders have the following significance:\n\ndata contains datasets used for analysis.\nderived_data contains files which represent modified forms of files in the above path.\nfigures contains images and visualisations (graphic files) which are generated by R for the final form of the document.\ncache isn't included in github but is usually used for working files\n\nNote: none of the contents of the above are included in the github repository unless they are unavailable from an external repository.\nAnd, a few notes for the data scientists\nOver the course of this research project (since 2013, really), the state of geospatial tools for datascience in R (and python) has shifted and the increased attention and resources that have been brought to bear on geospatial has resulted in a dramatic improvement in the quality and precision of tools available, particularly the development of SimpleFeatures and the sf and tmap packages for R. Ggplot2 is awesome, but starts to creak quickly when you push it in more creative geospatial directions. There are also inefficiencies with data handling in some of the older packages (such as sp) that aren't apparent until you start working with large datasets. Underlying data formats have been shifting quite a lot as well, from csvt and very problematic and proprietary ESRI shapefiles to geojson\/topojson and Geopackage formats. The result of this has a need to completely rewrite this script mid-way through the research process. I've left some of the messy bits in with as comprehensive comments as possible to give a sense of things, but there remain some bits which are accidentally messy.\nThere are a few aspects of this code which are novel or were difficult that I'm proud of, which I hope may be useful and on ehich I'd especially value\n\nThe use of sf() and tmap()\nThe creation of vignettes for visualisations\nThe level of reproducibility\nOptimisation of intensive geospatial operations for htpc and parallel computing\n\nPrerequisites for reproducing this codebase\nI've tried to follow best practices in setting up this script for reproducibility, but given some of the choices I've had to make computationally (e.g. running some operations in PostGIS) some setup is required before execution will be successful.\nThese steps are:\n\nAcquire a working installation of R (and RStudio). I have produced a Docker container that replicates the environment I have used to execute this script that is probably the easiest way to complete this task.\nSet up a working Postgres database with PostGIS extensions installed. The script will download necessary data and load it into your database if it is not already in place.\nInstall platform appropriate prerequisites for the R odbc() package, see here: [https:\/\/github.com\/r-dbi\/odbc#installation]\nConfigure a local config.yml file with the following information (used to connect to your PostGIS database):\n\ndefault:\n  datawarehouse:\n    driver: 'Postgres' \n    server: 'change.to.yourserver.com'\n    uid: 'change-to-your-username'\n    pwd: 'change-to-your-password'  \n    port: 5432\n    database: 'database-name'\n\n\nClone or download the code from this repository\nSet up a proper R\/RStudio working environment. I use the renv package to manage working environment, which takes snapshots and stores them to renv.lock. If you run renv::restore() in R after loading this code, it will install necessary libraries at proper versions.\nNearly all of the data used in this study is open, with one exception, that of the Ordnance Survey PointX data product. This is available to most UK academics via the EDINA service, so the user will need to manually download this data and place it in the \/data\/ directory.\n\nContributing\nPlease note that this project is released with a Contributor Code of Conduct. By contributing to this project, you agree to abide by its terms.\nLicense\nThe content of this research paper are licensed under the Creative Commons Attribution-ShareAlike 4.0 International Public License, and the underlying source code used to generate the paper is licensed under the GNU AGPLv3 license. Underlying datasets designed as part of this research have their own licenses that are specified in their respective repositories.\n","459":"osd-environmental-data\nScope\nA repository for creating and maintaining environmental data layers for OSD analysis.\nPlease note, this repository only links to or hosts contextual data sets in their rawest form. That is, no manipulations other than those that are absolutely needed for workability are performed and only when needed. Code and\/or documentation related to these manipulations will be recorded here. Please see this repository for information and code related to downstream analysis steps.\nThe Wiki\nDescriptions of the contextual data sets gathered for OSD will be present on this repository's wiki. Please read about the data sets' properties and any assumptions used (e.g. for satellite data or calculated geographic distances).\nCode\nTo be added.\nIssues\nIf you'd like to see what's in our TODO queue check out our issue tracker. You're free to create issues or add comments whereever you feel you can contribute! You'll need a GitHub account to do this, register for one here.\n","460":"\n\n\nMersea\nRequirements\n\nRuby MRI 2.5.x (rbenv recommended)\nBundler\nRails 5.x\nPostgres 9.5+ configuration file\nImageMagick(for thumbnails)\n\nSetup\nrbenv install\ngem install bundler\nDevelopment\nClone repository.\n# Install and configure db\n$ bundle install\n$ bundle exec rails db:create\n$ bundle exec rails db:migrate\n\n# Add static pages\n$ bundle exec rails db:seed\n\n# Launch app\n$ bundle exec rails s\nIncrease inotify watchers.\nReCaptcha is disabled in development. Configure key if needed using RECAPTCHA_SECRET_KEY and RECAPTCHA_SITE_KEY.\nCreate an admin account\nWithin a Rails console:\nbundle exec rails console\nAdmin.create(name: 'myname', email: 'myemail@email.local', password: 'mypassword')\nAdmin section is reachable at \/admin.\nFrontend\nTo setup frontend, see readme in .\/frontend.\nProduction with Docker\nConfigure your reCaptcha keys as environment variables\n\nStart server via Docker Compose\n\n$ cd \/path\/to\/mersea\n$ docker-compose up -d\n\nFeel free to modifies the provided docker-compose.yml to your needs.\n\nhttp:\/\/localhost:3000\n\nStart a Rails console\n\n# mersea_mersea_1 is the container name defined by docker-compose\n$ docker exec -it mersea_mersea_1 bundle exec rails c\nTo set any environment variable in the container, use one or more -e flags:\n\nJWT_SECRET \u2192 the JWT secret\nMERSEA_NAMESPACE \u2192 namespace the url\nRAILS_SERVE_STATIC_FILES \u2192 the webapp serves all the assets instead of NGINX\nMERSEA_DATABASE_POOL \u2192 database connection pool size\nMERSEA_DATABASE_HOST \u2192 database host (IP address or URL)\nMERSEA_DATABASE_PORT \u2192 database port (by default 5432)\nMERSEA_DATABASE_USERNAME \u2192 database credential\nMERSEA_DATABASE_PASSWORD \u2192 database credential\nRECAPTCHA_SITE_KEY \u2192 Google reCaptcha key\nRECAPTCHA_SECRET_KEY \u2192 Google reCaptcha secret\nBUGSNAG_API_KEY \u2192 Bugsnag key (leave empty to disable error reporting)\n\nLicense\nMIT. See the LICENSE for more details.\nAbout\n\nFor more information about the project checkout the about and information section on oceanplastictracker.com\n\nContributing\n\nFork it\nCreate your feature branch (git checkout -b my-new-feature)\nCommit your changes (git commit -am 'Add some feature')\nEnsure specs and Rubocop pass\nPush to the branch (git push origin my-new-feature)\nCreate new Pull Request\n\nSpecial thanks\nWe would like to thanks the following companies for their open source plans and support\n\n\n\n\n\n\n\n\n\n\nThanks to Bugsnag we can monitor and investigate errors on our application\n\n\n\nThank you to Mapbox for their mapping services and tools\n\n\n\nThank you to BrowserStack for their testing platform. It allows us to seamlessly test our web application on different devices and browser\n\n\n\nThanks to Circleci we can build efficient ci\/cd pipelines\n\n\n\nThanks to all the open source tools we are using to make our application (gemfile, package.json)\n","461":"emitter\nBase module for Brighter Planet's emitters. See the Brighter Planet developer page for details on Brighter Planet's development environment.\nInstallation\n$ gem install emitter\n\nUsage\n# my_emitter.rb\nrequire 'emitter'\n\nclass MyEmitter\n  include BrighterPlanet::Emitter\nend\n\nRequired modules\nYour emitter must define some modules under lib\/my_emitter\/, they are:\n\nlib\/my_emitter\/impact_model.rb - module MyEmitter::ImpactModel - defines the Leap decisions that calculate an impact.\nlib\/my_emitter\/characterization.rb - module MyEmitter::Characterization - defines the Characteristics that describe the model's inputs.\nlib\/my_emitter\/data.rb - module MyEmitter::Data - defines the schema definitions for the emitter and DataMiner processes that fetch and store data for the emitter.\nlib\/my_emitter\/relationships.rb - module MyEmitter::Relationships - defines the ActiveRecord relationships between the emitter and other Earth models.\nlib\/my_emitter\/summarization.rb - moduel MyEmitter::Summarization - defines phrases that describe various attributes (SummaryJudgement descriptors) about an emitter that are displayed on CM1's methodology pages.\n\nTools\nYou can use the bp gem to generate the skeleton for a new emitter.\nMagic\nEmitter, once included, will perform a couple tasks automatically:\n\nIt converts committees into characterizations that are not already characterized.\nIt adds auto_upgrade! and run_data_miner_on_parent_associations! tasks to DataMiner so that a call to MyEmitter.run_data_miner! will update the emitter's schema and run DataMiner tasks on any belongs_to associations.\n\nNote on Patches\/Pull Requests\n\nFork the project.\nMake your feature addition or bug fix.\nAdd tests for it. This is important so I don't break it in a\nfuture version unintentionally.\nCommit, do not mess with rakefile, version, or history.\n(if you want to have your own version, that is fine but bump version in a commit by itself I can ignore when I pull)\nSend me a pull request. Bonus points for topic branches.\n\nCopyright\nCopyright 2010, 2011 Brighter Planet, Inc. See LICENSE and LICENSE-PREAMBLE for details.\n","462":"emitter\nBase module for Brighter Planet's emitters. See the Brighter Planet developer page for details on Brighter Planet's development environment.\nInstallation\n$ gem install emitter\n\nUsage\n# my_emitter.rb\nrequire 'emitter'\n\nclass MyEmitter\n  include BrighterPlanet::Emitter\nend\n\nRequired modules\nYour emitter must define some modules under lib\/my_emitter\/, they are:\n\nlib\/my_emitter\/impact_model.rb - module MyEmitter::ImpactModel - defines the Leap decisions that calculate an impact.\nlib\/my_emitter\/characterization.rb - module MyEmitter::Characterization - defines the Characteristics that describe the model's inputs.\nlib\/my_emitter\/data.rb - module MyEmitter::Data - defines the schema definitions for the emitter and DataMiner processes that fetch and store data for the emitter.\nlib\/my_emitter\/relationships.rb - module MyEmitter::Relationships - defines the ActiveRecord relationships between the emitter and other Earth models.\nlib\/my_emitter\/summarization.rb - moduel MyEmitter::Summarization - defines phrases that describe various attributes (SummaryJudgement descriptors) about an emitter that are displayed on CM1's methodology pages.\n\nTools\nYou can use the bp gem to generate the skeleton for a new emitter.\nMagic\nEmitter, once included, will perform a couple tasks automatically:\n\nIt converts committees into characterizations that are not already characterized.\nIt adds auto_upgrade! and run_data_miner_on_parent_associations! tasks to DataMiner so that a call to MyEmitter.run_data_miner! will update the emitter's schema and run DataMiner tasks on any belongs_to associations.\n\nNote on Patches\/Pull Requests\n\nFork the project.\nMake your feature addition or bug fix.\nAdd tests for it. This is important so I don't break it in a\nfuture version unintentionally.\nCommit, do not mess with rakefile, version, or history.\n(if you want to have your own version, that is fine but bump version in a commit by itself I can ignore when I pull)\nSend me a pull request. Bonus points for topic branches.\n\nCopyright\nCopyright 2010, 2011 Brighter Planet, Inc. See LICENSE and LICENSE-PREAMBLE for details.\n","463":"AppConfiguration\n\n\n\n\nAppConfiguration is a very simple gem that helps you configure your Ruby applications. AppConfiguration uses YAML config files or environmental variales to set\nthe configuration parameters.\nInstallation\nAdd this line to your application's Gemfile:\ngem 'app_configuration'\n\nAnd then execute:\n$ bundle\n\nOr install it yourself as:\n$ gem install app_configuration\n\nUsage\nAppConfiguration comes with great default values. So if you want to setup a new config all you need to do is\nconfig = AppConfiguration.new\nmy_configurable_variable = config.foo\nmy_other_variable = config['bar']\nBy default, when getting the variable foo AppConfiguration will look for the environmental variable FOO.\nIf it cannot find it, AppConfiguration will look for the .config.yml file in the current working directory.\nIf there is no config file there, it will try to find the .config.yml in your home directory.\nA possible .config.yml for this example could look like this\nfoo: 'This is the foo variable'\nbar: 'This is the bar variable'\nCustomize your configuration\nAppConfiguration can be customized to fit your needs. Here is an example\nconfig = AppConfiguration.new('.setup.yml') do\n  base_local_path '\/usr\/local'\n  base_global_path '\/config'\n  use_env_variables true\n  prefix 'my_app'\nend\nYou can set the configuration file name by passing the name to the new method or you can use the config_file_name\nmethod inside the configuration block.\n\nconfig_file_name Sets the name of the config file. Default .config.yml.\nbase_local_path Sets the base path for the local configuration file. If there is no config file in this path it will\nlook in the global configuration path. Default .\/\nbase_global_path Sets the base path for the global configuration file. Default ~\/\nuse_env_variables Flag that activates the use of enviromental variable. Default true\nprefix A prefix to be appended when looking for environmental variables. For example if prefix is set to my_app,\nwhen the foo variable is fetched, the MY_APP_FOO environmental variable will be checked.\nThis is used to avoid name collitions. Default nil\n\nVariable lookup\nYou can retrieve a variable from a AppConfiguration::Config object by doing\nfoo = config.foo\nfoo = config['foo']\nEnvironmental variables will be checked first, adding the necesary prefix if provided. If there is no environmental\nvariable, the local config file will be checked. If there is no local file or a value has not been defined for\nthe given variable, the global config file will be checked. Otherwise it returns nil.\nConfiguration registry\nIf you create a new config object by using AppConfiguration.new, then you must keep the reference to this configuration.\nInstead you can registers a configuration by using AppConfiguration.for. Then you can obtain a configuration by using\nAppConfiguration[]. For example\nAppConfiguration.for :github\n# ... Then somewhere else ...\ngithub = AppConfiguration[:github]\ngithub.api_key\nIn the previous example the name of the configuration file is assumed to be .github.yml and all the environmental variables\nwill be prefixed with GITHUB_. You can change this behaviour by passing a configuration block to the for method.\nFor example if you want to change the local path you can register the configuration as follows\nAppConfiguration.for :github do\n  base_local_path Rails.root\nend\nDefault values\nTo change the default local path and the default global path for all the AppConfiguration::Config objects all you\nneed to do is\nAppConfiguration::Config.default_local_path = Rails.root\nAppConfiguration::Config.default_global_path = '\/usr\/configs'\nContributing\n\nFork it\nCreate your feature branch (git checkout -b my-new-feature)\nCommit your changes (git commit -am 'Add some feature')\nPush to the branch (git push origin my-new-feature)\nCreate new Pull Request\n\nPlease add specs for all new features. If you find a bug and an spec probing that the bug exists and in a separate commit\nadd the bug fix.\nLicense\nCopyright (c) 2013 Guido Marucci Blas\nMIT License\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and\/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n","464":"AppConfiguration\n\n\n\n\nAppConfiguration is a very simple gem that helps you configure your Ruby applications. AppConfiguration uses YAML config files or environmental variales to set\nthe configuration parameters.\nInstallation\nAdd this line to your application's Gemfile:\ngem 'app_configuration'\n\nAnd then execute:\n$ bundle\n\nOr install it yourself as:\n$ gem install app_configuration\n\nUsage\nAppConfiguration comes with great default values. So if you want to setup a new config all you need to do is\nconfig = AppConfiguration.new\nmy_configurable_variable = config.foo\nmy_other_variable = config['bar']\nBy default, when getting the variable foo AppConfiguration will look for the environmental variable FOO.\nIf it cannot find it, AppConfiguration will look for the .config.yml file in the current working directory.\nIf there is no config file there, it will try to find the .config.yml in your home directory.\nA possible .config.yml for this example could look like this\nfoo: 'This is the foo variable'\nbar: 'This is the bar variable'\nCustomize your configuration\nAppConfiguration can be customized to fit your needs. Here is an example\nconfig = AppConfiguration.new('.setup.yml') do\n  base_local_path '\/usr\/local'\n  base_global_path '\/config'\n  use_env_variables true\n  prefix 'my_app'\nend\nYou can set the configuration file name by passing the name to the new method or you can use the config_file_name\nmethod inside the configuration block.\n\nconfig_file_name Sets the name of the config file. Default .config.yml.\nbase_local_path Sets the base path for the local configuration file. If there is no config file in this path it will\nlook in the global configuration path. Default .\/\nbase_global_path Sets the base path for the global configuration file. Default ~\/\nuse_env_variables Flag that activates the use of enviromental variable. Default true\nprefix A prefix to be appended when looking for environmental variables. For example if prefix is set to my_app,\nwhen the foo variable is fetched, the MY_APP_FOO environmental variable will be checked.\nThis is used to avoid name collitions. Default nil\n\nVariable lookup\nYou can retrieve a variable from a AppConfiguration::Config object by doing\nfoo = config.foo\nfoo = config['foo']\nEnvironmental variables will be checked first, adding the necesary prefix if provided. If there is no environmental\nvariable, the local config file will be checked. If there is no local file or a value has not been defined for\nthe given variable, the global config file will be checked. Otherwise it returns nil.\nConfiguration registry\nIf you create a new config object by using AppConfiguration.new, then you must keep the reference to this configuration.\nInstead you can registers a configuration by using AppConfiguration.for. Then you can obtain a configuration by using\nAppConfiguration[]. For example\nAppConfiguration.for :github\n# ... Then somewhere else ...\ngithub = AppConfiguration[:github]\ngithub.api_key\nIn the previous example the name of the configuration file is assumed to be .github.yml and all the environmental variables\nwill be prefixed with GITHUB_. You can change this behaviour by passing a configuration block to the for method.\nFor example if you want to change the local path you can register the configuration as follows\nAppConfiguration.for :github do\n  base_local_path Rails.root\nend\nDefault values\nTo change the default local path and the default global path for all the AppConfiguration::Config objects all you\nneed to do is\nAppConfiguration::Config.default_local_path = Rails.root\nAppConfiguration::Config.default_global_path = '\/usr\/configs'\nContributing\n\nFork it\nCreate your feature branch (git checkout -b my-new-feature)\nCommit your changes (git commit -am 'Add some feature')\nPush to the branch (git push origin my-new-feature)\nCreate new Pull Request\n\nPlease add specs for all new features. If you find a bug and an spec probing that the bug exists and in a separate commit\nadd the bug fix.\nLicense\nCopyright (c) 2013 Guido Marucci Blas\nMIT License\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and\/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n","465":"\u6982\u8981\nUnix\u74b0\u5883\u3067\u5fc5\u8981\u3068\u306a\u308b\u958b\u767a\u30c4\u30fc\u30eb\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u30b3\u30f3\u30d1\u30a4\u30eb\u3059\u308b\u3068\u3044\u3046\u8ab0\u5f97\u306a\u30c4\u30fc\u30eb\u3067\u3059\u3002\n\u500b\u4eba\u7684\u306b\u65b0\u3057\u3044\u74b0\u5883\u306b\u5f15\u3063\u8d8a\u3057\u3057\u305f\u6642\u306b\u4f7f\u7528\u3057\u307e\u3059\u3002\n\u5185\u5bb9\u7269\n","466":"IndoPacific-Corals\nAnalysis of Indo-Pacific coral life histories: socio-environmental drivers and strategic management\n","467":"Grassberry High is an environmental controller for your home grow project. This repository contains the code for the backend Node.js server. Grassberry High is an open source software project. All contributions and the support is community based.\nIMPORTANT NOTICE \/ PROJECT STATUS\nI realized that I don't have the time and energy to develop this project in my free time further. I will still support the project as a maintainer, with guidance and support. But this project needs active developers and further maintainers! I cannot provide enough time to fix all bugs or add additional features at the moment.\nHelp\nIf you find any bugs, please use the issue tracker.\nIn case you need personal assistance you can either use:\n\nour reddit channel (how to use)\nStackOverflow (coding)\nGit-Start (coding)\n\nYou are missing some feature? There are three ways to create new features:\n\nContribute, read our contribution guidelines\nFind someone to code it for you, (a bounty might help)\nSupport development via the official Patreon Campaign\n\nWe are looking for people to translate documents into other languages!\nUseful information\nI2C Setup\ndetect on raspberry pi:\ni2cdetect -y 1 (alias: checki2c)\n0x20 (32) Relais Controller\n0x21 (33), 0x22 (34) Chirp Water Sensor\n0x40 (64), 0x43 (67) HDC1000\n0x4d (77) MHZ16\nDevelopment Slack\nDrop an email to hello <> grassberry-high.com with the title Invite me to Slack\nto get invited to the Slack channel.\nRun\nOn the Pi3\nFollow the instructions here:\nBuild your own tutorial\nShort Version\n\nPlugin all sensors & controllers into the i2c bus and add the power supply\nConnect to gh-config wifi hotspot\nEnter http:\/\/grassberry.local\nEnter your wifi credentials into the configuration, let the device reboot automatically\nDone\n\nConfiguration  Variables\nBasic\n\nNODE_ENV: sets the environment (devlopment, test, production)\n\nApi\n\nAPI_TOKEN: bearer token for api access, for future use\n\nDatabase\n\nMONGODB_URL: url to the database\nMONGODB_ADMIN: admin db\n\nSimulation\n\nSEED: automatically seed diff. collections e.g. \"chambers sensors outputs rules cronjobs\"\nUSER_SEED_TOKEN: give a default token to every user for test reasons\nON_SHOW_MODE_BLOCKED: block c\/u of crud to prevent users to mess around with the system on a fair\/exibition\nOS: turns on certain simulation functions e.g. I2C Bus, \"MAC OSX\"\nSIMULATION: turns on simulation mode for sensors\n\nDebug\n\nLONG_ERROR_TRACES: enables long error traces in prod mode (in dev always on)\nHEAP_SNAPSHOPT: turn heap snapshots on with 'true'\nDEBUG: enable debug loggers e.g. 'sensor*'\n\nOther\n\nNO_CRONS: Disables cronjobs\n\nCreate a simulation set:\n\nmongoexport --db LOC_gh --collection sensordatas -f value --query '{detectorType: \"temperature\"}' | head -1000 > temperature-simulation.json\nreplace \/{ \"value\" : (.*)\\, .* }\/ with $1,\nadd brackets and ,\n\nCoding Guidlines\n..1. Use separate branches for separate problems, feel free to push to master afterwards\n..2. More code is read than written, be specific in variable names\n..3. Small commits, commit the smallest unit\n..4. Write unit tests on critical functions, write unit tests where they are missing\n..5. No duplicate code, if code is needed twice, use classes, functions etc.\n..6. Write comments, readme if something is not 100% self explaining\n..7. SignOff your commits with git commit --signoff\nDebugging\nRemote debugging tutorial\nLicense\nThe project is licensed under MIT license.\nBy using\/contributing to the project you accept the license.\n","468":"seraphim \nseraphim is a R package for investigating the impact of environmental factors on the dispersal history and dynamics of viral lineages. The package can also be used to estimate dispersal statistics and mapping phylogeographic trees.\nInstallation\nseraphim can be installed with the devtools package:\ninstall.packages(\"devtools\"); library(devtools)\ninstall_github(\"sdellicour\/seraphim\/unix_OS\")\nReferences\n\nDellicour S, Rose R, Faria N, Lemey P, Pybus OG (2016). SERAPHIM: studying environmental rasters and phylogenetically-informed movements. Bioinformatics 32: 3204-3206.\nDellicour S, Rose R, Pybus OG (2016). Explaining the geographic spread of emerging epidemics: a framework for comparing viral phylogenies and environmental landscape data. BMC Bioinformatics 17: 82.\n\n","469":"EnvironmentalDefense\nTuck is not in the haus\n","470":"EnvironmentalCS\nThis program was created on Feb.20\/2020 and after 6 months of work, it was completed on Jun.22\/2020\nThe program is a comparison algorithm for people working towards environmental benefits and are monitoring the plant life growth in a\ncertain area. They can upload and save images of landscapes to our directory and compare them overtime with new images of the area. This\nwill provide them with a thorough analysis of how much plant life change there is in the location of interest.\n","471":"Albiorix\nCode used for configuration and administration of the bioinformatics computer cluster Albiorix at the Department of Biological and Environmental Sciences, University of Gothenburg.\n","472":"Albiorix\nCode used for configuration and administration of the bioinformatics computer cluster Albiorix at the Department of Biological and Environmental Sciences, University of Gothenburg.\n","473":"Albiorix\nCode used for configuration and administration of the bioinformatics computer cluster Albiorix at the Department of Biological and Environmental Sciences, University of Gothenburg.\n","474":"scadasim\nSCADA Simulator encompassing things from PLCs to devices such as valves, pumps, tanks, etc. and environmental properties such as water pH levels\nRequirements\n\npython-pip\n\nInstallation\n$ git clone https:\/\/github.com\/sintax1\/scadasim.git\n$ cd scadasim\n$ make\nRunning Tests\n$ make test\nRunning a simulation using a configuration file\n# Run default config\n$ make run\n-Or-\n# Run custom config\n$ python -i run.py -c [YAML config]\nINFO:root:[e660148d][reservoir][reservoir1]: Initialized\nINFO:root:[0efd0900][valve][valve1]: Initialized\nINFO:root:[db91f04a][pump][pump1]: Initialized\nINFO:root:[1d81d76b][valve][valve2]: Initialized\nINFO:root:[f41bb0d9][tank][tank1]: Initialized\nINFO:root:[0efd0900][valve][valve1]: Added input <- [e660148d][reservoir][reservoir1]\nINFO:root:[e660148d][reservoir][reservoir1]: Added output -> [0efd0900][valve][valve1]\nINFO:root:[db91f04a][pump][pump1]: Added input <- [0efd0900][valve][valve1]\nINFO:root:[0efd0900][valve][valve1]: Added output -> [db91f04a][pump][pump1]\nINFO:root:[f41bb0d9][tank][tank1]: Added input <- [1d81d76b][valve][valve2]\nINFO:root:[1d81d76b][valve][valve2]: Added output -> [f41bb0d9][tank][tank1]\nINFO:root:[1d81d76b][valve][valve2]: Added input <- [db91f04a][pump][pump1]\nINFO:root:[db91f04a][pump][pump1]: Added output -> [1d81d76b][valve][valve2]\nINFO:root:[1d81d76b][valve][valve2]: Active\nINFO:root:[f41bb0d9][tank][tank1]: Active\nINFO:root:[0efd0900][valve][valve1]: Active\nINFO:root:[e660148d][reservoir][reservoir1]: Active\nINFO:root:[db91f04a][pump][pump1]: Active\n>>> sim.devices\n{'valve2': [1d81d76b][valve][valve2], 'tank1': [f41bb0d9][tank][tank1], 'valve1': [0efd0900][valve][valve1], 'reservoir1': [e660148d][reservoir][reservoir1], 'pump1': [db91f04a][pump][pump1]}\n>>> sim.settings\n{'speed': 1}\n>>> sim.devices['tank1'].volume\n79\n>>> sim.devices['pump1'].turn_off()\n>>> sim.devices['tank1'].volume\n103\n>>> sim.devices['tank1'].volume\n103\n>>> sim.pause()\nINFO:root:[dd153bbb][valve][valve2]: Inactive\nINFO:root:[16960a58][tank][tank1]: Inactive\nINFO:root:[d4d9302d][valve][valve1]: Inactive\nINFO:root:[a2f02e65][reservoir][reservoir1]: Inactive\nINFO:root:[f1afd77b][pump][pump1]: Inactive\n>>> sim.start()\nINFO:root:[dd153bbb][valve][valve2]: Active\nINFO:root:[16960a58][tank][tank1]: Active\nINFO:root:[d4d9302d][valve][valve1]: Active\nINFO:root:[a2f02e65][reservoir][reservoir1]: Active\nINFO:root:[f1afd77b][pump][pump1]: Active\n>>> sim.stop()\n$\nExample YAML Config\nsettings:\n  speed: 1\n\ndevices:\n  - !reservoir\n    label: reservoir1\n    volume: 1000\n    fluid: !water {}\n  - !valve\n    label: valve1\n    state: 'open'\n  - !pump\n    label: pump1\n    state: 'on'\n  - !valve\n    label: valve2\n    state: 'open'\n  - !tank\n    label: tank1\n\nconnections:\n  reservoir1:\n    outputs: \n     - valve1\n  valve1:\n    outputs:\n     - pump1\n  pump1:\n    outputs:\n     - valve2\n  valve2:\n    outputs:\n     - tank1\n\n\n  \/*\n    slaveid\n\n        Each slave in a network is assigned a unique unit address from 1 to 247. When the master requests data, \n        the first byte it sends is the Slave address. This way each slave knows after the first byte \n        whether or not to ignore the message.\n\n    register_type & data_address\n\n    \u2018d\u2019 - Discrete Inputs initializer \u2018c\u2019 - Coils initializer \u2018h\u2019 - Holding Register initializer \u2018i\u2019 - Input Registers iniatializer\n\n    Coil\/Register Numbers   Data Addresses  Type        Table Name                          Use\n    1-9999                  0000 to 270E    Read-Write  Discrete Output Coils               on\/off read\/write   c\n    10001-19999             0000 to 270E    Read-Only   Discrete Input Contacts             on\/off readonly     d\n    30001-39999             0000 to 270E    Read-Only   Analog Input Registers              analog readonly     i\n    40001-49999             0000 to 270E    Read-Write  Analog Output Holding Registers     analog read\/write   h\n\n    Each coil or contact is 1 bit and assigned a data address between 0000 and 270E.\n    Each register is 1 word = 16 bits = 2 bytes\n\n  *\/\n\nplcs:\n  plc1:\n    slaveid: 1                  # valid range: 1-247\n    sensors:\n      reservoirsensor:\n          register_type: i       # Valid values: (d)iscretes,(i)inputs,(h)oliding,(c)oils\n          data_address: 0x0000    # Valid values: 0x0000 - 0x270e\n      pump1sensor:\n          register_type: d\n          data_address: 0x0000\n      valve1sensor:\n          register_type: d\n          data_address: 0x0001\n\nRunning a simulation within your own python script\n# Import a fluid with properties\nfrom scadasim.fluids import Water\n# Import the devices\nfrom scadasim.devices import Valve, Pump, Tank, Reservoir\n\n# Instantiate the fluid and devices\nwater = Water()\nreservoir1 = Reservoir(label=\"Reservoir1\", fluid=water, volume=100000000)\ntank2 = Tank(label=\"Tank2\")\npump1 = Pump(label=\"Pump1\")\nvalve1 = Valve(label=\"Valve1\")\nvalve2 = Valve(label=\"Valve2\")\n\n# Connect the devices\nreservoir1.add_output(valve1)\nvalve1.add_output(pump1)\npump1.add_output(valve2)\nvalve2.add_output(tank2)\n\n# Activate the devices\nreservoir1.activate()\nvalve1.activate()\npump1.activate()\nvalve2.activate()\n\n# Manipulate the devices\nvalve1.open()\nvalve2.open()\npump1.turn_on()\nExtending the simulator by adding your own device, sensor, or fluid\nfrom scadasim.devices import Device\n\nclass MyCustomDevice(Device):\n    yaml_tag = u'!mycustomdevice' # So it can be used within YAML configs\n    \n    def __init__(self, myvariable=0, **kwargs):\n        # Add your custom variables here\n        self.myvariable = myvariable\n        super(MyCustomDevice, self).__init__(device_type=\"tank\", **kwargs)\n\n    def input(self, fluid, volume):\n        \"\"\"Receive `volume` amount of `fluid` and return the amount your device is willing to receive\n            accepted_volume = 0: Don't accept any fluid\n            accepted_volume = volume: Accept it all\n            accepted_volume = volume \/ 2: Restrict flow by accepting a fraction of the volume\n        \"\"\"\n        ...\n        Do something here with the fluid that the connected devices send to your device's input\n        ...\n        return accepted_volume\n\n    def output(self, to_device, volume):\n        \"\"\" `to_device` is pulling this device's output (sucking fluid) in the mount of `volume`\n        \"\"\"\n        # If you accept the request, send the fluid to the requesting devices input\n        accepted_volume = to_device.input(self.fluid, volume)\n\n    def worker(self):\n        \"\"\"Do something each cycle of `worker_frequency`\n            Update fluid, pull inputs, push outputs, etc.\n            If your device only performs work based on input and output stimulation, \n            there may be no need to have this worker. Such as a valve.\n        \"\"\"\n        pass\n        \n# Use it\nmydevice = MyCustomDevice(fluid=water, myvariable=10) \n        \nReferences\nhttp:\/\/www.simplymodbus.ca\/faq.htm#Stored\nhttps:\/\/dbus.freedesktop.org\/doc\/dbus-python\/doc\/tutorial.html#basic-type-conversions\nhttp:\/\/home.isr.uc.pt\/~lino\/AIR\/Arquivo\/PLC_Tutor\/registers.htm\n","475":"scadasim\nSCADA Simulator encompassing things from PLCs to devices such as valves, pumps, tanks, etc. and environmental properties such as water pH levels\nRequirements\n\npython-pip\n\nInstallation\n$ git clone https:\/\/github.com\/sintax1\/scadasim.git\n$ cd scadasim\n$ make\nRunning Tests\n$ make test\nRunning a simulation using a configuration file\n# Run default config\n$ make run\n-Or-\n# Run custom config\n$ python -i run.py -c [YAML config]\nINFO:root:[e660148d][reservoir][reservoir1]: Initialized\nINFO:root:[0efd0900][valve][valve1]: Initialized\nINFO:root:[db91f04a][pump][pump1]: Initialized\nINFO:root:[1d81d76b][valve][valve2]: Initialized\nINFO:root:[f41bb0d9][tank][tank1]: Initialized\nINFO:root:[0efd0900][valve][valve1]: Added input <- [e660148d][reservoir][reservoir1]\nINFO:root:[e660148d][reservoir][reservoir1]: Added output -> [0efd0900][valve][valve1]\nINFO:root:[db91f04a][pump][pump1]: Added input <- [0efd0900][valve][valve1]\nINFO:root:[0efd0900][valve][valve1]: Added output -> [db91f04a][pump][pump1]\nINFO:root:[f41bb0d9][tank][tank1]: Added input <- [1d81d76b][valve][valve2]\nINFO:root:[1d81d76b][valve][valve2]: Added output -> [f41bb0d9][tank][tank1]\nINFO:root:[1d81d76b][valve][valve2]: Added input <- [db91f04a][pump][pump1]\nINFO:root:[db91f04a][pump][pump1]: Added output -> [1d81d76b][valve][valve2]\nINFO:root:[1d81d76b][valve][valve2]: Active\nINFO:root:[f41bb0d9][tank][tank1]: Active\nINFO:root:[0efd0900][valve][valve1]: Active\nINFO:root:[e660148d][reservoir][reservoir1]: Active\nINFO:root:[db91f04a][pump][pump1]: Active\n>>> sim.devices\n{'valve2': [1d81d76b][valve][valve2], 'tank1': [f41bb0d9][tank][tank1], 'valve1': [0efd0900][valve][valve1], 'reservoir1': [e660148d][reservoir][reservoir1], 'pump1': [db91f04a][pump][pump1]}\n>>> sim.settings\n{'speed': 1}\n>>> sim.devices['tank1'].volume\n79\n>>> sim.devices['pump1'].turn_off()\n>>> sim.devices['tank1'].volume\n103\n>>> sim.devices['tank1'].volume\n103\n>>> sim.pause()\nINFO:root:[dd153bbb][valve][valve2]: Inactive\nINFO:root:[16960a58][tank][tank1]: Inactive\nINFO:root:[d4d9302d][valve][valve1]: Inactive\nINFO:root:[a2f02e65][reservoir][reservoir1]: Inactive\nINFO:root:[f1afd77b][pump][pump1]: Inactive\n>>> sim.start()\nINFO:root:[dd153bbb][valve][valve2]: Active\nINFO:root:[16960a58][tank][tank1]: Active\nINFO:root:[d4d9302d][valve][valve1]: Active\nINFO:root:[a2f02e65][reservoir][reservoir1]: Active\nINFO:root:[f1afd77b][pump][pump1]: Active\n>>> sim.stop()\n$\nExample YAML Config\nsettings:\n  speed: 1\n\ndevices:\n  - !reservoir\n    label: reservoir1\n    volume: 1000\n    fluid: !water {}\n  - !valve\n    label: valve1\n    state: 'open'\n  - !pump\n    label: pump1\n    state: 'on'\n  - !valve\n    label: valve2\n    state: 'open'\n  - !tank\n    label: tank1\n\nconnections:\n  reservoir1:\n    outputs: \n     - valve1\n  valve1:\n    outputs:\n     - pump1\n  pump1:\n    outputs:\n     - valve2\n  valve2:\n    outputs:\n     - tank1\n\n\n  \/*\n    slaveid\n\n        Each slave in a network is assigned a unique unit address from 1 to 247. When the master requests data, \n        the first byte it sends is the Slave address. This way each slave knows after the first byte \n        whether or not to ignore the message.\n\n    register_type & data_address\n\n    \u2018d\u2019 - Discrete Inputs initializer \u2018c\u2019 - Coils initializer \u2018h\u2019 - Holding Register initializer \u2018i\u2019 - Input Registers iniatializer\n\n    Coil\/Register Numbers   Data Addresses  Type        Table Name                          Use\n    1-9999                  0000 to 270E    Read-Write  Discrete Output Coils               on\/off read\/write   c\n    10001-19999             0000 to 270E    Read-Only   Discrete Input Contacts             on\/off readonly     d\n    30001-39999             0000 to 270E    Read-Only   Analog Input Registers              analog readonly     i\n    40001-49999             0000 to 270E    Read-Write  Analog Output Holding Registers     analog read\/write   h\n\n    Each coil or contact is 1 bit and assigned a data address between 0000 and 270E.\n    Each register is 1 word = 16 bits = 2 bytes\n\n  *\/\n\nplcs:\n  plc1:\n    slaveid: 1                  # valid range: 1-247\n    sensors:\n      reservoirsensor:\n          register_type: i       # Valid values: (d)iscretes,(i)inputs,(h)oliding,(c)oils\n          data_address: 0x0000    # Valid values: 0x0000 - 0x270e\n      pump1sensor:\n          register_type: d\n          data_address: 0x0000\n      valve1sensor:\n          register_type: d\n          data_address: 0x0001\n\nRunning a simulation within your own python script\n# Import a fluid with properties\nfrom scadasim.fluids import Water\n# Import the devices\nfrom scadasim.devices import Valve, Pump, Tank, Reservoir\n\n# Instantiate the fluid and devices\nwater = Water()\nreservoir1 = Reservoir(label=\"Reservoir1\", fluid=water, volume=100000000)\ntank2 = Tank(label=\"Tank2\")\npump1 = Pump(label=\"Pump1\")\nvalve1 = Valve(label=\"Valve1\")\nvalve2 = Valve(label=\"Valve2\")\n\n# Connect the devices\nreservoir1.add_output(valve1)\nvalve1.add_output(pump1)\npump1.add_output(valve2)\nvalve2.add_output(tank2)\n\n# Activate the devices\nreservoir1.activate()\nvalve1.activate()\npump1.activate()\nvalve2.activate()\n\n# Manipulate the devices\nvalve1.open()\nvalve2.open()\npump1.turn_on()\nExtending the simulator by adding your own device, sensor, or fluid\nfrom scadasim.devices import Device\n\nclass MyCustomDevice(Device):\n    yaml_tag = u'!mycustomdevice' # So it can be used within YAML configs\n    \n    def __init__(self, myvariable=0, **kwargs):\n        # Add your custom variables here\n        self.myvariable = myvariable\n        super(MyCustomDevice, self).__init__(device_type=\"tank\", **kwargs)\n\n    def input(self, fluid, volume):\n        \"\"\"Receive `volume` amount of `fluid` and return the amount your device is willing to receive\n            accepted_volume = 0: Don't accept any fluid\n            accepted_volume = volume: Accept it all\n            accepted_volume = volume \/ 2: Restrict flow by accepting a fraction of the volume\n        \"\"\"\n        ...\n        Do something here with the fluid that the connected devices send to your device's input\n        ...\n        return accepted_volume\n\n    def output(self, to_device, volume):\n        \"\"\" `to_device` is pulling this device's output (sucking fluid) in the mount of `volume`\n        \"\"\"\n        # If you accept the request, send the fluid to the requesting devices input\n        accepted_volume = to_device.input(self.fluid, volume)\n\n    def worker(self):\n        \"\"\"Do something each cycle of `worker_frequency`\n            Update fluid, pull inputs, push outputs, etc.\n            If your device only performs work based on input and output stimulation, \n            there may be no need to have this worker. Such as a valve.\n        \"\"\"\n        pass\n        \n# Use it\nmydevice = MyCustomDevice(fluid=water, myvariable=10) \n        \nReferences\nhttp:\/\/www.simplymodbus.ca\/faq.htm#Stored\nhttps:\/\/dbus.freedesktop.org\/doc\/dbus-python\/doc\/tutorial.html#basic-type-conversions\nhttp:\/\/home.isr.uc.pt\/~lino\/AIR\/Arquivo\/PLC_Tutor\/registers.htm\n","476":"EnvironmentalProject\nWedio Enviromental Projects\n","477":"Environmental Impact of COVID-19\nThis project examines the \"potential impacts of reduced human traffic\" in protected environments, such as beaches, parks, marine monuments and other wilderness areas and was created as part of the NASA SpaceApps COVID-19 Challenge. These impacts could manifest in a number of forms such as:\n\nReduction in land degradation\nChange in water quality\nChange in vegetation growth\/density\n\nThis project focuses on the Long Island area, and tracks EVI (Enhanced Vegetation Index), Surface Albedo (proportion of incident light or radiation is reflected by a surface), and SST (sea surface temperature) in this region. Check out our team here!\nHow was this created?\nThis project was created using NASA remote sensing data from NASA Goddard Earth Sciences, NASA aqua MODIS, and NASA terra MODIS. Data was downloaded from NASA Giovanni and NASA Earthdata search in HDF format (for EVI) and netCDF format (for SST and surface albedo) for May 2016-2020 and then visualized using Panoply. The visualization showed the level of EVI, SST, and surface albedo on a 9-color scale, with more vibrant colors indicating higher levels of the given variable and paler colors indicating lower levels. After saving the visualization image as a png, it was run through an image processing python script which counted the frequency of each color on the scale and saved the results as a JSON. This information was then plotted as interactive graphs using ReactJS and the Material-UI library that show the frequency of each color versus time for all 3 data sets. The site also contains additional information about the variables used.\nSneak peek\nHere is a graph that shows EVI over time\n\n\n...created from the images above that range from May 2016 to May 2020.\nSo what can we deduce from this?\n\nThere is a slight increase in vegetation greenness between May 2019 and May 2020\nThere are drastic fluctuations in EVI prior to 2019 meaning that the change in 2020 may not be statistically significant\n\nWe plan to increase out dataset to include years prior to 2016 to get a better idea of the trends in EVI and whether or not 2020 marks a significant deviation. If you clone and run this project, you can interact with the EVI chart yourself along with charts for Surface Albedo and SST to draw your own conclusions!\nHow do I run this project?\nStart by installing yarn\nThen run the following commands in your terminal:\n\ngit clone https:\/\/github.com\/SpaceApps2020\/EnvironmentalImpacts.git\ncd EnvironmentalImpacts\/enviroviz\nyarn install\nyarn start\n\nThis should automatically open http:\/\/localhost:3000\/ on your computer where the webapp will be running! A demo of the website can be found here.\n","478":"EnvironmentalMonitor\nArduino+python temperature\/humidity\/etc. monitor and logger.\n","479":"EnvironmentalMonitor\nArduino+python temperature\/humidity\/etc. monitor and logger.\n","480":"EnvironmentalModeling\nLectures Environmental Science Modeling\n","481":"EnvironmentalModeling\nLectures Environmental Science Modeling\n","482":"Environment Monitoring\nA sensitive healthcare equipment needs suitable operating conditions.\nThe equipment's operating environment\nis the responsibility of the customer.\nTo assist the customer in maintaining a suitable environment,\nwe install an environment monitoring device at the customer premises\nand monitor the data.\nThis project is about simulating data from a monitoring device\nand issuing alerts and warnings.\nDecomposition\nAt a top level, the program runs in two processes - the sender and the receiver.\n\nThe Sender is responsible for simulating the monitoring device.\nThe Receiver analyzes the data.\nThe Sender sends data to the Receiver using console redirection.\nRun them on the command line as follows:\nsender-executable | receiver-executable\nThis would make the console-writes of the sender\nbecome the console-reads of the receiver.\nDecomposition of responsibility within the Sender and Receiver\nThe naming of source files within the Sender and within the Receiver\ngive their internal decomposition.\nThe Code\nThis project follows the practices and tools\nlisted here.\nThe Interface\nWe document the interface between the Sender and the Receiver as test cases.\nThe Sender and Receiver are testable on their own:\n\nThe Sender is testable without the Receiver - so we can develop\nfor another data-source, test and be confident about integration.\nThe Receiver is testable without the Sender - so we can enhance\nwithout re-testing against all Receivers again.\n\nMinimum Functionality\nFor simulating different sequences of data from the monitor,\nthe Sender takes a CSV file as input.\nThis file contains temperature and humidity data that the Sender\nsends periodically.\nThe Receiver outputs warnings and alerts on the console when environmental\nconditions breach these limits:\n\nTemperature warning levels: High: 37 C; Low: 4 C\nTemperature error levels: High: 40C; Low: 0 C\nHumidity warning level: High: 70%\nHumidity error level: High: 90%\n\nExtended Functionality\nThe Sender needs to send the data every 5 minutes. When the Receiver doesn't\nreceive any data for half an hour, the Receiver outputs an alert\nEvaluation Criteria\nSee here\nfor the evaluation criteria of this exercise.\n","483":"Environment Monitoring\nA sensitive healthcare equipment needs suitable operating conditions.\nThe equipment's operating environment\nis the responsibility of the customer.\nTo assist the customer in maintaining a suitable environment,\nwe install an environment monitoring device at the customer premises\nand monitor the data.\nThis project is about simulating data from a monitoring device\nand issuing alerts and warnings.\nDecomposition\nAt a top level, the program runs in two processes - the sender and the receiver.\n\nThe Sender is responsible for simulating the monitoring device.\nThe Receiver analyzes the data.\nThe Sender sends data to the Receiver using console redirection.\nRun them on the command line as follows:\nsender-executable | receiver-executable\nThis would make the console-writes of the sender\nbecome the console-reads of the receiver.\nDecomposition of responsibility within the Sender and Receiver\nThe naming of source files within the Sender and within the Receiver\ngive their internal decomposition.\nThe Code\nThis project follows the practices and tools\nlisted here.\nThe Interface\nWe document the interface between the Sender and the Receiver as test cases.\nThe Sender and Receiver are testable on their own:\n\nThe Sender is testable without the Receiver - so we can develop\nfor another data-source, test and be confident about integration.\nThe Receiver is testable without the Sender - so we can enhance\nwithout re-testing against all Receivers again.\n\nMinimum Functionality\nFor simulating different sequences of data from the monitor,\nthe Sender takes a CSV file as input.\nThis file contains temperature and humidity data that the Sender\nsends periodically.\nThe Receiver outputs warnings and alerts on the console when environmental\nconditions breach these limits:\n\nTemperature warning levels: High: 37 C; Low: 4 C\nTemperature error levels: High: 40C; Low: 0 C\nHumidity warning level: High: 70%\nHumidity error level: High: 90%\n\nExtended Functionality\nThe Sender needs to send the data every 5 minutes. When the Receiver doesn't\nreceive any data for half an hour, the Receiver outputs an alert\nEvaluation Criteria\nSee here\nfor the evaluation criteria of this exercise.\n","484":"Environment Monitoring\nA sensitive healthcare equipment needs suitable operating conditions.\nThe equipment's operating environment\nis the responsibility of the customer.\nTo assist the customer in maintaining a suitable environment,\nwe install an environment monitoring device at the customer premises\nand monitor the data.\nThis project is about simulating data from a monitoring device\nand issuing alerts and warnings.\nDecomposition\nAt a top level, the program runs in two processes - the sender and the receiver.\n\nThe Sender is responsible for simulating the monitoring device.\nThe Receiver analyzes the data.\nThe Sender sends data to the Receiver using console redirection.\nRun them on the command line as follows:\nsender-executable | receiver-executable\nThis would make the console-writes of the sender\nbecome the console-reads of the receiver.\nDecomposition of responsibility within the Sender and Receiver\nThe naming of source files within the Sender and within the Receiver\ngive their internal decomposition.\nThe Code\nThis project follows the practices and tools\nlisted here.\nThe Interface\nWe document the interface between the Sender and the Receiver as test cases.\nThe Sender and Receiver are testable on their own:\n\nThe Sender is testable without the Receiver - so we can develop\nfor another data-source, test and be confident about integration.\nThe Receiver is testable without the Sender - so we can enhance\nwithout re-testing against all Receivers again.\n\nMinimum Functionality\nFor simulating different sequences of data from the monitor,\nthe Sender takes a CSV file as input.\nThis file contains temperature and humidity data that the Sender\nsends periodically.\nThe Receiver outputs warnings and alerts on the console when environmental\nconditions breach these limits:\n\nTemperature warning levels: High: 37 C; Low: 4 C\nTemperature error levels: High: 40C; Low: 0 C\nHumidity warning level: High: 70%\nHumidity error level: High: 90%\n\nExtended Functionality\nThe Sender needs to send the data every 5 minutes. When the Receiver doesn't\nreceive any data for half an hour, the Receiver outputs an alert\nEvaluation Criteria\nSee here\nfor the evaluation criteria of this exercise.\n","485":"Environment Monitoring\nA sensitive healthcare equipment needs suitable operating conditions.\nThe equipment's operating environment\nis the responsibility of the customer.\nTo assist the customer in maintaining a suitable environment,\nwe install an environment monitoring device at the customer premises\nand monitor the data.\nThis project is about simulating data from a monitoring device\nand issuing alerts and warnings.\nDecomposition\nAt a top level, the program runs in two processes - the sender and the receiver.\n\nThe Sender is responsible for simulating the monitoring device.\nThe Receiver analyzes the data.\nThe Sender sends data to the Receiver using console redirection.\nRun them on the command line as follows:\nsender-executable | receiver-executable\nThis would make the console-writes of the sender\nbecome the console-reads of the receiver.\nDecomposition of responsibility within the Sender and Receiver\nThe naming of source files within the Sender and within the Receiver\ngive their internal decomposition.\nThe Code\nThis project follows the practices and tools\nlisted here.\nThe Interface\nWe document the interface between the Sender and the Receiver as test cases.\nThe Sender and Receiver are testable on their own:\n\nThe Sender is testable without the Receiver - so we can develop\nfor another data-source, test and be confident about integration.\nThe Receiver is testable without the Sender - so we can enhance\nwithout re-testing against all Receivers again.\n\nMinimum Functionality\nFor simulating different sequences of data from the monitor,\nthe Sender takes a CSV file as input.\nThis file contains temperature and humidity data that the Sender\nsends periodically.\nThe Receiver outputs warnings and alerts on the console when environmental\nconditions breach these limits:\n\nTemperature warning levels: High: 37 C; Low: 4 C\nTemperature error levels: High: 40C; Low: 0 C\nHumidity warning level: High: 70%\nHumidity error level: High: 90%\n\nExtended Functionality\nThe Sender needs to send the data every 5 minutes. When the Receiver doesn't\nreceive any data for half an hour, the Receiver outputs an alert\nEvaluation Criteria\nSee here\nfor the evaluation criteria of this exercise.\n","486":"EnvironmentalSensor\n","487":"EnvironmentalInterface\nUnderlying middleware for ServIoTicy.\nRequirements\n\nServIoTicy APIKEY inside \/servioticy\/res directory.\nsecrets.example must be fulfilled, instructions inside.\n\nDeletion Requirements\nIn order to use the delete scripts to clean Service Objects, additional tools are needed:\n\ncURL\nPostgreSQL client\nsudo apt-get install postgresql-common postgresql-client-<version>\nFile .pgpass in root directory with the following database info content\n\ncd ~\necho \"hostname:port:dbname:dbuser:dbpassword\" > .pgpass\n\nPreparation Phase\nIn order to create a valid \/servioticy folder, several files must be created before executing. Firstly, models for room sensors must be created. To do so, make use of the generator inside \/servioticy\/models\njavac modelGenerator.java\njava modelGenerator #rooms\n\nEach room is currently composed of 5 sensors (XM1000, Light, Power, Presence and Air quality).\nAdditionally, actuators can also be created by making use of the generator inside \/servioticy\/actuators\njavac actuatorGenerator.java\njava actuatorGenerator #rooms\n\nCurrently, each room contains Computer, Light and HVAC actuators. In order to push the actuators to ServIoTicy and store the IDS into the database, additional scripts are created.\n.\/push_actuators.sh\n\nThe script firstly uses the create_SO.sh script to communicate with ServIoTicy and obtain the IDs. Finally, it uses the script db.py to store the IDs into the database.\nUsage\nThere are several options to launch the Interface. Currently, virtual, real or both sensor servers can be run. If the real sensor server is needed, it is firstly required to start the serial forwarder. At the moment, only XM1000 motes are supported. For more driver and specs information refer to http:\/\/www.advanticsys.com\/shop\/asxm1000-p-24.html\n.\/start_sf.sh (only if the serial port is being used)\njava -jar EnvIface.jar [-comm <source>] [-port <port>]\n\nOnce the servers are running, if virtual sensors are needed, they are executed as follows:\njava sensors [-port <port>] [-ids <#sensors>]\n\nEither of those commands will execute the sensors, sending 2 messages for each of them.\n","488":"EnvironmentalReadings\nA PowerShell module for reading the temperature and humidity from the webpages of a sensor made using the instructions linked below.  The data is then appended to a CSV file.\nhttps:\/\/randomnerdtutorials.com\/esp32-dht11-dht22-temperature-humidity-web-server-arduino-ide\/\n","489":"EnvironmentalMonitoring\n\u914d\u7535\u623f\u73af\u5883\u8fdc\u7a0b\u63a7\u5236\u7cfb\u7edf\n1.\u767b\u5f55\n2.\u9996\u9875\u83b7\u53d6\u914d\u7535\u623f\u73af\u5883\u76d1\u63a7\u8bbe\u5907\u5305\u62ec\u5728\u7ebf\u60c5\u51b5\u3001\u521b\u5efa\u65f6\u95f4\u4ee5\u53ca\u540d\u79f0\u3001ID\u7b49\n3.\u5373\u65f6\u6570\u636e\u9875\u9762\u4e5f\u83b7\u53d6\u67d0\u4e2a\u8bbe\u5907\u6700\u65b0\u91c7\u96c6\u7684\u6570\u636e\n4.\u53ef\u4ee5\u641c\u7d22\u8bbe\u5907\uff0c\u6839\u636e\u8bbe\u5907\u7684\u4fe1\u606f\n5.\u9996\u9875\u6709Peek & Pop\u529f\u80fd\n6.\u4fee\u6539\u5bc6\u7801\u548c\u9000\u51fa\u767b\u5f55\n7.\u6570\u636e\u8be6\u60c5\u53ef\u4ee5\u89c2\u5bdf\u67d0\u4e2a\u8bbe\u5907\u6700\u65b0\u91c7\u96c6\u6570\u636e\u7684\u534a\u4e2a\u5c0f\u65f6\u5185\u7684\u6e29\u6e7f\u5ea6\u6298\u7ebf\u56fe\n8.\u5237\u65b0\u65b9\u5f0f\u6709\u4e0a\u4e0b\u62c9\u5237\u65b0\u548c\u81ea\u52a8\u5237\u65b0\n9.\u53ef\u4ee5\u67e5\u8be2\u5386\u53f2\u6570\u636e\n10.\u53ef\u4ee5\u5bfc\u51faExcel\u65e5\u5fd7\n11.\u5982\u679c\u6570\u636e\u5f02\u5e38\u80fd\u63a5\u6536\u5230\u63a8\u9001\n12.\u91cc\u9762\u5c11\u4e86\u4e00\u4e2aLibXL\u7684\u5e93 \u53ef\u4ee5\u81ea\u884c\u4e0b\u8f7d\u5bfc\u5165\u5373\u53ef\n","490":"EnvironmentalIssues\nFelix's Fables\n\n    \n        <title>My Great Game<\/title><\n    \n    \n\n hello \n","491":"ETD_EnvironmentalSensor\nProject in Python consisting of smaller apps talking to each other (micro-services) that enables reading measurements from Hum&Temp sensor and displaying them on a webpage.\nSteps for creating project\nDownload repo\ngit clone <adres_url>\nCreate venv and install required packages\npython3 -m venv venv\nsource .\/venv\/bin\/activate\npip install --upgrade pip\npip3 install -r .\/requirements.txt\npermanent alias\nnano ~\/.bashrc\nalias venv=\"source ~\/EnvironmentalSensors\/venv\/bin\/activate\"\n#reboot or type source ~\/.bashrc\nCAN config (for temp&hum sensor) \/\/add or uncomment\ndtparam=spi=on\ndtoverlay=mcp2515-can0,oscillator=8000000,interrupt=25,spimaxfrequency=1000000\nsudo apt update\nsudo modprobe mcp251x\nsudo apt install can-utils   #worth rebooting now\nsudo ip link set can0 up type can bitrate 460800\ncandump can0 -t A\nsome bug fix\nsudo apt-get install libatlas-base-dev\nrunning app\n.\/start.sh\nsigoihy\n","492":"EnvironmentalModeling\n","493":"EnvironmentalModeling\n","494":"EnvironmentalModeling\n","495":"EnvironmentalModeling\n","496":"Environmental Monitor\nData captured\nData is published to serial bus once per second as a comma delimited string.\nExample:\n26.70,35,736,1013,-5.91,26421\n\n\nTemperature - Celsius\nHumidity - Percent\nLight - Analog value between 0 and 1023\nPressure - Pa\nAltitude  - m (Not accurate)\nCRC-16 - checksum of data fields\n\nSensors\n\nDHT11 - temperature + humidity\nBMP085 - temperature + pressure\nLDR - light\n\nDependencies\npip3 install paho-mqtt pyserial crcmod\nConfig\n\nSerial - 9600\nLDR - A0\nDHT11 - 4\nBMP085 - 0x77\n\nPublishing to MQTT\nserToMQTT.py takes the data published by the Arduino and forwards it to an MQTT broker.\nIt takes the name of the serial port and name of the room it is in as parameters.\npython3 serToMQTT.py \"192.168.1.111\" \"\/dev\/ttyACM0\" \"livingroom\"\nAn alternative to python is the q versionserToMQTT.q\nq serToMQTT.q -q \"192.168.1.111\" \"\/dev\/ttyACM0\" \"livingroom\"\nYou can subscribe from the command line to confirm your data is publishing to your broker:\nmosquitto_sub -h 192.168.1.111 -t \"hassio\/#\"\nAdd as sensors to Home Assistant\nAdd to configuration.yaml:\nsensor:\n  platform: mqtt\n  name: \"Living Room Temperature\"\n  state_topic: \"hassio\/livingroom\/temperature\"\n  qos: 0\n  unit_of_measurement: \"\u00baC\"\n\nsensor 2:\n  platform: mqtt\n  name: \"Living Room Humidity\"\n  state_topic: \"hassio\/livingroom\/humidity\"\n  qos: 0\n  unit_of_measurement: \"%\"\n\nsensor 3:\n  platform: mqtt\n  name: \"Living Room Pressure\"\n  state_topic: \"hassio\/livingroom\/pressure\"\n  qos: 0\n  unit_of_measurement: \"hPa\"\n\nsensor 4:\n  platform: mqtt\n  name: \"Living Room Light\"\n  state_topic: \"hassio\/livingroom\/light\"\n  qos: 0\n  unit_of_measurement: \"\/1024\"\nAdding sensors to Lovelace Dashboard\nTo add to a Lovelace dashboard:\nentities:\n  - entity: sensor.living_room_temperature\n  - entity: sensor.living_room_humidity\n  - entity: sensor.living_room_pressure\n  - entity: sensor.living_room_light\nshow_icon: true\nshow_name: false\nshow_state: true\ntitle: Living Room\ntype: glance\n","497":"Environmental Monitor\nData captured\nData is published to serial bus once per second as a comma delimited string.\nExample:\n26.70,35,736,1013,-5.91,26421\n\n\nTemperature - Celsius\nHumidity - Percent\nLight - Analog value between 0 and 1023\nPressure - Pa\nAltitude  - m (Not accurate)\nCRC-16 - checksum of data fields\n\nSensors\n\nDHT11 - temperature + humidity\nBMP085 - temperature + pressure\nLDR - light\n\nDependencies\npip3 install paho-mqtt pyserial crcmod\nConfig\n\nSerial - 9600\nLDR - A0\nDHT11 - 4\nBMP085 - 0x77\n\nPublishing to MQTT\nserToMQTT.py takes the data published by the Arduino and forwards it to an MQTT broker.\nIt takes the name of the serial port and name of the room it is in as parameters.\npython3 serToMQTT.py \"192.168.1.111\" \"\/dev\/ttyACM0\" \"livingroom\"\nAn alternative to python is the q versionserToMQTT.q\nq serToMQTT.q -q \"192.168.1.111\" \"\/dev\/ttyACM0\" \"livingroom\"\nYou can subscribe from the command line to confirm your data is publishing to your broker:\nmosquitto_sub -h 192.168.1.111 -t \"hassio\/#\"\nAdd as sensors to Home Assistant\nAdd to configuration.yaml:\nsensor:\n  platform: mqtt\n  name: \"Living Room Temperature\"\n  state_topic: \"hassio\/livingroom\/temperature\"\n  qos: 0\n  unit_of_measurement: \"\u00baC\"\n\nsensor 2:\n  platform: mqtt\n  name: \"Living Room Humidity\"\n  state_topic: \"hassio\/livingroom\/humidity\"\n  qos: 0\n  unit_of_measurement: \"%\"\n\nsensor 3:\n  platform: mqtt\n  name: \"Living Room Pressure\"\n  state_topic: \"hassio\/livingroom\/pressure\"\n  qos: 0\n  unit_of_measurement: \"hPa\"\n\nsensor 4:\n  platform: mqtt\n  name: \"Living Room Light\"\n  state_topic: \"hassio\/livingroom\/light\"\n  qos: 0\n  unit_of_measurement: \"\/1024\"\nAdding sensors to Lovelace Dashboard\nTo add to a Lovelace dashboard:\nentities:\n  - entity: sensor.living_room_temperature\n  - entity: sensor.living_room_humidity\n  - entity: sensor.living_room_pressure\n  - entity: sensor.living_room_light\nshow_icon: true\nshow_name: false\nshow_state: true\ntitle: Living Room\ntype: glance\n","498":"Environmental Monitor\nData captured\nData is published to serial bus once per second as a comma delimited string.\nExample:\n26.70,35,736,1013,-5.91,26421\n\n\nTemperature - Celsius\nHumidity - Percent\nLight - Analog value between 0 and 1023\nPressure - Pa\nAltitude  - m (Not accurate)\nCRC-16 - checksum of data fields\n\nSensors\n\nDHT11 - temperature + humidity\nBMP085 - temperature + pressure\nLDR - light\n\nDependencies\npip3 install paho-mqtt pyserial crcmod\nConfig\n\nSerial - 9600\nLDR - A0\nDHT11 - 4\nBMP085 - 0x77\n\nPublishing to MQTT\nserToMQTT.py takes the data published by the Arduino and forwards it to an MQTT broker.\nIt takes the name of the serial port and name of the room it is in as parameters.\npython3 serToMQTT.py \"192.168.1.111\" \"\/dev\/ttyACM0\" \"livingroom\"\nAn alternative to python is the q versionserToMQTT.q\nq serToMQTT.q -q \"192.168.1.111\" \"\/dev\/ttyACM0\" \"livingroom\"\nYou can subscribe from the command line to confirm your data is publishing to your broker:\nmosquitto_sub -h 192.168.1.111 -t \"hassio\/#\"\nAdd as sensors to Home Assistant\nAdd to configuration.yaml:\nsensor:\n  platform: mqtt\n  name: \"Living Room Temperature\"\n  state_topic: \"hassio\/livingroom\/temperature\"\n  qos: 0\n  unit_of_measurement: \"\u00baC\"\n\nsensor 2:\n  platform: mqtt\n  name: \"Living Room Humidity\"\n  state_topic: \"hassio\/livingroom\/humidity\"\n  qos: 0\n  unit_of_measurement: \"%\"\n\nsensor 3:\n  platform: mqtt\n  name: \"Living Room Pressure\"\n  state_topic: \"hassio\/livingroom\/pressure\"\n  qos: 0\n  unit_of_measurement: \"hPa\"\n\nsensor 4:\n  platform: mqtt\n  name: \"Living Room Light\"\n  state_topic: \"hassio\/livingroom\/light\"\n  qos: 0\n  unit_of_measurement: \"\/1024\"\nAdding sensors to Lovelace Dashboard\nTo add to a Lovelace dashboard:\nentities:\n  - entity: sensor.living_room_temperature\n  - entity: sensor.living_room_humidity\n  - entity: sensor.living_room_pressure\n  - entity: sensor.living_room_light\nshow_icon: true\nshow_name: false\nshow_state: true\ntitle: Living Room\ntype: glance\n","499":"Enviro-monitor\nIndoor\/outdoor environmental monitor project for the Enviro+ environmental monitoring board.\nUses OpenWeather api to get the current weather and show it on the display.\nAlso, the display can be turned on\/off by passing your finger near the light sensor to reduce energy consumption.\n\nPython library and more steps to install can be found on pimoroni\/enviroplus-python\nInstalling\nInstall and configure dependencies from GitHub:\n\ngit clone https:\/\/github.com\/pimoroni\/enviroplus-python\ncd enviroplus-python\nsudo .\/install.sh && cd ..\n\nNote Raspbian Lite users may first need to install git: sudo apt install git\n\ngit clone https:\/\/github.com\/cesnietor\/enviro-monitor.git\ncd enviro-monitor\n\nAdd environment variables:\n\n\nMake sure you have a valid APPID from OpenWeather on:\ncurl https:\/\/api.openweathermap.org\/data\/2.5\/weather?id=2172797&APPID=<UniqueUUID>&units=imperial\n\n\n\nDefine city id and APPID as environment variables:\nexport OPENWEATHERMAP_CITY_ID=<YourCityID>\nexport OPENWEATHERMAP_APPID=<UniqueUUID>\n\n\n\nChange time_zone and city_name timezone and city for python timezone on enviro-monitor.py\n\n\nRunning\npython3 enviro-monitory.py\n\nIf you want to run it as a background process and your are using ssh on your raspberry pi\nmake sure the process is re-parented by init.\nsetsid python3 enviro-monitor.py < \/dev\/zero &> error.log &\n\nIf yout want to run it when the pi boots refer to rc.local\n","500":"Enviro-monitor\nIndoor\/outdoor environmental monitor project for the Enviro+ environmental monitoring board.\nUses OpenWeather api to get the current weather and show it on the display.\nAlso, the display can be turned on\/off by passing your finger near the light sensor to reduce energy consumption.\n\nPython library and more steps to install can be found on pimoroni\/enviroplus-python\nInstalling\nInstall and configure dependencies from GitHub:\n\ngit clone https:\/\/github.com\/pimoroni\/enviroplus-python\ncd enviroplus-python\nsudo .\/install.sh && cd ..\n\nNote Raspbian Lite users may first need to install git: sudo apt install git\n\ngit clone https:\/\/github.com\/cesnietor\/enviro-monitor.git\ncd enviro-monitor\n\nAdd environment variables:\n\n\nMake sure you have a valid APPID from OpenWeather on:\ncurl https:\/\/api.openweathermap.org\/data\/2.5\/weather?id=2172797&APPID=<UniqueUUID>&units=imperial\n\n\n\nDefine city id and APPID as environment variables:\nexport OPENWEATHERMAP_CITY_ID=<YourCityID>\nexport OPENWEATHERMAP_APPID=<UniqueUUID>\n\n\n\nChange time_zone and city_name timezone and city for python timezone on enviro-monitor.py\n\n\nRunning\npython3 enviro-monitory.py\n\nIf you want to run it as a background process and your are using ssh on your raspberry pi\nmake sure the process is re-parented by init.\nsetsid python3 enviro-monitor.py < \/dev\/zero &> error.log &\n\nIf yout want to run it when the pi boots refer to rc.local\n","501":"##Environmental Data Logger\nThe design files and the software for a small low-power temperature and humidity logger\nProbably the most remarkable feature is the power consumption of just 3.2\u00b5A or less\na better documentation can be found on Hackaday.io\nCredits:\n-HD44780 Library by SA Development\n-I\u00b2C Library by Peter Fleury\n","502":"##Environmental Data Logger\nThe design files and the software for a small low-power temperature and humidity logger\nProbably the most remarkable feature is the power consumption of just 3.2\u00b5A or less\na better documentation can be found on Hackaday.io\nCredits:\n-HD44780 Library by SA Development\n-I\u00b2C Library by Peter Fleury\n","503":"##Environmental Data Logger\nThe design files and the software for a small low-power temperature and humidity logger\nProbably the most remarkable feature is the power consumption of just 3.2\u00b5A or less\na better documentation can be found on Hackaday.io\nCredits:\n-HD44780 Library by SA Development\n-I\u00b2C Library by Peter Fleury\n","504":"EnvironmentalClub\n","505":" ,-----.,--.                  ,--. ,---.   ,--.,------.  ,------.\n'  .--.\/|  | ,---. ,--.,--. ,-|  || o   \\  |  ||  .-.  \\ |  .---'\n|  |    |  || .-. ||  ||  |' .-. |`..'  |  |  ||  |  \\  :|  `--, \n'  '--'\\|  |' '-' ''  ''  '\\ `-' | .'  \/   |  ||  '--'  \/|  `---.\n `-----'`--' `---'  `----'  `---'  `--'    `--'`-------' `------'\n----------------------------------------------------------------- \n\nWelcome to your Rails project on Cloud9 IDE!\nTo get started, just do the following:\n\nRun the project with the \"Run Project\" button in the menu bar on top of the IDE.\nPreview your new app by clicking on the URL that appears in the Run panel below (https:\/\/HOSTNAME\/).\n\nHappy coding!\nThe Cloud9 IDE team\nSupport & Documentation\nVisit http:\/\/docs.c9.io for support, or to learn more about using Cloud9 IDE.\nTo watch some training videos, visit http:\/\/www.youtube.com\/user\/c9ide\n","506":"EnvironmentalMonitoring\narduino code\n","507":"EnvironmentalConfiguration\n\n\nA lightweight configuration library for .NET projects, built to support configuration for multiple environments from within the same configuration file.\n","508":"Environmental Sensing with AWS IoT\nA project for environmental sensing - pH, various gases, particulate matter, sound and capturing images\nThis is multi-part project to demonstrate environmental monitoring using several types of sensors and AWS services. The first part focuses on building the hardware and monitoring environmental parameters such as CO2, particulate matter, sound and capturing images. This project can be used for environmental monitoring in several use cases such as Industrial Manufacturing, Distribution Warehouses etc.\nThe first version of the environmental sensor box and the software along with it is capable of the following features:\n\nSense temperature, humidity, pressure, CO2, tvoc, proximity, and range and publish them to AWS IoT Core.\nCapture and upload images to an Amazon S3 bucket.\nThe project also uses the AWS Systems Manager to enable remote access to the Raspberry Pi.\nHow to use AWS IoT Rules to log data to Amazon Elasticsearch Service\n\nA second version of the project retains the temperature, humidity, pressure, CO2, tvoc, proximity, and replaces the camera and the range sensor with a pH sensor from Atlas Scientific in a smaller enclosure. The source code remains the same.\nApplications\npH\nThe pH sensor can be used to monitor several industrial and agricultural parameters:\n\nDough Fermentation\nSoil pH - different crops and plants need specific levels of pH in the soil.\n\nHardware and Mechanical\nList of off the shelf hardware used to build the environmental sensing unit:\n\nRaspberry Pi Zero W\nSparkFun Qwiic Kit for Raspberry Pi\nUltrasonic Range Finder - HRXL-MaxSonar-VR\n\nThe unit supports a camera with Raspberry Pi to capture images and load them to AWS S3.\nThe camera used:\n\nArducam Lens Board SKU B0031\n\nYou could use any other compatible camera as well.\nHere is the information on the pH sensor, pH reading circuit and the smaller enclosure:\n\nAtlas Scientific Spear Tip pH Probe\nEZO pH Circuit\nEZO Carrier Board\nSmaller Enclosure\n\nPlease note that the code was tested with an earlier version of the Spear Tip probe and EZO circuits - however the new probe and circuit will work fine. Also important to note that by default the carrier board is in UART mode, and has to be re-programmed to support the I2C mode which is used in this project. The carrier board interfaces with a Qwiic cable to the Qwiic hat.\nA baseplate was designed and 3D printed to house the components in the following case bought from Amazon.com:\n\nUniversal Project Enclosure\n\nHere is an image of the assembled unit:\n\nThe first iteration of this does not support the PM2.5 (Particulate Matter 2.5) sensing - but you can see the sensor PMS7003 below the camera in the image.\nHere is an image of the version with pH support:\n\nArchitecture\nHere is a high level architecture of the first iteration\/part of this project:\n\nConfigure & Setup AWS IoT\nRead through Setting up AWS IoT and Create a Thing. Once you have created a thing for the Raspberry Pi - make sure that the keys are present in the 'keys' subfolder. Also copy the sampleenv file as .env and provide the specifics - you will need these\nLogging data to AWS IoT Core\nPrior to logging data - you should take the sampleenv file - copy it to .env and then make sure that al parameters are set correctly.\nRun the script rpiQwiicAWSIoT.py to read sensor data and log to AWS IoT Core. The script calls two helper modules:\n\nimageCapture.py - to capture an image using hte picamera package, and upload it to S3. Note that the S3 bucket name has to be specified in the .env file.\nultraSonic.py - this script reads the value from the Range Finder sensor if connected.\n\nTwo flags are used to control the import and execution of the above modules - S3_ENABLE and ULTRA_ENABLE in the .env file.\n\nIf you want to exclude both or one of them - set the flag to an emptry string.\nIf the module is to be included then set it to 'True'\n\nSee example below:\nS3_ENABLE='True'\nULTRA_ENABLE=''\nOnce the .env file is configured correctly - you can start tbe execution as follows:\npython3 rpiQwiicAWSIoT.py\nIf you want to run the program in the background, and ensure it keeps running when you disconnect your remote session in to the Raspberry Pi then execute the following:\nnohup python3 -u .\/rpiQwiicAWSIoT.py > output.log &\n\nYou can now go to the \"Test\" secion of the AWS IoT Console, and subscribe to the topic that you are using. The topic used for testing was the following:\ntelemetry\/<thing_name>\nSample output from the unit:\n{\n  \"timestamp\": 1583361438,\n  \"time\": \"03-04-2020 17:37:17\",\n  \"tempc\": 27.63,\n  \"tempf\": 81.752,\n  \"humidity\": 34.475,\n  \"pressure\": 106.863,\n  \"tvoc\": 0,\n  \"co2\": 400,\n  \"proximity\": 2556,\n  \"ambient\": 128,\n  \"image\": \"pzb827ebed3f9a-1583361438\"\n}\nThe data above is not using the Ultrasonic sensor readings and does not have them. The data packet also provides the image that was captured and the filename used to store in the S3 bucket.\nStoring data with Amazon Elasticsearch\nWe will use Amazon Elasticsearch to store transformed data and later on use it for visualization. Setup a Amazon Elasticsearch in the same region as you have used to create the IoT thing. Once your Elasticsearch is setup, go to the AWS IoT console, and setup an IoT rule. See the image below on how it is setup.\nThis the specific IoT rule being used to transform the incoming packets:\nSELECT topic(2) as thing_name, timestamp, parse_time(\"yyyy-MM-dd'T'HH:mm:ssZZ\", timestamp(), \"America\/New_York\" ) as ts, tempf, tempc, humidity, pressure, co2, ambient, tvoc, proximity FROM 'telemetry\/+'\nThis rule does minor transformation of the incoming data message, and the output should look as follows:\n{\n  \"thing_name\": \"pzb827ebed3f9a\",\n  \"timestamp\": 1583361502,\n  \"ts\": \"2020-03-04T17:38:26-05:00\",\n  \"tempf\": 82.058,\n  \"tempc\": 27.81,\n  \"humidity\": 34.288,\n  \"pressure\": 106.548,\n  \"co2\": 400,\n  \"ambient\": 125,\n  \"tvoc\": 0,\n  \"proximity\": 2555\n}\n","509":"Environmental Sensing with AWS IoT\nA project for environmental sensing - pH, various gases, particulate matter, sound and capturing images\nThis is multi-part project to demonstrate environmental monitoring using several types of sensors and AWS services. The first part focuses on building the hardware and monitoring environmental parameters such as CO2, particulate matter, sound and capturing images. This project can be used for environmental monitoring in several use cases such as Industrial Manufacturing, Distribution Warehouses etc.\nThe first version of the environmental sensor box and the software along with it is capable of the following features:\n\nSense temperature, humidity, pressure, CO2, tvoc, proximity, and range and publish them to AWS IoT Core.\nCapture and upload images to an Amazon S3 bucket.\nThe project also uses the AWS Systems Manager to enable remote access to the Raspberry Pi.\nHow to use AWS IoT Rules to log data to Amazon Elasticsearch Service\n\nA second version of the project retains the temperature, humidity, pressure, CO2, tvoc, proximity, and replaces the camera and the range sensor with a pH sensor from Atlas Scientific in a smaller enclosure. The source code remains the same.\nApplications\npH\nThe pH sensor can be used to monitor several industrial and agricultural parameters:\n\nDough Fermentation\nSoil pH - different crops and plants need specific levels of pH in the soil.\n\nHardware and Mechanical\nList of off the shelf hardware used to build the environmental sensing unit:\n\nRaspberry Pi Zero W\nSparkFun Qwiic Kit for Raspberry Pi\nUltrasonic Range Finder - HRXL-MaxSonar-VR\n\nThe unit supports a camera with Raspberry Pi to capture images and load them to AWS S3.\nThe camera used:\n\nArducam Lens Board SKU B0031\n\nYou could use any other compatible camera as well.\nHere is the information on the pH sensor, pH reading circuit and the smaller enclosure:\n\nAtlas Scientific Spear Tip pH Probe\nEZO pH Circuit\nEZO Carrier Board\nSmaller Enclosure\n\nPlease note that the code was tested with an earlier version of the Spear Tip probe and EZO circuits - however the new probe and circuit will work fine. Also important to note that by default the carrier board is in UART mode, and has to be re-programmed to support the I2C mode which is used in this project. The carrier board interfaces with a Qwiic cable to the Qwiic hat.\nA baseplate was designed and 3D printed to house the components in the following case bought from Amazon.com:\n\nUniversal Project Enclosure\n\nHere is an image of the assembled unit:\n\nThe first iteration of this does not support the PM2.5 (Particulate Matter 2.5) sensing - but you can see the sensor PMS7003 below the camera in the image.\nHere is an image of the version with pH support:\n\nArchitecture\nHere is a high level architecture of the first iteration\/part of this project:\n\nConfigure & Setup AWS IoT\nRead through Setting up AWS IoT and Create a Thing. Once you have created a thing for the Raspberry Pi - make sure that the keys are present in the 'keys' subfolder. Also copy the sampleenv file as .env and provide the specifics - you will need these\nLogging data to AWS IoT Core\nPrior to logging data - you should take the sampleenv file - copy it to .env and then make sure that al parameters are set correctly.\nRun the script rpiQwiicAWSIoT.py to read sensor data and log to AWS IoT Core. The script calls two helper modules:\n\nimageCapture.py - to capture an image using hte picamera package, and upload it to S3. Note that the S3 bucket name has to be specified in the .env file.\nultraSonic.py - this script reads the value from the Range Finder sensor if connected.\n\nTwo flags are used to control the import and execution of the above modules - S3_ENABLE and ULTRA_ENABLE in the .env file.\n\nIf you want to exclude both or one of them - set the flag to an emptry string.\nIf the module is to be included then set it to 'True'\n\nSee example below:\nS3_ENABLE='True'\nULTRA_ENABLE=''\nOnce the .env file is configured correctly - you can start tbe execution as follows:\npython3 rpiQwiicAWSIoT.py\nIf you want to run the program in the background, and ensure it keeps running when you disconnect your remote session in to the Raspberry Pi then execute the following:\nnohup python3 -u .\/rpiQwiicAWSIoT.py > output.log &\n\nYou can now go to the \"Test\" secion of the AWS IoT Console, and subscribe to the topic that you are using. The topic used for testing was the following:\ntelemetry\/<thing_name>\nSample output from the unit:\n{\n  \"timestamp\": 1583361438,\n  \"time\": \"03-04-2020 17:37:17\",\n  \"tempc\": 27.63,\n  \"tempf\": 81.752,\n  \"humidity\": 34.475,\n  \"pressure\": 106.863,\n  \"tvoc\": 0,\n  \"co2\": 400,\n  \"proximity\": 2556,\n  \"ambient\": 128,\n  \"image\": \"pzb827ebed3f9a-1583361438\"\n}\nThe data above is not using the Ultrasonic sensor readings and does not have them. The data packet also provides the image that was captured and the filename used to store in the S3 bucket.\nStoring data with Amazon Elasticsearch\nWe will use Amazon Elasticsearch to store transformed data and later on use it for visualization. Setup a Amazon Elasticsearch in the same region as you have used to create the IoT thing. Once your Elasticsearch is setup, go to the AWS IoT console, and setup an IoT rule. See the image below on how it is setup.\nThis the specific IoT rule being used to transform the incoming packets:\nSELECT topic(2) as thing_name, timestamp, parse_time(\"yyyy-MM-dd'T'HH:mm:ssZZ\", timestamp(), \"America\/New_York\" ) as ts, tempf, tempc, humidity, pressure, co2, ambient, tvoc, proximity FROM 'telemetry\/+'\nThis rule does minor transformation of the incoming data message, and the output should look as follows:\n{\n  \"thing_name\": \"pzb827ebed3f9a\",\n  \"timestamp\": 1583361502,\n  \"ts\": \"2020-03-04T17:38:26-05:00\",\n  \"tempf\": 82.058,\n  \"tempc\": 27.81,\n  \"humidity\": 34.288,\n  \"pressure\": 106.548,\n  \"co2\": 400,\n  \"ambient\": 125,\n  \"tvoc\": 0,\n  \"proximity\": 2555\n}\n","510":"Environmental Sensing with AWS IoT\nA project for environmental sensing - pH, various gases, particulate matter, sound and capturing images\nThis is multi-part project to demonstrate environmental monitoring using several types of sensors and AWS services. The first part focuses on building the hardware and monitoring environmental parameters such as CO2, particulate matter, sound and capturing images. This project can be used for environmental monitoring in several use cases such as Industrial Manufacturing, Distribution Warehouses etc.\nThe first version of the environmental sensor box and the software along with it is capable of the following features:\n\nSense temperature, humidity, pressure, CO2, tvoc, proximity, and range and publish them to AWS IoT Core.\nCapture and upload images to an Amazon S3 bucket.\nThe project also uses the AWS Systems Manager to enable remote access to the Raspberry Pi.\nHow to use AWS IoT Rules to log data to Amazon Elasticsearch Service\n\nA second version of the project retains the temperature, humidity, pressure, CO2, tvoc, proximity, and replaces the camera and the range sensor with a pH sensor from Atlas Scientific in a smaller enclosure. The source code remains the same.\nApplications\npH\nThe pH sensor can be used to monitor several industrial and agricultural parameters:\n\nDough Fermentation\nSoil pH - different crops and plants need specific levels of pH in the soil.\n\nHardware and Mechanical\nList of off the shelf hardware used to build the environmental sensing unit:\n\nRaspberry Pi Zero W\nSparkFun Qwiic Kit for Raspberry Pi\nUltrasonic Range Finder - HRXL-MaxSonar-VR\n\nThe unit supports a camera with Raspberry Pi to capture images and load them to AWS S3.\nThe camera used:\n\nArducam Lens Board SKU B0031\n\nYou could use any other compatible camera as well.\nHere is the information on the pH sensor, pH reading circuit and the smaller enclosure:\n\nAtlas Scientific Spear Tip pH Probe\nEZO pH Circuit\nEZO Carrier Board\nSmaller Enclosure\n\nPlease note that the code was tested with an earlier version of the Spear Tip probe and EZO circuits - however the new probe and circuit will work fine. Also important to note that by default the carrier board is in UART mode, and has to be re-programmed to support the I2C mode which is used in this project. The carrier board interfaces with a Qwiic cable to the Qwiic hat.\nA baseplate was designed and 3D printed to house the components in the following case bought from Amazon.com:\n\nUniversal Project Enclosure\n\nHere is an image of the assembled unit:\n\nThe first iteration of this does not support the PM2.5 (Particulate Matter 2.5) sensing - but you can see the sensor PMS7003 below the camera in the image.\nHere is an image of the version with pH support:\n\nArchitecture\nHere is a high level architecture of the first iteration\/part of this project:\n\nConfigure & Setup AWS IoT\nRead through Setting up AWS IoT and Create a Thing. Once you have created a thing for the Raspberry Pi - make sure that the keys are present in the 'keys' subfolder. Also copy the sampleenv file as .env and provide the specifics - you will need these\nLogging data to AWS IoT Core\nPrior to logging data - you should take the sampleenv file - copy it to .env and then make sure that al parameters are set correctly.\nRun the script rpiQwiicAWSIoT.py to read sensor data and log to AWS IoT Core. The script calls two helper modules:\n\nimageCapture.py - to capture an image using hte picamera package, and upload it to S3. Note that the S3 bucket name has to be specified in the .env file.\nultraSonic.py - this script reads the value from the Range Finder sensor if connected.\n\nTwo flags are used to control the import and execution of the above modules - S3_ENABLE and ULTRA_ENABLE in the .env file.\n\nIf you want to exclude both or one of them - set the flag to an emptry string.\nIf the module is to be included then set it to 'True'\n\nSee example below:\nS3_ENABLE='True'\nULTRA_ENABLE=''\nOnce the .env file is configured correctly - you can start tbe execution as follows:\npython3 rpiQwiicAWSIoT.py\nIf you want to run the program in the background, and ensure it keeps running when you disconnect your remote session in to the Raspberry Pi then execute the following:\nnohup python3 -u .\/rpiQwiicAWSIoT.py > output.log &\n\nYou can now go to the \"Test\" secion of the AWS IoT Console, and subscribe to the topic that you are using. The topic used for testing was the following:\ntelemetry\/<thing_name>\nSample output from the unit:\n{\n  \"timestamp\": 1583361438,\n  \"time\": \"03-04-2020 17:37:17\",\n  \"tempc\": 27.63,\n  \"tempf\": 81.752,\n  \"humidity\": 34.475,\n  \"pressure\": 106.863,\n  \"tvoc\": 0,\n  \"co2\": 400,\n  \"proximity\": 2556,\n  \"ambient\": 128,\n  \"image\": \"pzb827ebed3f9a-1583361438\"\n}\nThe data above is not using the Ultrasonic sensor readings and does not have them. The data packet also provides the image that was captured and the filename used to store in the S3 bucket.\nStoring data with Amazon Elasticsearch\nWe will use Amazon Elasticsearch to store transformed data and later on use it for visualization. Setup a Amazon Elasticsearch in the same region as you have used to create the IoT thing. Once your Elasticsearch is setup, go to the AWS IoT console, and setup an IoT rule. See the image below on how it is setup.\nThis the specific IoT rule being used to transform the incoming packets:\nSELECT topic(2) as thing_name, timestamp, parse_time(\"yyyy-MM-dd'T'HH:mm:ssZZ\", timestamp(), \"America\/New_York\" ) as ts, tempf, tempc, humidity, pressure, co2, ambient, tvoc, proximity FROM 'telemetry\/+'\nThis rule does minor transformation of the incoming data message, and the output should look as follows:\n{\n  \"thing_name\": \"pzb827ebed3f9a\",\n  \"timestamp\": 1583361502,\n  \"ts\": \"2020-03-04T17:38:26-05:00\",\n  \"tempf\": 82.058,\n  \"tempc\": 27.81,\n  \"humidity\": 34.288,\n  \"pressure\": 106.548,\n  \"co2\": 400,\n  \"ambient\": 125,\n  \"tvoc\": 0,\n  \"proximity\": 2555\n}\n","511":"DAT257\/DIT257- Agile software project management - Team Phish\nUN sustainability project for course in agile management.\nThe goal selected was Goal 13 Climate Action\nTeam members\nUsernames  - Real name\nPontare25\nDarclander\nadrianhak\nCladnic\nmunchgar\nHersiZa\nMotivation\nThis project was created as part of a course (DAT257\/DIT257- Agile software project management) taught at Chalmers University in collaboration with the University of Gothenburg. The primary motivateion behind the project was to learn to use Agile (and SCRUM) as a developer framework.\nInstallation\nTo run the application we recommend using IntelliJ.\n\nClone the repository\nRun the application using the Maven tab, scroll down to JavaFX and use the javaFX:run option (In IntelliJ the Maven tab is located at the top right).\n\n\nOBS! This is a Maven project using dependencies from JavaFX. Large portions of the program will run using the regular run button, but some dependencies require the maven support.\nHow to use\nFirst follow the steps in Installation. Once you have run the application using the Maven tab the application will urge you to either sign in or register.\n\nRegister: Register by entering the prompts.\nLog in: Either log in using the credentials you entered in the register section or use the Demo credentials. Username: Demo, Password: pass.\n\nOnce logged in you are greted with a homescreen with some information about the application and the UN goal 13\n\nAt the top you will find the global navigator where the main sectins are: Home, Calculator, Statistics, Vehicles, and All Emissions.\nIn the Calculator section you will be able to log all the relevant activity data for your personal emissions, for example, food and personal transport\n\n\nFrom which you can add both vehicles and activities. You need to have registered a vehicle to add a transport activity.\nAt the bottom you will find the Results section which summarises the different emission activities and allows for filteering of categories and dates.\n\nFor more in depth knowledge of the emissions we turn to the global navigator Statistics section\n\nHere we can more graphically break down exactly which activities are most responsible for the emissions.\n\n\nAPI Reference\n\nThis project was developed using java version 14.01. There have been some issues with using older versions so if there are issues with running we recommend using this version or later. These are set in the pom.xml file and the .iml file.\nMaven 4.0.0\nDateAxis\n\nBelow are a list of the external dependencies handled by Maven (see pom.xml file)\n\nMaven compiler version 3.8.0\njavafx-maven-plugin version 0.0.4\nFor JavaFX we use org.openjfx version 14\nFor SQLite Database we use version 3.32.3\n\nFrameworks used\n\nGUI: JavaFX (openjfx) 14\nDatabase: SQLite, SQLite dependency for Maven\nFor managing dependencies Maven has been used.\n\nCredits\n\nDateAxis for charts: Christian Schudt and Diego Cirujano\nSetting up JavaFX and Maven: ByteSmyth Easiest JavaFX Setup, IntelliJ + Maven with Debugger (2020)\nOrganising JavaFX windows: Software Development Tutorials GUI Application Development using JavaFX with Scene Builder\nUN Sustainability goal 13 graphics\n\n","512":"Environmental Monitor (Raspberry Pi Zero W)\n\nDocumentation on Wordpress\nIntro\nThe final assignment is to create a environmental monitor that is connected to internet and send data to a serve\/database.\n","513":"EnvironmentalSensors\nhttps:\/\/user-images.githubusercontent.com\/12248815\/29771433-53faa10c-8c11-11e7-82ce-36de73631b2d.png\n","514":"BODO\nPetroleum analysis in Niger Delta\n","515":"EnvironmentalConfiguration\n\n\nA lightweight configuration library for .NET projects, built to support configuration for multiple environments from within the same configuration file.\n","516":"EnvironmentalConfiguration\n\n\nA lightweight configuration library for .NET projects, built to support configuration for multiple environments from within the same configuration file.\n","517":"EnvironmentalConfiguration\n\n\nA lightweight configuration library for .NET projects, built to support configuration for multiple environments from within the same configuration file.\n","518":"EnvironmentalConfiguration\n\n\nA lightweight configuration library for .NET projects, built to support configuration for multiple environments from within the same configuration file.\n","519":"EnvironmentalViolence\nEnvironmentalViolence\n","520":" ,-----.,--.                  ,--. ,---.   ,--.,------.  ,------.\n'  .--.\/|  | ,---. ,--.,--. ,-|  || o   \\  |  ||  .-.  \\ |  .---'\n|  |    |  || .-. ||  ||  |' .-. |`..'  |  |  ||  |  \\  :|  `--, \n'  '--'\\|  |' '-' ''  ''  '\\ `-' | .'  \/   |  ||  '--'  \/|  `---.\n `-----'`--' `---'  `----'  `---'  `--'    `--'`-------' `------'\n----------------------------------------------------------------- \n\nWelcome to your Rails project on Cloud9 IDE!\nTo get started, just do the following:\n\nRun the project with the \"Run Project\" button in the menu bar on top of the IDE.\nPreview your new app by clicking on the URL that appears in the Run panel below (https:\/\/HOSTNAME\/).\n\nHappy coding!\nThe Cloud9 IDE team\nSupport & Documentation\nVisit http:\/\/docs.c9.io for support, or to learn more about using Cloud9 IDE.\nTo watch some training videos, visit http:\/\/www.youtube.com\/user\/c9ide\n","521":"The previous contents of this repository have been migrated to https:\/\/github.com\/DLFMetadataAssessment\/DLFMetadataAssessment.github.io as of October 2019.\nFor the site previously housed in this repository, please see [https:\/\/dlfmetadataassessment.github.io\/EnvironmentalScan\/)(https:\/\/dlfmetadataassessment.github.io\/EnvironmentalScan\/).\n","522":"\u4e00\u4e2a\u7528\u4e8e\u5b9e\u65f6\u663e\u793a\u76d1\u63a7\u6570\u636e\u7684app\uff0c\u4f7f\u7528retrofit\u4ece\u670d\u52a1\u5668\u5f97\u5230\u6570\u636e\uff0c\u4f7f\u7528hellocharts\u5e93\u8fdb\u884c\u56fe\u6807\u7684\u663e\u793a\n","523":"Environmental Governance Data Analysis in R\nThis is an example of code that I have used in an academic project.\n","524":"Environmental Governance Data Analysis in R\nThis is an example of code that I have used in an academic project.\n","525":"EnvironmentalSensor\n\u30aa\u30e0\u30ed\u30f3\u74b0\u5883\u30bb\u30f3\u30b5\u30fc\u3092\u6271\u3046\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\n\n\n\u4f7f\u7528\u3059\u308b\u74b0\u5883\u30bb\u30f3\u30b5\n\u30aa\u30e0\u30ed\u30f3 \u74b0\u5883\u30bb\u30f3\u30b5\uff08USB\u30bf\u30a4\u30d7\uff09 2JCIE-BU01\n\n\n\u7247\u624b\u9593\u958b\u767a\u306e\u305f\u3081\u3001\u4e0d\u5b9a\u671f\u66f4\u65b0\n\n\n\u958b\u767a\u9014\u4e2d\u306e\u305f\u3081\u3001\u9014\u4e2d\u3067\u4ed5\u69d8\u5909\u66f4\u3055\u308c\u308b\u53ef\u80fd\u6027\u5927\n\n\n","526":"EnvironmentalSensor\n\u30aa\u30e0\u30ed\u30f3\u74b0\u5883\u30bb\u30f3\u30b5\u30fc\u3092\u6271\u3046\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\n\n\n\u4f7f\u7528\u3059\u308b\u74b0\u5883\u30bb\u30f3\u30b5\n\u30aa\u30e0\u30ed\u30f3 \u74b0\u5883\u30bb\u30f3\u30b5\uff08USB\u30bf\u30a4\u30d7\uff09 2JCIE-BU01\n\n\n\u7247\u624b\u9593\u958b\u767a\u306e\u305f\u3081\u3001\u4e0d\u5b9a\u671f\u66f4\u65b0\n\n\n\u958b\u767a\u9014\u4e2d\u306e\u305f\u3081\u3001\u9014\u4e2d\u3067\u4ed5\u69d8\u5909\u66f4\u3055\u308c\u308b\u53ef\u80fd\u6027\u5927\n\n\n","527":" This is a project that a had the idea to do \n It is an info page about the actual environmental problems that we face. \n","528":" This is a project that a had the idea to do \n It is an info page about the actual environmental problems that we face. \n","529":"EnvironmentalProtection\n","530":"PECT: Power Externality Correlation Tool\nQuantifying the environmental impacts of electricity purchased from the grid\nLicense: LGPL\nVersion: 1.2.0.0\nNew! Google Colaboratory Option: https:\/\/colab.research.google.com\/drive\/1UWDTphLkr8tja5R0HPN9nE66_8kPPYCx\nNew! Read the paper (open access): https:\/\/doi.org\/10.1016\/j.softx.2018.12.001\nThis script can be used to model the water consumption, water withdrawal, CO2 emissions, NOx emissions and SO2 emissions attributed to the power generation fuel mix within a specific location over a specified time frame. If the PECT.ipynb file is used in google colaboratory then there are no software requirments for running the script and obtaining outputs. However, it is best to use Google Chrome. Other browsers such as Firefox throw Network Errors when the script attempts to download the results file.\nNOTE: The emissions factors used in this script are calculated with the eGRID excel database included in this repository. This database is updated every two years. The most recent database can be found here: https:\/\/www.epa.gov\/energy\/emissions-generation-resource-integrated-database-egrid. The most recent database should be downloaded and included in the working directory for best results. The FindEmission_Rates script will automatically use the most recent database in the directory as long as it contains \"egrid\" and the corresponding year in the name.\nUser Inputs:\n\nLocation: The location for which the numbers will correlate to (city, state, etc.)\nTime Frame: The start and end data\/time from which data will be pulled\nWattTime Credentials: Username and password for a valid WattTime API account\n\nOutputs:\n\nTime Array\nGeneration for each fuel type\nWater Consumption\nWater Withdrawal\nCOs, NOx and SO2 emissions\nEmission factors for each fuel type\nWater consumption and withdrawal factors for each fuel type\n\nInstructions (Colaboratory Notebook):\n\nClick on the link provided here: https:\/\/colab.research.google.com\/drive\/1UWDTphLkr8tja5R0HPN9nE66_8kPPYCx\nRun each cell and provide user inputs as directed\nResults file should be downloaded through your internet browser\n\nInstructions (Python File):\n\nDownload the electricityandenvironment zip file\nRun the Power_Ex.py or Power_Ex.ipynb file if using a jupyter notebook file with the necessary dependancies (Python3, urllib, numpy, pandas)\nNote: The FindEmission_Rates.py or FindEmission_Rates.ipynb file must be located in the same folder\nFollow the command prompts to input the necessary information corresponding to your desired data output\nThe output file will be located in the same directory as the Power_Ex.py file. It will be named Results.xlsx\n\nCite: Plewe, K. & Smith, A. D. PECT: A tool for computing the temporal and spatial variation of externalities related to power generation in the United States. SoftwareX 9, 61\u201367 (2019). doi:10.1016\/j.softx.2018.12.001\n","531":"PECT: Power Externality Correlation Tool\nQuantifying the environmental impacts of electricity purchased from the grid\nLicense: LGPL\nVersion: 1.2.0.0\nNew! Google Colaboratory Option: https:\/\/colab.research.google.com\/drive\/1UWDTphLkr8tja5R0HPN9nE66_8kPPYCx\nNew! Read the paper (open access): https:\/\/doi.org\/10.1016\/j.softx.2018.12.001\nThis script can be used to model the water consumption, water withdrawal, CO2 emissions, NOx emissions and SO2 emissions attributed to the power generation fuel mix within a specific location over a specified time frame. If the PECT.ipynb file is used in google colaboratory then there are no software requirments for running the script and obtaining outputs. However, it is best to use Google Chrome. Other browsers such as Firefox throw Network Errors when the script attempts to download the results file.\nNOTE: The emissions factors used in this script are calculated with the eGRID excel database included in this repository. This database is updated every two years. The most recent database can be found here: https:\/\/www.epa.gov\/energy\/emissions-generation-resource-integrated-database-egrid. The most recent database should be downloaded and included in the working directory for best results. The FindEmission_Rates script will automatically use the most recent database in the directory as long as it contains \"egrid\" and the corresponding year in the name.\nUser Inputs:\n\nLocation: The location for which the numbers will correlate to (city, state, etc.)\nTime Frame: The start and end data\/time from which data will be pulled\nWattTime Credentials: Username and password for a valid WattTime API account\n\nOutputs:\n\nTime Array\nGeneration for each fuel type\nWater Consumption\nWater Withdrawal\nCOs, NOx and SO2 emissions\nEmission factors for each fuel type\nWater consumption and withdrawal factors for each fuel type\n\nInstructions (Colaboratory Notebook):\n\nClick on the link provided here: https:\/\/colab.research.google.com\/drive\/1UWDTphLkr8tja5R0HPN9nE66_8kPPYCx\nRun each cell and provide user inputs as directed\nResults file should be downloaded through your internet browser\n\nInstructions (Python File):\n\nDownload the electricityandenvironment zip file\nRun the Power_Ex.py or Power_Ex.ipynb file if using a jupyter notebook file with the necessary dependancies (Python3, urllib, numpy, pandas)\nNote: The FindEmission_Rates.py or FindEmission_Rates.ipynb file must be located in the same folder\nFollow the command prompts to input the necessary information corresponding to your desired data output\nThe output file will be located in the same directory as the Power_Ex.py file. It will be named Results.xlsx\n\nCite: Plewe, K. & Smith, A. D. PECT: A tool for computing the temporal and spatial variation of externalities related to power generation in the United States. SoftwareX 9, 61\u201367 (2019). doi:10.1016\/j.softx.2018.12.001\n","532":"PECT: Power Externality Correlation Tool\nQuantifying the environmental impacts of electricity purchased from the grid\nLicense: LGPL\nVersion: 1.2.0.0\nNew! Google Colaboratory Option: https:\/\/colab.research.google.com\/drive\/1UWDTphLkr8tja5R0HPN9nE66_8kPPYCx\nNew! Read the paper (open access): https:\/\/doi.org\/10.1016\/j.softx.2018.12.001\nThis script can be used to model the water consumption, water withdrawal, CO2 emissions, NOx emissions and SO2 emissions attributed to the power generation fuel mix within a specific location over a specified time frame. If the PECT.ipynb file is used in google colaboratory then there are no software requirments for running the script and obtaining outputs. However, it is best to use Google Chrome. Other browsers such as Firefox throw Network Errors when the script attempts to download the results file.\nNOTE: The emissions factors used in this script are calculated with the eGRID excel database included in this repository. This database is updated every two years. The most recent database can be found here: https:\/\/www.epa.gov\/energy\/emissions-generation-resource-integrated-database-egrid. The most recent database should be downloaded and included in the working directory for best results. The FindEmission_Rates script will automatically use the most recent database in the directory as long as it contains \"egrid\" and the corresponding year in the name.\nUser Inputs:\n\nLocation: The location for which the numbers will correlate to (city, state, etc.)\nTime Frame: The start and end data\/time from which data will be pulled\nWattTime Credentials: Username and password for a valid WattTime API account\n\nOutputs:\n\nTime Array\nGeneration for each fuel type\nWater Consumption\nWater Withdrawal\nCOs, NOx and SO2 emissions\nEmission factors for each fuel type\nWater consumption and withdrawal factors for each fuel type\n\nInstructions (Colaboratory Notebook):\n\nClick on the link provided here: https:\/\/colab.research.google.com\/drive\/1UWDTphLkr8tja5R0HPN9nE66_8kPPYCx\nRun each cell and provide user inputs as directed\nResults file should be downloaded through your internet browser\n\nInstructions (Python File):\n\nDownload the electricityandenvironment zip file\nRun the Power_Ex.py or Power_Ex.ipynb file if using a jupyter notebook file with the necessary dependancies (Python3, urllib, numpy, pandas)\nNote: The FindEmission_Rates.py or FindEmission_Rates.ipynb file must be located in the same folder\nFollow the command prompts to input the necessary information corresponding to your desired data output\nThe output file will be located in the same directory as the Power_Ex.py file. It will be named Results.xlsx\n\nCite: Plewe, K. & Smith, A. D. PECT: A tool for computing the temporal and spatial variation of externalities related to power generation in the United States. SoftwareX 9, 61\u201367 (2019). doi:10.1016\/j.softx.2018.12.001\n","533":"Bayesian-Environmental-Modeling-Course-exercises\nR-scripts generated from 2017 Bayesian Environmental Modeling course at UFZ in Leipzig to be shared with students and instructors\nThere are 6 files: two each on sensitivity analyses (Sobol's and Morris elementary effects), on basics of Bayesian inference (Bayesian inference and Bayesian least squares), and on numerics for Bayesian methods (Markov chain Monte Carlo simulations and optimization). These refer to exercises from the day 1, 2, and 3 of the course respectively. Several input files (.dat or .txt) are included.\n","534":"Bayesian-Environmental-Modeling-Course-exercises\nR-scripts generated from 2017 Bayesian Environmental Modeling course at UFZ in Leipzig to be shared with students and instructors\nThere are 6 files: two each on sensitivity analyses (Sobol's and Morris elementary effects), on basics of Bayesian inference (Bayesian inference and Bayesian least squares), and on numerics for Bayesian methods (Markov chain Monte Carlo simulations and optimization). These refer to exercises from the day 1, 2, and 3 of the course respectively. Several input files (.dat or .txt) are included.\n","535":"Environmental Monitor\nParticle based environmental monitor\nAbout\nThis project was created to help better understand and utilize Particle devices and systems.\nThe goal is to monitor temperature and humidity in a controlled environment, such as a reptile enclosure (in my case).\nRequirements\nParticle device such as an Argon, 3 pin DHT11 temp and humidity sensor.\nKnown bugs\nOccasionally reports extremely high or low temperature incorrectly which may cause LED to change to red or blue unexpetedly.  Does not impact functionality.\n\n","536":"Multirotors\nResearch in Andrew Bennett's Lab. Using Multirotors to conduct environmental exploration, sensing, and sampling missions.\nProjects\nThis code repository contains the mission files and the general architecture for several mission types which can be executed with drones, namely:\n\nBreath Condensate Collection from a Cetacean\nWireless Tracker Tagging for a large Cetacean\nPhotogrammetry for Animal Studies\nPoint-of-Interest Data Collection\nEnvironmental Exploration\nWaypoint Navigation\nSense and Avoid of Unfriendly Multirotors\n\nEach of these missions is designed in a mission file. This mission file is then executed by a generic autonomy structure based upon State Configured Layer Control (SCLC) which controls the actions of the drone.\nRunning this Code\nStill under construction\nRC override:\nAll computer control can be overridden by switching ch. 6 on the transmitter to a value greater than 1500.\nkeyboard controls:\nm = stabilize (sort of manual)\nl = loiter\no = auto\nr = arm\nt = disarm\np = open planner\njoystick controls:\nspecific to joystick and not finalized yet\n","537":"environmentalMonitor\nD1mini + BME280, CCS811\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u7d44\u307f\u5408\u308f\u305b\u305f\u74b0\u5883\u30e2\u30cb\u30bf\u3067\u3059\u3002\n\u6e29\u5ea6\u3001\u6e7f\u5ea6\u3001\u6c17\u5727\u3001CO2,\u3000TVOC\u5024\u3092\u4ea4\u4e92\u306b\u8868\u793a\u3057\u307e\u3059\u3002\u8868\u793a\u306f\u79cb\u6708\u306eI2C LCDmodule\u3092\u4f7f\u7528\u3057\u3066\u3044\u307e\u3059\u3002\n","538":"cafe-portal\nProject setup\nnpm install\n\nconfig files\nyou can configure the project by edit config\/config.json\nCompiles and hot-reloads for development\nnpm run serve:local\nnpm run start\n\nCompiles and minifies for production\nnpm run build\n\nServe APP at Prod environment\nnpm run serve\n\nLints and fixes files\nnpm run lint\n\n","539":"Environmental Mapping\n\nUsing WebGL and shaders to simulate enviormental reflection.\nLaunch Chrome with  --allow-file-access-from-files so that it can load the local models. Like this in OSX:\n\/Applications\/Google\\ Chrome.app\/Contents\/MacOS\/Google\\ Chrome --allow-file-access-from-files &\n\n","540":"environmentalSound\nimage data gotten from the es50 environmental sound dataset on kaggle, method of extraction was librosa mel spectrograms. each img is h:128 x w:157 in size and there are about 16000 of them. after processing X_img and y were pickled out and downloaded resulting in these files the labels are stored in the y.pickle\n","541":"environmentalSound\nimage data gotten from the es50 environmental sound dataset on kaggle, method of extraction was librosa mel spectrograms. each img is h:128 x w:157 in size and there are about 16000 of them. after processing X_img and y were pickled out and downloaded resulting in these files the labels are stored in the y.pickle\n","542":"EnvironmentalAnalysis\n\nWorks of GIS data processing and analysing\nsolving problems related to land coverage and air quality variations in the US and eastern Asia. I designed\nmodels to perform Geographic Information System database standardizing, and to analyze and visualize raw data.\nKriging approach using Scikit-learn package, interpolating multidimensional global air\nquality, as well as precipitation data.\n\n","543":"EnvironmentalAnalysis\n\nWorks of GIS data processing and analysing\nsolving problems related to land coverage and air quality variations in the US and eastern Asia. I designed\nmodels to perform Geographic Information System database standardizing, and to analyze and visualize raw data.\nKriging approach using Scikit-learn package, interpolating multidimensional global air\nquality, as well as precipitation data.\n\n","544":"EnvironmentalDay\n","545":"EnvironmentalGame\nThis game was developed for 'Environment Sciences' class in Universidade Federal do Rio Grande, Brazil.\n","546":"EnvironmentalGame\nThis game was developed for 'Environment Sciences' class in Universidade Federal do Rio Grande, Brazil.\n","547":"Allay - Alleviate environmental pain\nInstallation\nRequirements\n\nPython 2 (2.7 or greater) - https:\/\/www.python.org\/downloads\/\npip - https:\/\/pip.pypa.io\/en\/stable\/installing\/ or using brew (MacOS Users) brew install python - https:\/\/brew.sh\/\nDocker Toolbox or Docker for Windows\/Mac - https:\/\/docs.docker.com\/engine\/installation\/\n\n\nPrerequisite\n\n\nInstall magnet: pip install git+https:\/\/github.com\/brian-dlee\/magnet.git#egg=magnet\n\npip install git+https:\/\/github.com\/brian-dlee\/allay.git#egg=allay\nConfiguring database synchronization\n\nEnsure you have a volume configured to store database files and database schema files in volumes.yml.\nIn settings.yml, add a section for dbsync. All of the settings specified below are required.\n\ndbsync:\n  user: allay\n  host: mydbhost.com\n  schemas: schema1,schema2\n  schemas-volume: VOLUME_NAME[:OPTIONAL_PATH]\n  database-volume: VOLUME_NAME[:OPTIONAL_PATH]\n\nOptional properties include:\n\n(integer) schema_file_max_age Determines when a schema is deemed old (in days)\n(string)  remote_path Determines where to look for database schema files (default is $HOME\/database-schemas)\n\n\n\n\nConfigure your server\n\n\nCreate a user account to use for database synchronization\nConfigure user to write database SQL dumps to your desired location. Default is $HOME\/database-schemas.\nSchema files should be named according the schema they represent\nA schema file for schema1 will be stored at $HOME\/database-schemas\/schema1.sql.gz\nSetup key access for your user to access the new user account. Currently, this only supports the use of the default key at ~\/.ssh\/id_rsa.pub\n\nAll set! The next time allay runs it will try to connect to your host using the configured user account, run a comparison between the files currently found in the schemas-volume director and the corresponding files on the server and download them over SSH.\nNext, you should ensure your database container is equipped to ingest these schema files on initialization.\nWARNING: When allay downloads new schemas is deletes the contents of the database data directory to force the ingestion of the newly downloaded files.\n","548":"Clean-Afrik\nClean Afrik\nClean Afrik is a web application that aims to promote environmental health progression in Western Africa by providing educational resources\nand by supporting charities currently implrmenting environmental changes in Western Africa through an included merchandise store.\n","549":"QGIS-applications\nEnvironmental GIS applications.\nThe repository includes GIS open source environmental applications.\n","550":"\u667a\u80fd\u5bb6\u5c45\u73af\u5883\u76d1\u6d4b\u7cfb\u7edf\n\u6280\u672f\u6808\n1\u3001java(IO,NET,JDBC)\n2\u3001jdbc(java database connection)\n3\u3001oracel\n4\u3001xml(dom4j\u89e3\u6790)\n5\u3001log4j\n\u529f\u80fd\n1\u3001\u5b9a\u671f\u91c7\u96c6\uff08\u6b21\/\u5c0f\u65f6\uff09\u539f\u59cb\u73af\u5883Log\u6587\u4ef6\uff0c\u6574\u7406\u6210\u6e29\u5ea6,\u6e7f\u5ea6,\u4e8c\u6c27\u5316\u78b3\u6570\u636e\u6e05\u5355\uff0c\u5e76\u4e0a\u4f20\u7ed9\u4e2d\u5fc3\u5904\u7406\u7cfb\u7edf\u3002\n2\u3001\u4e2d\u5fc3\u5904\u7406\u7cfb\u7edf\uff08\u63a5\u6536\u7cfb\u7edf\uff09\u4fa6\u542c\u5e76\u6536\u96c6\u91c7\u96c6\u7cfb\u7edf\u53d1\u9001\u7684\u6570\u636e\u4fe1\u606f\u6e29\u5ea6\u548c\u6e7f\u5ea6\uff0c\u5e76\u5c06\u6570\u636e\u4fdd\u5b58\u7684\u6570\u636e\u5e93\u8868 t_detail_X(1-31)\n3\u3001\u91c7\u96c6\u539f\u59cb\u73af\u5883Log\u6587\u4ef6\uff0c\u6574\u7406\u6210Environment\u7c7b\u6570\u636e\u6e05\u5355\n4\u3001\u5c06\u91c7\u96c6\u7cfb\u7edf\u5ba2\u6237\u7aef\u91c7\u96c6\u5f62\u6210\u7684Environment\u7c7b\u6570\u636e\u6e05\u5355\u4f20\u8f93\u7ed9\u4f4d\u4e8e\u4e2d\u5fc3\u5904\u7406\u7cfb\u7edf\u7684\u670d\u52a1\u5668\u7aef\uff1b\n5\u3001\u8c03\u7528\u5165\u5e93\u6a21\u5757\u63d2\u5165\u6570\u636e\n6\u3001\u901a\u8fc7dom4\u89e3\u6790\uff0c\u4effSpringIOC\u5bb9\u5668\uff0c\u964d\u4f4e\u6a21\u5757\u4e4b\u95f4\u7684\u5076\u6838\u6027\n","551":"horus\nHORUS is a coastal and environmental video-based monitoring software made in MATLAB.\nThis system is divided in three modules: capture, processing and visualization.\n","552":"Config-Ninja\nA quick and easy way to load in config from disk or environment variables. Config-Ninja uses the NODE_ENV environment variable to determine whether your code is running in production mode, staging, or any other environment, otherwise development mode is assumed.\nOnce your config has been initialised Config-Ninja allows you to const config = require('config-ninja').use('my-config'); in any of your modules and get access to your config object.\nQuick Start\nCreate a directory to hold your config files and create a production.config.json file which will contain all your configuration properties. Then create a development.config.json file which will hold only the specific values that need to be different in your development environment. Then in your application entry point, e.g. index.js:\n\/\/ Prepare the ninja on application load.\nconst config = require('config-ninja').init('my-config', '\/path\/to\/cfg\/dir\/');\nTo load the config in other modules:\n\/\/ Load in the config again, taking advantage of Node's module caching.\nconst config = require('config-ninja').use('my-config');\n\n\/\/ Use the config!\nconsole.dir(config);\nconsole.log('Nested Number:', config.nested.number);  \/\/ See examples.\nExample: See example.js for a working example which you can run with node .\/examples\/example.\nImportant Notes\nProduction Config\nThe production config is always the default config. If you specify another environment such as staging or development, Config-Ninja will deep merge the properties from that environment into the production config, overwriting any values that already exist. You can nest properties as deeply as you like. Your files are not modified.\nSetup your Config Files\nYou will need at least 2 config files, one for production and one for development. You may also want config files for other environments such as staging. You can have as many files as you need.\n\/myConfig\n  \/production.config.json\n  \/staging.config.json\n  \/development.config.json\n  \/custom.config.json\n\nConfig ID\nThe config id you set needs to be unique for your application or module because of the way Node caches modules in memory. It's possible that your module and another dependency will be using the same instance of Config-Ninja.\nIf that happens and there is a collision of config ids an error will be thrown. One way to avoid this could be to use some information from your package.json to set the config id like this:\nconst packageJson = require(`.\/package.json`);\nconst config = require(`config-ninja`).init(`${packageJson.name}-${packageJson.version}-config`);\nReserved Property Names\nProperties in the top level of your config that begin with two underscores (i.e. __reload) are reserved names and should not be used as config properties.\nAdvanced Usage\nSpecify Extra Options\nYou can also specify some options when instantiating Config-Ninja. All options are optional and must be passed as a hash as the last parameter:\nconst config = require('config-ninja').init('my-config', '\/path\/to\/cfg\/dir\/', 'development', { ... });\nconst config = require('config-ninja').init('my-config', { ... });\nSee the API Overview below for the options you can specify.\nLocal Config\nYou may also wish to add local config files that are not committed to your repo but must be present on every developer's machine e.g. local.config.json. Use the ignore rules for your VCS (e.g. .gitignore) to ignore the local files and prevent them from being committed.\nBy default we assume you might have a local file called local.config.json. You can change this by passing in an array of names in the localConfig option. If you want to throw an error if any of the specified local config files are missing then set the requireLocalConfig option to true.\n\/\/ Default options for local config.\nconst config = require('config-ninja').init('my-config', {\n  localConfig: ['local'],\n  requireLocalConfig: false,\n});\nOverride the Config Directory\nBy default we assume the config files are located in current working directory + '\/config'. You can change this by passing in an absolute or relative path as the second parameter:\nconst config = require('config-ninja').init('my-config', '\/path\/to\/cfg\/dir\/');\nconst config = require('config-ninja').init('my-config', {\n  dir: '\/path\/to\/cfg\/dir\/',\n});\nOverride the Environment\nBy default production and development environment strings are understood. If you have additional environments you can override the environment string by passing in a third parameter called env, which matches the name of your config file (e.g. staging.config.json):\nconst config = require('config-ninja').init('my-config', '\/path\/to\/cfg\/dir\/', 'staging');\nconst config = require('config-ninja').init('my-config', {\n  dir: '\/path\/to\/cfg\/dir\/',\n  env: 'staging',\n});\nEnvironment Variables\nYou can also load config from the environment variables, and optionally from a .env file (see config options below). You'll need to provide a mapping of environment variable names to paths in your config to use this feature. Environment variables overwrite values in your config files even if they are empty strings, but you can avoid this if don't set them at all in the environment.\nNote: String representations of true, null false, integers and floats will be converted to their correct data types.\nWarning: The NODE_ENV environment variable cannot be loaded from a .env file and will be ignored.\nExample .env file:\nLOG_LEVEL=verbose\nNINJA_AWESOMENESS=\"very awesome\"\nOFFSET=5\nExample mapping configuration:\n{\n  environmentVariables: {\n    mapping: {\n      LOG_LEVEL: `logLevel`,\n      NINJA_AWESOMENESS: `how.awesome.are.ninjas`,\n      OFFSET: `timezoneOffset`,\n    }\n  }\n}\nAPI Overview\n.init(configId[, dir[, env[, options]]])\nSets up a new config object and returns it. Any of the following function signatures are acceptable:\n\n.init(configId)\n.init(configId, dir)\n.init(configId, dir, env)\n.init(configId, dir, env, options)\n.init(configId, dir, options)\n.init(configId, options)\n\nYou can specify the following options. You can either pass dir and env into the function as parameters, or add them as options, or rely on the default values.\n\n\n\nOption\nDefault\nDescription\n\n\n\n\ndir\n.\/config\nSet the directory where your config is stored. Relative paths are relative to the current working directory of your process.\n\n\nenv\n`process.env.NODE_ENV\n\n\n\nshortFilenames\nfalse\nSet true if you want to your config filenames to be in the format of development.json instead of the default development.config.json.\n\n\nenvironmentLevels\n{ production: 1, staging: 2, development: 3 }\nIf the property env is not already specified in your config files this option will set env.id to the environment string (e.g. \"production\"), and will set env.level to the corresponding integer specified in this option. Pass in a falsy value to disable this feature.\n\n\nlocalConfig[]\n['local']\nSpecify a list of other filenames to merge into your config, if the files don't exist they will just be ignored by default. Properties in local files will overwrite properties with the same name in your config.\n\n\nrequireLocalConfig\nfalse\nBy default we don't throw an error if a local config file is missing. Set true to throw an error instead.\n\n\nenvironmentVariables.enableDotenv\nfalse\nSet true to load in files from a .env file.\n\n\nenvironmentVariables.dotenvPath\nfalse\nOptionally provide a custom absolute path to the .env file.\n\n\nenvironmentVariables.mapping\n\nProvide a mapping of environment variables to paths in your config file (see the Environment Variables section above).\n\n\nsingle\n\nSet to a string e.g. \"my-settings\" if you only want to load a single config file e.g. \"my-settings.config.json\".\n\n\nimmutable\nfalse\nSet true to force the config objects to always be immutable.\n\n\nplain\nfalse\nSet true to always construct the config without any of the utility functions attached.\n\n\n\n.use(configId[, immutable[, plain]])\nReturn an existing config object that has been initialised with .init().\nYou can pass true as the second parameter to return a copy of the config, which prevents accidental changes to the config from propagating through to other modules. This has no affect if the immutable option was passed to .init() as true.\nYou can also pass true as the third parameter if you wish to return a plain copy of the config without the utility functions attached. This has no affect if the plain option was passed to .init().\n.wipe(configId)\nThis will remove the config from memory, allowing you to re-use an existing config id. This will NOT prevent other parts of your application from continuing to use the config if they have already got a reference to it from .use().\nConfig Overview\nOnce you have a config object you can use these utility functions:\nconfig.__inspect()\nReturns information about the config object, including some meta data and the options used to initialise the config in .init().\nconfig.__reload()\nReloads the config files from disk, using the original options passed to .init(). Returns the reloaded config, and if the immutable option is false it will also mutate the config object itself.\nWarning: This operation is synchronous and blocking.\nconfig.__switch(env)\nReloads the config files from disk and switches to the new environment specified, using the original options passed to .init(). Returns the new config, and if the immutable option is false it will also mutate the config object itself.\nWarning: This operation is synchronous and blocking.\nconfig.__addLocal(localConfig)\nReloads the config using the original options passed to .init(), but adds in the extra local config files you specify. Returns the reloaded config, and if the immutable option is false it will also mutate the config object itself.\nWarning: This operation is synchronous and blocking.\nconfig.__get(env)\nLoads and prepares the config for the specified environment as if we had initialised under than environment, without actually modifying the existing config.\nWarning: This operation is synchronous and blocking.\nconfig.__raw(env)\nReturns the raw JSON from the config file for the specified environment (from memory). Does not do any merging and does not mutate the existing config.\nconfig.__plain()\nReturns a copy of the config without any of the utility functions attached, just the plain properties from your config files.\nconfig.__trace()\nReturns a stack trace for when the config was first initialised (or reloaded\/switched\/etc) as an array of strings. Can be used for debugging to see which module and function instantiated the config object.\nFAQ\nHow can I tell which environment string my config was initialised with?\nBy default, the env.id property will be set inside your config. If you have manually specified a property called env in your config or the feature has been disabled (by setting the localConfig option) you can use the config.__inspect() method instead. This returns the options that were used to instantiate the config:\nconst inspection = config.__inspect();\nconsole.log(inspection.options.env);\nHow can I reload my config?\nSimply call config.__reload(). This will reload config files from disk and variables from the environment. See the Config Overview above.\nHow can I change the environment of my config after initialisation?\nCall config.__switch(env). This will reload the config with the new environment set. See the Config Overview above.\nHow can I load in additional config files from disk after initialisation?\nCall config.__addLocal(localConfig) and pass in an array of local config files to load. This will reload the config with the extra config files merged in. See the Config Overview section above.\nHow can I create a code branch that executes on multiple environments?\nSee the localConfig initilisation option. If your config files do not include a property called env then Config-Ninja will add in a property with this shape by default:\n\/\/ THIS\n{\n  id: \"production\",\n  level: 1,\n}\n\n\/\/ OR THIS\n{\n  id: \"staging\",\n  level: 2,\n}\n\n\/\/ OR THIS\n{\n  id: \"development\",\n  level: 3,\n}\nYou can use this to create code branches that only execute if the environment is above a certain \"level\". For example, the following branch will execute if the environment level is higher than 1. By default this will be either the \"staging\" or \"development\" environments.\nif (config.env.level > 1) { ... }\nCan I load config files asynchronously?\nNo. That's beyond the scope of this module. Config should be loaded when your application first boots, and then only sparingly. This will prevent expensive IO from getting in the way of your application's execution.\nCan I load config from a database?\nNo. That's beyond the scope of this module.\n","553":"Multirotors\nResearch in Andrew Bennett's Lab. Using Multirotors to conduct environmental exploration, sensing, and sampling missions.\nProjects\nThis code repository contains the mission files and the general architecture for several mission types which can be executed with drones, namely:\n\nBreath Condensate Collection from a Cetacean\nWireless Tracker Tagging for a large Cetacean\nPhotogrammetry for Animal Studies\nPoint-of-Interest Data Collection\nEnvironmental Exploration\nWaypoint Navigation\nSense and Avoid of Unfriendly Multirotors\n\nEach of these missions is designed in a mission file. This mission file is then executed by a generic autonomy structure based upon State Configured Layer Control (SCLC) which controls the actions of the drone.\nRunning this Code\nStill under construction\nRC override:\nAll computer control can be overridden by switching ch. 6 on the transmitter to a value greater than 1500.\nkeyboard controls:\nm = stabilize (sort of manual)\nl = loiter\no = auto\nr = arm\nt = disarm\np = open planner\njoystick controls:\nspecific to joystick and not finalized yet\n","554":"ATMOS 6910, Fall 2018\nEnvironmental Programming, Atmospheric Science\nUniversity of Utah\nFall Semester 2018; second half\nMWF, 9:40AM-10:30AM; WBB711\n\n\n\nInstructor\nEmail\nPhone Number\nOffice Hours\nOffice Location\n\n\n\n\nChris Galli\nchris.galli@utah.edu\n801-647-2263\nby appointment\n482 INSCC\n\n\nSally Benson\nsally.benson@utah.edu\n801-859-1644\nby appointment\n603 WBB\n\n\n\nCopy of the Syllabus can be found here\nCourse Description\nEnvironmental scientists need the ability to acquire, process and display environmental data, imagery, and gridded fields.  This course is designed to develop the skills necessary to solve physically-based problems relating to atmospheric science data sets. After a review of basic programming concepts, students will develop code to solve problems using programming languages and data sources relevant to their ongoing or future research.  The course is particularly relevant for first-year graduate students as they begin research leading towards their thesis proposal.\nIt is assumed students have exposure and practical experience working with a common programming language used within physical sciences, such as Python, MatLab, or IDL. There is no requirement for using one language over another. However, it is important the student is comfortable working in a language that has available module\/API bindings to common data libraries; specifically, NetCDF4, HDF, and CSV parsing.\nCourse Outcomes\nBy the end of this course, you will be able to:\n\nWrite computer programs for analyzing data.\nAcquire and use data in multiple file formats.\nCreate custom ways to display data.\n\nCheck out CHPC's Intro to Python Series\nOngoing class links\nOctober 15, Lecture 1: Introduction\nOctober 17, Lecture 2: Data types\n\nIDL example file lecture02_variables_datatypes.pro\nHomework assignment 1\n\nOctober 19, Lecture 3: Basic programs and arrays\nOctober 22, Lecture 4: I\/O part I\n\nSupplemental slides\n\nOctober 24, Lecture 6: I\/O NetCDF and HDF\nOctober 26, Lecture 6: I\/O part II\n\nSupplemental slides\nexample06.py\n\nOctober 29, Lecture 7: Final Project Review\nOctober 31, Lecture 8: Basic Control Structures\nNovember 2, Lecture 9: Arrays part I\n\nHomework assignment 2\n\nNovember 5, Lecture 10: Code design and more arrays\nNovember 7, Project reviews. Approach discussions. Questions.\n\nHomework assignment 3\n\nNovember 9, Lecture 11: Arrays part II\nNovember 12, Lecture 12: Optimization\nNovember 14, Lecture 13: Numerical Applications\nNovember 16, Lecture 14: Intro to debugging\n\nDebug exercise\n\n","555":"PECT: Power Externality Correlation Tool\nQuantifying the environmental impacts of electricity purchased from the grid\nLicense: LGPL\nVersion: 1.2.0.0\nNew! Google Colaboratory Option: https:\/\/colab.research.google.com\/drive\/1UWDTphLkr8tja5R0HPN9nE66_8kPPYCx\nNew! Read the paper (open access): https:\/\/doi.org\/10.1016\/j.softx.2018.12.001\nThis script can be used to model the water consumption, water withdrawal, CO2 emissions, NOx emissions and SO2 emissions attributed to the power generation fuel mix within a specific location over a specified time frame. If the PECT.ipynb file is used in google colaboratory then there are no software requirments for running the script and obtaining outputs. However, it is best to use Google Chrome. Other browsers such as Firefox throw Network Errors when the script attempts to download the results file.\nNOTE: The emissions factors used in this script are calculated with the eGRID excel database included in this repository. This database is updated every two years. The most recent database can be found here: https:\/\/www.epa.gov\/energy\/emissions-generation-resource-integrated-database-egrid. The most recent database should be downloaded and included in the working directory for best results. The FindEmission_Rates script will automatically use the most recent database in the directory as long as it contains \"egrid\" and the corresponding year in the name.\nUser Inputs:\n\nLocation: The location for which the numbers will correlate to (city, state, etc.)\nTime Frame: The start and end data\/time from which data will be pulled\nWattTime Credentials: Username and password for a valid WattTime API account\n\nOutputs:\n\nTime Array\nGeneration for each fuel type\nWater Consumption\nWater Withdrawal\nCOs, NOx and SO2 emissions\nEmission factors for each fuel type\nWater consumption and withdrawal factors for each fuel type\n\nInstructions (Colaboratory Notebook):\n\nClick on the link provided here: https:\/\/colab.research.google.com\/drive\/1UWDTphLkr8tja5R0HPN9nE66_8kPPYCx\nRun each cell and provide user inputs as directed\nResults file should be downloaded through your internet browser\n\nInstructions (Python File):\n\nDownload the electricityandenvironment zip file\nRun the Power_Ex.py or Power_Ex.ipynb file if using a jupyter notebook file with the necessary dependancies (Python3, urllib, numpy, pandas)\nNote: The FindEmission_Rates.py or FindEmission_Rates.ipynb file must be located in the same folder\nFollow the command prompts to input the necessary information corresponding to your desired data output\nThe output file will be located in the same directory as the Power_Ex.py file. It will be named Results.xlsx\n\nCite: Plewe, K. & Smith, A. D. PECT: A tool for computing the temporal and spatial variation of externalities related to power generation in the United States. SoftwareX 9, 61\u201367 (2019). doi:10.1016\/j.softx.2018.12.001\n","556":"Installation\nIt requires to download MySQL Connector in order to connect with MySQL Database System.\nUsage\nSpecializes in structured data storing for detailed information on Environmental Inspection documents. Utilizes ChartView statistics.\n","557":"Installation\nIt requires to download MySQL Connector in order to connect with MySQL Database System.\nUsage\nSpecializes in structured data storing for detailed information on Environmental Inspection documents. Utilizes ChartView statistics.\n","558":"MKR1010_EnvironmentalShield\nDon't forget to reate a \"secrets.h\" file in the same folder as the .ino file. It needs to 3 #defines with your wireless network information.\n#define MYSSID \"YOUR-SSID-HERE\"\n#define MYPASS \"YOUR-WIFI-KEY-HERE\"\n#define MY_THING_ID \"YOUR-THING-ID-HERE\"\n","559":"MKR1010_EnvironmentalShield\nDon't forget to reate a \"secrets.h\" file in the same folder as the .ino file. It needs to 3 #defines with your wireless network information.\n#define MYSSID \"YOUR-SSID-HERE\"\n#define MYPASS \"YOUR-WIFI-KEY-HERE\"\n#define MY_THING_ID \"YOUR-THING-ID-HERE\"\n","560":"Humes | Environmental Sensors & Controls\nA data driven, mesh networked home automation project\n\nComponents\n\nAdafruit HUZZAH ESP8266\nDHT22 Temperature and Humidity Sensor\nMH-Raindrop Detector\nBMP180 Pressure Sensor\nTSL2561 Light Sensor\n\nOES | Outdoor Environment Sensor\nA small circuitboard holding an ESP-12F with a DHT22, TLS2165, BMP180 and a raindrop sensor. All the components housed in a small enclosure and placed outside with a solar panel. The sensor is connected to a WiFi Mesh which pushes data to a node and allows posting of weather information to OpenWeatherMap and internal database to inform remotes.\nIES | Internal Environment Sensor\nWhile similar to the OES, this board removes the TLS2165 and MH-Raindrop Detector and gains the MQ135 Air Quality sensor. Information for each room can be entered on the admin page of the main node.\nRemote | Data Controlled Switches\nRemotes contain all the functions needed to interface with the Mesh and activate\/deactivate equipment. They can be hidden inside the body of a device to toggle power and forward basic commands, provided the device allows serial communication.\n","561":"EnvMon\nAn environmental monitoring system.\n","562":"Wildlife Tracker\nA java spark app for the Forest Service to conduct an environmental impact study.\nTechnologies and frameworks used\n1. java 11\n2. spark core 2.12\n3. Gradle 4.10\n4. Spark Template Velocity\n5. Junit 5\n6. Postgres database\n\nDatabase\nIn PSQL:\nCREATE TABLE animals(id SERIAL PRIMARY KEY,health varchar, age varchar, type varchar,name varchar);\nCREATE TABLE locations(id SERIAL PRIMARY KEY, name varchar);\nCREATE TABLE rangers(id SERIAL PRIMARY KEY, firstname varchar, lastname varchar , badgenumber int);\nCREATE TABLE sightings(id SERIAL PRIMARY KEY, ranger varchar , location varchar, animalid int);\n\nTesting\n gradle test\nScreenShots\n\nThis is the homepage and it comprises a list of all the rangers registered in the system.\n\nThis page displays a table of all sigthings.\n\nThis is where a table of all animals is displayed and new animals can be added into the system.\n\nThe table above displays all available locations in the forest and other locations can be added.\nLicense\n\n","563":"environment.monitor\n\n\n\nIs a tool for continuous gathering, aggregation and representation of environment health, that provides access to environment status information via both UI dashboards & REST API\n\n\n\nCurrent environment components states\nEnvironment components daily statistics\n\n\n\n\n\n\n\n\n\n\n\n\nParticular component availability over time\n\n\n\n\n\n\n\n\nQuickstart with test extension\nWith docker:\ngit clone  https:\/\/github.com\/YagelNasManit\/environment.monitor.git\ndocker-compose up --build\nWithout docker:\n\nQuick start with test extension\n\nDocumentation\nSee the Wiki for the available documentation\nFeature Requests & Bugs\nFound a bug or would like to see a new feature implemented? Raise an issue in the Issue Tracker\nContributing\nEager to fix a bug or introduce a new feature? Clone the repository and issue a pull request\nLicense\nenvironment.monitor is licensed under the Apache License 2.0\n","564":"environment.monitor\n\n\n\nIs a tool for continuous gathering, aggregation and representation of environment health, that provides access to environment status information via both UI dashboards & REST API\n\n\n\nCurrent environment components states\nEnvironment components daily statistics\n\n\n\n\n\n\n\n\n\n\n\n\nParticular component availability over time\n\n\n\n\n\n\n\n\nQuickstart with test extension\nWith docker:\ngit clone  https:\/\/github.com\/YagelNasManit\/environment.monitor.git\ndocker-compose up --build\nWithout docker:\n\nQuick start with test extension\n\nDocumentation\nSee the Wiki for the available documentation\nFeature Requests & Bugs\nFound a bug or would like to see a new feature implemented? Raise an issue in the Issue Tracker\nContributing\nEager to fix a bug or introduce a new feature? Clone the repository and issue a pull request\nLicense\nenvironment.monitor is licensed under the Apache License 2.0\n","565":"Air Hound\n\n\n\nFront end development for the EPA RFI (Air Hound).\n\n\n\nKey Links\nURLs\n\n\n\n\nAir Hound app\nhttps:\/\/airhound.540.co\n\n\nAPI Documentation\nhttps:\/\/airhound.540.co\/api-docs\/\n\n\nBackend repo\nhttps:\/\/github.com\/540co\/epa-rfi-backend\n\n\n\nGetting started\nClone repo.\nInstall dependencies\nFrom within the cloned folder epa-rfi run:\nNode dependencies\nnpm install\n\nBower dependencies\nbower install\n\nConfigure application\nFrom within the cloned folder epa-rfi run:\nEdit .\/src\/app\/app.config.js and update accordingly.\nConfigure Google Analytics\nFrom within the cloned folder epa-rfi run:\nEdit .\/src\/assets\/scripts\/ga.js and update accordingly.\nGulp tasks\n\ngulp or gulp build to build an optimized version of your application in \/dist\ngulp serve to launch a browser sync server on your source files\ngulp serve:dist to launch a server on your optimized application\ngulp test to launch your unit tests with Karma\ngulp test:auto to launch your unit tests with Karma in watch mode\ngulp protractor to launch your e2e tests with Protractor\ngulp protractor:dist to launch your e2e tests with Protractor on the dist files\n\n","566":"comparative-analysis for source apportionment\nComparative analysis of environmental data from source apportionment\nThis project is about comparative analysis of environmental data coming out from source apportionment analysis.\nThe comparison is made between the results found by several laboratories that carried out source apportionment on a common database.\nThe output of source apportionment runs are:\n\nfactor profiles (pollutant factors)\nuncertainties of factor profiles\ntime trends of factor profiles\nfactor contributions to a given chemical species\n\nData from each laboratory are loaded and classified according to given categories\nwhich are chosen among the main pollutant sources .\nThe R code: CLASSIFY.R acts as follow:\n\nloads data,\nmakes mathematical transformations for comparative analysis purposes, group factor profiles,\nchooses and groups factor profiles into chosen categories\nextract the Source Contribution Estimations (and their uncertainties).\n\n##################################################################################################################\nComparative analysis begins with performing Pearson correlation classified data.\nCorrelation is then carried on all possible pairs of factor profiles found by each laboratory.\nAlso correlation with a reference source profile is performed.\nThe R code: CORR.R acts as follow:\n\nloads data\nmakes all possible correlations between factor profiles\nmakes correlations between factor and reference source profiles.\nmakes boxplots for correlation between factor profiles\nmakes matplots for correlation between factor and reference source profiles.\n\n##################################################################################################################\nComparative analysis takes also into account uncertainties of data. For this purpose, the\nWeighted Difference (WD) is a way to compare data between laboratories considering uncertainties.\nThe R code: WEIGH_DIFF.R acts as follow:\n\nloads data\nmakes all possible WD between factor profiles\nmakes WD between factor and reference source profiles.\nmakes boxplots for WD between factor profiles\nmakes matplots for WD between factor and reference source profiles.\n\n#################################################################################################################\nThreshold limit of acceptability for the Pearson correlation are set at 2.0.\nProficiency tests are performed according to the ISO 13528:\nR codes have been written for:\n\nZ'_score\nZ_score\nEn_number\n\n","567":"php\u63a2\u9488\nphp\u63a2\u9488 php\u73af\u5883\u4fa6\u6d4b php Environmental detector\n\nhttp:\/\/qingmvc.com\nhttp:\/\/qingcms.com\nhttp:\/\/logo234.com\nhttp:\/\/mangdian.net\n\n\u8f7b\u91cf\u7ea7\uff0c\u4e3b\u8981\u76ee\u7684\n\n\u5217\u51faphpinfo()\u7684\u91cd\u8981\u4fe1\u606f\n\u68c0\u6d4b\u5371\u9669\u51fd\u6570\u662f\u5426\u5f00\u542f\n\u68c0\u6d4b\u51fd\u6570\/\u7c7b\/\u6269\u5c55\u662f\u5426\u652f\u6301\n\u68c0\u6d4b\u6570\u636e\u5e93\u8fde\u63a5\n\u68c0\u6d4bphp.ini\u8fd0\u884c\u65f6\u914d\u7f6e\u60c5\u51b5\n\n\u622a\u56fe screenshot\n\n","568":"National CO2 Emissions from Fossil-Fuel Burning, Cement Manufacture, and Gas\nFlaring, 1751-2014.\nContributors\nT.A. Boden and R.J. Andres\nCarbon Dioxide Information Analysis Center\nEnvironmental Sciences Division\nOak Ridge National Laboratory\nOak Ridge, Tennessee 37831-6290, U.S.A.\nG. Marland\nResearch Institute for Environment, Energy and Economics\nAppalachian State University\nBoone, North Carolina, 28608-2131, U.S.A.\nDOI\n10.3334\/CDIAC\/00001_V2017\nNotes\nAll emission estimates are expressed in thousand metric tons of carbon. To\nconvert these estimates to units of carbon dioxide (CO2), simply multiply\nthese estimates by 3.667.\nPer capita emission estimates are expressed in metric tons of carbon.\nPopulation estimates were not available to permit calculations of global per\ncapita estimates before 1950.  Please note that annual sums were tallied before\neach element (e.g., Gas) was rounded and reported here so totals may differ\nslightly from the sum of the elements due to rounding.\nMethods\nPublications containing historical energy statistics make it possible to\nestimate fossil fuel CO2 emissions back to 1751. Etemad et al. (1991)\npublished a summary compilation that tabulates coal, brown coal, peat, and\ncrude oil production by nation and year. Footnotes in the Etemad et al.(1991)\npublication extend the energy statistics time series back to 1751. Summary\ncompilations of fossil fuel trade were published by Mitchell (1983, 1992, 1993,\n1995). Mitchell's work tabulates solid and liquid fuel imports and exports by\nnation and year. These pre-1950 production and trade data were digitized and\nCO2 emission calculations were made following the procedures discussed in\nMarland and Rotty (1984) and Boden et al. (1995). Further details on the\ncontents and processing of the historical energy statistics are provided in\nAndres et al. (1999).\nThe 1950 to present CO2 emission estimates are derived primarily from energy\nstatistics published by the United Nations (2016), using the methods of Marland\nand Rotty (1984). The energy statistics were compiled primarily from annual\nquestionnaires distributed by the U.N. Statistical Office and supplemented by\nofficial national statistical publications. As stated in the introduction of\nthe Statistical Yearbook, \"in a few cases, official sources are supplemented by\nother sources and estimates, where these have been subjected to professional\nscrutiny and debate and are consistent with other independent sources.\" Data\nfrom the U.S. Department of Interior's Geological Survey (USGS 2016) were used\nto estimate CO2 emitted during cement production. Values for emissions from gas\nflaring were derived primarily from U.N. data but were supplemented with data\nfrom the U.S. Department of Energy's Energy Information Administration (1994),\nRotty (1974), and data provided by G. Marland. Greater details about these\nmethods are provided in Marland and Rotty (1984), Boden et al. (1995), and\nAndres et al. (1999).\nReferences\nAndres, R.J., D.J. Fielding, G. Marland, T.A. Boden, and N. Kumar. 1999. Carbon dioxide emissions from fossil-fuel use, 1751-1950. Tellus 51B:759-65.\nBoden, T.A., G. Marland, and R. J. Andres. 1995. Estimates of global, regional, and national annual CO2 emissions from fossil-fuel burning, hydraulic cement production, and gas flaring: 1950-1992. ORNL\/CDIAC-90, NDP-30\/R6. Oak Ridge National Laboratory, U.S. Department of Energy, Oak Ridge, Tennessee.\nMarland, G., and R.M. Rotty. 1984. Carbon dioxide emissions from fossil fuels: A procedure for estimation and results for 1950-82. Tellus 36(B):232-61.\nEtemad, B., J. Luciani, P. Bairoch, and J.-C. Toutain. 1991. World Energy Production 1800-1985. Librarie DROZ, Switzerland.\nMitchell, B.R. 1983. International Historical Statistics: The Americas and Australasia 1750-1988. pgs. 522-525. Gale Research Company, Detroit, United States.\nMitchell, B.R. 1992. International Historical Statistics: Europe 1750-1988. pgs. 465-485. Stockton Press, New York, United States.\nMitchell, B.R. 1993. International Historical Statistics: The Americas 1750-1988. pgs. 405-414. Stockton Press, New York, United States.\nMitchell, B.R. 1995. International Historical Statistics: Africa, Asia and Oceania 1750-1988. pgs. 490-497. Stockton Press, New York, United States.\nRotty, R.M. 1974. First estimates of global flaring of natural gas. Atmospheric Environment 8:681-86.\nUnited Nations. 2017. 2014 Energy Statistics Yearbook. United Nations Department for Economic and Social Information and Policy Analysis, Statistics Division, New York.\nU.S. Department of Energy. 1994. International Energy Annual 1994. DOE\/EIA-0219(91). Energy Information Administration, Office of Energy Markets and End Use, Washington, D.C.\nU.S. Geological Survey. 2017. 2014 Minerals Yearbook - Cement H.G. van Oss (Ed.), U.S. Department of the Interior, U.S. Geological Survey, Reston, Virginia.\nLicence\nThe CDIAC page states\n\nIf you wish to use a diagram, image, graph, table, or other materials from the CDIAC website and are concerned with obtaining permission and possible copyright restrictions, there should be no concerns. All of the reports, graphics, data, and other information on the CDIAC website are freely and publicly available without copyright restrictions.\n\n\nHowever as a professional courtesy, we ask that the original data source be acknowledged. Suggested citations appear at the bottom of the page for each data set.\n\nCitation\nBoden, T.A., G. Marland, and R.J. Andres. 2017. Global, Regional, and National\nFossil-Fuel CO2 Emissions. Carbon Dioxide Information Analysis Center, Oak Ridge\nNational Laboratory, U.S. Department of Energy, Oak Ridge, Tenn., U.S.A.\nhttps:\/\/doi.org\/10.3334\/CDIAC\/00001_V2017\n","569":"EnvironmentalEventsDetector\nInstallation\nRequirement: register your Earth Engine API token\nTo use our application you will need a Google Earth Engine API key. To generate one, please follow these instructions.\nIn order to run this server, you must own an Earth Engine API token. You can\nask for an access on their [official website][earth engine]. This is a\nrequirement to run our server.\nCreate a token\nIf you never used the Python Earth Engine API, you must first download the\nrequired packages to get a token:\nsudo apt-get update\nsudo apt-get install python-dev python-pip\npip install --user google-api-python-client pyCrypto earthengine-api\n\nOnce you have all those packages installed, you can then authenticate.\n~\/.local\/bin\/earthengine authenticate\n\nYour token is stored in ~\/.config\/earthengine\/credentials.\nDeploy our application\nTo deploy our application execute the following command:\n.\/install.sh\n\nRun our application\nTo run our application, execute the following command:\n.\/run.sh\n\nThen go to http:\/\/localhost:9000\/index.html\n","570":"EnvironmentalEventsDetector\nInstallation\nRequirement: register your Earth Engine API token\nTo use our application you will need a Google Earth Engine API key. To generate one, please follow these instructions.\nIn order to run this server, you must own an Earth Engine API token. You can\nask for an access on their [official website][earth engine]. This is a\nrequirement to run our server.\nCreate a token\nIf you never used the Python Earth Engine API, you must first download the\nrequired packages to get a token:\nsudo apt-get update\nsudo apt-get install python-dev python-pip\npip install --user google-api-python-client pyCrypto earthengine-api\n\nOnce you have all those packages installed, you can then authenticate.\n~\/.local\/bin\/earthengine authenticate\n\nYour token is stored in ~\/.config\/earthengine\/credentials.\nDeploy our application\nTo deploy our application execute the following command:\n.\/install.sh\n\nRun our application\nTo run our application, execute the following command:\n.\/run.sh\n\nThen go to http:\/\/localhost:9000\/index.html\n","571":"Computing for Environmental Science and Management\n","572":"XDK IOTA Data Market Place Example\nHow to add x sensors to one specific nodeJS server.\n","573":"NAG Brooklyn's Greenpoint - Williamsburg Toxicity Map\nAn interactive map for Neighbors Allied For Good Growth showing pollution and demographic data in the neighborhoods of Greenpoint and Williamsburg in Brooklyn, New York.\nCreated Summer \/ Fall, 2015 for Pratt's Spatial Analysis and Visualization Initiative.\nDependencies\n\nNode.js\nCartodb.js\nMapbox.js\nBower\njQuery\njQuery UI\nHandlebars.js\nNormalize.css\n\nInstallation:\nDo bower install to download the dependencies locally.\nData Processing in CartoDB\nSee the sql\/ directory for code relating to formatting the data tables in CartoDB \/ Postgres.\nCreating The Basemap Tiles\nRequires using Mapbox Studio Classic and having a MapBox account.\nNote: at the time of creating this project Mapbox Studio Classic was replaced by a newer version of the software titled Mapbox Studio.\nThe basemap\/ directory contains the necessary files to create the basemap tiles with Mapbox Studio Classic:\n\ntm2\/: the files specifying the styling of the basemap's tiles.\ntm2.source\/: contains the necessary files that point to the custom data layers in data\/.\n(this folder is created by mapbox studio classic after adding the data layer (aka: source))\ndata\/: contains zipped ESRI Shapefiles that are required for tm2.source\/.\ntoxicity-basemap.tm2z the project's styles and metadata in a compressed format\n\nUpdating Map's CartoDB Data Layers' Styles\nTo make the editing of CartoCSS easier for the CartoDB data layers, each layer's corresponding CartoCSS has been saved to a .mss file in the mss\/ directory. The carto-to-js.js script is then used to minify each .mss file and compile them into an object that is returned by the app.cartocss module.\nTo update the CartoCSS do the following:\n\n\nAlter the corresponding mss file for the data layer in the mss\/ directory and save it.\n\n\nDo node carto-to-js.js to update the app.cartocss module which is stored inside the file js\/carto.js.\n\n\nContributors:\n\nChris Henrick\nBowon Chung\n\n","574":"frGIS: a tool for implemeting GIS-based tools with factorial regression on GxE analysis\nPackage overview\nfrGIS is a useful package for diagnostic recommendations for new cultivars and evaluating the phenotypic plasticity of germplasm against spatial variations over a target region. This package can also be used to support the targeting of products in pre-commercial material evaluation phases, guiding the effort allocation and resources management to priority target regions that demands most breeding efforts. Until now, this package only employes least-squares methods under the parametric point of view. Howerver, future updates will be focused on including iterative non-parametric methods, bayesian approaches, and ridge regressions. We are open to establishing partnerships in order to improve the tools achieved here. For those interested in contributing to the project, please get in touch with germano.cneto@usp.br\nBackground\nThe methodology of factorial regression integrated with thematic maps was proposed by Martins (2004) in his master's thesis at the Federal University of Goi\u00e1s (UFG, Goias, Brazil), under the supervision of Professor Jo\u00e3o Batista Duarte (jbduarte@ufg.br). The method was expanded by Costa Neto (2017) in his master's thesis at UFG-Embrapa (Brazilian Agricultural Research Corporation), with Alexandre Bryan Heinemann advices for reaching the current molds. Currently this author is also responsible for the updates and maintenance of this package (germano.cneto@usp.br)\nInstall\nlibrary(devtools)\ninstall_github(\"gcostaneto\/frGIS\")\nBasic usage\nFactorial Regression with geographic covariates\nrequire(frGIS)\n\n#' data set\n#'--------------------------------------------------------------------------\ndata(rice2)\nhead(rice2)\n\n#' Factorial regression\n#'--------------------------------------------------------------------------\noutput = FR.model(df.y = rice2,intercept = T)\n\noutput$coefficients   # genotypic coefficients\noutput$sum.of.squares # anova output for each genotype\noutput$frac.ss        # fraction of phenotypic variance explained by the effect of environment covariates\n\n#' Cross-validation\n#'--------------------------------------------------------------------------\noutput = FRcv(df.y = rice2,f = .1,part.env = 1,intercept = T,boot=1E3) # 1000-boot, leaving one environment out plus 10% of the genotypes\n\n#- Examples\n#'--------------------------------------------------------------------------\nmet1 = FRcv(df.y = rice1,f = .1,part.env = 1,intercept = T,boot=1E3)\nmet2 = FRcv(df.y = rice2,f = .1,part.env = 1,intercept = T,boot=1E3)\n\nsummary.FRcv(met1)$coefficients\nsummary.FRcv(met2)$coefficients\n\nsummary.FRcv(met1)$frac.ss\nsummary.FRcv(met1)$frac.ss\n\nPredicting yield adaptability trends (Surface trend analysis with yield adaptability)\nrequire(plyr)\n\n# cov.coord = raster of environmental variables\ncoef.1 = dcast(summary.FRcv(met1)$coefficients, formula = gid~variable)\ncoef.2 = dcast(summary.FRcv(met2)$coefficients, formula = gid~variable)\n\noutput1 = predict.Ad(b=coef.1,cov.raster = cov.coord,intercept = T)\noutput2 = predict.Ad(b=coef.2,cov.raster = cov.coord,intercept = T)\n\nReferences\nCosta-Neto, G.M.F., Morais J\u00fanior, O.P., Heinemann, A.B. et al. A novel GIS-based tool to reveal spatial trends in reaction norm: upland rice case study. Euphytica 216, 37 (2020). https:\/\/doi.org\/10.1007\/s10681-020-2573-4\nMartins, A. S. (2004). Aplica\u00e7\u00e3o de sistema de informa\u00e7\u00f5es geogr\u00e1ficas no estudo da intera\u00e7\u00e3o gen\u00f3tipos com ambientes. Master's thesis in Agronomy, Escola de Agronomia e Engenharia de Alimentos. Universidade Federal de Goi\u00e1s, Goi\u00e2nia (in portuguese).\nCosta-Neto, G. M. F. (2017). Integrating environmental covariates and thematic maps into genotype by environment interaction analysis in upland rice. Master's thesis in Genetics and Plant Breeding, Escola de Agronomia e Engenharia de Alimentos. Universidade Federal de Goi\u00e1s, Goi\u00e2nia\nAcknowledgements\nThis study was financed in part by the Coordena\u00e7\u00e3o de Aperfei\u00e7oamento de Pessoal de N\u00edvel Superior - Brasil (CAPES) and Brazilian Agricultural Research Corporation. Special thanks for the researchers Alexandre Bryan Heinemann, phD and Adriano Pereira de Castro, phD for the co-authored support for this methodological development\n","575":"RPI-EnvironmentalMonitoring\nRaspberry Pi Home Environment Monitoring System\nTest\nconfig\nmodule.exports = {\n    port:\"8080\",\n    session: {\n        maxAge: 20 * 60 * 1000  \/\/ session for 20 min\n    },\n    db:{\n        host: 'localhost',\n        user: 'root',\n        password: '111111',\n        database: 'rpi-environmentalmonitoring',\n        port: '3307'\n    }\n}\n\nset admin_table password\ndefault:\nlocalhost:{$port}\/admin\nusername:admin\npassword:111111\ncd web\/lib\/\nnode logmd5.js\n\nrun node server\ngit clone\ncd web\nnpm install\nnode index.js\n\n\n","576":"RPI-EnvironmentalMonitoring\nRaspberry Pi Home Environment Monitoring System\nTest\nconfig\nmodule.exports = {\n    port:\"8080\",\n    session: {\n        maxAge: 20 * 60 * 1000  \/\/ session for 20 min\n    },\n    db:{\n        host: 'localhost',\n        user: 'root',\n        password: '111111',\n        database: 'rpi-environmentalmonitoring',\n        port: '3307'\n    }\n}\n\nset admin_table password\ndefault:\nlocalhost:{$port}\/admin\nusername:admin\npassword:111111\ncd web\/lib\/\nnode logmd5.js\n\nrun node server\ngit clone\ncd web\nnpm install\nnode index.js\n\n\n","577":"vi-suite04\nRepository for version 0.4 of the VI-Suite, a building environmental performance addon for Blender.\nAn article describing the VI-Suite has been published in 'Open Geospatial Data, Software and Standards'. As the article is open-access a link to the full text can be found at http:\/\/rdcu.be\/vRj5. The article reference can be used to cite the VI-Suite in research work. The bibtex formatted reference is below:\n@article{Southall2017,\nabstract = {The VI-Suite is a free and open-source addon for the 3D content creation application Blender, developed primarily as a tool for the contextual and performative analysis of buildings. Its functionality has grown from simple, static lighting analysis to fully parametric lighting, shadowing, and building energy analyses. It adopts a flexible, mesh geometry based approach to the specification of calculation points and this has made it suitable for certain types of 3D geospatial analyses and data visualisation.},\nauthor = {Southall, Ryan and Biljecki, Filip},\nday = {14},\ndoi = {10.1186\/s40965-017-0036-1},\nissn = {2363-7501},\njournal = {Open Geospatial Data, Software and Standards},\nmonth = {Sep},\nnumber = {1},\npages = {23},\ntitle = {{The VI-Suite: a set of environmental analysis tools with geospatial data applications}},\nurl = {https:\/\/doi.org\/10.1186\/s40965-017-0036-1},\nvolume = {2},\nyear = {2017}\n}\n","578":"vi-suite04\nRepository for version 0.4 of the VI-Suite, a building environmental performance addon for Blender.\nAn article describing the VI-Suite has been published in 'Open Geospatial Data, Software and Standards'. As the article is open-access a link to the full text can be found at http:\/\/rdcu.be\/vRj5. The article reference can be used to cite the VI-Suite in research work. The bibtex formatted reference is below:\n@article{Southall2017,\nabstract = {The VI-Suite is a free and open-source addon for the 3D content creation application Blender, developed primarily as a tool for the contextual and performative analysis of buildings. Its functionality has grown from simple, static lighting analysis to fully parametric lighting, shadowing, and building energy analyses. It adopts a flexible, mesh geometry based approach to the specification of calculation points and this has made it suitable for certain types of 3D geospatial analyses and data visualisation.},\nauthor = {Southall, Ryan and Biljecki, Filip},\nday = {14},\ndoi = {10.1186\/s40965-017-0036-1},\nissn = {2363-7501},\njournal = {Open Geospatial Data, Software and Standards},\nmonth = {Sep},\nnumber = {1},\npages = {23},\ntitle = {{The VI-Suite: a set of environmental analysis tools with geospatial data applications}},\nurl = {https:\/\/doi.org\/10.1186\/s40965-017-0036-1},\nvolume = {2},\nyear = {2017}\n}\n","579":"scs_dfe_edu\nUNDER DEVELOPMENT\nEnvironmental sampling abstractions for the South Coast Science educational board.\nContains library classes only.\nSampling operations are performed using command line utilities found in the\nscs_dev package. System configuration is performed using\nutilities found in the scs_mfr package.\nRequired libraries:\n\nThird party: tzlocal\nSCS root: scs_core\nSCS host: scs_host_rpi\n\nBranches:\nThe stable branch of this repository is master. For deployment purposes, use:\ngit clone --branch=master https:\/\/github.com\/south-coast-science\/scs_dfe_edu.git\n\n","580":"EnvironmentalQuizApp\n","581":"EnvironmentalSemanticWeb\nIntro\nTest and support to implementation of semantic web technologies in French environmental information systems (French Biodiversity Office, BRGM, IFREMER, MNHN, French Water Information System, ...).\nBetter interlinkage between them and also with international ones.\nOGC Interoperability experiments\nELFIE (Environmental Linked Features Interoperability Experiment)\nRunning over 2018-2019, the OGC ELFIE was intended to test existing OGC and W3C standards with the goal of establishing a best practice for exposing links between and among environmental domain and sampling features in a highly adoptible standards compliant way that is compatible with modern web search technology.\nINSIDE pushed the following use cases in ELFIE\n\nSurface-Ground Water Networks Interaction\nGround Water Monitoring\n\nVisit the ELFIE outcomes webpage (Engineering Report, demos)  : https:\/\/opengeospatial.github.io\/ELFIE\/\nSELFIE (Second ELFIE)\nRangin from 2019 to 2020 and building on the content-focused outcomes of the first ELFIE, the Second ELFIE (SELFIE) is designing and vetting Web-resource model and network behavior for cross-domain linked feature data that compliments and uses WFS3 as a building block. This aims to answer the question, how do we use linked data in a way that's compatible with W3C best practices and leverages OGC standards?\nSELFIE outcomes will enrich the initial ELFIE outcomes webpage.\nVisit SELFIE GitHub : https:\/\/github.com\/opengeospatial\/SELFIE\nLinked data demo\nFirst tests on French surface water quality observation database.\nData is linked to MNHN and IFREMER and external resources (CSIRO, qudt, ChemId+, ...)\nSome quick link below to dive in the demos (see 'demo' folder).\nFor more info on how BLiV works and its code, see https:\/\/github.com\/BRGM\/BLiv\nLinked data registries comparison\nA comparison of the two main existing tools in Europe has been carried out.\nIt's shared in the 'linkeddataregistries' folder\nFrench Water Information System 1st ontologies\nComparability analysis of first ontologies and RDF\/XML representations generated by ST Sandre.\nAvailable in the 'ontologies\/French_ST_Sandre' folder\nOutreach\nPresentations in RDA and OGC hydro related groups, complementing (S)ELFIE ones\nAvailable in the 'presentations' folder\n","582":"RPI-EnvironmentalMonitoring\nRaspberry Pi Home Environment Monitoring System\nTest\nconfig\nmodule.exports = {\n    port:\"8080\",\n    session: {\n        maxAge: 20 * 60 * 1000  \/\/ session for 20 min\n    },\n    db:{\n        host: 'localhost',\n        user: 'root',\n        password: '111111',\n        database: 'rpi-environmentalmonitoring',\n        port: '3307'\n    }\n}\n\nset admin_table password\ndefault:\nlocalhost:{$port}\/admin\nusername:admin\npassword:111111\ncd web\/lib\/\nnode logmd5.js\n\nrun node server\ngit clone\ncd web\nnpm install\nnode index.js\n\n\n","583":"comfort-o-meter\nThe IoT SIG project to monitor office environmental data. See the wiki page for setup details.\nTwo examples\n\npython - python-based gateway and mote code\nnode - node.js-based gateway and mote code\n\nIdeas for improvement\n\nImprove the accuracy of the altitude reading by finding out the daily actual local atmospheric pressure at sea level and use that instead of using a hard-coded assumed value.\nUse Protocol Buffers (or similar header-based cross-platform message definition mechanism) to encode and decode the message over ZigBee more efficiently.\nMake the sound level average more samples over a longer period to get a more realistic reading of ambient sound.\n\n","584":"comfort-o-meter\nThe IoT SIG project to monitor office environmental data. See the wiki page for setup details.\nTwo examples\n\npython - python-based gateway and mote code\nnode - node.js-based gateway and mote code\n\nIdeas for improvement\n\nImprove the accuracy of the altitude reading by finding out the daily actual local atmospheric pressure at sea level and use that instead of using a hard-coded assumed value.\nUse Protocol Buffers (or similar header-based cross-platform message definition mechanism) to encode and decode the message over ZigBee more efficiently.\nMake the sound level average more samples over a longer period to get a more realistic reading of ambient sound.\n\n","585":"EnvironmentalQuizApp\n","586":"A CORBA-based client-server system.  The requirements of the system can be broken down into a number of separate systems which will need to communicate in a client-server manner to solve the overall requirements:\n1.  The Monitoring Station:\nThe Monitoring Station is a stand-alone monitoring system, to be prototyped as a CORBA server, that supports the following functionality at least:\n\nRegister itself with a Regional Centre upon initial activation\nCan be remotely activated\nCan be remotely deactivated\nCan be remotely reset\nCan return, upon request, the current value of the nitrogen oxides sensor\nCan identify anomalous or potentially dangerous readings of nitrogen oxides and alert the Local Server immediately.\n\n2.  Precompile the IDL.  To do this open a (IntelliJ) Terminal and type:\nThe Local Server is to be prototyped as a CORBA server that supports the following functionality at least:\n\nReceives requests to register Monitoring Stations and maintains a list of connected devices\nReceives alerts from connected Monitoring Stations, and maintains a log of these alerts\nTriggers an alarm at the Environmental Centre when two alarms happen within a specified time frame\nReturns the log upon request\nPolls all connected Monitoring Stations when requested to do so, and returns a set of readings\n\n3.  The  Monitoring Centre\nThe Monitoring Centre is to be prototyped as a CORBA server that supports the following functionality at least:\n\nReceives confirmed alarms from Local Servers\nAlerts the operator when a confirmed alarm is received\nAllows agencies (e.g. the Environment Agency, local councils, local pressure groups, etc.) to register for notifications in particular areas in case of alarms\nMaintains a list of connected Local Servers\nPolls all Local Servers upon request and displays the results of readings returned, highlighting readings of concern\n\nTo run the demo from IntelliJ:\n\n\nAdd all the libraries from the Jacorb lib folder to the module (NOTE - add them to the module, not the project.  They are not all required, but I don't know the minmum set) AND add the jboss library too.\n\n\nPrecompile the IDL.  To do this open a (IntelliJ) Terminal and type:\ncd RelayWithGUIsDemo\/src\n<path_to_jacorb_dir>\/bin\/idl LocalMonitoringStation.LocalMonitoringStationUI.idl\n\n\ne.g. I would type:\ncd RelayWithGUIsDemo\/src\n\/spare\/jacorb-3.9\/bin\/idl LocalMonitoringStation.LocalMonitoringStationUI.idl\n\n\n\nYou can then run the different components of the system.  You need to start them in the following order:\nSensor.SensorServer\nLocalMonitoringStation.LocalMonitoringStationUI\nHeadQuarter.HeadQuarterUI\n\n\n","587":"BuzzSense\nAs ecological observation are increasingly augmented by autonomous systems, the analysis and transmission\nof data poses serious problems for information manager. The aim of this project is to bridge the technological gap between\nthe needs of biologists and recent advances in mobile imaging.\nTo solve this we present BuzzSense, an application for Bee population counting running on an Android mobile device.\n To run this application \nAn android device running Android 4.2 or better.\nYou will need the OpenCV Manager\navailable on the Play Store.\nYou will also need to copy images from the project .\/samples\/ directory\nto \/media\/samples\/ on your mobile device.\n To compile this application \nYou will need to download the Open CV Android 2.4.8 or better SDK.\nYou will need to download and install the Android NDK (Native Development Kit).\nThis program uses native C++ libraries (wraped in easy to use Java calls) for hardware accelerated image processing.\n","588":"BEES3041: Big Data in the Biological, Earth and Environmental Sciences\n.\nLab: Modelling the photosynthetic response to environmental conditions\n10:00 am - 12:00 pm, 14th June, 2019 (T2)\nIn this lab we are going to explore the C3 leaf-level photosynthesis model proposed by Farquhar et al. (1980) and use this to simulate photosynthesis at leaf, ecosystem and global scale\nWe are going to use this model to:\n\nlearn how leaf-level photosynthesis responds to changes in the environmental forcing (photosynthetically active radiation, temperature and carbon dioxide).\nsimulate GPP at the ecosystem-scale (~1 km^2) using FLUXNET (eddy covariance) meteorological data.\nsimulate a global estimate of GPP.\n\nKey References:\n\nFarquhar GD, Von Caemmerer S and Berry JA (1980) A\nbiochemical model of photosynthetic CO2 assimilation in leaves of C3 species. Planta 149: 78\u201390\n\nRunning on your own computer\nTo run the practical:\n\nDownload or clone the entire repository, either:\n\nDownload the repository as a zip file, and uncompress it.\ngit clone https:\/\/github.com\/mdekauwe\/BEES3041_lab_photosynthesis.git\n\n\nThen open up the project file in the repository folder in RStudio.\nYou will have to knit the Rmd file to generate the practical instructions. To do so, open the Rmd file and click the knit icon.\n\n.\n","589":"\n\n\n\n\n\n\n  Gatsby's hello-world starter\n\nKick off your project with this hello-world boilerplate. This starter ships with the main Gatsby configuration files you might need to get up and running blazing fast with the blazing fast app generator for React.\nHave another more specific idea? You may want to check out our vibrant collection of official and community-created starters.\n\ud83d\ude80 Quick start\n\n\nCreate a Gatsby site.\nUse the Gatsby CLI to create a new site, specifying the hello-world starter.\n# create a new Gatsby site using the hello-world starter\ngatsby new my-hello-world-starter https:\/\/github.com\/gatsbyjs\/gatsby-starter-hello-world\n\n\nStart developing.\nNavigate into your new site\u2019s directory and start it up.\ncd my-hello-world-starter\/\ngatsby develop\n\n\nOpen the source code and start editing!\nYour site is now running at http:\/\/localhost:8000!\nNote: You'll also see a second link: http:\/\/localhost:8000\/___graphql. This is a tool you can use to experiment with querying your data. Learn more about using this tool in the Gatsby tutorial.\nOpen the my-hello-world-starter directory in your code editor of choice and edit src\/pages\/index.js. Save your changes and the browser will update in real time!\n\n\n\ud83e\uddd0 What's inside?\nA quick look at the top-level files and directories you'll see in a Gatsby project.\n.\n\u251c\u2500\u2500 node_modules\n\u251c\u2500\u2500 src\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .prettierrc\n\u251c\u2500\u2500 gatsby-browser.js\n\u251c\u2500\u2500 gatsby-config.js\n\u251c\u2500\u2500 gatsby-node.js\n\u251c\u2500\u2500 gatsby-ssr.js\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 package-lock.json\n\u251c\u2500\u2500 package.json\n\u2514\u2500\u2500 README.md\n\n\n\n\/node_modules: This directory contains all of the modules of code that your project depends on (npm packages) are automatically installed.\n\n\n\/src: This directory will contain all of the code related to what you will see on the front-end of your site (what you see in the browser) such as your site header or a page template. src is a convention for \u201csource code\u201d.\n\n\n.gitignore: This file tells git which files it should not track \/ not maintain a version history for.\n\n\n.prettierrc: This is a configuration file for Prettier. Prettier is a tool to help keep the formatting of your code consistent.\n\n\ngatsby-browser.js: This file is where Gatsby expects to find any usage of the Gatsby browser APIs (if any). These allow customization\/extension of default Gatsby settings affecting the browser.\n\n\ngatsby-config.js: This is the main configuration file for a Gatsby site. This is where you can specify information about your site (metadata) like the site title and description, which Gatsby plugins you\u2019d like to include, etc. (Check out the config docs for more detail).\n\n\ngatsby-node.js: This file is where Gatsby expects to find any usage of the Gatsby Node APIs (if any). These allow customization\/extension of default Gatsby settings affecting pieces of the site build process.\n\n\ngatsby-ssr.js: This file is where Gatsby expects to find any usage of the Gatsby server-side rendering APIs (if any). These allow customization of default Gatsby settings affecting server-side rendering.\n\n\nLICENSE: This Gatsby starter is licensed under the 0BSD license. This means that you can see this file as a placeholder and replace it with your own license.\n\n\npackage-lock.json (See package.json below, first). This is an automatically generated file based on the exact versions of your npm dependencies that were installed for your project. (You won\u2019t change this file directly).\n\n\npackage.json: A manifest file for Node.js projects, which includes things like metadata (the project\u2019s name, author, etc). This manifest is how npm knows which packages to install for your project.\n\n\nREADME.md: A text file containing useful reference information about your project.\n\n\n\ud83c\udf93 Learning Gatsby\nLooking for more guidance? Full documentation for Gatsby lives on the website. Here are some places to start:\n\n\nFor most developers, we recommend starting with our in-depth tutorial for creating a site with Gatsby. It starts with zero assumptions about your level of ability and walks through every step of the process.\n\n\nTo dive straight into code samples, head to our documentation. In particular, check out the Guides, API Reference, and Advanced Tutorials sections in the sidebar.\n\n\n\ud83d\udcab Deploy\n\n\n","590":"\n\n\n\n\n\n\n  Gatsby's hello-world starter\n\nKick off your project with this hello-world boilerplate. This starter ships with the main Gatsby configuration files you might need to get up and running blazing fast with the blazing fast app generator for React.\nHave another more specific idea? You may want to check out our vibrant collection of official and community-created starters.\n\ud83d\ude80 Quick start\n\n\nCreate a Gatsby site.\nUse the Gatsby CLI to create a new site, specifying the hello-world starter.\n# create a new Gatsby site using the hello-world starter\ngatsby new my-hello-world-starter https:\/\/github.com\/gatsbyjs\/gatsby-starter-hello-world\n\n\nStart developing.\nNavigate into your new site\u2019s directory and start it up.\ncd my-hello-world-starter\/\ngatsby develop\n\n\nOpen the source code and start editing!\nYour site is now running at http:\/\/localhost:8000!\nNote: You'll also see a second link: http:\/\/localhost:8000\/___graphql. This is a tool you can use to experiment with querying your data. Learn more about using this tool in the Gatsby tutorial.\nOpen the my-hello-world-starter directory in your code editor of choice and edit src\/pages\/index.js. Save your changes and the browser will update in real time!\n\n\n\ud83e\uddd0 What's inside?\nA quick look at the top-level files and directories you'll see in a Gatsby project.\n.\n\u251c\u2500\u2500 node_modules\n\u251c\u2500\u2500 src\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .prettierrc\n\u251c\u2500\u2500 gatsby-browser.js\n\u251c\u2500\u2500 gatsby-config.js\n\u251c\u2500\u2500 gatsby-node.js\n\u251c\u2500\u2500 gatsby-ssr.js\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 package-lock.json\n\u251c\u2500\u2500 package.json\n\u2514\u2500\u2500 README.md\n\n\n\n\/node_modules: This directory contains all of the modules of code that your project depends on (npm packages) are automatically installed.\n\n\n\/src: This directory will contain all of the code related to what you will see on the front-end of your site (what you see in the browser) such as your site header or a page template. src is a convention for \u201csource code\u201d.\n\n\n.gitignore: This file tells git which files it should not track \/ not maintain a version history for.\n\n\n.prettierrc: This is a configuration file for Prettier. Prettier is a tool to help keep the formatting of your code consistent.\n\n\ngatsby-browser.js: This file is where Gatsby expects to find any usage of the Gatsby browser APIs (if any). These allow customization\/extension of default Gatsby settings affecting the browser.\n\n\ngatsby-config.js: This is the main configuration file for a Gatsby site. This is where you can specify information about your site (metadata) like the site title and description, which Gatsby plugins you\u2019d like to include, etc. (Check out the config docs for more detail).\n\n\ngatsby-node.js: This file is where Gatsby expects to find any usage of the Gatsby Node APIs (if any). These allow customization\/extension of default Gatsby settings affecting pieces of the site build process.\n\n\ngatsby-ssr.js: This file is where Gatsby expects to find any usage of the Gatsby server-side rendering APIs (if any). These allow customization of default Gatsby settings affecting server-side rendering.\n\n\nLICENSE: This Gatsby starter is licensed under the 0BSD license. This means that you can see this file as a placeholder and replace it with your own license.\n\n\npackage-lock.json (See package.json below, first). This is an automatically generated file based on the exact versions of your npm dependencies that were installed for your project. (You won\u2019t change this file directly).\n\n\npackage.json: A manifest file for Node.js projects, which includes things like metadata (the project\u2019s name, author, etc). This manifest is how npm knows which packages to install for your project.\n\n\nREADME.md: A text file containing useful reference information about your project.\n\n\n\ud83c\udf93 Learning Gatsby\nLooking for more guidance? Full documentation for Gatsby lives on the website. Here are some places to start:\n\n\nFor most developers, we recommend starting with our in-depth tutorial for creating a site with Gatsby. It starts with zero assumptions about your level of ability and walks through every step of the process.\n\n\nTo dive straight into code samples, head to our documentation. In particular, check out the Guides, API Reference, and Advanced Tutorials sections in the sidebar.\n\n\n\ud83d\udcab Deploy\n\n\n","591":"About EISES\nThe EISES coding project has been separated into four subsections of the software to be implemented. These sections of the program are, in procedural order: data feed processing, fact generation, rule evaluation , and alert distribution (see below).\n[insert image here]\nCurrent Functionality\nFuture Applications\n\nEISES Development Checklist:\n( todo: \u2b1c, in progress: \ud83d\udd28, completed \u2714\ufe0f)\nLast Updated: 10\/08\/2019\nQuestions: madison.soden@noaa.gov\nData Processing:\n\u2714\ufe0f 1. Compile a testing data set to use when adapting EISES to be used in PE project.\n\nTesting data: \n\u2714\ufe0f OBS data\n\u2714\ufe0f ABS data\n\u2714\ufe0f Light attenuation (surface light and underwater light if possible)\n\u2714\ufe0f Deposition\n\u2714\ufe0f Waves\n\u2714\ufe0f Ocean Current information\n\n\ud83d\udd28 2. Adapt EISES's data loading scripts, and fact class definitions to accept information from these types on sensors.\n\ud83d\udd28 3. Adapt EISES's parsers to get data from thredds server and\/or parse csv file types.\n\n\ud83d\udd28 waiting to get copy of csv file format.\n\nFact Generation:\nRule Evaluation:\nAlert Distribution:\n\ud83d\udd28 1. Create use-case\/design document based on testing Alert request list (X\/J).\n\u2b1c 2. Review possible design\/development of alert distribution and web-based archives.\n","592":"ecaura\nThis application provides a visual experience for environmental reports.\nIt is a single page application, which you can load by pointing your browser to the model\/index.html. If you don't have a localhost set up, you can quickly get one by running python -m SimpleHTTPServer.\nKey Features\n\nEnter usage for water, electricity, waste, fuel, and food over time.\nVisualize absolute values for these areas over time\nVisualize relative values (compared to others in industry) for these areas over time\nReal time updates. If another user adds a datapoint, the application will automatically update all relevant visualizations.\n\nTechnologies Used\n\nHTML, Javascript, CSS, and JQuery for web work.\nD3 for charting.\nPolymer for formatting\nFirebase for backend, and for real-time updates.\n\n","593":"EnvironmentalDataLiteracy\nText an learning materials for the Environmental Data Literacy courses in the Center for Environmental Studies at Virginia Commonwealth University\n","594":"EnvironmentalReportCard\nWebpage hosting environmental report card maps\n","595":"EnvironmentalReportCard\nWebpage hosting environmental report card maps\n","596":"EnvironmentalEducationGame\n","597":"EnvironmentalEducationGame\n","598":"EnvironmentalDataPredict\nEnvironmental Data Predict\n","599":"EnvironmentalDataPredict\nEnvironmental Data Predict\n","600":"This app had been deployed to get some data (such tempreture) using nodeMCU and send them to server to drow graphs and show them to owner client.\n","601":"foodprint-calculator\nSetup\nnpm install\nnpm run dev\n\nDeploy\npush to master!\n\n","602":"EnvironmentalNewsAp\n","603":"umi project\nGetting Started\nInstall dependencies,\n$ yarn\nStart the dev server,\n$ yarn start\n","604":"umi project\nGetting Started\nInstall dependencies,\n$ yarn\nStart the dev server,\n$ yarn start\n","605":"Indoor Environmental Monitoring System\nOverview\nOur project is an Indoor environment monitor. The project's goal is to monitor, record,\nand display time series data for a given indoor environment. The sensors used in\nthis project will include a thermometer, humidity sensor, pressure sensor,\nlight detector, carbon dioxide, accelerometer, microphone and an airborne particle\ndetector. This data will be collected, recorded and displayed for the client on a central\nhub and a basic Android application as well as a REST interface for external integration.\nImplementation Details\nWe'll be using multiple microcontrollers to handle data collection and pre-processing.\nOur main microcontroller will handle the data collection and communication with the hub.\nAny secondary microcontrollers will be used to preprocess data in the event of a sampling rate\nfar higher than the communication rate, such as acoustic data and the accelerometer. This data\nwill be sent over WiFi\/HTTP over to the server which will store the data in MongoDB. MongoDB has\nbuilt in support for time series data, as well as a non-relational structure and low read\/write overhead\nwhich makes it ideal for IoT style applications such as this. This data is then exposed over a REST\nAPI, for easy querying from our Android application or any other service the user wants to integrate\nour system with.\nResources\nAnticipated cost is around $400 CAD. The bulk of this will be in the microcontroller, we expect to\nspend around $100 CAD on the microcontrollers, with most of the rest being sensors and other hardware.\nThe sensors, depending on their sensitivities and sampling rates, could be as expensive as $50 CAD,\nhowever the average will be far less than that. The balance will be tied up in packaging and\nother smaller items.\n","606":"YAPEC\nYet Another Parser for Environmental Configuration\nBecause there just aren't enough npm modules for getting config values from your enviroment already!\nTravis Status\n\n\nInstallation\nBe sane, use npm\n$ npm install yapec\notherwise clone this repo via git\n$ git clone https:\/\/github.com\/sandfox\/node-yapec.git\nUsage\nvar yapec = require('yapec');\nvar config = yapec(['PRE_FIX'], configSpec, process.env, opts);\nyapec takes a spec in the form of an object (which can be nested to your heart's content) where the leaf of every path must be a string which dictates how to parse the corresponding ENV_VAR string.\nThe path itself is converted into UPPERCASE, and dot seperators exchanged for underscores*.\nAn optional prefix may be supplied as the first arg which will act as a mask when searching the env object. An optional options object may be supplied, so far the only option is 'ignoreMissing' that accepts a bool, is false by default, and when true rather than throwing an exception if an ENV VAR is missing, instead returns a null for that value.\n*yes I realise this is probably not the clearest way to describe what it does but my brain is failing me at this point in time\nExamples\nSome of these examples can also be found in the examples folder inside this project.\nvar yapec = require('yapec');\n\n\/\/Represents something we could expect process.env to return\nvar env = {\n    APP_PATH: '\/opt\/appy',\n    APP_NAME: 'super server',\n    APP_SERVER_ENABLED: 'true',\n    APP_SERVER_PROCS: '8',\n    APP_SERVER_MAGIC: '2e2'\n}\n\nvar configSpec = {\n    app : {\n        path: 'string',\n        name: 'string',\n        server: {\n            enabled: 'bool',\n            procs: 'int',\n            magic: 'float'\n        }\n    }\n}\n\nvar config = yapec(configSpec, env);\n\nconsole.log(config)\n\/\/outputs the following\n{ app:\n   { path: '\/opt\/appy',\n     name: 'super server',\n     server: {\n        enabled: true,\n        procs: 8,\n        magic: 200 }\n    }\n}\nOptionally a prefix can be supplied as the first arguement which acts as a mask when looking through the enviroment variables.\nExample\nvar yapec = require('yapec');\n\nvar env = {\n    FALLOVER: 'true',\n    MY_APP_FALLOVER: 'false'\n}\n\nvar spec = {\n    fallover: 'bool'\n}\n\nvar config = yapec('MY_APP_', spec, env);\n\nconsole.log(config);\n\n{fallover:false}\nCaveats\nDue to the way this modules works certain combinations of ENV VAR strings are forbidden, for example the following would fail because it could not be resolved into an object in any sane way because app could not be both a string and object at the same time.\nAPP=\"super app\"\nAPP_DB_NAME=\"megadb\"\nAPP_DB_PORT=\"8000\"\nHelpers\nyapec also comes with helpers for creating configs from process.env style objects and for creating ENV VAR strings from a config object. Checkout the examples folder as it should be pretty self explanatory. todo - document this better\nyapec.getSpec([prefix], process.env)\nand\nyapec.getEnvStrings([prefix], config)\nStability Index\nBased up on node.js stability index\nStability: 2 - Unstable\nTesting\nCode is tested with mocha + should, just run npm test as usual.\nThe tests aren't bad, but they could be more complete. There are travis tests too!\nUpgrades, fixes, ideas\nAll ideas, bug fixes, suggestions etc are gladly excepted so feel free to raise pull requests and issues.\nLicense\n(The MIT License)\nCopyright (c) 2013 James Edward Butler AKA sandfox\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and\/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n","607":"EnvironmentalStatisticsMsc2020\nThis repository is supposed to give the opportunity for developing solutions together\n","608":"This was created as a submission to HackGT 2017.\nIt is built in Processing 3.\n","609":"Mhav env check on Jenkins\n","610":"Mhav env check on Jenkins\n","611":"Mhav env check on Jenkins\n","612":"Greening a PostIndustrial City:  Applying keyword extractor methods to monitor a fast-changing environmental narrative\nWorcester, Massachusetts (population just under 200,000) is the second largest city after Boston in Massachusetts, USA.  It was important in the American industrial revolution; factories dominated its landscape until the mid-20th century when the city slid physically, and mentally, into post-industrial decline.\nAt first glance, Worcester might present an all-too-familiar global story of gentrification, the loss of city identity and community, but does even a small survey of the historic record of local public discourse confirm this view? Or does a more complicated local story surface?\nTo answer these questions,  literary geographer Sarah Luria teams up with computer scientist Ricardo Campos, developer of the keyword extractor YAKE! to discover if it can create a helpful survey or image of stories told about a neighborhood over time. We believe this interdisciplinary work can play a crucial role by showing how Artificial Intelligence (AI) can track this fast-developing story of urban revitalization and environmental cleanup.\nFrom our survey we curated a small corpus of 26 English-language texts that described the Canal District\/Green Island over time. A majority of the texts are  from 2018-2019, but examples from 1862, 1917, the 1980s and 1990s provide some historic range. The corpus includes descriptions of the Canal District before the industrial revolution altered it dramatically, the building of its canal and railroad, the peak of its industrialization and identity as an Irish working class neighborhood,  its post-industrial decline, and its stages of revitalization. While a majority of texts come from the local major newspaper The Worcester Telegram Gazette, the corpus includes articles from New York Times, Boston Globe, and National Public Radio; also included are  Worcester-born poet Mary Fell\u2019s 1984 poem The Prophecy and historian Roy Rosenzweig\u2019s acclaimed history of Worcester\u2019s working class Eight Hours for What We Will (1985). A description of each one is given below.\nDataset details\nBelow we give some details of each text (sorted by date).\nFilename: 1 - 1862_Lincoln, from History of Worcester (archive.org) landscape description\nSource: William Lincoln, from History of Worcester Lincoln, William. History of Worcester, Massachusetts, from its earliest settlement to September, 1836 : with various notices relating to the history of Worcester County. Worcester: M.D. Phillips & Co., 1862.\nURL: https:\/\/archive.org\/details\/historyofworcest1836linc\/page\/n6\nPublication Date: 1862\nDescription: Worcester\u2019s landscape before the industrial revolution.\nTokens: 256\n\nFilename: 2 - 1879_Abijah Perkins Marvin, History of Worcester (archive.org), railroad descriptionn\nSource: Abijah Perikins Marvin, History of Worcester County, Massachusetts, embracing a comprehensive history of the country from its first settlement to the present time.  Boston; Jewett & Co, 1879, pp. 82-83.\nURL: https:\/\/archive.org\/details\/historyofworcest03marv\/page\/82\nPublication Date: 1879\nDescription: A description of the beginning of the Blackstone canal and the Worcester railroad.\nTokens: 638\n\nFilename: 3 - 1917_Washburn, Industrial History of Worcester (archive.org) re canal\nSource: Charles G. Washburn, Industrial Worcester. Worcester: The Davis Press, 1917, p. 23.\nURL: https:\/\/archive.org\/details\/industrialworces00wash\/page\/n6\nPublication Date: 1917\nDescription: Description of the creation of the Blackstone canal and its importance\nTokens: 199\n\nFilename: 4 - 1917_Washburn, Industrial History of Worcester (archive.org) re entrepreneurial spirit of city\nSource: Charles G. Washburn, Industrial Worcester. Worcester: The Davis Press, 1917, p. 31.\nURL: https:\/\/archive.org\/details\/industrialworces00wash\/page\/60\nPublication Date: 1917\nDescription: The introduction of steam-power to Worcester industries.\nTokens: 72\n\nFilename: 5 - 1917_Washburn, Industrial History, re importance of steam power\nSource: Charles G. Washburn, Industrial Worcester. Worcester: The Davis Press, 1917, p. 300.\nURL: https:\/\/archive.org\/details\/industrialworces00wash\/page\/60\nPublication Date: 1917\nDescription: Entrepreneurial spirit of city.\nTokens: 150\n\nFilename: 6 - 1983-25-9_Worcester Shedding Smokestack Image (New York Times)\nSource: \u201cWorcester Shedding Smokestack Image,\u201d New York Times. Sept. 25, 1983.\nPublication Date: 1983-25-9\nDescription:\nTokens: 911\n\nFilename: 7 - 1984_Mary Fell, The Prophecy (Poem)\nSource: Mary Fell, \u201cThe Prophecy\u201d, from the Persistence of Memory. 1984.\nURL: http:\/\/capa.conncoll.edu\/fell.persistence.html\nPublication Date: 1984\nDescription: Poem collection about Worcester.\nTokens: 328\n\nFilename: 8 - 1985_Roy Rosenzweig, Eight Hours For What We Will (history of recreation for industrial labor)\nSource: Roy Rosenzweig, Eight Hours For What We Will. Cambridge, UK: Cambridge, 1985.\nPublication Date: 1985\nDescription: A history of recreation for Worcester\u2019s industrial labor force.\nTokens: 287\n\nFilename: 9 - 1989-10-12_A New Look for an Old Area (New York Times) (Lafayette Place\/Green Island)\nSource: \u201cWorcester, Mass.: A New Focus for an Old Area,\u201d New York Times.\nPublication Date: 1989-10-12\nDescription: The building of new senior affordable housing in Green Island.\nTokens: 450\n\nFilename: 10 - 1997-11-18_Bureau urges liability relief for brownfields, WTG\nSource: Bronislaus B. Kush, \u201cBureau urges liability relief for brownfields,\u201d Worcester Telegram Gazette.\nPublication Date: 1997-11-18\nDescription:\nTokens: 585\n\nFilename: 11 - 1998-16-7_Green Island Businesses Say City Help Is Killing Them, WTG\nSource: Bronislaus B. Kush, \u201cGreen Island Businesses Say City Help Is Killing Them,\u201d Worcester Telegram Gazette.\nPublication Date: 1998-16-7\nDescription:\nTokens: 597\n\nFilename: 12 - 1999-12-1_Vacant Industrial Sites of No Use to Neighborhood, WTG\nSource: Winston W. Wiley, \u201cVacant Industrial Sites of No Use to Neighborhood,\u201d Worcester Telegram Gazette.\nPublication Date: 1999-12-01\nDescription:\nTokens: 436\n\nFilename: 13 - 2000-29-6_Green Island Revitalization Plan Dropped, WTG\nSource: Lisa Eckelbecker, \u201cGreen Island Revitalization Plan Dropped,\u201d Worcester Telegram Gazette.\nPublication Date: 2000-29-6\nDescription:\nTokens: 446\n\nFilename: 14 - 2007-25-9_Canal District Shapes Up: Old Buildings, New Life on Green Street, WTG\nSource: Shaun Sutner, \u201cCanal District Shapes Up: Old Buildings, New Life on Green Street,\u201d Worcester Telegram Gazette.\nPublication Date: 2007-25-09\nDescription:\nTokens: 645\n\nFilename: 15 - 2011-23-8_Life in Green Island: We have Hope. In City Times (local alternative newspaper)\nSource: Maureen Schwab, \u201cLife in Green Island: We have Hope,\u201d In City Times (local alternative newspaper).\nPublication Date: 2011-23-08\nDescription:\nTokens: 1149\n\nFilename: 16 - 2018-8-17_WooSox Ball Park Has Long History. Boston Globe\nSource: Tim Logan, \u201cNew Home for WooSox Has Long History,\u201d Boston Globe.\nPublication Date: 2018-8-17\nDescription:\nTokens: 632\n\nFilename: 17 - 2018-10-11_Time to Talk About Gentrification in Worcester, Worcester Mag.\nSource: Bill Shaner, \u201cIt\u2019s Time to Talk About Gentrification in Worcester,\u201d Worcester Magazine.\nPublication Date: 2018-10-11\nDescription:\nTokens: 4165\n\nFilename: 18 - 2018-10-23_Worcester: The New  \u201cIt Town.\u201d National Public Radio\nSource: Aaron Schachter, \u201cWorcester: The New\u2018It\u2019 Town.\u201d National Public Radio: WGBH.\nPublication Date :2018-10-23\nDescription:\nTokens: 1184\n\nFilename: 19 - 2018_Worcester, A City Reclaimed.  Vitality Magazine\nSource: Bernard Whitmore, \u201cA Mayor, A Manager, A City Reclaimed.\u201d  Vitality Magazine.\nPublication Date: 2018-11\nDescription:\nTokens: 2077\n\nFilename: 20 - 2019-2-27_Worcester Organizers Hear from Nashville, Buffalo on Tips for WooSox CBA Push, Worcester Mag.\nSource: Bill Shaner, Worcester Organizers Hear from Nashville, Buffalo on Tips for WooSox CBA Push,\u201d Worcester Magazine.\nPublication Date: 2019-02-27\nDescription:\nTokens: 540\n\nFilename: 21_2019-4-10_A Totally Cool Place to Live. MassLive?\nSource: Aviva Luttrell, \u201cA Totally Cool Place to Live,\u201d MassLive.com.\nPublication Date: 2019-04-10\nDescription:\nTokens: 497\n\nFilename: 22 - 2019-6-1_New Shine for Old Building: Former Walker Shoe Factory to be Converted into Studios. WTG\nSource: Scott O\u2019Connell, \u201cNew Shine for Old Building: Former Walker Shoe Factory to be Converted into Studios,\u201d Worcester Telegram Gazette.\nPublication Date: 2019-06-01\nDescription:\nTokens: 468\n\nFilename: 23 - 2019-6-20_Construction, WooSox, and Regulation are Killing Canal District Dreams. Worcester Business Journal\nSource: Renee Diaz, \u201cConstruction, WooSox, and Regulation are Killing Canal District Dreams,\u201d Worcester Business Journal.\nPublication Date: 2019-06-20\nDescription:\nTokens: 739\n\nFilename: 24 - 2019-6-24_Worcester Gets Brownfield Funds. WTG\nSource: \u201cWorcester Gets Brownfield Funds,\u201d Worcester Telegram Gazette.\nPublication Date: 2019-06-24\nDescription:\nTokens: 517\n\nFilename: 25 - 2019-6-24_Worcester Pledges $3M to Green Island. WTG\nSource: Kim Ring, \u201cWorcester Pledges $3M to Green Island,\u201d Worcester Telegram Gazette.\nPublication Date: 2019-06-24\nDescription:\nTokens: 490\n\nFilename: 26 - 2019-7-6_An Away Game for Businesses; Property Owners Near Ballpark Site Make Way for Development. WTG\nSource: \u201cAn Away Game for Businesses; Property Owners Near Ballpark Site Make Way for Development,\u201d Worcester Telegram Gazette.\nPublication Date: 2019-07-06\nDescription:\nTokens: 1322\n\n","613":"EnvironmentalNewsApp\nEnvironmentalNewsApp\n","614":"EnvironmentalNewsApp\nEnvironmentalNewsApp\n","615":"ESResNet\nEnvironmental Sound Classification Based on Visual Domain Models\nThis repository contains implementation of the models described in the paper arXiv:2004.07301 (submitted to ICPR 2020).\nAbstract\nEnvironmental Sound Classification (ESC) is an active research area in the audio domain and has seen a lot of progress in the past years. However, many of the existing approaches achieve high accuracy by relying on domain-specific features and architectures, making it harder to benefit from advances in other fields (e.g., the image domain). Additionally, some of the past successes have been attributed to a discrepancy of how results are evaluated (i.e., on unofficial splits of the UrbanSound8K (US8K) dataset), distorting the overall progression of the field.\nThe contribution of this paper is twofold. First, we present a model that is inherently compatible with mono and stereo sound inputs. Our model is based on simple log-power Short-Time Fourier Transform (STFT) spectrograms and combines them with several well-known approaches from the image domain (i.e., ResNet, Siamese-like networks and attention). We investigate the influence of cross-domain pre-training, architectural changes, and evaluate our model on standard datasets. We find that our model out-performs all previously known approaches in a fair comparison by achieving accuracies of 97.0 % (ESC-10), 91.5 % (ESC-50) and 84.2 % \/ 85.4 % (US8K mono \/ stereo).\nSecond, we provide a comprehensive overview of the actual state of the field, by differentiating several previously reported results on the US8K dataset between official or unofficial splits. For better reproducibility, our code (including any re-implementations) is made available.\nHow to run the model\nThe required Python version is >= 3.7.\nESResNet\nOn the ESC-10 dataset\npython main.py --config protocols\/esc10\/esresnet-esc10-cv1.json --Dataset.args.root \/path\/to\/ESC10\n\nOn the ESC-50 dataset\npython main.py --config protocols\/esc50\/esresnet-esc50-cv1.json --Dataset.args.root \/path\/to\/ESC50\n\nOn the UrbanSound8K dataset (stereo)\npython main.py --config protocols\/us8k\/esresnet-us8k-stereo-cv1.json --Dataset.args.root \/path\/to\/UrbanSound8K\n\nReproduced results\nLMCNet on the UrbanSound8K dataset\npython main.py --config protocols\/us8k\/lmcnet-us8k-cv1.json --Dataset.args.root \/path\/to\/UrbanSound8K\n\n","616":"ESResNet\nEnvironmental Sound Classification Based on Visual Domain Models\nThis repository contains implementation of the models described in the paper arXiv:2004.07301 (submitted to ICPR 2020).\nAbstract\nEnvironmental Sound Classification (ESC) is an active research area in the audio domain and has seen a lot of progress in the past years. However, many of the existing approaches achieve high accuracy by relying on domain-specific features and architectures, making it harder to benefit from advances in other fields (e.g., the image domain). Additionally, some of the past successes have been attributed to a discrepancy of how results are evaluated (i.e., on unofficial splits of the UrbanSound8K (US8K) dataset), distorting the overall progression of the field.\nThe contribution of this paper is twofold. First, we present a model that is inherently compatible with mono and stereo sound inputs. Our model is based on simple log-power Short-Time Fourier Transform (STFT) spectrograms and combines them with several well-known approaches from the image domain (i.e., ResNet, Siamese-like networks and attention). We investigate the influence of cross-domain pre-training, architectural changes, and evaluate our model on standard datasets. We find that our model out-performs all previously known approaches in a fair comparison by achieving accuracies of 97.0 % (ESC-10), 91.5 % (ESC-50) and 84.2 % \/ 85.4 % (US8K mono \/ stereo).\nSecond, we provide a comprehensive overview of the actual state of the field, by differentiating several previously reported results on the US8K dataset between official or unofficial splits. For better reproducibility, our code (including any re-implementations) is made available.\nHow to run the model\nThe required Python version is >= 3.7.\nESResNet\nOn the ESC-10 dataset\npython main.py --config protocols\/esc10\/esresnet-esc10-cv1.json --Dataset.args.root \/path\/to\/ESC10\n\nOn the ESC-50 dataset\npython main.py --config protocols\/esc50\/esresnet-esc50-cv1.json --Dataset.args.root \/path\/to\/ESC50\n\nOn the UrbanSound8K dataset (stereo)\npython main.py --config protocols\/us8k\/esresnet-us8k-stereo-cv1.json --Dataset.args.root \/path\/to\/UrbanSound8K\n\nReproduced results\nLMCNet on the UrbanSound8K dataset\npython main.py --config protocols\/us8k\/lmcnet-us8k-cv1.json --Dataset.args.root \/path\/to\/UrbanSound8K\n\n","617":"AI_EnvironmentalLighting\nThis is a bit of a niche mod.  It is mainly intended for people that like to use DHH in the main game, but hate that it messes with the in game day\/night light cycle.  DHH replaces some of the ambient\/direct light that changes depending on time of day and position of the sun\/moon with a static light source.  This causes the night, and especially the moon light to be way too bright.  The mod restores the in game lighting to its normal behavior, but lets you use all of the other really neat features of DHH like color balancing.\nThis mod also adds some other features that work with or without DHH.  These features give you more control over the environmental lighting to adjust them as you see fit.  These features include:\nAutomatically blends the day light and moon light settings.  Normally in game there is a harsh transition from day light to moon light that you can see, this blends the transition so it looks like a more natural sunrise\/sunset.\nAllow you to control what style of ambient light to use, so you can swith to Skybox or Trilight (default) if you choose.  Skybox mode automatically calculates ambient light based off of the time of day.\nIncreases the number of skybox calculations during dawn\/dusk.  The default settings don't update rapidly enough during this transition period.\nIndependet contols of daytime and nighttime ambient light with blending between the day\/night cycles.\nAllows modifications to the direct sun and moon light settings.  Unlike DHH, these modify the base values instead of replace so it still follows the in game light calculations.\n","618":"AoZer_EnvironmentalProtection\n","619":"GreenFerries\nImprove passenger ships environmental impact transparency\nLive website: greenferries.org\n\n\nEcosystem\n\n\nPublic Website: The\nmain public-facing static website. Uses the EleventyJS framework and TailwindCSS\n\n\nData platform:\ndatasets, APIs and iPython notebooks to explore the different original data\nsources that were used to create the GreenFerries database\n\n\nScrapers:\nScrapers used to populate data from ferries booking websites\n\n\nScreenshot\n\n","620":"EnvironmentalSampleLogger\nAn application which helps environmental consultants visualize the distribution of subsurface soil\nwhen drilling boreholes. The user can create a new borehole location, and add samples specify\nparameters such as colour, stratigraphy, and whether or not the sample is odourous. Save your\nprogress and come back to it later.\n\n\n","621":"EnvironmentalPollution\nINFO 5100 - Project 3\nThis project focuses on some typical and dangerous environment pollutants and its connection to health. We designed a map, a linear regression graph and a bubble chart to presents pollutants\u2019 distribution, its relation to longevity and disease.\n","622":"meds-demo\nTeaching demonstration for UCSB Masters in Environmental Data Science\nPlease visit for more on background, prerequisites and setup:\nhttps:\/\/benbestphd.com\/meds-demo\nwebsite\nThe website was generated using bookdown.\n","623":"Environmental-Detection-System\nThis is my unversity graduated project which is related with IOT.\nThe goal of this project is for detecting environment.\n1.Setting web server and mysql server in Respberry Pi\n2.Using humidity sensor and Pi camera to detect\/watch environment\n3.Showing the result on website\n","624":"Stochastic\/Environmental Signal Processing: ECEN 5224\n","625":"EnvironmentalChamberCode\nWalker Wind's code for humidity sensors, flask website setup, and html templates\n6\/13\/19\nChris and Ethan's Lab\nFiles in the repository:\nhumidsensors.py ::\nWhen run, this program records humidity and temperature sensor data using the Adafruit DHT library, and outputs a two text files and a     jpg file. The two text files, titled humiddataA and humiddataB, have a text chart that displays the exact numbers of each data point.\nThe jpg file is a chart with four subplots displaying the data using the python library matplotlib\nTo run, use the command line input:\n$python humidsensors.py\n\nhumidwebsite.py ::\nThis code is used to set up the flask web server. Using the flask library, it implements several pages connected to the local webserver     that the Raspberry Pi puts out on the network it is connected to. The website has a couple different pages\n$sudo FLASK_APP=humidwebsite.py flask --host=0.0.0.0 --port=80\n\nindexpage.html ::\nThis is html code used to design a template for the index page\nchartdata.html ::\nThis is html code used to display an image\ntextchart.html ::\nThis is html code used to display a text file\n","626":"EnvironmentalChamberCode\nWalker Wind's code for humidity sensors, flask website setup, and html templates\n6\/13\/19\nChris and Ethan's Lab\nFiles in the repository:\nhumidsensors.py ::\nWhen run, this program records humidity and temperature sensor data using the Adafruit DHT library, and outputs a two text files and a     jpg file. The two text files, titled humiddataA and humiddataB, have a text chart that displays the exact numbers of each data point.\nThe jpg file is a chart with four subplots displaying the data using the python library matplotlib\nTo run, use the command line input:\n$python humidsensors.py\n\nhumidwebsite.py ::\nThis code is used to set up the flask web server. Using the flask library, it implements several pages connected to the local webserver     that the Raspberry Pi puts out on the network it is connected to. The website has a couple different pages\n$sudo FLASK_APP=humidwebsite.py flask --host=0.0.0.0 --port=80\n\nindexpage.html ::\nThis is html code used to design a template for the index page\nchartdata.html ::\nThis is html code used to display an image\ntextchart.html ::\nThis is html code used to display a text file\n","627":"EnvironmentalChamberCode\nWalker Wind's code for humidity sensors, flask website setup, and html templates\n6\/13\/19\nChris and Ethan's Lab\nFiles in the repository:\nhumidsensors.py ::\nWhen run, this program records humidity and temperature sensor data using the Adafruit DHT library, and outputs a two text files and a     jpg file. The two text files, titled humiddataA and humiddataB, have a text chart that displays the exact numbers of each data point.\nThe jpg file is a chart with four subplots displaying the data using the python library matplotlib\nTo run, use the command line input:\n$python humidsensors.py\n\nhumidwebsite.py ::\nThis code is used to set up the flask web server. Using the flask library, it implements several pages connected to the local webserver     that the Raspberry Pi puts out on the network it is connected to. The website has a couple different pages\n$sudo FLASK_APP=humidwebsite.py flask --host=0.0.0.0 --port=80\n\nindexpage.html ::\nThis is html code used to design a template for the index page\nchartdata.html ::\nThis is html code used to display an image\ntextchart.html ::\nThis is html code used to display a text file\n","628":"EnvironmentalChamberCode\nWalker Wind's code for humidity sensors, flask website setup, and html templates\n6\/13\/19\nChris and Ethan's Lab\nFiles in the repository:\nhumidsensors.py ::\nWhen run, this program records humidity and temperature sensor data using the Adafruit DHT library, and outputs a two text files and a     jpg file. The two text files, titled humiddataA and humiddataB, have a text chart that displays the exact numbers of each data point.\nThe jpg file is a chart with four subplots displaying the data using the python library matplotlib\nTo run, use the command line input:\n$python humidsensors.py\n\nhumidwebsite.py ::\nThis code is used to set up the flask web server. Using the flask library, it implements several pages connected to the local webserver     that the Raspberry Pi puts out on the network it is connected to. The website has a couple different pages\n$sudo FLASK_APP=humidwebsite.py flask --host=0.0.0.0 --port=80\n\nindexpage.html ::\nThis is html code used to design a template for the index page\nchartdata.html ::\nThis is html code used to display an image\ntextchart.html ::\nThis is html code used to display a text file\n","629":"Corporate environmental performance prediction in China: An empirical study of energy service companies\nAuthors: Saina Zheng Chenhang He, Shu-Chien Hsu, Joseph Sarkis and Jieh-Haur Chen\nThis code was originally used in the paper \"Corporate environmental performance prediction in China: An empirical study of energy service companies\", it contains three fundalmental\nmachine learning regression model Random Forest, SVM and XGBoost. The code is well commented and can be easy to used by anyone with beginner level of python programming skills.\nThe evaluation metrics and some visualization code are also included.\nDependencies\n\npython (tested on 3.5)\nscikit-learn\nXGBoost\npandas\n\nCitation\nIf you find this work useful in your research, please consider cite:\n@article{zheng2020CEPPC,\ntitle={Corporate environmental performance prediction in China: An empirical study of energy service companies },\nauthor={Saina Zheng, Chenhang He, Shu-Chien Hsu, Joseph Sarkis, and Jieh-Haur Chen},\njournal={Journal of Cleaner Production (JCLP)},\nyear={2020}\n}\n\n","630":"OGC API - EDR Sprint 2\n\nThis Github repository is for the second OGC API - EDR code sprint focusing on the OGC API - Environmental Data Retrieval candidate standard.\n#OGCAPI\nAbout the Code Sprint\nThe Open Geospatial Consortium (OGC) invites developers to the OGC API - EDR Sprint 2 virtual event to be held through remote participation\/web-conferencing on November 9-10, 2020, from 9:00am 5:30pm EST. Registration for the OGC API - EDR Sprint 2 virtual event and the associated pre-event Webinar is here.\nThe code sprint will focus on refining the OGC API - Environmental Data Retrieval candidate standard. The candidate standard uses current web technologies and best practices to enable end-users - or anyone with web development experience - to easily identify and retrieve a subset of data from \u2018big data\u2019 stores. The idea is to save those users interested in environmental (or other) data from having to transfer and deal with datasets that inevitably contain data concerning areas or time periods that are irrelevant to their interests.\nRegister at https:\/\/portal.ogc.org\/public_ogc\/register\/202011q4_api_edr.php\n\nSprint Description\nAPI Specs\nSprint Logistics\nSchedule\/Agenda\nImplementations\nDatasets\nWhat is everybody going to be working on?\nLessons and Next Steps\nAdditional Resources\nFrequently Asked Questions (FAQs)\n\nThe sprint will begin at 09:00am EST on the first day, and end at 05:00pm EST on the second day.\n","631":"EnvironmentalGameMS\n","632":"EnvironmentalGameMS\n","633":"\n\nSEAStAR - A framework for the analysis of next-generation metagenomes\nThe Basics\nSEAStAR is a package of tools supporting the construction of complete analysis pipelines for next-generation (Illumina\u00ae, SOLiD\u2122) sequencing data generated from environmental samples.\nIt includes high-performance tools for dealing with:\n\nConverting between file formats (CSFASTA -> FASTQ)\nTrimming raw reads for quality (with tuning support)\nPCR de-duplication of paired reads (without reference sequences)\nSelecting and estimating the relative abundance of sequences from large reference databases (e.g. 16S rDNA)\nSub-sampling paired FASTQ files randomly, or based on reads included in (or excluded from) reference alignments\nConverting assembled color-space (SOLiD) contigs to nucleotide-space\nConnecting assembled contigs together via paired reads (constructing an assembly graph)\nSplitting complicated metagenomic assembly graphs into well-supported scaffolds\nBinning scaffolds by organism using tetra-nucleotide statistics\nIdentifying small circular scaffolds that are likely virus or plasmid genomes\n\nSEAStAR works with, but does not supply:\n\nShort-read sequence aligners (e.g. BWA, Bowtie)\nDe novo contig assemblers (e.g. Velvet)\nTools for visualizing assembly graphs (e.g. GraphViz, ZGRViewer)\n16S Taxonomic classifiers (e.g. RDP Classifier)\n\nYou can find out more about SEAStAR on its Armbrust Lab Homepage.\nThis file contains information on how to build and install the SEAStAR tools. For information on using the tools themselves, please see the included SEAStAR User Guide file.\nLicense\nSEAStAR is released under the GPLv3 license, a copy of which is provided in the included file \"COPYING\". By using this software, you are agreeing to be bound by the terms of this license.\nInstallation\nThe instructions that follow are for building the SEAStAR tools from source code.\nSEAStAR is designed to build and run on any 64-bit Unix-like system, including Linux and Mac OS X version 10.7 or later. Many components of SEAStAR are optimized for multiple CPU cores and require substantial memory. We recommend a machine with a minimum of 4 CPU cores and 32 GB of RAM to run these tools.  Depending on your datasets and what you are trying to do (e.g. de novo assembly) you may require a substantially more powerful machine than this minimum recommendation.\nThe SEAStAR package has dependencies on a small number of software packages that you (or your system administrator) may need to install or update. The process described in the next section will notify you if your system is missing any of these components.\nRequired Tools:\n\ngcc -- version 4.2 or newer, supporting OpenMP (version 4.7 recommended)\ncmake -- version 2.8.5 or newer\nnode.js -- version 0.10 or newer\ngawk -- version 3.1.5 or newer (version 4.0.2 recommended)\n\nAdditional instructions are available below for fulfilling these requirements for Mac OS X, and for programmers wishing to make modifications to the included source code.\nOnce you have the above packages: To build SEAStAR using Unix style command line tools, run the following commands from the directory where all files generated in the build process should be placed (including executables). This is your \"destination tree\".\ncmake [dir]\nmake\n\nWhere [dir] is the path to the root of the SEASTAR source tree (where this README file is found).\nIf the path \".\" is used for [dir] above (run from the \"source tree\"), then the binary and source tree will be the same (an \"in-source build\"). After a successful make, executables will be found in the bin\/ subdirectory.\nThis directory (the bin subdirectory of the destination tree) should be added to your PATH environment variable, so that newly built tools can be found from your data analysis directories:\nexport PATH=$PATH:[dest_dir]\/bin   # Where [dest_dir] is the fully qualified path to your destination tree directory\n\nTo test the newly built components:\nmake test\n\nIf any tests fail, do not use the executables!\nTo clean all files generated in the source directory for an in-source build (this will only work for git checked-out repositories):\ngit clean -fxd\n\nFor an out-of-source build you can simply delete the destination tree directory and start again.\nAdditional installation details for Mac OS X\nFor Mac OS X users: To fulfill the above requirements, you will first need to download and install Apple's \"Command Line Developer Tools\".\nxcode-select --install\n\nAnd then we recommend installing the other required packages using HomeBrew or MacPorts.\nHomeBrew (preferred)\nVisit the link below to download and install HomeBrew.\n\nhttps:\/\/brew.sh\/\n\nThen run the following commands to install the required packages:\nbrew update\nbrew install cmake\nbrew install node   # Node may also optionally be installed using nvm\nbrew install gawk\nbrew install gcc@8\n\nMacPorts\nVisit the link below to download and install MacPorts.\n\nhttp:\/\/www.macports.org\/install.php\n\nThen run the following commands to install the required packages:\nsudo port selfupdate\nsudo port install cmake\nsudo port install node  # Node may also optionally be installed using nvm\nsudo port install gawk\nsudo port install gcc8  # or whatever version you may prefer\n\nAn important note about compilers on Mac OS X :\nXcode's default Clang-based compiler does not support OpenMP (a standard for writing efficiently parallelized C code); this is why we specify above that you must install the gcc compiler. The cmake script provided checks OS X systems to see if the OpenMP support is working correctly with the default (or specified) C compiler. If you receive an error when trying to build that says \"You need to install gcc (version 4.4 or later)\" it is because our build system is attempting to use the Xcode compiler, and not the one you installed using HomeBrew or MacPorts.\nYou will need to define an environment variable to explicitly tell cmake which compiler to use. Note that this must be done each time you start a command line session where you wish to run cmake again (or add it to your shell startup file, e.g. .bash_profile in your home directory).  For example:\nexport CC=\/usr\/local\/bin\/gcc-8  # Homebrew\n\nor\nexport CC=\/opt\/local\/bin\/gcc-8  # MacPorts\n\nChange the numbers above if you are using a different version!\nNote: It may also be possible, with some more work, to use a newer version of clang than provided by Apple to compile with OpenMP support, but we mave not tested this. Both HomeBrew and MacPorts enable installation of LLVM 7 (which includes the clang C compiler). Have fun with that!\nFor Developers\nSome of the included JavaScript (.js) files are automatically generated from CoffeeScript source files (CoffeeScript is a transcompiled dialect of JavaScript with Python-like syntax.) If you wish to modify these components, please edit the .coffee files in the scripts\/ subdirectory of the source tree. The make system will automatically regenerate the .js files in the bin\/ subdirectory of the destination tree. To successfully transcompile these files, you will need the to install the CoffeeScript package for node.js:\nsudo npm install -g coffee-script\n\nIt is sometimes useful to build with GCC debug flags turned on.  To achieve this follow the normal cmake build procedure with one additional user defined cmake cache entry:\ncmake -D DEBUG=ON [dir]\n\n","634":"OPERA\nOPERA is a free and open-source\/open-data suite of QSAR models providing predictions on physicochemical properties, environmental fate and toxcicity endpoints as well as additional information including applicability domain and accuracy assessment. All models were built on curated data and standardized QSAR-ready chemical structures. OPERA is available in command line and user-friendly graphical interface for Windows and Linux operating systems. It can be installed as a standalone desktop application or embedded in a different tool\/workflow.\nReferences:\n[1] Mansouri K. et al. J Cheminform (2018) https:\/\/doi.org\/10.1186\/s13321-018-0263-1.\n[2] Mansouri, K. et al. SAR and QSAR in Env. Res. (2016). https:\/\/doi.org\/10.1080\/1062936X.2016.1253611\n[3] Williams A. J. et al. J Cheminform (2017) https:\/\/doi.org\/10.1186\/s13321-017-0247-6\n[4] The CompTox Chemistry Dashboard https:\/\/comptox.epa.gov\/dashboard\n[5] JRC QSAR Model Database https:\/\/qsardb.jrc.ec.europa.eu\/qmrf\/endpoint\n[6] Mansouri, K. et al. EHP (2016) https:\/\/doi.org\/10.1289\/ehp.1510267\n[7] Mansouri, K. et al. J Cheminform (2019) https:\/\/doi.org\/10.1186\/s13321-019-0384-1\n[8] Mansouri, K. et al. EHP (2020) https:\/\/doi.org\/10.1289\/EHP5580\nModels:\n      + Molecular descriptors:  \n- PaDEL (2.21) (https:\/\/doi.org\/10.1002\/jcc.21707 )\n- CDK (2.0) (https:\/\/doi.org\/10.1186\/s13321-017-0220-4)\n\n\n      + New models (since v2.0):\n\n\n- FuB: Plasma fraction unbound (human)\n\n- Clint: hepatic intrinsic clearance (human)\n\n- pKa: acid dissociation constant\n\n- LogD: Octanol-water distribution constant. LogD is equivalent to logP for non-ionisable compounds.\n\n- CERAPP: Collaborative Estrogen Receptor Activity Prediction Project. Binding, Agonist and Antagonist Estrogen Receptor activity (https:\/\/ehp.niehs.nih.gov\/15-10267\/)\n\n- CoMPARA: Collaborative Modeling Project for Androgen Receptor Activity. Binding, Agonist and Antagonist Androgen Receptor activity (https:\/\/doi.org\/10.13140\/RG.2.2.19612.80009, https:\/\/doi.org\/10.13140\/RG.2.2.21850.03520)\n\n- CATMoS: Collaborative Acute Toxicity Modeling Suite. Very-Toxic, Non-Toxic, EPA categories, GHS categories, LD50 (Log mg\/kg) (https:\/\/doi.org\/10.1016\/j.comtox.2018.08.002)\n\n- Structural Properties: MolWeight, nbAtoms, nbHeavyAtoms, nbC, nbO, nbN, nbAromAtom, nbRing, nbHeteroRing, Sp3Sp2HybRatio, nbRotBd, nbHBdAcc, ndHBdDon, nbLipinskiFailures, TopoPolSurfAir, MolarRefract, CombDipolPolarizability.\n\n\n      + Previous models (since v1.5):\n\n\n- OH (LogOH) in cm3\/molecule-sec: The OH rate constant for the atmospheric, gas-phase reaction between photochemically produced hydroxyl radicals and organic chemicals.\n\n- BCF (Log): Fish bioconcentration factor\n\n- Biodeg (LogHalfLife) in days: biodegradation half-life for compounds containing only carbon and hydrogen (i.e. hydrocarbons). \n\n- Ready_biodeg (classification: 0\/1): Ready biodegradability of organic chemicals. \n\n- BP in deg C: Boiling Point at 760 mm Hg\n\n- HL (LogHL) in atm-m3\/mole: The Henry\u2019s Law constant (air\/water partition coefficient) at 25C\n\n- Km (Log KmHL) half-lives in days: The whole body primary biotransformation rate constant for organic chemicals in fish. \n\n- KOA (Log): The octanol\/air partition coefficient.\n\n- LogP (Log): Octanol-water partition coefficient, log KOW, of chemicals.\n\n- MP in deg C: Melting Point\n\n- Koc (Log) in L\/Kg: the soil adsorption coefficient of organic compounds. \u00a0The ratio of the amount of chemical adsorbed per unit weight of organic carbon in the soil or sediment to the concentration of the chemical in solution at equilibrium.\n\n- VP (Log) in mmHg: Vapor Pressure experimental values between 15 and 30 deg C (majority at 25-20C)\n\n- WS (Log) in Molar moles\/L: Water solubility at 25C. \n\n- RT in minutes: HPLC retention time.\n\n","635":"software-engineering\nProgetto\n","636":"Palladio-Addons-EnvironmentalDynamics\nEnvironmental dynamics comprises modeling and analysis capabilities to enhance the PCM with probabilistic specifications of the execution environment.\n","637":"Environmental Science Associates  \nJekyll theme based on Freelancer bootstrap theme \n","638":"MoodCube\n3D lattice of RGB LEDs driven by ANN with environmental sensors as inputs\nExisting Things\n\nProgrammable cube ($390) with Mic and Acc:  http:\/\/cubetube.org\/\nhttp:\/\/www.instructables.com\/id\/8X8X8-RGB-LED-Cube\/\nNeoPixel (https:\/\/learn.adafruit.com\/adafruit-neopixel-uberguide\/overview) single wire, RGB\nAudio Spectrum Analyzer with Pi\n\nSignal Flow\n\nSomething acquires a sample each from many sensors\nThese samples are passed to a Neural Network which does some nonlinear processing on the vector of input time series.\nThe outputs of the NN are passed to a an output processor, which takes the outputs and writes them to the LEDs.\n\n\nLED Drive\n\nThe NeoPixel or DotStar style of Arduino \/ Raspberry Pi compatible LEDs are a single strip of addressable RGB LEDs.\n\nthere are 3rd party products also like HKBAYI\n\n\nThe FadeCandy board takes a USB input and can drive 8 strips having 64 LEDs each. That's a total of 8x64 = 512 LEDs.\n\ncould do a cube with 4 sides + 1 top. 10x10 LEDs per side = 500 total.\n\n\nThe LED strips can be mounted on some clear plastic rods so as to make the shape into something like a cube.\n\nuse a 3D printer to make some wild shapes to mount it on: trees, spheres, Japanese lantern, Klein bottle\nmaybe hang them from a frame like Hanging Gardens or the living trees in Avatar\n\n\nneeds ~60 mA per LED for full power. Should use a 5V, 10A AC\/DC adapter and a power bus to spread power to each strip.\n\n\n\n\nGitHub Markdown: https:\/\/guides.github.com\/features\/mastering-markdown\/\n\nLearning\n\nstochastic gradient method with least mean squares\n\nsynapse sensors (sources)\n\naudio                     data=((CHUNK,), int16), fs=1\/CHUNK, (-16k, 16k)\naudio_blrms:chunk,bands   data=((bands,), int16), fs=1\/chunk, (-16k, 16k)\nproximity:fs              data=((bands,), int16), fs=fs,      (0, 400)\ndate:fs                   data=(dt.weekday(), dt.hour, dt.minute, dt.second), fs=fs\n\nsynapse auto-start with systemd\nBoth the fcserver and synapse processes will auto-start using the \"pi\"\nuser system --user session:\n\n\/home\/pi\/.config\/systemd\/user\/fcserver.service\n\/home\/pi\/.config\/systemd\/user\/moodcube.service\n\nThe services are called \"fcserver\" and \"moodcube\".  They launch the\nfollowing scripts:\n\nfcserver: \/home\/pi\/GIT\/MoodCube\/FadeCandy\/fcserver_launch.sh\nmoodcube: \/home\/pi\/GIT\/MoodCube\/launch\n\nYou can control the processes using the \"systemctl --user\" command.  *\nshow service status:\n$ systemctl --user status moodcube\n\n\nreload configuration (only needed if you change the config file in\n~\/.config\/systemd\/user\":\n$ systemctl --user daemon-reload\n\n\nrestart service:\n$ systemctl --user restart moodcube\n\n\nstop service:\n$ systemctl --user stop moodcube\n\n\nfollow logs:\n$ journalctl -f\n$ journalctl -f -o cat   (more terse)\n\n\n","639":"MonalisR \n\n\n\nHandling open Databases in South Tyrol\nThis R-Package is designed to interact with open environmental databases in the Autonomous Province of South Tyrol in Italy. Our mission is to use exposed APIs in order to etrieve a multitude of environmental variables. This approach guarantees a steady and reproducible access to a wide variety of data potentially interesting for diverse scientific research.For each database core functionalities were implemented aiming at simplifying:\n\ndata access and exploration\ndownload and storage of the desired data set(s)\nspatial plotting of the data \n\nFor each database the respective functions are divided according to these three tasks. Following that, the naming conventions utilize the prefixes get, plot and download.\nDatabases\nThis package offers the possibility to access databases exposing JSON Files with Sensor Observation Service (SOS) convention defined by the Open Geospatial Consortium (OGC) or by CKAN APIs. We implemented the access to two different Databases as exposed by EURAC Research and the OpenData Portal South Tytol.\nBoth Databases offer rich environmental and meteorological Databases across the province of South Tyrol.\nMONALISA\nThe MONALISA project (MONitoring key environmental parameters in the ALpine environment Involving Science, technology and Application) aims at the development of multi-scale monitoring approaches for key environmental parameters and production processes using innovative monitoring technologies and non-destructive methods in the application field of agriculture.\nWithin this project the MONALISA Database has been created to store and distribute the wide variety of environmental parameters collected.\nOpen Data Portal South Tyrol - Meteo Data\nA second platform to retrieve open data for scientific applications is now openly accessible via the Open Data Portal of the Autonomous Province of South Tyrol. On this platform multiple meteorological variables have been opened to the public. A central API handles the request for each single database stored. For now the package offers the possibility to access one of these databases is addressable with this package containing meteorological data of several fixed Stations continuously operated by the Meteorological Service of South Tyrol.\nDownload the Package\nThe stable versions of the packages will be shared on the Github and can be downloaded without the need to provide the credentials: \nlibrary(devtools)\n\ndevtools::install_github(\"https:\/\/github.com\/mattia6690\/MonalisR\")\n\nContributors & Contact\nMattia Rossi \nDaniel Frisinghelli \n\n","640":"env\nEnvironmental configuration files to be shared across any machine I happen to\nbe using.\nIn addition to these files, it have also installed git completion manually\n(not sure if this is still needed):\nhttps:\/\/raw.githubusercontent.com\/git\/git\/master\/contrib\/completion\/git-completion.bash\nvim\nFor vim, install these plugins by cloning into\n${HOME}\/.vim\/pack\/bundle\/start\/. The following are a list of vim libraries\nI've used at one point or another.\n\nvim-slime Inject from one tmux\npane to another.\nale Asynchronous Lint Engine\ntabular Auto-align text,\ntypically by a record separator. For example, :Tabularize \/| aligns on\npipe characters.\nvim-repeat Allows using . with\nplugins.\nvim-sandwich\nnerdcommenter Code\ncommenting functions.\nvim-grepper Grepper for\nasynchronous greps\nrainbow For rainbow\nparentheses.\n\nClojure\n\nvim-clojure-static\nvim-iced\nvim-sexp\n\nErlang\n\nerlang-motions\nvim-erlang-compiler\nvim-erlang-tags\nvim-erlang-omnicomplete\n\nElixir\n\nalchemist\nphoenix\n\nvim Colors\nI've been favoring light themes for a bit now, but I keep a sparse\n..vim\/colors\/ directory. Currently using\nPaperColor,\nbut have also been happy with\nsolarized8_flat.\nCTags\nI sometimes set up projects to use ctags.\nuniversal-ctags\nOCaml\nI'm not actively developing in OCaml at the moment, but I still like to have\nit set up in my environment, particularly so I can take advantage of\npatdiff. My\n.bash_profile already checks for opam installation (the\nOCaml package manager), .ocamlinit is already set up, and\n.gitconfig is set up to allow git patdiff <file>.\nbrew install opam\nopam init\neval `opam config env`\nopam update\nopam install patdiff\n","641":"Assistant System by Environmental Analysis For Visually Impaired\n\u4e2d\u6587\u7248 Readme \u8acb\u9078\u6211\nSummary\nWith the evolution of society, Socially vulnerable groups getting attention gradually, so use technology to solve or help socially vulnerable groups make life more friendly and also have become a major issue.\nAnd although there are many assistive devices can assist visually impaired people to live, but there are still many problems can not be solved, such as the use of guide cane can not sense obstacles upper body when walking or unable to understand the environment and other problems, resulting in danger.\n\n\n\nTherefore, the contribution of this paper is to propose an innovative Assistive technology devices conception, through a combination of hardware and software wearable device, design a vest for the visually impaired person can wear and combine with the system which can do image recognition technology to identify surrounding environments.\nThis paper focuses on visually impaired people when walking issue. Design an environment recognition system and to detect intersection zebra, avoid straying into dangerous lane systems and billboards when they\u2019re walking. For billboards system, through the color histogram filter object by color feature, and do object recognition by SURF feature; crossing detection system, looking straight through Hough Line, then repairing and filtering line, and analysis zebra crossing texture to judge finally.\n\n\n\n\n\n\nThe system can be modular for the expansion needs of the visually impaired and function. Developing friendly and useful assistive technology devices for visually impaired people.\nDevelopment Environment\n\nProgramming Language \uff1aC#\nIDE : Visual Studio 2012\nLibrary : EmguCV 2.4.0 for x86 (libemgucv-windows-x86-2.4.0.1717.exe)\n\nSlide Link\nYou could see the slide from the Slide Link\nPaper Link\nYou could read the introduction of paper from Paper Link\n","642":"sensor-puck\nThis is the repository for all collateral related to the Silicon Labs Sensor Puck.\nNote. The Sensor Puck is no longer actively supported and this code is provided as is.\nThe android directory has the Sensor Puck android app source code.\nThe iOS directory has the iPhone app source code.\n","643":"Mining Sensor Data to Evaluate Indoor Environmental Quality of Public Educational Buildings\nIn this project, we will collect, extract, transform, load, and analyse sensor data transmitted\nfrom large amount of sensors installed in school buildings across three European countries.\nThe sensor data report multiple types of information including temperature, humidity, outdoor weather,\nelectronic consumption, human activities, and etc.\nUsing python library such as Pandas, Matplotlib, Numpy and Comfort Tools from Berkeley ,\nwe aim to predict the overall comfort and other KPI for indoor environmental quality in the school buildings\nBased on our findings, school management can optimise the environment quality.\nBasic information\nWhy do we care about collecting data in schools?\nFrom six until we are ready to step out to get to work, most of our time spent at school,\nsometimes even after school we still stay there for sports activities, or stay in the library for studying.\nWhat should be an ideally school?\nEnough illumination, comfortable temperature not too hot not too cold,\nenough fresh air to cool you head down before you crashed down by study and\/or stress?\nThe governments spend a lot of money on education,\nbut is that enough money or is there some way to put the money on the better place instead of just paying the electricity bills?\nIf we really want to do something for making a better place to study,\nwhere should we start to do or look at?\nWe need some first-hand data to tell us which part is the most expensive one so we can start to work on it.\nIn this situation, sensor data is good cutting point for having an observation and do the analysis.\nPoints of sensors geography distribution\n\nLocations in Google Map\n\n\n\n\n\nCountry\nParameter\nNumber\nComment\n\n\n\n\nGreece\nSensing endpoints\n872\nEach sensor equals 1 sensing endpoint\n\n\n\nSensing rate\n1 minute\nCan be modified\n\n\n\nEducators\n294\nGreek public schools in GAIA\n\n\n\nStudents\n2267\nGreek public schools in GAIA\n\n\nItaly (Roma)\nSensing endpoints\n118\nWill soon be augmented\n\n\n\nSensing rate\n1 minute\nCan be modified\n\n\n\nEducators\n120\nUniversity faculty and Post Doc\n\n\n\nStudents\n1706\nUniversity students\n\n\nItaly(Prato)\nSensing endpoints\n117\n\n\n\nSweden(Soderhamn)\nSensing endpoints\n3\ncreate on 2017-07-12T12 more to add, no data yet\n\n\n\nTotal : 16 sites and 1922 sensors are on the record till 2017\/09\/16.\nPart of them are newly installed in this year and some have history data from 2015.\nThe data is collected under different weather condition, from different cultures , with different user behaviour pattens\nIt is a good start we could see the difference and find the similarity.\nSensor data \/ unit\n\n\nPower consumption\n\n\nCalculated Power Consumption : mWh\n\n\nPower Consumption : mWh\n\n\nElectrical Current : mA\/A\n\n\nActive Power : mW\n\n\nApparent Energy : Vah\n\n\nApparent Power : VA\n\n\nVoltage : V\n\n\nPower Factor : Raw Value\n\n\nReactive Energy : VARh\n\n\nReactive Power : VAR\n\n\n\n\nEnvironmental parameters\n\n\nNoise : Raw Value\n\n\nMotion : Raw Value\n\n\nMovement : Raw Value\n\n\nLuminosity : Raw Value\n\n\nLight : lux\n\n\nAtmospheric Pressure : kPa\n\n\nExternal Relative Humidity : %\n\n\nRelative Humidity :  %\n\n\nRain Height : mm\n\n\nWind Direction : degrees\n\n\nWind Speed : m\/sec\n\n\nTemperature : Centigrade\n\n\nExternal Temperature : C\n\n\nRadiation \uff1auSv\/h ( be careful, too high, you will die )\n\n\nExternal Air Contaminants : Raw Value\n\n\nExternal Ammonia Concentration : Raw Value\n\n\nExternal Carbon Dioxide Concentration : Raw Value\n\n\nExternal Carbon Monoxide Concentration : Raw Value\n\n\nExternal Oxygen Concentration : Raw Value\n\n\nCarbon Monoxide Concentration : Raw Value\n\n\nMethane Concentration : Raw Value\n\n\n\n\n\nPoints of sensors connection\n\nWiFi\n2G\/3G mobile network connection\nEthernet\nLow-rate wireless personal area networks(IEEE 802.15.4)\n\nData Variability and Potential Patterns\nTake a close look on the raw data and seek for the changing patterns :\n\nTemperature\nLight\nMotion\nPower consumption\n\nDemo on all the schools in Greece, for one year, time interval: day\n\nPower Consumption, 10 schools in Greece\n\nThere are 3 other schools without power consumption sensors or no data.\n- Temperature, 12 schools in Greece\n\n\nDemo on site 8\u03bf \u0393\u03c5\u03bc\u03bd\u03ac\u03c3\u03b9\u03bf \u03a0\u03b1\u03c4\u03c1\u03ce\u03bd,Greece ,for 3 weeks, time interval: hour\n\n\nTemperature for 4 weeks in the main building with building floor plan\nSo here are the pattens\n\nthe room(4ce) at ground floor , heading to the north has lowest temperature all the time.\nthe two on the first floor, two classrooms to west (class 1 and 2) are next to each other and have similar pattern of temperature changing\nand the \"warmest\" rooms in the whole school building.\nthe rooms at the north are cooler\n\n\n\n\nDemo on site \u0393\u03c5\u03bc\u03bd\u03ac\u03c3\u03b9\u03bf \u03a0\u03b5\u03bd\u03c4\u03b1\u03b2\u03c1\u03cd\u03c3\u03bf\u03c5 \u039a\u03b1\u03c3\u03c4\u03bf\u03c1\u03b9\u03ac\u03c2,Greece, for 4 weeks, time interval: hour\n\n\nTemperature at the main building with building floor plan\nPatterns :\nTemperature in Computer Lab is more stable than the rest of others , but still fit our expectation.\n\n\n\nHumidity at the main building with building floor plan\nPatterns : we can see the basement has the highest humidity and the music class is stable and remain in a good dry condition for preserving the music instruments\n\n\n\nLuminosity at the main building and the sub-site building\nPattern:\nMost of the rooms use natural light but there is always light only turn off during the weekend\nThe rooms facing south exposed in the longer daylight have maximum luminosity compared with the lab in the basement.\n\n\n\n\nAvailability\nAlgorithm for Availability is different from prediction in clean outlier and inactive data\nIntuition:\n\nSome sensor data has reasonable zero value as true value,like motion while no one walking around\nSome sensor data should never be zero , like Temperature and humidity always above zero, or some others type might below zero.\n\nIn general , the summary for one point of sensors even there is(\/are) some sensor data has \"legal\" zero\nthe summary based on the same timestamps should always be above zero as long as it is active.\nProcess :\n\nPut all [value != 0] =  1\nSum for all sensor data in one points of sensors\nNormalized all [value > 0] = 1\n\nOutput :  1 = active , 0 = inactive for each points of sensors\nVisualize in Heatmap for points of sensors availabilities\n\nThis table includes large range of data which are missing due to sensors no longer working or the whole sites are power off  during [2015-Nov-1,2017-Oct-30]\n\n\n\nID\nName\nInactive\nstart time\noutlier\nTotal number of measurements\n\n\n\n\n144024\n\u0394\u03b7\u03bc\u03bf\u03c4\u03b9\u03ba\u03cc \u03a3\u03c7\u03bf\u03bb\u03b5\u03af\u03bf \u039b\u03c5\u03b3\u03b9\u03ac\u03c2\n30.48 %\nbefore 2015-10-30\n16.49%\n73,000\n\n\n144242\n1\u03bf \u0393\u03c5\u03bc\u03bd\u03ac\u03c3\u03b9\u03bf \u039d. \u03a6\u03b9\u03bb\u03b1\u03b4\u03ad\u03bb\u03c6\u03b5\u03b9\u03b1\u03c2\n2.94 %\nbefore 2015-10-30\n10.90%\n94,900\n\n\n144243\n\u0394\u03b7\u03bc\u03bf\u03c4\u03b9\u03ba\u03cc \u03a3\u03c7\u03bf\u03bb\u03b5\u03af\u03bf \u039c\u03b5\u03b3\u03af\u03c3\u03c4\u03b7\u03c2\n24.49 %\nbefore 2015-10-30\n15.80%\n64,970\n\n\n155076\nGramsci-Keynes School\n4.56 %\n2016-08-04\n39.77%\n39.77%\n\n\n155077\nSapienza\n58.22 %\n2016-10-29\n51.01%\n177,390\n\n\n155849\n6\u03bf \u0394\u03b7\u03bc\u03bf\u03c4\u03b9\u03ba\u03cc \u03a3\u03c7\u03bf\u03bb\u03b5\u03af\u03bf \u039a\u03b1\u03b9\u03c3\u03b1\u03c1\u03b9\u03b1\u03bd\u03ae\u03c2\n22.98 %\nbefore 2015-10-30\n16.76%\n52,560\n\n\n155851\n5\u03bf \u0394\u03b7\u03bc\u03bf\u03c4\u03b9\u03ba\u03cc \u03a3\u03c7\u03bf\u03bb\u03b5\u03af\u03bf \u039d\u03ad\u03b1\u03c2 \u03a3\u03bc\u03cd\u03c1\u03bd\u03b7\u03c2\n29.23 %\n2016-08-02\n39.25%\n75,190\n\n\n155865\n46\u03bf \u0394\u03b7\u03bc\u03bf\u03c4\u03b9\u03ba\u03cc \u03a3\u03c7\u03bf\u03bb\u03b5\u03af\u03bf \u03a0\u03b1\u03c4\u03c1\u03ce\u03bd\n38.72 %\n2016-09-22\n38.28%\n53,290\n\n\n155877\n2\u03bf \u0394\u03b7\u03bc\u03bf\u03c4\u03b9\u03ba\u03cc \u03a3\u03c7\u03bf\u03bb\u03b5\u03af\u03bf \u03a0\u03b1\u03c1\u03b1\u03bb\u03af\u03b1\u03c2 \u03a0\u03b1\u03c4\u03c1\u03ce\u03bd\n35.18 %\n2017-02-01\n45.80%\n46,720\n\n\n157185\n\u0395\u03bb\u03bb\u03b7\u03bd\u03bf\u03b3\u03b5\u03c1\u03bc\u03b1\u03bd\u03b9\u03ba\u03ae \u0391\u03b3\u03c9\u03b3\u03ae\n3.31 %\n2017-02-01\n40.50%\n123,370\n\n\n159705\nSoderhamn\n0.00 %\n2017-09-21\n48.24%\n70,810\n\n\n19640\n\u0393\u03c5\u03bc\u03bd\u03ac\u03c3\u03b9\u03bf \u03a0\u03b5\u03bd\u03c4\u03b1\u03b2\u03c1\u03cd\u03c3\u03bf\u03c5 \u039a\u03b1\u03c3\u03c4\u03bf\u03c1\u03b9\u03ac\u03c2\n1.72 %\nbefore 2015-10-30\n20.34%\n112,420\n\n\n27827\n8\u03bf \u0393\u03c5\u03bc\u03bd\u03ac\u03c3\u03b9\u03bf \u03a0\u03b1\u03c4\u03c1\u03ce\u03bd\n3.71 %\nbefore 2015-10-30\n10.71%\n71,540\n\n\n28843\n2\u03bf \u0395\u03a0\u0391\u039b \u039b\u03ac\u03c1\u03b9\u03c3\u03b1\u03c2\n43.08 %\nbefore 2015-10-30\n22.17%\n117,530\n\n\n28850\n55o \u0394\u03b7\u03bc\u03bf\u03c4\u03b9\u03ba\u03cc \u03a3\u03c7\u03bf\u03bb\u03b5\u03af\u03bf \u0391\u03b8\u03b7\u03bd\u03ce\u03bd\n21.23 %\nbefore 2015-10-30\n22.36%\n91,250\n\n\n\nVisualize in Heatmap all sensor data availabilities\n\nIn this table, statistic for sensors belong to three different vendors and different connections\n\n\n\nName\nInactive\noutlier\nTotal number of measurements\n\n\n\n\nLibelium for outdoor weather\n15.16%\n10.61%\n31,390\n\n\nSynfield for outdoor weather\n14.40 %\n9.28%\n10,950\n\n\nElectrical Power Consumption\n18.68 %\n33.40 %\n73010\n\n\n\nVisualize in Heatmap category by different connections for sensors data\n\nReliability\n\n\nClean the times period which all the sensors are inactive.\n\n\nClean the sensors which are always inactive\n\nIf the site is not power-on yet, it will not be counted as inactive\nOnly after sensor(s)(maybe just a few of them)actived, start to count inactive missing data\n\n\n\nRemove the outliers with Turkey's fences and replace with min\/max value\nWhat is outliers \n    In statistics, an outlier is an observation point that is distant from other observations.\n    An outlier may be due to variability in the measurement or it may indicate experimental error; \n    the latter are sometimes excluded from the data set.[3] Outliers can occur by chance in any distribution, \n    but they often indicate either measurement error or that the population has a heavy-tailed distribution. \n    In the former case one wishes to discard them or use statistics that are robust to outliers, \n    while in the latter case they indicate that the distribution has high skewness \n    and that one should be very cautious in using tools or intuitions that assume a normal distribution. \n    A frequent cause of outliers is a mixture of two distributions, which may be two distinct sub-populations, \n    or may indicate 'correct trial' versus 'measurement error'; this is modeled by a mixture model.\n\n    Output Two ways to indicate a data point is an outlier\n     - Real-valued outlier score, higher values of the score make the point more like an outlier\n     - Binary label binary value yes or no for an data point to be outlier\n\n\n\nidentify outliers by using Turkey's fences, aka inter quartile range\nQ1 = First Quartile\nQ3 = Third Quartile\nInter-quartile Range (IQR) = Q3 - Q1\nLower Outlier Boundary = Q1 - 3 * IQR\nUpper Outlier Boundary = Q3 + 3 * IQR\n\n\nidentify outliers by using a sliding windows W holds last W-1 values\nMoving windows through data from the beginning\n\nIf the inter quartile range becomes biggest ever seen,here comes a outliers : replace it with min or max\nIf the new value is NaN, it is also an outlier : replace it with average\nmin\/max\/average = min\/max\/average (previous W-1 values)\n\n\n\nmoving window average to smooth out short-term fluctuations and highlight longer-term trends or cycles\nThe SMA is the most straightforward calculation, the average over a chosen time period. \nThe main advantage of the SMA is that it offers a smoothed line, less prone to whipsawing up and down in response to slight, \ntemporary price swings back and forth. Therefore, it provides a more stable level indicating support or resistance. \nThe SMA's weakness is that it is slower to respond to rapid changes that often occur at market reversal points. \nThe SMA is often favored by analysts operating on longer time frames, such as daily or weekly charts.\n\n\n\nrefill the NaN with average of the whole series values\n\n\n\nLinear fit\nIn statistics, linear regression is a linear approach for modeling the relationship \nbetween a scalar dependent variable y and one or more explanatory variables \n(or independent variables) denoted X.```\n\n\n\nVisualize one day temperature data after processes mentioned above\n\n\n\nAccuracy\nCan we retrieve outdoor weather through API ?\nOpenweathermap for real-time data\nBut this response is only for the real time request.\nWorldweatheronline for history data\nBoth of APIs response :\n\n\n\nTemperature\nWind\nHumidity\nPressure\nCloud...\n\n\n\nWhat about the accuracy between data retrieved from API and sensors?\n\n\nNotice API from worldweatheronline does not provide longer than 32days data\nConclusion : Yes we can retrieve both realtime and history,but the accuracy is not pretty enough\nInterpretation\nOrientation Prediction and Deviation\n\n\nAssuming the indoor temperature should rise as the day time passing by.\nWe do not put human activity or others into the consideration, for now\n\n\nIdentify patten by peak time:\n\n\nIntuitively while observing the temperature peak for different rooms:\n\nEast: the peak temperature mostly arrives at the early day\nWest: the peak  at the late of the day\nSouth: the peak should be at the mid-noon or later\nRest: room facing north\/music room\/computer lab\/basement room will have relatively low variation and average of the temperature\n\n\n\nIf we put cloud cover persentage with orientation of the room.\nObserve the time difference for indoor vs outdoor reach daily peak temperature\n\n\n\n\nPredicting orientation by using peak temperature :\n\n\nUsing RESTful API to retrieve the time : [sunrise , noon ,and sunset],unit: hour.\n\n\nOnly check the temperature during the daytime between [sunrise,sunset]\n\n\npick the hottest time and put that time:hour into [list_peak_at_hour]\n\n\nOrientation = sum( [list_peak_at_hour]  \/24hour *360degree)\/length([list_peak_at_hour] ) (unit:degree)\n\n\nSimply match Orientation into :\n\n0-90 degree: North-East\n90-180 degree: South-East\n180-270 degree: South-West\n270-360 degree: North-West\n\n(.\/image\/comp1.jpg)\n\n\nExmaple:8\u03bf \u0393\u03c5\u03bc\u03bd\u03b1\u0301\u03c3\u03b9\u03bf \u03a0\u03b1\u03c4\u03c1\u03c9\u0301\u03bd, \nClass 1 id fb8, the classroom reach the highest temperature at hour: \npeak_at_hour_list = [ 18, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n17, 17, 17, 16, 16, 16, 16, 18, 17, 16, 16, 17, 16, 17, 16, 16, 17, 16, 18, 17, 17, 17, 16, 16, 17, 17, 16, 17,17, \n16, 16, 17, 17, 17, 16, 17, 17, 18, 17, 17, 16, 16, 17, 17, 17, 17,17, 17, 16, 17, 17, 16, 17, 15, 16, 17, 16, 16, \n16, 16, 16, 16, 17, 17, 16, 17, 16, 17, 17, 15, 16, 17, 17, 17, 16, 16, 16] \nin total: \n[(16 o'clock, 33times), (18 o'clock, 5times),(15 o'clock, 2times), (17 o'clock, 60times)]\nOrientation = sum(16\/24*360*26+...+15\/24*360*2+17\/24*360*60)\/Length(peak_at_hour_list) = 250.2 degree\nSo we got the orientation is 250.2 degrees which looks like south-west. \n\n\nBut ... if there are also a lot of peaks happened in the morning  \nClasslB2 id :0x317.\nThis room gets enough exposed in the sunshine\/high temperature during the morning and also likely it facing to the south-east\nin total: (14 o'clock, 5times), (16 o'clock, 3times), (10 o'clock, 3times), (12 o'clock, 3times), \n(11 o'clock, 3times), (15 o'clock, 3times),(13 o'clock, 2times), (18 o'clock, 2times), (17 o'clock, 2times), \n(7 o'clock, 1times), (19 o'clock, 1times)\nOrientation = 205.7 degree,have peak temperature in the mornings at [7, 10, 11], takes 25.0% in total\nwe got something more like heading to the east , or south east\n\n\nWe take a close look at the distribution of site rooms in  different orientation\nThe south-east are in lower temperature compared with south and south-west room\n\nCategory by site :\n\n\n\nSITE ID\nOrientation Prediction Correct\n\n\n\n\n144024\n60%\n\n\n144243\n50%\n\n\n155851\n20%\n\n\n155865\n50%\n\n\n19640\n0%\n\n\n27827\n25%\n\n\n144242\n0%\n\n\n155877\n33%\n\n\n159705\n28%\n\n\n155849\n0%\n\n\n157185\n44%\n\n\nREST (no data)\n\n\n\n\nCategory by the room orientation :\n\n\n\nOrientation\nOrientation Prediction Correct\ncomment\n\n\n\n\nN - E\n0%\n0\/12\n\n\nE - S\n35%\n6\/17\n\n\nS - W\n56%\n9\/16\n\n\nW\n0%\n0\/1\n\n\nW - N\n0%\n0\/11\n\n\n\n\n\nThe cloudy coverage impact on the indoor temperature:\n\n\n\n\n\n\n\n\nIdentify deviation by slope = delta(temperature)\/delta(time):\n\n\nSlope for one room: first picture is the data after ETL, second is the slop for the data\nIf we are focusing on detecting sudden change of the indoor temperature, this slope plot could provide fast and efficient\nway, such as the fluctuate exists on Sep-23 on the top plot, a peak matching to this change is observed at the bottom plot as well.\nWe can use the similar algorithm: searching the \"outliers\" for slope to detect the fluctuate.\n\n\n\nAnd put all the classrooms from one site together(ETL data on top and slope on bottom) we can detect which room behavior abnormal :\nthe room in red during the day time and room in orange in the night time.\n\n\n\n\n\n\nComfort\nFrom Wikipedia\n\nThermal comfort\n\nThermal comfort is the condition of mind that expresses satisfaction with the thermal environment \nand is assessed by subjective evaluation (ANSI\/ASHRAE Standard 55).\n\n\nANSI\/ASHRAE Standard 55\n\n(Thermal Environmental Conditions for Human Occupancy) is a standard \nthat provides minimum requirements for acceptable thermal indoor environments. \nThe purpose of the standard is to specify the combinations of indoor thermal environmental factors \nand personal factors that will produce thermal environmental conditions \nacceptable to a majority of the occupants within the space\n\nThe standard addresses the four primary environmental factors \n(temperature, thermal radiation, humidity, and air speed) \nand two personal factors (activity and clothing) that affect thermal comfort. \nIt is applicable for healthy adults at atmospheric pressures in altitudes up to (or equivalent to) 3,000 m (9,800 ft), \nand for indoor spaces designed for occupancy of at least 15 minutes.\n\n\nComfort zone\n\nRefers to the combinations of air temperature, mean radiant temperature (tr), \nand humidity that are predicted to be an acceptable thermal environment at particular values of \nair speed, metabolic rate, and clothing insulation (Icl)\n\nIntuitively, we want the temperature indoor in the certain range like [18,24]\nduring Monday to Friday, from 8:00 to 18:00\nObviously, the truth is not always what we wish for\n\nTool: CBE Thermal Comfort Tool for ASHRAE-55 \nHow to use:\nBy choosing the Adaptive method at the very top of the user interface, \nthe chart changes and the input variables include air temperature, mean radiant temperature and prevailing mean outdoor temperature. \nThis is because the personal factors and humidity are not significant in this method since adaptation is considered, and the only variable is the outdoor temperature.\nSee above for explanation of the first two variables, air and mean radiant temperature.\n\nPrevailing mean outdoor temperature\nHere you can type the outdoor temperature averaged as explained on the standard. \nSee the Wikipedia link for a brief explanation.\nChanging this variable makes the dot representing the current condition move horizontally. \nThe meaning of this chart is that certain conditions of indoor-outdoor temperature fall inside the comfort zone, \nwhich in this case is static.\n\n\n\n\nSample period 2017.Sep.05-2017.Nov.04 , weekday: Monday-Friday, Time: 8:00-16:00, week of year: 36-44\n\n\nIn daytime, this room is comforable for (n*8hours) , 0 < n < 1\n\n\nAll day comfortable = 1 all day not comfortable = 0\n\n\nThe following two pictures are comfortness ratio per day is based on hourly temperature from site ID 27827 8\u03bf \u0393\u03c5\u03bc\u03bd\u03ac\u03c3\u03b9\u03bf \u03a0\u03b1\u03c4\u03c1\u03ce\u03bd\n\nuse \"Site-Temperature\" sensor as outdoor temperature source\n\nUse Worldweatheronline API as outdoor temperature source\n\nThe difference might because of the not accuracy from \"Site-Temperature\"\n\n\n\nThe following two pictures are comfortness ratio per day is based on hourly temperature from site ID 144242,1\u03bf \u0393\u03c5\u03bc\u03bd\u03ac\u03c3\u03b9\u03bf \u039d. \u03a6\u03b9\u03bb\u03b1\u03b4\u03ad\u03bb\u03c6\u03b5\u03b9\u03b1\u03c2\n\nuse libelium sensor as outdoor temperature source\n\nUse Worldweatheronline API as outdoor temperature.\n\nThe difference might because of the \"complete nonsense data\" from this libelium sensor\n\n\n\nThe following two pictures are comfortness ratio per day is based on hourly temperature from site ID 19640,\u0393\u03c5\u03bc\u03bd\u03ac\u03c3\u03b9\u03bf \u03a0\u03b5\u03bd\u03c4\u03b1\u03b2\u03c1\u03cd\u03c3\u03bf\u03c5 \u039a\u03b1\u03c3\u03c4\u03bf\u03c1\u03b9\u03ac\u03c2\n- use libelium sensor as outdoor temperature source\n\n\nUse Worldweatheronline API as outdoor temperature.\n\n\n\n\n\n\nRetrieve the data\n\n\n Retrieve the data by using APIs on  https:\/\/api.sparkworks.net\/swagger-ui.html\nDemo for \"POST \/v1\/resource\/query\/timerange\" :\n\n\n    Command line:\n        curl -X POST --header 'Content-Type: application\/json' --header 'Accept: application\/json' --header 'Authorization: Bearer cd885cf5-7fca-4be8-b32e-97225da6763f' -d '{\n          \"queries\": [\n            {\n              \"from\": 1498867200000,\n              \"granularity\": \"day\",\n              \"resourceID\": 156972,\n              \"resultLimit\": 0,\n              \"to\": 1500076799000\n            }\n          ]\n        }' 'https:\/\/api.sparkworks.net\/v1\/resource\/query\/timerange'\n        \n        \n    Reponse body:\n        {\n          \"results\": {\n            \"{\\\"resourceID\\\":156972,\\\"resourceURI\\\":\\\"gaia-ea\/room-1\/temp\\\",\\\"from\\\":1498867200000,\\\"to\\\":1500076799000,\\\"granularity\\\":\\\"day\\\",\\\"resultLimit\\\":0}\": {\n              \"average\": 31.995042261495424,\n              \"summary\": 479.92563392243136,\n              \"data\": [\n                {\n                  \"timestamp\": 1498856400000,\n                  \"reading\": 34.19535065107274\n                },\n                {\n                  \"timestamp\": 1498942800000,\n                  \"reading\": 35.618584889499054\n                },\n                ....\n                {\n                  \"timestamp\": 1499979600000,\n                  \"reading\": 25.807027188020786\n                },\n                {\n                  \"timestamp\": 1500066000000,\n                  \"reading\": 28.399119190883642\n                }\n              ]\n            }\n          }\n        }\n\nKnown Issues:\n\n\n when we request data within the time range, for different granularity ,\nthe response time stamps are different\n\n5min : it's the code running time, not the fixed data timestamp as below\n1hour : beginning of every hour\n1day : 21:00 for each day\n1month :  at 21:00 last day of the month\n\nSolution : use \".toInstant().toEpochMilli()\/ 300000*300000\" to change the time into 5mins interval in one hour.\nSo we will have 5', 10',15',...55' for the record timestamp\n\n\n Cassandra do not have connector as data source for flink\nSolution\nreference : CassandraConnectorITCase \nClusterBuilder cb = new ClusterBuilder() {\n        @Override\n        public Cluster buildCluster(Cluster.Builder builder) {\n            return builder.addContactPoint(\"127.0.0.1\").build();\n        }\n    };\nString query = \"SELECT ResourceID,Reading FROM gaia.reading_data WHERE ResourceID=155873\";\nInputFormat<Tuple2<Integer, Float>, InputSplit> source = new CassandraInputFormat<>(query, cb);\nsource.configure(null);\nsource.open(null);\nList<Tuple2<Integer, Float>> result = new ArrayList<>();\nwhile (!source.reachedEnd()) result.add(source.nextRecord(new Tuple2<Integer, Float>()));\nsource.close();\n\n\n\n Can't read data through API:\nResource  historical data resource ID: 90946 from : 2017-08-24T09:25:49.323Z to 2017-08-31T09:25:49.080Z with steps per hour\n[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\nHowever the real data is not all-zeros in https:\/\/console.sparkworks.net\/resource\/view\/90946\nWe will use the data extracted from API for further process , the console data are only for reference.\n\n\nData is missed from time to time:\nResource  historical data resource ID: 155918 from : 2017-08-24T09:25:49.323Z to 2017-08-31T09:25:49.080Z with steps per hour [32.34, 32.34, 32.34, 32.473637, 33.4425, 34.259167, 34.75733, 34.365334, 33.32, 32.764668, 32.570587, 32.36722, 32.3155, 32.3068, 32.241306, 31.868149, 31.868149, 31.85, 31.838118, 31.808867, 31.826338, 31.822662, 31.832302, 31.852188, 31.842134, 31.841246, 31.85319, 32.140522, 33.013374, 33.919827, 34.664608, 34.72307, 32.34, 32.34, 32.34, 31.85, 31.85, 32.34, 31.85, 31.85, 31.85, 31.85, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.367912, 31.374935, 31.410751, 31.416487, 31.51673, 31.94285, 32.77366, 33.64148, 34.232605, 33.768044, 32.68922, 32.30267, 32.140594, 31.958946, 31.87191, 31.852951, 31.830269, 31.64, 31.46889, 31.456898, 31.3657, 31.385254, 31.381018, 31.41322, 31.534771, 31.668463, 31.79291, 31.836, 31.869188, 32.38108, 33.044456, 33.666306, 33.827496, 32.96945, 32.38393, 32.23478, 32.038074, 31.907423, 31.856163, 31.844433, 31.838556, 31.69923, 31.6932, 31.511343, 31.412098, 31.391008, 31.380096, 31.443954, 31.619139, 31.776262, 31.830036, 31.832235, 31.799591, 31.84828, 32.09569, 32.928936, 33.33732, 33.126163, 32.188957, 31.83223, 31.623442, 31.422161, 31.361742, 31.356749, 31.3123, 30.906296, 30.886333, 30.878448, 30.859062, 30.843264, 30.859325, 30.861336, 30.849495, 30.85837, 30.85697]\n\n\nReference\n\nThe building data genome project\nBig data computing\nNaked Statistics: Stripping the Dread from the Data by Charles Wheelan\nReal Time sensor status on GAIA\n\nSupervisors:\nProfessor Ioannis Chatzigiannakis\nProfessor Aris Anagnostopoulos\nAcknowledgement :\nSince the first day I stepped into Sapienza , you are the ones lead me to \u201cfind true love with data mining\u201d.\nTill the last six months, you not only gave me \u201cfish\u201d but also taught me \u201chow to fish\u201d with all your supports and encourage.\nThat is beyond anything I could expect but I am so blessed to have. Without you, I won\u2019t be standing here today.\n","644":"\n\nEnvironmentally-Driven Edge Detection Program\nDisentangling environmental effects in microbial association networks\nEven though ecological interactions among microbes are fundamental for ecosystem functioning,\nmost of them remain unknown. High-throughput omics can help unveiling microbial interactions\nby inferring species correlations over space or time, which can be represented as networks.\nAssociations in these networks can indicate ecological interactions between species or\nalternatively, similar or different environmental preferences. Therefore, it is important to\ndisentangle these associations and determine whether two species are correlated because they\ninteract ecologically or because they are correlated to an abiotic or biotic environmental\nfactor. We developed an approach to determine whether or not two species are associated in a\nnetwork due to environmental preference. We use four methods (Sign Pattern, Overlap,\nInteraction Information, and Data Processing Inequality) that in combination can detect what\nassociations in a network are environmentally-driven. The approach is implemented in the\npublicly available software tool EnDED.\nGENERAL USAGE NOTES\nEnDED is a program that aims to detect environmentally-driven (\"indirect\") edges in an association network.\nThe makefile contains the code to generate all required commands to compile the program.\nGo within the terminal into the folder EnDED and type\nmake\n\nThe command to use the program is:\nEnDED\/build\/EnDED --input_network_file [PATH\/NETWORKFILE] --methods [METHODS] [optional OPTIONS]\n\nDEPENDENCIES\nThe program requires the\n\ngcc = GNU Compiler Collection (GCC)\nboost = boost C++ Libraries\n\nGet help with\n.\/build\/EnDED -h\n\nor\n.\/build\/EnDED --help\n\nOptions\n\n-h,--help Returns this help message\n-v,--version Returns the version of the program.\n-d,--defaults Returns the default values of the program.\n\nRequired options\n\n-f,--input_network_file [network_filename] Path and name of\nthe input network file. The first line(row) represent the\ncolumn names.\n-m,--methods [method IDs] Lists the method\/s you would like\nto use separated by a comma. SP=SignPattern, OL=Overlap,\nII=InteractionInformation, DPI=DataProcessingInequality\n(minMi), CO=Co-Occurrence, e.g.: SP,II. Instead of mentioning\nall methods, you can shortly write -m all\n\nMethods Settings:\nSign Pattern:\n\n--SP_colnum_interaction_score [num] Required for method\nSignPattern(SP). \"num\" is the column number of the interaction\nscore.\n\nOverlap:\n\n\n--OL_colnum_interactionlength_startX_startY [num1,num2,num3]\nRequired for method Overlap(OL).\n\"num1\" = column containing the interaction length,\n\"num2\" and \"num3\" = columns indicating start point of X and Y.\n\n\n--OL_percentage_threshold [num] Default: 60.0, edge is\nconsidered not indirect, if overlap is below this number.\n\n\nData Processing Inequality:\n\n--DPI_minMI_threshold [double] Default: 0, threshold for how much\nsmaller min MI has to be compared to other two MIs.\n\nInteraction Information and Data Processing Inequality:\n\n\n--II_DPI_max_nan_threshold [num] Default: 20, threshold(in\npercentage) for maximum portion of 'nan' in vectors used for II\nand DPI.\nInteraction Information - Significance determination:\n\n\n--II_significance_level [double] Default: 0.05, significance\nlevel for interaction information is a number between 0 and 1.\n\n\n--II_permutation_iteration [int].Default: 100, number of\niterations to determine the significance of the interaction\ninformation.\n\n\n--do_pre_jointP_comp Default: ENV vectors are randomized anew\nfor each Signifiance determination.\nOptional: ENV vectors are permutated before and stored.\nNote: might cause memory troubles, so it is not set by default.\n\n\nStrategy for method combination:\n\n\n--method_count_threshold [double] Default: 100, threshold(in\npercentage) for minimum methods that suggest edge as indirect.\n\n\n--triplet_count_threshold [double] Default: 1, threshold for\nminimum triplets that suggest edge as indirect.\n\n\nAdditional input files:\n\n\n--II_DPI_abundance_file [filename] Required for method\nInteractionInformation(II) and DataProcessingInequality(DPI).\nName(if not in same folder, also with path) of the abundance file\n(first line are the column names: 1st column = ID\/ENV-name, other\ncolumns are abundances).\n\n\n--II_DPI_ENVparameter_file [filename] Optional for method\nInteractionInformation(II) and DataProcessingInequality(DPI).\nName(if not in same folder, also with path) of the ENV parameter file,\nif ENV not within the abundance file, then first line are the column\nnames: 1st column = ENV-name, other columns are abundances)(Column names\nhave to match the ones from the abundance file).\n\n\n--input_ID_ENV_nw_file [network_filename] Optional: Name of the input\nnetwork file that contains ID-ENV edges (first line are the column names,\nthat have to be the same as the ones for the network file).\n\n\nInputfile separators:\n\n\n--separator_network_file \"[sep]\" Default: tab, other possibilities, but\nnot limited to: \";\" or \" \"\n\n\n--separator_abundance_file \"[sep]\" Default: tab, other possibilities, but\nnot limited to: \";\" or \" \"\n\n\nOutput:\n\n\n-o,--output_network_file [filename] Default: \"extended_nw.txt\"; name of\nthe output network file.\n\n\n--output_ID_ENV_edge_dont_print Default: ID-ENV edges are printed in\nextended nw file. With this option, they will not be printed.\n\n\n-t,--output_triplet_info [filename] Create output with Triplets information.\n\n\n--output_discretized_vectors [filename] Create output with discretized vectors.\n\n\nOther:\n\n\n--input_node_col [colnum_x,colnum_y]Default: \"1,2\". Number of the 2 columns\ncontaining the nodes X and Y.\n\n\n--input_ENV_identicator [indicator string]Default: \"ENV\"; indicator for\nenvironmental parameter name, needs to be included in node name.\n\n\nDefault settings\n\nNo method is selected by default.\nMethod Overlap: The percentage threshold to decide if an edge\nis regared as indirect by the method is 60.\nMethod Interaction Information: The significance level of the\nInteraction Information Score is 0.05.\nMethod Interaction Information: The number of permutation to\ndetermine the significance of the Interaction Information\nScore is 100.\nMethod Data Processing Inequality compares Mutual\nInformations. Ranks Mutual Information and by default regards\nID-ID as indirect if it is the smallest. That means, by\ndefault is the threshold for how much smaller the MI has to\nbe: 0.\nENV-vector will be permuted anew during examining the networks\ntriplets.\nMethod Interaction Information and Data Processing Inequality\nuse data that may contain 'nan'. By default is the threshold(in\npercentage) for maximum portion of 'nan' in vectors: 20.\nCombination strategy of considering an edge indirect. By\ndefault all methods have to agree that an edge within one\ntriplet is indirect before it is considered as indirect. And\nat least one triplet has to suggest the edge as being indirect\nbefore the edge is considered indirect.\nInputfile separators are by default tabs\nOutput: by default the only output is the network file which\nis extended by the methods information and named as\nextended_nw.txt\nID-ENV edges are printed in extended nw file.\nNumber of the 2 columns containing the nodes X and Y are by\ndefault 1,2.\nENV is the indicator for environmental parameter name that\nneeds to be included in node name.\n\nExample: test data\nInput data\nThe folder test_data contains an example datasets that can be used\nto try out the program. The following files are included:\nInput folder containing\n- network.txt containing the network file (ID-ID edges,\nID-ENV edges, and ENV-ENV edges)\n- ID_ENV_edges.txt containing ID-ENV edges\n- ID_abundance.txt contains the abundances\/counts for\nthe IDs (rows) per sample (columns)\n- ENV_parameters.txt contains the environmental\nparameters for the ENVs (rows) per sample (columns)\nOutput data\nlogfile\nThe log-file contains information about the program and the\nindirect edge detection:\n\ncommand used to run the program\nprogram version\nSettings\nInputfiles\nInformation tracked during the indirect edge detection\n\nnumber of ID-ENV edges found in input file and how many\nof them are considered for the indirect edge detection\n(duplicated are not considered, only first appearance\nwill be used).\nnumber of ID-ENV edges that are within at least one\ntriplet.\nnumber of ENV-ENV edges.\nnumber of ID-ID edges.\nnumber of ID-ID edges that are not in a triplet.\nnumber of IDs are connected to at least one ENV\nparameter.\nnumber of ID-ID edges that are in at least one triplet.\nnumber of edges that are considered indirect, and not indirect by each selected method and (if more\nthan one method got selected) by the method combination.\n\n\nStart and end time as well as the duration of the computation.\n\nextended_network\nThe output of the EnDED program is Output\/extended_network.txt.\nIt's columns are all columns from the input network file and\nadditionally the following columns:\n\nSignPattern is 0 for indirect and 1 for not indirect.\nOverlap is the maximal detected Overlap in percentage of the\nX-Y edge with the edges X-ENV and Y-ENV.\nMutualInformation is the mutual information between X and Y.\nInteractionInformation is the minimal significant\ninteraction information of X, Y, and ENV.\nII_p_value is the significance of the interaction\ninformation of X, Y, and each of the ENV.\nDataProcessingInequality_Rank is the minimal rank of the\nmutual information of X, Y in comparison with the mutual\ninformation of X-ENV and Y-ENV for each of the ENV: 1 being\nthe smallest and 3 being the highest.\nDataProcessingInequality_indirect is 0 for indirect and\n1 for not indirect. The data processing information regards\nthe X-Y association as indirect if the mutual information of\nX and Y is smaller than the other two (by default). Or it\nhas to be smaller by a certain value that can be specified\nwith: --DPI_minMI_threshold. That means the mutual\ninformation has to be smaller than MI-DPI_minMI_threshold in\norder for DPI to determine the XY-association as indirect.\nCOMBI_SP_OL_II_DPI is 0 for indirect and 1. It is based\non a combination of the 4 methods in detecting indirect\nedges.\npercentage_co_occurrence is the percentage of how often X and Y\nco-occurred in all samples in which at least one of them occurred.\n\ntriplet_info.txt\nAn extra output that contains information about the triplets: Output\/triplet_info.txt.\nColumns:\n\nX nodes X as indicated in the network file\nY nodes Y as indicated in the network file\nnum_triplets number of triplets that contain the edge\nbetween X and Y\nENV environmental factor\/s that is\/are in a closed triplet\nwith X and Y\nSignPattern is a ';'-separated list that contains for each\ntriplet the Sign Pattern indirect detection determination:\n0 for indirect and 1 for not indirect.\nOverlap is a ';'-separated list that contains for each\ntriplet the Overlap in percentage of the X-Y edge with the\nedges X-ENV and Y-ENV.\nMutualInformation is the mutual information between X and Y.\nConditionalMutualInformation is a ';'-separated list that\ncontains for each triplet the conditional mutual information\nof X, Y, and each of the ENV.\nInteractionInformation is a ';'-separated list that contains\nfor each triplet the interaction information of X, Y, and\neach of the ENV.\nII_p_value is a ';'-separated list that contains for each\ntriplet the significance of the interaction information of X,\nY, and each of the ENV.\nDataProcessingInequality_MI_rank is a ';'-separated list\nthat contains for each triplet the rank of the mutual\ninformation of X, Y in comparison with the mutual\ninformation of X-ENV and Y-ENV for each of the ENV: 1 being\nthe smallest and 3 being the highest.\nDataProcessingInequality_indirect is a ';'-separated list\nthat contains for each triplet if the data processing\ninformation regards the X-Y association as indirect (0) or\nnot indirect (1). It is regarded as indirect if the mutual\ninformation of X and Y is smaller than the other two (by\ndefault). Or it has to be smaller by a certain value that can\nbe specified with: --DPI_minMI_threshold. That means the\nmutual information has to be smaller than MI reduced by\nDPI_minMI_threshold (=MI-DPI_minMI_threshold) in order for\nDPI to determine the XY-association as indirect.\nDPI_num_MI_rank1 counts the number of times the\nXY-association had rank 1.\nDPI_num_MI_rank2 counts the number of times the\nXY-association had rank 2.\nDPI_num_MI_rank3 counts the number of times the\nXY-association had rank 3.\nCOMBI_SP_OL_II_DPI is a ';'-separated list that contains for\neach triplet the combination of the 4 methods in detecting\nindirect edges: 0 for indirect and 1 for not indirect.\nportion_NA_X_Y gives the portion of pairwise NAs in the\nvectors for X and Y. If it is above the threshold, MI will be\nNA and II and DPI will be NA as well.\n`portion_NA_X_Y_ENV is a ';'-separated list that gives the\nportion of three-wise NAs in the vectors for X and Y and ENV\nfor each ENV. If it is above the threshold, MI will be NA and\nII and DPI will be NA as well.\npresence_X is the number of samples in which X occurred.\npresence_Y is the number of samples in which Y occurred.\npresence_X_AND_Y is the number of samples in which both, i.e.\nX and Y, occurred.\npresence_X_OR_Y is the number of samples in which at least one\nof X and Y occurred.\npercentage_co_occurrence is the percentage of how often X and Y\nco-occurred in all samples in which at least one of them occurred.\nNote: the column names X and Y are the column names for node X\nand node Y in the network file, and ENV is the\nENV-indicator that can be adjusted with option\n--input_ENV_identicator [indicator string].\n\ndisc_vectors.txt\nAn extra output that contains discretized vectors:\nOutput\/disc_vectors.txt.\nColumns = columns from input abundance file\nContent = discretized values of the original abundance\/count\nID data and environmental parameters\nCommand\nAfter loading all required modules, and compiling the program.\nThe program can be run.\nThe command to produce the output files in the test data set is presented here:\n.\/..\/build\/EnDED --input_network_file Input\/network.txt --methods SP,OL,II,DPI,CO --SP_colnum_interaction_score 3 --OL_colnum_interactionlength_startX_startY 8,6,7 --II_DPI_abundance_file Input\/ID_abundance.txt --II_DPI_ENVparameter_file Input\/ENV_parameters.txt --output_network_file Output\/extended_network.txt --output_triplet_info Output\/triplet_info.txt --output_discretized_vectors Output\/disc_vectors.txt --do_pre_jointP_comp --II_permutation_iteration 100\n\nExample: real data (used in EnDED paper)\nThe folder BBMO_data contains the abundance table, ASV taxonomy assignment, network including EnDED results, and file containing all triplets with the environmental factor and how methods performed on each one of them.\nSimulated data (used in EnDED paper)\nThe file FromDataSimulationToEvaluatingEnDED.RMD contains R code to generate simulated abundance tables, commands to run eLSA network construction and EnDED, as well as the command to run the C++ program network_evaluation.cpp and R code used for evaluation.\nBackground\nMicrobial communities are not a mere collection of independent\nindividuals; they are interconnected being involved in various\necological interactions such as symbiosis, parasitism or\npredation. These interactions are important to maintain\necosystem function. For understanding microbial ecosystems, it\nis essential to understand microbiome interactions. They are\nbarely understood due to previous limitations in tools and\nmethods. However, during the last decade, there have been\nadvances in omics tools, analytical methods as well as\ncomputing performance.\nThe omics-technologies allow the screening of a large number of\nmicrobes; we obtain a list of microbes that are present in an\necosystem and are also able to quantify them. This data can be\nused to infer associations. Analyzing and converting microbiome\ndata into meaningful biological insights is challenging.\nFurthermore, microbes and microbial interactions can be\naffected by the environment. Thus, associations between\nmicrobes and the environment should be considered when studying\nan ecosystem.\nMicrobial interactions can be represented and modeled as\nnetworks: The nodes of the network represent the microbes as\nwell as the environmental parameters. An edge between two nodes\nrepresents an association between two microbes, or between a\nmicrobe and environmental parameter. State of the art network\nconstruction tools are still far from perfect. The obtained\nMicrobial Association Networks are likely to contain false\nassociations due to indirect associations (indirect edges). The\nso called Effect of indirect dependencies is when two species\nare indirectly correlated because both are correlated with a\nthird species or environmental factor, i.e. two microbes\nrespond similarly to a common environmental condition. Thus, in\nassociation networks we obtain two types of edges: direct and\nindirect associations.\nOnly direct associations predict microbial interactions.\nTherefore, indirect associations need to be removed from the\nnetwork before analyzing and interpreting the network as a\nrepresentation of the microbial ecosystem. In order to remove\nindirect edges from microbial networks that are environmentally\ndriven we implemented (C++ program EnDED - indirect edge\ndetection), which contains four methods that aim to detect\nindirect edges: Sign Pattern, Overlap, Interaction Information,\nand Data Processing Inequality.\nThe indirect edge detection methods\nThere are four methods that aim to detect indirect edges: Sign\nPattern, Overlap, Interaction Information, and Data Processing\nInequality. All four methods use closed triplets to detect\nenvironmentally driven edges within the network, which is a\nconstellation of three nodes that are all connected to each\nother. Let T={v_1,v_2,v_3} be the closed triplet. Let v_1 and\nv_2 be species and v_3 be the environment. Such triplets have\nbeen used by (Lima-Mendez, Faust, Henry et al. 2015,\nDeterminants of community structure in the global plankton  interactome) and were called environmental triplets. Note that\nan edge between two species might be in none, one or several\ntriplets with different considered environmental parameters,\ne.g. temperature, salinity, oxygen level.\n\nSign Pattern uses the sign of the association, i.e. whether\nthe association is positive or negative.\nOverlap uses the start and length of the association.\nInteraction Information and Data Processing Inequality use the\nabundance\/count and environmental data given for the two\nspecies and the environmental parameter.\n\nWe build up on three methods, namely Sign Pattern, Interaction\nInformation, and Data Processing Inequality, as well as\ndeveloped the method Overlap to use the additional information\nthat can be obtained from temporal data. We combine these methods.\nOnly if all methods suggest that the edge is indirect, the edge is\nconsidered to be indirect. As for now, the methods (and combination\nfor them) are implemented in the C++ program, EnDED (short for\nEnvironmentally-Driven Edge Detection).\nAdditionally, the co-occurrence of the X and Y is determined that\nmay be used filter and analyse the network further.\nPlease cite as\nIna Maria Deutschmann, Gipsi Lima-Mendez, Anders K. Krabber\u00f8d, Jeroen Raes, Karoline Faust and Ramiro Logares (2019). EnDED - Environmentally-Driven Edge Detection Program\nhttps:\/\/doi.org\/10.5281\/zenodo.3271730\nVersion\nEnDED_v1.0.1, 15. June  2019\nCONTACT\nIna Maria Deutschmann\nina.m.deutschmann[at]gmail.com\n","645":"EnvironmentalThreatsApliedDataScience\n","646":"Deprecated\nThis version of epp is deprected, please use the version found at\nhttps:\/\/github.com\/blendle\/epp.\n","647":"s_environmentalProtectionBigData\n\u73af\u4fdd\u5927\u6570\u636e\u5e73\u53f0\n","648":"Python Audio Feature Extraction\nThis repository holds a library of implementations of a few separate utilities to be used for the extraction and processing of features from audio files. The underlying extraction library is librosa, which offers the ability to extract a variety of spectral features as well as a few other miscellaneous features.\nProject Goals\n\nTo learn more about feature extraction from audio files\nTo standardize parameters for use during extraction on large amounts of audio samples\nTo allow for a relatively easy interface to select and extract subsets of parameters from subsets of samples\nTo provide Pandas wrappings of extraction results to hold important metadata and information about the extraction process\n\nCurrent Implementations\n\nAudioFeatureExtractor: this class defines an object that can be used to standardize a set of parameters to be used during feature extraction. It provides wrapper methods to librosa functions and can handle preprocessing steps such as preemphasis filtering and hard low and high cutoffs to facilitate data cleaning.\nBatchExtractor: this class defines an object that holds information about a batch of audio samples for which feature extraction should be performed. It implements methods that handle batch extraction using a set of standardized settings and easy selection of desired features.\nFeatureVisualizer: this class defines an object that can handle the visualization of features through Matplotlib.\n\n\nUsage Documentation\nAudioFeatureExtractor\nEach class can be imported from the afe module. In other words, to import the AudioFeatureExtractor object, simply put from afe import AudioFeatureExtractor along with the rest of your needed imports. Then, you can instantiate an AudioFeatureExtractor object and put it to work. This object takes as parameters at instantiation:\n\nThe desired sample rate in Hz to use for loading and analysis of audio (default 22050)\nThe desired number of samples to use as the window length for framed computations and feature extractions. This number should be set to an integer power of 2 to optimize the Fourier engine (default 1024)\nThe desired ratio of a window length to hop during framed computations -- i.e. an overlapping factor, setting this to 4 implies that the frame jumps 1\/4 of a window length during framed computations (default 4).\n\nAn AudioFeatureExtractor:\n\nhas the capability of retrieving audio from a string file path at the instance's sample rate and loading it as a Numpy array\ncan detect onsets, perform preemphasis filtering, and bandpass filtering for noise removal in the low and high regions\ncan extract a feature using the instance's standardized framing attributes, either from a Numpy array of audio samples or from a preprocessed STFT\/CQT (such as with bandpass noise removal)\n\nCurrently the following feature extraction methods are implemented (all feature extraction methods begin with the prefix extract_:\n\nextract_stft: extracts a short time Fourier transform\nextract_cqt: extracts a constant-Q transform\nextract_chroma_stft: extracts a chromagram\nextract_chroma_cqt: extracts a chromagram of a CQT\nextract_chroma_cens: extracts an energy normalized variant chromagram\nextract_melspectrogram: extracts a Mel-windowed spectrogram\nextract_mfcc: extracts the Mel-frequency cepstral coefficients\nextract_rms: extracts the framed root-mean-square\nextract_spectral_centroid: extracts the spectral centroid\nextract_spectral_bandwidth: extracts the spectral bandwidth\nextract_spectral_contrast: extracts the spectral contrast\nextract_spectral_flatness: extracts the spectral flatness\nextract_spectral_rolloff: extracts the spectral rolloff\nextract_zero_crossing_rate: extracts the framed zero crossing rate\nextract_tonnetz: extracts the tonnetz (tonal centroid)\nextract_poly_features: extracts polynomial combinations of features from a given feature matrix or audio\n\nUltimately I would like to add these functionalities to the AudioFeatureExtractor:\n\nTempo related feature extraction methods\nFeature manipulation tools offered by librosa\nFeature inversion tools to translate back from the feature space to the auditory space, to hopefully facilitate some interesting generative projects later on\nPerhaps incorporating some other utilities could be helpful for later projects or methods of feature engineering.\n\nBatchExtractor\nThe BatchExtractor is somewhat of an extension of the AudioFeatureExtractor to handle standardized extraction of a batch of samples. In order to use the BatchExtractor object, we must import it in the same way: from afe import BatchExtractor. Then we can instantiate a BatchExtractor object. This object accepts at instantiation the following parameters:\n\nThe same three parameters as accepted during instantiation of an AudioFeatureExtractor object\nA string path of a folder containing audio samples\nEither a Pandas dataframe or a string path to a CSV file that can be read as a dataframe which has metadata information about samples in the specified folder of audio. Details about the formatting of this index dataframe are discussed more in-depth below\nThe number of Mel-frequency cepstral coefficients to compute (default 12)\nA boolean flag indicating whether or not preemphasis filtering should be applied to audio before computation of features (default False)\nA float between 0 and 1 indicating the desired preemphasis filter coefficient if this option is desired and appropriately set using the Boolean flag (default 0.97)\nA boolean flag indicating whether or not hard-bandpass filtering of noise in the higher and lower frequencies should be applied (default False)\nIf hard-bandpass noise filtering should be applied and the flag has been appropriately set, then integer values can be set for the upper and lower limits of this noise filtering (default None)\nA boolean flag indicating whether or not the start of the audio samples should be trimmed to the first computed onset (default False)\n\nThe BatchExtractor, as specified, requires that an index dataframe be specified, either as a string pointing to a CSV file or by passing in the dataframe itself. In particular, this dataframe needs a column named file_name which indicates for each audio sample to be analyzed the file path as a string and relative to the BatchExtractor's stored audio folder path. Other columns present in the index dataframe could depend on the context of the project.\nCurrently, the BatchExtractor can be used to perform the following tasks:\n\nThere are methods available to set any of the preprocessing options:\n\nset_bp_filter: sets the bandpass noise filtering flag and parameters\nset_preemphasis: sets the preemphasis flag and parameters\nset_trim: sets the flag for trimming to first onset\n\n\nThere are methods to extract and merge features from the batch of samples stored in the instance's index of the folder of audio. Each of these methods accepts a string indicating a results_folder in which to either save the extracted feature matrices as CSV files or look for the saved extraction results as CSV files (in the case of merging). Additional options for each method are further detailed below.\n\nbatch_extract_feature: accepts a string abbreviation of a single extraction method to apply to the entire batch of audio in the index. Saves the results to the given results_folder.\nbatch_extract_features: accepts a list of string abbreviations of extraction methods to apply to the entire batch of audio in the index. Saves the results to the given results_folder.\nmerge_features: accepts a list of string abbreviations of features to merge into a single dataframe. In other words, for each sample in the audio index, each of the feature matrices specified in the list of abbreviations will be loaded from the results_folder and merged, then saved as a new dataframe.\nbatch_extract_and_merge: Performs a batch extraction then a merging of all features given in the list of string abbreviations for all audio samples in the index.\nmerge_and_flatten_features: The only of these methods to have a non-null return, this method loads for each sample in the audio index the feature matrices for the given list of extraction abbreviations, flattens them into a single row (creating many many columns), then concatenates all these rows into an appropriately padded dataframe containing feature information for all samples in the index.\n\n\n\nI would eventually like to add the following to the BatchExtractor implementation\nFeatureVisualizer\nThe FeatureVisualizer class defines an object which could be helpful for the purposes of debugging or identifying import sonic features. In general, computations such as the STFT\/spectrogram are helpful because they can give us a very good visual description of what is happening in audio, even though their quantities are also helpful by making more specific quantifications for the purposes of analysis. The FeatureVisualizer class is my attempt at creating an interface for the visualization of features extracted using the BatchExtractor (or similarly AudioFeatureExtractor) object. At instantiation, this object accepts the following parameters:\n\nA string path indicating a folder containing extracted features with the following naming convention: '{sample_name}_{feature_abbreviation}_features.csv'\nA default figure size to use when plotting (default (18, 8)).\n\nThis is currently the class for which the least implementation has been written. Currently the object is capable of visualizing by simply calling the name of the sample to be loaded from the folder of extracted features.\n\nSTFT\/spectrograms\nMel-windowed spectrograms\nChromagrams\n\nThere are many more feature visualization methods that I would like to implement (CQTs, spectral bandwidth and related features, tempograms eventually).\n","649":"TracerLPM\nAn Excel workbook program for evaluating groundwater age distributions from environmental tracer data\nThis folder contains the installation packages (.msi) for 32- and 64-bit versions of TracerLPM. The installation package must macth the version of Microsoft Office installed on a user's machine. By default, the 32-bit version of Office is normally installed even though most operating systems are 64-bit. Only use the 64-bit installation package of TracerLPM if the version of Office is 64-bit.\nSubfolders contain all the code and workbooks used to develop TracerLPM. The Workbook folder contains the latest version of the Excel workbook and is written in visual basic for applications (VBA). The folder LPM_FunctionsXLL contains Visual Studio (2015) solution code written in C++ that computes tracer concentrations. The folder OptimizationXLL contains Visual Studio (2015) solution code written in C++ that computes best-fit lumped parameter models to environmental tracer data. The Visual Studio codes generate XLLs (dynamic linked library recognized by Excel) that are installed in the Microsoft Add-in folder on a user's machine. The XLL have worksheet functions that can be called from any worksheet cell in TracerLPM. TracerLPM will pass data to the XLL fitting routines and generate output from the results.\n","650":"d3-EnvironmentalHealthScores\nSelect Environmental Health Scores displayed as a d3 map and graph\n","651":"SnapGreen | Cal Poly Software Engineering I & II 2020\n\n\n\n\nProviding users with a measurable awareness of their environmental impact. Users can track daily habits and scan products to increase and improve their environmental score.\nUnderstanding Our Backend\nCoding Style\nKotlin Style Convention\nJavascript Style Convention: Prettier\nStatic Code Analysis\nView SonarCloud Project Dashboard\nContinuous Integration Software\nView Travis CI Dashboard\nDesign Diagrams and Prototypes\n\nView Diagrams Here\n\nUI Prototypes\nView Figma Mockup\nComponent Diagram\n\nUse Case Diagram\nThe app involves two actors, one being a player(user) and the other being a clock. The player can perform various activities. They can login to the app and if they don't have an account they can create a new account. A player can also access their settings, add friends, enter usage stats which will also lead to the system to calculate the stats. They can create a new game, which in turn will start the game clock countdown and this is managed by the clock. Finally the player can scan the product barcode and in return view the environmental impact of it.\n\nActivity Diagram\nThis diagram displays the process of creating, playing, and ending a game. Reading from top to bottom you can see the different decisions at each step and what happens after the user makes a decision on whether or not to perform a certain action. The diagram is pretty self-explanatory and easy to follow.\n\nThis diagram shows the basic workflow when adding usage data into SnapGreen. Several different statistics are updated including any games in progress.\n\nClass Diagram\nThis diagram is a rough draft that shows the interaction between the different main classes of the game. It also shows the different methods that perform the various actions within the app. It also highlights the dependencies between one class and another.\n\nSequence Diagram\nThis diagram shows the interaction between the app, server, and database when a user tries to login. The app sends the login attempt information to the server and the server queries the database and recieves a response. The server then sends a response to the app based on whether the login attempt was valid, whether the user doesn't exist, or whether the password doesn't match.\n\n\nTesting\nOur team is utilizing Espresso and JUnit for Kotlin and Jest for JS testing.\nView Code Coverage\nAcceptance Tests:\nView Acceptance Test Specification\nView Acceptance Test Code\nUnit \/ Integration Tests:\nView Android Unit \/ Integration Test Code\nView Backend Unit Test Code\nSetting up the Developer Environment\nOur app utilizes Android Studio for front-end development and Node.js for the backend. View both\n\nAndroid Studio Setup\n\nInstallation:\n\nInstall latest version of [Android Studio](https:\/\/developer.android.com\/studio).\nNavigate to Tools > SDK Manager\nDownload and Install Android 9.0 (Pie)\nNavigate to SDK Tools\nDownload and Install Google Play Services\nClone the repository\nGo to File > Open and select the \"Client\" folder from the repository.\nWait for import and gradle sync to complete.\nIf prompted, download and install the latest versions of both gradle and kotlin (may not be neccessary)\nDownload the GoogleServices.json from the Firebase console.\nPlace the JSON in the \"app\" directory\nConnect an android phone with developer mode activated and USB debugging turned on\nOR Navigate to Tools > AVD Manager\nSelect Create Virtual Device\nSelect Pixel 3 > Pie > Finish\nClick on the play button on the top of Android Studio to build and run the app!\n\n\n\nNode Server Setup\n\nInstallation:\nWindows\nWe recommend enabling WSL (Windows Subsystem for Linux) first--while it is\npossible to install these programs on Windows without doing so, the server will\nultimately be hosted in a Linux environment and therefore will be expressed with\nLinux commands. When choosing a \"flavor\" of Linux to install, choose \"Ubuntu\n18.04 LTS\" from the Microsoft store--certain commands vary depending on which\nvariety of Linux you choose, and for this we are going with Ubuntu (for now).\nHow to install\/enable WSL on Windows 10\nOnce WSL has been installed\/enabled, you can start it by going to any folder in\nexplorer, clicking in the box showing your location (e.g. \"This PC > Local Disk\n(C:) > Users...,\" just above the folder contents), then typing \"wsl\" and hitting\nenter. That will put you into the Linux command line.\nLinux\nInstalling node.js (from the command line)\n\nsudo apt update\n\n\nsudo apt install nodejs\n\n\nnodejs -v\n\nInstalling npm (node package manager)\n\nsudo apt install npm\n\n\nnpm -v\n\nInstalling express.js\n\nnpm install express\n\nMac\nFirst, you need to install XCode (from the Apple App Store), and Homebrew\n(Apple's package manager for Mac). All following commands should be entered\ninto the terminal:\nInstalling Homebrew\n\nruby -e \"$(curl -fsSl https:\/\/raw.githubusercontent.com\/Homebrew\/install\/master\/install)\"\n\nInstalling node and npm\n\nbrew install node\n\n\nnode -v\n\n\nnpm -v\n\nupdating node and npm\n\nbrew upgrade\n\n\nbrew upgrade node\n\n\nnode -v\n\n\nnpm -v\n\nUninstall:\nWindows\nIf you've installed via WSL, follow the Linux instructions below from the linux\ncommand line. Otherwise, uninstall programs as you normally would.\nLinux\n\nsudo apt remove nodejs\n\n\nsudo apt purge nodejs\n\n\nsudo apt autoremove\n\nMac\n\nbrew uninstall node\n\nSome Important Dev Dependencies\nhusky: Allows for pre-commits hooks (Used to run prettier styling for every JS commit)\njest: Testing framework for JS\nnodemon: Utilized to have the server refresh automatically with every change\nprettier: Automatic code formatting for every JS commit\nRunning the Server\nRunning the server is as simple as two commands\n\nnpm install\n\n\nnpm run serve\n\nYou may get a warning from your firewall--go ahead and let it slide.\nYour terminal should announce that the server is running. Open up a browser\nwindow, and go to \"localhost:8080\". You should see a blank page with a button\nat the bottom; you should also see a message in the terminal that states \"user\nconnected.\" Try clicking on the button--you will see repeated messages.\n\n","652":"GDAL-Point-Extraction-for-Environmental-Raster-Data\nThe following code is for pulling the pixel data by lat\/long coordinates from environmental raster datasets provided by the USGS: 1) annual maximum green vegetation fraction derived NDVI (normalized difference vegetation index) satellite data; and 2) land cover type (Water, Mixed Forest, Grasslands, Urban & Built Up, etc.) Understanding the geographic distribution of vegetation and environmental resources is crucial for planning and sustainable design strategies.\nThe code pulls data from the following .tif maps: 1 km MODIS-based Maximum Green Vegetation Fraction (http:\/\/landcover.usgs.gov\/green_veg.php) and 0.5 km MODIS-based Global Land Cover Climatology (http:\/\/landcover.usgs.gov\/global_climatology.php).\nNOTE: Make sure to set the GDAL_DATA environment data. Since I installed GDAL with Anacanda, before executing the python file from terminal I ran:\nexport GDAL_DATA=\/austinarrington\/anaconda2\/share\/gdal\n","653":"EPA SMS Dispatcher\n\nThis is a simple system for Environmental Protection Agency to dispatch its Substitute Military Service personnel.\nAlthough this system is designed for EPA, it can be easily modified to fit other departments as well.\nDemo\nDemo page:\n\nhttp:\/\/chunnorris.cc\/demo\/epa-sms\/\n\nDemo files:\n\nSample Input (txt)\nSample Output Personnel (csv)\nSample Output Personnel (jpg)\nSample Output Region (csv)\nSample Output Region (jpg)\n\n\uff08\u96f6\uff09\u6b65\u9a5f\u7e3d\u89bd\n\n\u4e8b\u524d\u6e96\u5099\uff0c\u4fee\u6539\u5f79\u7537\u4eba\u6578\u3001\u5404\u7e23\u5e02\u540d\u984d\u7b49\u53c3\u6578\u3002\n\u6574\u7406\u5f79\u7537\u540d\u55ae\uff0c\u4e26\u5f59\u6574\u6210\u6b64\u7cfb\u7d71\u53ef\u63a5\u53d7\u7684\u683c\u5f0f\u3002\n\u958b\u59cb\u9810\u6392\u3002\n\u5132\u5b58\u4e26\u5217\u5370\u9810\u6392\u4e4b\u7d50\u679c\u3002\n\n\uff08\u4e00\uff09\u4fee\u6539\u53c3\u6578\n\n\u4f9d\u7167\u9019\u4e00\u68af\u7684\u5f79\u7537\u7e3d\u4eba\u6578\u4fee\u6539 region.json \u7684 what_T \u6b04\u4f4d\n\u4f9d\u7167\u9019\u4e00\u68af\u7684\u5f79\u7537\u7e3d\u4eba\u6578\u4fee\u6539 region.json \u7684 total_students \u6b04\u4f4d\n\u4f9d\u7167\u9019\u4e00\u68af\u5404\u7e23\u5e02\u7684\u540d\u984d\u4fee\u6539 region.json \u7684 available \u6b04\u4f4d\n\n\n\uff08\u4e8c\uff09\u5916\u90e8\u532f\u5165\u8cc7\u6599\u4e4b\u683c\u5f0f\n\u9664\u4e86\u624b\u52d5\u8f38\u5165\u5916\uff0c\u4e5f\u53ef\u4ee5\u5f9e\u6a94\u6848\u76f4\u63a5\u532f\u5165\u8cc7\u6599\u3002\n\u5916\u90e8\u532f\u5165\u7684\u8cc7\u6599\u5fc5\u9808\u7b26\u5408\u4e0b\u5217\u683c\u5f0f\uff1a\n\n\u5fc5\u9808\u662f\u4ee5 ANSI Big5 \u7de8\u78bc\u7684 csv \u6a94\u6848\uff0c\n\u6216\u662f\u6709 BOM \u7684 UTF-8 \u7de8\u78bc\u7684 csv \u6a94\u6848\u3002\ncsv \u8868\u683c\u5167\u7e3d\u5171\u4e09\u6b04\uff0c\u7b2c\u4e00\u6b04\u70ba\u865f\u78bc\u3001\u7b2c\u4e8c\u6b04\u70ba\u5206\u6578\u3001\u7b2c\u4e09\u6b04\u70ba\u6236\u7c4d\u5730\u3002\u5982\u4e0b\u5716\uff1a\n\n\n\uff08\u4e09\uff09\u5916\u90e8\u532f\u5165\u8cc7\u6599\u7bc4\u4f8b\u6d41\u7a0b\n(1) \u62ff\u5230\u6559\u52d9\u7d44\u7d66\u7684 \u6236\u7c4d\u5730 \u8207 \u6210\u7e3e \u8cc7\u6599\n\n\n(2) \u958b\u65b0\u6a94\u6848 -> \u65b0\u589e -> \u7a7a\u767d\u6d3b\u9801\u7c3f\uff0c\u8cbc\u4e0a\u8cc7\u6599\uff0c\u7b2c\u4e00\u6b04\u70ba\u865f\u78bc\u3001\u7b2c\u4e8c\u6b04\u70ba\u5206\u6578\u3001\u7b2c\u4e09\u6b04\u70ba\u6236\u7c4d\u5730\u3002\n\n(3) \u8cbc\u4e0a\u6642\uff0c\u8a18\u5f97\u9078\u64c7\"\u8cbc\u4e0a\u7d14\u503c\"\uff0c\u82e5\u5206\u6578\u8d85\u904e\u5c0f\u6578\u9ede\u5169\u4f4d\u4e5f\u6c92\u95dc\u4fc2\uff0c\u4e0d\u7528\u523b\u610f\u7de8\u8f2f\u3002\n\n(4) \u53e6\u5b58\u65b0\u6a94\u6642\uff0c\u9078\u64c7 CSV(\u9017\u865f\u5206\u683c)\uff0c\u6a94\u540d\u5efa\u8b70\u547d\u540d\u6210 xxxT_input_file.csv\n\n(5) \u5b58\u6a94\uff0c\u9047\u5230\u8b66\u544a\u6642\u8acb\u6309\u78ba\u5b9a\n\n\n(6) \u95dc\u9589\u6a94\u6848\uff0c\u6b64\u6642\u9078\u64c7\u4e0d\u8981\u5132\u5b58(\u525b\u525b\u5df2\u7d93\u5132\u5b58\u904e\u4e86)\n\n\u7279\u6b8a\u60c5\u5f62\n\u72c0\u6cc1\uff1a\u5047\u8a2d\u67d0\u68af\u5f79\u7537\u5171 50 \u4eba\uff0c\u5176\u4e2d 7 \u865f\u540c\u5b78\u5728\u958b\u59cb\u53d7\u8a13\u5f8c\u624d\u9a57\u9000\u800c\u9000\u8a13\uff0c\u5269\u4e0b 49 \u4eba\u3002\n\u89e3\u6cd5\uff1a\u4e0d\u7528\u4fee\u6539\u7a0b\u5f0f\u7e3d\u4eba\u6578\uff0c\u4e00\u6a23\u5c07 7 \u865f\u540c\u5b78\u7684\u8cc7\u6599\u653e\u9032 csv \u4e2d\uff0c\u4e26\u5728\u5176\u6210\u7e3e\u6b04\u586b\u5165 NA \u3002\u5982\u6b64\u4e00\u4f86\uff0c\u672c\u7cfb\u7d71\u5c31\u4e0d\u6703\u5c07 7 \u865f\u540c\u5b78\u7b97\u5165\u5e73\u5747\u5206\u6578\u4ee5\u53ca\u4e4b\u5f8c\u7684\u9810\u6392\u6f14\u7b97\u6cd5\u4e2d\u3002\n\n\uff08\u4e09\uff09\u958b\u59cb\u9810\u6392\n\n\u958b\u555f Firefox \u700f\u89bd\u5668\uff0c\u82e5\u5c1a\u672a\u5b89\u88dd\u53ef\u4ee5\u7531\u6b64\u4e0b\u8f09\n\u5f9e github \u53f3\u65b9\u7684 download zip \u6309\u9215\u4e0b\u8f09\u672c\u7a0b\u5f0f\uff0c\u89e3\u58d3\u7e2e\u5f8c\u7528 firefox \u958b\u555f index.html \n\u9ede\u9078\u5de6\u4e0a\u89d2\u7684\u700f\u89bd\u6309\u9215\uff0c\u8b80\u53d6\u4e4b\u524d\u7684 csv \u6216\u662f txt \u6a94\u6848\u7576\u4f5c\u7bc4\u4f8b\uff0c\u4e26\u6309\u4e0b\u4e0b\u65b9\u7684\u300c\u958b\u59cb\u9810\u6392\u300d\u6309\u9215\n\n\n\u5c07\u756b\u9762\u5f80\u4e0b\u6372\uff0c\u4ee5\u6b64\u7bc4\u4f8b\u6a94\u6848\u5411\u5f79\u7537\u8b1b\u89e3\u672c\u7cfb\u7d71\uff1a\n\n\n\u78ba\u8a8d\u5e73\u5747\u5206\u6578\u662f\u5426\u6b63\u78ba\n\u8b1b\u89e3\u540d\u984d\u8207\u52a0\u6e1b\u4eba\u6578\u6b04\u4f4d\n\u8aaa\u660e\u4e0a\u65b9\u984f\u8272\u5340\u584a\uff08\u5206\u767c\u898f\u5247\u8aaa\u660e\uff09\n\u4e0b\u65b9\u5c1a\u672a\u5206\u914d\u5230\u7684\u5b78\u865f\u3001\u9ede\u9078\u53ef\u81ea\u52d5\u641c\u5c0b\u6700\u4f73\u843d\u9ede\n\n\n\n\u63a5\u8457\u8b1b\u89e3\u9810\u6392\u7684\u898f\u5247\uff1a\n\n\n\u88ab\u9ede\u5230\u865f\u78bc\u7684\u5f79\u7537\u8acb\u5927\u8072\u8aaa\u51fa\u81ea\u5df1\u7684\u5fd7\u9858\n\u7576\u5207\u63db\u5230\u81ea\u5df1\u6240\u5c6c\u7684\u9801\u9762\u6642\uff0c\u8acb\u6aa2\u67e5\u81ea\u5df1\u7684\u6236\u7c4d\u5730\u8207\u6210\u7e3e\u662f\u5426\u6b63\u78ba\n\u6bcf\u56de\u5408\u7d50\u675f\u5f8c\uff0c\u6703\u6709\u4e09\u5230\u4e94\u5206\u9418\u8a0e\u8ad6\u6642\u9593\n\u544a\u77e5\u9810\u6392\u622a\u6b62\u6642\u9593\uff08\u554f\u7ba1\u7406\u5e79\u90e8\uff09\n\u8a62\u554f\u662f\u5426\u6709\u4e0d\u61c2\u5206\u767c\u898f\u5247\u7684\uff0c\u6216\u6709\u5176\u4ed6\u7591\u554f\u7684\u8acb\u767c\u554f\n\n\n\u63a5\u4e0b\u4f86\u958b\u59cb\u6b63\u5f0f\u9810\u6392\uff1a\n\n\u91cd\u65b0\u6574\u7406\u9801\u9762\uff0c\u4e26\u8b80\u53d6\u9019\u68af\u7684 csv \u6216\u662f txt \u6a94 (e.g. 144T_input_file.csv)\n\u7b2c\u4e00\u8f2a\uff1a\u7167\u865f\u78bc\u53eb\uff0c\u9078\u64c7\u5fd7\u9858\u3002\u5bb6\u56e0\u512a\u5148\u8005\u82e5\u6236\u7c4d\u5730\u6c92\u958b\u7f3a\u984d\uff0c\u53ef\u512a\u5148\u9078\u64c7\u6236\u7c4d\u5730\u5468\u570d\u7e23\u5e02\n\u5b58\u64cb\u3001\u770b\u9810\u6392\u7d50\u679c\u3001\u8a0e\u8ad6\n\u7b2c\u4e8c\u8f2a\uff1a\u4e00\u5230\u5341\u865f\u60f3\u4fee\u6539\u5fd7\u9858\u7684\u8209\u624b\uff0c\u4f9d\u6b64\u985e\u63a8\n\u5b58\u64cb\u3001\u770b\u9810\u6392\u7d50\u679c\u3001\u8a0e\u8ad6\n\u7b2c\u4e09\u8f2a\u4e4b\u5f8c\uff0c\u60f3\u4fee\u6539\u7684\u76f4\u63a5\u8209\u624b\n\u7576\u5c1a\u672a\u5206\u914d\u5230\u7684\u4eba\u6578\u8d8a\u4f86\u8d8a\u5c11\u6642\uff0c\u76f4\u63a5\u9ede\u9078\u5176\u865f\u78bc\uff0c\u7cfb\u7d71\u6703\u63d0\u793a\u9019\u500b\u865f\u78bc\u9084\u5269\u54ea\u4e9b\u5730\u65b9\u53ef\u4ee5\u9078\u64c7\n\n\u8acb\u6bcf\u6b21\u6309\u4e0b\u9810\u6392\u6309\u9215\u5f8c \u90fd\u5148\u5b58\u64cb\uff08txt\u6a94\uff09\uff0c\u4ee5\u907f\u514d\u7a81\u767c\u72c0\u6cc1\u9020\u6210\u8cc7\u6599\u6d41\u5931\u3001\u5f71\u97ff\u9810\u6392\u6642\u9593\u3002\n\u9810\u6392\u7d50\u675f\u5f8c\uff0c\u53ef\u8b93\u5f79\u7537\u5011\u62cd\u7167\u7559\u5ff5\uff0c\u4e5f\u53ef\u622a\u5716\u5099\u4efd\u3002\n\u9810\u6392\u7d50\u675f\u5f8c\uff0c\u6309\u4e0b\u53f3\u4e0b\u89d2\u8f38\u51fa\u8868\u683c\u7d66\u6559\u52d9\u7d44\u3002\n\u5176\u4ed6\u8a2d\u5b9a\njs\/global.js \u5167\u7684 printRound_N \u53ef\u4ee5\u8a2d\u5b9a\u9810\u6392\u7d50\u679c\u7684\u300c\u7e23\u5e02\u6b04\u4f4d\u300d\u986f\u793a\u5e7e\u7b46\u8cc7\u6599\u5f8c\u624d\u63db\u884c\nprintRound_N = 3; \/\/ \u6bcf\u4e09\u7b46\u8cc7\u6599\u5c31\u63db\u884c\uff0c\u5982\u4e0b\u5716\uff1a\n\n\nprintRound_N = 6; \/\/ \u6bcf\u516d\u7b46\u8cc7\u6599\u624d\u63db\u884c\uff0c\u5982\u4e0b\u5716\uff1a\n\n\n\njs\/global.js \u5167\u7684 fontColors{} \u53ef\u4ee5\u6539\u8b8a\u4e0d\u540c\u968e\u6bb5\u9304\u53d6\u7684\u984f\u8272\n\u4f7f\u7528\u4e0d\u540c\u984f\u8272\u4f86\u4ee3\u8868 \u4e0d\u540c\u968e\u6bb5\u9304\u53d6 \u7684\u5f79\u7537\nfontColors = {\n  type1 : \"black\", \/\/ \u7b2c\u4e00\u968e\u6bb5\u9304\u53d6\uff08\u5206\u6578\u5927\u65bc\u5747\u6a19\uff0c\u6236\u7c4d\u5730\uff09\n  type2 : \"#229922\", \/\/ \u7b2c\u4e8c\u968e\u6bb5\u9304\u53d6\uff08\u5206\u6578\u5927\u65bc\u5747\u6a19\uff0c\u975e\u6236\u7c4d\u5730\uff09\n  type3 : \"#0000dd\", \/\/ \u7b2c\u4e09\u968e\u6bb5\u9304\u53d6\uff08\u5206\u6578\u4f4e\u65bc\u5747\u6a19\uff0c\u6236\u7c4d\u5730\uff09\n  type4 : \"#4488ff\", \/\/ \u7b2c\u56db\u968e\u6bb5\u9304\u53d6\uff08\u5206\u6578\u4f4e\u65bc\u5747\u6a19\uff0c\u975e\u6236\u7c4d\u5730\uff09\n  \/\/ typeDefault : \"black\", \/\/ \u9810\u8a2d\u984f\u8272\n  typeHome : \"orange\", \/\/ \u5bb6\u56e0\u984f\u8272\n  typeKicked : \"red\", \/\/ \u9078\u67d0\u500b\u5730\u5340\u6642\uff0c\u88ab\u64e0\u6389\u7684\u4eba\u7684\u984f\u8272\n  leftOver : \"red\", \/\/ \u672c\u56de\u5408\u7d50\u675f\u5f8c\uff0c\u5c1a\u672a\u5206\u914d\u5230\u670d\u52e4\u55ae\u4f4d\u7684\u984f\u8272\n  shortage : \"blue\", \/\/ \u5730\u5340\u4eba\u6578\u77ed\u7f3a\u6642\u7684\u984f\u8272\n  overheat : \"red\" \/\/ \u5730\u5340\u4eba\u6578\u904e\u591a\u6642\u7684\u984f\u8272\n};\n\nTodo Lists\n\n\u53f0\u5317\u5e02 \u8ddf \u81fa\u5317\u5e02 \u5230\u5e95\u8981\u7528\u54ea\u500b\u5b57\uff1f\n123456789123\n\u88dd firefox, notepad++, D\u789f\u4e0d\u6703\u81ea\u52d5\u56de\u5fa9\nChrome modification.\n\nhttps:\/\/stackoverflow.com\/questions\/2541949\/problems-with-jquery-getjson-using-local-files-in-chrome\nMAC: open \/Applications\/Google\\ Chrome.app --args --allow-file-access-from-files\nhttp:\/\/eureka.ykyuen.info\/2013\/09\/24\/chrome-bypass-access-control-allow-origin-on-local-file-system\/\n\n\n\nLicense\nThis project is licensed under the terms of the MIT license.\nPlease note that this project is built with materials from the following parties:\n\nBootstrap\nflatly\njQuery\n\nPlease also refer to their Licenses for further information.\n","654":"Streaming Data from ESP8266 using MicroPython and MQTT\nResources\n\nMicroPython\nMicroPython Online Simulator\nMicroPython libraries\nMicroPython PiP Package Index\nESP8266 Documentation\nESP8266 Firmware\nESP8266 Firmware Tutorial\nAdafruit MicroPython Resources\n\nOther\n\nMicroPython BME280 Sensor Driver\nMicroPython SHT30 Sensor Driver\nEspressif esptool\nMosquitto Broker\nPuTTY\nSerial Support on the Windows Subsystem for Linux\n\nOverview of ESP8266 flashing process\n\nInstall esptool\nErase Flash\nDeploy MicroPython Firmware\n\nSee Flashing MicroPython Flasing How-to Tutorial\nMicroPython and Publish over MQTT\nDeploy the solution to the ESP8266 MicroPython flash as follows.\nSee Adafruit MicroPython Tool (ampy) for information on copying files to the ESP32.\npip install adafruit-ampy\n\nampy --port \/dev\/ttyUSB0 put boot.py\nampy --port \/dev\/ttyUSB0 put main.py\nampy --port \/dev\/ttyUSB0 put config.py\n\nampy --port \/dev\/ttyUSB0 put bme280.py\nampy --port \/dev\/ttyUSB0 put sht30.py\n\nampy --port \/dev\/ttyUSB0 put config_default.json\n\nampy --port \/dev\/ttyUSB0 put sensor_bme280.py\nampy --port \/dev\/ttyUSB0 put sensor_sht30.py\nampy --port \/dev\/ttyUSB0 put sensor_fake.py\n# boot.py\n\nimport network\nsta_if = network.WLAN(network.STA_IF)\nsta_if.active(True)\nsta_if.connect(\"Wifi SSID\", \"Wifi password\")\n# main.py\n\n# http:\/\/docs.micropython.org\/en\/latest\/esp8266\/index.html\n# http:\/\/garybake.com\/wemos-oled-shield.html\n# http:\/\/docs.micropython.org\/en\/latest\/esp8266\/esp8266\/quickref.html#adc-analog-to-digital-conversion\n\nfrom umqtt.robust import MQTTClient\nfrom machine import I2C, Pin\nimport utime as time\nimport gc\nimport ssd1306 as oled\nfrom machine import ADC\nimport esp\nimport config\n\n\n# Wifi connect established in the boot.py file. Uncomment if needed\n# import network\n# sta_if = network.WLAN(network.STA_IF)\n# sta_if.active(True)\n\n\n#upip packages - see README.md\n# upip.install('micropython-umqtt.simple')\n# upip.install('micropython-umqtt.robust')\n\nBuiltinLedPin = 2\n\ncfg = config.Config('config_default.json')\n\nsta_if.connect(cfg.wifiSsid, cfg.wifiPwd)\nclient = MQTTClient(str(esp.flash_id()), cfg.mqttBroker)\nmySensor = cfg.sensor.Sensor()\n\nbuiltinLed = Pin(BuiltinLedPin, Pin.OUT)\nadc = ADC(0)            # create ADC object on ADC pin\ni2c = I2C(scl=Pin(5), sda=Pin(4)) \n\nesp.sleep_type(esp.SLEEP_LIGHT)\n\n\ndef initDisplay(i2c):\n    i2cDevices = I2C.scan(i2c)\n    if 0x3c in i2cDevices:\n        display = oled.SSD1306_I2C(64, 48, i2c)\n        return True\n    else:        \n        print('No OLED Display found')\n        return False\n\ndef initialise():\n    blinkcnt = 0\n    checkwifi()\n    while blinkcnt < 50:\n        builtinLed.value(blinkcnt % 2)\n        blinkcnt = blinkcnt + 1\n        time.sleep_ms(100)\n\ndef checkwifi():\n    blinkcnt = 0\n    while not sta_if.isconnected():\n        time.sleep_ms(500)\n        builtinLed.value(blinkcnt % 2)\n        blinkcnt = blinkcnt + 1\n\ndef setContrast():\n    lightlevel = adc.read()\n    if lightlevel < 200:\n        return 0\n    if lightlevel < 600:\n        return 100\n    return 255\n\ndef publish():\n    count = 1\n    while True:\n        builtinLed.value(0)\n        checkwifi()\n        \n        temperature, pressure, humidity = mySensor.measure()\n\n        freeMemory = gc.mem_free()\n\n        if oledDisplay:\n            display.fill(0)\n            display.contrast(setContrast())\n            display.text(v[0], 0, 0)\n            display.text(v[1], 0, 10)\n            display.text(v[2], 0, 20)\n            display.text(str(freeMemory), 0, 30)\n            display.text(str(count), 0, 40)\n            display.show()    \n\n        msg = b'{\"DeviceId\":\"%s\",MsgId\":%u,\"Mem\":%u,\"Celsius\":%s,\"Pressure\":%s,\"Humidity\":%s}' % (cfg.deviceId, count, freeMemory, temperature, pressure, humidity)\n        client.publish(b\"home\/weather\/%s\" % cfg.deviceId, msg)\n\n        builtinLed.value(1)\n        count = count + 1\n        \n        time.sleep(cfg.sampleRate)\n\n\noledDisplay = initDisplay(i2c)\n\ninitialise()\n\nclient.reconnect()\n\npublish()\nConnecting to ESP32 with Putty\nInstall Putty for your platform. Connect at 115200 baud rate\nSee Adafruit Serial REPL Tutorial.\n","655":"mPies: metaProteomics in environmental sciences \nmPies is a workflow to create annotated databases for metaproteomic analysis.\nThis workflow uses three different databases for a metagenome (i) OTU-table, (ii) assembled-derived, (iii) and\nunassembled-derived to build a consensus of these databases and increase the mapping sensitivity.\nIf you use mPies for your research, please cite our publication:\nWerner, J., G\u00e9ron, A., Kerssemakers, J. et al. mPies: a novel metaproteomics tool for the creation of relevant protein databases and automatized protein annotation. Biol Direct 14, 21 (2019) doi: 10.1186\/s13062-019-0253-x\nInstallation\nThe easiest way is to use bioconda and create a new environment.\nconda env create -n mpies --file conda_env.yml\nconda activate mpies\nSingleM has been packaged by AppImage (due to the Python 2 dependency).  Download\nAppImage and build the image with\ncd appimages\n.\/appimage_singlem.sh\nappimagetool-x86_64.AppImage singlem-x86_64.AppImage\/ singlem.AppImage\nUsage\nmPies consists of two parts: database creation and annotation. Both parts are written in Snakemake.\n# database creation\nsnakemake --snakefile database_creation.smk --configfile database_creation.json --cores 28\n\n# annotation\nsnakemake --snakefile annotation.smk --configfile annotation.json --cores 28\nDetailed explanation of the mpies workflow\nDatabase creation\nPreprocessing\nThe preprocessing trims the raw reads and combines the single reads into one file.\nAmplicon-derived proteome file\nIn order to create the amplicon-derived proteome file, there are two possibilities. If amplicon data is available,\nthen a text file with the taxon names (one per line) is used for downloading the proteomes from UniProt. If no\namplicon data is available, you can set the option config[\"otu_table\"][\"run_singlem\"] to true and a taxon file is\ncreated with SingleM (this tool detects OTU abundances based on metagenome shotgun sequencing data).\nFunctional-derived subset\nIt is also possible to create a subset derived from UniProt based not only on taxonomy but to also restrict the\ngene and functional names instead of downloading the entire proteomes for the taxa of interest. To do so, a TOML file\nshould be created (see example below)\nTaxonomy = [\n    \"Bacteria\"\n]\nGene_names = [\n     \"dnaK\",\n     \"soxA\"\n]\nProtein_names = [\n    \"Heat shock protein 70\", # something commented\n]\nand the path needs to be set in the snakemake configuration (config[\"functional_subset\"][\"toml_file\"]).\nAssembled-derived proteome file\nIf only raw data is available, it is possible to run an assembly with MEGAHIT or metaSPAdes (set\nconfig[\"assembled\"][\"run_assembly\"] to true and config[\"assembled\"][\"assembler\"] to megahit or metaspades).\nPlease keep in mind that assemblies can take a lot of time depending on the size of the dataset. If you already have an\nassembly, set config[\"assembled\"][\"run_assembly\"] to false and create a symlink of your assembly into\n{sample}\/assembly\/contigs.fa. If you have no gene calling yet, remember to set\nconfig[\"assembled\"][\"run_genecalling\"] to true.\nIf you have both assembly and gene calling already performed, set config[\"assembled\"][\"run_assembly\"] and\nconfig[\"assembled\"][\"run_genecalling\"] to false and create a symlink of the assembled proteome into\n{sample}\/proteome\/assembled.faa.\nUnassembled-derived proteome file\nTo create the unassembled-derived proteome file, FragGeneScan is used (and prior to that a fastq-to-fasta\nconversion).\nPostprocessing\nDuring the postprocessing, the all three proteomes are combined into one file. Short sequences (< 30 amino acids)\nare deleted and all duplicates are removed. Afterwards, the fasta headers are hashed to shorten the headers (and save\nsome disk space).\nAnnotation\nPreprocessing\nFor now, the identified proteins are inferred from ProteinPilot. The resulting Excel file is used to create a protein\nfasta file that only contains the identified proteins. Taxonomic and functional analysis are conducted for the\nidentified proteins.\nTaxonomical annotation\nThe taxonomic analysis is performed with blast2lca from the MEGAN package. Per default, the taxonomic analysis is set\nto false in the snake config file.\nSome prerequisites are necessary to run the taxonomic analysis for the created proteome fasta file.\n\n\nDownload MEGAN. Don't forget to also\nto download and unzip the file prot_acc2tax-June2018X1.abin.zip from the same page.\n\n\nDownload the nr.gz fasta file from NCBI (size: 40 GB).\n\n\nwget ftp:\/\/ftp.ncbi.nlm.nih.gov\/blast\/db\/FASTA\/nr.gz\nwget ftp:\/\/ftp.ncbi.nlm.nih.gov\/blast\/db\/FASTA\/nr.gz.md5\nmd5sum -c nr.gz.md5\nIf the checksum does not match, the download was probably not complete. wget -c continues a partial download.\n\nCreate a diamond database of the file nr.gz.\n\ndiamond makedb --threads <number_of_threads> --in nr.gz --db nr.dmnd\n\nNow you can set config[\"taxonomy\"][\"run_taxonomy\"] to true and run snakemake. Remember to set the paths for the\ndiamond database, the binary of blast2lca and the path to the file prot_acc2tax-Jun2018X1.abin. Please note that\ndiamond blastp takes a very long time to execute.\n\nFunctional annotation\nDifferent databases can be used to add functional annotation. Per default, the funtional annotation is set to false.\nCOG\nIn order to use the COG database, some prerequisites have to be fulfilled before.\n\nDownload the necessary files from the FTP server.\n\nwget ftp:\/\/ftp.ncbi.nih.gov\/pub\/COG\/COG2014\/data\/prot2003-2014.fa.gz\nwget ftp:\/\/ftp.ncbi.nih.gov\/pub\/COG\/COG2014\/data\/cog2003-2014.csv\nwget ftp:\/\/ftp.ncbi.nih.gov\/pub\/COG\/COG2014\/data\/cognames2003-2014.tab\nwget ftp:\/\/ftp.ncbi.nih.gov\/pub\/COG\/COG2014\/data\/fun2003-2014.tab\n\nCreate a diamond database of the file prot2003-2014.fa.gz.\n\ndiamond makedb --threads <number_of_threads> --in prot2003-2014.fa.gz --db cog.dmnd\n\nNow you can set config[\"functions\"][\"run_cog\"][\"run_functions_cog\"] to true and run snakemake. Remember to set\nthe paths for the diamond database and the files cog_table, cog_names, and cog_functions.\n\nUniProt\/GO\nIn order to use the GO ontologies included in the UniProt database (SwissProt or TrEMBL), some prerequisites have to\nbe fulfilled before.\n\nDownload the necessary files from the FTP server.\n\n# SwissProt\nwget ftp:\/\/ftp.uniprot.org\/pub\/databases\/uniprot\/current_release\/knowledgebase\/complete\/uniprot_sprot.fasta.gz\nwget ftp:\/\/ftp.uniprot.org\/pub\/databases\/uniprot\/current_release\/knowledgebase\/complete\/uniprot_sprot.dat.gz\n\n# TrEMBL\nwget ftp:\/\/ftp.uniprot.org\/pub\/databases\/uniprot\/current_release\/knowledgebase\/complete\/uniprot_trembl.fasta.gz\nwget ftp:\/\/ftp.uniprot.org\/pub\/databases\/uniprot\/current_release\/knowledgebase\/complete\/uniprot_trembl.dat.gz\nPlease note that TrEMBL is quite large (29 GB for uniprot_trembl.fasta.gz and 78 GB for uniprot_trembl.dat.gz).\n\nCreate a diamond database of the fasta file (here the SwissProt database will be used)\n\ndiamond makedb --threads <number_of_threads> --in uniprot_sprot.fasta.gz --db sprot.dmnd\n\nUse the dat file downloaded from UniProt to create a table with protein accessions and GO annotations\n\n.\/main.py prepare_uniprot_files -u ...\/uniprot_sprot.dat.gz -t ...\/sprot.table.gz\nPlease note that input and output files must be\/are compressed with gzip.\n\nNow you can set config[\"functions\"][\"run_uniprot\"][\"run_functions_uniprot\"] to true and run snakemake.\n\nTest data\nThe test data set is a subset from the Ocean Sampling Day (first 18,000 lines for each read file), Accession number\nERR770958 obtained from https:\/\/www.ebi.ac.uk\/ena\/data\/view\/ERR770958). The data is deposited in the test_data\ndirectory of this repository.\n","656":"SETENV\nThis project helps manage project-specific environmental variables: There when\nyou want 'em, gone when you don't.\nUsage\n\n\nClone this repository and copy the setenv.sh file to the root of your project.\n\n\nIf installing for the first time - PERFORM INITIAL SETUP OF THE VIRTUAL ENVIRONMENT (by issuing virtualenv venv)\n\n\nCreate a file named .env and list your project's environmental variables,\ne.g., DATABASE=\/path\/to\/database.db\n\n\nIssue: source setenv.sh to set up environment variables AND start the virutalenv. If the venv\nand environment variables are correctly setup a [VENV+] indicator will appear on the left\nhand side of the prompt in bold purple. (Issuing pip -V should also show the directory of the\nvirtual environment's python interpreter.)\n\n\nIssue: usetenv to exit the virtual environment AND unset all environment variables.\n\n\nNOTES:\n\nThis will completely override the builtin deactivate command.\nThe default venv scripts are not modified; so the canned venv setup script will still work out of\nthe box if you chose to use it. However, if you launch setenv (using source setenv.sh), any\ninteraction with the canned venv scripts will be disabled.\n\n","657":"ResonantEco\nDevelop environment setup\nResonantEco has server, client two components. They are located under server and client directory respectively.\nPrerequisite\n\nPyhton 3.5+\nMongodb running at the default port\nNode 8\nClone this repo git clone https:\/\/github.com\/OpenDataAnalytics\/resonanteco.git\n\nServer\n\npip install -e .\/resonanteco\/server\/\ngirder build\nThe girder interface will be available at http:\/\/localhost:8080\/girder\n\nClient\nThe client is a Vue CLI based application. All Vue-CLI options are available.\n\ncd .\/resonanteco\/client\nnpm install\nnpm run serve\nNavigate to localhost:8081\nRegister user then login the system\n\nlinting\n\nnpm run lint\n\nData ingestion\n\nIn the same python envrionment as the server\nNavigate to server\/data\nexport GIRDER_MONGO_URI=mongodb:\/\/localhost:27017\/girder-resonanteco if you db is not the default girder\nexecute python ingest.py .\/data\n\n","658":"Modeling for Environmental Management Workshop\n13-14 August 2018, Universiti Sains Malaysia\n","659":"trafficsignrecognize\n\u0110\u1ed3 \u00e1n nh\u1eadn di\u1ec7n bi\u1ec3n b\u00e1o c\u1ea5m \u0111\u01a1n trong \u1ea3nh m\u00f4i tr\u01b0\u1eddng c\u00f3 s\u1eed d\u1ee5ng deep learning.\nY\u00eau c\u1ea7u:\nPython:\n\npython 3.6.9\n\n\nPackages:\n*Khuy\u1ebfn kh\u00edch s\u1eed d\u1ee5ng Anaconda 3 t\u1ea1o m\u1ed9t environment m\u1edbi t\u00ean \"opencv\" \u0111\u1ec3 c\u00e0i t\u1ea5t c\u1ea3 packages nh\u01b0 h\u00ecnh\n\n\n\nnumpy 1.17.2\nmatplotlib 3.1.1\nopencv 3.4.2\ndjango 2.2.5\nscikit-image 0.15.0\ntensorflow 2.0.0\ntensorflow-mkl 1.15.0\nkeras 2.2.4\npillow 6.2.1\n\nRun project:\nActivate bi\u1ebfn m\u00f4i tr\u01b0\u1eddng Anaconda 3\nsource ospath\/anaconda3\/anaconda3\/bin\/activate\nActivate m\u00f4i tr\u01b0\u1eddng ch\u1ee9a c\u00e1c packages c\u1ea7n thi\u1ebft\nconda activate opencv\nDi chuy\u1ec3n \u0111\u1ebfn th\u01b0 m\u1ee5c ch\u1ee9a project\ncd parentProjectPath\/traffic_sign_recognize-master \nCh\u1ea1y server\npython manage.py runserver\nSau khi ch\u1ea1y server th\u00e0nh c\u00f4ng truy c\u1eadp \u0111\u1ecba ch\u1ec9 localhost:8000 \u0111\u1ec3 thao t\u00e1c.\n\nH\u1ed7 tr\u1ee3 c\u00e1c bi\u1ec3n b\u00e1o: (Theo b\u1ed9 bi\u1ec3n b\u00e1o chu\u1ea9n Vi\u1ec7t Nam)\n\n101: \u0110\u01b0\u1eddng c\u1ea5m\n102: C\u1ea5m \u0111i ng\u01b0\u1ee3c chi\u1ec1u\n122: D\u1eebng l\u1ea1i\n127: T\u1ed1c \u0111\u1ed9 t\u1ed1i \u0111a cho ph\u00e9p\n\nTham kh\u1ea3o source code train file model.h5 t\u1ea1i github.com\/quangkhoiuit98\/trainmodeltrafficsignrecognize\n\n\nCh\u1ee9c n\u0103ng ch\u00ednh\nTrang ch\u1ee7\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Nh\u1eadn di\u1ec7n bi\u1ec3n b\u00e1o t\u1eeb \u1ea3nh m\u00f4i tr\u01b0\u1eddng\n\nTrang tra c\u1ee9u bi\u1ec3n b\u00e1o\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Tra c\u1ee9u bi\u1ec3n b\u00e1o t\u1eeb d\u1eef li\u1ec7u c\u1ee7a \u1ee9ng d\u1ee5ng\n\n","660":"Extracting-land-use-proportion-around-spatial-points-from-environmental-shapefiles\nThis script allows to extract land-use proportions around points in a given radius from land-use shapefiles, and then quickly\nget theses proportions for any lower sizes of buffers. Outputs are in form of shapefiles and crossed tables to use information easily.\nMainly adapted for land-use shapefiles containing all types of land-use such as cesbio landcover shapefiles which can be downloaded here:\nhttp:\/\/osr-cesbio.ups-tlse.fr\/echangeswww\/TheiaOSO\/vecteurs_2017\/liste_vecteurs.html\nExtracting-land-use-proportion-around-spatial-points-from-one-environmental-raster\nThis script allows to extract land-use proportions around points in several radius sizes from a raster layer.\nLand-use layer used available here: http:\/\/osr-cesbio.ups-tlse.fr\/echangeswww\/TheiaOSO\/OCS_2018_CESBIO.tif\nEncapsulated in a function.\nScript used\n\nExtractingLandUseBuffers.R # adapted for shapefile environmental layer (time-consuming)\nExtractingLandUseBuffers_fromRaster.R # adapted for raster environmental layer (fast)\n\nData used\n\ndepartement_01.shp # first French department used as example which must be downloaded here: http:\/\/osr-cesbio.ups-tlse.fr\/echangeswww\/TheiaOSO\/vecteurs_2017\/departement_01.zip\ndepartement_39.shp # second French department used as example which must be downloaded here: http:\/\/osr-cesbio.ups-tlse.fr\/echangeswww\/TheiaOSO\/vecteurs_2017\/departement_39.zip\npoints.shp # random points used as example\nDEPARTEMENT.shp # French departement layer allowing to only select in the script department layers (when a lot of layers are in the folder) containing points\n\n","661":"\nLake levels from the Yahara Watershed\nhttp:\/\/www.yahara.info\nMadison Wisconsin and the surrounding Dane County saw near record level rainfalls in late August. Widespread flooding caused over two hundred million dollars in damage (Associated Press).\nIn the months leading up to the flood, the lakes surrounding Madison were higher than the maximum level set by the Wisconsin Department of Natural Resources in 1979.\nHow often has that been true? Are the lakes currently above that maximum level? Why were they kept so high? All of these questions and more we hope to address.\nEnvironment setup\nInstall postgresql.\nMake sure you have an environment variable named USER with your username as its value. On UNIX variants this likely already exists\nCreate a new user with your username who has permissions to create a database, e.g. with sudo -u postgres createuser -s $USER.\nIt is recommended to set up some sort of virtual environment. After that, install the requirements with\npip install -r requirements.txt\nCode\nThe code is in madison_lake_levels, and requires python >= 3.6. You can run tests with python -m pytest run from the top level of this project.\nRunning locally\nRun with\n# Get env set up\nexport FLASK_APP=app.py\nexport DATABASE_URL=postgres:\/\/$USER:@:\/madisonlakes # heroku's env var format\ncreatedb madisonlakes -U $USER\n# Run the app\nflask run\n# To run in debug mode (don't do in prod!):\nexport FLASK_ENV=development\nflask run\n\nDeploy\nThe webapp is deployed to Heroku. It can be found at http:\/\/www.yahara.info. The heroku-format Procfile and runtime.txt are used to control deployment.\nA free-tier of a database on Heroku is used to persist the data.\nA cron job runs every 30 minutes that updates the database. The job is created using Heroku Scheduler, and hits a simple API route on the web-app that causes an update. Running the job every 30 minutes has a nice side effect of preventing the website from going into hibernation mode (which Heroku does on the free tier).\n","662":"epidemiar\nThe Epidemic Prognosis Incorporating Disease and Environmental Monitoring for Integrated Assessment (EPIDEMIA) Forecasting System is a set of tools coded in free, open-access software, that integrate surveillance and environmental data to model and create short-term forecasts for environmentally-mediated diseases.\nThis R package contains the functions for modeling, forecasting, validation, and early detection & early warning alerts.\nFor producing formatted reports, see also the demo project based on malaria in Ethiopia (with demo data): https:\/\/github.com\/EcoGRAPH\/epidemiar-demo\nEPIDEMIA project: http:\/\/ecograph.net\/epidemia\/\n","663":"A collection of environment configurations that I use for bash.\n","664":"Machine Learning - Environmental Effects on Health\nThis project, developed as a requirement in a machine learning course, attempts to learn the impact of environmental factors on health.\nThe goal is to predict the health status statistics of a country's residents by analysing various environmental factors, such as various types of air pollution.\nThe project's scripts will become available here shortly.\n","665":"POSEC\nLearning Environmental Calibration Actions for Policy Self-Evolution\nPOSEC code for the paper\n\nChao Zhang, Yang Yu, Zhi-Hua Zhou. Learning environmental calibration actions for policy self-evolution. In: Proceedings of the 27th International Joint Conference on Artificial Intelligence (IJCAI'18), Stockholm, Sweden.\n\nRequirement\n\npython 2.7\nargparse\npickle\nkeras (1.0.1)\ntheano (0.8.2)\ntabulate\nscipy\nnumpy\n\nInstructions\nWe mainly use three tasks of mujoco environment in Gym, namely Pusher, Striker and Thrower. Here, we take the Pusher task as an example, and Striker and Thrower are alternative.\n\nStep 1:Training Base Policies\n\n# Generating multiple different configuration environments<br>\npython change_env_config.py pusher \n    \n# Using TRPO[1] to generate multiple base policies\npython run_pg.py --env pusher --agent modular_rl.agentzoo.TrpoAgent  \n\nStep 2:Optimizing Combination Weightss\n\n# In a batch of new configuration environments, the optimal weights of base policies are obtained based on zoopt[2]\npython get_best_weight.py pusher\n\nStep 3:Optimizing Calibration Actions\n\n# In a batch of new configuration environments, the optimal calibration actions are obtained based on zoopt[2]\npython get_best_action.py pusher \n[1] Schulman J, Levine S, Abbeel P, et al. Trust region policy optimization. In: Proceedings of the 32nd International Conference on Machine Learning (ICML'15), pages 1889-1897, Lille, France, 2015.\n[2] Yu-Ren Liu, Yi-Qi Hu, Hong Qian, Yang Yu, Chao Qian. ZOOpt: Toolbox for Derivative-Free Optimization. arXiv:1801.00329, 2017.\n","666":"POSEC\nLearning Environmental Calibration Actions for Policy Self-Evolution\nPOSEC code for the paper\n\nChao Zhang, Yang Yu, Zhi-Hua Zhou. Learning environmental calibration actions for policy self-evolution. In: Proceedings of the 27th International Joint Conference on Artificial Intelligence (IJCAI'18), Stockholm, Sweden.\n\nRequirement\n\npython 2.7\nargparse\npickle\nkeras (1.0.1)\ntheano (0.8.2)\ntabulate\nscipy\nnumpy\n\nInstructions\nWe mainly use three tasks of mujoco environment in Gym, namely Pusher, Striker and Thrower. Here, we take the Pusher task as an example, and Striker and Thrower are alternative.\n\nStep 1:Training Base Policies\n\n# Generating multiple different configuration environments<br>\npython change_env_config.py pusher \n    \n# Using TRPO[1] to generate multiple base policies\npython run_pg.py --env pusher --agent modular_rl.agentzoo.TrpoAgent  \n\nStep 2:Optimizing Combination Weightss\n\n# In a batch of new configuration environments, the optimal weights of base policies are obtained based on zoopt[2]\npython get_best_weight.py pusher\n\nStep 3:Optimizing Calibration Actions\n\n# In a batch of new configuration environments, the optimal calibration actions are obtained based on zoopt[2]\npython get_best_action.py pusher \n[1] Schulman J, Levine S, Abbeel P, et al. Trust region policy optimization. In: Proceedings of the 32nd International Conference on Machine Learning (ICML'15), pages 1889-1897, Lille, France, 2015.\n[2] Yu-Ren Liu, Yi-Qi Hu, Hong Qian, Yang Yu, Chao Qian. ZOOpt: Toolbox for Derivative-Free Optimization. arXiv:1801.00329, 2017.\n","667":"The Elite: Dangerous Immersion Toolkit\nThe The Elite: Dangerous Immersion Toolkit (EDIT) is an application that integrates with the Elite: Dangerous commander log and provides a way to have external actions trigger on events from the log.\nOnce started it looks for the current game log, a list of event methods are provided that do actions based on the events from the log. For example if we get the HeatWarning event we trigger our environmental\neffects set for it.\n{ \"timestamp\":\"2017-11-05T21:13:28Z\", \"event\":\"HeatWarning\" }\nIt also provides a way to create environmental schemes for ambient light.  Currently the app only ships with star colours, but could be extended to include things like star system economy types.\nCurrently the only implemented plugin is the Philips Hue light control.  Features to be added:\n\n Play sounds\n Trigger Webhooks\n Create streaming endpoints\n Write to another file\n Better API Endpoint and behind token based authentication\n Better Docs!\n\nWhy create this tool\nIt started as an experiment with the Philips Hue API and integrating it into the game events.  I started with an experiment using the light and triggering on certain events. Once I got this\nworking I realised I could add other outputs from the app such as playing an additional sound, or triggering a webhook to a peripheral or network service.\nThis app is built on nodejs 8 and uses async\/await through the code to achive a well structured layout in writing light recipies.\nInstalling\nCurrently the application is alpha software and not yet available via npm, or as a binary. You require node 8 to run this.  After installing node you also need to run npm install -g windows-build-tools to install the required build tools.\nOnce done you can clone the repo:\n> git clone https:\/\/github.com\/ed-it\/toolkit.git ed-it\n> cd ed-it\n> npm install\n> npm start\nOnce up and running you can go to http:\/\/localhost:12342\/hubs and click \"Manage Hubs\".  It will find all available hubs in the network.  Select the one you want to use for the client.\nNext go to http:\/\/localhost:12342\/settings and enter the username associated with your hub (docs on this soon!).\nYou also need to enter the location of you Elite: Dangerous logs.  On Windows this is usually C:\\Users\\[username]\\Documents\\Save Games\\Frontier Developments\\Elite Dangerous.\nThanks to millstonebarn for the name suggestion.\n","668":"LEGIT\n\n\nThis is a R implementation of the Latent Environmental & Genetic InTeraction (LEGIT) model.\n\nCitation\nIf you use this software, please cite:\nJolicoeur-Martineau, A., Wazana, A., Szekely, E., Steiner, M., Fleming, A. S., Kennedy, J. L., ... & Greenwood, C. M. (2018). Alternating optimization for G\u00d7 E modelling with weighted genetic and environmental scores: Examples from the MAVAN study. Psychological methods.\nIf you use the function for GxE interaction testing, please also cite:\nJolicoeur-Martineau, A., Belsky, J., Szekely, E., Widaman, K., Pluess, M., Greenwood, C., & Wazana, A. (2020). Distinguishing differential susceptibility, diathesis-stress, and vantage sensitivity: Beyond the single gene and environment model. Development and Psychopathology, 32(1), 73-83. doi:10.1017\/S0954579418001438\nDescription\nThe LEGIT model is an interaction model with two latent variables: a weighted sum of genetic variants (genetic score) and a weighted sum of environmental variables (environmental score). Alternating optimization is used to estimate the model parameters (https:\/\/arxiv.org\/abs\/1703.08111). This approach has greatly enhanced predictive power over traditional GxE models which include only a single genetic variant and a single environmental exposure. Although this approach was originally made for GxE modelling, it is flexible and does not require the use of genetic and environmental variables. It can also handle more than 2 latent variables (rather than just G and E) and 3-way interactions or more. The LEGIT model produces highly interpretable results and is very parameter-efficient thus it can even be used with small sample sizes (n < 250). Tools to determine the type of interaction (vantage sensitivity, diathesis-stress or differential susceptibility), with any number of genetic variants or environments, are available (https:\/\/psyarxiv.com\/27uw8).\nHow to use\nA vignette explaining how to use the software is available here : https:\/\/rawgit.com\/AlexiaJM\/LEGIT\/master\/inst\/doc\/LEGIT.html\nAn additional vignette explaining how it can be used for GxE testing as per Belsky et al. (2013) is available here: https:\/\/rawgit.com\/AlexiaJM\/LEGIT\/master\/inst\/doc\/GxE_testing.html\nHow to install\nTo install the latest stable version, run in R :\n\ninstall.packages(\"LEGIT\")\n\nTo install the latest GitHub development version which could contain new or experimental features, run in R :\n\ninstall.packages(\"devtools\")\ndevtools::install_github(\"AlexiaJM\/LEGIT\")\n\nRegarding the GitHub installation. When it ask \"Enter one or more numbers, or an empty line to skip updates:\", just write nothing and press enter. Otherwise, you risk getting a \"Cannot remove prior package X\" error.\nExamples\nHere is an example with 2 latent variables and a 2-way interaction (see https:\/\/arxiv.org\/abs\/1703.08111) :\n\nHere is an example with 3 latent variables and a 3-way interaction (see https:\/\/arxiv.org\/abs\/1703.08111) :\n\nReferences\n\nhttps:\/\/arxiv.org\/abs\/1703.08111\nhttps:\/\/psyarxiv.com\/27uw8\nhttps:\/\/ajolicoeur.wordpress.com\/legit\/\n\n","669":"Enviro-Plus\nExperiments in environmental monitoring with Pimoroni's Enviro+ board and Raspberry Pi\n","670":"BIBEMME\nBiblatex styles for journals of environmental microbiology and microbial ecology\nBiblatex is the modern way of working with citations in LaTeX documents. Together with biber it completely replaces the old BibTeX facilities. While it is easy to use and almost unlimited in flexibility it offers a relatively restricted number of citation styles. Unlike simply using biblatex, writing new citation styles is time consuming and non-trivial to the novice user. The aim of this project is to develop comprehensive citation styles to leading journals of environmental microbiology and microbial ecology requiring little to no tweaking on the user's side.\nAll styles are designed to work with biblatex 2.3 and above together with biber.\nIn constructing the styles I referred to the author guidelines of each journal but also to publications from latest issues, as there are occasional conflicts or missing guidelines regarding some types of sources or special cases. Each style defines explicitly the formatting of only the following bibtex reference types: article, book, incollection and inproceedings. Other types are too rare, and in any case are usually not formally described in the author guidelines.\nDisclaimer\nThis project as a whole and each style in particular are under continuous development and might therefore contain mistakes or bugs. Please report if you find any bug or missing feature.\nCopyright (C) 2012 Roey Angel\nangel[AT]mpi-marburg.mpg.de\nTHIS PROGRAM COMES AS IS WITH ABSOLUTELY NO WARRANTY.\nThis software is distributed under the terms of the The LaTeX Project Public License.\nThis project was inspired by Timoth\u00e9e Poisot's ecobiblatex and I used his geb.bbx as a template.\nUsage:\nPlease refer to .bbx file of each individual style for specific usage instructions.\n\nPlace the .bbx and .cbx files in your tex path (e.g. $TEXMFHOME\/texmf-var\/tex\/latex\/biblatex in linux) and add the following to the preamble:\n\\usepackage[style=STYLE_NAME, natbib=true, backend=biber]{biblatex}\n\\addbibresource{YOUR_BIB_FILE.bib}\nThe style and .bib source names should, of course, be replaced by the desired citation style and your personal bibtex collection file.\nFor styles requiring journal name abbreviations (all styles at the moment), the appropriate JourAbs-AB_STYLE.map file or a link to it must be placed withing the same directory as the LaTeX document, where 'AB_STYLE' refers to the specific abbreviation style used by the journal.\nAdd a bibliography list in the document using: \\printbibliography[sorting=SORT_SCHEME]. Typically the references should be sorted using \\printbibliography[sorting=nyt] but note that some styles might require a different sorting scheme (e.g. emi).\n\nCurrently available styles\n\nemi:     Environmental Microbiology\nismej:   The ISME Journal - Multidisciplinary Journal of Microbial Ecology\nfemsme:  FEMS Microbiology Ecology\naem:     Applied and Environmental Microbiology - NEW! Conforms to the new 2013 citation scheme\ntufte-handout: Tufte handouts style - not a journal but I use this document class for my own notes.\n\n","671":"GoEnvConfig\nImmutable configuration loaded from environment variables.\n\n\n\n\n\nAutomatically load environmental variables into structs with private properties.\nInstallation\ngo get github.com\/j7mbo\/goenvconfig\nExample\nBash:\nexport PORT=1337 \nGo:\npackage main\n\nimport (\n    \"github.com\/j7mbo\/goenvconfig\"\n    \"fmt\"\n)\n\ntype Config struct {\n    host     string  `env:\"HOME\" default:\"localhost\"`\n    port     int     `env:\"PORT\" default:\"8080\"`\n}\n\nfunc (c *Config) GetHost() string { return c.host }\nfunc (c *Config) GetPort() int { return c.port }\n\nfunc main() {\n    config := Config{}\n    parser := goenvconfig.NewGoEnvParser()\n    \n    if err := parser.Parse(&config) {\n    \tpanic(err)\n    }\n    \n    fmt.Println(config.GetHost()) \/\/ localhost\n    fmt.Println(config.GetPort()) \/\/ 1337\n}\nSupported Types\nFor now the following simple types are supported:\n\nint\nstring\n\nWhy\nJust because you want to automatically load environment variables into configuration structs does not mean you should\nexpose modifiable exported properties on your configuration object. Instead the struct should be immutable with\nproperties only accessible via getters.\nYou can either idiomatically create a factory method thereby greatly reducing the simplicity of an automated solution,\nor you do something you're \"not supposed to\" and use a library that utilises the reflect and unsafe packages.\n","672":"citizen-scientist\nMonitor air quality and automatically share the collected data using inexpensive hardware.\nOpenWest slides show how to build the project, including slide 24 with wiring explanation.\nSetup\nInstall arduino 1.8.2 or newer\nInstall serial driver from vendor drivers\nSet up esp8266 runtime for arduino\nOpen geothunk.ino in arduino and select board. Tools->Board->NodeMCU 1.0 (ESP-12E Module)\nLibraries: sketch->include library->manage libraries\n\nWiFiManager (0.14.x)\nArduinoJson (5.x.x)\nPubSubClient (2.x.x)\n\"ESP8266 and ESP32 Oled Driver for SSD1306 display\" (4.x.x)\nEsp8266TrueRandom (wget https:\/\/github.com\/marvinroger\/ESP8266TrueRandom\/archive\/master.zip; sketch->include library->Add .zip Library)\n\nPlug in board and choose the port. On mac: Tools->Port->\/dev\/cu.SLAB_USBtoUART (Reboot and check your USB cable is a full power+data cable if the port isn't available.)\nHit the upload button.\nReboot the board and use your phone to connect to the Geothunk-XXX access point. In the captive portal screen, set the password for your access point. Hit save. There is a youtube video to show this in practice.\nIf you're on the same access point as the sensor, you should be able to see graphs for your measurements by clicking its geothunk.local mdns link. If mdns isn't working or you have multiple sensors, point a browser at the IP address displayed on the device instead.\nRegister and agree to share your data with our agreement\nContributors\n\nBrad Midgley wrote the firmware and built the sensor\nTim Harper updated the firmware with refactors, overflow protection, improved sensor listener\nDorian Tolman designed the case\n\nParts:\n\nEsp8266 D-Duino\nDHT22 (3-wire package)\nPMS3003\n\n","673":"Environmentalizer - WIP - DO NOT USE YET\nNOTE: At the moment, this script will not work when run by itself. It has been modified to work with an OS X companion app. To run as a stanalone script, please check out commit: ce4f529d9ee09725c529dfb5fafd046c3f064c59.\nA bash script to quickly and easily bootstrap a well-setup programming\nenvironment. It assumes a fresh install of OS X 10.9 (Mavericks) or OS X 10.10 (Yosemite).  Any software already installed will be skipped.\nWhat It Sets Up\n\nFlatiron School's standard .bash_profile, which includes case-insensitive auto completion, a nice prompt with git branch awareness, and many useful shortcuts.\nHomebrew\nGit\nSQlite3\nRVM, Ruby 2.2.* and their dependencies\nThe Learn gem and its dependencies\nSublime Text 3 with Package Control, Solarized Theme, and proper tab defaults\nSensible .gitconfig, .gitignore, .gemrc, and .irbrc files\nSSH Key for GitHub\nA simple directory structure for well-organized code\nGoogle Chrome\n\nWhat You Need Before You Begin\n\nKnow your admin password (you'll need to enter it once when the script first runs)\nKnow your GitHub username\nKnow the email address associated with your GitHub account\nA personal access api token for GitHub. You can create one here: https:\/\/github.com\/settings\/tokens\/new. The name doesn't matter. You MUST select the write:public_key scope.\nYou MUST to have pre-installed Xcode, accepted its license, and have the Command Line Tools.\n\nNotes\n\nYou'll need to run this script from an account with admin status. (DO NOT prepend sudo to the command below.)\nWhen the script first runs, you'll need to enter your admin password once for Homebrew to install and again for Sublime's symlink.\nDuring installation, Sublime Text will open for a few seconds and then close automatically. Do not close it yourself. This step is required for some important directories to be created.\n\nUsage\ncurl -L \"https:\/\/raw.githubusercontent.com\/flatiron-school\/environmentalizer\/master\/runner.sh\" | bash\nTesting\nEnvironmentalizer utilizes Bats (Bash Automated Testing System) for testing.\nInstallation\n\n$ git clone https:\/\/github.com\/sstephenson\/bats\n$ cd bats\n$ .\/install.sh \/usr\/local\n\nUse\nRunning Tests\n\nRun tests with $ bats test\nAlternatively, run $ bin\/test\n\nWriting Tests\n\nAdd all test files to the test directory\nTest files should have the .bats extension\nAll files need the #!\/usr\/bin\/env bats shebang at the top\nSee a sample in test\/sample.bats\nFor more documentation, visit the (Bats Readme)[https:\/\/github.com\/sstephenson\/bats\/blob\/master\/README.md]\n\nTODO\n\nExtract 'check if file exists and if it has this content' logic into\nreusable function\nWrite tests\n\n","674":"Environmentalist\n","675":"AEM 6510 - Environmental and Resource Economics\nClass location: Zoom (link on Canvas)\nClass time: Tues\/Thurs 3:00-4:15\nOffice hours: Tues\/Thurs 4:20-4:50 (link on Canvas)\nTeaching assistant: Diego Cardoso\nTA office hours: Mon 3:00-4:00  (link on Canvas)\nTextbook: A Course in Environmental Economics by Phaneuf and Requate is required. Causal Inference: The Mixtape by Cunningham is also required and free.\nPrerequisites: MATH 1110 or equivalent.\nCourse description: An introduction to environmental economics. The first half of the class focuses on the core theory, theory of regulation, and theory of welfare analysis. The second half of the course covers empirical topics. We will be learning how to use R for empirical research in environmental economics.\nCourse requirements: Students are expected to attend the Zoom class sessions if they are in a reasonable timezone. If you are not (e.g. 12 hour difference) you may take the course asynchronously. Students are expected to prepare for class, prelims, and complete problem sets outside of class.\nGrading and Assignments\nGrading\n\nPrelims: 30% and 25%\nProblem sets: 20%\nFinal project paper: 20%\nFinal project presentation: 5%\n\nThe grading scale is:\n\nA: 92-100; A-: 90-91\nB+: 88-89; B: 82-87; B-: 80-81\nC+: 78-79; C: 72-77; C-: 70-71\nD+: 68-69; D: 62-67; D-: 60-61\nF: < 60\n\nPrelims\nThere will be 2 prelims. You will have 24 hours for the theory prelim. You will have 48 hours for the empirical prelim. The class time is reserved for Zoom office hours for any questions. You are expected to complete the prelims on your own, not in groups. Your higher-scoring prelim will be 30% of your grade, your lower-scoring prelim will be 25% of your grade. If you miss a prelim without an acceptable excuse you will receive a zero. If you have an acceptable excuse (these must be brought in beforehand except for sickness, injuries, accidents, etc) an alternative prelim will be scheduled. If you miss a prelim and do not notify me beforehand you must have a valid document (doctor's note, etc) explaining why you missed class and were not able to let me know before the missed prelim. Prelims submitted late will have a 30% deduction.\nProblem sets\nYou will have 4 problem sets. You may work in groups of up to 3 on problem sets. Problem sets may be turned in late with a penalty of 20% of that homework's grade for each day it is late. Problem sets are due at the start of class on Canvas.\nFinal project\nFor your final project you can choose between a literature review or a data dive. Descriptions of both are below and more details will come a few weeks into the semester.\nLiterature review\nYou can do a literature review on up to 5 papers on an environmental, resource, or energy economics topic of your choice. Your goal will be to summarise the findings, find common threads, and work yet to be done in the area. In the last two weeks of class you will give a short presentation of your review of the literature. Papers are due after the semi-final period. My approval of your choice of papers is required before you start the literature review.\nData dive\nYou can find a new dataset that we do not cover in class but appears useful for environmental economics research. Your goal is to describe the data, how you get them, how you use them, and what makes them relevant. You will also need to do some preliminary analysis on the data. In the last two weeks of class you will give a short presentation of the data and your preliminary analysis. Papers are due after the semi-final period. My approval of your choice of dataset is required before you start the literature review.\nReadings\nSome sections of the course have readings (available on Canvas if not in the book or through the library). The lectures, homeworks and exams will draw from these readings. Lecture notes will be posted online at the end of each section.\nImportant dates\n\nTheory prelim: October 13\nEmpirical prelim: December 3\nFinal project paper due: December 16\nFinal project presentations: December 8, 10, 15\n\nOther things\nAttendance: Class attendance is not explicitly required but highly recommended.\nGrade appeals: If you wish to appeal your grade on a prelim or problem you must bring it to my attention, in writing, within 24 hours of when the prelim or problem set is returned.  Grades brought to my attention after this will not be eligible for a grade appeal. I reserve the right to regrade the entire assignment and the new grade will be final.\nGroup work: For problem sets, you may consult with me or Diego during office hours, or with other students. Problem sets can done in groups of up to 3. If you work in a group, turn in only one assignment for the group. You must complete prelims without help.\nIntegrity of credit: I expect every student in this course to abide by the Cornell University Code of Academic Integrity. I strongly encourage collaboration in this course, but each student is responsible for making sure that she or he follows the rules laid out in this syllabus, and with those stated in the Code of Academic Integrity. Any student found to have violated the stated policies on problem sets will receive a zero for that assignment, and any student found to have cheated on a prelim will receive a zero on that prelim. Multiple violations in a semester may result in failure of the course. The Code of Academic Integrity is available for review here: https:\/\/cuinfo.cornell.edu\/aic.cfm.\nCourse outline and readings\nSep 3: Micro and math recap [slides posted]\nReading: None\nSep 8: Theory of externalities [slides posted] \nReading: PR Chapter 1\nSep 10: Introduction to the theory of environmental policy [slides posted] \nReading: PR Chapter 3\nSep 15: Imperfect information [slides posted] \nReading: PR Chapter 4.1.1-4.1.2\nSep 17: Competitive output markets [slides posted] \nReading: PR Chapter 5\nSep 22: Non-competitive output markets [slides posted] \nReading: PR Chapter 6\nSep 24: Pre-existing distortions [slides posted] \nReading: PR Chapter 7\nSep 29: Theory of applied welfare economics [slides posted]\nReading: PR Chapter 14\nOct 1: Theory of applied welfare economics [slides posted]\nReading: PR Chapter 14\nOct 6: Revealed preference models [skipped]\nReading: PR Chapter 15\nOct 8: Hedonics [slides posted]\nReading: PR Chapter 18\nOct 13: Theory Prelim\nOct 15: R and the tidyverse, causal inference [slides posted]\nReading:\n\nMixtape: properties of regression, directed acyclical graphs, potential outcomes causal model\nGreenstone, M. and Gayer, T., 2009. Quasi-experimental and experimental approaches to environmental economics. Journal of Environmental Economics and Management, 57(1), pp.21-44.\n\nWe will be using RStudio Cloud for computing.\nOct 20: R and the tidyverse, causal inference, randomized control trials [slides posted] \nReading:\n\nMixtape: properties of regression, directed acyclical graphs, potential outcomes causal model\nGuiteras, Raymond, James Levinsohn, and Ahmed Mushfiq Mobarak. \"Encouraging sanitation investment in the developing world: a cluster-randomized trial.\" Science 348, no. 6237 (2015): 903-906.\n\nOct 22: Deforestation, remote sensing\/simple features, regression discontinuity [slides posted] \nReading:\n\nMixtape: regression discontinuity\nGeocomputation with R\nBurgess, R., Costa, F. and Olken, B.A., 2019. The Brazilian Amazon\u2019s Double Reversal of Fortune.\n\nOct 27: Hedonics [skipping for now]\nReading: Muehlenbachs, Lucija, Elisheba Spiller, and Christopher Timmins. \"The housing market impacts of shale gas development.\" American Economic Review 105, no. 12 (2015): 3633-59.\nOct 29: Environmental health, difference-in-differences, and event studies [slides posted] \nReading:\n\nMixtape: difference-in-differences\nHollingsworth A. and Rudik, I., 2021. The effect of leaded gasoline on elderly mortality: Evidence from regulatory exemptions. American Economic Journal: Economic Policy.\nGraff Zivin, J. and Neidell, M., 2013. Environment, health, and human capital. Journal of Economic Literature, 51(3), pp.689-730.\n\nNov 3: Environmental health, difference-in-differences, and event studies [slides posted] \nReading:\n\nMixtape: difference-in-differences\nHollingsworth A. and Rudik, I., 2021. The effect of leaded gasoline on elderly mortality: Evidence from regulatory exemptions. American Economic Journal: Economic Policy.\nGraff Zivin, J. and Neidell, M., 2013. Environment, health, and human capital. Journal of Economic Literature, 51(3), pp.689-730.\n\nNov 5: Climate change science [slides posted]\nReading:\n\nHsiang, S. and Robert Kopp. 2018. An economist's guide to climate change science, Journal of Economic Perspectives, Vol. 32, No. 4, pp. 3-32.\nHsiang, S., 2016. Climate econometrics. Annual Review of Resource Economics, 8, pp.43-75.\nGood resource on doing climate-econ research: ClimateEstimate.net\n\nNov 10: Climate change and the Ricardian model [slides posted]\nReading:\n\nMendelsohn, R., Nordhaus, W.D. and Shaw, D., 1994. The impact of global warming on agriculture: a Ricardian analysis. The American economic review, pp.753-771.\nOrtiz\u2010Bobea, A., 2020. The role of nonfarm influences in Ricardian estimates of climate change impacts on US agriculture. American Journal of Agricultural Economics, 102(3), pp.934-959.\n\nNov 12: Climate change and two way fixed effects, integrated assessment [slides posted]\nReading: Desch\u00eanes, O. and Greenstone, M., 2007. The economic impacts of climate change: evidence from agricultural output and random fluctuations in weather. American Economic Review, 97(1), pp.354-385.\nNov 17: Semi-final period\nNov 19: Semi-final period\nNov 24: Semi-final period\nNov 26: Thanksgiving break\nDec 1: Perverse incentives, clean air act, remote sensing\nReading:\n\nGeocomputation with R\nZou, E., 2021. Unwatched pollution: The effect of intermittent monitoring on air quality. American Economic Review.\n\nDec 3: Empirical prelim\nDec 8: Final project presentations\nDec 10: Final project presentations\nDec 15: Final project presentations\n","676":"SpotFire\nSpotfire is a crowd-sourcing tool that can support real-time detection and monitoring of wildfires; improving environmental safety to preserve it from wildfire risk.\nSpotfire, allows users to report wildfires with different means, and provides experts with the means to monitor them, gain insights, make predictions and give warnings to potential disasters.\nThis project was designed for the NASA Space Apps 2018 Challenge. For the 30 seconds pitch video and more details, please visit NASA Space Apps 2018 Challenge Page.\nOverview\n\n\nGetting Started\nProject Structure\nSPOFI\n\u251c\u2500\u2500 README.md #This File \n\u251c\u2500\u2500 requirements.txt # Python dependencies\n\u251c\u2500\u2500 app # Android app\n\u251c\u2500\u2500 core # Backend, main service and database handlers \n    \u251c\u2500\u2500 data # All the open-data\n    \u2514\u2500\u2500 server.py # server side (one-method interface to handel reports submissions)\n\u2514\u2500\u2500 templates\n\t\u251c\u2500\u2500 css\n\t\u251c\u2500\u2500 js\n\t\u2514\u2500\u2500  platform.html # frontpage\nInstallation\nDevelop on your own environment\nFirst, clone the project\n$ git clone --recursive -j8 https:\/\/github.com\/AhmedMaghawry\/SPOFI.git\nRequirments\n\nPython 3.x\nFirebase\nKeras\nTensorflow\nPandas\nNumpy\n\nInstall all the prerequisites listed in requirements.txt by:\n$ pip install -r requirements.txt\nAlso, check the README.md file in the core folder.\nContributers:\n\nAhmed Ezzat\nAhmed Rizk\nYoussef Ahmed\nYahia El-shahawy\n\n","677":"SpotFire\nSpotfire is a crowd-sourcing tool that can support real-time detection and monitoring of wildfires; improving environmental safety to preserve it from wildfire risk.\nSpotfire, allows users to report wildfires with different means, and provides experts with the means to monitor them, gain insights, make predictions and give warnings to potential disasters.\nThis project was designed for the NASA Space Apps 2018 Challenge. For the 30 seconds pitch video and more details, please visit NASA Space Apps 2018 Challenge Page.\nOverview\n\n\nGetting Started\nProject Structure\nSPOFI\n\u251c\u2500\u2500 README.md #This File \n\u251c\u2500\u2500 requirements.txt # Python dependencies\n\u251c\u2500\u2500 app # Android app\n\u251c\u2500\u2500 core # Backend, main service and database handlers \n    \u251c\u2500\u2500 data # All the open-data\n    \u2514\u2500\u2500 server.py # server side (one-method interface to handel reports submissions)\n\u2514\u2500\u2500 templates\n\t\u251c\u2500\u2500 css\n\t\u251c\u2500\u2500 js\n\t\u2514\u2500\u2500  platform.html # frontpage\nInstallation\nDevelop on your own environment\nFirst, clone the project\n$ git clone --recursive -j8 https:\/\/github.com\/AhmedMaghawry\/SPOFI.git\nRequirments\n\nPython 3.x\nFirebase\nKeras\nTensorflow\nPandas\nNumpy\n\nInstall all the prerequisites listed in requirements.txt by:\n$ pip install -r requirements.txt\nAlso, check the README.md file in the core folder.\nContributers:\n\nAhmed Ezzat\nAhmed Rizk\nYoussef Ahmed\nYahia El-shahawy\n\n","678":"newproject\nstrojka\nenvironmentallab\n","679":"newproject\nstrojka\nenvironmentallab\n","680":"newproject\nstrojka\nenvironmentallab\n","681":"Environmentalist\n[tree_hugging_gopher.jpg]\nUsage\nEnvironmentalist is an application that provides a consistent API for using a number of secrets management tools including:\n  * Hashicorp Vault\n  * AWS SSM\n  * Ansible Vault\n        etc...\n\nThe Server runs as both a RESTful service as well as a gRPC service so it should be usable for almost any situation.\n\nA RESTful request to access a secret looks something like this:\n  curl -X GET https:\/\/environmentalist:5005\/hashicorp-vault\/get\/mySharedSecret\n\nA RESTful request to store a new secret looks something like this:\n  curl -X POST -H \"Content-Type: application\/json\" -d '{\"mySharedSecret\": \"thisIsASuperSecretPassword\"}' https:\/\/environmentalist:5005\/hashicorp-vault\/new\/mySharedSecret\n\nA RESTful request to delete a secret looks something like this:\n  curl -X DELETE https:\/\/environmentalist:5005\/hashicorp-vault\/delete\/mySharedSecret\n\nA RESTful request to modify a secret looks something like this:\n  curl -X PUT -H \"Content-Type: application\/json\" -d '{\"mySharedSecret\": \"thisIsANewSuperSecretPassword\"}' https:\/\/environmentalist:5005\/hashicorp-vault\/update\/mySharedSecret\n\nPlease see https:\/\/github.com\/j4ng5y\/envrionmentalist for a full API breakdown.\n\nUsage:\n  environmentalist [flags]\n  environmentalist [command]\n\nAvailable Commands:\n  help        Help about any command\n  run         run the environmentalist daemon\n  stop        stop the envrionmentalist daemon\n\nFlags:\n  -s, --aws-ssm                            the aws-ssm flag tells envrionmentalist that we want to use aws ssm\n      --aws-ssm-access-key-id string       the aws-ssm-access-key-id flag tells envrionmentalist what Access Key to use to connect to AWS with\n      --aws-ssm-credential-type string     the aws-ssm-credential-type flag tells environmentalist what type of credentials to look for to access AWS. (Options:\"profile\", \"manual\", \"role\" (default \"profile\")\n      --aws-ssm-profile-name string        the aws-ssm-profile-name flag tells envrionmentalist what AWS profile to connect to AWS with (default \"Default\")\n      --aws-ssm-region string              the aws-ssm-region flag tells envrionmentalist what AWS region to connect to (default \"us-east-1\")\n      --aws-ssm-secret-access-key string   the aws-ssm-secret-access-key flag tells envrionmentalist what Secret Key to use to connect to AWS with\n  -v, --hashicorp-vault                    the hashicorp-vault flag tells environmentalist that we want to use the hashicorp vault\n      --hashicorp-vault-auth-type string   the hashicorp-vault-auth-type flag tells envrionmentalist what authentication type to use to log into the hashi-corp vault (default \"approle\")\n  -h, --help                               help for environmentalist\n      --version                            version for environmentalist\n\nUse \"environmentalist [command] --help\" for more information about a command.\n\n","682":"126025-Hackathon\nhttps:\/\/docs.google.com\/presentation\/d\/1JI2I1P-k3O6hL6JzyvtkS_CwexMdHA6uvZ8Yh0cljgQ\/edit#slide=id.g927fc7e3de_0_215\nJustin the Dustbin is a solar powered dustbin which is able to open and close with the simple swipe of a human hand and can accurately tell how much free space there is left in the dustbin. It is also equipped with UVC LEDs which helps it to sterilize the waste. Not only that, but also it is equipped with a smart lock that won\u2019t unlock if a person tries to open a full bin\n","683":"Environmentalist\nEnvironmentalist is a tool for working with .env files on a projects.\nWe often follow the convention of putting all the necessary ENV keys in a\n.sample.env file that is checked into version control. Along with this, we run\na setup script that usually copies over a .env file. This file is not checked\ninto version control. This allows us to make sure we do not store sensitive data\nin version control.\nThe problem with this setup comes along when a teammate adds a new key to the\n.sample.env file. We run into a situation where a person on the project may\nnot realize this has been added and ends up having to track the line down by\nhand and move it over. This is where environmentalist comes in!\nPrimary Function\nWhen you run the environmentalist command, with no options, environmentalist\nwill copy any keys from the .sample.env file in the current directory to the\n.env file.\nYou may also specify a file for the sample file as the first argument to the\ncommand and a second file as the file to use as your actual env file.\n","684":"Environmentalist\nEnvironmentalist is a tool for working with .env files on a projects.\nWe often follow the convention of putting all the necessary ENV keys in a\n.sample.env file that is checked into version control. Along with this, we run\na setup script that usually copies over a .env file. This file is not checked\ninto version control. This allows us to make sure we do not store sensitive data\nin version control.\nThe problem with this setup comes along when a teammate adds a new key to the\n.sample.env file. We run into a situation where a person on the project may\nnot realize this has been added and ends up having to track the line down by\nhand and move it over. This is where environmentalist comes in!\nPrimary Function\nWhen you run the environmentalist command, with no options, environmentalist\nwill copy any keys from the .sample.env file in the current directory to the\n.env file.\nYou may also specify a file for the sample file as the first argument to the\ncommand and a second file as the file to use as your actual env file.\n","685":"LiveObjects_SDK_MKR_EnvironmentalShield\n","686":"EnvironmentalSetup-itmo-544-444-fall2015\nEnvironmental Setup for itmo-544-444-fall2015\n","687":"Environmentality\n\nA code repository for the environmentality web application\nThe app will work on both mobile and desktop platforms and serve as a tool to educate the masses on the Chesapeake bay and the effect that people have had on it.  It will also contain an element of rewards based on activities that the user takes part in that helps the bay recover.\nVisit environmentality.org to see the current status of the project.\n","688":"environmentalist\nLoad an environment from a YAML file.\n","689":"environmentalawareness\n","690":"environmentalism\nThe H0LiCOW environments tell us about kappa_ext\n","691":"Environmentalicious\nQuite tasty. And looks decent on mobile as well.\nSynopsis\nEnvironmentalicious is a web application that allows users to locate environmental conservation and sustainability events in their community. These users can create their own account and register to attend events that they believe are interesting.\nThis is the very first release candidate of the application, and exhibits all main core functionalities. In the current state of the system, the user is able to create events, find events by their relative locations, and search for events based on criteria such as event name and event description tags. They may also join events and invite their friends to become event participants.\nInstallation\/Running\nIf you would like to view the application without installing a server on your local machine,\nyou may navigate to http:\/\/salsa.rit.edu:3000\/\n\nThis link may not always be available. Please follow the instructions to install on your local machine if you cannot access the deployed version.\n\nIn order to load the application locally, Node.js must be installed on the local system. The most recent version of Node.js (0.10.33 at the time of this writing) can be found at http:\/\/nodejs.org\/\nOnce a Node.js environment has been installed, open a command prompt or terminal and move to the root directory of the project. In order to install dependencies for the project, first type 'npm install'. Once this is completed, run the command 'node server.js' and navigate your browser to http:\/\/localhost:3000\nnpm install\nnode server.js\n\nApplication Usage\n\n\nCreating an event\n** Navigate to the 'create event' section in the left hand bar bar of the home screen after login.\n** Enter the desired event information and select the 'create event' button!\n\n\nFinding an already created event\n** Navigate to the 'find event' section in the left hand bar of the home screen after login.\n** Enter information such as the event name, event location, or a keyword which can be found in the description of an event you would like to attend!\n** Click the 'find event' button and locate a result in the left hand portion of the screen. You may click on any of these events to navigate to the main event section of that page.\n\n\nJoining an event\n** Once on the main page for the specific event you would like to join, click the 'join event' button at the bottom of the screen.\n** A pop up will notify you that you have successfully joined the event. When you return to the individual event page you will be able to see yourself as a participant in the event.\n\n\nInviting friends to an event\n** Provide valid line separated email addresses in the invite friends text box and click the 'invite friends' button.\n** An alert will notify you that your friends have been successfully invited to the event and they will recieve an email letting them know they have been marked as a potential participant.\n\n\nKnown Bug(s)\n\nThere is no user authentication or login functionality. Selecting the 'log in' button on the main about page will direct the user into the web application with a default account\n\nContributors\nDanielle Gonzalez\nJustin Peterson\nRichie Kapadia\nJoe Ksiazek\n","692":"Environmentalicious\nQuite tasty. And looks decent on mobile as well.\nSynopsis\nEnvironmentalicious is a web application that allows users to locate environmental conservation and sustainability events in their community. These users can create their own account and register to attend events that they believe are interesting.\nThis is the very first release candidate of the application, and exhibits all main core functionalities. In the current state of the system, the user is able to create events, find events by their relative locations, and search for events based on criteria such as event name and event description tags. They may also join events and invite their friends to become event participants.\nInstallation\/Running\nIf you would like to view the application without installing a server on your local machine,\nyou may navigate to http:\/\/salsa.rit.edu:3000\/\n\nThis link may not always be available. Please follow the instructions to install on your local machine if you cannot access the deployed version.\n\nIn order to load the application locally, Node.js must be installed on the local system. The most recent version of Node.js (0.10.33 at the time of this writing) can be found at http:\/\/nodejs.org\/\nOnce a Node.js environment has been installed, open a command prompt or terminal and move to the root directory of the project. In order to install dependencies for the project, first type 'npm install'. Once this is completed, run the command 'node server.js' and navigate your browser to http:\/\/localhost:3000\nnpm install\nnode server.js\n\nApplication Usage\n\n\nCreating an event\n** Navigate to the 'create event' section in the left hand bar bar of the home screen after login.\n** Enter the desired event information and select the 'create event' button!\n\n\nFinding an already created event\n** Navigate to the 'find event' section in the left hand bar of the home screen after login.\n** Enter information such as the event name, event location, or a keyword which can be found in the description of an event you would like to attend!\n** Click the 'find event' button and locate a result in the left hand portion of the screen. You may click on any of these events to navigate to the main event section of that page.\n\n\nJoining an event\n** Once on the main page for the specific event you would like to join, click the 'join event' button at the bottom of the screen.\n** A pop up will notify you that you have successfully joined the event. When you return to the individual event page you will be able to see yourself as a participant in the event.\n\n\nInviting friends to an event\n** Provide valid line separated email addresses in the invite friends text box and click the 'invite friends' button.\n** An alert will notify you that your friends have been successfully invited to the event and they will recieve an email letting them know they have been marked as a potential participant.\n\n\nKnown Bug(s)\n\nThere is no user authentication or login functionality. Selecting the 'log in' button on the main about page will direct the user into the web application with a default account\n\nContributors\nDanielle Gonzalez\nJustin Peterson\nRichie Kapadia\nJoe Ksiazek\n","693":"\nCREST - Classification Resources for Environmnetal Sequence Tags, is a collection of software and databases for taxonomic classification of environmental marker genes from sequencing-based community profiling studies (also known as \"meta-\" + \"-genomics\", \" -transcriptomics\", \"-barcoding\"; \"taxonomic-\" or \"phylogenetic-\" profiling)). The program LCAClassifier is used used for classification of sequences aligned to the reference databases provided.\nIf you use CREST or the LCAClassifier in your research, please cite:\nLanz\u00e9n A , J\u00f8rgensen SL, Huson D, Gorfer M, Grindhaug SH, Jonassen I, \u00d8vre\u00e5s L, Urich T (2012) CREST - Classification Resources for Environmental Sequence Tags, PLoS ONE 7:e49334\nClassification databases supported\nSilvaMod was derived by manual curation of the SILVA nr SSU Ref v128. It supports SSU sequences from bacteria and archaea (16S) as well as eukaryotes (18S), with a high level of manual curation and defined environmental clades. Release supported: Silva nr SSU Ref v128 (Sep 2016)\nGreengenes is an alternative reference database for classification of prokaryotic 16S, curated and maintained by The Greengenes Database Consortium. Release supported: May 2013\nUnite seeks to maintain the cleanest possible copy of all public fungal ITS sequences. Third-party sequence annotation is supported, and everyone with the expertise to improve the sequence data and their annotation\/metadata are welcome to participate in the annotation effort. Release supported: v7.2, 2017-10-10\namoA is a reference database for phylogenetic (not taxonomic) classification of ammonia monooxidase A (amoA) amplicons developed by Alves et al. (2018).\nBOLD Barcode of Life Datasystems (BOLD) is a community resource including a reference database for COI (Mitochondrial Cytochrome Oxidase I) metabarcoding and barcoding. The partial version available here is from 2018 and has been adapted and curated for CREST, including standardizing rank structure and taxon names using the NCBI Taxonomy.\nTo update your database files, new versions can be downloaded separately (wihtout the need to install a new version of CREST), from http:\/\/services.cbu.uib.no\/supplementary\/crest\nInstallation\nLCAClassifier uses pairwise alignments to a reference database of marker genes (such as SSU rRNA) as input. Alignment files must be in XML format and produced by the NCBI blastall suit. For best performance, we recommend the Megablast algorithm. Megablast is both implemented as a separate program in NCBI's legacy Blastall suite, that can be downloaded from ftp:\/\/ftp.ncbi.nlm.nih.gov\/blast\/executables\/release\/LATEST\/; or as part of the blastn program of the newer BLAST+ implementation, available at ftp:\/\/ftp.ncbi.nlm.nih.gov\/blast\/executables\/blast+\/LATEST\/. The later implementation is slightly faster.\nLCAClassifier also requires python (v.2.7 or higher), included as part of recent MacOSX and Linux distributions, as well as setuptools.\nInstallation procedure. It also requires Python-Dev.\nDownload the latest stable distribution and expand it using tar:\ntar -xvzf LCAClassifierV3.2.0.tar.gz\nOr download the development version:\ngit clone https:\/\/github.com\/lanzen\/CREST.git\nThen go to the LCAClassifier directory and run the script install.sh:\ncd LCAClassifier\n.\/install.sh\nThe script will take a while (up to 30 minutes) as several python packages as well as the CREST reference databases are downloaded automatially. It will also produce lots of output including warnings that you can safely ignore.\nThe executable file classifiy should then have been generated in the directory bin and is ready to use! To easily access it from anywhere in your file system, either add this directory to your PATH environment variable or create a symbolic link to it in a directory already in your path, for example $HOME\/bin:\nHow to use the LCAClassifier\nClassification algorithm\nTaxonomical classification starts with alignment to a reference sequence database (such as SilvaMod or Greengenes) using the NCBI Blast+ or legacy blastall implementation of Megablast. The LCAClassifier requires that output is saved in XML format. The classification is then carried out based on a subset of the best matching alignments using the Lowest Common Ancestor (LCA) of this subset. Briefly, the subset includes sequences that score within x% of the \u201cbit-score\u201d of the best alignment, providing the best score is above a minimum value. Default values for the minimum bit-score is 155 and for the LCA range (x) 2%. Based on cross-validation testing using the non-redundant SilvaMod database, this results in relatively few false positives for most datasets. However, the LCA range can be increased up to about 10% (using the -r option), to increase accuracy with short reads and for datasets with many novel sequences.\nIn addition to LCA classification, a minimum similarity filter is used, based on a set of taxon-specific requirements, by default depending on their taxonomic rank. By default, a sequence must be aligned with at least 99% nucleotide similarity to the best reference sequence in order to be classified to the species rank. For the genus, family, order, class and phylum ranks the respective default cut-offs are 97%, 95%, 90%, 85% and 80%. These cutoffs can be changed manually by editing the .map file of the respective reference database, or deactivated using option -f. This filter ensures that classification is made to the taxon of the lowest allowed rank, effectively re-assigning sequences to parent taxa until allowed.\nPreparing sequences\nFor amplicon sequences, we strongly recommend noise reduction using e.g AmpliconNoise for 454 Pyrosequencing data; vsearch, UPARSE, DADA2, SWARM or similar for Illumina MiSeq and other platforms; as well as chimera removal (using e.g. UCHIME) prior to submission.\n###Preparing an OTU table\nFor amplicon sequencing experiments with many replicates or similar samples (>~10), unique noise-reduced sequences may be further clustered using a similarity threshold (often 97% although larger thresholds are probably preferable) into Operational Taxonomic Units (OTUs), prior to classification. Alternatively, the unique sequence variants may be used as OTUs. The LCAClassifier can then use the distribution data of OTUs across datasets, in order to determine weighted relative abundance for each taxon across datasets, as well are OTU richness and a Chao-estimate of total richness.\nAn OTU table defines the distribution of an OTU across datasets and can be in delimeted text format or in BIOM-format (the later is default in QIIME and the former in many other applications). Make sure to divide datasets into combinations that \"make sense\", i.e. that you want to analyse together, before OTU clustering. For example, dividing data from a sequencing run of two separate experiements, or merging together data from two sequencing runs belonging to the same experiment. Also make sure sequence \/ OTU names in the OTU table correspond to those used in the FASTA file with representative sequences, to be aligned.\n###Using individual sequence datasets\nIn some cases, OTU clustering may not be possible, e.g. when classifying data from shotgun transcriptomic or metagenomic sequencing experiments. In this case, one BLAST output file must be prepared per dataset, instead of submitting an OTU table.\n###Aligning sequences using Megablast\nFirst download and install the NCBI blast+ from ftp:\/\/ftp.ncbi.nlm.nih.gov\/blast\/executables\/blast+\/LATEST\/. Then use the blastn program with the Silvamod or Greengenes reference databases that are installed automatically with the LCAClassifier. Other marker genes can also be used, but require that the construction of a custom database (see below).\nSilvamod and Greengenes are installed in the directory where LCAClassifier was installed, under parts\/flatdb.\nExample\nTo align the sequences of fasta file dataset1.fa to the Silvamod database, providing LCAClassifier was installed in the home directory, use, with blastn (BLAST+ sutie):\nblastn -task megablast -query dataset1.fa -db ~\/LCAClassifier\/parts\/flatdb\/silvamod\/silvamod.fasta -num_alignments 100 -outfmt 5 -out dataset1_silvamod.xml\nWe also recommend that you use -num_threads n to enable multi-threading and speed up the alignment. You can also use gzip to compress your blast output in order to conserve disk space since CREST supports gzipped input files.\n...or for the older legacy blast:\nmegablast -i dataset1.fa -d ~\/LCAClassifier\/parts\/flatdb\/silvamod\/silvamod.fasta -b100 -v100 -m7 -o dataset1_silvamod.xml\nAlignments will be written to the file dataset1_silvamod.xml.\nClassification\nThe executable for the LCAClassifier is called classify and uses a very simple command line interface:\nclassify [options] alignment-file(s).xml\nTo classify the alignment file dataset1_silvamod.xml using default parameters, simply use:\nclassify dataset1_silvamod.xml\nSilvamod is the default reference database. In case another database, e.g. UNITE was used, the -d option must be used to specify the database name:\nclassify -d unite dataset1_unite.xml\nLet\u2019s say that dataset1.fa contains representative OTU sequneces. Normally, we would be more interested in the taxonomic composition across each individual sample included in that dataset. The information of how OTUs are distributed will then be contained in an OTU-table, for example called dataset1_OTUs.csv. To incorporate this information, use:\nclassify -t dataset1_OTUs.csv dataset1_silvamod.xml\nIf the OTU table is instead in BIOM-format, we use the -b option:\nclassify -b dataset1_OTUs.biom dataset1_silvamod.xml\nIn both cases, a new OTU-table, in the same format and with the same name as given, will be written to the output directory, with taxonomic annotations added (for text-format as an extra column and for BIOM as observation metadata using the key taxonomy. We can also write annotated fasta-file, if the representative sequences are provided (option -i):\nclassify -i dataset1.fa -b dataset1_OTUs.biom dataset1_silvamod.xml\nTo specify output directory name, use option -o:\nclassify -o dataset1_CREST_Out -i dataset1.fa -b dataset1_OTUs.biom dataset1_silvamod.xml\nIf several datasets, not clustered into common OTUs, were aligned to the reference database, classification can be carried out for alignment XML file at a time, or simultaneously for several files. The advantage of the later option is that rows will always be inserted in the composition output files for all taxa that are present in at least one of the datasets, even if they are not present in all. For example, to classify dataset1_silvamod.xml.gz and dataset2_silvamod.xml.gz simultaneously, use:\nclassify dataset1_silvamod.xml.gz dataset2_silvamod.xml.gz\nNote that gzip-compressed alignment files can be used - practical for avoiding to use a lot of disk space!\nOutput\nThe output of LCAClassifier is written to the directory specified by option -o (by default CREST_Results. It produces at least two output files for each sample dataset classified. If an OTU-table is provided, the output files are named after sample names used in it. If not, they are named using the XML alignment files from which they were derived.\nSample-specific files\nFor example, for a (compressed) alignment file named Dataset.xml.gz and no specified OTU-table, LCAClassifier will write the following files:\nRelaitve_Abundaces.tsv provides relative abundance data across datasets normalised to the total number of assigned reads in each dataset. Option -m can be used to filter this output from the least abundant taxa. This is recommended particularly when datasets of different sequencing depths (total number of reads), will be compared.\nDataset_Composition.tsv contains the taxonomical composition of the dataset in tab-separated text format, designed for reading in a spreadsheet editor like Open Office (or Excel). Composition is given separately for each rank from domain to species, starting with a meta-level giving the total number of reads, classified and unclassfied reads. For each taxon, the total number of reads, its relative abundance, number of unique sequences and a chao estimate of total unique sequences is given. For each rank, the total number of reads assigned to that rank or better is also given.\nDataset_Tree.txt shows the taxonomical composition in a simple space-indented tree (in plaintext format), each taxon annotated with the number of reads.\nDataset_Assignments.fasta this file gives all taxonomically annotated sequences in FASTA format. In the FASTA header, the original sequence name is first given, then the predicted taxonomic assignment from the root of the taxonomic tree to the best rank at which classification was possible (separated by semicolons). If the Minimum similarity filter prevented assignment at a higher level for this sequence, indicating it to represent a novel taxa, the last taxon is prefixed with the word \"Unknown\".\nDataset_Assignments.tsv written by using option -p, this file lists all sequence names and their assignments in a simpe semicolon-separated format. If the Minimum similarity filter prevented assignment at a higher level for this sequence, indicating it to represent a novel taxa, the last taxon is prefixed with the word \"Unknown\".\nCommon \/ dataset-specific output files\nAll_Assignments.tsv provides counts of the number of assignments at each taxonomic rank for all datasets in a tab-separated format. Note that only assignments to the taxon node itself are counted, not to child taxa at lower ranks. For each taxon, the full taxonomic path from root to the taxon itself is also given. This file is more suitable for parsing than Dataset_Composition.txt.\nAll_Cumulative.tsv provides cumulative counts for the number of assignments at each taxonomic rank for all datasets in a tab-separated format. As opposed to All_Assignments.tsv, assignments to child taxa (lower ranks) are also counted. This file is more suitable for parsing than Dataset_Composition.txt.\nRichness.tsv provides number of unique OTUs for each taxon\n (if given) +\"_Assigned.fasta\" sequences with assignments added in FASTA header. Written with option -i\nOther options\n-a: BI-weights-file calculates biotic index using the submitted file specifying the index weights (e.g. microgAMBI for 16S)\n-h: shows a help message listing all options\n-r: LCA bitscore range in percent (given as an integer >0; default = 2)\n-s: Minimum bit-score for classification (integer >0; default = 155)\n-n: Normalise relative abundances to classified sequences only (ignoring unclassified)\n-f: De-activate the minimum similarity filter\n-i fasta-file: By default sequences in the taxonomically annotatated FASTA-output (_Assignments.fasta) are taken directly from the alignment XML file. This means that un-aligned sequence stretches or completely un-aligned sequences are ignored. This option instead uses the sequences from the supplied FASTA-file\n-q qual-file: This option works like -i, but instead accepts a file with Phred quality scores in fasta.qual format and outputs an annotated .qual file.\n-v: Use Verbose mode. Outputs information about interesting assignments to standard out.\n-c: Selects which configuration file to use (by default, the file parts\/etc\/lcaclassifier.conf in the LCAClassifier\u2019s installation directory is used)\nConstructing a custom reference database\nStarting from a reference alignment of a phylogenetic marker gene annotated with taxonomical information, the script nds2CREST.py can create a custom reference database for use with the LCAClassifier. We recommend using the program ARB to create and annotate such an alignment from a set of sequences.\nnds2CREST.py requires at least two different input files:\n\n\nSequences of the reference marker genes in the alignment, in FASTA format (sequences.fasta in the example below). It is important that the sequences are cropped so that stretches of unaligned sequence is not included. Such sequences may bias the alignments during classification. In ARB, this can be done by using a positional filter when exporting sequences.\n\n\nA tab-separated text file (in ARB language \"NDS file\") containing the taxonomic annotations of each aligned sequence (taxa.nds in the example below). This file must contain three columns separated by tabs. The first column is the accession number corresponding to the sequence file. The second contains the taxonomic structure with ranks separated by slash, semicolon or underscores (e.g. Domain;Phylum;Class). The third column contains the species or strain name or a unique description of the sequence. This file can be exported from ARB by first setting up NDS display correctly in the menu Tree > NDS (Node Display Setup). For SILVA, check the leaf box for \"acc\", then for group for \"tax_slv\" and for leaf for \"full name\". Then write the file using File > Export > Export fields using NDS. Make sure to tick the checkbox marked \"Use TABs for columns\"! Example: \"A16379 Bacteria\/Proteobacteria\/Gammaproteobacteria_1\/Pasteurellales_Pasteurellaceae\/Haemophilus Haemophilus ducreyi\"\n\n\nnds2CREST.py -o database-name -i sequences.fasta taxa.nds\nA file containing changes to the taxonomic tree for implementation during parsing can also be supplied (option -c) as well as a file containing rank information, in the same format as used by NCBI taxonomy (option -r.). For helo. use option -h.\nDatabase parsing may result in a list of warnings being written to standard.error if for example a sequence included sequences.fasta was not in the taxa.nds file or vice versa, or if duplicate names of taxa appeared in different topological context. In the former case, the sequence will be ignored. In the later, a parent suffix will be added to the sequence, for example \"Cryptococcus\", which is the name of an insect genus as well as a fungal one, will become \"Cryptococcus (Eriococcidae)\". The same happens if the same name is used for two different ranks, e.g. \"Bacteria;Actinobacteria;Actinobacteria\" will become \"Bacteria;Actinobacteria (phylum);Actinobacteria (class)\".\nAfter successful completion, nds2CREST will create three new files:\n\ndatabase-name.tre: the taxonomy of the reference database in http:\/\/en.wikipedia.org\/wiki\/Newick_format[Newick format], each taxon represented by a unique numeral identifier\ndatabase-name.map:  a mapping file, mapping the taxa identifiers to their full names and taxonomic rank\ndatabase-name.fasta: the reference database in FASTA-format (simply the same as sequences.fasta but with un-mapped sequences removed).\n\nThese files are needed by the LCAClassifier in order to make taxonomic assignments and the .tre and .map files for Silvamod can be found in \/LCAClassifier\/LCADir\/parts\/flatdb\/silvamod\/silvamod.map or silvamod.tre if LCAClassifier was installed in the $HOME directory (). To add your own custom database with the somewhat unimaginative name \"database-name\" as used in the examples above, create a new directory named \"database-name\" under the directory flatdb and copy these two files there:\nmkdir ~\/LCAClassifier\/LCADir\/parts\/flatdb\/database-name\ncp database-name.* ~\/LCAClassifier\/LCADir\/parts\/flatdb\/database-name\nYou also need to format the FASTA-file for Megablast (or BLAST) using the command formatdb (installed with the blastall suite):\ncd ~\/LCAClassifier\/LCADir\/parts\/flatdb\/database-name\nformatdb -i database-name.fasta -pF\nThe final change you need to do before using your own reference database is to tell the configuration file of the LCAClassifier where to find it. Edit the file ~\/LCAClassifier\/parts\/etc\/lcaclassifier.conf and add a new line. For example:\ndatabase-name = \/Home\/user\/LCAClassifier\/parts\/flatdb\/database-name\nNote that this will be overwritten if you update the LCAClassifier or re-build it. To make the change permanent, also add it in the file ~\/LCAClassifier\/etc\/lcaclassifier.conf.in\nAs you notice, you can keep your reference database anywhere you want in the file system, not necessarily in the LCAClassifier installation directory, as long as you make the correct changes in lcaclassifier.conf\nTo use your new reference database:\nmegablast -i env.fa -d ~\/LCAClassifier\/parts\/flatdb\/database-name\/database-name.fasta -b100 -v100 -m7 -o env_custom.xml\nclassifiy -d database-name env_custom.xml\n","694":"\nCREST - Classification Resources for Environmnetal Sequence Tags, is a collection of software and databases for taxonomic classification of environmental marker genes from sequencing-based community profiling studies (also known as \"meta-\" + \"-genomics\", \" -transcriptomics\", \"-barcoding\"; \"taxonomic-\" or \"phylogenetic-\" profiling)). The program LCAClassifier is used used for classification of sequences aligned to the reference databases provided.\nIf you use CREST or the LCAClassifier in your research, please cite:\nLanz\u00e9n A , J\u00f8rgensen SL, Huson D, Gorfer M, Grindhaug SH, Jonassen I, \u00d8vre\u00e5s L, Urich T (2012) CREST - Classification Resources for Environmental Sequence Tags, PLoS ONE 7:e49334\nClassification databases supported\nSilvaMod was derived by manual curation of the SILVA nr SSU Ref v128. It supports SSU sequences from bacteria and archaea (16S) as well as eukaryotes (18S), with a high level of manual curation and defined environmental clades. Release supported: Silva nr SSU Ref v128 (Sep 2016)\nGreengenes is an alternative reference database for classification of prokaryotic 16S, curated and maintained by The Greengenes Database Consortium. Release supported: May 2013\nUnite seeks to maintain the cleanest possible copy of all public fungal ITS sequences. Third-party sequence annotation is supported, and everyone with the expertise to improve the sequence data and their annotation\/metadata are welcome to participate in the annotation effort. Release supported: v7.2, 2017-10-10\namoA is a reference database for phylogenetic (not taxonomic) classification of ammonia monooxidase A (amoA) amplicons developed by Alves et al. (2018).\nBOLD Barcode of Life Datasystems (BOLD) is a community resource including a reference database for COI (Mitochondrial Cytochrome Oxidase I) metabarcoding and barcoding. The partial version available here is from 2018 and has been adapted and curated for CREST, including standardizing rank structure and taxon names using the NCBI Taxonomy.\nTo update your database files, new versions can be downloaded separately (wihtout the need to install a new version of CREST), from http:\/\/services.cbu.uib.no\/supplementary\/crest\nInstallation\nLCAClassifier uses pairwise alignments to a reference database of marker genes (such as SSU rRNA) as input. Alignment files must be in XML format and produced by the NCBI blastall suit. For best performance, we recommend the Megablast algorithm. Megablast is both implemented as a separate program in NCBI's legacy Blastall suite, that can be downloaded from ftp:\/\/ftp.ncbi.nlm.nih.gov\/blast\/executables\/release\/LATEST\/; or as part of the blastn program of the newer BLAST+ implementation, available at ftp:\/\/ftp.ncbi.nlm.nih.gov\/blast\/executables\/blast+\/LATEST\/. The later implementation is slightly faster.\nLCAClassifier also requires python (v.2.7 or higher), included as part of recent MacOSX and Linux distributions, as well as setuptools.\nInstallation procedure. It also requires Python-Dev.\nDownload the latest stable distribution and expand it using tar:\ntar -xvzf LCAClassifierV3.2.0.tar.gz\nOr download the development version:\ngit clone https:\/\/github.com\/lanzen\/CREST.git\nThen go to the LCAClassifier directory and run the script install.sh:\ncd LCAClassifier\n.\/install.sh\nThe script will take a while (up to 30 minutes) as several python packages as well as the CREST reference databases are downloaded automatially. It will also produce lots of output including warnings that you can safely ignore.\nThe executable file classifiy should then have been generated in the directory bin and is ready to use! To easily access it from anywhere in your file system, either add this directory to your PATH environment variable or create a symbolic link to it in a directory already in your path, for example $HOME\/bin:\nHow to use the LCAClassifier\nClassification algorithm\nTaxonomical classification starts with alignment to a reference sequence database (such as SilvaMod or Greengenes) using the NCBI Blast+ or legacy blastall implementation of Megablast. The LCAClassifier requires that output is saved in XML format. The classification is then carried out based on a subset of the best matching alignments using the Lowest Common Ancestor (LCA) of this subset. Briefly, the subset includes sequences that score within x% of the \u201cbit-score\u201d of the best alignment, providing the best score is above a minimum value. Default values for the minimum bit-score is 155 and for the LCA range (x) 2%. Based on cross-validation testing using the non-redundant SilvaMod database, this results in relatively few false positives for most datasets. However, the LCA range can be increased up to about 10% (using the -r option), to increase accuracy with short reads and for datasets with many novel sequences.\nIn addition to LCA classification, a minimum similarity filter is used, based on a set of taxon-specific requirements, by default depending on their taxonomic rank. By default, a sequence must be aligned with at least 99% nucleotide similarity to the best reference sequence in order to be classified to the species rank. For the genus, family, order, class and phylum ranks the respective default cut-offs are 97%, 95%, 90%, 85% and 80%. These cutoffs can be changed manually by editing the .map file of the respective reference database, or deactivated using option -f. This filter ensures that classification is made to the taxon of the lowest allowed rank, effectively re-assigning sequences to parent taxa until allowed.\nPreparing sequences\nFor amplicon sequences, we strongly recommend noise reduction using e.g AmpliconNoise for 454 Pyrosequencing data; vsearch, UPARSE, DADA2, SWARM or similar for Illumina MiSeq and other platforms; as well as chimera removal (using e.g. UCHIME) prior to submission.\n###Preparing an OTU table\nFor amplicon sequencing experiments with many replicates or similar samples (>~10), unique noise-reduced sequences may be further clustered using a similarity threshold (often 97% although larger thresholds are probably preferable) into Operational Taxonomic Units (OTUs), prior to classification. Alternatively, the unique sequence variants may be used as OTUs. The LCAClassifier can then use the distribution data of OTUs across datasets, in order to determine weighted relative abundance for each taxon across datasets, as well are OTU richness and a Chao-estimate of total richness.\nAn OTU table defines the distribution of an OTU across datasets and can be in delimeted text format or in BIOM-format (the later is default in QIIME and the former in many other applications). Make sure to divide datasets into combinations that \"make sense\", i.e. that you want to analyse together, before OTU clustering. For example, dividing data from a sequencing run of two separate experiements, or merging together data from two sequencing runs belonging to the same experiment. Also make sure sequence \/ OTU names in the OTU table correspond to those used in the FASTA file with representative sequences, to be aligned.\n###Using individual sequence datasets\nIn some cases, OTU clustering may not be possible, e.g. when classifying data from shotgun transcriptomic or metagenomic sequencing experiments. In this case, one BLAST output file must be prepared per dataset, instead of submitting an OTU table.\n###Aligning sequences using Megablast\nFirst download and install the NCBI blast+ from ftp:\/\/ftp.ncbi.nlm.nih.gov\/blast\/executables\/blast+\/LATEST\/. Then use the blastn program with the Silvamod or Greengenes reference databases that are installed automatically with the LCAClassifier. Other marker genes can also be used, but require that the construction of a custom database (see below).\nSilvamod and Greengenes are installed in the directory where LCAClassifier was installed, under parts\/flatdb.\nExample\nTo align the sequences of fasta file dataset1.fa to the Silvamod database, providing LCAClassifier was installed in the home directory, use, with blastn (BLAST+ sutie):\nblastn -task megablast -query dataset1.fa -db ~\/LCAClassifier\/parts\/flatdb\/silvamod\/silvamod.fasta -num_alignments 100 -outfmt 5 -out dataset1_silvamod.xml\nWe also recommend that you use -num_threads n to enable multi-threading and speed up the alignment. You can also use gzip to compress your blast output in order to conserve disk space since CREST supports gzipped input files.\n...or for the older legacy blast:\nmegablast -i dataset1.fa -d ~\/LCAClassifier\/parts\/flatdb\/silvamod\/silvamod.fasta -b100 -v100 -m7 -o dataset1_silvamod.xml\nAlignments will be written to the file dataset1_silvamod.xml.\nClassification\nThe executable for the LCAClassifier is called classify and uses a very simple command line interface:\nclassify [options] alignment-file(s).xml\nTo classify the alignment file dataset1_silvamod.xml using default parameters, simply use:\nclassify dataset1_silvamod.xml\nSilvamod is the default reference database. In case another database, e.g. UNITE was used, the -d option must be used to specify the database name:\nclassify -d unite dataset1_unite.xml\nLet\u2019s say that dataset1.fa contains representative OTU sequneces. Normally, we would be more interested in the taxonomic composition across each individual sample included in that dataset. The information of how OTUs are distributed will then be contained in an OTU-table, for example called dataset1_OTUs.csv. To incorporate this information, use:\nclassify -t dataset1_OTUs.csv dataset1_silvamod.xml\nIf the OTU table is instead in BIOM-format, we use the -b option:\nclassify -b dataset1_OTUs.biom dataset1_silvamod.xml\nIn both cases, a new OTU-table, in the same format and with the same name as given, will be written to the output directory, with taxonomic annotations added (for text-format as an extra column and for BIOM as observation metadata using the key taxonomy. We can also write annotated fasta-file, if the representative sequences are provided (option -i):\nclassify -i dataset1.fa -b dataset1_OTUs.biom dataset1_silvamod.xml\nTo specify output directory name, use option -o:\nclassify -o dataset1_CREST_Out -i dataset1.fa -b dataset1_OTUs.biom dataset1_silvamod.xml\nIf several datasets, not clustered into common OTUs, were aligned to the reference database, classification can be carried out for alignment XML file at a time, or simultaneously for several files. The advantage of the later option is that rows will always be inserted in the composition output files for all taxa that are present in at least one of the datasets, even if they are not present in all. For example, to classify dataset1_silvamod.xml.gz and dataset2_silvamod.xml.gz simultaneously, use:\nclassify dataset1_silvamod.xml.gz dataset2_silvamod.xml.gz\nNote that gzip-compressed alignment files can be used - practical for avoiding to use a lot of disk space!\nOutput\nThe output of LCAClassifier is written to the directory specified by option -o (by default CREST_Results. It produces at least two output files for each sample dataset classified. If an OTU-table is provided, the output files are named after sample names used in it. If not, they are named using the XML alignment files from which they were derived.\nSample-specific files\nFor example, for a (compressed) alignment file named Dataset.xml.gz and no specified OTU-table, LCAClassifier will write the following files:\nRelaitve_Abundaces.tsv provides relative abundance data across datasets normalised to the total number of assigned reads in each dataset. Option -m can be used to filter this output from the least abundant taxa. This is recommended particularly when datasets of different sequencing depths (total number of reads), will be compared.\nDataset_Composition.tsv contains the taxonomical composition of the dataset in tab-separated text format, designed for reading in a spreadsheet editor like Open Office (or Excel). Composition is given separately for each rank from domain to species, starting with a meta-level giving the total number of reads, classified and unclassfied reads. For each taxon, the total number of reads, its relative abundance, number of unique sequences and a chao estimate of total unique sequences is given. For each rank, the total number of reads assigned to that rank or better is also given.\nDataset_Tree.txt shows the taxonomical composition in a simple space-indented tree (in plaintext format), each taxon annotated with the number of reads.\nDataset_Assignments.fasta this file gives all taxonomically annotated sequences in FASTA format. In the FASTA header, the original sequence name is first given, then the predicted taxonomic assignment from the root of the taxonomic tree to the best rank at which classification was possible (separated by semicolons). If the Minimum similarity filter prevented assignment at a higher level for this sequence, indicating it to represent a novel taxa, the last taxon is prefixed with the word \"Unknown\".\nDataset_Assignments.tsv written by using option -p, this file lists all sequence names and their assignments in a simpe semicolon-separated format. If the Minimum similarity filter prevented assignment at a higher level for this sequence, indicating it to represent a novel taxa, the last taxon is prefixed with the word \"Unknown\".\nCommon \/ dataset-specific output files\nAll_Assignments.tsv provides counts of the number of assignments at each taxonomic rank for all datasets in a tab-separated format. Note that only assignments to the taxon node itself are counted, not to child taxa at lower ranks. For each taxon, the full taxonomic path from root to the taxon itself is also given. This file is more suitable for parsing than Dataset_Composition.txt.\nAll_Cumulative.tsv provides cumulative counts for the number of assignments at each taxonomic rank for all datasets in a tab-separated format. As opposed to All_Assignments.tsv, assignments to child taxa (lower ranks) are also counted. This file is more suitable for parsing than Dataset_Composition.txt.\nRichness.tsv provides number of unique OTUs for each taxon\n (if given) +\"_Assigned.fasta\" sequences with assignments added in FASTA header. Written with option -i\nOther options\n-a: BI-weights-file calculates biotic index using the submitted file specifying the index weights (e.g. microgAMBI for 16S)\n-h: shows a help message listing all options\n-r: LCA bitscore range in percent (given as an integer >0; default = 2)\n-s: Minimum bit-score for classification (integer >0; default = 155)\n-n: Normalise relative abundances to classified sequences only (ignoring unclassified)\n-f: De-activate the minimum similarity filter\n-i fasta-file: By default sequences in the taxonomically annotatated FASTA-output (_Assignments.fasta) are taken directly from the alignment XML file. This means that un-aligned sequence stretches or completely un-aligned sequences are ignored. This option instead uses the sequences from the supplied FASTA-file\n-q qual-file: This option works like -i, but instead accepts a file with Phred quality scores in fasta.qual format and outputs an annotated .qual file.\n-v: Use Verbose mode. Outputs information about interesting assignments to standard out.\n-c: Selects which configuration file to use (by default, the file parts\/etc\/lcaclassifier.conf in the LCAClassifier\u2019s installation directory is used)\nConstructing a custom reference database\nStarting from a reference alignment of a phylogenetic marker gene annotated with taxonomical information, the script nds2CREST.py can create a custom reference database for use with the LCAClassifier. We recommend using the program ARB to create and annotate such an alignment from a set of sequences.\nnds2CREST.py requires at least two different input files:\n\n\nSequences of the reference marker genes in the alignment, in FASTA format (sequences.fasta in the example below). It is important that the sequences are cropped so that stretches of unaligned sequence is not included. Such sequences may bias the alignments during classification. In ARB, this can be done by using a positional filter when exporting sequences.\n\n\nA tab-separated text file (in ARB language \"NDS file\") containing the taxonomic annotations of each aligned sequence (taxa.nds in the example below). This file must contain three columns separated by tabs. The first column is the accession number corresponding to the sequence file. The second contains the taxonomic structure with ranks separated by slash, semicolon or underscores (e.g. Domain;Phylum;Class). The third column contains the species or strain name or a unique description of the sequence. This file can be exported from ARB by first setting up NDS display correctly in the menu Tree > NDS (Node Display Setup). For SILVA, check the leaf box for \"acc\", then for group for \"tax_slv\" and for leaf for \"full name\". Then write the file using File > Export > Export fields using NDS. Make sure to tick the checkbox marked \"Use TABs for columns\"! Example: \"A16379 Bacteria\/Proteobacteria\/Gammaproteobacteria_1\/Pasteurellales_Pasteurellaceae\/Haemophilus Haemophilus ducreyi\"\n\n\nnds2CREST.py -o database-name -i sequences.fasta taxa.nds\nA file containing changes to the taxonomic tree for implementation during parsing can also be supplied (option -c) as well as a file containing rank information, in the same format as used by NCBI taxonomy (option -r.). For helo. use option -h.\nDatabase parsing may result in a list of warnings being written to standard.error if for example a sequence included sequences.fasta was not in the taxa.nds file or vice versa, or if duplicate names of taxa appeared in different topological context. In the former case, the sequence will be ignored. In the later, a parent suffix will be added to the sequence, for example \"Cryptococcus\", which is the name of an insect genus as well as a fungal one, will become \"Cryptococcus (Eriococcidae)\". The same happens if the same name is used for two different ranks, e.g. \"Bacteria;Actinobacteria;Actinobacteria\" will become \"Bacteria;Actinobacteria (phylum);Actinobacteria (class)\".\nAfter successful completion, nds2CREST will create three new files:\n\ndatabase-name.tre: the taxonomy of the reference database in http:\/\/en.wikipedia.org\/wiki\/Newick_format[Newick format], each taxon represented by a unique numeral identifier\ndatabase-name.map:  a mapping file, mapping the taxa identifiers to their full names and taxonomic rank\ndatabase-name.fasta: the reference database in FASTA-format (simply the same as sequences.fasta but with un-mapped sequences removed).\n\nThese files are needed by the LCAClassifier in order to make taxonomic assignments and the .tre and .map files for Silvamod can be found in \/LCAClassifier\/LCADir\/parts\/flatdb\/silvamod\/silvamod.map or silvamod.tre if LCAClassifier was installed in the $HOME directory (). To add your own custom database with the somewhat unimaginative name \"database-name\" as used in the examples above, create a new directory named \"database-name\" under the directory flatdb and copy these two files there:\nmkdir ~\/LCAClassifier\/LCADir\/parts\/flatdb\/database-name\ncp database-name.* ~\/LCAClassifier\/LCADir\/parts\/flatdb\/database-name\nYou also need to format the FASTA-file for Megablast (or BLAST) using the command formatdb (installed with the blastall suite):\ncd ~\/LCAClassifier\/LCADir\/parts\/flatdb\/database-name\nformatdb -i database-name.fasta -pF\nThe final change you need to do before using your own reference database is to tell the configuration file of the LCAClassifier where to find it. Edit the file ~\/LCAClassifier\/parts\/etc\/lcaclassifier.conf and add a new line. For example:\ndatabase-name = \/Home\/user\/LCAClassifier\/parts\/flatdb\/database-name\nNote that this will be overwritten if you update the LCAClassifier or re-build it. To make the change permanent, also add it in the file ~\/LCAClassifier\/etc\/lcaclassifier.conf.in\nAs you notice, you can keep your reference database anywhere you want in the file system, not necessarily in the LCAClassifier installation directory, as long as you make the correct changes in lcaclassifier.conf\nTo use your new reference database:\nmegablast -i env.fa -d ~\/LCAClassifier\/parts\/flatdb\/database-name\/database-name.fasta -b100 -v100 -m7 -o env_custom.xml\nclassifiy -d database-name env_custom.xml\n","695":"Environmentalist\nProtect your environment! On teams, sometimes you need to lock down an environment while you work. Environmentalist allows you keep others from trashing it.\n","696":"Environmentalist\nProtect your environment! On teams, sometimes you need to lock down an environment while you work. Environmentalist allows you keep others from trashing it.\n","697":"Earth Genome: Environmental Data for Decision Making\n\nBy Dan Hammer, Chief Data Scientist, Earth Genome and Jeff Chen, Chief Data Scientist, US Department of Commerce.\nAs part of the Commerce Data Usability Project, Earth Genome in collaboration with the Commerce Data Service has created a tutorial that will guide you though processing and visualizating digital elevation model data. If you have question, feel free to reach out to the Commerce Data Service at data@doc.gov or Earth Genome at dan@earthgenome.org.\n","698":"my-app\nProject setup\nnpm install\n\nCompiles and hot-reloads for development\nnpm run serve\n\nCompiles and minifies for production\nnpm run build\n\nLints and fixes files\nnpm run lint\n\nCustomize configuration\nSee Configuration Reference.\n","699":"Environmentalists\n","700":"environmentalissues\n","701":"environmentalthing\n","702":"Environmentalist\nEnvironmentalist is a simple tool to generate configuration files based on a template.\nUsage\nThe tool takes one parameter with a configuration file:\nEnvironmentalist.exe configfile.conf\nConfiguration\nThe configuration consists of several files.\nconfigfile.conf\nThis file describes input and output.\ntemplatePath=template.env\nresultPath=result.env\nprofilePath=profile1.txt\nsecureVaultPath=secrets.kdbx\nsecureVaultPass=[EnvVar](SecureVaultPass)\n\ntemplatePath is a path to a template which is taken as a source of output file.\nresultPath is a path to an output file. This file will be created based on the template and configuration.\nprofilePath is a path to a profile file. The profile file describes how to fill templates with values.\nsecureVaultPath is a path to a KeePass database file.\nsecureVaultPass is password to a KeePass database file.\nThe tool supports reading environment variables. [EnvVar](SecureVaultPass) means that during parsing configuration value of environment variable SecureVaultPass will be used in this place.\ntemplate\nThe file is a source for the output file.\nTemplate must be in form of Key=Value, where Key and Valueare any valid strings. The Values will be replaced by specific values from config file.\nValue can be also already fill with a real value or be path to secret.\nE.g.:\nKEY0=[KeePass](test_entry)\nKEY1=VALUE1\nKEY2=VALUE2\nKEY3=VALUE3\nKEY4=VALUE4\n\n[KeePass](test_entry) means that output file will be filled with a password from KeePass for entry test_entry. Valid formulas are title of entry or username in entry.\nprofile\nThe file has the same structure as template.\nValues from this file are copied to template file and evaluated.\nE.g.:\nVALUE2=[KeePass](test_user)\nVALUE4=[KeePass](test_entry)\nVALUE3=some_value\n\nPlaceholders like VALUE2 must have corresponding placeholder in the template file. If there are values in the template file which have no corresponding entries in the config file then will be left as they are.\n","703":"Environmentalism\n\n\n\nSimple package that loads variables from your DotEnv files.\nRequirements\n\nMacOS or Linux\nSwift 4+\n\nInstallation\nYou can grab this package through Swift Package Manager:\nimport PackageDescription\n\nlet package = Package(\n    name: \"Example\",\n    products: [\n      .executable(name: \"Example\", targets: [\"Example\"])\n    ],\n    dependencies: [\n      .package(url: \"https:\/\/github.com\/fborges\/Environmentalism\", from: \"1.0.0\")\n    ],\n    targets: [\n        .target(\n            name: \"Example\",\n            dependencies: [\"Environmentalism\"]),\n    ]\n)\n\nUsage\nThis package has basically One struct that brings up the stuff for you:\nimport Environmentalism\n\n\/\/ Load environment variables from file at specified URL\nlet env = try! Environment(url: url)\n\n\/\/ Supports subscripting\nlet victories = env[\"BRAZIL_WORLD_CHAMPION\"] -> \"5\"\n\n\/\/ Push all key-value pairs into actual environment variables\nenv.commit()\nFurther improvements\nSee Issues.\nLicense\nMIT License\n","704":"environmentalissues\n","705":"\nThis repo is deprecated and is to be replaced by PicorderOS (https:\/\/github.com\/directive0\/picorderOS)\nThe TR-108 Picorder\nThis repo is a set of python components that together provide functionality for the TR-108 Tricorder I am building, as well as necessary files for anyone to build their own should they so desire. The TR-108 is a Raspberry Pi Zero based system that includes a sensor package, battery, display and supplemental components to provide a satisfying and accurate Tricorder experience. In the interest of inspiring others to build on what I have done I am providing all of the documentation I can.\nNotes:\nBasic functionality is complete; the program logs values from the sense hat and displays them. I have become to optimize this code.\nI am hoping to add:\n\nGraph auto ranging\nStandardize sensor value retrieval\nOrganize and modularize code for easier feature additions.\n\nRequirements:\nPicorder.py uses a number of modules to operate, specifically:\n\nPygame\nSenshat\nRPi.GPIO\nsys\ntime\nmath\nos\npsutil (PC Demo only)\n\nBe sure you have these modules installed before attempting to run this program.\nConstruction:\nYou can find all the necessary construction documents in the \"construction\" folder.\nAdafruit parts Wishlist is here:\nhttp:\/\/www.adafruit.com\/wishlists\/435166\nThe base I used for the tricorder:\nhttps:\/\/www.amazon.ca\/gp\/product\/B001820194\/ref=ox_sc_sfl_title_6?ie=UTF8&psc=1&smid=A3DWYIK6Y9EEQB\nSources\nThis project was made possible by information and inspiration provided by these sources:\n\nhttps:\/\/hackaday.io\/project\/5437-star-trek-tos-picorder\nhttps:\/\/github.com\/tobykurien\/rpi_lcars\n\n","706":"Environmental Animation Course Repository\nA repository of resources and precedents for creating animations of environments. The primary repository for the students of the Environmental Animation class at the University of Pennsylvania PennDesign School.\nInstructor: Chris Landau\nSchool: University of Pennsylvania Stuart Weitzman School of Design\n","707":"Environmental Animation Course Repository\nA repository of resources and precedents for creating animations of environments. The primary repository for the students of the Environmental Animation class at the University of Pennsylvania PennDesign School.\nInstructor: Chris Landau\nSchool: University of Pennsylvania Stuart Weitzman School of Design\n","708":"Environmentalist \nDead-simple setup for Laravel apps. Environmentalist is a collection of handy tools for making setup scripts with Artisan. Easily create an environment file, prompt the user for values (with smart defaults & autocomplete), and run commands - all without needing to write out or follow lengthy directions.\nUsage\nDocumentation coming soon!\nLicense\nMIT \u00a9 David Furnes\n","709":"compute-hdc: Highest density contour method in Matlab\n\nA software to compute a highest density environmental contour.\nA highest density (HD) contour is one possible definition for an environmental\ncontour. This definition has been proposed by Haselsteiner, Ohlendorf,\nWosniok and Thoben (2017; http:\/\/doi.org\/10.1016\/j.coastaleng.2017.03.002)\nDownload and use the repository\nTo download this repository and its submodules use\ngit clone --recurse-submodules https:\/\/github.com\/ahaselsteiner\/compute-hdc.git\nIndividual files and functionality\nThis software involves a couple of .m files for computing a HD contour:\n\ncomputeHdc: Computes the contour. It needs a probabilistic model,\nan exceedance probability and a grid as its input.\ncomputeHdcExampleWithCMA: Cotains examples how to use computeHdc.\ngetProbabilisticModel: Returns some sample probabilistic models,\nwhich can be used with computeHdc.\nThe other functions are subroutines needed for computeHdc.\n\nThe software also includes implementations of other environmental contour\nmethods, which use different definitions for the exceedance probablity\nof an environmental contour:\n\ncomputeIFormContour: Computes an inverse first order reliablity method\n(IFORM) contour.\ncomputeDsContour: Computes a direct sampling contour.\ncomputeISormContour: Computes an inverse second order reliablity method\n(ISORM) contour.\n\nCite as\nIf you are using this software in your academic work please cite it as\nA.F. Haselsteiner (2020): compute-hdc: Highest density contour method in\nMatlab (version 1.2.3; https:\/\/github.com\/ahaselsteiner\/compute-hdc).\n","710":"PhenoPath\nPhenoPath learns genomic trajectories (pseudotimes) in the presence of heterogenous environmental and genetic backgrounds encoded as additional covariates and identifies interactions between the trajectories and covariates. Scalable variational Bayesian inference allows the trajectory and interactions to be inferred for thousands of samples and genes quickly.\n\nTo quickly get started, see either of the vignettes:\n\nIntroduction to PhenoPath\nEnd-to-end example on Shalek et al. (2014) from raw data to stimulant-pseudotime interactions\n\nInstallation\ninstall.packages(\"devtools\") # If not already installed\ndevtools::install_github(\"kieranrcampbell\/phenopath\", build_vignettes = TRUE)\nOverview\nPhenoPath models the observed expression y in terms of a latent pathway score (pseudotime) z. Uniquely, the evolution of genes along the trajectory isn't common to each gene but can be perturbed by an additional sample-specific covariate. For example, this could be the mutational status of each sample or a drug that each sample was exposed to.\n\nInference\nInference is performed using co-ordinate ascent variational inference (CAVI) implemented using the Rcpp library for increased performance. This minimises the KL-divergence between a set of approximating distributions and the true posterior by making a full-factorized mean-field approximation.\nGetting started\nSee the vignette for details.\nAuthors\nKieran R Campbell & Christopher Yau\n","711":"About AutoTax\n[][hub]\nAutoTax is a linux BASH script that automatically generates de novo taxonomy from full length 16S rRNA amplicon sequence variants (FL-ASVs). This allows generation of eco-system specific de novo taxonomic databases based on any environmental sample(s). It does so by combining several different software tools, listed below, into a single BASH script that otherwise only requires a single FASTA file as input. For a more detailed description of AutoTax, please refer to the paper Dueholm et al, 2020. AutoTax has only been tested on Ubuntu 18.04 LTS, but will probably run just fine on other Linux distributions as long as the required software listed below is installed.\nTable of Contents\n\nAbout AutoTax\nTable of Contents\nWhat the script does\nInstallation and requirements\n\nSoftware\nDatabase files\n\n\nUsage\nRunning AutoTax from a docker container (recommended)\n\nImportant notes when running through docker container\n\n\nUnit tests\nGenerating input full-length 16S sequences\nSee also\nNotes\n\nCreated by gh-md-toc\nWhat the script does\nIn brief, the script performs the following steps:\n\nCheck user input, files and folders, and check for installed R packages, installing missing ones\n\nGenerate\/identify FL-ASVs\n\nOrient the sequences based on the SILVA taxonomic database (usearch)\nDereplicate the input sequences (both strands), and determine the coverage of each unique sequence (usearch)\nDenoise the dereplicated sequences using UNOISE3, with minsize = 2 (usearch)\nRemove all sequences that match exactly (100% identity) with other, but longer sequences (R)\nSort the sequences based on coverage, and rename the sequences in order of occurence, in the format FLASVx.length, e.g. FLASV123.1410 (R)\nIf desired, update an existing FL-ASV database (FASTA file) by matching the generated FL-ASVs to the database, replacing identical FL-ASVs with longer sequences if any, and adding the new ones to the end of the FASTA file, renamed to continue numbering from the database (R)\n\nGenerate de novo taxonomy\n\nPerform a multiple sequence alignment of the FL-ASVs with both the SILVA and SILVA typestrains databases using SINA, then trim, strip gaps, format, and sort based on FL-ASV IDs (multithreading doesn't always preserve ordering) (SINA+awk+R)\nAssign taxonomy to that of the best hit in both the SILVA and SILVA typestrains databases (usearch)\nCluster the FL-ASVs at different identity thresholds each corresponding to a taxonomic level and use the FL-ASV ID of the cluster centroids as a de novo placeholder name at each level (usearch, thresholds from Yarza et al, 2014)\nReformat the output from the last 2 steps into 3 separate tables where each column contains the taxonomy at each taxonomic level (Kingdom->Species) of each FL-ASV (R)\nMerge the 3 tables so that the de novo taxonomy fills in where the assigned taxonomy based on SILVA and SILVA typestrains are below the taxonomic thresholds (R)\nManually curate the taxonomy based on a replacement file if any (R)\n\nOutput the taxonomy in the following formats:\n\nFL-ASVs in FASTA format with usearch SINTAX formatted taxonomy in the headers (R)\nQIIME formatted table (R)\nCSV files of the individual tables mentioned earlier as well as the combined, complete taxonomy for each FL-ASV (R)\n\nInstallation and requirements\nAs AutoTax is simply a BASH script that wraps and combines other software tools and their outputs, so there is no installation to do for the AutoTax script itself. Simply download the autotax.bash script by either:\nwget https:\/\/raw.githubusercontent.com\/KasperSkytte\/AutoTax\/master\/autotax.bash\n\nor clone the github repository by (make sure git is installed):\ngit clone https:\/\/github.com\/KasperSkytte\/AutoTax.git\ncd AutoTax\n\nOther than the standard linux tools awk, grep, and cat (which is included in most Linux distributions), AutoTax depends on a few other software tools, however, which need to be installed and be available in the PATH variable. The tools can be installed manually by refering to the documentation of the individual tools. It is recommended to run AutoTax through the docker container image based on Ubuntu linux 18.04, however, with everything pre-installed and tested (except database files), see this section.\nSoftware\n\nGNU parallel (version 20161222)\nusearch (version 10 or later)\nSINA (version 1.6 or later)\nR (version 3.5 or later) with the following packages installed (the script will attempt to install if missing):\n\nBiostrings (from Bioconductor, be ready for trouble if you dont have administrative rights, try manually if it fails)\ndoParallel\nstringr (and stringi)\ndata.table\ntidyr\ndplyr\n\n\n\nDatabase files\nOther than these software tools, SILVA and SILVA typestrains database files in both UDB and ARB format are needed. A zip file of all 4 files can be found on figshare here (both SILVA release 132 and 138). Make sure the paths to these files are set correctly in the autotax.bash script. You can also use other databases, but the script is made to handle the finicky details of SILVA particularly. If you want to use other databases, you will need to adjust the script.\nFor SILVA version 138 this can be done from a shell by the following commands:\nwget https:\/\/ndownloader.figshare.com\/files\/22790396 -O SILVA138_NR99.zip\nunzip SILVA138_NR99.zip -d refdatabases\/\n\nUsage\nAdjust the variables in the SETUP chunk at the start of the autotax.bash script to match the paths to the database files and executables. If you downloaded SILVA138 using the link above, you don't have to adjust anything if you create a folder named refdatabases and extract all the files into the folder. Make sure the script is executable with chmod +x autotax.bash.\nType bash autotax.bash -h to show available options and version:\n$ bash autotax.bash -h\nPipeline for extracting Full-length 16S rRNA Amplicon Sequence Variants (FL-ASVs) from full length 16S rRNA gene DNA sequences and generating de novo taxonomy\nVersion: 1.5.4\nOptions:\n  -h    Display this help text and exit.\n  -i    Input FASTA file with full length DNA sequences to process (required).\n  -c    Cluster the resulting FL-ASVs at 99% (before generating de novo taxonomy),\n          do chimera filtering on the clusters, and then add them on top in the same way as when using -d.\n  -d    FASTA file with previously processed FL-ASV sequences.\n          FL-ASVs generated from the input sequences will then be appended to this and de novo taxonomy is rerun.\n  -t    Maximum number of threads to use. Default is all available cores except 2.\n  -b    Run all BATS unit tests to assure everything is working as intended (requires git).\n  -v    Print version and exit.\n\nUsing the example data in \/test\/example_data\/ a usage example would be:\nbash autotax.bash -i test\/example_data\/10k_fSSUs.fa -t 20.\nThe main output files can then be found in the output\/ folder and all intermediate files along the way in temp\/.\nRunning AutoTax from a docker container (recommended)\nTo run AutoTax through a docker container first install Docker Engine - Community as described there. A prebuilt image autotax based on Ubuntu Linux 18.04 can then be retrieved from Docker Hub with all the required software and dependencies preinstalled (exact versions that are tested and guaranteed to work as intended):\nsudo docker pull kasperskytte\/autotax:latest\n\nAlternatively build the image manually by downloading the Dockerfile directly from the github repository (may take 10-20 minutes):\ngit clone https:\/\/github.com\/KasperSkytte\/AutoTax.git\ncd AutoTax\nsudo docker build -t kasperskytte\/autotax:latest docker\/\n\nThe image also contains the autotax github repository itself (most recent from master branch) in \/opt\/autotax\/. Now run AutoTax with the current working directory mounted inside the container as \/autotax:\nsudo docker run -it --rm --name autotax -v ${PWD}:\/autotax kasperskytte\/autotax:latest -h\n\nImportant notes when running through docker container\nAs usearch is non-free software it is not included in the image. You must buy it or use the free 32-bit version (limited to 4GB memory and is doubtfully going to be sufficient, but you are welcome to try) and place the executable in the same folder that is mounted inside the container and name it usearch11. Please respect the usearch software license.\nBy default the autotax.bash script included in the image is executed, which assumes you have extracted the SILVA138 database (most recent as of the time of writing) into a folder named refdatabases in the current working directory as described in Database files. If you wish to use a different version you need to adjust the paths in the script itself, hence you must also copy the autotax.bash script into the current working folder, adjust the paths, and run that instead of that included in the image.\nWhen running through the docker container all paths must relative to the working directory. Absolute paths (i.e. starts with \/) won't work as the container file system is separate from the host file system. Furthermore, the output folders temp and output will be owned by root, so it's a good idea to change ownership afterwards with fx:\nsudo chown -R $(id -u ${USER}):$(id -g ${USER}) temp\/ output\/\n\nUnit tests\nAutoTax is being unit tested by the Bash Automated Testing System. To run the tests, preferably before running with your own data, you can do so with the autotax.bash -b argument. This requires you to run from the root of a clone of the AutoTax git repository as several additional test files are needed. The test result is printed to the terminal as well as a log file test_result.log. If you want to run through docker, you can run the tests properly with the following command:\nsudo docker run -it --rm --name autotax -v ${PWD}:\/autotax kasperskytte\/autotax:latest -b\n\nThe exact docker command above is being used for testing the master branch on https:\/\/github.com\/kasperskytte\/autotax, the latest test log of the master branch can be seen here).\nGenerating input full-length 16S sequences\nAutoTax is made to take input sequences obtained from the method described in Karst et al, 2018. The sequences need to be processed first using the Perl scripts in the \/fSSU-pipelines subfolder.\nIt is also possible to use full-length 16S sequences obtained from other methods such as that described in Callahan et al, 2019 based on PacBio circular consensus sequencing as long as the the error-rate is near-zero.\nSee also\nIn the future full ribosomal operon taxonomic databases may be possible using Nanopore Sequencing and Unique Molecular Tagging, see https:\/\/www.biorxiv.org\/content\/10.1101\/645903v2.\nNotes\nIf you want to use vsearch instead of usearch, feel free to adjust the script accordingly and test it. We would love to hear about the results if so, we have only used and tested usearch10 and usearch11.\n","712":"Netatmo LED Display\n\nProject Goal\nDrive a 64x32 RGA LED Display and display current environmental data\nfrom a Netatmo Weather-Station.\nTechnical Details\nThe heart of the system is an\nArduino Y\u00fan.\nThe ATmega32u4 processor will drive the LCD-Display and the Atheros\nLinux SOC will talk to the Netatmo API using the\nNetatmo Python Client.\nUsing the 5x7 Font (included in the Adafruit GFX Library) the display\nis capable of displaying 10x4 Chars (using some spacing between the\nchars).\nProject Status\nCurrently WIP and not fully functional (just displaying some static\ndemo).\nArduino\nThis project uses the Adafruit_GXF libraries, which is available on\nGithub:\ncd ~\/Documents\/Arduino\/libraries\/ # your Arduino libraries dir\ngit clone https:\/\/github.com\/adafruit\/Adafruit-GFX-Library.git\n\nInitially the Ultrathin LED Matrix Library was considered (see the\nGithub-link below). But because of the bad performance and missing\nfeatures (green led was not implemented), the whole hardware related\nstuff was rewritten from scratch and integrated in the LEDDisplay\nlibrary, which is bundled with this project (separate library, can be\nused also for other projects as well).\nUsing the current implementation, the matrix refresh cycles (full\nrefresh running on 100Hz) do use only about 12% of the 16MHz CPU,\nleaving enough room for the main application.\nPCB \/ Eagle\nA custom Arduino-shield is provided for the connection between the\nArduino and the LED Display. To minimize costs the shield is one-sided\n(TOP coper).\nReferences\n\nLDP-6432 LCD Matrix Display\nATmega32U4 Datasheet\nAdafruit GFX Lib Tutorial\nAdafruit GFX Arduino Library\nUltrathin LED Matrix Library\nGLCD Library\n\n","713":"fault-bucket.m\nMatlab code for fault and anomaly detection, drawn from MA Osborne, R Garnett, K Swersky, and N de Freitas. Prediction and Fault Detection of Environmental Signals with Uncharacterised Faults. (2012). AAAI Conference on Artificial Intelligence (AAAI 2012).\nInstallation\nYou will need to install GPML.\nUsage\nSee EXAMPLE_of_fault_bucket_use.m.\nContact\nMichael A Osborne, mosb@robots.ox.ac.uk.\n","714":"EnvironmentalEvents\nThis project was generated with Angular CLI version 1.0.1.\nDependencies\nnpm i angular-in-memory-web-api\nnpm install @ngui\/map @types\/googlemaps --save\nDevelopment server\nRun ng serve for a dev server. Navigate to http:\/\/localhost:4200\/. The app will automatically reload if you change any of the source files.\nCode scaffolding\nRun ng generate component component-name to generate a new component. You can also use ng generate directive|pipe|service|class|module.\nBuild\nRun ng build to build the project. The build artifacts will be stored in the dist\/ directory. Use the -prod flag for a production build.\nRunning unit tests\nRun ng test to execute the unit tests via Karma.\nRunning end-to-end tests\nRun ng e2e to execute the end-to-end tests via Protractor.\nBefore running the tests make sure you are serving the app via ng serve.\nFurther help\nTo get more help on the Angular CLI use ng help or go check out the Angular CLI README.\n","715":"Environmental Hazards\nThis is an application for tracking environmental hazards in your area. It allows the user to:\n\nView the hazards on the map,\nDocument and edit existing hazards\nSearch the hazards by description\n\nRunning the development version\nPlease follow these steps to run the development version of this application:\n\nInstall npm\nRun npm install -g ionic\nClone this repository\nMove into the repository folder\nRun npm install\nRun ionic serve\n\nMore info on this can be found on the Ionic Getting Started page and the Ionic CLI repo.\n","716":"Environmental Hazards\nThis is an application for tracking environmental hazards in your area. It allows the user to:\n\nView the hazards on the map,\nDocument and edit existing hazards\nSearch the hazards by description\n\nRunning the development version\nPlease follow these steps to run the development version of this application:\n\nInstall npm\nRun npm install -g ionic\nClone this repository\nMove into the repository folder\nRun npm install\nRun ionic serve\n\nMore info on this can be found on the Ionic Getting Started page and the Ionic CLI repo.\n","717":"Environmental Hazards\nThis is an application for tracking environmental hazards in your area. It allows the user to:\n\nView the hazards on the map,\nDocument and edit existing hazards\nSearch the hazards by description\n\nRunning the development version\nPlease follow these steps to run the development version of this application:\n\nInstall npm\nRun npm install -g ionic\nClone this repository\nMove into the repository folder\nRun npm install\nRun ionic serve\n\nMore info on this can be found on the Ionic Getting Started page and the Ionic CLI repo.\n","718":"EnvironmentalForm\nThis project was generated with Angular CLI version 8.3.23.\nDevelopment server\nRun ng serve for a dev server. Navigate to http:\/\/localhost:4200\/. The app will automatically reload if you change any of the source files.\nCode scaffolding\nRun ng generate component component-name to generate a new component. You can also use ng generate directive|pipe|service|class|guard|interface|enum|module.\nBuild\nRun ng build to build the project. The build artifacts will be stored in the dist\/ directory. Use the --prod flag for a production build.\nRunning unit tests\nRun ng test to execute the unit tests via Karma.\nRunning end-to-end tests\nRun ng e2e to execute the end-to-end tests via Protractor.\nFurther help\nTo get more help on the Angular CLI use ng help or go check out the Angular CLI README.\n","719":"Environment\nThis project was generated with Angular CLI version 1.4.7.\nDevelopment server\nRun ng serve for a dev server. Navigate to http:\/\/localhost:4200\/. The app will automatically reload if you change any of the source files.\nCode scaffolding\nRun ng generate component component-name to generate a new component. You can also use ng generate directive|pipe|service|class|guard|interface|enum|module.\nBuild\nRun ng build to build the project. The build artifacts will be stored in the dist\/ directory. Use the -prod flag for a production build.\nRunning unit tests\nRun ng test to execute the unit tests via Karma.\nRunning end-to-end tests\nRun ng e2e to execute the end-to-end tests via Protractor.\nFurther help\nTo get more help on the Angular CLI use ng help or go check out the Angular CLI README.\n","720":"Environmental Sensor Data Display\nIntroduction\nWhen you press ||input: button A||, ||logic: if|| the ||gatorEnvironment: carbon dioxide|| is ||logic: less|| than 500 how a down arrow else show an up arrow. Things to think about. Draw a picture to help think about what you want to happen. When you're ready press the NEXT button to start.\nStep 1\nWhen you turn the micro:bt on, ||gatorEnvironment: initialize|| the environmental sensor\ngatorEnvironment.beginEnvironment()\n\nStep 2\nCode your micro:bit to take a ||gatorEnvironment: carbon dioxide|| reading when ||input: button A|| is pressed and ||basic: show|| that reading on the micro:bit.\ngatorEnvironment.beginEnvironment()\ninput.onButtonPressed(Button.A, function () {\n    basic.showNumber(gatorEnvironment.getMeasurement(measurementType.eCO2))\n})\n\nStep 3\nNow code your micro:bit to display a ||basic: down arrow|| ||logic: if|| ||gatorEnvironment: carbon dioxide||\nis ||logic: less than|| 500.\ngatorEnvironment.beginEnvironment()\ninput.onButtonPressed(Button.A, function () {\n       basic.showNumber(gatorEnvironment.getMeasurement(measurementType.eCO2)) \n       if (gatorEnvironment.getMeasurement(measurementType.eCO2) < 500) {\n        basic.showIcon(IconNames.Sword)\n    }\n})\n\nStep 4\nNow code your micro:bit to display ||basic: up arrow|| if  ||gatorEnvironment: carbon dioxide||\nis ||logic: greater than|| 500.\ninput.onButtonPressed(Button.A, function () {\n    basic.showNumber(gatorEnvironment.getMeasurement(measurementType.eCO2))\n    if (gatorEnvironment.getMeasurement(measurementType.eCO2) < 500) {\n        basic.showIcon(IconNames.Sword)\n    } else {\n        basic.showLeds(`\n            . . # . .\n            . # # # .\n            . . # . .\n            . . # . .\n            . . # . .\n            `)\n    }\n})\n\nStep 5\n|Download your code| and try it out\nStep 6\nModify the program so that when you press ||input: button B||,\n||logic: if|| the ||gatorEnvironment: temperature|| is ||logic: greater than|| 75 F,\nthe gator:bit ||music: plays a song||.\ninput.onButtonPressed(Button.B, function () {\n    if (gatorEnvironment.getMeasurement(measurementType.degreesF) > 75) {\n        music.beginMelody(music.builtInMelody(Melodies.Chase), MelodyOptions.Once)\n        basic.showString(\"Temp\")\n    }\n})\n\nStep 7\n|Download| your code and try it out\nStep 8\nModify either the lights or music to ||Loops: repeat|| 5 times\ninput.onButtonPressed(Button.A, function () {\n for (let i = 0; i < 5; i++) {\n        basic.showNumber(gatorEnvironment.getMeasurement(measurementType.eCO2))\n        if (gatorEnvironment.getMeasurement(measurementType.eCO2) < 500) {\n            basic.showIcon(IconNames.Sword)\n        } else {\n            basic.showLeds(`\n                . . # . .\n                . # # # .\n                . . # . .\n                . . # . .\n                . . # . .\n                `)\n        }\n    }\n})\n\nStep 9\n||basic: wait|| 10 seconds in between each time the sensor takes a reading\ninput.onButtonPressed(Button.A, function () {\n    for (let i = 0; i < 5; i++) {\n        basic.showNumber(gatorEnvironment.getMeasurement(measurementType.eCO2))\n        if (gatorEnvironment.getMeasurement(measurementType.eCO2) < 500) {\n            basic.showIcon(IconNames.Sword)\n        } else {\n            basic.showLeds(`\n                . . # . .\n                . # # # .\n                . . # . .\n                . . # . .\n                . . # . .\n                `)\n        }\n        basic.pause(10000)\n    }\n})\n\nStep 10\n|Download| the code and try it out.\ngatorEnvironment=github:sparkfun\/pxt-gator-environment\nneopixel=github:microsoft\/pxt-neopixel\n\n","721":"environmental_demo\n","722":"environmental-server\nNodeJS project to work with environmental-sensor project\nThe aim of this project is to develop a small REST service working with the environmental-sensor.\nLe REST service will let the sensor inject new data in database, client asking for values stored in database and finally, in a short future I hope, get access to a webapp the show the statistics using graphs, plots etc.\nIt will be able to manage different sensors, TeleInfo etc.\nWork in progress ...\nThis is my first attempt to NodeJS development so if you want to give me advices \/ help me, you're welcome !  :)\n","723":"Snapshots of Environmental Twitter Activity\nOverview\nVisit the website here: environmental-twitter.herokuapp.com\nThe default tweet cap is set at 500 tweets so that the Twitter rate limit doesn't quickly block using the website. If you would like to increase the cap, change the text box next to the reload button to a higher number (must be multiple of 100). Twitter may still return fewer tweets if there aren't enough available or if the rate limit is reached. Increase the cap at your own risk.\nBackground\nSince the inauguration of Donald Trump as the 45th President of the United States, the EPA has faced severe funding cuts and deregulation. One of the biggest centers of community response has been on Twitter, where many users have expressed their outrage - and some their praise - over the recent changes to environmental protection in the US. To capture this well of public opinion, I poll Twitter data and perform sentiment analysis on it in order to better understand how the public feels about the EPA at a given time. The site does not track or store data over long periods, but rather looks at a quick snapshot of Twitter activity that is captured on every page load. I do not argue that this provides context long term trend analysis, but rather that it allows users to get insight into how the public feels about the EPA in the instant that they load the site.\nMethods\nIn a general sense, the website will read current Tweets about the EPA (any recent tweets that tags @EPA) and will perform sentiment analysis on those tweets, searching for positive or negative sentiment. The results are then graphed in various charts that look at tweet counts, retweet counts, and break down sentiment by timezone.\nLearn more about my methods here: methods\nInput Data\nThe input for the analysis is a JSON object that is returned by the Twitter REST APIs. I focus on the following attributes in the input data:\n\njsonResponse['statuses'] - this contains all the tweet objects that were returned in the latest search\ntweet['full_text'] - this extracts the full text of the current status\ntweet['user']['name'] - gives the username of the person who tweeted the current status\ntweet['user']['time_zone'] - gives the timezone of the user\ntweet['retweet_count'] - the retweet count of the current tweet (how many times other users have retweeted it)\ntweet['created_at'] - gives the date and time the tweet was posted\n\nOutput Data\nThe data that I plot is broken into the following segments:\n\ndata[\"sentiments\"] - the sentiment total of each tweet\ndata[\"items\"] - the raw tweet data (e.g. username, text, etc.)\ndata[\"dates\"] - the dates of each tweet\ndata[\"retweets\"] - the sentiment totals weighted by retweet count (see methodology above)\ndata[\"timezones\"] - the count of tweets from each timezone\ndata[\"timezones_sentiment\"] - the overall sentiment at each timezone\n\nDisplay of Data\nI display the data using two histograms (sentiment count from tweets themselves, and sentiment count from retweets), a pie chart (timezone distribution), and a bar chart (the overall sentiment from each timezone)\nDeploying\nTo deploy the website, I simply push updated files to this repo, which automatically deploys to Heroku. If the app crashes, let me know and I can restart the dynos.\nAuthor\nThis web app was created by Nick Moolenijzer (nick@moolenijzer.com) - contact me with any questions!\nArchitecture\n\nDjango - used Django framework to serve and render HTML files with output from Python data analysis\nHeroku - builds and hosts the web app\nRedis To Go - Heroku add-on for simple Redis implementation\n\nLibraries\n\npython-oauth2 - utilized to authorize GET requests using Twitter auth tokens\nNatural Language Toolkit - necessary tools for analyzing tweets for sentiment (e.g. tokenizing, POS analysis, classifying)\nplotly - used to plot the results of text analysis\nNumPy - helps with various calculations and scientific analysis\nDjango-RQ - provides framework for background workers to analyze Twitter data off the web dyno\nRedis - provides back-end for RQ background workers\/queueing\n\nAPIs\n\nTwitter REST APIs - allows for programmatic search of Twitter activity\n\nAssets\n\nGoogle Material Icons - icons for web use\n\nLicense\nAll of my written code is licensed under the MIT License open source license, but all libraries, data, and external resources may have their own licenses that must be followed.\nSources, Tutorials, and Helpful References\nBird, Steven, Ewan Klein, and Edward Loper. Natural Language Processing with Python. Beijing: O'Reilly, 2009. http:\/\/www.nltk.org\/book_1ed\/.\nKantrowitz, Mark, and Bill Ross. \"Names Corpus.\" N.p., 29 Mar. 1994. Web. 30 Jan. 2017. http:\/\/www-2.cs.cmu.edu\/afs\/cs\/project\/ai-repository\/ai\/areas\/nlp\/corpora\/names\/.\nLiu, Bing. \"Pros and Cons.\" N.p., 2008. Web. https:\/\/www.cs.uic.edu\/~liub\/FBS\/sentiment-analysis.html#datasets.\nLoper, Edward. \"Source Code for Nltk.classify.naivebayes.\" Nltk.classify.naivebayes \u2014 NLTK 3.0 Documentation. N.p., n.d. Web. 30 Jan. 2017.\nNLTK. \"Classifiers.\" Classifiers. N.p., n.d. Web. 30 Jan. 2017.\nNLTK. \"Natural Language Toolkit.\" Natural Language Toolkit \u2014 NLTK 3.0 Documentation. N.p., n.d. Web. 30 Jan. 2017.\nNLTK. \"Nltk Package.\" Nltk Package \u2014 NLTK 3.0 Documentation. N.p., n.d. Web. 30 Jan. 2017.\nNLTK. \"Nltk.classify Package.\" Nltk.classify Package \u2014 NLTK 3.0 Documentation. N.p., n.d. Web. 30 Jan. 2017.\nPerkins, Jacob. \"Python NLTK Demos for Natural Language Text Processing.\" Python NLTK Demos for Natural Language Text Processing and NLP. N.p., n.d. Web. 30 Jan. 2017.\nPoole, David, and Alan Mackworth. \"Artificial Intelligence.\" Artificial Intelligence - Foundations of Computational Agents -- 7.3.3 Bayesian Classifiers. N.p., 2010. Web. 30 Jan. 2017\n5 . Categorizing and Tagging Words. (n.d.). Retrieved March 12, 2017, from http:\/\/www.nltk.org\/book\/ch05.html\nAsynchronous tasks and jobs in Django with RQ | en.proft.me. (n.d.). Retrieved March 11, 2017, from http:\/\/en.proft.me\/2016\/10\/4\/asynchronous-tasks-and-jobs-django-rq\/\nBackground Tasks in Python with RQ | Heroku Dev Center. (n.d.). Retrieved March 7, 2017, from https:\/\/devcenter.heroku.com\/articles\/python-rq\nCoolors. (n.d.). Retrieved March 11, 2017, from https:\/\/coolors.co\/9f7e69-d2bba0-f2efc7-f7ffe0-ffeee2\nDeploying Python and Django Apps on Heroku | Heroku Dev Center. (n.d.). Retrieved February 16, 2017, from https:\/\/devcenter.heroku.com\/articles\/deploying-python\ndjango - Connection refused for Redis on Heroku - Stack Overflow. (n.d.). Retrieved March 11, 2017, from http:\/\/stackoverflow.com\/questions\/11813470\/connection-refused-for-redis-on-heroku\nGET search\/tweets \u2014 Twitter Developers. (n.d.). Retrieved March 9, 2017, from https:\/\/dev.twitter.com\/rest\/reference\/get\/search\/tweets\nGoogle Fonts. (n.d.). Retrieved March 8, 2017, from https:\/\/fonts.google.com\/\nHeroku Redis | Heroku Dev Center. (n.d.). Retrieved March 11, 2017, from https:\/\/devcenter.heroku.com\/articles\/heroku-redis#connecting-in-python\nHistograms. (n.d.). Retrieved March 11, 2017, from https:\/\/plot.ly\/python\/histograms\/\nHow to use sessions | Django documentation | Django. (n.d.). Retrieved March 11, 2017, from https:\/\/docs.djangoproject.com\/en\/1.10\/topics\/http\/sessions\/\nHTTP GET request in JavaScript? - Stack Overflow. (n.d.). Retrieved March 11, 2017, from http:\/\/stackoverflow.com\/questions\/247483\/http-get-request-in-javascript\njavascript - What\u2019s the easiest way to call a function every 5 seconds in jQuery? - Stack Overflow. (n.d.). Retrieved March 11, 2017, from\nhttp:\/\/stackoverflow.com\/questions\/2170923\/whats-the-easiest-way-to-call-a-function-every-5-seconds-in-jquery\njoestump\/python-oauth2. (n.d.). Retrieved March 12, 2017, from https:\/\/github.com\/joestump\/python-oauth2\njoestump\/python-oauth2: A fully tested, abstract interface to creating OAuth clients and servers. (n.d.). Retrieved February 16, 2017, from https:\/\/github.com\/joestump\/python-oauth2\nManaging static files (e.g. images, JavaScript, CSS) | Django documentation | Django. (n.d.). Retrieved February 16, 2017, from https:\/\/docs.djangoproject.com\/en\/1.10\/howto\/static-files\/\nMaterial icons - Material Design. (n.d.). Retrieved March 12, 2017, from https:\/\/material.io\/icons\/\nNatural Language Toolkit \u2014 NLTK 3.0 documentation. (n.d.). Retrieved March 12, 2017, from http:\/\/www.nltk.org\/\nNumPy \u2014 NumPy. (n.d.). Retrieved March 12, 2017, from http:\/\/www.numpy.org\/\nPersonal apps | Heroku. (n.d.). Retrieved March 12, 2017, from https:\/\/dashboard.heroku.com\/apps\nPie Charts. (n.d.). Retrieved March 11, 2017, from https:\/\/plot.ly\/python\/pie-charts\/\npyplot \u2014 Matplotlib 2.0.0 documentation. (n.d.). Retrieved March 8, 2017, from http:\/\/matplotlib.org\/api\/pyplot_api.html\npython - Adding config modes to Plotly.Py offline - modebar - Stack Overflow. (n.d.). Retrieved March 9, 2017, from\nhttp:\/\/stackoverflow.com\/questions\/36554705\/adding-config-modes-to-plotly-py-offline-modebar\npython - Embedding a Plotly chart in a Django template - Stack Overflow. (n.d.). Retrieved March 9, 2017, from\nhttp:\/\/stackoverflow.com\/questions\/36846395\/embedding-a-plotly-chart-in-a-django-template\npython - Flask: passing around background worker job (rq, redis) - Stack Overflow. (n.d.). Retrieved March 11, 2017, from\nhttp:\/\/stackoverflow.com\/questions\/12162021\/flask-passing-around-background-worker-job-rq-redis\nPython: How to get job result by RQ - Stack Overflow. (n.d.). Retrieved March 11, 2017, from http:\/\/stackoverflow.com\/questions\/22776924\/python-how-to-get-job-result-by-rq\nRedis. (n.d.). Retrieved March 12, 2017, from https:\/\/redis.io\/\nredis - How to get Job by id in RQ python? - Stack Overflow. (n.d.). Retrieved March 11, 2017, from http:\/\/stackoverflow.com\/questions\/15181630\/how-to-get-job-by-id-in-rq-python\nRedis: OOM command not allowed when used memory > \u201cmaxmemory.\u201d (2016, May 16). Retrieved from https:\/\/ma.ttias.be\/redis-oom-command-not-allowed-used-memory-maxmemory\/\nRedis To Go - Add-ons - Heroku Elements. (n.d.). Retrieved March 12, 2017, from https:\/\/elements.heroku.com\/addons\/redistogo\nREST APIs \u2014 Twitter Developers. (n.d.). Retrieved February 16, 2017, from https:\/\/dev.twitter.com\/rest\/public\nRQ: Simple job queues for Python. (n.d.). Retrieved March 11, 2017, from http:\/\/python-rq.org\/\nSimple Job Queues with django_rq | Imaginary Landscape. (n.d.). Retrieved March 11, 2017, from https:\/\/www.imagescape.com\/blog\/2013\/06\/13\/simple-job-queues-django_rq\/\nSingle-user OAuth with Examples \u2014 Twitter Developers. (n.d.). Retrieved February 16, 2017, from https:\/\/dev.twitter.com\/oauth\/overview\/single-user\nSmistad, E. (n.d.). Making charts and output them as images to the browser in Django \u2013 Erik Smistad. Retrieved from\nhttps:\/\/www.eriksmistad.no\/making-charts-and-outputing-them-as-images-to-the-browser-in-django\/\nStack Overflow. (n.d.). Retrieved March 7, 2017, from http:\/\/stackoverflow.com\/\nStreet, A. (n.d.). Using redis-queue for asynchronous calls with Django. Retrieved from http:\/\/racingtadpole.com\/blog\/redis-queue-with-django\/\nThe Web framework for perfectionists with deadlines | Django. (n.d.). Retrieved March 12, 2017, from https:\/\/www.djangoproject.com\/\nThumbnail gallery \u2014 Matplotlib 2.0.0 documentation. (n.d.). Retrieved March 7, 2017, from http:\/\/matplotlib.org\/gallery.html\nui\/django-rq. (n.d.). Retrieved March 12, 2017, from https:\/\/github.com\/ui\/django-rq\nVisualize Data, Together. (n.d.). Retrieved March 12, 2017, from https:\/\/plot.ly\/\nWorldvectorlogo \u2014 Brand logos free to download. (n.d.). Retrieved March 7, 2017, from https:\/\/worldvectorlogo.com\/\n","724":"Snapshots of Environmental Twitter Activity\nOverview\nVisit the website here: environmental-twitter.herokuapp.com\nThe default tweet cap is set at 500 tweets so that the Twitter rate limit doesn't quickly block using the website. If you would like to increase the cap, change the text box next to the reload button to a higher number (must be multiple of 100). Twitter may still return fewer tweets if there aren't enough available or if the rate limit is reached. Increase the cap at your own risk.\nBackground\nSince the inauguration of Donald Trump as the 45th President of the United States, the EPA has faced severe funding cuts and deregulation. One of the biggest centers of community response has been on Twitter, where many users have expressed their outrage - and some their praise - over the recent changes to environmental protection in the US. To capture this well of public opinion, I poll Twitter data and perform sentiment analysis on it in order to better understand how the public feels about the EPA at a given time. The site does not track or store data over long periods, but rather looks at a quick snapshot of Twitter activity that is captured on every page load. I do not argue that this provides context long term trend analysis, but rather that it allows users to get insight into how the public feels about the EPA in the instant that they load the site.\nMethods\nIn a general sense, the website will read current Tweets about the EPA (any recent tweets that tags @EPA) and will perform sentiment analysis on those tweets, searching for positive or negative sentiment. The results are then graphed in various charts that look at tweet counts, retweet counts, and break down sentiment by timezone.\nLearn more about my methods here: methods\nInput Data\nThe input for the analysis is a JSON object that is returned by the Twitter REST APIs. I focus on the following attributes in the input data:\n\njsonResponse['statuses'] - this contains all the tweet objects that were returned in the latest search\ntweet['full_text'] - this extracts the full text of the current status\ntweet['user']['name'] - gives the username of the person who tweeted the current status\ntweet['user']['time_zone'] - gives the timezone of the user\ntweet['retweet_count'] - the retweet count of the current tweet (how many times other users have retweeted it)\ntweet['created_at'] - gives the date and time the tweet was posted\n\nOutput Data\nThe data that I plot is broken into the following segments:\n\ndata[\"sentiments\"] - the sentiment total of each tweet\ndata[\"items\"] - the raw tweet data (e.g. username, text, etc.)\ndata[\"dates\"] - the dates of each tweet\ndata[\"retweets\"] - the sentiment totals weighted by retweet count (see methodology above)\ndata[\"timezones\"] - the count of tweets from each timezone\ndata[\"timezones_sentiment\"] - the overall sentiment at each timezone\n\nDisplay of Data\nI display the data using two histograms (sentiment count from tweets themselves, and sentiment count from retweets), a pie chart (timezone distribution), and a bar chart (the overall sentiment from each timezone)\nDeploying\nTo deploy the website, I simply push updated files to this repo, which automatically deploys to Heroku. If the app crashes, let me know and I can restart the dynos.\nAuthor\nThis web app was created by Nick Moolenijzer (nick@moolenijzer.com) - contact me with any questions!\nArchitecture\n\nDjango - used Django framework to serve and render HTML files with output from Python data analysis\nHeroku - builds and hosts the web app\nRedis To Go - Heroku add-on for simple Redis implementation\n\nLibraries\n\npython-oauth2 - utilized to authorize GET requests using Twitter auth tokens\nNatural Language Toolkit - necessary tools for analyzing tweets for sentiment (e.g. tokenizing, POS analysis, classifying)\nplotly - used to plot the results of text analysis\nNumPy - helps with various calculations and scientific analysis\nDjango-RQ - provides framework for background workers to analyze Twitter data off the web dyno\nRedis - provides back-end for RQ background workers\/queueing\n\nAPIs\n\nTwitter REST APIs - allows for programmatic search of Twitter activity\n\nAssets\n\nGoogle Material Icons - icons for web use\n\nLicense\nAll of my written code is licensed under the MIT License open source license, but all libraries, data, and external resources may have their own licenses that must be followed.\nSources, Tutorials, and Helpful References\nBird, Steven, Ewan Klein, and Edward Loper. Natural Language Processing with Python. Beijing: O'Reilly, 2009. http:\/\/www.nltk.org\/book_1ed\/.\nKantrowitz, Mark, and Bill Ross. \"Names Corpus.\" N.p., 29 Mar. 1994. Web. 30 Jan. 2017. http:\/\/www-2.cs.cmu.edu\/afs\/cs\/project\/ai-repository\/ai\/areas\/nlp\/corpora\/names\/.\nLiu, Bing. \"Pros and Cons.\" N.p., 2008. Web. https:\/\/www.cs.uic.edu\/~liub\/FBS\/sentiment-analysis.html#datasets.\nLoper, Edward. \"Source Code for Nltk.classify.naivebayes.\" Nltk.classify.naivebayes \u2014 NLTK 3.0 Documentation. N.p., n.d. Web. 30 Jan. 2017.\nNLTK. \"Classifiers.\" Classifiers. N.p., n.d. Web. 30 Jan. 2017.\nNLTK. \"Natural Language Toolkit.\" Natural Language Toolkit \u2014 NLTK 3.0 Documentation. N.p., n.d. Web. 30 Jan. 2017.\nNLTK. \"Nltk Package.\" Nltk Package \u2014 NLTK 3.0 Documentation. N.p., n.d. Web. 30 Jan. 2017.\nNLTK. \"Nltk.classify Package.\" Nltk.classify Package \u2014 NLTK 3.0 Documentation. N.p., n.d. Web. 30 Jan. 2017.\nPerkins, Jacob. \"Python NLTK Demos for Natural Language Text Processing.\" Python NLTK Demos for Natural Language Text Processing and NLP. N.p., n.d. Web. 30 Jan. 2017.\nPoole, David, and Alan Mackworth. \"Artificial Intelligence.\" Artificial Intelligence - Foundations of Computational Agents -- 7.3.3 Bayesian Classifiers. N.p., 2010. Web. 30 Jan. 2017\n5 . Categorizing and Tagging Words. (n.d.). Retrieved March 12, 2017, from http:\/\/www.nltk.org\/book\/ch05.html\nAsynchronous tasks and jobs in Django with RQ | en.proft.me. (n.d.). Retrieved March 11, 2017, from http:\/\/en.proft.me\/2016\/10\/4\/asynchronous-tasks-and-jobs-django-rq\/\nBackground Tasks in Python with RQ | Heroku Dev Center. (n.d.). Retrieved March 7, 2017, from https:\/\/devcenter.heroku.com\/articles\/python-rq\nCoolors. (n.d.). Retrieved March 11, 2017, from https:\/\/coolors.co\/9f7e69-d2bba0-f2efc7-f7ffe0-ffeee2\nDeploying Python and Django Apps on Heroku | Heroku Dev Center. (n.d.). Retrieved February 16, 2017, from https:\/\/devcenter.heroku.com\/articles\/deploying-python\ndjango - Connection refused for Redis on Heroku - Stack Overflow. (n.d.). Retrieved March 11, 2017, from http:\/\/stackoverflow.com\/questions\/11813470\/connection-refused-for-redis-on-heroku\nGET search\/tweets \u2014 Twitter Developers. (n.d.). Retrieved March 9, 2017, from https:\/\/dev.twitter.com\/rest\/reference\/get\/search\/tweets\nGoogle Fonts. (n.d.). Retrieved March 8, 2017, from https:\/\/fonts.google.com\/\nHeroku Redis | Heroku Dev Center. (n.d.). Retrieved March 11, 2017, from https:\/\/devcenter.heroku.com\/articles\/heroku-redis#connecting-in-python\nHistograms. (n.d.). Retrieved March 11, 2017, from https:\/\/plot.ly\/python\/histograms\/\nHow to use sessions | Django documentation | Django. (n.d.). Retrieved March 11, 2017, from https:\/\/docs.djangoproject.com\/en\/1.10\/topics\/http\/sessions\/\nHTTP GET request in JavaScript? - Stack Overflow. (n.d.). Retrieved March 11, 2017, from http:\/\/stackoverflow.com\/questions\/247483\/http-get-request-in-javascript\njavascript - What\u2019s the easiest way to call a function every 5 seconds in jQuery? - Stack Overflow. (n.d.). Retrieved March 11, 2017, from\nhttp:\/\/stackoverflow.com\/questions\/2170923\/whats-the-easiest-way-to-call-a-function-every-5-seconds-in-jquery\njoestump\/python-oauth2. (n.d.). Retrieved March 12, 2017, from https:\/\/github.com\/joestump\/python-oauth2\njoestump\/python-oauth2: A fully tested, abstract interface to creating OAuth clients and servers. (n.d.). Retrieved February 16, 2017, from https:\/\/github.com\/joestump\/python-oauth2\nManaging static files (e.g. images, JavaScript, CSS) | Django documentation | Django. (n.d.). Retrieved February 16, 2017, from https:\/\/docs.djangoproject.com\/en\/1.10\/howto\/static-files\/\nMaterial icons - Material Design. (n.d.). Retrieved March 12, 2017, from https:\/\/material.io\/icons\/\nNatural Language Toolkit \u2014 NLTK 3.0 documentation. (n.d.). Retrieved March 12, 2017, from http:\/\/www.nltk.org\/\nNumPy \u2014 NumPy. (n.d.). Retrieved March 12, 2017, from http:\/\/www.numpy.org\/\nPersonal apps | Heroku. (n.d.). Retrieved March 12, 2017, from https:\/\/dashboard.heroku.com\/apps\nPie Charts. (n.d.). Retrieved March 11, 2017, from https:\/\/plot.ly\/python\/pie-charts\/\npyplot \u2014 Matplotlib 2.0.0 documentation. (n.d.). Retrieved March 8, 2017, from http:\/\/matplotlib.org\/api\/pyplot_api.html\npython - Adding config modes to Plotly.Py offline - modebar - Stack Overflow. (n.d.). Retrieved March 9, 2017, from\nhttp:\/\/stackoverflow.com\/questions\/36554705\/adding-config-modes-to-plotly-py-offline-modebar\npython - Embedding a Plotly chart in a Django template - Stack Overflow. (n.d.). Retrieved March 9, 2017, from\nhttp:\/\/stackoverflow.com\/questions\/36846395\/embedding-a-plotly-chart-in-a-django-template\npython - Flask: passing around background worker job (rq, redis) - Stack Overflow. (n.d.). Retrieved March 11, 2017, from\nhttp:\/\/stackoverflow.com\/questions\/12162021\/flask-passing-around-background-worker-job-rq-redis\nPython: How to get job result by RQ - Stack Overflow. (n.d.). Retrieved March 11, 2017, from http:\/\/stackoverflow.com\/questions\/22776924\/python-how-to-get-job-result-by-rq\nRedis. (n.d.). Retrieved March 12, 2017, from https:\/\/redis.io\/\nredis - How to get Job by id in RQ python? - Stack Overflow. (n.d.). Retrieved March 11, 2017, from http:\/\/stackoverflow.com\/questions\/15181630\/how-to-get-job-by-id-in-rq-python\nRedis: OOM command not allowed when used memory > \u201cmaxmemory.\u201d (2016, May 16). Retrieved from https:\/\/ma.ttias.be\/redis-oom-command-not-allowed-used-memory-maxmemory\/\nRedis To Go - Add-ons - Heroku Elements. (n.d.). Retrieved March 12, 2017, from https:\/\/elements.heroku.com\/addons\/redistogo\nREST APIs \u2014 Twitter Developers. (n.d.). Retrieved February 16, 2017, from https:\/\/dev.twitter.com\/rest\/public\nRQ: Simple job queues for Python. (n.d.). Retrieved March 11, 2017, from http:\/\/python-rq.org\/\nSimple Job Queues with django_rq | Imaginary Landscape. (n.d.). Retrieved March 11, 2017, from https:\/\/www.imagescape.com\/blog\/2013\/06\/13\/simple-job-queues-django_rq\/\nSingle-user OAuth with Examples \u2014 Twitter Developers. (n.d.). Retrieved February 16, 2017, from https:\/\/dev.twitter.com\/oauth\/overview\/single-user\nSmistad, E. (n.d.). Making charts and output them as images to the browser in Django \u2013 Erik Smistad. Retrieved from\nhttps:\/\/www.eriksmistad.no\/making-charts-and-outputing-them-as-images-to-the-browser-in-django\/\nStack Overflow. (n.d.). Retrieved March 7, 2017, from http:\/\/stackoverflow.com\/\nStreet, A. (n.d.). Using redis-queue for asynchronous calls with Django. Retrieved from http:\/\/racingtadpole.com\/blog\/redis-queue-with-django\/\nThe Web framework for perfectionists with deadlines | Django. (n.d.). Retrieved March 12, 2017, from https:\/\/www.djangoproject.com\/\nThumbnail gallery \u2014 Matplotlib 2.0.0 documentation. (n.d.). Retrieved March 7, 2017, from http:\/\/matplotlib.org\/gallery.html\nui\/django-rq. (n.d.). Retrieved March 12, 2017, from https:\/\/github.com\/ui\/django-rq\nVisualize Data, Together. (n.d.). Retrieved March 12, 2017, from https:\/\/plot.ly\/\nWorldvectorlogo \u2014 Brand logos free to download. (n.d.). Retrieved March 7, 2017, from https:\/\/worldvectorlogo.com\/\n","725":"Environmental-Computers\n","726":"Environmental-Computers\n","727":"environmental-demo\n","728":"Environmental-Inequality\nThis contains the data and code I utilized to build an economic model detailing air quality levels depending on one's socioeconomic characteristics.\nI did not include any code, as raw data exceed github's repository limit. Please contact me if you wish to recieve the code and I can import it to you.\nIncluded are my presentation, poster, thesis, and STATA.do file for this project. They encompass all the significant parts of my project, specifically the results and anlysis.\n","729":"environmental_scrollytelling\nOur repo for the environmental scrollytelling project\nGeneral goal:\nWe want to contextualise the issue of how Germany is progressing on decarbonisation, and potentially place this within a European.\nWhat do we need:\n\nSpatial data on coal mining\/consumption sites in Germany\nSubsidy data for fossil fuels\/renewables\nCoal consumption for Germany\nGermany legislation on climate policy\nInvestment of Germany companies in coal related projects (maybe focus on the five major power companies)\n\n","730":"Environmental-Project-\nWater Level Effect on San Diego Terrain\n","731":"This project was bootstrapped with Create React Native App.\nBelow you'll find information about performing common tasks. The most recent version of this guide is available here.\nTable of Contents\n\nUpdating to New Releases\nAvailable Scripts\n\nnpm start\nnpm test\nnpm run ios\nnpm run android\nnpm run eject\n\n\nWriting and Running Tests\nEnvironment Variables\n\nConfiguring Packager IP Address\n\n\nCustomizing App Display Name and Icon\nSharing and Deployment\n\nPublishing to Expo's React Native Community\nBuilding an Expo \"standalone\" app\nEjecting from Create React Native App\n\nBuild Dependencies (Xcode & Android Studio)\nShould I Use ExpoKit?\n\n\n\n\nTroubleshooting\n\nNetworking\niOS Simulator won't open\nQR Code does not scan\n\n\n\nUpdating to New Releases\nYou should only need to update the global installation of create-react-native-app very rarely, ideally never.\nUpdating the react-native-scripts dependency of your app should be as simple as bumping the version number in package.json and reinstalling your project's dependencies.\nUpgrading to a new version of React Native requires updating the react-native, react, and expo package versions, and setting the correct sdkVersion in app.json. See the versioning guide for up-to-date information about package version compatibility.\nAvailable Scripts\nIf Yarn was installed when the project was initialized, then dependencies will have been installed via Yarn, and you should probably use it to run these commands as well. Unlike dependency installation, command running syntax is identical for Yarn and NPM at the time of this writing.\nnpm start\nRuns your app in development mode.\nOpen it in the Expo app on your phone to view it. It will reload if you save edits to your files, and you will see build errors and logs in the terminal.\nSometimes you may need to reset or clear the React Native packager's cache. To do so, you can pass the --reset-cache flag to the start script:\nnpm start --reset-cache\n# or\nyarn start --reset-cache\n\nnpm test\nRuns the jest test runner on your tests.\nnpm run ios\nLike npm start, but also attempts to open your app in the iOS Simulator if you're on a Mac and have it installed.\nnpm run android\nLike npm start, but also attempts to open your app on a connected Android device or emulator. Requires an installation of Android build tools (see React Native docs for detailed setup). We also recommend installing Genymotion as your Android emulator. Once you've finished setting up the native build environment, there are two options for making the right copy of adb available to Create React Native App:\nUsing Android Studio's adb\n\nMake sure that you can run adb from your terminal.\nOpen Genymotion and navigate to Settings -> ADB. Select \u201cUse custom Android SDK tools\u201d and update with your Android SDK directory.\n\nUsing Genymotion's adb\n\nFind Genymotion\u2019s copy of adb. On macOS for example, this is normally \/Applications\/Genymotion.app\/Contents\/MacOS\/tools\/.\nAdd the Genymotion tools directory to your path (instructions for Mac, Linux, and Windows).\nMake sure that you can run adb from your terminal.\n\nnpm run eject\nThis will start the process of \"ejecting\" from Create React Native App's build scripts. You'll be asked a couple of questions about how you'd like to build your project.\nWarning: Running eject is a permanent action (aside from whatever version control system you use). An ejected app will require you to have an Xcode and\/or Android Studio environment set up.\nCustomizing App Display Name and Icon\nYou can edit app.json to include configuration keys under the expo key.\nTo change your app's display name, set the expo.name key in app.json to an appropriate string.\nTo set an app icon, set the expo.icon key in app.json to be either a local path or a URL. It's recommended that you use a 512x512 png file with transparency.\nWriting and Running Tests\nThis project is set up to use jest for tests. You can configure whatever testing strategy you like, but jest works out of the box. Create test files in directories called __tests__ or with the .test extension to have the files loaded by jest. See the the template project for an example test. The jest documentation is also a wonderful resource, as is the React Native testing tutorial.\nEnvironment Variables\nYou can configure some of Create React Native App's behavior using environment variables.\nConfiguring Packager IP Address\nWhen starting your project, you'll see something like this for your project URL:\nexp:\/\/192.168.0.2:19000\n\nThe \"manifest\" at that URL tells the Expo app how to retrieve and load your app's JavaScript bundle, so even if you load it in the app via a URL like exp:\/\/localhost:19000, the Expo client app will still try to retrieve your app at the IP address that the start script provides.\nIn some cases, this is less than ideal. This might be the case if you need to run your project inside of a virtual machine and you have to access the packager via a different IP address than the one which prints by default. In order to override the IP address or hostname that is detected by Create React Native App, you can specify your own hostname via the REACT_NATIVE_PACKAGER_HOSTNAME environment variable:\nMac and Linux:\nREACT_NATIVE_PACKAGER_HOSTNAME='my-custom-ip-address-or-hostname' npm start\n\nWindows:\nset REACT_NATIVE_PACKAGER_HOSTNAME='my-custom-ip-address-or-hostname'\nnpm start\n\nThe above example would cause the development server to listen on exp:\/\/my-custom-ip-address-or-hostname:19000.\nSharing and Deployment\nCreate React Native App does a lot of work to make app setup and development simple and straightforward, but it's very difficult to do the same for deploying to Apple's App Store or Google's Play Store without relying on a hosted service.\nPublishing to Expo's React Native Community\nExpo provides free hosting for the JS-only apps created by CRNA, allowing you to share your app through the Expo client app. This requires registration for an Expo account.\nInstall the exp command-line tool, and run the publish command:\n$ npm i -g exp\n$ exp publish\n\nBuilding an Expo \"standalone\" app\nYou can also use a service like Expo's standalone builds if you want to get an IPA\/APK for distribution without having to build the native code yourself.\nEjecting from Create React Native App\nIf you want to build and deploy your app yourself, you'll need to eject from CRNA and use Xcode and Android Studio.\nThis is usually as simple as running npm run eject in your project, which will walk you through the process. Make sure to install react-native-cli and follow the native code getting started guide for React Native.\nShould I Use ExpoKit?\nIf you have made use of Expo APIs while working on your project, then those API calls will stop working if you eject to a regular React Native project. If you want to continue using those APIs, you can eject to \"React Native + ExpoKit\" which will still allow you to build your own native code and continue using the Expo APIs. See the ejecting guide for more details about this option.\nTroubleshooting\nNetworking\nIf you're unable to load your app on your phone due to a network timeout or a refused connection, a good first step is to verify that your phone and computer are on the same network and that they can reach each other. Create React Native App needs access to ports 19000 and 19001 so ensure that your network and firewall settings allow access from your device to your computer on both of these ports.\nTry opening a web browser on your phone and opening the URL that the packager script prints, replacing exp:\/\/ with http:\/\/. So, for example, if underneath the QR code in your terminal you see:\nexp:\/\/192.168.0.1:19000\n\nTry opening Safari or Chrome on your phone and loading\nhttp:\/\/192.168.0.1:19000\n\nand\nhttp:\/\/192.168.0.1:19001\n\nIf this works, but you're still unable to load your app by scanning the QR code, please open an issue on the Create React Native App repository with details about these steps and any other error messages you may have received.\nIf you're not able to load the http URL in your phone's web browser, try using the tethering\/mobile hotspot feature on your phone (beware of data usage, though), connecting your computer to that WiFi network, and restarting the packager. If you are using a VPN you may need to disable it.\niOS Simulator won't open\nIf you're on a Mac, there are a few errors that users sometimes see when attempting to npm run ios:\n\n\"non-zero exit code: 107\"\n\"You may need to install Xcode\" but it is already installed\nand others\n\nThere are a few steps you may want to take to troubleshoot these kinds of errors:\n\nMake sure Xcode is installed and open it to accept the license agreement if it prompts you. You can install it from the Mac App Store.\nOpen Xcode's Preferences, the Locations tab, and make sure that the Command Line Tools menu option is set to something. Sometimes when the CLI tools are first installed by Homebrew this option is left blank, which can prevent Apple utilities from finding the simulator. Make sure to re-run npm\/yarn run ios after doing so.\nIf that doesn't work, open the Simulator, and under the app menu select Reset Contents and Settings.... After that has finished, quit the Simulator, and re-run npm\/yarn run ios.\n\nQR Code does not scan\nIf you're not able to scan the QR code, make sure your phone's camera is focusing correctly, and also make sure that the contrast on the two colors in your terminal is high enough. For example, WebStorm's default themes may not have enough contrast for terminal QR codes to be scannable with the system barcode scanners that the Expo app uses.\nIf this causes problems for you, you may want to try changing your terminal's color theme to have more contrast, or running Create React Native App from a different terminal. You can also manually enter the URL printed by the packager script in the Expo app's search bar to load it manually.\n","732":"Read environmental information and plot with bokeh\nThere are two main files:\nread_environmentals.py\nThis file reads environmental information from the raspberry pi sense-hat as\nwell as the MPL3115A2 sensors (for calibration), saves them, and then pushes\nthem to an AWS EC2 instance which in turn plots them.\nThere is another directory to be created in the home directory '~\/data' where\nthe files will be saved locally.\nenvironmentals.py\nThis file lives on the EC2 instance and plots the data from the raspberry pi on\na bokeh server.  There is another directory '~\/data' that needs to be created\nin the home directory for storing the data.\n","733":"Read environmental information and plot with bokeh\nThere are two main files:\nread_environmentals.py\nThis file reads environmental information from the raspberry pi sense-hat as\nwell as the MPL3115A2 sensors (for calibration), saves them, and then pushes\nthem to an AWS EC2 instance which in turn plots them.\nThere is another directory to be created in the home directory '~\/data' where\nthe files will be saved locally.\nenvironmentals.py\nThis file lives on the EC2 instance and plots the data from the raspberry pi on\na bokeh server.  There is another directory '~\/data' that needs to be created\nin the home directory for storing the data.\n","734":"environmental-organisation\n","735":"Environmental-Sustainability\nA document that was created during ThinkChicago's Idea Week that focuses on a environmental sustainability in Chicago.\nSelected as one of 20 total teams to pitch our solution to judges.\nLinks to surveys at the end of the document.\nQuality of the app and food survey: https:\/\/www.surveymonkey.com\/r\/9JYVNZK\nDemographic survey: https:\/\/www.surveymonkey.com\/r\/9QB3NYY\nFarmer survey: https:\/\/www.surveymonkey.com\/r\/9SQ2WZP\nI plan on creating a web app for this once I get more experience in web backend.\n","736":"\nUrban Insights\n\n\n\nAEC Hackathon 2019 Silicon Valley project.\nAn application for visualizing proposed buildings, their code-constraints, and environmental analyses in situ using AR & VR.\nCurrent Deployed Build\nCurrent build can be accessed from the \"Deployment\" Badge above.\nDeveloper Set Up\nClone the repository and run the commands below to start the development server. Navigate to localhost:8080 on your local machine to visualize.\nnpm install\nnpm run serve\nIn order to deploy this project as intended, use Now's documentation to deploy a static, serverless build of the application. Once an account has been created with Now, you should be able to run the commands below in the root of the repository to deploy.\nnpm run build\nnow\nConcept\nPrototype\n\n\n\n\nMobile\nWeb\n\n\n\n\n\n\n\n\n\nStack\n\n","737":"environmental-app\n","738":"environmental-app\n","739":"Environmental-Issues\n","740":"environmental_notices\nOpen data application for Estonian Fund for Nature https:\/\/elfond.ee\/.\nScrapes official notifications from Estonian government site, parses and filters the results sends them regularily to the mailing list and provides geodata preview.\nImplemented in NodeJS.\nInstallation\nnpm install\n\nThen create a config\/config.json file:\n{\n  \"baseUrl\": \"site_base_url\",\n  \"mailFrom\": \"mail_to_send_from\",\n  \"mailTo\": [\n    \"mail_to_send_to_1\",\n    \"mail_to_send_to_2\"\n  ],\n  \"mailUsername\": \"gmail_account_to_sent_from\",\n  \"mailPassword\": \"gmail_account_password\"\n}\n\nRunning\nTo invoke data scraping:\nnode scraper.js\n\nTo invoke mailer:\nnode mailer.js\n\n","741":"environmental_notices\nOpen data application for Estonian Fund for Nature https:\/\/elfond.ee\/.\nScrapes official notifications from Estonian government site, parses and filters the results sends them regularily to the mailing list and provides geodata preview.\nImplemented in NodeJS.\nInstallation\nnpm install\n\nThen create a config\/config.json file:\n{\n  \"baseUrl\": \"site_base_url\",\n  \"mailFrom\": \"mail_to_send_from\",\n  \"mailTo\": [\n    \"mail_to_send_to_1\",\n    \"mail_to_send_to_2\"\n  ],\n  \"mailUsername\": \"gmail_account_to_sent_from\",\n  \"mailPassword\": \"gmail_account_password\"\n}\n\nRunning\nTo invoke data scraping:\nnode scraper.js\n\nTo invoke mailer:\nnode mailer.js\n\n","742":"#required-env-var-plugin \n\nRequire an environmental variable in your application or throw routhlessly.\n\nA zero-dependency webpack plugin.\n##Motivation\nIf you have ever found yourself setting up default env vars in your project just to make sure your app does get some data when a developer forgets to provide it, you run a risk of serving a hard debugging time to other contributors or even worse, ending up with wrong configuration in deployment process.\nNo more accidental values for environmental variables in your app. Get a hard reminder on your face that there's something to be set.\n##Usage\nThe only requirement is a webpack package installed, but since you're checking out a webpack plugin, you're probably already there.\nJust register the plugin and provide the required env var names as parameters:\nconst RequiredEnvVarPlugin = require('required-env-var-plugin')\n\/\/...\nmodule.exports = {\n  \/\/...\n  plugins: [\n    new RequiredEnvVarPlugin('API_URL', 'USER', 'PASS')\n  ]\n  \/\/...\n}\nYou can provide the variables both as a list: REVP('API_URL', 'USER', 'PASS') or as an array: REVP(['API_URL', 'USER', 'PASS']).\n#How does it work?\nUnder the hood it just uses webpack's DefinePlugin and passes it the object of shape:\n{\n  'process.env': {\n    API_URL: xxx,\n    USER: xxx,\n    PASS: xxx,\n  }\n}\nwhere xxx are respective environmental variables derived from process.env.xxx. If it doesn't find one, throws.\n##FAQ\n###Why throw? Can't I just warn the user?\nNo. That's the whole purpose of the plugin. If developer didn't infere from the code, didn't find out from the docs or didn't deduce from the application working that the env var hadn't been set, then he surely won't notice it in a bunch of logs spitted onto the console during startup. The message has to be clear: You forgot to do it, I won't launch!\nLicense\nMIT (https:\/\/opensource.org\/licenses\/mit-license.php)\n","743":"#required-env-var-plugin \n\nRequire an environmental variable in your application or throw routhlessly.\n\nA zero-dependency webpack plugin.\n##Motivation\nIf you have ever found yourself setting up default env vars in your project just to make sure your app does get some data when a developer forgets to provide it, you run a risk of serving a hard debugging time to other contributors or even worse, ending up with wrong configuration in deployment process.\nNo more accidental values for environmental variables in your app. Get a hard reminder on your face that there's something to be set.\n##Usage\nThe only requirement is a webpack package installed, but since you're checking out a webpack plugin, you're probably already there.\nJust register the plugin and provide the required env var names as parameters:\nconst RequiredEnvVarPlugin = require('required-env-var-plugin')\n\/\/...\nmodule.exports = {\n  \/\/...\n  plugins: [\n    new RequiredEnvVarPlugin('API_URL', 'USER', 'PASS')\n  ]\n  \/\/...\n}\nYou can provide the variables both as a list: REVP('API_URL', 'USER', 'PASS') or as an array: REVP(['API_URL', 'USER', 'PASS']).\n#How does it work?\nUnder the hood it just uses webpack's DefinePlugin and passes it the object of shape:\n{\n  'process.env': {\n    API_URL: xxx,\n    USER: xxx,\n    PASS: xxx,\n  }\n}\nwhere xxx are respective environmental variables derived from process.env.xxx. If it doesn't find one, throws.\n##FAQ\n###Why throw? Can't I just warn the user?\nNo. That's the whole purpose of the plugin. If developer didn't infere from the code, didn't find out from the docs or didn't deduce from the application working that the env var hadn't been set, then he surely won't notice it in a bunch of logs spitted onto the console during startup. The message has to be clear: You forgot to do it, I won't launch!\nLicense\nMIT (https:\/\/opensource.org\/licenses\/mit-license.php)\n","744":"environmental-hazards\nWebsite for Environmental Hazards Detection LLC\n","745":"CRUES\nCo-operative robotics using environmental sensors\nDirectory structure\n\ndocs: Documentation, including PDF of final report\n\ndocs\/interim: Interim report LaTeX root\ndocs\/final: Final report LaTeX root\ndocs\/img: Image root for reports\n\n\nwiring: Wiring diagrams, PCB files\nrviz: Rviz configuration files for visualising odemetry and mapping data\ncrues_pi: ROS nodes and Python code\n\ncrues_pi\/ros_pkgs: ROS packages to be added to catkin workspace\ncrues_pi\/crues: Scripts used for testing and debugging\ncrues_pi\/config: Configuration files for individual robots\n(Deploy script copies correct file to each RPi)\ncrues_pi\/crues_deploy: Script for deploying code to RPis\ncrues_pi\/crues_run: Script for running Roomba code on RPis\n\n\n\nDeploying and running code\n\nTurn on robots\nConnect to CruesNet ad-hoc WiFi network\nAdd crues_pi\/crues_deploy and crues_pi\/crues_run to PATH\nRun crues_deploy [ROBOTS] to deploy code, with [ROBOTS] replaced by any combination of blinky, inky and clyde\nRun crues_run [ROBOTS] to run the roomba.launch ROS launch file\n\nMore details can be found in the project Wiki.\n","746":"Grow\n\nFeatures:\n\nMonitor the enviroment\nOptionally control temperature with Wemo switches (edit the script to control other devices)\nOptionally report soil moisture on a per-plant basis (up to 8)\nE-mail alerts when enviroment exceeds alarm values\n\nRequires:\n\nEcowitt GW1000 WiFi gateway\nLinux, apache, MySQL, python3\n\nOptional:\n\nWemo switches for automation\nIP Webcam\nEcowitt soil moisture sensors\n\nSee my full grow list.\nAs an Amazon Associate I earn from qualifying purchases.\nInstallation\n\nPrepare linux host with working MySQL and python3.\nPlace files under the web root and make sure .py files execute as CGI\nCreate a database called grow and create tables with mysql> create database grow and mysql grow < schema.mysql.\ncp myconfig.sample myconfig.py and edit cofiguration.\nConfigure Ecowitt GW1000 to post data to ecowitt.py (Use \"WS View\" app, go to \"Weather Services -> Customized\", enter server address, \/ecowitt.py as path, upload interval 60.\nCopy grow.service to \/etc\/systemd\/system and edit to make the grow-control.py run at boot, and restart on crash.  systemctl daemon-reload once in place, then systemctl enable grow then service grow start then service grow status.\n\nWemo automation:\n\nInstall ouimeaux\nTest command line: wemo list\nMake sure device names match those in grow-control.py.\n\nWebcam setup:\n\nEdit get-image.bash to fetch an image from your webcam so the python script can add to it.\nCreate a cronjob to run the above script every minute: * * * * * \/path\/to\/get-image.bash\nRun the script by hand to test it creates output as expected\nFetch out.jpg via your webserver\nOptionally speciy location (x,y coordinates with 0,0 at top left) of pots\/soil sensors in config file\n\n","747":"Grow\n\nFeatures:\n\nMonitor the enviroment\nOptionally control temperature with Wemo switches (edit the script to control other devices)\nOptionally report soil moisture on a per-plant basis (up to 8)\nE-mail alerts when enviroment exceeds alarm values\n\nRequires:\n\nEcowitt GW1000 WiFi gateway\nLinux, apache, MySQL, python3\n\nOptional:\n\nWemo switches for automation\nIP Webcam\nEcowitt soil moisture sensors\n\nSee my full grow list.\nAs an Amazon Associate I earn from qualifying purchases.\nInstallation\n\nPrepare linux host with working MySQL and python3.\nPlace files under the web root and make sure .py files execute as CGI\nCreate a database called grow and create tables with mysql> create database grow and mysql grow < schema.mysql.\ncp myconfig.sample myconfig.py and edit cofiguration.\nConfigure Ecowitt GW1000 to post data to ecowitt.py (Use \"WS View\" app, go to \"Weather Services -> Customized\", enter server address, \/ecowitt.py as path, upload interval 60.\nCopy grow.service to \/etc\/systemd\/system and edit to make the grow-control.py run at boot, and restart on crash.  systemctl daemon-reload once in place, then systemctl enable grow then service grow start then service grow status.\n\nWemo automation:\n\nInstall ouimeaux\nTest command line: wemo list\nMake sure device names match those in grow-control.py.\n\nWebcam setup:\n\nEdit get-image.bash to fetch an image from your webcam so the python script can add to it.\nCreate a cronjob to run the above script every minute: * * * * * \/path\/to\/get-image.bash\nRun the script by hand to test it creates output as expected\nFetch out.jpg via your webserver\nOptionally speciy location (x,y coordinates with 0,0 at top left) of pots\/soil sensors in config file\n\n","748":"Grow\n\nFeatures:\n\nMonitor the enviroment\nOptionally control temperature with Wemo switches (edit the script to control other devices)\nOptionally report soil moisture on a per-plant basis (up to 8)\nE-mail alerts when enviroment exceeds alarm values\n\nRequires:\n\nEcowitt GW1000 WiFi gateway\nLinux, apache, MySQL, python3\n\nOptional:\n\nWemo switches for automation\nIP Webcam\nEcowitt soil moisture sensors\n\nSee my full grow list.\nAs an Amazon Associate I earn from qualifying purchases.\nInstallation\n\nPrepare linux host with working MySQL and python3.\nPlace files under the web root and make sure .py files execute as CGI\nCreate a database called grow and create tables with mysql> create database grow and mysql grow < schema.mysql.\ncp myconfig.sample myconfig.py and edit cofiguration.\nConfigure Ecowitt GW1000 to post data to ecowitt.py (Use \"WS View\" app, go to \"Weather Services -> Customized\", enter server address, \/ecowitt.py as path, upload interval 60.\nCopy grow.service to \/etc\/systemd\/system and edit to make the grow-control.py run at boot, and restart on crash.  systemctl daemon-reload once in place, then systemctl enable grow then service grow start then service grow status.\n\nWemo automation:\n\nInstall ouimeaux\nTest command line: wemo list\nMake sure device names match those in grow-control.py.\n\nWebcam setup:\n\nEdit get-image.bash to fetch an image from your webcam so the python script can add to it.\nCreate a cronjob to run the above script every minute: * * * * * \/path\/to\/get-image.bash\nRun the script by hand to test it creates output as expected\nFetch out.jpg via your webserver\nOptionally speciy location (x,y coordinates with 0,0 at top left) of pots\/soil sensors in config file\n\n","749":"Environmental Variables\nWhy use environmental variables?\nLeaving sensitive information in the code you push to Github can leave you vulnerable to attacks by malicious, evil, ne'er-do-wells, which can land you in financial or legal trouble. By using environmental variables, we ensure that the variables we want to keep hidden are only accessible on a particular machine and to the programs running on it.\nHere's a quick and dirty guide to hiding your secrets (like your API keys or other sensitive information) in your environment!\nTable of Contents\n\nExporting variables in bash\nDefining variables in your bash profile\nUsing the dotenv npm module\n\nExporting variables in bash\nWhat is an \"environment?\"\n\nYour bash environment contains variables that define system properties.\nIt's how your system is configured. It's actually just a set of key\/value pairs we can view by typing printenv in our terminals.\n\n$ printenv\n\n> displays all sorts of key-value pairs!\nWe can add variables to our environment...\n$ export ENV_VAR=\"anna is cool\"\n$ echo $ENV_VAR\n> \"anna is cool\"\n...and delete them.\n$ unset ENV_VAR\n$ echo $ENV_VAR\n>\nOur variable is dead and gone.\nNote: Notice that while we don't set an environmental variable with a \"$\", we do need to add it when we're referring to it again in bash.\nUsing your bash profile\nOur enviromental variables disappear when we close out of our terminal window and reopen it. OH NO. Solution: add it to our bash profile. Our bash profile is a hidden file in our \/users\/YOURUSERNAMEHERE\/ folder that saves our configuration commands and runs them whenever we start up a new terminal window. It's how we set up customizations and defaults.\nOpen up your bash profile...\nsubl ~\/.bash_profile\n\n...add environmental variables at will...\nexport super_secret=\"shh don't tell\"\n...save the file, and back in your terminal...\nsource ~\/.bash_profile\n...load up your new defaults. Your enviromental variable is now accessible!\nNode, process.env, and you\nYou can access your enviromental variables in node through the process.env object:\nconsole.log(process.env);\n...will perform almost the same function as typing printenv in bash.\nAccess particular variables using dot notation:\nconsole.log(process.env.super_secret)\n\/\/ prints \"shh don't tell\"\ndotenv\ndotenv is a module that allows us to store environmental variables in an external file in our project folder, rather than in our bash environments.\nAdvantages of using the npm module\n\nWe don't need to store a potentially infinite amount of sensitive info in our bash profiles.\nWe can store sensitive information in a project-specific location (and store only the keys we need for that project).\n\nUsage is very simple.\n\nCreate a .env file in your app's folder.\nAdd your secrets to the file.\n\nanna=\"awesome\"\nso_very_secret2=\"shh don't tell\"\n\n\nRequire the module and run the load function in your app.\n\nJavascript:\n\/\/ requires the dotenv module & runs its load function immediately\nvar dotenv = require('dotenv').load();\n\n\/\/ now our custom environmental variables have been added to process.env!\nconsole.log(process.env.anna)\n\/\/prints \"awesome\"\nRuby\n# requires dotenv, loads in env vars\nrequire \"dotenv\"\nDotenv.load\n# same deal!\nputs ENV['anna']\n# prints \"awesome\"\nVERY IMPORTANT:\nDo NOT push your .env file to Github!!!!\nMake sure this file is included in your .gitignore, or your secrets will be on display for all to steal.\nDigital Ocean\nYou can either touch a new .env file on your Digital Ocean droplet, or use scp (secure copy).\nHeroku\nOnce your app is deployed, use heroku's config:set, get, and unset methods\nheroku config:set ENV_VAR=\"whatever\"\n# like printenv\nheroku config\nheroku config:get ENV_VAR\nheroku config:unset ENV_VAR\nYou could also secure copy over your .env file:\nheroku run bash\n# Copy the file FROM your machine to the local (heroku) machine\nscp user@mylocalmachine:\/home\/user\/dir\/file.txt .\n\nOR use Foreman apparently iono\n","750":"hamlet\n","751":"eflow-species\nPISCES species analysis by environmental flow (eflow) type\nPublished versions of Rmd files in github pages branch or at\nhttp:\/\/ucd-cws.github.io\/eflows-species\/eflow-distance.html (for example)\n","752":"eflow-species\nPISCES species analysis by environmental flow (eflow) type\nPublished versions of Rmd files in github pages branch or at\nhttp:\/\/ucd-cws.github.io\/eflows-species\/eflow-distance.html (for example)\n","753":"Environmental Consulting Web Site\nThis project was an attempt to re-create the web site of an environmental consulting firm using Bootstrap. I think it's a big improvement.\n","754":"Environmental-Logger\nLog environmental data such as temperature, pressure, humidity, and ambient light using a Tessel 2. Data is then streamed using socket.io and dygraphs.\nBME280 is on pins 0 and 1, and photoresistor is on pin 7, all on port A.\n","755":"Welcome to GitHub Pages\nYou can use the editor on GitHub to maintain and preview the content for your website in Markdown files.\nWhenever you commit to this repository, GitHub Pages will run Jekyll to rebuild the pages in your site, from the content in your Markdown files.\nMarkdown\nMarkdown is a lightweight and easy-to-use syntax for styling your writing. It includes conventions for\nSyntax highlighted code block\n\n# Header 1\n## Header 2\n### Header 3\n\n- Bulleted\n- List\n\n1. Numbered\n2. List\n\n**Bold** and _Italic_ and `Code` text\n\n[Link](url) and ![Image](src)\nFor more details see GitHub Flavored Markdown.\nJekyll Themes\nYour Pages site will use the layout and styles from the Jekyll theme you have selected in your repository settings. The name of this theme is saved in the Jekyll _config.yml configuration file.\nSupport or Contact\nHaving trouble with Pages? Check out our documentation or contact support and we\u2019ll help you sort it out.\n","756":"\n\n\n\n\n\n\n\n\n\n\nWhat is Svelte?\nSvelte is a new way to build web applications. It's a compiler that takes your declarative components and converts them into efficient JavaScript that surgically updates the DOM.\nLearn more at the Svelte website, or stop by the Discord chatroom.\nDevelopment\nPull requests are encouraged and always welcome. Pick an issue and help us out!\nTo install and work on Svelte locally:\ngit clone https:\/\/github.com\/sveltejs\/svelte.git\ncd svelte\nnpm install\n\nDo not use Yarn to install the dependencies, as the specific package versions in package-lock.json are used to build and test Svelte.\n\nTo build the compiler, and all the other modules included in the package:\nnpm run build\nTo watch for changes and continually rebuild the package (this is useful if you're using npm link to test out changes in a project locally):\nnpm run dev\nThe compiler is written in TypeScript, but don't let that put you off \u2014 it's basically just JavaScript with type annotations. You'll pick it up in no time. If you're using an editor other than Visual Studio Code you may need to install a plugin in order to get syntax highlighting and code hints etc.\nRunning Tests\nnpm run test\nTo filter tests, use -g (aka --grep). For example, to only run tests involving transitions:\nnpm run test -- -g transition\nsvelte.dev\nThe source code for https:\/\/svelte.dev, including all the documentation, lives in the site directory. The site is built with Sapper.\nIs svelte.dev down?\nProbably not, but it's possible. If you can't seem to access any .dev sites, check out this SuperUser question and answer.\nLicense\nMIT\n","757":"\n\n\n\n\n\n\n\n\n\n\nWhat is Svelte?\nSvelte is a new way to build web applications. It's a compiler that takes your declarative components and converts them into efficient JavaScript that surgically updates the DOM.\nLearn more at the Svelte website, or stop by the Discord chatroom.\nDevelopment\nPull requests are encouraged and always welcome. Pick an issue and help us out!\nTo install and work on Svelte locally:\ngit clone https:\/\/github.com\/sveltejs\/svelte.git\ncd svelte\nnpm install\n\nDo not use Yarn to install the dependencies, as the specific package versions in package-lock.json are used to build and test Svelte.\n\nTo build the compiler, and all the other modules included in the package:\nnpm run build\nTo watch for changes and continually rebuild the package (this is useful if you're using npm link to test out changes in a project locally):\nnpm run dev\nThe compiler is written in TypeScript, but don't let that put you off \u2014 it's basically just JavaScript with type annotations. You'll pick it up in no time. If you're using an editor other than Visual Studio Code you may need to install a plugin in order to get syntax highlighting and code hints etc.\nRunning Tests\nnpm run test\nTo filter tests, use -g (aka --grep). For example, to only run tests involving transitions:\nnpm run test -- -g transition\nsvelte.dev\nThe source code for https:\/\/svelte.dev, including all the documentation, lives in the site directory. The site is built with Sapper.\nIs svelte.dev down?\nProbably not, but it's possible. If you can't seem to access any .dev sites, check out this SuperUser question and answer.\nLicense\nMIT\n","758":"EWATEC\nThis is a web-based platform buit on top ODM (observational data model) for sharing environmental data.\nFeatures\nSetup database\nInstall postgresql\n$ sudo sh -c 'echo \"deb http:\/\/apt.postgresql.org\/pub\/repos\/apt\/ `lsb_release -cs`-pgdg main\" >> \/etc\/apt\/sources.list.d\/pgdg.list'\n$ wget -q https:\/\/www.postgresql.org\/media\/keys\/ACCC4CF8.asc -O - | sudo apt-key add -\n$ sudo apt-get update\n$ sudo apt-get install postgresql postgresql-contrib\n\nInstall postgis\nsudo apt-add-repository ppa:ubuntugis\/ubuntugis-unstable\nsudo apt-get update\nsudo apt-get install postgis\n\nConnect to PostgreSQL\n$ sudo su - postgres\n$ psql\n\nSetup virtual environment\n$ virtualenv env\nInstall GDAL in virtualenv\n\nGDAL library must have been installed.\n\nsudo apt-get install libgdal-dev.\n\nNow install Python binding for GDAL.\n\n$ export CPLUS_INCLUDE_PATH=\/usr\/include\/gdal\n$ export C_INCLUDE_PATH=\/usr\/include\/gdal\n$ (env) pip install GDAL==1.11.2\n\nInstall ibfreetype6-dev libxft-dev (for matplotlib)\n$ sudo apt-get install libfreetype6-dev libxft-dev\nInstall gfortran libblas-dev liblapack-dev libatlas-base-dev  (for scipy numpy)\n$ sudo apt-get install gfortran libblas-dev liblapack-dev libatlas-base-dev\nInstall requirements\n$ (env) pip install -r requirements.txt\nSetup gunicorn\nSetup nginx\n","759":"EWATEC\nThis is a web-based platform buit on top ODM (observational data model) for sharing environmental data.\nFeatures\nSetup database\nInstall postgresql\n$ sudo sh -c 'echo \"deb http:\/\/apt.postgresql.org\/pub\/repos\/apt\/ `lsb_release -cs`-pgdg main\" >> \/etc\/apt\/sources.list.d\/pgdg.list'\n$ wget -q https:\/\/www.postgresql.org\/media\/keys\/ACCC4CF8.asc -O - | sudo apt-key add -\n$ sudo apt-get update\n$ sudo apt-get install postgresql postgresql-contrib\n\nInstall postgis\nsudo apt-add-repository ppa:ubuntugis\/ubuntugis-unstable\nsudo apt-get update\nsudo apt-get install postgis\n\nConnect to PostgreSQL\n$ sudo su - postgres\n$ psql\n\nSetup virtual environment\n$ virtualenv env\nInstall GDAL in virtualenv\n\nGDAL library must have been installed.\n\nsudo apt-get install libgdal-dev.\n\nNow install Python binding for GDAL.\n\n$ export CPLUS_INCLUDE_PATH=\/usr\/include\/gdal\n$ export C_INCLUDE_PATH=\/usr\/include\/gdal\n$ (env) pip install GDAL==1.11.2\n\nInstall ibfreetype6-dev libxft-dev (for matplotlib)\n$ sudo apt-get install libfreetype6-dev libxft-dev\nInstall gfortran libblas-dev liblapack-dev libatlas-base-dev  (for scipy numpy)\n$ sudo apt-get install gfortran libblas-dev liblapack-dev libatlas-base-dev\nInstall requirements\n$ (env) pip install -r requirements.txt\nSetup gunicorn\nSetup nginx\n","760":"METEO\nMETEO - Environmental monitoring platform (Final Master Project)\n","761":"METEO\nMETEO - Environmental monitoring platform (Final Master Project)\n","762":"METEO\nMETEO - Environmental monitoring platform (Final Master Project)\n","763":"environmental-science\nMy first website developed using html\/css\/javascript\nCreated following the mozilla foundation getting started with the web tutorial\n","764":"environmental-economics\n\u73af\u5883\u7ecf\u6d4e\u5b66\u7b14\u8bb0\n","765":"\nenvPred \n\n\n\n\n\n\n\n\n\nenvPred is a package that calculates five statistics from\nenvironmental time-series data: seasonality, the colour of environmental\nnoise (hereafter colour), constancy, contingency and predictability.\nSeasonality entails the regularity in the timing and magnitude of\nfluctuations in the average environmental state over seasons. Colour is\ndefined by how predictable and similar the environment is between\nsuccessive time points, or how far into the future the environmental\nstate is likely to stay the same, independent of the mean environmental\nstate. White noise occurs when there is no correlation between one\nmeasurement and the next, while for reddened noise, there is some\ncorrelation between measurements separated by a finite time-scale.\nSeasonality and colour are calculated following the steps described in\nBarneche et\nal.\u00a0(2018).\nWe first remove linear trends by extracting the residuals from a linear\nregression model fitted to the raw time series. Seasonality is estimated\nin two forms: 1) as the \u201cunbounded\u201d fraction of the total variance that\nis due to predictable seasonal periodicities, \u03b1\/\u03b2, where \u03b1 is the\nvariance of the seasonal trend, and \u03b2 is the variance of the residual\ntime series (i.e.\u00a0the time series after the seasonal trend was removed);\nor 2) as the \u201cbounded\u201d fraction of the total variance that is due to\npredictable seasonal periodicities, \u03b1\/(\u03b1\u2005+\u2005\u03b2). The seasonal trend\nis estimated by binning the time-series data into monthly intervals,\naveraging each month across the duration of the time series, then\nre-creating a seasonal time-series dataset on the same time-scale as the\noriginal data using a linear interpolation between the monthly\nmidpoints. To calculate colour, we first calculate a residual time\nseries by subtracting the corresponding seasonal value from each data\npoint in the time series. The spectral density (i.e.\u00a0variance in the\nresidual time series) was assumed to scale with frequency, f,\naccording to an inverse power law, 1\/f\u03b8 (Halley & Kunin,\n1999;\nVasseur & Yodzis,\n2004).\nThe spectral exponent \u03b8 is then estimated as the negative slope of the\nlinear regression of the natural log of spectral density as a function\nof the natural log of frequency. By definition, white noise means that\n\u03b8\u2004=\u20040, and reddened noise means that \u03b8\u2004>\u20040. Spectral density is\nestimated using the\nspectrum\nfunction from the\nstats R\npackage if the time series is evenly distributed, and the Lomb\u2013Scargle\nfunction\nlsp\nfrom the\nlomb R\npackage if the time series is unevenly distributed (Glynn et\nal.\u00a02006).\nSpectral densities and therefore \u03b8 are calculated between the\nfrequencies of 2\/(n\u00a0\u0394\u00a0t) and 1\/(2\u00a0\u0394\u00a0t) (i.e.\u00a0Nyquist\nfrequency), where \u0394\u00a0t is the time gap between consecutive points in\nthe time series, and n is the number of observations in the time\nseries.\nConstancy, contingency and predictability are calculated following\nColwell\n(1974).\nConstancy measures the extent to which the environment is the same for\nall months in all years. Contingency measures the extent to which the\nenvironmental differences between months are the same in all years.\nPredictability is the sum of constancy and contingency. Maximum\npredictability can be attained as a consequence of either complete\nconstancy, complete contingency, or a combination of constancy and\ncontingency.\nInstallation\nThe envPred package can be installed from GitHub using the\ndevtools package using\ndevtools::install_github.\nIf you do not yet have devtools, install with\ninstall.packages(\"devtools\").\nThen install envPred using the following:\nlibrary(devtools)\ninstall_github(\"dbarneche\/envPred\")\nlibrary(envPred)\nAvailable data sources in envPred\nenvPred provides two test datasets for the user to understand the\nbehaviour and output of package functions: sst (Sea Surface\nTemperature), and npp (ocean Net Primary Productivity). The former\ncontains evenly, complete distributed data at a daily interval; the\nlatter contains unevenly, incomplete (i.e.\u00a0missing data) data. Both\nsample datasets were obtained from a random coordinate using the\nnoaaErddap R package:\n\nNet Primary Productivity (NPP)\ndata\nSea Surface Temperature\n(SST)\n\nThe package can be used for any time-series data, e.g.\u00a0temperature,\nrainfall, light intensity, etc.\nAuthors\nDr.\u00a0Diego Barneche (Australian Institute of Marine Science) and\nDr.\u00a0Scott Burgess (Florida State University Tallahassee)\nFurther Information\nFurther information about envPred, including vignettes and help files,\ncan be seen on the on-line project\npage.\nThis R package is provided for use under the MIT License\n(MIT) by the authors.\nBug reporting\nPlease report any issues or\nbugs.\n","766":" Environmental Scanner\nThis is the code repository for an environmentally aware robot, that uses an Arduino Uno to sense the environment using a variety of analog and digital sensors. This data is then sent to a Raspberry Pi, using the serial (USB) connection.\nArduino sketch for a DIY environmental sensor array\nThis comprehensive scanner uses an Arduino Uno, light sensor, water sensor, gas sensor, smoke sensor and hall sensor and to detect light, water, gas, smoke and electromagnetic fields and then sends an alert over USB to a Raspberry Pi. Currently the Raspberry Pi will only display the current status of each sensor, but future releases will allow the Raspberry Pi to use this information to make intelligent decisions based on each sensor.\nUpload the arduino-raspberry.iso to your Arduino Uno. You will need the following sensors for this project:\n\nHall Sensor (KY-003)\nGas and Alcohol Sensor (MQ3)\nLight Sensor (KY-018)\nSmoke Sensor (MQ2)\nWater Level Sensor\n\nUpload the raspberry-arduino.py script to your Raspberry Pi. In your Raspberry Pi interface, be sure to enable Serial and I2C in PiConfig. Restart your Raspberry Pi and execute the following commands:\nsudo apt-get install python-serial\nsudo pip install pyserial\nNext, connect your Arduino to your Raspberry Pi then execute:\nls \/dev\/tty*\nLook for a line with \/dev\/ttyACMO or something similar (an ACM with any number 0, 1, 2, etc.).\nOpen the raspberry-arduino.py script and update the ser=serial.Serial(\"dev\/ttyACM0\",9600) to the ACM number you found. Next, run the raspberry-arduino.py script in Pyhton3. You will see a the status of each sensor in your Python terminal.\n","767":" Environmental Scanner\nThis is the code repository for an environmentally aware robot, that uses an Arduino Uno to sense the environment using a variety of analog and digital sensors. This data is then sent to a Raspberry Pi, using the serial (USB) connection.\nArduino sketch for a DIY environmental sensor array\nThis comprehensive scanner uses an Arduino Uno, light sensor, water sensor, gas sensor, smoke sensor and hall sensor and to detect light, water, gas, smoke and electromagnetic fields and then sends an alert over USB to a Raspberry Pi. Currently the Raspberry Pi will only display the current status of each sensor, but future releases will allow the Raspberry Pi to use this information to make intelligent decisions based on each sensor.\nUpload the arduino-raspberry.iso to your Arduino Uno. You will need the following sensors for this project:\n\nHall Sensor (KY-003)\nGas and Alcohol Sensor (MQ3)\nLight Sensor (KY-018)\nSmoke Sensor (MQ2)\nWater Level Sensor\n\nUpload the raspberry-arduino.py script to your Raspberry Pi. In your Raspberry Pi interface, be sure to enable Serial and I2C in PiConfig. Restart your Raspberry Pi and execute the following commands:\nsudo apt-get install python-serial\nsudo pip install pyserial\nNext, connect your Arduino to your Raspberry Pi then execute:\nls \/dev\/tty*\nLook for a line with \/dev\/ttyACMO or something similar (an ACM with any number 0, 1, 2, etc.).\nOpen the raspberry-arduino.py script and update the ser=serial.Serial(\"dev\/ttyACM0\",9600) to the ACM number you found. Next, run the raspberry-arduino.py script in Pyhton3. You will see a the status of each sensor in your Python terminal.\n","768":"AREA-Website\nA website currently being developed for AREA Environmental.\nMade with Bootstrap, JS, HTML, CSS.\nV1 being the first version to be supplied to the client for changes to be suggested.\nV2 being the currently developed version with the client.\n","769":"Environmental-Forecasting\n","770":"Environmental-Forecasting\n","771":"Environmental-Forecasting\n","772":"#Environmental Health Project\n#more beautiful module design\n#module programming\n","773":"Environmental-Degradation\n","774":"Environmental Statistics\nThis repository is to contain my work for Stat 614 in Spring of 2020.\n","775":"Environmental Statistics\nThis repository is to contain my work for Stat 614 in Spring of 2020.\n","776":"amritsar.today\nReal time environmental data for Amritsar city (Backend + Frontend)\n","777":"PMIS_PCIS\nR scripts used to implement the PMIS and PCIS input variable selection (IVS) algorithms as part of the IVS4EM project described in Galelli et. al. (2014). The PMIS algorithm is a filter IVS method developed by Sharma (2000) and later modified by Bowden et al. (2005) and May et al. (2008), where the relevance of potential inputs is evaluated based on the mutual information (MI) between each input variable and the output. The PCIS algorithm (May et al., 2008) is also a filter IVS method, where input relevance is based on partial correlation analysis. Further details of this particular implementation of these algorithms can be found in:\nGalelli S., Humphrey G.B., Maier H.R., Castelletti A., Dandy G.C. and Gibbs M.S. (2014)  An evaluation framework for input variable selection algorithms for environmental data-driven models, Environmental Modelling and Software, 62, 33-51, DOI: 10.1016\/j.envsoft.2014.08.015. (Link to Paper)\nThe purpose of the IVS4EM project is to support a comprehensive framework for the testing and evaluation of IVS algorithms, through the sharing of algorithms (open source code), datasets, and evalution criteria. (Link to IVS4EM Website)\nContents:\n\nPMI_PCIS.R: code to implement the PMIS and PCIS algorithms.\nPMIS_run.R: run the PMIS algorithm to select the most relevent inputs for a given set of input data.\nPCIS_run.R: run the PCIS algorithm to select the most relevant inputs for a given set of input data.\ninp_dat.csv: an example input data file. Column 1 contains an array of data labels or IDs (e.g. dates on which data were recorded); columns 2 to P+1 contain the P candidate input variables; and column P+2 contains the response variable, while the rows are data points. The first row contains the variable names.\n\nTo run the PMIS algorithm, the following command should be used:\nR --args [filename] [out_dir] < PMI_run.R\nwhere filename is the name of the name of the input data file (including path) and out_dir is the name of the output directory (i.e. the directory to which results will be written. This name should NOT include the whole path). The PCIS algorithm is run similarly.\nSharma, A., 2000. Seasonal to interannual rainfall probabilistic forecasts for improved water supply management: Part 1 - a strategy for system predictor identification. Journal of Hydrology 239, 232-239.\nBowden, G.J., Maier, H.R., Dandy, G.C., 2005. Input determination for neural network models in water resources applications. Part 1. Background and methodology. Journal of Hydrology 301, 75-92.\nMay, R.J., Maier, H.R., Dandy, G.C., Fernando, T.M.K.G., 2008. Nonlinear variable selection for artificial neural networks using partial mutual information. Environmental Modelling & Software 23, 1312-1326.\nCopyright 2014 Greer Humphrey.\n","778":"environmental-configuration\nAdapter to select an appropriate configuration file based on an Environment\nInstall\nnpm install environmental-configuration --save\n\nUsage\nconfig = require('environmental-configuration')('.\/config')\n\n.\/config should be the path to your configuration relative to the file that is calling it. Within that folder, you need to have at least one file called base.json. For your other environments, they need to be named **env**.json.\n","779":"environmental-configuration\nAdapter to select an appropriate configuration file based on an Environment\nInstall\nnpm install environmental-configuration --save\n\nUsage\nconfig = require('environmental-configuration')('.\/config')\n\n.\/config should be the path to your configuration relative to the file that is calling it. Within that folder, you need to have at least one file called base.json. For your other environments, they need to be named **env**.json.\n","780":"environmental-configuration\nAdapter to select an appropriate configuration file based on an Environment\nInstall\nnpm install environmental-configuration --save\n\nUsage\nconfig = require('environmental-configuration')('.\/config')\n\n.\/config should be the path to your configuration relative to the file that is calling it. Within that folder, you need to have at least one file called base.json. For your other environments, they need to be named **env**.json.\n","781":"environmental_law\n","782":"Environmental-Pioneer\n\u4e00\u4e2a\u8ba9\u4f60\u660e\u767d\u5783\u573e\u5206\u7c7b\u7684\u7f51\u7ad9\n\u9879\u76ee\u5f00\u53d1\u56e2\u961f\nUI \u5c0f\u908b\u9062\n\u524d\u7aef marsblue\n\u540e\u7aef Elis_ao\n\u9879\u76ee\u7b80\u4ecb\n\u73b0\u5728\u793e\u4f1a\u8d8a\u6765\u8d8a\u52a0\u91cd\u89c6\u5783\u573e\u56de\u6536\u548c\u5229\u7528\uff0c\u4f46\u4eba\u4eec\u5bf9\u4e8e\u5783\u573e\u7684\u5206\u7c7b\u56de\u6536\u7b49\u77e5\u8bc6\u4e86\u89e3\u7a0b\u5ea6\u4e0d\u9ad8\uff0c\u5bfc\u81f4\u4e86\u6211\u4eec\u7684\u5783\u573e\u6709\u6548\u5206\u7c7b\u7a0b\u5ea6\u4e0d\u9ad8\uff0c\u65e0\u6cd5\u5145\u5206\u6709\u6548\u7684\u5229\u7528\u5783\u573e\u8d44\u6e90\uff0c\u6211\u4eec\u7684\u9879\u76ee\u5c31\u662f\u6293\u4f4f\u4e86\u8fd9\u4e2a\u70b9\uff0c\u5e0c\u671b\u901a\u8fc7\u8fd9\u4e2a\u9879\u76ee\u5bf9\u5927\u5bb6\u7684\u5783\u573e\u5206\u7c7b\u77e5\u8bc6\u8fdb\u884c\u666e\u53ca\uff0c\u63d0\u5347\u56fd\u6c11\u7684\u5bf9\u4e8e\u5783\u573e\u5206\u7c7b\u7684\u8ba4\u77e5\uff0c\u4ece\u800c\u63d0\u5347\u5783\u573e\u5206\u7c7b\u6709\u6548\u6027\uff0c\u4f7f\u5f97\u5783\u573e\u8d44\u6e90\u80fd\u591f\u66f4\u4f4e\u6210\u672c\u7684\u56de\u6536\uff0c\u540c\u65f6\u4fdd\u62a4\u73af\u5883\uff0c\u521b\u5efa\u4e00\u4e2a\u66f4\u7f8e\u597d\u7684\u5730\u7403\u3002\n\u7f51\u7ad9\u7b80\u4ecb\n\u672c\u7ad9\u662f\u81f4\u529b\u4e8e\u63a8\u8fdb\u5783\u573e\u56de\u6536\uff0c\u5ba3\u4f20\u548c\u79d1\u666e\u5783\u573e\u56de\u6536\u77e5\u8bc6\uff0c\u65b9\u4fbf\u5927\u4f17\u8fdb\u884c\u5783\u573e\u5206\u7c7b\u4e3a\u4e00\u4f53\u7684web\u5e73\u53f0\uff0c\u9488\u5bf9\u73b0\u4ee3\u793e\u4f1a\u5bf9\u4e8e\u5783\u573e\u56de\u6536\u7684\u6108\u52a0\u91cd\u89c6\uff0c\u4f46\u5927\u591a\u6570\u7fa4\u4f17\u5bf9\u4e8e\u8fd9\u4e00\u5757\u4e86\u89e3\u8fd8\u662f\u6709\u6240\u6b20\u7f3a\u7684\u73b0\u72b6\uff0c\u672c\u7ad9\u4e13\u95e8\u8bbe\u6709\u5783\u573e\u5206\u7c7b\u79d1\u666e\u77e5\u8bc6\u7684\u677f\u5757\uff0c\u4ecb\u7ecd\u4e86\u4e00\u4e9b\u5e38\u89c1\u5783\u573e\u5206\u7c7b\u7684\u5c0f\u77e5\u8bc6\uff0c\u540c\u65f6\u8fd8\u6709\u4e00\u4e9b\u76f8\u5173\u5783\u573e\u5206\u7c7b\u65b0\u95fb\u7684\u7248\u5757\uff0c\u8fd8\u589e\u8bbe\u4e00\u4e2a\u589e\u5f3a\u5783\u573e\u5206\u7c7b\u77e5\u8bc6\u7684\u5c0f\u6d4b\u8bc4\u529f\u80fd\uff0c\u4ece\u591a\u65b9\u9762\u63a8\u8fdb\u4e86\u5927\u4f17\u5bf9\u4e8e\u5783\u573e\u5206\u7c7b\u7684\u91cd\u89c6\u4e0e\u4e86\u89e3\u3002\nPS\n\u6211\u4eec\u5728GitHub\u4e0a\u5f00\u653e\u6211\u4eec\u7684\u6e90\u4ee3\u7801\u5c31\u662f\u5e0c\u671b\u80fd\u591f\u5f97\u5230\u66f4\u591a\u4eba\u7684\u5efa\u8bae\u4e0e\u6279\u8bc4\uff0c\u5e0c\u671b\u4f60\u7684\u5efa\u8bae\u80fd\u4fc3\u4f7f\u6211\u4eec\u7684\u5f3a\u5927\uff0c\u5982\u679c\u4f60\u5bf9\u6211\u4eec\u7684\u9879\u76ee\u6709\u5174\u8da3\u5e0c\u671b\u52a0\u5165\u6211\u4eec\u7684\u56e2\u961f\u53ef\u4ee5\u5728GitHub\u6216\u8005\u90ae\u7bb1\uff081559830979@qq.com\uff09\u4e0a\u8054\u7cfb\u6211\uff0c\u6211\u4eec\u671f\u5f85\u4f60\u7684\u52a0\u5165\uff01\uff01\n","783":"Environmental-Pioneer\n\u4e00\u4e2a\u8ba9\u4f60\u660e\u767d\u5783\u573e\u5206\u7c7b\u7684\u7f51\u7ad9\n\u9879\u76ee\u5f00\u53d1\u56e2\u961f\nUI \u5c0f\u908b\u9062\n\u524d\u7aef marsblue\n\u540e\u7aef Elis_ao\n\u9879\u76ee\u7b80\u4ecb\n\u73b0\u5728\u793e\u4f1a\u8d8a\u6765\u8d8a\u52a0\u91cd\u89c6\u5783\u573e\u56de\u6536\u548c\u5229\u7528\uff0c\u4f46\u4eba\u4eec\u5bf9\u4e8e\u5783\u573e\u7684\u5206\u7c7b\u56de\u6536\u7b49\u77e5\u8bc6\u4e86\u89e3\u7a0b\u5ea6\u4e0d\u9ad8\uff0c\u5bfc\u81f4\u4e86\u6211\u4eec\u7684\u5783\u573e\u6709\u6548\u5206\u7c7b\u7a0b\u5ea6\u4e0d\u9ad8\uff0c\u65e0\u6cd5\u5145\u5206\u6709\u6548\u7684\u5229\u7528\u5783\u573e\u8d44\u6e90\uff0c\u6211\u4eec\u7684\u9879\u76ee\u5c31\u662f\u6293\u4f4f\u4e86\u8fd9\u4e2a\u70b9\uff0c\u5e0c\u671b\u901a\u8fc7\u8fd9\u4e2a\u9879\u76ee\u5bf9\u5927\u5bb6\u7684\u5783\u573e\u5206\u7c7b\u77e5\u8bc6\u8fdb\u884c\u666e\u53ca\uff0c\u63d0\u5347\u56fd\u6c11\u7684\u5bf9\u4e8e\u5783\u573e\u5206\u7c7b\u7684\u8ba4\u77e5\uff0c\u4ece\u800c\u63d0\u5347\u5783\u573e\u5206\u7c7b\u6709\u6548\u6027\uff0c\u4f7f\u5f97\u5783\u573e\u8d44\u6e90\u80fd\u591f\u66f4\u4f4e\u6210\u672c\u7684\u56de\u6536\uff0c\u540c\u65f6\u4fdd\u62a4\u73af\u5883\uff0c\u521b\u5efa\u4e00\u4e2a\u66f4\u7f8e\u597d\u7684\u5730\u7403\u3002\n\u7f51\u7ad9\u7b80\u4ecb\n\u672c\u7ad9\u662f\u81f4\u529b\u4e8e\u63a8\u8fdb\u5783\u573e\u56de\u6536\uff0c\u5ba3\u4f20\u548c\u79d1\u666e\u5783\u573e\u56de\u6536\u77e5\u8bc6\uff0c\u65b9\u4fbf\u5927\u4f17\u8fdb\u884c\u5783\u573e\u5206\u7c7b\u4e3a\u4e00\u4f53\u7684web\u5e73\u53f0\uff0c\u9488\u5bf9\u73b0\u4ee3\u793e\u4f1a\u5bf9\u4e8e\u5783\u573e\u56de\u6536\u7684\u6108\u52a0\u91cd\u89c6\uff0c\u4f46\u5927\u591a\u6570\u7fa4\u4f17\u5bf9\u4e8e\u8fd9\u4e00\u5757\u4e86\u89e3\u8fd8\u662f\u6709\u6240\u6b20\u7f3a\u7684\u73b0\u72b6\uff0c\u672c\u7ad9\u4e13\u95e8\u8bbe\u6709\u5783\u573e\u5206\u7c7b\u79d1\u666e\u77e5\u8bc6\u7684\u677f\u5757\uff0c\u4ecb\u7ecd\u4e86\u4e00\u4e9b\u5e38\u89c1\u5783\u573e\u5206\u7c7b\u7684\u5c0f\u77e5\u8bc6\uff0c\u540c\u65f6\u8fd8\u6709\u4e00\u4e9b\u76f8\u5173\u5783\u573e\u5206\u7c7b\u65b0\u95fb\u7684\u7248\u5757\uff0c\u8fd8\u589e\u8bbe\u4e00\u4e2a\u589e\u5f3a\u5783\u573e\u5206\u7c7b\u77e5\u8bc6\u7684\u5c0f\u6d4b\u8bc4\u529f\u80fd\uff0c\u4ece\u591a\u65b9\u9762\u63a8\u8fdb\u4e86\u5927\u4f17\u5bf9\u4e8e\u5783\u573e\u5206\u7c7b\u7684\u91cd\u89c6\u4e0e\u4e86\u89e3\u3002\nPS\n\u6211\u4eec\u5728GitHub\u4e0a\u5f00\u653e\u6211\u4eec\u7684\u6e90\u4ee3\u7801\u5c31\u662f\u5e0c\u671b\u80fd\u591f\u5f97\u5230\u66f4\u591a\u4eba\u7684\u5efa\u8bae\u4e0e\u6279\u8bc4\uff0c\u5e0c\u671b\u4f60\u7684\u5efa\u8bae\u80fd\u4fc3\u4f7f\u6211\u4eec\u7684\u5f3a\u5927\uff0c\u5982\u679c\u4f60\u5bf9\u6211\u4eec\u7684\u9879\u76ee\u6709\u5174\u8da3\u5e0c\u671b\u52a0\u5165\u6211\u4eec\u7684\u56e2\u961f\u53ef\u4ee5\u5728GitHub\u6216\u8005\u90ae\u7bb1\uff081559830979@qq.com\uff09\u4e0a\u8054\u7cfb\u6211\uff0c\u6211\u4eec\u671f\u5f85\u4f60\u7684\u52a0\u5165\uff01\uff01\n","784":"Environmental-Game\nEnvironmental game created in 2014 as my independent project at Brooklyn College.\n","785":"\nWhat is CodeIgniter\nCodeIgniter is an Application Development Framework - a toolkit - for people\nwho build web sites using PHP. Its goal is to enable you to develop projects\nmuch faster than you could if you were writing code from scratch, by providing\na rich set of libraries for commonly needed tasks, as well as a simple\ninterface and logical structure to access these libraries. CodeIgniter lets\nyou creatively focus on your project by minimizing the amount of code needed\nfor a given task.\n\nWhat is HMVC\nHMVC stands for Hierarchical Model View Controller application design pattern which makes your application modular. It\ngive you chance to separate the controller, model and view in to some module so you can maintenance or improve the application easily.\n\nServer Requirements\nPHP version 5.6 or newer is recommended.\nIt should work on 5.3.7 as well, but we strongly advise you NOT to run\nsuch old versions of PHP, because of potential security and performance\nissues, as well as missing features.\n\nInstallation\n\nDefault CodeIgniter installation: https:\/\/codeigniter.com\/user_guide\/installation\/index.html\nVia Composer : composer create-project alzen8work\/ci_hmvc\n\n","786":"Environmental-Recycling\n","787":"The main part of the Project was created while the Seadevcon Hackathon was taking place (07. - 08.09.18).\nThe FeatureEngeneering notebook contains the cleaning of the seadevcon table, so there will be no NaN values left in it.\nIn Modelling.ipynb I used Random Forrest algorithm to predict what fuel the ship is using depending on all 81 parameters left. I also used Random Forrest for forecasting and got a high accuracy of predicting on what fuel the ship will be going (up to about) 100 min in the future. But the results should be used with caution! The most relevant features are accRunTime and RunNumber, so the Model is clearly overfitting to the history of this ship and engine. Sadly, while the Hackathon, I did not have the time to correct this and after the Hackathon I had to delete all the data.\nThe Some_Data_Analysis merges Seadevcon and Runlog to give an overview about the use of gas\/gasdiesel\/diesel and heavy oil over the years.\nThe solution I was providing won me 1500 Euro in the Zero Emission challenge at the Seadevcon Hackathon.\nhttp:\/\/seadevcon.com\/challenges-hackathon\/ (Challenge 2)\n","788":"Example sketch for Environmental sensing Workshop on Maker Fest in Novi Sad on 10th June 2018.\nMore info in this doc.\n","789":"environmental-monitoring\nPython\n","790":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","791":"Summary\nThis project consists of simple Atmel ATmega328P based nodes utilizing HopeRF LoRa RFM95W\/RFM96W radios. Battery-powered nodes measure temperature, humidity and barometric pressure, depending on connected hardware. Externally powered pulse type nodes count pulses from different utility meters and also connect to Kamstrup Multical energy meters. Gateway receives and collects these measurements from the sensor nodes and can be accessed by serial communication using Modbus RTU protocol via either two-wire RS-485 or common 3.3 volt UART. This enables interfacing with many DIY home automation systems such as Domoticz, Home Assistant and openHAB. Sensors uses custom circuit boards but is programmed with Arduino IDE.\n\nThis project is a complete package: it includes both hardware designs and software. Schematics contains PCB designs so you can manufacture or order PCBs from a factory and solder the nodes. Software is ready to be uploaded as it is. If you do not want to use the hardware designs provided, you should be able to use, for example, Arduino Pro Minis with protoboards instead. Browse through the .inos and the schematics to find out pin definitions. Remember to take into account battery usage if using Pro Minis or other \"full size\" Arduinos. Also remember that the components used are mostly 3.3 volt tolerant only, so using a 5 volt Uno requires level shifting.\nSkip directly to Instructions, although I strongly recommend reading the whole readme first.\nTable of Contents\n\nExternal requirements\n\nLibraries\nHardware package (core)\n\n\nGateway\n\nModbus registers\n\nGateway specific registers\nBattery powered node specific registers\nPulse node specific registers\nPulse node with Kamstrup Multical 602 energy meter specific registers\n\n\n\n\nNode types\n\nBattery\n\nSupported sensors\n\n\nPulse\nPulse with Kamstrup Multical 602 energy meter\n\n\nRadios\nSchematics and PCB\n\nBOM\n\nGateway \/ Pulse \/ Pulse with Kamstrup Multical\nBattery\n\n\nLEDs\n\nGateway\nBattery\nPulse \/ Pulse with Kamstrup Multical\n\n\nHeaders, terminals and buttons\n\nGateway\nBattery\nPulse \/ Pulse with Kamstrup Multical\n\n\n\n\nInstructions\nVersion history\n\nExternal requirements\nSensors requires a few external components to work: libraries provide functions for radio communications and connected sensors while hardware package handles needed fuses to work with custom boards used by Sensors. Follow carefully especially the instructions regarding RadioHead and Cryptography libraries, as these require a couple of underlying changes.\nLibraries\nRadioHead Packet Radio library for embedded microprocessors provides support for RFM95W\/RFM96W radios (and many others as well). Download from airspayce.com. After extracting the library to your Arduino IDE libraries folder you will have to do one adjustment. In the beginning of RadioHead\/RH_RF95.h change line\n#define RH_RF95_FIFO_SIZE 255\nto\n#define RH_RF95_FIFO_SIZE 64\nCommunication will not work without this change. You also risk running out of SRAM without this adjustment.\nArduino Cryptography Library includes support for encryption. If you do not plan to encrypt traffic, you will not need this library. Download from github.com. You will need to download the ZIP and extract contents of libraries to your Arduino IDE libraries folder. Also remember to uncomment the following line at the very end of RadioHead\/RadioHead.h to enable encryption:\n\/\/#define RH_ENABLE_ENCRYPTION_MODULE\nYou will also need to disable watchdog entropy harvesting by commenting out the following line at the beginning of Crypto\/RNG.cpp because watchdog timer is already used by battery powered nodes:\n#define RNG_WATCHDOG 1      \/\/ Harvest entropy from watchdog jitter.\nIf you are overwhelmed by all this, you may just want not to enable encryption at all. After all, Sensors is not exactly high security system anyway.\nLowPowerLab SI7021 library is needed to work with Silicon Labs Si7021 temperature and humidity sensor. Download from github.com.\nSparkFun BME280 Arduino Library interfaces with Bosch Sensortech BME280 temperature, humidity and barometric pressure sensor. Documentation at github.com. Install using Arduino IDE Library Manager.\nHardware package (core)\nSensors uses a bit different hardware design than regular Arduino boards. For example, battery operated nodes run on internal 1 MHz clock and gateway uses external 8 MHz crystal. They also lack bootloader (although you could use it, hardware just doesn't provide serial pins to burn new firmware using bootloader anyway). Instead, program is flashed using ICSP through ISP header.\nYou could set the necessary fuses manually but it is considerably easier to just use a ready-made hardware package. MCUdude has a nice core specifically to do this. Download MCUdude's MiniCore from github.com.\nGateway\nGateway collects data from nodes and acts as an relay to a Modbus network. By using Maxim Integrated MAX3485 RS-485 transceiver gateway can be connected to an existing RS-485 Modbus RTU network as a slave. Omitting the transceiver provides a direct TTL serial port. This can be accessed with, for example, another Arduino board, FTDI chip or connected directly to a Raspberry Pi. Regardless of the physical connection, gateway is accessed using Modbus protocol. Gateway requires regulated 3.3 volts or (unregulated) 5-12 volts DC power supply. In addition, gateway has three pulse inputs (pulse values are periodically saved to EEPROM and restored on power-up), one of which can be used as an NTC thermistor input. These inputs are also accessible via Modbus.\nOne drawback of Modbus protocol is that a slave can not inform the master of new messages. For this, pulse 2 can be enabled to work as an external interrupt. This pin behaves like an emulated open collector output (external high state voltage is limited to 3.3 volts, however). The pin will be pulled to ground when a message is received either from an important node or any node, depending on the gateway settings. After Modbus read has been done, this pin will be set back to high impedance state.\n\nWarning: UART serial port is 3.3 volts, so don't connect it to a 5 volt system.\nWhy Modbus? Modbus is an easy to use and integrate protocol for this kind of data transfer. Although it is old and somewhat limited in features, it still provides all the necessary things and is widely used in industry. Libraries to access it exist for more or less every platform. Also, most DIY home automation systems (Home Assistant, Domoticz and openHAB to name a few) have Modbus support.\nModbus registers\nRegisters can be accessed using either function code 3 (read holding registers) or 4 (read input registers). Both return the same register values. Note that registers not defined can not be read. For example, trying to read registers 21-99 or 108-199 will return illegal data address exception.\nGateway specific registers\n\n\n\nAddress\nNumber\nName\nType \/ Unit\nNotes\n\n\n\n\n0\n30001\nModbus errors (CRC failed or corrupted)\nCounter\n\n\n\n1\n30002\nModbus overflown frames\nCounter\n\n\n\n2\n30003\nModbus illegal function reads\nCounter\n\n\n\n3\n30004\nModbus illegal address reads\nCounter\n\n\n\n4\n30005\nModbus frames received\nCounter\n\n\n\n5\n30006\nModbus frames sent\nCounter\n\n\n\n6\n30007\nNodes during last hour\nCounter\n\n\n\n7\n30008\nNodes during last 12 hours\nCounter\n\n\n\n8\n30009\nNodes during last 24 hours\nCounter\n\n\n\n9\n30010\nAt least one node low on battery\nBoolean\n\n\n\n10\n30011\nGateway out of memory\nBoolean\n\n\n\n11\n30012\nGateway uptime\nHour\n\n\n\n12\n30013\nFirmware version\n\n8 MSB = major, 8 LSB = minor\n\n\n13\n30014\nStatus\n\nSee below for bits.\n\n\n14\n30015\nPulse 1\nCounter\n32 bit\n\n\n16\n30017\nPulse 2\nCounter\n32 bit\n\n\n18\n30019\nPulse 3 \/ Temperature\nCounter \/ \u00b0C\n32 bit\n\n\n20\n30021\nLast received node ID\n\n\n\n\n\nStatus register bits (from LSB to MSB):\n\nBit 0 External SRAM: 1 if gateway has external SRAM, 0 if using internal SRAM. Affects maximum number of nodes, see notes in Schematics and PCB.\nBit 1-15 Reserved\n\nBattery powered node specific registers\nFirst address is node id * 100. For example, this table shows addresses for a node id 1. Similarly, measurements for node id 2 start at address 200, and so on.\n\n\n\nAddress\nNumber\nName\nType \/ Unit\nNotes\n\n\n\n\n100\n30101\nLast received\nMinute\nWhen was node last seen.\n\n\n101\n30102\nBattery voltage\nmV\nCurrent battery voltage.\n\n\n102\n30103\nTransmit power\n%\nRelative transmit power.\n\n\n103\n30104\nTransmit interval\nMinute\nHow often the node transmits at least.\n\n\n104\n30105\nHeader\n\nOnly 8 LSB, debug data. See below for bits.\n\n\n105\n30106\nTemperature\n\u00b0C\n\u00d710\n\n\n106\n30107\nRelative humidity\nRH%\n\u00d710. Only if node has Si7021 or BME280.\n\n\n107\n30108\nBarometric pressure \/ Temperature\nhPa \/ \u00b0C\n\u00d710. Pressure if node has BME280, temperature if node has both Si7021 and NTC.\n\n\n\nHeader register bits (from LSB to MSB):\n\nBit 0-2 Node type: Internal definiton of the node type.\nBit 3 Reserved\nBit 4 Battery-powered: 1 if node is battery-powered, 0 if powered externally.\nBit 5 Important: 1 if node has declared itself important, 0 if not.\nBit 6-7 Reserved\n\nPulse node specific registers\nFirst address is node id * 100. For example, this table shows addresses for a node id 2. Similarly, measurements for node id 3 start at address 300, and so on.\n\n\n\nAddress\nNumber\nName\nType \/ Unit\nNotes\n\n\n\n\n200\n30201\nLast received\nMinute\nWhen was node last seen.\n\n\n201\n30202\nTransmit power\n%\nRelative transmit power.\n\n\n202\n30203\nTransmit interval\nMinute\nHow often the node transmits at least.\n\n\n203\n30204\nHeader\n\nOnly 8 LSB, debug data. See below for bits.\n\n\n204\n30205\nPulse 1\nCounter\n32 bit\n\n\n206\n30207\nPulse 2\nCounter\n32 bit\n\n\n208\n30209\nPulse 3 \/ Temperature\nCounter \/ \u00b0C\n32 bit\n\n\n\nHeader register bits (from LSB to MSB):\n\nBit 0-2 Node type: Internal definiton of the node type.\nBit 3 Reserved\nBit 4 Battery-powered: 1 if node is battery-powered, 0 if powered externally.\nBit 5 Important: 1 if node has declared itself important, 0 if not.\nBit 6-7 Reserved\n\nPulse node with Kamstrup Multical 602 energy meter specific registers\nFirst address is node id * 100. For example, this table shows addresses for a node id 3. Similarly, measurements for node id 4 start at address 400, and so on.\n\n\n\nAddress\nNumber\nName\nType \/ Unit\nNotes\n\n\n\n\n300\n30301\nLast received\nMinute\nWhen was node last seen.\n\n\n301\n30302\nTransmit power\n%\nRelative transmit power.\n\n\n302\n30303\nTransmit interval\nMinute\nHow often the node transmits at least.\n\n\n303\n30304\nHeader\n\nOnly 8 LSB, debug data. See below for bits.\n\n\n304\n30305\nPulse 1\nCounter\n32 bit\n\n\n306\n30307\nPulse 2\nCounter\n32 bit\n\n\n308\n30309\nPulse 3 \/ Temperature\nCounter \/ \u00b0C\n32 bit\n\n\n310\n30311\nHeat energy\nkWh\n32 bit\n\n\n312\n30313\nActual flow\nl\/h\n32 bit\n\n\n314\n30315\nVolume\nm\u00b3\n\u00d7100. 32 bit\n\n\n316\n30317\nActual power\nkW\n\u00d710. 32 bit\n\n\n318\n30319\nActual t\u2081\n\u00b0C\n\u00d7100. 32 bit\n\n\n320\n30321\nActual t\u2082\n\u00b0C\n\u00d7100. 32 bit\n\n\n\nHeader register bits (from LSB to MSB):\n\nBit 0-2 Node type: Internal definiton of the node type.\nBit 3 Reserved\nBit 4 Battery-powered: 1 if node is battery-powered, 0 if powered externally.\nBit 5 Important: 1 if node has declared itself important, 0 if not.\nBit 6-7 Reserved\n\nNode types\nSensors includes two main types of nodes: battery and pulse. Battery-powered low-power nodes monitor temperature, humidity and pressure. Pulse type nodes are externally powered and count pulses from utility meters. Pulse nodes also support connecting one NTC thermistor for temperature monitoring and RS-485 Modbus RTU. The latter enables the node to be connected to a Kamstrup Multical 602 energy meter.\nBattery\nBattery powered sensors provide simple nodes to monitor temperature, humidity and barometric pressure. These nodes operate on two normal 1.5 volt AA alkaline batteries. If longer lifetime is needed or if node is placed in cold environment, more expensive 1.5 volt AA-size lithium batteries can also be used.\nWarning: Hardware provides no reverse voltage protection in order to conserve power and to keep number of parts minimal, so make sure to observe polarity when inserting batteries or you will destroy the node.\nNodes spend most of the time sleeping, only to wake up to take measurements and send values to gateway. Frequency can be controlled through settings at the beginning of the code file. In threshold mode, nodes wake up periodically and take measurements. If values differ enough from previously sent ones, a message is sent. If not, nodes return to sleep. However, there is a specific force time controlling how often a new message is sent at least regardless of threshold. If a node is not operating in threshold mode, it will send a message every time it wakes up.\n\nSupported sensors\nNodes support three types of sensors: Silicon Labs Si7021, Bosch Sensortech BME280, and a common NTC thermistor. The first one has temperature and humidity, the second one adds barometric pressure, and the latter provides only temperature. A node can have only one kind of sensor, or as a special case both Si7021 and NTC at the same time. PCB provides footprints for all, and the exact type is defined in runtime. That is, every node is flashed with the same software and it checks at bootup what kind of sensor configuration is connected.\nSi7021 sensors can be bought as breakout boards from eBay and similar places for a couple of dollars. When buying the sensor, get one that does not include voltage regulator and I2C level shifting. Battery powered nodes operate on 3.3 volts so Si7021 can be fed directly. Not having (unnecessary) regulator saves battery power. For example, this one is recommended, while this one is not.\nBME280 sensors are also available in eBay, Aliexpress and similar as breakout boards. They are a bit more expensive. These seem not to be available without the onboard regulator, so if you want to lower power consumption, your only option is to remove the regulator. Example image of a removed regulator shown here. This sensor, for example, has been used successfully.\nNote: Chinese sellers sometimes mix the BME280 with earlier and less featured BMP280. Be careful when buying the sensor. Info about this for example here and here.\nNTC thermistors can be purchased from the same places as the other sensors. When buying thermistors, make sure you get three necessary values: nominal resistance, nominal temperature and beta coefficient. For example, this thermistor has been successfully used and works with the default values.\nPulse\nPulse type nodes are intended to measure pulses from a water, electricity, gas or other kind of meter with pulse output. Nodes have three pulse inputs, one of which can be used as an NTC thermistor input instead of a pulse input. Pulse inputs are pulled high internally by microcontroller or with optional external resistors, and connected meter pulls it low to ground. Pulse values are periodically saved to EEPROM and restored on power-up. Pulse nodes require either regulated 3.3 volts or (unregulated) 5-12 volts DC power supply. They use the same PCB as the gateway.\nPulse with Kamstrup Multical 602 energy meter\nThese nodes are regular pulse nodes with added support for Kamstrup Multical 602 energy meter. Node is connected by RS-485 to a Multical 602 energy meter and periodically reads certain values from the meter. See Modbus register listing above for these values.\nNote: Multical 602 seems to be discontinued and replaced by Multical 603. According to datasheet, Multical 603 supports the same Modbus registers as the old 602. Therefore nodes should work with newer 603s but this is untested.\nProtip: Using this node as an example, it should be quite easy to connect some other kind of Modbus RTU capable device to a Pulse type node and adjust code accordingly. This way you can read any other Modbus meters or devices via Sensors nodes.\nRadios\nSensors utilize HopeRF RFM95W and RFM96W LoRa radios. RFM95W is for 868\/915 MHz and RFM96W for 433 MHz. These are cheap low power radios with very good range. Battery nodes use wire or helical antennas, while gateway and pulse nodes have SMA connectors for better performing antennas. Please consider local regulations when choosing frequency range, bandwidth, transmit power and other radio related settings. Nodes automatically adjust transmit power to the lowest possible level.\nAttainable range depends greatly on numerous things but personally I have easily achieved over one kilometer through a reinforced concrete wall and a metal facade. This was between a gateway with a dipole SMA antenna and a battery node with helical antenna. The same setup also reached over 200 meters through buildings in a more built environment. However, as with wireless communication in general, your results will vary.\nNote: On the PCB there is footprint for older HopeRF RFM69HW radio as well. It should work, but it has not been tested and there is currently no support in software for this. Feel free to create a new branch and implement it.\nSchematics and PCB\nFollowing is the table of bill of materials. Not all components are needed, see the notes below for these parts. Majority of the SMD components are 1206 package for easier hand soldering. Gateways and pulse nodes share the same PCB.\nSome notes:\n\nMAX3485 transceiver is needed only if you connect the gateway to an existing RS-485 network. If you use direct UART it is not needed. In this case, remember to also short COMM_JMP at the bottom.\nExternal pull-up resistors are probably not needed in most cases as internal ones in ATmega328P are usually adequate. However, if you are connecting NTC thermistor to pulse 3, remember to solder the 10 kOhm series resistor.\nPulse smoothing capacitors are optional. Use them if you encounter erroneous pulses, ie. too many pulses are counted. For example, I had a rain gauge connected to a pulse input with a rather long cable (about 10 meters running next to mains power supply for part of length). Extra pulses were counted even when no rain had fallen. Adding a 10 uF capacitor removed these wrong measures.\nMIC5209 regulator makes it possible to power the gateway\/pulse node with DC voltage between 5-12 volts (technically up to 16 volts but it might start to get warm). If you can supply the board with regulated 3.3 volts, you can omit the regulator. In this case, also short the PWR_JMP.\nThe Microchip 23K256 SRAM chip is optional. Without it, gateway falls back using its internal SRAM. However, this severely limits the amount of nodes. With the 23K256 gateway supports 100 nodes regardless of type, without it only 10. This varies by node type, however. For example, without external SRAM gateway supports 10 battery nodes, or 5 pulse nodes, or 6 battery nodes plus 2 pulse nodes.\nSMA connector can be omitted and replaced with a wire or a helical antenna if these smaller gain antennas are sufficient. You can also, with some very careful alignment, solder a u.FL connector on to the SMA connector footprint. This allows using a u.FL to SMA pigtail to move the actual SMA connector away.\n\nI have successfully ordered PCBs from Seeed Studio. You can get boards for 10 gateways\/pulse nodes and 10 battery nodes for $9.80 plus postage. Of course any prototype PCB factory will work. PCBs are designed not to have any tight spacings or need for strict tolerances. For gateway and pulse node, select 1.6mm thickness (the enclosure will hold the PCB better). With battery nodes, boards can be thinner (for example 1.2mm works well). Other options should be okay with defaults.\nBoards are designed to fit the enclosures mentioned in the table. Bud Industries DMB-4771 is a 35mm DIN rail mounted box, while Supertronic PP42 is a simple wall mounted enclosure (use double-sided tape). In the schematics folder there is also AP9_holder.stl which is a 3D model of a simple holder to fix a battery node into an ABB AP9 junction box. This is especially handy if you install a node outside and have access to a 3D printer. You will need two holders and a set of small screws. You will also need to have a way to make the box rain-proof but still let humidity and temperature in. Poking some holes into membrane cable entries is one way, or if you want to go professional, use a sintered protective cover. This has been proven to work: a BME280 breakout board will just fit inside if you solder wires to the board as shown here. Remember to wrap the breakout board (but not the sensor itself) with some insulating tape or use heat shrink to prevent short circuits. This image shows an Si7021 breakout board prepared for outdoor sensor use. You will also need to drill off the plastic inside with the connectors of the protective cover. Use some imagination here. A ready-made weatherproofed sensor looks something like this. Connecting an NTC thermistor with sufficiently long wire will make a nice water temperature node as shown here.\nBOM\nGateway \/ Pulse \/ Pulse with Kamstrup Multical\n\n\n\nPart\nValue\nDevice\nPackage\nType\nNotes\n\n\n\n\nC1\n100 nF\nDecoupling capacitor\n1206\nCeramic\n\n\n\nC2\n22 pF\nCrystal capacitor\n1206\nCeramic\n\n\n\nC3\n22 pF\nCrystal capacitor\n1206\nCeramic\n\n\n\nC4\n100 nF\nDecoupling capacitor\n1206\nCeramic\nUsed only with RFM95W \/ RFM96W.\n\n\nC5\n100 nF\nDecoupling capacitor\n1206\nCeramic\nUsed only with RFM69HW.\n\n\nC6\n100 nF\nDecoupling capacitor\n1206\nCeramic\nUsed only with U2 (MAX3485).\n\n\nC7\n1 uF\nPower input capacitor\n1206\nTantalum\n\n\n\nC8\n1 uF\nPower output capacitor\n1206\nTantalum\n\n\n\nC9\n10 uF\nPower output capacitor\n1206\nCeramic\n\n\n\nC10\n100 nF\nDecoupling capacitor\n1206\nCeramic\nUsed only with 23K256.\n\n\nC11\nDepends\nPulse 3 smoothing capacitor\n1206\nCeramic\nUse if erroneous pulses are counted.\n\n\nC12\nDepends\nPulse 2 smoothing capacitor\n1206\nCeramic\nUse if erroneous pulses are counted.\n\n\nC13\nDepends\nPulse 1 smoothing capacitor\n1206\nCeramic\nUse if erroneous pulses are counted.\n\n\nR1\n10 kOhm\nReset pull-up resistor\n1206\n\n\n\n\nR2\n10 kOhm\nRadio slave select pull-up resistor\n1206\n\n\n\n\nR3\n120 Ohm\nRS-485 termination resistor\n1206\n\nUsed only with U2 (MAX3485).\n\n\nR4\nDepends\nPower LED resistor\n1206\n\nSelect value based on LED in use.\n\n\nR5\nDepends\nActivity LED resistor\n1206\n\nSelect value based on LED in use.\n\n\nR6\nDepends\nSerial activity LED resistor\n1206\n\nSelect value based on LED in use.\n\n\nR7\nDepends \/ 10 kOhm\nPulse 3 pull-up \/ NTC series resistor\n1206\n\nUse if ATmega328P internal pull-up resistor is not strong enough, or NTC is to be used.\n\n\nR8\nDepends\nPulse 2 pull-up resistor\n1206\n\nUse if ATmega328P internal pull-up resistor is not strong enough.\n\n\nR9\nDepends\nPulse 1 pull-up resistor\n1206\n\nUse if ATmega328P internal pull-up resistor is not strong enough.\n\n\nR10\n10 kOhm\nSRAM slave select pull-up resistor\n1206\n\nUsed only with 23K256.\n\n\nD1\n\nSerial activity LED\n1206\n\n\n\n\nD2\n\nPower LED\n1206\n\n\n\n\nD3\n\nActivity LED\n1206\n\n\n\n\nY1\n8 MHz\nHC-49US 8 MHz crystal\n\n\n\n\n\nS1\n\nMomentary push button\n3x6 mm\n\nFor example, this one.\n\n\nX1\n\nSMA connector\n\n\nFor example, this one.\n\n\nHeader\n\nISP programming header\n2x3, 0.1\" pitch\n\n\n\n\nHeader\n\nNode ID selection header\n2x5, 0.1\" pitch\n\n\n\n\nHeader\n\nRS-485 terminate and J1 header\n2x2, 0.1\" pitch\n\n\n\n\nScrew terminals\n\nPower, serial, pulse grounds, pulse inputs\n3x2 + 1x3, 5.08mm pitch\n\nFor example, two terminal and three terminal.\n\n\nPWR_JMP\n\nSolder jumper\n1206\n\nShort or use a zero-ohm resistor if not using U4, i.e. board is provided external regulated 3.3 volts.\n\n\nCOMM_JMP\n\nSolder jumper\n\n\nShort if not using U2, i.e. direct UART is used.\n\n\nU1\n\nAtmel ATmega328P microcontroller\nDIP-28\n\nPreferably use a socket.\n\n\nU2\n\nMaxim MAX3485 RS-485 transceiver\nDIP-8\n\nPreferably use a socket. Use only if connected to an RS-485 network.\n\n\nU3\n\nHopeRF RFM95W\/RFM96W\/RFM69HW\n\n\n\n\n\nU4\n\nMicrochip MIC5209-3.3 regulator\nSOT-223\n\nOptional (see notes above).\n\n\nU5\n\nMicrochip 23K256 SRAM\nDIP-8\n\nOptional (see notes above). Preferably use a socket.\n\n\nEnclosure\n\nBud Industries DMB-4771\n\n\n\n\n\n\nBattery\n\n\n\nPart\nValue\nDevice\nPackage\nType\nNotes\n\n\n\n\nC1\n100 nF\nDecoupling capacitor\n1206\nCeramic\n\n\n\nC2\n100 nF\nDecoupling capacitor\n1206\nCeramic\nUsed only with RFM69HW.\n\n\nC3\n100 nF\nDecoupling capacitor\n1206\nCeramic\nUsed only with RFM95W \/ RFM96W.\n\n\nC4\n100 nF\nPower smoothing capacitor\n1206\nCeramic\n\n\n\nC5\n10 uF\nPower smoothing capacitor\n1206\nCeramic\n\n\n\nC6\n100 nF\nDecoupling capacitor\n1206\nCeramic\n\n\n\nR1\nDepends\nActivity LED resistor\n1206\n\nSelect value based on LED in use.\n\n\nR2\n10 kOhm\nReset pull-up resistor\n1206\n\n\n\n\nR3\n10 kOhm\nNTC series resistor\n1206\n\nUse only with NTC.\n\n\nR4\n10 kOhm\nRadio slave select pull-up resistor\n1206\n\n\n\n\nD1\n\nActivity LED\n1206\n\n\n\n\nS1\n\nMomentary push button\n3x6 mm\n\nFor example, this one.\n\n\nAntenna\n\nAntenna for frequency in use, helical or wire\n\n\nFor example, this one.\n\n\nHeader\n\nISP programming header\n2x3, 0.1\" pitch\n\n\n\n\nHeader\n\nNode ID selection header\n2x6, 0.1\" pitch\n\n\n\n\nHeader\n\nJ1 header\n1x2, 0.1\" pitch\n\n\n\n\nU1\n\nAtmel ATmega328P microcontroller\nDIP-28\n\nPreferably use a socket.\n\n\nU2 \/ U3\n\nSi7021 \/ BME280 sensor\n\n\nTwo footprints for different pin orders. See Supported sensors for more info.\n\n\nU4\n\nHopeRF RFM95W\/RFM96W\/RFM69HW\n\n\n\n\n\nNTC\n\nNTC thermistor\n\n\nHeader provided. See Supported sensors for more info.\n\n\nBattery holder\n\nHolder for two AA size batteries\n\n\nFor example, a pair of these.\n\n\nEnclosure\n\nSupertronic PP42\n\n\n\n\n\n\nLEDs\nBoards have a few onboard LEDs to indicate different events. This chapter describes these events. All boards will blink the current running firmware version after power-up.\nGateway\nPWR is lit whenever gateway is powered. L2 blinks when gateway is transmitting in Modbus network. The following table concerns L1.\n\n\n\nBlinks\nInterval\nDescription\nDuring\nNotes\n\n\n\n\n1\n2 sec.\nIllegal ID set.\nStartup\nCheck ID headers and reboot.\n\n\n5\n2 sec.\nFailed to initialize radio.\nStartup\nCheck connections.\n\n\n1\n-\nReceived and saved a message from a node.\nOperation\n\n\n\n2\n-\nReceived a message from a node but memory is full.\nOperation\nAdd external SRAM or lower amount of nodes.\n\n\n3\n-\nSuccessful Modbus read from master.\nOperation\n\n\n\n4\n-\nFailed Modbus read from master.\nOperation\n\n\n\n\nBattery\nBattery nodes have only one LED.\n\n\n\nBlinks\nInterval\nDescription\nDuring\nNotes\n\n\n\n\n1\n2 sec.\nIllegal ID set.\nStartup\nCheck ID headers and reboot.\n\n\n3\n2 sec.\nFailed to initialize a proper sensor configuration.\nStartup\nCheck connections.\n\n\n5\n2 sec.\nFailed to initialize radio.\nStartup\nCheck connections.\n\n\n1\n-\nSuccessful transmit.\nOperation\nOnly in debug mode or forced transmit.\n\n\n2\n-\nFailed transmit.\nOperation\nOnly in debug mode or forced transmit.\n\n\n\nPulse \/ Pulse with Kamstrup Multical\nPulse nodes share the same board as gateway so they also have three LEDs. PWR is lit whenever node is powered. L2 blinks when node is transmitting in Modbus network. The following table concerns L1. Unlike in battery nodes, in pulse nodes L1 blinks always as they are not limited by battery.\n\n\n\nBlinks\nInterval\nDescription\nDuring\nNotes\n\n\n\n\n1\n2 sec.\nIllegal ID set.\nStartup\nCheck ID headers and reboot.\n\n\n5\n2 sec.\nFailed to initialize radio.\nStartup\nCheck connections.\n\n\n1\n-\nSuccessful transmit.\nOperation\n\n\n\n2\n-\nFailed transmit.\nOperation\n\n\n\n3\n-\nSuccessful Modbus read.\nOperation\n\n\n\n4\n-\nFailed Modbus read.\nOperation\n\n\n\n\nHeaders, terminals and buttons\nBoards have a couple of user settable headers. These need to be set before boards are powered. Each device also has one button. In addition, gateway and pulse nodes have screw terminals for power, serial communications and pulse inputs.\nGateway\nHeaders\n\nTERM is 120 Ohm RS-485 termination resistor. Short if the gateway is in the very end of a long RS-485 line.\nJ1 is currently not in normal use. See below for clearing old pulse values from EEPROM.\nNODE ID sets 5 bit Modbus slave address.\n\nButton\nButton in gateway is currently not in use in normal operation. However, if you short J1 and hold the button while powering on the gateway, saved pulse values in EEPROM will be set to zero.\nTerminals\n\n+ and - are the 5-12 volts DC power inputs.\nA\/RX and B\/TX are UART\/RS-485 serial terminals.\nTwo GNDs can be used as grounds for pulse inputs.\nP1 is the pulse 1 input.\nP2 is the pulse 2 input or external interrupt output (active low open drain), depending on the settings.\nP3\/NTC is the pulse 3 input or NTC thermistor input, depending on the settings.\n\nBattery\nHeaders\n\nJ1 marks a node important. When a node declares itself important to gateway, the gateway sets external interrupt pin to inform upstream device of received messages from important nodes.\nNODE ID sets 6 bit address in radio network. Every node has to have a unique address.\n\nButton\nIf button is pressed while applying power, a node is put into debug mode. In this mode, the node sends new values every 8 seconds and also blinks the LED indicating success. Do not use in long-term as this will drain batteries quickly. Power cycle the node to cancel debug mode.\nDuring normal operation button triggers instant send with full power and blinks the LED indicating success. Use to quickly test if the node is within gateway's range.\nPulse \/ Pulse with Kamstrup Multical\nHeaders\n\nTERM is 120 Ohm RS-485 termination resistor. Short if the node is in the very end of a long RS-485 line.\nJ1 marks a node important. When a node declares itself important to gateway, the gateway sets external interrupt pin to inform upstream device of received messages from important nodes.\nNODE ID sets 5 bit address in radio network. Every node has to have a unique address.\n\nButton\nIf button is pressed while applying power, a node is put into debug mode. In this mode, the node sends new values every 8 seconds. Do not use in long-term as this will unnecessarily congest radio network.\nDuring normal operation button triggers instant send with full power. Use to quickly test if the node is within gateway's range. In addition, if you short J1 and hold the button while powering on the node, saved pulse values in EEPROM will be set to zero.\nTerminals\n\n+ and - are the 5-12 volts DC power inputs.\nA\/RX and B\/TX are UART\/RS-485 serial terminals.\nTwo GNDs can be used as grounds for pulse inputs.\nP1 is the pulse 1 input.\nP2 is the pulse 2 input.\nP3\/NTC is the pulse 3 input or NTC thermistor input, depending on the settings.\n\nInstructions\n1. Solder boards\nRefer to Schematics and PCB for detailed instructions and ideas for manufacturing boards. All the chips are through hole packages for easier hand soldering. Smaller components are mostly SMD but they are sufficiently large so that even unexperienced solderers should be able to hand solder them.\n2. Download this repository\nDownload the repository. Place the contents of libraries to your Arduino libraries folder. Also copy SensorsGateway, SensorsBattery and SensorsPulse folders to your Arduino sketchbook.\n3. Install hardware package\nYou can easily install MiniCore using Boards Manager in Arduino IDE. Follow instructions on MiniCore's page.\n4. Install external libraries\nInstall all the necessary external libraries. Refer to Libraries section to further instructions. Pay extra attention to the part regarding cryptographic library if you are using encryption.\n5. Adjust settings\nIn the beginning of each .ino there is a section containing all the necessary settings with good explanations. Adjust the settings as needed. Remember that frequency, encryption key and low rate have to match on every device in the same network or communication will not work.\n6. Burn fuses\nSince Sensors uses very different hardware than ordinary Arduino boards, microcontrollers have to be programmed with some special settings. To do this, you will need an external AVR ISP programmer. Luckily, you can also use another Arduino (Uno or Pro Mini, for example) if you don't have a dedicated ISP programmer available. Follow instructions at Arduino.cc for wiring and burning the ArduinoISP sketch. There is just one catch: whatever you use to program a new board has to be 3.3 volts. ATmega328P is fine with 5 volts, but all other components work at 3.3 volts so supplying the board with 5 volts will most likely burn some or all components. What I suggest is a 3.3 volt version of Arduino Pro Mini or Pro Micro.\nFollow the previously mentioned instructions until you hit Program the bootloader. In Tools > Board and under MiniCore select ATmega328. Select other options as follows:\n\nClock: 1 MHz internal for battery node, 8 MHz external for all others\nBOD: 1.8v for battery node, 2.7v for others\nVariant: 328P \/ 328PA\nCompiler LTO: LTO enabled\nBootloader: No bootloader\nPort: Serial port where the programmer Arduino is connected to\nProgrammer: Arduino as ISP\n\nNext, hit Burn Bootloader. This doesn't actually burn any bootloader since we selected not to use a bootloader, it will only burn the necessary fuses. Keep the two boards still connected since next we will upload the sketch.\n\nNote: This has to be done only once with every new microcontroller. If you later change sketch settings and upload the new sketch, you can skip step 6 and follow directly step 7.\n\n7. Uploading code\nWith still the two boards connected, Arduino IDE board settings as described in step 6 and the actual sketch open, just hit Upload Using Programmer under Sketch. This will upload the sketch like any other Arduino sketch. After this, you are done.\n8. Place the sensors\nPlace your gateway to a central location and connect it to a Modbus capable network. Using the jumper headers, set its Modbus slave address and apply power.\nDistribute other nodes as needed, selecting first their addresses with jumper headers and then connecting external power or batteries. Use the button on the nodes to force a transmit with full power - normally nodes adjust their transmit power automatically to the lowest possible level. One blink of the onboard LED indicates a successful transmit, two blinks a failed one. LED blinks only when forcing a transmit with the button. You can use the provided Python script read_modbus.py to read data from the gateway for debugging purposes.\nStart logging measurements to a MySQL database (save_modbus_to_db.py provides a starting point for this), for example, and graph it with Grafana, or connect the gateway to a home automation hub and monitor measurements that way.\nVersion history\nv1.1.3 (2020-10-14)\n\nFixed number of last seen nodes zeroing after 2^16 minutes. #12\n\nv1.1.2 (2020-06-07)\n\nFixed 23K256 SRAM handler transactions. #8\nFixed initial transmit power of battery and pulse type nodes.\nFixed RFM95W transmit powers to address changes made in the RadioHead library.\n\nv1.1.1 (2020-03-31)\n\nFix and refine NTC sensor reading and calculations in NTCSensor.\nFixed a possible memory allocation error in SensorsSRAMHandler.\nUpdate GPL to version 3 and bump copyright years to 2020.\n\nv1.1.0 (2020-02-15)\n\nPulse 2 in gateways can be configured as an external interrupt (active low open drain) which informs upstream device of a new message. See gateway settings for more information.\nBattery and pulse nodes have a new important mode set by the jumper J1. Setting this mode will trigger gateway to set external interrupt when an important node sends new messages.\nID of the last received node added to gateway Modbus registers.\nChanged some button and header functions. See Headers, terminals and buttons.\n\nv1.0.2 (2020-02-04)\n\nFixed overflow bug in gateway uptime calculation after 45 days.\nAdded image of a wired Si7021 breakout board.\n\nv1.0.1 (2019-12-29)\n\nFixed a bug in NTCSensor library where enable pin was controlled even though it was not in actual use, possibly interfering with serial communication.\n\nv1.0.0 (2019-12-26)\nInitial public release.\n","792":"Environmental Studies\n\nEnvironmental Studies is statically generated with Jekyll and hosted by The College of Liberal Arts at Temple University.\n\n\n\nLinks\n\n\n\n\n\nDevelopment\nhttps:\/\/develop.cla.temple.edu\/environmental-studies\/\n\n\nProduction\nhttps:\/\/www.cla.temple.edu\/environmental-studies\/\n\n\n\nContent Structure\n\n\n\nDirectory\n\n\n\n\n\n_data\/faculty.yaml\nDatafile for list of faculty.\n\n\n_data\/navigation.yaml\nDatafile for primary   navigation links.\n\n\npages\/*\nPage content, in .md or .html format.\n\n\nmedia\/*\nImages, pdfs, and other uploaded static content.\n\n\n_config.yml\nSite configuration options.\n\n\n\nContributing\nIf you discover typographic errors, bugs, or have problems navigating this site please consider opening a new issue. A brief summary of the problem along with suggestions for improvement are welcome.\nPull requests are also welcome if you would like to contribute or edit page content. Prose.io is a quick and convenient way to edit content in Markdown.\n","793":"electric-imp-environmentals\nA demo project to collect, store and chart environmental data from an Electric Imp device using Node.js, Angular and MongoDB.\nRequirements\n\nAn Electric Imp dev kit with an Environmental Tail\nNode.js environment with a MongoDB database.\nKnowledge of Javascript\/Node.js environments\n\nServer Setup\nThe server must be publicly accessible.\n\nnpm update\nbower update\nnode server.js\n\nDevice Setup\n\nLogin at https:\/\/ide.electricimp.com\nRegister your Electric Imp device.\nInstall agent.nut and device.nut.\nUpdate agent.nut for your environment.\n\n\/\/ Begin - Settings\nconst serverUrl = \"http:\/\/yourhost.com\";\nconst WUNDERGROUND_API_KEY = \"xxxxxxxxxx\";\nconst WUNDERGROUND_LOCATION = \"NY\/Albany\";\n\/\/ End - Settings\n\n","794":"electric-imp-environmentals\nA demo project to collect, store and chart environmental data from an Electric Imp device using Node.js, Angular and MongoDB.\nRequirements\n\nAn Electric Imp dev kit with an Environmental Tail\nNode.js environment with a MongoDB database.\nKnowledge of Javascript\/Node.js environments\n\nServer Setup\nThe server must be publicly accessible.\n\nnpm update\nbower update\nnode server.js\n\nDevice Setup\n\nLogin at https:\/\/ide.electricimp.com\nRegister your Electric Imp device.\nInstall agent.nut and device.nut.\nUpdate agent.nut for your environment.\n\n\/\/ Begin - Settings\nconst serverUrl = \"http:\/\/yourhost.com\";\nconst WUNDERGROUND_API_KEY = \"xxxxxxxxxx\";\nconst WUNDERGROUND_LOCATION = \"NY\/Albany\";\n\/\/ End - Settings\n\n","795":"Environmental Monitor\nMy home environmental monitor system.\nBOM\n\nAdafruit HUZZAH32 \u2013 ESP32 Feather Board\nPM2.5 Air Quality Sensor and Breadboard Adapter Kit - PMS5003\nAdafruit Sensirion SHT31-D - Temperature & Humidity Sensor\nAdafruit CCS811 Air Quality Sensor Breakout - VOC and eCO2\n\nLive Monitoring\nAdafruit IO\nWiring\n\nNotes on Sensors\nThis is still WIP, but some early observations.\nCCS811 - eCO2 and VOC\n\nneeds a temperature and humidity measurement to have accuracy.\nthe onboard temperature is no good.\ntends to fluctuate the first 48 hours after startup.\n\nSHT31\n\nHas onboard heater to reduce accumulated condensation\nTemp and Humidity oscillate, symptom of the above?\nFrequency to trigger heater?\n\nPM2.5 Sensor\nHas several readings. Currently using PM standard. Also has environmental and PPM\/0.1L.\nWill it run off the 3.7V battery?\nESP32\nI used some tricks from this article. The ESP32 runs notably cooler\nto the touch with a lower frequency and BT off.\nObservations\nSo far I have tested in my room.\nCO2\nUnfortunately one of my room windows is right below a chimney. We burn natural gas here. There\nare distinct spikes in CO2 detected if this window is open and the boiler is running. There\nare similar rises when the gas stove is in use in the kitchen.\nOvernight C02 levels also rise to around 1500PPM, unless a window is cracked in which case they are around 600-1000PPM.\nWorking from home, I spend easily 18-22 hours a day in my room. Air circulation is quite good and the CO2 levels generally stay\nunder 1000PPM. Nominal values seem to be around 600-800.\nI have 7 house plants; spider, sanservia, bamboo, and pothos varieties. Only two are full size. I'd like to see how watering cycles\nand growth affect CO2, and how quantity of plants affect the rate of drop in CO2.\nPM2.5\nI have a HEPA filter over my AC and a standalone Coway filter. Both seem to keep PM2.5 <0.2.\nI am curious to see how this changes in the winter when only the Coway is running.\n","796":"Environmentalist\n\n\n\nA simple Node.js app to be used with Slack for managing environment occupancy.\nUsage\nPlease see the wiki for quick start tutorial. Wiki contains all the\ndetails how to install and setup the app.\nInstallation\nInstalling environmentalist.js javascript library is super simple. Use the following command in your terminal:\nnpm install environmentalist.js\n","797":"\nEnvironmental-Monitoring\nThis repo contains the open-source environmental monitoring hardware designs detailed in our Low-cost electronic sensors for environmental research: pitfalls and opportunities paper. Designs are included in their individual folders:\n1. Basic versatile logger\n2. Water table depth probe\n3. Air quality logger\n4. Water quality logger\n5. Time-sequencing lake sediment trap\n6. High-frequency measurements of wind-blown sand\nSchematics and build instructions for the Freestation Automated Weather Stations and other specific designs can be found at www.freestation.org\nLicense\nThis work is licensed under a Creative Commons Attribution 4.0 International\nLicense - any use of any material here requires attribution.\nCitation Information:\nChan, K., Schillereff, D., Baas, A., Chadwick, M., Main, B., Mulligan, M., O'Shea, F., Pearce, R., Smith, T.E., van Soesbergen, A., Tebbs, E. and Thompson, J., 2020. Low-cost electronic sensors for environmental research: pitfalls and opportunities. Progress in Physical Geography: Earth and Environment DOI:10.1177\/0309133320956567\n\n","798":"environmental-website\nThis is a front-end page of an environmental website\nENVIRONMENTAL WEBSITE - October 2019- June 2020\nENGLISH :\nCreation of the front page of a website in order to make it look exactly like the template.\nTechnologies used :\n\nCSS3\nHTML5\nJavascript\n\nFRANCAIS :\nLe but de ce projet \u00e9tait de recr\u00e9er \u00e0 l'identique une page d'accueil en suivant un template.\nTechnologies utilis\u00e9es :\n\nCSS3\nHTML5\nJavascript\n\n","799":"Environmental-instrument\nThe Environmental Instrument translates data from its surroundings into frequencies. This project was conceived when my composition class instructor assigned a \"non-standard notation piece that incorporated and element of randomness\". The instrument does this by using three sensors that control separate waveforms.: a light sensor; a temperature sensor,;and a motion sensor. The light sensor controls the most prevalent frequency, meaning that more light will equal higher frequencies, and less light will equal lower frequencies. Similarly, the temperature sensor changes its frequency positively with with increased temperatures, and negatively with decreased temperatures. The pitch, roll, and yaw all control separate frequencies as well. Again, a negative or positive pitch, roll, and yaw, will control the frequencies respectively. These sensors are read and turned into frequencies by using a Teensy 3.2, and the Teensy audio library.\nAn example of this piece being performed can be seen here on my Soundcloud account, Kokonama.\n","800":"\u73af\u5883\u5b89\u9632\u9879\u76ee\n","801":"<<<<<<< HEAD\nEnvironmental-Corrosion\na new project\ndisney\na edu poject.\n\n\n\n\n\n\n\n74284d2f53aad22fc784289ae4d75f3a5f007785\n\n\n\n\n\n\n\n","802":"For project content and some techniqual tools, this project is for for crawling air pollution data (2013-2019) from the web\uff08https:\/\/www.aqistudy.cn\/historydata\/) using selenium and scrapy, including setting up defect logging in scrapy for checking unvisited url links.  P.S. I do not think the air pollution data in this website is highly reliable, because it does not clarify how to average the 24hours data for one day result. I  have some other reliable datasets about air pollution from other web. Welcome to contact me to get it without any commercial purpose. Hope we can do our own contribution to protect our environment.\nIn terms of detailed techniqual issues about missing some urls due to the network environment, like internet speed. Hence, I set up log in the settings.py for the following steps to check which urls I fail to visit.\n","803":"environmental-jeopardy\n","804":"Environmental Sensors\nIn August 4, 2019 I built a circuit using a TMP117 temperature sensor,\nSi7021 Humidity sensor, and SGP30 Air Quality sensor. It displays the\ndata on a 16x2 LCD display. The microcontroller used here is an MSP430G2553.\nI never posted the source code because it didn't seem that useful to\nothers. The code itself is written in assembly and I ended up using a\nsoftware i2c instead of the built-in hardware. I've recently received\nemails asking for the source, so here it is.\nTo build it, it requires naken_asm and the Makefile will need to be\nmodified for your environment (just the path to the include files).\nFor more information on the circuit:\nhttps:\/\/www.mikekohn.net\/micro\/environmental_sensors.php\n","805":"DevSite\nThis is a set of files for a designer to download and begin editing css files for a custom academic design. This would be a good place to put instructions on setting up a new site.\n","806":"Environmental-Day\n","807":"environmental-issues.\n","808":"Environmental-pollution\n","809":"Environmental-pollution\n","810":"HPSNZ Games Environmental Report\nPreparing NSOs for Olympic venue climate using historical data\nPurpose\nThe HPSNZ Performance Physiology team strive to best prepare athletes, coaches and support staff for training and competition performance.\nAn important aspect of their remit is sharing anunderstanding of the environmental conditions they will experience at the Tokyo Olympic and Paralympic Games.\nVenue-specific and date-specific evidence is crucial in this performance preparation. Historical environmental and weather data from the Japanese Meteorological Agency can provide facts to inform campaigns.\nData sources\nThe Japanese Meteorological Agency provides public historical weather observations from stations around the country. Measures of temperature, humidity, rainfall, wind, etc are available for download from the website https:\/\/www.data.jma.go.jp\/risk\/obsdl\/index.php.\nBackground\nDr Julia Casadio created the first Environmental Report ahead of the Rio 2016 Olympic and Paralympic Games. A Tokyo 2020 version of the report was first written in 2018, and subsequently updated in 2019.\nIn lieu of the Tokyo 2020 Games (postponed due to the COVID-19 global pandemic), and at the time of writing, it is prudent to provide an update of 2020 conditions.\nAnalysis\nTo compare Olympic and Paralympic periods in 2020 to prior years, the update report will present the following measures and calculations:\n\nMax day time temperature (deg C)\nRelative humidity at hottest part of the day (%)\nMax day time 'feels like' temperature (deg C)\nPercentage days 'feels like' above 30 deg C (%)\nPercentage days 'feels like' above 35 deg C (%)\nPercentage days 'feels like' above 40 deg C (%)\nTotal rainfall over period (mm)\nNumber of days rainfall above 0mm (# or %)\n? Wind speed\n? Average air pollution\n? Average water pollution\n\nThese will be reported for the following competition venues areas:\n\nEdogawa (Tokyo Bay Zone)\nFuchu (Heritage Zone)\nMobara (Surfing)\nNerima (Shooting)\nTokorozawa (Golf)\nTsujido (Yachting)\nIzu (Cycling & Mountain Bike)\nSapporo (Marathon & Race Walk)\n\nIncluded in the 2020 Update Tokyo Environmental Report will be a figure showing daily maximum 'feels like' temperature during the period, averaged across last 6 years.\nTime periods\nOlympic -- 10 July until 9 August\nParalympic -- 11 August until 6 September\n\nNotes 2020-09-07\nAttendees: Ben, Lorenz\nUpdate meeting to discuss some details of data presentation for report. All data as defined below has been downloaded from the Japanese Meteorological Agency website.\nDATA\n\nYears 2015-2020\nVenues as listed above, plus additional Tokyo Central venue. Izu weather measurements gathered from Ajiro station.\n\nDECISIONS\n\nSplit tables into 1) Olympic lead-in and Games period, and 2) Para lead-in and Games period\nIn each table have 1 column for the years 2016, 2017, 2018, 2019, 2020. Grouping years (e.g. 2015-2017) makes it hard to aggregate individual measures i.e. how would you report humidity over that period? max? avg?\nSeparate the lead-in and Games sub-periods within each period 1 and 2\nRemove wind measure, since sports interested in this would have investigated it further (e.g. Yachting)\nNo new data for air quality or water quality\n\nNEXT STEPS\n\nBen to develop summary tables\nBen to investigate additional charts, and amend line charts to reflect rolling average\n\n\nNotes 2020-07-23\nAttendees: Ben, Lauren, Lorenz\nTabled 2020 update report to be sent out to NSOs after Paralympic period in September. Purpose is to demonstrate 'what we would've experienced this year' BUT FOR the COVID-19 global pandemic.\nDECISIONS\n\nAiming to align the Tokyo Venues Tableau Dashboard with the reported measures in the Environmental Report\nChange day counts (e.g. days temp > 30) to count heat index temperature\n\nNo. Days >= 30\nNo. Days >= 35\n\n\nOmit humidity measures; instead include heat index (to contextualise humidity)\nInclude 2x visuals in this report update\n\nDay by day temp H and temp L for heritage zone and tokyo bay zone (with 1 week prior to Games period, 5 years prior)\nWithin-day temp comparison, demonstrating fluctuations through the day (morning, afternoon, evening - do hourly median temps)\n\n\n\nACTIONS\n\nLK and LK to sketch draft visuals to aim for\nLK and LK to confirm no additional or changed venue locations\nBD to adjust analysis process to account for decisions made\n\n","811":"Envrionmental Justice Project\nDetails:\n\n\nca_cap_trade.sql : SQL file containing create table commands and LOAD DATA commands.\n\n\nwebapp-ENV : Folder containing the flask application files.\n\n\nSTEPS TO RUN\n\n\nInstall docker, DataGrip and clone the https:\/\/github.com\/munners17\/INFO-257-Sp2020 repository.\n\n\nGo to https:\/\/github.com\/munners17\/INFO257-Sp2020\/tree\/master\/lectures\/01-30 for detailed description of how to proceed\nwith creating a container in docker and connecting it with your database on Datagrip.\n\n\nNow, clone this repository and put all the .csv files in path: \/Documents\/Github\/docker\/datadir\n\n\nRun the .sql file  excluding the LOAD DATA LOCAL INFILE statememts on Datagrip console to create schema of your database. Make sure that you are connected to docker at the point and the container is up and running.\n\n\nTo start your container, type in terminal docker start mariadb-diveshop where mariadb-diveshop is your container name.\n\n\nNow we need to load our data. So go to terminal and type : docker exec -it mariadb-diveshop bash\n\n\nNow type : cd home\n\n\nNow type : mysql -u root -p and it will prompt for a password .\n\nEnter the password which you set while making docker container.\n\n\n\nYou are successfully connected to MySQL Command Client . Type in the command use CA_CAP_TRADE;\n\n\nYou can type in SHOW TABLES if you like to know what the schema looks like.\n\n\nAt this point , open the .sql file and down below you will find some statements starting with LOAD DATA LOCAL INFILE\n\n\nCopy these statements onto the MySQL Command Client and run it one by one for each table.\n\nMariaDB[CA_CAP_TRADE]> LOAD DATA LOCAL INFILE ....\n\n\n\nYou must have now loaded all the data and you can see it on Datagrip.\n\n\nNow open the app.py file and change the password field to your password for docker container.\n\n\nNow go into terminal into the directory and type python app.py\n\n$ Environmental-Justice-master\/webapp-ENV> python app.py\n\n\n\nThe server should be up and running on localhost. Open it up on the browser and go ahead to test our app.\n\n\n","812":"Arcpy_Habitat\nScripts for delineating habitat and environmental suitability\n","813":"modulefile\n\n\n\nSearch prefix directory of installed software and generate\nenvironmental modules\nmodulefile.\nInstallation\ngit clone https:\/\/github.com\/UConn-HPC\/modulefile\npip install --user --upgrade --editable modulefile\/\nMake sure that ~\/.local\/bin or similar is in your path per\nPEP 370.\nUsage\nmodulefile \/path\/to\/my\/app\/1.0 > \/path\/to\/my\/modulefile\/dir\/app\/1.0\nTests\nVirtual environments and tests are orchestrated using tox.  Install\ntox using pip:\npip install --user tox\n\nRun all tests using:\ntox\n\nDebug failing tests:\ntox -- --pdb\n\nIf you add dependencies and get import errors, you need to recreate\nthe tox environment:\ntox --recreate\n\nWhen you edit the files, you're likely going to create lots of linter\nerrors caught by the tox unit tests if your text editor doesn't have\ninteractive error reporting.  If you use Emacs, you can configure it\nfor python development by installing\nelpy.\n","814":"Master's thesis\n-- Simultaneous localization and classification of environmental sounds using deep learning techniques --\nAbstract\nThe purpose of the present thesis is the simultaneous classification and localization of\nsounds using bio-inspired computing, including deep learning and binaural recording.\nThis falls within the scope of computational auditory scene analysis, where a machine-\nhearing agent shall identify and localize sounds from its environment.\nThe data is a mixture of binaural recordings related to a fire emergency (alarm, fire\nnoise, people shouting, etc.) along with their related labels (for classification) and\nazimuths (for localization). The extracted features that are fed into the machine-\nhearing agent are similar to these used by the actual auditory system, such as\nratemaps.\nRepresenting sounds mainly by their spectrogram images allows us to train our\ndata on convolutional neural networks, which appear to be particularly suitable for\npattern recognition on images. Appropriate metrics help select and assess the best\narchitectures along with a random search on the hyperparameter space.\nClean sounds can be highly accurately identified (88.8% accuracy) and localized\n(88.7% accuracy). Although mixed sounds identification is also achieved (71.0%\nbalanced accuracy for the best class), their localization has proved a much harder\ntask (60.0% balanced accuracy for the best azimuth). Side conclusions can also be\ndrawn with respect to feature transferability in deep networks, supporting the fact\nthat layers become increasingly more task-specific as depth increases.\nKeywords: bio-inspired artificial intelligence, deep learning, convolutional neural\nnetworks, supervised classification, multitask learning, machine-hearing system.\n","815":"environmental-sensor\nArduino\/ESP8266 project using environmental sensor BME280\n","816":"environmental-sensor\nArduino\/ESP8266 project using environmental sensor BME280\n","817":"Home Environmental\nEste proyecto est\u00e1 enfocado para el desarrollo del control y gesti\u00f3n de sensores, el prop\u00f3sito es el tratamiento de informaci\u00f3n y la recopilaci\u00f3n de datos desde diferentes sensores ambientales.\nEl Proyecto captura los datos por medio del protocolo MQTT, utilizando un Server-Side (nodejs) como mediador, para luego exponerlo en un webservice.\nUtiliza el kit de desarrollo NodeMCU para transmitir los datos y comunicar los sensores con el servidor, este desarrollo esta bajo un mismo lineamiento establecido por una librer\u00eda estandarizada para el dialogo entre el servidor y los nodos.  Los nodos abarcan diferentes sensores, ya que el nodo trabaja bajo el modelo publicador.\n##Dependencias\n\nNodes\nServer\n\nTopologia de la arquitectura\n\n","818":"Envsensor\nEnvironmental Sensor Server. Intended for Raspberry Pi's sampling temperature & humidity from the physical location using DHT11 or DHT22 (\/AM2302) sensors and exposing the realtime data via HTTP.\nThere's two parts to the app, firstly it samples the sensor every so often (configurable) and keeps a record of the latest reading taken.\nThe second part is the webserver, which exposes the data as JSON at \/ and also for Prometheus at \/metrics.\nUsage\nInstall it on your RPi:\nsudo apt install golang\nGOPATH=$HOME\/go go get -u github.com\/caius\/go-envsensor\/cli\/envsensor\nThen you'll want to figure out which GPIO pin your sensor is connected to and which model of sensor you have (DHT22 is more accurate!)\n# DHT22 with data connected to physical pin 12, BCM pin 18, GPIO.1\n$HOME\/go\/bin\/envsensor -sensor-pin 18 -sensor-version 22\nSee init\/systemd.txt for an example Systemd unit file you can use to run it as a service (aka run on boot & restart if it crashes.)\nArchitecture\nThe sensor is sampled in a goroutine, controlled via DHTSensor. (This is split across three files, so it can be developed on a mac without the DHT library installed.) This is kicked off by a time.Ticker channel every delay seconds. Any successful reading is sent into the readings channel.\nThe other half of the process is the webserver, which has a reading stored in a variable and both the endpoint handlers just return the data in that variable. It listens to the readings channel, any reading received is wrapped to a CachedReading which then expires a minute after it was created.\nLicense\nApache 2, see LICENSE for further details.\n","819":"EFD\nThis repository contains course materials from Environmental Fluid Dynamics.\nEFD is an advanced special topics graduate course taught at the University of Utah in the Department of Mechanical Engineering. Students are generally from atmospheric sciences or engineering. The course was originally developed by Dr. Eric Pardyjak.\nThese materials were adapted from Dr. Pardyjak's written notes and were expanded and updated for new content by me. I last taught the course using these materials in Spring 2017.\n","820":"modulefile\n\n\n\nSearch prefix directory of installed software and generate\nenvironmental modules\nmodulefile.\nInstallation\ngit clone https:\/\/github.com\/UConn-HPC\/modulefile\npip install --user --upgrade --editable modulefile\/\nMake sure that ~\/.local\/bin or similar is in your path per\nPEP 370.\nUsage\nmodulefile \/path\/to\/my\/app\/1.0 > \/path\/to\/my\/modulefile\/dir\/app\/1.0\nTests\nVirtual environments and tests are orchestrated using tox.  Install\ntox using pip:\npip install --user tox\n\nRun all tests using:\ntox\n\nDebug failing tests:\ntox -- --pdb\n\nIf you add dependencies and get import errors, you need to recreate\nthe tox environment:\ntox --recreate\n\nWhen you edit the files, you're likely going to create lots of linter\nerrors caught by the tox unit tests if your text editor doesn't have\ninteractive error reporting.  If you use Emacs, you can configure it\nfor python development by installing\nelpy.\n","821":"environmental-monitoring\nan android app that read the luminosity, temperature and humidity values from a teensy via bluetooth\n","822":"Master's thesis\n-- Simultaneous localization and classification of environmental sounds using deep learning techniques --\nAbstract\nThe purpose of the present thesis is the simultaneous classification and localization of\nsounds using bio-inspired computing, including deep learning and binaural recording.\nThis falls within the scope of computational auditory scene analysis, where a machine-\nhearing agent shall identify and localize sounds from its environment.\nThe data is a mixture of binaural recordings related to a fire emergency (alarm, fire\nnoise, people shouting, etc.) along with their related labels (for classification) and\nazimuths (for localization). The extracted features that are fed into the machine-\nhearing agent are similar to these used by the actual auditory system, such as\nratemaps.\nRepresenting sounds mainly by their spectrogram images allows us to train our\ndata on convolutional neural networks, which appear to be particularly suitable for\npattern recognition on images. Appropriate metrics help select and assess the best\narchitectures along with a random search on the hyperparameter space.\nClean sounds can be highly accurately identified (88.8% accuracy) and localized\n(88.7% accuracy). Although mixed sounds identification is also achieved (71.0%\nbalanced accuracy for the best class), their localization has proved a much harder\ntask (60.0% balanced accuracy for the best azimuth). Side conclusions can also be\ndrawn with respect to feature transferability in deep networks, supporting the fact\nthat layers become increasingly more task-specific as depth increases.\nKeywords: bio-inspired artificial intelligence, deep learning, convolutional neural\nnetworks, supervised classification, multitask learning, machine-hearing system.\n","823":"Envsensor\nEnvironmental Sensor Server. Intended for Raspberry Pi's sampling temperature & humidity from the physical location using DHT11 or DHT22 (\/AM2302) sensors and exposing the realtime data via HTTP.\nThere's two parts to the app, firstly it samples the sensor every so often (configurable) and keeps a record of the latest reading taken.\nThe second part is the webserver, which exposes the data as JSON at \/ and also for Prometheus at \/metrics.\nUsage\nInstall it on your RPi:\nsudo apt install golang\nGOPATH=$HOME\/go go get -u github.com\/caius\/go-envsensor\/cli\/envsensor\nThen you'll want to figure out which GPIO pin your sensor is connected to and which model of sensor you have (DHT22 is more accurate!)\n# DHT22 with data connected to physical pin 12, BCM pin 18, GPIO.1\n$HOME\/go\/bin\/envsensor -sensor-pin 18 -sensor-version 22\nSee init\/systemd.txt for an example Systemd unit file you can use to run it as a service (aka run on boot & restart if it crashes.)\nArchitecture\nThe sensor is sampled in a goroutine, controlled via DHTSensor. (This is split across three files, so it can be developed on a mac without the DHT library installed.) This is kicked off by a time.Ticker channel every delay seconds. Any successful reading is sent into the readings channel.\nThe other half of the process is the webserver, which has a reading stored in a variable and both the endpoint handlers just return the data in that variable. It listens to the readings channel, any reading received is wrapped to a CachedReading which then expires a minute after it was created.\nLicense\nApache 2, see LICENSE for further details.\n","824":"Environmental Sensor\nCode for the environmental sensor.\n","825":"EFD\nThis repository contains course materials from Environmental Fluid Dynamics.\nEFD is an advanced special topics graduate course taught at the University of Utah in the Department of Mechanical Engineering. Students are generally from atmospheric sciences or engineering. The course was originally developed by Dr. Eric Pardyjak.\nThese materials were adapted from Dr. Pardyjak's written notes and were expanded and updated for new content by me. I last taught the course using these materials in Spring 2017.\n","826":"EFD\nThis repository contains course materials from Environmental Fluid Dynamics.\nEFD is an advanced special topics graduate course taught at the University of Utah in the Department of Mechanical Engineering. Students are generally from atmospheric sciences or engineering. The course was originally developed by Dr. Eric Pardyjak.\nThese materials were adapted from Dr. Pardyjak's written notes and were expanded and updated for new content by me. I last taught the course using these materials in Spring 2017.\n"}}