{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ry_prepare as p\n",
    "import acquire_ry as a\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import ry_wrangle as w\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = a.get_github2(cached=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GLSL</td>\n",
       "      <td>EnvironmentalVisualEnhancements\\nVisual enhanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PowerShell</td>\n",
       "      <td>dbachecks\\n\\ndbachecks is a framework created ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python</td>\n",
       "      <td>ESC-50: Dataset for Environmental Sound Classi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>Leaflet Environmental Layers (LEL)\\n\\n \\n\\n\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHP</td>\n",
       "      <td>Emoncms\\n\\n\\nEmoncms is an open-source web app...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     language                                            content\n",
       "0        GLSL  EnvironmentalVisualEnhancements\\nVisual enhanc...\n",
       "1  PowerShell  dbachecks\\n\\ndbachecks is a framework created ...\n",
       "2      Python  ESC-50: Dataset for Environmental Sound Classi...\n",
       "3  JavaScript  Leaflet Environmental Layers (LEL)\\n\\n \\n\\n\\n\\...\n",
       "4         PHP  Emoncms\\n\\n\\nEmoncms is an open-source web app..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 827 entries, 0 to 826\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   language  827 non-null    object\n",
      " 1   content   827 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 19.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>content</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>words</th>\n",
       "      <th>doc_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python</td>\n",
       "      <td>ESC-50: Dataset for Environmental Sound Classi...</td>\n",
       "      <td>esc50 dataset environmental sound classificati...</td>\n",
       "      <td>esc50 dataset environment sound classif overvi...</td>\n",
       "      <td>esc50 dataset environmental sound classificati...</td>\n",
       "      <td>[esc50, dataset, environmental, sound, classif...</td>\n",
       "      <td>1313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>Leaflet Environmental Layers (LEL)\\n\\n \\n\\n\\n\\...</td>\n",
       "      <td>leaflet environmental layers lel leaflet plugi...</td>\n",
       "      <td>leaflet environment layer lel leaflet plugin c...</td>\n",
       "      <td>leaflet environmental layer lel leaflet plugin...</td>\n",
       "      <td>[leaflet, environmental, layer, lel, leaflet, ...</td>\n",
       "      <td>1098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python</td>\n",
       "      <td>\\n\\nEARS: Environmental Audio Recognition Syst...</td>\n",
       "      <td>ears environmental audio recognition system ea...</td>\n",
       "      <td>ear environment audio recognit system ear proo...</td>\n",
       "      <td>ear environmental audio recognition system ear...</td>\n",
       "      <td>[ear, environmental, audio, recognition, syste...</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Python</td>\n",
       "      <td>Mycodo\\nEnvironmental Regulation System\\nLates...</td>\n",
       "      <td>mycodo environmental regulation system latest ...</td>\n",
       "      <td>mycodo environment regul system latest version...</td>\n",
       "      <td>mycodo environmental regulation system latest ...</td>\n",
       "      <td>[mycodo, environmental, regulation, system, la...</td>\n",
       "      <td>2447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Python</td>\n",
       "      <td>NO LONGER SUPPORTED\\nEBOWLA\\nUSAGE: ./ebowla.p...</td>\n",
       "      <td>longer supported ebowla usage ebowlapy exedlls...</td>\n",
       "      <td>longer support ebowla usag ebowlapi exedllshel...</td>\n",
       "      <td>longer supported ebowla usage ebowlapy exedlls...</td>\n",
       "      <td>[longer, supported, ebowla, usage, ebowlapy, e...</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     language                                            content  \\\n",
       "2      Python  ESC-50: Dataset for Environmental Sound Classi...   \n",
       "3  JavaScript  Leaflet Environmental Layers (LEL)\\n\\n \\n\\n\\n\\...   \n",
       "5      Python  \\n\\nEARS: Environmental Audio Recognition Syst...   \n",
       "6      Python  Mycodo\\nEnvironmental Regulation System\\nLates...   \n",
       "7      Python  NO LONGER SUPPORTED\\nEBOWLA\\nUSAGE: ./ebowla.p...   \n",
       "\n",
       "                                               clean  \\\n",
       "2  esc50 dataset environmental sound classificati...   \n",
       "3  leaflet environmental layers lel leaflet plugi...   \n",
       "5  ears environmental audio recognition system ea...   \n",
       "6  mycodo environmental regulation system latest ...   \n",
       "7  longer supported ebowla usage ebowlapy exedlls...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "2  esc50 dataset environment sound classif overvi...   \n",
       "3  leaflet environment layer lel leaflet plugin c...   \n",
       "5  ear environment audio recognit system ear proo...   \n",
       "6  mycodo environment regul system latest version...   \n",
       "7  longer support ebowla usag ebowlapi exedllshel...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "2  esc50 dataset environmental sound classificati...   \n",
       "3  leaflet environmental layer lel leaflet plugin...   \n",
       "5  ear environmental audio recognition system ear...   \n",
       "6  mycodo environmental regulation system latest ...   \n",
       "7  longer supported ebowla usage ebowlapy exedlls...   \n",
       "\n",
       "                                               words  doc_length  \n",
       "2  [esc50, dataset, environmental, sound, classif...        1313  \n",
       "3  [leaflet, environmental, layer, lel, leaflet, ...        1098  \n",
       "5  [ear, environmental, audio, recognition, syste...         401  \n",
       "6  [mycodo, environmental, regulation, system, la...        2447  \n",
       "7  [longer, supported, ebowla, usage, ebowlapy, e...         203  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = p.prep_data(df, 'content', extra_words=[], exclude_words=[])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>content</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>words</th>\n",
       "      <th>doc_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HTML</td>\n",
       "      <td>Environmental_Data_Analytics\\nData analytics c...</td>\n",
       "      <td>environmentaldataanalytics data analytics cour...</td>\n",
       "      <td>environmentaldataanalyt data analyt cours duke...</td>\n",
       "      <td>environmentaldataanalytics data analytics cour...</td>\n",
       "      <td>[environmentaldataanalytics, data, analytics, ...</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Java</td>\n",
       "      <td>MinCED - Mining CRISPRs in Environmental Datas...</td>\n",
       "      <td>minced mining crisprs environmental datasets m...</td>\n",
       "      <td>minc mine crispr environment dataset minc prog...</td>\n",
       "      <td>minced mining crisprs environmental datasets m...</td>\n",
       "      <td>[minced, mining, crisprs, environmental, datas...</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Python</td>\n",
       "      <td>Open Simulation Interface (OSI)\\n\\nThe Open Si...</td>\n",
       "      <td>open simulation interface osi open simulation ...</td>\n",
       "      <td>open simul interfac osi open simul interfac 1 ...</td>\n",
       "      <td>open simulation interface osi open simulation ...</td>\n",
       "      <td>[open, simulation, interface, osi, open, simul...</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Python</td>\n",
       "      <td>Community Water Model (CWatM)\\nIIASA\\n13rd Oct...</td>\n",
       "      <td>community water model cwatm iiasa 13rd october...</td>\n",
       "      <td>commun water model cwatm iiasa 13rd octob 2020...</td>\n",
       "      <td>community water model cwatm iiasa 13rd october...</td>\n",
       "      <td>[community, water, model, cwatm, iiasa, 13rd, ...</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>HTML</td>\n",
       "      <td>EnvironmentalGame\\nThis game was developed for...</td>\n",
       "      <td>environmentalgame game developed ' environment...</td>\n",
       "      <td>environmentalgam game develop ' environ scienc...</td>\n",
       "      <td>environmentalgame game developed ' environment...</td>\n",
       "      <td>[environmentalgame, game, developedenvironment...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>environmental-issues.\\n</td>\n",
       "      <td>environmentalissues</td>\n",
       "      <td>environmentalissu</td>\n",
       "      <td>environmentalissues</td>\n",
       "      <td>[environmentalissues]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Java</td>\n",
       "      <td>EnvironmentalProject\\n</td>\n",
       "      <td>environmentalproject</td>\n",
       "      <td>environmentalproject</td>\n",
       "      <td>environmentalproject</td>\n",
       "      <td>[environmentalproject]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python</td>\n",
       "      <td>ESC-50: Dataset for Environmental Sound Classi...</td>\n",
       "      <td>esc50 dataset environmental sound classificati...</td>\n",
       "      <td>esc50 dataset environment sound classif overvi...</td>\n",
       "      <td>esc50 dataset environmental sound classificati...</td>\n",
       "      <td>[esc50, dataset, environmental, sound, classif...</td>\n",
       "      <td>1313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Python</td>\n",
       "      <td>Image Dehazing via Joint Estimation of Transmi...</td>\n",
       "      <td>image dehazing via joint estimation transmitta...</td>\n",
       "      <td>imag dehaz via joint estim transmitt map envir...</td>\n",
       "      <td>image dehazing via joint estimation transmitta...</td>\n",
       "      <td>[image, dehazing, via, joint, estimation, tran...</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>Java</td>\n",
       "      <td>software-engineering\\nProgetto\\n</td>\n",
       "      <td>softwareengineering progetto</td>\n",
       "      <td>softwareengin progetto</td>\n",
       "      <td>softwareengineering progetto</td>\n",
       "      <td>[softwareengineering, progetto]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       language                                            content  \\\n",
       "26         HTML  Environmental_Data_Analytics\\nData analytics c...   \n",
       "36         Java  MinCED - Mining CRISPRs in Environmental Datas...   \n",
       "35       Python  Open Simulation Interface (OSI)\\n\\nThe Open Si...   \n",
       "156      Python  Community Water Model (CWatM)\\nIIASA\\n13rd Oct...   \n",
       "546        HTML  EnvironmentalGame\\nThis game was developed for...   \n",
       "..          ...                                                ...   \n",
       "807  JavaScript                            environmental-issues.\\n   \n",
       "192        Java                             EnvironmentalProject\\n   \n",
       "2        Python  ESC-50: Dataset for Environmental Sound Classi...   \n",
       "308      Python  Image Dehazing via Joint Estimation of Transmi...   \n",
       "635        Java                   software-engineering\\nProgetto\\n   \n",
       "\n",
       "                                                 clean  \\\n",
       "26   environmentaldataanalytics data analytics cour...   \n",
       "36   minced mining crisprs environmental datasets m...   \n",
       "35   open simulation interface osi open simulation ...   \n",
       "156  community water model cwatm iiasa 13rd october...   \n",
       "546  environmentalgame game developed ' environment...   \n",
       "..                                                 ...   \n",
       "807                                environmentalissues   \n",
       "192                               environmentalproject   \n",
       "2    esc50 dataset environmental sound classificati...   \n",
       "308  image dehazing via joint estimation transmitta...   \n",
       "635                       softwareengineering progetto   \n",
       "\n",
       "                                               stemmed  \\\n",
       "26   environmentaldataanalyt data analyt cours duke...   \n",
       "36   minc mine crispr environment dataset minc prog...   \n",
       "35   open simul interfac osi open simul interfac 1 ...   \n",
       "156  commun water model cwatm iiasa 13rd octob 2020...   \n",
       "546  environmentalgam game develop ' environ scienc...   \n",
       "..                                                 ...   \n",
       "807                                  environmentalissu   \n",
       "192                               environmentalproject   \n",
       "2    esc50 dataset environment sound classif overvi...   \n",
       "308  imag dehaz via joint estim transmitt map envir...   \n",
       "635                             softwareengin progetto   \n",
       "\n",
       "                                            lemmatized  \\\n",
       "26   environmentaldataanalytics data analytics cour...   \n",
       "36   minced mining crisprs environmental datasets m...   \n",
       "35   open simulation interface osi open simulation ...   \n",
       "156  community water model cwatm iiasa 13rd october...   \n",
       "546  environmentalgame game developed ' environment...   \n",
       "..                                                 ...   \n",
       "807                                environmentalissues   \n",
       "192                               environmentalproject   \n",
       "2    esc50 dataset environmental sound classificati...   \n",
       "308  image dehazing via joint estimation transmitta...   \n",
       "635                       softwareengineering progetto   \n",
       "\n",
       "                                                 words  doc_length  \n",
       "26   [environmentaldataanalytics, data, analytics, ...          74  \n",
       "36   [minced, mining, crisprs, environmental, datas...         219  \n",
       "35   [open, simulation, interface, osi, open, simul...         259  \n",
       "156  [community, water, model, cwatm, iiasa, 13rd, ...         245  \n",
       "546  [environmentalgame, game, developedenvironment...           9  \n",
       "..                                                 ...         ...  \n",
       "807                              [environmentalissues]           1  \n",
       "192                             [environmentalproject]           1  \n",
       "2    [esc50, dataset, environmental, sound, classif...        1313  \n",
       "308  [image, dehazing, via, joint, estimation, tran...         167  \n",
       "635                    [softwareengineering, progetto]           2  \n",
       "\n",
       "[234 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_exp, X_train, y_train, X_validate, y_validate, X_test, y_test = w.split(df,'language')\n",
    "train_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.language.value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove_lang_list = ['CoffeeScript','Other','Go','Stata','Lua','Kotlin','Objective-C','Shell','Vim script','Batchfile','Swift','PowerShell','Vue', 'Mathematica','TypeScript']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[~df.language.isin(remove_lang_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234, 6)\n",
      "(79, 6)\n",
      "(79, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_validate.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['access',\n",
       " 'add',\n",
       " 'allows',\n",
       " 'analysis',\n",
       " 'api',\n",
       " 'app',\n",
       " 'application',\n",
       " 'available',\n",
       " 'based',\n",
       " 'build',\n",
       " 'cd',\n",
       " 'change',\n",
       " 'check',\n",
       " 'class',\n",
       " 'clone',\n",
       " 'code',\n",
       " 'command',\n",
       " 'config',\n",
       " 'configuration',\n",
       " 'contains',\n",
       " 'control',\n",
       " 'copy',\n",
       " 'create',\n",
       " 'created',\n",
       " 'creating',\n",
       " 'current',\n",
       " 'data',\n",
       " 'database',\n",
       " 'default',\n",
       " 'dependencies',\n",
       " 'description',\n",
       " 'designed',\n",
       " 'details',\n",
       " 'developed',\n",
       " 'development',\n",
       " 'different',\n",
       " 'directory',\n",
       " 'documentation',\n",
       " 'download',\n",
       " 'end',\n",
       " 'environment',\n",
       " 'environmental',\n",
       " 'example',\n",
       " 'features',\n",
       " 'file',\n",
       " 'files',\n",
       " 'folder',\n",
       " 'following',\n",
       " 'free',\n",
       " 'git',\n",
       " 'git clone',\n",
       " 'github',\n",
       " 'help',\n",
       " 'image',\n",
       " 'include',\n",
       " 'including',\n",
       " 'information',\n",
       " 'input',\n",
       " 'install',\n",
       " 'installation',\n",
       " 'installed',\n",
       " 'instructions',\n",
       " 'interface',\n",
       " 'license',\n",
       " 'like',\n",
       " 'line',\n",
       " 'list',\n",
       " 'local',\n",
       " 'location',\n",
       " 'look',\n",
       " 'make',\n",
       " 'make sure',\n",
       " 'model',\n",
       " 'module',\n",
       " 'monitoring',\n",
       " 'multiple',\n",
       " 'need',\n",
       " 'needs',\n",
       " 'new',\n",
       " 'note',\n",
       " 'number',\n",
       " 'object',\n",
       " 'open',\n",
       " 'order',\n",
       " 'output',\n",
       " 'page',\n",
       " 'pip',\n",
       " 'pip install',\n",
       " 'process',\n",
       " 'program',\n",
       " 'project',\n",
       " 'projects',\n",
       " 'provide',\n",
       " 'provided',\n",
       " 'provides',\n",
       " 'public',\n",
       " 'python',\n",
       " 'read',\n",
       " 'repository',\n",
       " 'request',\n",
       " 'required',\n",
       " 'requirements',\n",
       " 'research',\n",
       " 'results',\n",
       " 'run',\n",
       " 'running',\n",
       " 'script',\n",
       " 'search',\n",
       " 'sensor',\n",
       " 'sensors',\n",
       " 'server',\n",
       " 'service',\n",
       " 'set',\n",
       " 'setup',\n",
       " 'simple',\n",
       " 'software',\n",
       " 'source',\n",
       " 'specific',\n",
       " 'start',\n",
       " 'sudo',\n",
       " 'support',\n",
       " 'sure',\n",
       " 'temperature',\n",
       " 'test',\n",
       " 'time',\n",
       " 'tool',\n",
       " 'tools',\n",
       " 'update',\n",
       " 'usage',\n",
       " 'use',\n",
       " 'used',\n",
       " 'user',\n",
       " 'uses',\n",
       " 'using',\n",
       " 'value',\n",
       " 'values',\n",
       " 'version',\n",
       " 'want',\n",
       " 'way',\n",
       " 'web',\n",
       " 'work',\n",
       " 'working']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create CountVectorizer, which create bag-of-words model.\n",
    "# stop_words : Specify language to remove stopwords. \n",
    "# min_df: ignore terms that have a document frequency strictly \n",
    "# lower than the given threshold. This value is also called cut-off in the literature. \n",
    "# If float, the parameter represents a proportion of documents, integer absolute counts. \n",
    "# ngram_range: the lower and upper boundary of the range of n-values for \n",
    "# different word n-grams or char n-grams to be extracted. \n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english', \n",
    "                             min_df=20, \n",
    "                             ngram_range=(1,2), \n",
    "                             binary=True)\n",
    "\n",
    "# Learn vocabulary in sentences. \n",
    "vectorizer.fit(X_train.clean)\n",
    "\n",
    "# Get dictionary. \n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform each sentences in vector space.\n",
    "bow = vectorizer.transform(X_train.clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is just to see the array of 0's and 1's\n",
    "bow_array = bow.toarray()\n",
    "bow_array[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environmentaldataanalytics data analytics course duke university course code env 872l user kateri salk instructions using repository fork repository github account clone forked repository onto local drive pull updates repository add repository upstream remote git remote add upstream httpsgithubcomkaterisalkenvironmentaldataanalytics verify repository upstream remote git remote v repository listed origin repository listed upstream pull updates repository git pull upstream master git fetch upstream git merge upstreammaster conflict arises merge update files liking stage commit testing merge error taylor\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0]\n",
      "minced mining crisprs environmental datasets minced program find clustered regularly interspaced short palindromic repeats crisprs full genomes environmental datasets assembled contigs metagenomes iff want identify crisprs raw short read data size range 100200bp try using crass httpsgithubcomctskennertoncrass minced runs commandline derived crt httpwwwroom220comcrt charles bland et al crispr recognition tool crt tool automatic detection clustered regularly interspaced palindromic repeats bmc bioinformatics 8 1 2007 209 installation need install dependencies first java httpwwwjavacomendownload makefile source directory installation simple cd downloadfolder make run minced minced options filefa help page obtained typing minced help get minced version way minced version note always keep minced mincedjar folder examples finding crisprs e coli genome minced ecolifna find repeats short sequences need decrease minimum number repeats find example 100 bp reads could possibly find 2 repeats minced minnr 2 metagenomefna output large save file minced minnr 2 metagenomefna metagenomecrisprs also save table output gff output time minced ecolifna outtxt outgff copyright license copyright 2011 florent angly florentanglygmailcom 20132019 connor skennerton cskennertongmailcom minced free software redistribute andor modify terms gnu general public license published free software foundation either version 3 license option later version minced distributed hope useful without warranty without even implied warranty merchantability fitness particular purpose see gnu general public license details received copy gnu general public license along minced see httpwwwgnuorglicenses bugs complex software bugs lurking program exception find bug please post issue github httpsgithubcomctskennertonmincedissues\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1\n",
      " 0 0 0 0 1 1 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0]\n",
      "open simulation interface osi open simulation interface 1 osi generic interface based google ' protocol buffers environmental perception automated driving functions virtual scenarios complexity automated driving functions rapidly increases requirements test development methods growing testing virtual environments offers advantage completely controlled reproducible environment conditions context osi defines generic interfaces ensure modularity integrability interchangeability individual components information osi see official documentation official reference documentation defined protobuf messages 1 hanke hirsenkorn n vandriesten c garciaramos p schiementz schneider biebl e 2017 february 03 generic interface environment perception automated driving functions virtual scenarios retrieved january 25 2020 httpswwwhoteitumdeforschungautomotiveveroeffentlichungen usage example writing reading osi message python osi3osisensorviewpb2 import sensorview osi3osisensordatapb2 import sensordata def main initialize sensorview sensordata sensorview sensorview sensordata sensordata clear sensordata sensordataclear get boundary line attributes sensorview svgroundtruth sensorviewglobalgroundtruth svlaneboundary svgroundtruthlaneboundaryadd svboundaryline svlaneboundaryboundarylineadd svboundarylinepositionx 169920 svboundarylinepositiony 10016 svboundarylinepositionz 00 svboundarylinewidth 013 svboundarylineheight 00 set boundary line attributes sensordata sdlaneboundary sensordatalaneboundaryadd sdboundaryline sdlaneboundaryboundarylineadd sdboundarylinepositionx svboundarylinepositionx sdboundarylinepositiony svboundarylinepositiony sdboundarylinepositionz svboundarylinepositionz sdboundarylinewidth svboundarylinewidth sdboundarylineheight svboundarylineheight serialize sensordata send stringbuffer sensordataserializetostring clear sensordata show parsing string sensordataclear received string buffer parsed sensordataparsefromstringstringbuffer print sensordata printsensordata name main main output laneboundary boundaryline position x 16992 10016 z 00 width 013 height 00 see google ' documentation tutorials use protocol buffers python c installation dependencies install cmake 3102 sudo aptget install cmake install pip3 missing python packages sudo aptget install python3pip python3setuptools install protobuf 300 sudo aptget install libprotobufdev protobufcompiler build install c usage git clone httpsgithubcomopensimulationinterfaceopensimulationinterfacegit cd opensimulationinterface mkdir build cd build cmake make sudo make install install python usage local git clone httpsgithubcomopensimulationinterfaceopensimulationinterfacegit cd opensimulationinterface sudo pip3 install virtualenv virtualenv p python3 venv source venvbinactivate python3 pip install global git clone httpsgithubcomopensimulationinterfaceopensimulationinterfacegit cd opensimulationinterface sudo pip3 install windows installation see information\n",
      "[0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "community water model cwatm iiasa 13rd october 2020 cwatm represents one new key elements iiasaas water program assess water supply water demand environmental needs global regional level hydrologic model open source flexible link different aspects water energy food nexus cwatm basis develop nextgeneration global hydroeconomic modeling coupled existing iiasa models like message globiom httpwwwiiasaacatcwatm model design processes included community water model cwatm designed purpose assess water availability water demand environmental needs includes accounting future water demands evolve response socioeconomic change water availability change response climate figure 1 schematic view cwatm processes modules hydrological processes eg snow soil groundwater etc located folder hydrologicalmodules kinematic routing c routines speeding computational time folder hydrologicalmodulesroutingreservoirs figure 2 schematic graph cwatm modules nextgeneration global hydroeconomic modeling framework community water model help develop nextgeneration hydroeconomic modeling tool represents economic tradeoffs among water supply technologies demands tool track water use sectors identify leastcost solutions meeting future water demands policy constraints addition tool track energy requirements associated water supply system eg desalination water conveyance facilitate linkage energyeconomic tool tool also incorporate environmental flow requirements ensure sufficient water environmental needs nexus framework iiasa nexus framework water energy food ecosystem cwatm coupled existing iiasa models including integrated assessment model message global land ecosystem model globiom order realize improved assessments waterenergyfoodecosystem nexus associated feedback figure 3 iiasa model nexus short medium vision vision short medium term work introduce water quality eg salinization deltas eutrophication associated mega cities cwatm consider qualitative quantitative measures transboundary river groundwater governance integrated modelling framework link full model documentation httpscwatmiiasaacat\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "environmentalgame game developed ' environment sciences ' class universidade federal rio grande brazil\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "people feel shipping json yml xml config files upgrade using archaic environment variables ' let app load config inject instead unix environment vars ideal configuration yet encounter application ' better override value nearruntime without changebackup config files debug node runjs inject environment variables passwords api keys memory process belonging nonprivileged user source envsproductionsh sudo ehu wwwdata node runjs without run write software inherit inside stagingsh source productionsh inside kevinsh source developmentsh operating system aware provides tools inspect debug optionally pass processes etc directly use config across languages eg supporting bash scripts directly use config terminal eg cd myappdir type config groupsave files keep version control one downside environment variables little convention syntactic sugar highlevel languages ' feel atomic think ' likely let module attempts change environmental ' break 12factor get way environmental impose one way dealing environment variables make vars available nested format inside app eg myappredishost becomes configredishost 3 unix interpret multiple inherited bash environment files isolated environment capture prepare exporting nodejitsu heroku conventions layout environmental tree defaultsh developmentsh testsh productionsh stagingshsh disk envs defaultsh developmentsh productionsh stagingsh testsh could make superdry actually recommend using mainly developmentsh productionsh duplicate keys easily compare side side use defaultsh testsh stagingsh tweaks keep things clear read ' inheritance bitch ' see inheritance bitch one common pitfall reuse variables export mysqlhost127001 export mysqlurlmysqluserpassmysqlhostdbname extend override mysqlhost obviously mysqlurl remain unaware host change ergo duplication vars might lesser evil compared going way dry things inject features instead code make decisions based environment processenvnodeenv production install cronjobs keep responsibility environment files cat envsdefaultsh tlscronjobsinstall0 cat envsproductionsh tlscronjobsinstall1 configcronjobsinstall 1 install cronjobs mandatory unprefixed variables variables mandatory special meaning syntactic sugar access via processenvvar export nodeappprefixmyapp filter nest vars starting myapp right app export nodeenvproduction environment program thinks ' running export deployenvstaging machine actually running export debug used control debug levels per module getting way feel free start hacking prefixing vars myapp actual short abbreviation app name ' use underscore name example tls app name export nodeappprefixtls export tlsredishost127001 export tlsredisuserjane getting started new project type npm install save environmental install node module next ' want set example environment shown layout using templates cp ra nodemodulesenvironmentalenvs envs add envssh project ' gitignore file accidentally committed repository env files git convenient ' still protoyping go live ' want change credentials sync env files separately code accessing config inside app start app ways source envsdevelopmentsh node myappjs source envsproductionsh debug node myappjs source envsstagingsh following seems weird sudo preserve path regardless e sudo ehu wwwdata env pathpath node myappjs source envsdevelopmentsh node myappjs start myapp see upstart example inside app obviously already access processenvmyappredishost environmental also provides syntactic sugar could type configredishost instead ' var config require ' environmental ' config consolelogconfig return redis host ' 127001 ' coffeescript ' cup tea config requireenvironmentalconfig redisclient rediscreateclientconfigredisport configredishost see underscore env var names signifies new nesting level configuration remaining keys lowercased config takes two arguments flat defaulting processenv filter defaulting processenvnodeappprefix changing allow inject reload environment variables capturing specific config file default environmental code capture environment variables current process however also use capture variables isolation produced gives shell file works inherits env new environmental envcapture dirnameenvsproductionsh err flat expecterrtobenull expectflatmyappredishost 127001 notice nest configuration using config method passing flat environment vars config environmentalconfig flat myapp expectconfigtodeepequal redis host 127001 exporting nodejitsu nodejitsu also works environment variables since hard ship want bundle json file environmental create temporary json file commandline example figures vars envsproductionsh even inherits files nodemodulesbinenvironmental fileenvsproductionsh formatjson tmpjitsuenvjson jitsu confirm env load tmpjitsuenvjson jitsu confirm deploy rm tmpjitsuenvjson exporting heroku heroku configset nodemodulesbinenvironmental fileenvsproductionsh formatspace exporting servers generate single file server source nodemodulesbinenvironmental fileenvsproductionsh formatnewline note different source envsproductionsh env output cleansed environment variable declared envproductionsh one ' ancestors could use list inject process upon restarts save file upstart inject nonprivileged process use eg rsync distribute amongst privileged users host echo myappsshhosts rsync recursive links perms times devices specials progress envs hostmyappdirenvs done injecting nonprivileged user process deploy app production run servers might want use upstart respawn process crashes ' upstart file etcinitmyapp could look like root user injects environment keys process memory unpriviliged user big security advantage program cannot even read credentials disk stop runlevel 016 start started networking respawn respawn limit 10 5 limit nofile 32768 32768 prestop exec status myapp grep q stopwaiting initctl emit nowait stopped jobmyapp true script exec bash c cd srvmyappcurrent chown root envssh chmod 600 envssh source envsproductionsh exec sudo ehu wwwdata make start 21 end script todo offer better ways syncing config without git means requiring vars particular environments failing hardearly better compact consise api language tests integrate heroku export target sponsor development like project consider donation ' surprised rewarding see someone spend actual money efforts even 1\n",
      "[1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0 0 1\n",
      " 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1\n",
      " 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1 0 0 0]\n",
      "earth genome environmental data decision making dan hammer chief data scientist earth genome jeff chen chief data scientist us department commerce part commerce data usability project earth genome collaboration commerce data service created tutorial guide though processing visualizating digital elevation model data question feel free reach commerce data service datadocgov earth genome danearthgenomeorg\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "wildlife tracker java spark app forest service conduct environmental impact study technologies frameworks used 1 java 11 2 spark core 212 3 gradle 410 4 spark template velocity 5 junit 5 6 postgres database database psql create table animalsid serial primary keyhealth varchar age varchar type varcharname varchar create table locationsid serial primary key name varchar create table rangersid serial primary key firstname varchar lastname varchar badgenumber int create table sightingsid serial primary key ranger varchar location varchar animalid int testing gradle test screenshots homepage comprises list rangers registered system page displays table sigthings table animals displayed new animals added system table displays available locations forest locations added license\n",
      "[0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "virocon viroconweb virocon software compute environmental contours viroconweb package belonging software virocon using web framework django provides browserbased graphical user interface virocon helps design marine structures need withstand load combinations based wave wind current lets define extreme environmental conditions given return period using environmental contour method following methods available viroconweb additonal methods available viroconcom fitting probabilistic model measurement data using maximum likelihood estimation defining probabilistic model conditonal modeling approach cma computing environmental contour using either inverse first order reliability method iform highest density contour hdc method virocon written python 364 software seperated two main packages viroconweb viroconcom repository viroconweb web application written web framework django 111 second package viroconcom handles statistical computations repository use virocon requirements make sure installed python 364 even python 35 ' work consider using python version management pyenv git latex install run copy virocon locally fist clone repository typing git clone httpsgithubcomviroconorganizationviroconweb shell install required python packages prepare webapplication type cd viroconweb pip install r requirementstxt python managepy collectstatic python managepy migrate shell usage everything set run local copy running managepy using ' runserver ' argument type python managepy runserver shell reach local version virocon httplocalhost8000 ' want work viroconweb ' graphical userer interface want compute environmental contours python use package built needed statistical computations viroconcom documentation code code ' documentation found methods app help page describes implemented methods detail runt app found httplocalhost8000infohelp template located paper softwarex paper virocon software compute multivariate extremes using environmental contour method provides concise description software contributing various ways contribute could improve code improve documentation add feature report bug improvement leave us implement issue spotted bug idea improvement new feature please open issue please open issue cases want work want leave us work fork want work issue please fork repository develop feature copy repository finally file pull request merge repository conventions contribution guide summarize conventions consistent pep8 cite using viroconweb academic work please cite referencing softwarex paper example long environmental contours computed using package viroconweb software virocon viroconweb version 108 viroconcom version 120 1 example short environmental contours computed using software virocon 1 1 af haselsteiner j lemkuhl pape kl windmeier kd thoben virocon software compute multivariate extremes using environmental contour method accepted softwarex license software licensed mit license information read file license\n",
      "[0 1 0 0 0 1 1 1 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0\n",
      " 0 0 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 1 0]\n",
      "general overworld surface expansion incentivises exploring existing biomes completes improves visually\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "snapshots environmental twitter activity overview visit website environmentaltwitterherokuappcom default tweet cap set 500 tweets twitter rate limit ' quickly block using website would like increase cap change text box next reload button higher number must multiple 100 twitter may still return fewer tweets ' enough available rate limit reached increase cap risk background since inauguration donald trump 45th president united states epa faced severe funding cuts deregulation one biggest centers community response twitter many users expressed outrage praise recent changes environmental protection us capture well public opinion poll twitter data perform sentiment analysis order better understand public feels epa given time site track store data long periods rather looks quick snapshot twitter activity captured every page load argue provides context long term trend analysis rather allows users get insight public feels epa instant load site methods general sense website read current tweets epa recent tweets tags epa perform sentiment analysis tweets searching positive negative sentiment results graphed various charts look tweet counts retweet counts break sentiment timezone learn methods methods input data input analysis json object returned twitter rest apis focus following attributes input data jsonresponse ' statuses ' contains tweet objects returned latest search tweet ' fulltext ' extracts full text current status tweet ' user ' ' name ' gives username person tweeted current status tweet ' user ' ' timezone ' gives timezone user tweet ' retweetcount ' retweet count current tweet many times users retweeted tweet ' createdat ' gives date time tweet posted output data data plot broken following segments datasentiments sentiment total tweet dataitems raw tweet data eg username text etc datadates dates tweet dataretweets sentiment totals weighted retweet count see methodology datatimezones count tweets timezone datatimezonessentiment overall sentiment timezone display data display data using two histograms sentiment count tweets sentiment count retweets pie chart timezone distribution bar chart overall sentiment timezone deploying deploy website simply push updated files repo automatically deploys heroku app crashes let know restart dynos author web app created nick moolenijzer nickmoolenijzercom contact questions architecture django used django framework serve render html files output python data analysis heroku builds hosts web app redis go heroku addon simple redis implementation libraries pythonoauth2 utilized authorize get requests using twitter auth tokens natural language toolkit necessary tools analyzing tweets sentiment eg tokenizing pos analysis classifying plotly used plot results text analysis numpy helps various calculations scientific analysis djangorq provides framework background workers analyze twitter data web dyno redis provides backend rq background workersqueueing apis twitter rest apis allows programmatic search twitter activity assets google material icons icons web use license written code licensed mit license open source license libraries data external resources may licenses must followed sources tutorials helpful references bird steven ewan klein edward loper natural language processing python beijing ' reilly 2009 httpwwwnltkorgbook1ed kantrowitz mark bill ross names corpus np 29 mar 1994 web 30 jan 2017 httpwww2cscmueduafscsprojectairepositoryaiareasnlpcorporanames liu bing pros cons np 2008 web httpswwwcsuiceduliubfbssentimentanalysishtmldatasets loper edward source code nltkclassifynaivebayes nltkclassifynaivebayes nltk 30 documentation np nd web 30 jan 2017 nltk classifiers classifiers np nd web 30 jan 2017 nltk natural language toolkit natural language toolkit nltk 30 documentation np nd web 30 jan 2017 nltk nltk package nltk package nltk 30 documentation np nd web 30 jan 2017 nltk nltkclassify package nltkclassify package nltk 30 documentation np nd web 30 jan 2017 perkins jacob python nltk demos natural language text processing python nltk demos natural language text processing nlp np nd web 30 jan 2017 poole david alan mackworth artificial intelligence artificial intelligence foundations computational agents 733 bayesian classifiers np 2010 web 30 jan 2017 5 categorizing tagging words nd retrieved march 12 2017 httpwwwnltkorgbookch05html asynchronous tasks jobs django rq enproftme nd retrieved march 11 2017 httpenproftme2016104asynchronoustasksandjobsdjangorq background tasks python rq heroku dev center nd retrieved march 7 2017 httpsdevcenterherokucomarticlespythonrq coolors nd retrieved march 11 2017 httpscoolorsco9f7e69d2bba0f2efc7f7ffe0ffeee2 deploying python django apps heroku heroku dev center nd retrieved february 16 2017 httpsdevcenterherokucomarticlesdeployingpython django connection refused redis heroku stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions11813470connectionrefusedforredisonheroku get searchtweets twitter developers nd retrieved march 9 2017 httpsdevtwittercomrestreferencegetsearchtweets google fonts nd retrieved march 8 2017 httpsfontsgooglecom heroku redis heroku dev center nd retrieved march 11 2017 httpsdevcenterherokucomarticlesherokuredisconnectinginpython histograms nd retrieved march 11 2017 httpsplotlypythonhistograms use sessions django documentation django nd retrieved march 11 2017 httpsdocsdjangoprojectcomen110topicshttpsessions http get request javascript stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions247483httpgetrequestinjavascript javascript whats easiest way call function every 5 seconds jquery stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions2170923whatstheeasiestwaytocallafunctionevery5secondsinjquery joestumppythonoauth2 nd retrieved march 12 2017 httpsgithubcomjoestumppythonoauth2 joestumppythonoauth2 fully tested abstract interface creating oauth clients servers nd retrieved february 16 2017 httpsgithubcomjoestumppythonoauth2 managing static files eg images javascript css django documentation django nd retrieved february 16 2017 httpsdocsdjangoprojectcomen110howtostaticfiles material icons material design nd retrieved march 12 2017 httpsmaterialioicons natural language toolkit nltk 30 documentation nd retrieved march 12 2017 httpwwwnltkorg numpy numpy nd retrieved march 12 2017 httpwwwnumpyorg personal apps heroku nd retrieved march 12 2017 httpsdashboardherokucomapps pie charts nd retrieved march 11 2017 httpsplotlypythonpiecharts pyplot matplotlib 200 documentation nd retrieved march 8 2017 httpmatplotliborgapipyplotapihtml python adding config modes plotlypy offline modebar stack overflow nd retrieved march 9 2017 httpstackoverflowcomquestions36554705addingconfigmodestoplotlypyofflinemodebar python embedding plotly chart django template stack overflow nd retrieved march 9 2017 httpstackoverflowcomquestions36846395embeddingaplotlychartinadjangotemplate python flask passing around background worker job rq redis stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions12162021flaskpassingaroundbackgroundworkerjobrqredis python get job result rq stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions22776924pythonhowtogetjobresultbyrq redis nd retrieved march 12 2017 httpsredisio redis get job id rq python stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions15181630howtogetjobbyidinrqpython redis oom command allowed used memory maxmemory 2016 may 16 retrieved httpsmattiasberedisoomcommandnotallowedusedmemorymaxmemory redis go addons heroku elements nd retrieved march 12 2017 httpselementsherokucomaddonsredistogo rest apis twitter developers nd retrieved february 16 2017 httpsdevtwittercomrestpublic rq simple job queues python nd retrieved march 11 2017 httppythonrqorg simple job queues djangorq imaginary landscape nd retrieved march 11 2017 httpswwwimagescapecomblog20130613simplejobqueuesdjangorq singleuser oauth examples twitter developers nd retrieved february 16 2017 httpsdevtwittercomoauthoverviewsingleuser smistad e nd making charts output images browser django erik smistad retrieved httpswwweriksmistadnomakingchartsandoutputingthemasimagestothebrowserindjango stack overflow nd retrieved march 7 2017 httpstackoverflowcom street nd using redisqueue asynchronous calls django retrieved httpracingtadpolecomblogredisqueuewithdjango web framework perfectionists deadlines django nd retrieved march 12 2017 httpswwwdjangoprojectcom thumbnail gallery matplotlib 200 documentation nd retrieved march 7 2017 httpmatplotliborggalleryhtml uidjangorq nd retrieved march 12 2017 httpsgithubcomuidjangorq visualize data together nd retrieved march 12 2017 httpsplotly worldvectorlogo brand logos free download nd retrieved march 7 2017 httpsworldvectorlogocom\n",
      "[0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 0]\n",
      "code data paper learning navigate unseen environments back translation environmental dropout environment installation download roomtoroom navigation data bash tasksr2rdatadownloadsh download image features environments mkdir imgfeatures wget httpswwwdropboxcomso57kxh2mn5rkx4oresnet152imagenetzip p imgfeatures cd imgfeatures unzip resnet152imagenetzip python requirements need python36 python 35 ok since removed allennlp dependencies pip install r pythonrequirementstxt install matterport3d simulators git submodule update init recursive sudo aptget install libjsoncppdev libepoxydev libglmdev libosmesa6 libosmesa6dev libglewdev mkdir build cd build cmake deglrenderingon make j8 code speaker bash runspeakerbash 0 0 id gpu train speaker save snapshot snapspeaker agent bash runagentbash 0 0 id gpu train agent save snapshot snapagent unseen success rate would around 46 agent speaker back translation pretraining speaker agnet bash runbtenvdropbash 0 0 id gpu load pretrained agent run back translation environmental dropout currently result pytorch 11 little bit lower naacl reported number still easily reaches success rate 50 4 wo back translation implementation details training speaker listener drop features much means image feature dropped randomly smaller dropout rate seen used multiple vision papers mlweight increased using back translation since quality generated sentence high rl would misled instead training augmented data finetuning training data trained together semantic views shown fig6 paper semanticviews17drp5sb8fy10c252c90fa24ef3b698c6f54d984c5c14png repo rendered semantic views matterport3d dataset provide preview semantic views rgb views forder semanticviews access full rendered data please first sign terms use agreement form httpsgithubcomniessnermatterport cc ' email us haotancsuncedu would share download link thanks one teaches calibrate camera note would small pixellevel disagreement rgb view semantic view since semantic view rendered 3d annotations rgb view rendered skyboxes still aiming solving todo ' provide test script beam search code trainpy agentpy release pretrained snapshots check pytorch 11 configurations update pip requirement version specifications\n",
      "[1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0\n",
      " 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 1 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 0 0]\n",
      "buzzsense ecological observation increasingly augmented autonomous systems analysis transmission data poses serious problems information manager aim project bridge technological gap needs biologists recent advances mobile imaging solve present buzzsense application bee population counting running android mobile device run application android device running android 42 better need opencv manager available play store also need copy images project samples directory mediasamples mobile device compile application need download open cv android 248 better sdk need download install android ndk native development kit program uses native c libraries wraped easy use java calls hardware accelerated image processing\n",
      "[0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "environmentalsustainability document created thinkchicago ' idea week focuses environmental sustainability chicago selected one 20 total teams pitch solution judges links surveys end document quality app food survey httpswwwsurveymonkeycomr9jyvnzk demographic survey httpswwwsurveymonkeycomr9qb3nyy farmer survey httpswwwsurveymonkeycomr9sq2wzp plan creating web app get experience web backend\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "onestop stack onestop distributed scalable eventdriven database search engine environmental data designed receive metadata automated systems manual uploads iso19115 xml metadata implements generic parsing analysis metadata also enabling arbitrary processing flows metadata entities retrievable via rest api exposed streaming events via kafka indexed support wide range search discovery capabilities via elasticsearch developed grant team researchers university colorado legal info documentation overview usage deployment development information project check docs legal software developed onestop project 1553647 msn project 1555839 noaa award numbers na12oar4320137 na17oar4320101 respectively cooperative institute research environmental sciences university colorado code licensed gpl version 2 2020 regents university colorado program free software redistribute andor modify terms gnu general public license published free software foundation version 2 license program distributed hope useful without warranty without even implied warranty merchantability fitness particular purpose see gnu general public license details received copy gnu general public license along program write free software foundation inc 51 franklin street fifth floor boston 021101301 usa\n",
      "[0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "mixturesworkshop columbia university mailman school public health environmental mixtures workshop 20182019 introduction multiple techniques analyze exposure mixtures environmental health repository guide within repository find code materials used mixtures workshop 20182019 help navigate repository description repository organization repository organized two main folders unsupervised supervised contained materials unsupervised supervised methods correspondingly unsupervised folder subdivide three folders pca fa clustering supervised folder subdivide wqs variable selection bkmr materials respective method within folder note rmd file titled method ' name contains main code addition unsupervised supervised folders find following folders data contains data data dictionary mitroetalmaterials contains code data used mitro et al workshoppaperfigures contains figures include gibson et al paper warning repo created r version 353 results differ newer r versions r version 360 changed default method generating discrete uniform distribution used sample additionally version 313 grpreg package used recreate published results\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0]\n",
      "neutrino neutrino environmental monitoring home hvac diy projects neutrino designed alternative zoned hvac system supplement zoned hvac system relatively easy implement people ' want retrofit fully zoned system ways may even better zoned system cost effective also allows ability get system control ' going commercial systems offer zoned systems ' always work well ideally zoned system heats cools efficiently unfortunately limitations ability ductwork supply airflow often cause system open bypass relieve pressure essentially connects output input short circuiting system zone needs air getting capacity wasted traditional single zone system air would go rooms might need moment probably would eventually called pressure issue mitigated somewhat different blower speeds furnace means expensive zoning system sometimes zone conflicts cause system act nonintuitively like waiting blower stop one zone kicking request another zone sometimes zoned system overkill structure needs boost higher accuracy someone wants data many reasons end neutrino gives diy user ability go change works first giving average user ability finetune system detailed information room big bonus allows use adjust vent covers appropriately sometimes make difference top users choose sensors hvac system pay attention whether one particular room average multiple 2014 ' make much sense drive hvac hallway temperature unless course enjoy hanging hallway also gives advanced users ability go change system works providing open system starts sensors tiny inexpensive battery powered sensors placed wherever makes sense sense surroundings wall putty doublesided tape shelf etc next sensors grouped together user software however see fit groups represent zones ' match example sensor room driven hvac system could included sensor group controls hvac system b finally users choose set hotcold set points group toggle sensors group ' count ' system average values sensors count whether single sensor ten sensors sensors consist microcontroller temperaturehumiditypressure sensor 24ghz radio battery use radio wifi power efficient inexpensive implement sensors report sensor hubs via radio six sensors assigned single hub sensors assigned id 0 5 via jumpers sensor hubs responsible getting sensor info database ' necessarily correspond sensor groups group span hubs hubs currently consist raspberry pi 24ghz radio attached software sensorlistener listens radio plugs output mysql database eight sensor hubs supported per system sensorlistener assigned hub id 07 via config file sensors told hub report via second set jumpers ' controller controllers computer relays control actual hvac furnace ac humidifier blower controller software looks database sensor group ' readings checks ' set points via controller table adjusts hvac accordingly finally ' web ui user easily see sensor data create sensor groups set heatingcooling points code rpisensorlistener c application raspberry pi requires makemake install rf24 library httpsgithubcommlsorensenrf24treemasterlibrf24rpilibrf24 well aptget install mysql libconfig libs start read config file supply via ' c ' flag see example config start listening six radios assigned gets message puts mysql optionally publishes zabbix via zabbix sender keys ' neutrinosensoridhubidtemperature ' etc arduino code runs sensor microcontrollers also contains schematics controllers requires arduino ide import arduinoversion rf24 library httpsgithubcommlsorensenrf24 bmp180 library httpsgithubcommlsorensenbmp180git rocketscream low power library httpsgithubcomrocketscreamlowpower controller software controls controller web ui code deployment deployment currently adhoc following may help running sensor hub sudo aptget install daemon cd neutrinohub sudo daemon name sensorlistener respawn outputdaemonerr homepineutrinohubsensorlistener c etcsensorlistenercfg stopping sensor hub sudo daemon name sensorlistener stop running controller cd neutrinocontroller screen dms controller sudo controller c etccontrollerconf running web ui cd neutrinoweb sudo hypnotoad neutrinowebapp stopping web ui sudo hypnotoad neutrinowebapp stop\n",
      "[0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0\n",
      " 0 0 1 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 1 0]\n",
      "envirotreaties\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmental stressor aspnet core web application test environment like server cluster provides operations simulate long running startup long running request high cpu usage memory leak memory high throughput running docker image available httpshubdockercomrmatheusnederenvironmentalstressor docker run matheusnederenvironmentalstressorv10alpha4\n",
      "[0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "utah turbulence environmental studies process analysis code utespac created derek jensen eric pardyjak derek591gmailcom version 41 version date 15 january 2017 utespac designed specifically use campbell scientific dataloggers accompanying loggernet software native support sonic anemometers rmyoung 8100 campbell sci csat3 open path gas analyzers licor 7500 campbell sci ec150 irgason krypton hygrometers finewire thermocouples heat flux computations propeller anemometers mean meteorological sensors eg trh pressure solar cup anemometers etc utespac expects 24 48hr csv tables quality controls data computes means fluxes variances derived temperatures potential temperature virtual potential temperature stores output matlab structure netcdf file steps use convert campbell binary files csv files using card convert program loggernet options file processing use time set 2 days 00 h time settings file naming use timedate filenames append last file multiple site files exist array csv options timestamp options include year day hourminutes seconds ' include midnight 2400 array id array datalogger format hourminutes seconds create folder individual site folder name needs preceded keyword site eg site named playa folder name siteplaya place csv files within site folder create subfolder named output output data stored create header files data table syntax 91tablename92headerdat eg playa1hzheaderdat playa20hzheaderdat note 91tablename92 must consistent csv tablenames created step 1 header file single line dat comma delimited file containing variable names heights columns within respective data table header file 3 columns shorter csv data file utespac immediately calculates serial date numbers date vectors columns 1 96 4 contained data tables serial dates stored column 1 columns 2 96 4 deleted thus becoming consistent header file easiest way create header file card convert create ascii t0a5 file need run whole binary file simply stop conversion immediately hundred lines created open file text editor delete lines outside variable headers typically line 5 variable names within header sensor templates defined lines 155169 must consistent template used utespac identify specific sensors header rules creating template header variable names template variable name exact except sensor height replaced wildcard ' ' template eg template ' ux ' header variable name ' ux05 ' ' ux10 ' sensor height must last numeric value header variable name sensors exception solar battery need associated height meters heights within header variable name given tower height need exactly match eg ' fw5 ' ' ux5 ' ' rh5 ' global planar fit used pfinfo structure containing global planar fit coefficients stored site folder need anything note global planar fit must 1 1 set 5 minute local planar fit data global planar fit fail ' 5minavglpflindetrend ' ' 5minavglpfconstdetrend ' output folder must one ' matter fill information section code lines 56 116 run code full example study included utespaczip use getdata structfill structconcat produce complete missing days datasets full experiment see example\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 1 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0\n",
      " 0 1 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 0]\n",
      "enviro designed environmental monitoring enviro lets measure air quality pollutant gases particulates temperature pressure humidity light noise level learn httpsshoppimoronicomproductsenviroplus installing ' best using oneline install method want uart serial configuration pms5003 particulate matter sensor run automatically note code repository supports enviro enviro mini boards enviro mini board gas sensor breakout pm sensor oneline installs github curl ssl httpsgetpimoronicomenviroplus bash note report issues oneline installer httpsgithubcompimoroniget install configure dependencies github git clone httpsgithubcompimoronienviropluspython cd enviropluspython sudo installsh note raspbian lite users may first need install git sudo apt install git install pypi configure manually run sudo pip install enviroplus note wont perform required configuration changes pi may additionally need enable i2c raspiconfig nonint doi2c 0 enable spi raspiconfig nonint dospi 0 ' using pms5003 sensor need enable serial raspiconfig nonint setconfigvar enableuart 1 bootconfigtxt disable serial terminal sudo raspiconfig nonint doserial 1 add dtoverlaypi3miniuartbt bootconfigtxt install additional dependencies sudo apt install pythonnumpy pythonsmbus pythonpil pythonsetuptools alternate software user projects enviro monitor httpsgithubcomroscoe81enviromonitor mqttall httpsgithubcomrobmarkcolerpienviromqtt upstream see examplesmqttallpy adafruitiopy httpsgithubcomdedsyn4ps3enviropluspythonblobmasterexamplesadafruitiopy uses adafruit blinka bme280 libraries publish adafruit io enviroplusexporter httpsgithubcomtijmenvandenbrinkenviroplusexporter prometheus exporter added support luftdaten influxdb cloud help support gpio pinout httpspinoutxyzpinoutenviroplus support forums httpforumspimoronicomcsupport discord httpsdiscordgghr93byc\n",
      "[0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0]\n",
      "openthc raspberry pi toolkit collection documentation scripts tools using raspberry pi cannabis operations scale support one scales connected rpi via serialusb adapters may need highspeed usb hub four scales used sensor support co2 x ch4 methane humiditytemperature dht11 dht22 lumens light cycle onoff wind speed wind direction solar ph soil liquid vpd vapor pressure deficit floodmoisture sensor ek1361 te215 water level sensor soil moisture httpswwwamazoncomxcsourcemoistureautomaticwateringte215dpb00zr3b60irefpdsim8613encodingutf8pdrdib00zr3b60ipdrdrc3b5e56b9b6511e8800d291f7dc96a5epdrdw8nsu8pdrdwgye39npfrdidesktopdpsimspfrdmatvpdkikx0derpfrdpa180fdfbb54e490485bad852197d6c09pfrdry61esta6t2n3ax4a6qtbpfrdsdesktopdpsimspfrdt40701psc1refridy61esta6t2n3ax4a6qtb httpswwwamazoncomkumanmoisturecompatibleraspberryautomaticdpb071f4rdhyrefpdsim864encodingutf8pdrdib071f4rdhypdrdr520fcfc79b6511e88a22f3d4eee18e06pdrdwuxo65pdrdwgar8odpfrdidesktopdpsimspfrdmatvpdkikx0derpfrdpa180fdfbb54e490485bad852197d6c09pfrdrxp2yx5bb9h3r8mwecg8cpfrdsdesktopdpsimspfrdt40701psc1refridxp2yx5bb9h3r8mwecg8cdpid51roavqo3xlprestsy300ql70dpsrcdetail httpswwwamazoncomgikfunmoisturesensorarduinoek1361dpb00rk1vytirefsr11ieutf8qid1533771952sr81keywordssoilmoisturesensor httpswwwamazoncomctyrzchmoisturesensorautomaticwateringdpb01essmlqurefsr119ieutf8qid1533771976sr819keywordssoilmoisturesensor httpswwwamazoncomdfrobotgravitycapacitivecorrosionresistantdpb01ghy0n4krefsr120ieutf8qid1533771976sr820keywordssoilmoisturesensor httpswwwamazoncomdfrobotgravitycapacitivecorrosionresistantdpb01ghy0n4krefpdsim862encodingutf8pdrdib01ghy0n4kpdrdr520fcfc79b6511e88a22f3d4eee18e06pdrdwuxo65pdrdwgar8odpfrdidesktopdpsimspfrdmatvpdkikx0derpfrdpa180fdfbb54e490485bad852197d6c09pfrdrxp2yx5bb9h3r8mwecg8cpfrdsdesktopdpsimspfrdt40701psc1refridxp2yx5bb9h3r8mwecg8cdpid41w7vqm6gxlprestsy300ql70dpsrcdetail httpswwwamazoncomwingoneersensordropletdetectionarduinodpb06xhdz3q4refpdsim863encodingutf8pdrdib06xhdz3q4pdrdr520fcfc79b6511e88a22f3d4eee18e06pdrdwuxo65pdrdwgar8odpfrdidesktopdpsimspfrdmatvpdkikx0derpfrdpa180fdfbb54e490485bad852197d6c09pfrdrxp2yx5bb9h3r8mwecg8cpfrdsdesktopdpsimspfrdt40701psc1refridxp2yx5bb9h3r8mwecg8c httpswwwamazoncomphantomyoyocompatiblesensitivitymoisturedpb00afcnr3urefpdsim8650encodingutf8pdrdib00afcnr3updrdr520fcfc79b6511e88a22f3d4eee18e06pdrdwuxo65pdrdwgar8odpfrdidesktopdpsimspfrdmatvpdkikx0derpfrdpa180fdfbb54e490485bad852197d6c09pfrdrxp2yx5bb9h3r8mwecg8cpfrdsdesktopdpsimspfrdt40701psc1refridxp2yx5bb9h3r8mwecg8c httpswwwamazoncomdpb01n7na3hprefsxbssxwdsstppvp1pfrdmatvpdkikx0derpfrdp6297546923292665688pdrdwgn1jtppfrdrz9tkr6jwbxesk34wwszepfrdsdesktopsxbottomslotpfrdt301pdrdib01n7na3hppdrdwvhi9npfrdisoilmoisturesensorpdrdr46cb234ec9874ef68c13b213336fca55ieutf8qid1533771976sr1 httpswwwamazoncomdpb00tmd43bsrefpsdc3480689011t4b00zr3b60i control support onoff ac power onoff dc power hardware ' need misc resistors capacators stuff httpswwwamazoncomdpb076lh75jqrefsspadkdetail12psc1pdrdib076lh75jqpdrdwg7ha91pdrdrdt8weqmjthswbh952y2ypdrdwpdyie httpswwwamazoncomdpb07bvtfchprefsspadkdetail3psc1pdrdib07bvtfchppdrdwgtderypdrdr6k5p8ytefm594rdcm0v6pdrdwaahec httpswwwamazoncom24valueelectrolyticcapacitorassortment01ufefbc8d1000ufdpb01msqox0qrefpdbxgy3283encodingutf8pdrdib01msqox0qpdrdr6k5p8ytefm594rdcm0v6pdrdwzmcy1pdrdwgtderypsc1refrid6k5p8ytefm594rdcm0v6dpid51lvgjm9iulprestsy300ql70dpsrcdetail\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
      "environmental environmental proof column politecnico di torino\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enfin environmental finance service overview environmental finance service allows individuals track carbon footprint enfin team redefining individuals ' methods towards watching impact environment using estimations based current environmental research every dollar spent mapped environmental impact history enfin founded impact labs fellowship fellowship designed passionate motivated students come together combine computer science social good learning create humanitarian software development founders strong idea regarding effects individuals climate change enfin highlights belief\n",
      "[0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "etdenvironmentalsensor project python consisting smaller apps talking microservices enables reading measurements humtemp sensor displaying webpage steps creating project download repo git clone adresurl create venv install required packages python3 venv venv source venvbinactivate pip install upgrade pip pip3 install r requirementstxt permanent alias nano bashrc alias venvsource environmentalsensorsvenvbinactivate reboot type source bashrc config temphum sensor add uncomment dtparamspion dtoverlaymcp2515can0oscillator8000000interrupt25spimaxfrequency1000000 sudo apt update sudo modprobe mcp251x sudo apt install canutils worth rebooting sudo ip link set can0 type bitrate 460800 candump can0 bug fix sudo aptget install libatlasbasedev running app startsh sigoihy\n",
      "[0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0\n",
      " 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "mesopy mesopy small pure python wrapper around mesowest httpmesowestutahedu api updated daily 45 million observations useful retrieving meteorological data 40000 observation stations united states project created researcher mind would value feedback using mesopy using mesopy need obtain api keytoken filling quick form receive email immediately api key link generate token click link copy token generated instancing meso object like mesotoken ' apitoken ' installation two easy ways install mesopy run pip install mesopy command line window download source folder place mesopypy working directory version 2 updates requests package dependency longer exists function names simplified additional query parameters added function new functions added request services mesowest data latency statistics network information lists may passed parameters usage retrieving data request different types observations simply creating meso object calling function mesopy import meso mesotoken ' apitoken ' precip mprecipstid ' kfnl ' start ' 201504261800 ' end ' 201504271200 ' units ' precipin ' returns following data dictionary units precipitationinches station statusactive mnetid1 periodofrecord start19700101t000000z end20180313t015600z elevation5016 namefort collinsloveland northern colorado regional airport restrictedfalse stidkfnl elevdem5000 longitude10501667 stateco observations obstarttime120150426t181500z totalprecipvalue1009 obendtime120150427t115500z count153 latitude4045 timezoneamericadenver id192 summary dataquerytime50201416016 responsecode1 responsemessageok metadataresponsetime00920295715332 ms numberofobjects1 precipdatatime54969787598 dataparsetime04601478577 retrieve dictionary keysvalues listed merely following let ' print total precip accumulation fort collins airport station precip ' station ' 0 ' stid ' remember stored dictionary precip variable totalprecip precip ' station ' 0 ' observations ' ' totalprecipvalue1 ' print ' total accumulated precip ' station ' ' strtotalprecip ' ' prints total accumulated precip kfnl 009 note one thing example whenever data ' requesting returns ' station ' necessary specify station index value list subsequently referring example pass stidkdenkslc dictionary return list two stations ' relevant info get information kden denver would type ' station ' 0 kden would first list stations ' station ' 1 kslc salt lake city remember specifies dictionary denotes list 0 first position list may useful store precip ' station ' variable reduce clutter example denverprecipobs precip ' station ' 0 saltlakeprecipobs precip ' station ' 1 could write printdenverprecipobs ' observations ' ' totalprecipvalue1 ' returns 013 request api created always return list since user request multiple stations time always stipulation function list latest get latest observation data particular stations attime get latest observation data particular stations specific time precipitation obtain precip totals specified period stations timeseries retrieve observations specified period stations climatology obtain climatology specified period stations metadata retrieve list station metadata based search parameters variables get list sensor variables possible observing stations climatestats retrieve aggregated yearly climate statistics stations timestats obtain statistics specific time frame stations latency retrieve data latency values stations networks obtain metadata concerning observing networks mesowest repository networktypes returns network categories observing networks documentation function well documented docstrings interactive interpreter simply type helpsomefunc code type somefuncdoc example projects found examples path version license 202 released 7 jan 2016 mit license support credits mesopy designed simple possible hope enjoy usage questionscomments please direct supportmesowestorg mesowest group led dr john horel university utah additional facilities provided western region national weather service\n",
      "[0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1\n",
      " 1 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 0 0\n",
      " 1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0 1]\n",
      "scee website goal repo make maintain scee website society civil environmental engineering scee oldest largest technical society delhi technological university frontend frontend carried using bootstrap lot frontend tasks done lot still left website needs completed end october backend much backend work backend includes counting number visitors emailer send emails regarding new updates blogs using flask backend backend needs special attention contributions contributions welcome contributor guidelines look scee thanks valuable contributions list contributors follow us instagram printhappy coding\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0\n",
      " 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "environmentalquizapp\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "eink mini mqtt information display time headlines environmental data files setup run eink mqtt information display see httpswwwconnectedenvironmentsorgmakingthe files divided two parts scripts process data send mqtt via cron timetomqttpy gets time converts words publishes mqtt topic rsstomqttpy fetches rss news feed reads latest headline publishes mqtt topic clientrawmqttwdpy fetches feed weather display converts data text publish personal weather station darkskytomqttpy fetches weather dark sky converts wind bearing text publishes mqtt feed main script run eink display show mqtt feeds version eink phat thepiphatpy version eink thepiwhatpy check font download background images\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "environmentalquizapp\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "coronawhy ties task force worldwide effort volunteers fight coronavirus covid19 understanding covid19 transmission incubation environmental stability documentation httpstasktiesreadthedocsioenlatest task homepage httpsgithubcomcoronawhytaskties main coronawhy homepage httpswwwcoronawhyorg coronawhy coronawhy crowdsourced team 350 engineers researchers project managers sorts professionals diverse backgrounds joined forces tackle greatest global problem todayunderstanding conquering covid19 pandemic team formed response kaggle cord19 competition synthesize flood new knowledge generated every day covid19 goal organization inform policy makers care providers combat virus knowledge latest research disposal coronawhy ties task todo coronawhy ties task force list collaborators pending install also although strictly required usage virtualenv highly recommended order avoid interfering software installed system minimum commands needed create virtualenv using python36 taskties pip install virtualenv virtualenv p python36 taskties afterwards execute command activate virtualenv source tasktiesbinactivate remember execute every time start new console work taskties virtualenv activated clone repository install source running make installdeveop stable branch git clone gitgithubcomcoronawhytasktiesgit cd taskties git checkout stable make installdevelop code installed local system ready help us contribution first please look contributing guide\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "environmentaleconomic electric power dispatch nsgaii 1 algorithm shared library develpoment environment windows 64 visual studio 2015 visual studio 2015 project 11 nsgaii shared library shared library based nsgaii nondominated sorting genetic algorithm riginal code c dr kalyanmoy deb httpwwwiitkacinkangal 12 environmentaleconomic electric power dispatchshared library shared library based nsgaii shared library developing applications around environmentaleconomic electric power dispatch 2 example python python 35 python packages numpy matplotlib tornado standard ieee sixgenerator 30bus test system abido novel multiobjective evolutionary algorithm environmentaleconomic power dispatch electric power systems research 657181 2003 used demonstrate effectiveness shared library 21 example api python pythonexample run python biobjloaddispatchpy ctypes import import numpy np import pylab plt class nsga2cfgstructure fields nrealcint nobjcint nconcint popsizecint ngencint pcrossrealcdouble pmutrealcdouble etaccdouble etamcdouble class curvecoffstructure fields ccfloat3 ecfloat5 class unitloadstructure fields mincfloat maxcfloat coffcurvecoff class loadvstructure fields xrealcfloat10 cobjcfloat eobjcfloat loadmin 005005005005005005 loadmax cdouble6 loadmax 1515115151515 c10200100 10150120 2018040 1010060 2018040 10150100 e cdouble65 e40915554649020e42857 25436047563850e43333 42585094458610e68000 54263550338020e32000 42585094458610e68000 61315555515110e56667 mydllwindlllibseubiobjloaddispatch fmydllseubiobjloaddispatch unitnumcint totalloadcdouble gansga2cfg popsizecint bestcloadv besteloadv bestloadv unitnum6 uloadunitloadunitnum rangeunitnum uloadimin loadmini uloadimax loadmaxi j range3 uloadicoffcjcij j range5 uloadicoffejeij ganrealunitnum ganobj2 gancon1 gapopsize200 gangen200 gapcrossreal09 gapmutreal01 gaetac20 gaetam15 x pointercdouble gapopsize rangegapopsize xi cdouble ganreal obj pointercdouble gapopsize rangegapopsize obji cdouble ganobj totalload2834 fgaunitnumuloadcdoubletotalloadbyrefxbyrefobjbyrefpopsizebyrefbestcbyrefbestebyrefbest print ' bestc ' printbestccobj printbestceobj print ' load ' rangeganreal printbestcxreali100 print ' beste ' printbestecobj printbesteeobj print ' load ' rangeganreal printbestexreali100 print ' best ' printbestcobj printbesteobj print ' load ' rangeganreal printbestxreali100 print ' paretocobj ' cnpzerosshapegapopsize rangegapopsize ciobji0 printobji0 print ' paretoeobj ' enpzerosshapegapopsize rangegapopsize eiobji1 printobji1 bcnpzerosshape1 bc0bestcobj benpzerosshape1 be0besteobj pltplotce ' b ' label ' pareto ' pltplotbcbe ' ro ' label ' best ' pltminortickson pltxlabel ' ch ' pltylabel ' eth ' pltshow 22 example web application webappexamplewebappexample simple web application based tornado run python apppy 3 ppt chinese ppt designed introduce shared library ' application chinese undergraduate computer design contest 2014 4 award 1st prize 7th china undergraduate computer design contest jiangsu province 3rd prize 7th china undergraduate computer design contest 5 license mit\n",
      "[0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0]\n",
      "environmentalsamplelogger application helps environmental consultants visualize distribution subsurface soil drilling boreholes user create new borehole location add samples specify parameters colour stratigraphy whether sample odourous save progress come back later\n",
      "[0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "mhav env check jenkins\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "binsanity v03 please see wiki usage installation requirements httpsgithubcomedgrahambinsanitywiki issue arises process utilizing binsanity please create issue address soon possible expedite response please provide associated error messages project actively improved comments suggestions welcome binsanity forum citation graham ed heidelberg jf tully bj 2017 binsanity unsupervised clustering environmental microbial assemblies using coverage affinity propagation peerj 5e3035 httpsdoiorg107717peerj3035\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "environementalmodellinggithubio environmental modelling courses rudn\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmental health channel environmental health channel interactive webbased platform creating sharing environmental sensing health data narratives data shared affected residents collected environmental health project ehp includes physical psychosocial health symptoms particulate pollution pm25 air measurements personal stories residents tool displays data using visualization exploratory data analysis techniques enables researchers health professionals public interactively explore share compelling scientific evidence local impacts oil gas drilling usage first get google map javascript api key replace api key folowing line webvizhtml file script srchttpsmapsgoogleapiscommapsapijskeyyour api keyscript obtain zcta5 json file documented project run following bash commands terminal cd path ehpchannel folder mkdir data cd data mkdir geo cd geo mv path zcta5 json file mv zcta5 json file zcta5json cd py python updatechanneldatapy create data folder web folder website running python command need install dependencies see libraries imported utilpy file utilpy file shared projects libraries used project however run code please install deployment example apache config file https virtualhost 443 servername envhealthchannelorg serveralias wwwenvhealthchannelorg sslengine rewriteengine rewritecond httphost envhealthchannelorg nc rewritecond httphost rewriterule httpenvhealthchannelorg1 lr301 header set cachecontrol maxage0 mustrevalidate documentroot yourpathenvhealthchannelorgwwwweb directory yourpathenvhealthchannelorg addoutputfilterbytype deflate applicationoctetstream allowoverride none allow listing directory ' indexhtml follow symlinks options indexes followsymlinks order allowdeny allow directory sslcertificatefile etcletsencryptliveenvhealthchannelorgcertpem sslcertificatekeyfile etcletsencryptliveenvhealthchannelorgprivkeypem include etcletsencryptoptionssslapacheconf sslcertificatechainfile etcletsencryptliveenvhealthchannelorgchainpem virtualhost virtualhost 80 servername envhealthchannelorg serveralias wwwenvhealthchannelorg rewriteengine rewriterule httpsservernamerequesturi lnerpermanent virtualhost add https support website please refer setup https section readme repository periodically update data channel set cron job crontab e add following line crontab 30 cd yourpathenvhealthchannelorgwwwpy runone python updatechanneldatapy\n",
      "[0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 1 0 0]\n",
      "anomaly detection iotacquired environmental sensor data abstract demand monitoring landfill site increasing landfill site produces methane poisonous gas harmful existence nature monitoring landfill sites made possible using sensors data quality issues arising sensors persist research focusses solving problem anomaly detection turn solving issues related data quality giving indication presence subtle anomaly exhaustive search solve problem apply existing techniques core idea also involved speaking researchers industry basic techniques ranging gaussian mixture model autoencoder implemented finally various problems finding perfect solution reported ensemble approach solving problem anomaly detection ecological monitoring proposed\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "environmentalforecasting\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "lake levels yahara watershed httpwwwyaharainfo madison wisconsin surrounding dane county saw near record level rainfalls late august widespread flooding caused two hundred million dollars damage associated press months leading flood lakes surrounding madison higher maximum level set wisconsin department natural resources 1979 often true lakes currently maximum level kept high questions hope address environment setup install postgresql make sure environment variable named user username value unix variants likely already exists create new user username permissions create database eg sudo u postgres createuser user recommended set sort virtual environment install requirements pip install r requirementstxt code code madisonlakelevels requires python 36 run tests python pytest run top level project running locally run get env set export flaskappapppy export databaseurlpostgresusermadisonlakes heroku ' env var format createdb madisonlakes u user run app flask run run debug mode ' prod export flaskenvdevelopment flask run deploy webapp deployed heroku found httpwwwyaharainfo herokuformat procfile runtimetxt used control deployment freetier database heroku used persist data cron job runs every 30 minutes updates database job created using heroku scheduler hits simple api route webapp causes update running job every 30 minutes nice side effect preventing website going hibernation mode heroku free tier\n",
      "[0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0\n",
      " 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0]\n",
      "environmentalissues\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "rgb480p20rgbubuntu 16ros kinectganzhixinxitxytxxyy xml pythonpythonopencvrosrospyoencvhaaropencvxml sample xml xmlcatkinwsxmlrosrosnodemsgubuntu roscorerosroshttpwikirosorgcn tanrgbrgb70y0tanzxyttxy ros 1xy 1rospython2737tensorflow objectdetection api 2\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "privatenotes java linux algorithm environmental configuration etc content java linux java java java java jdbc jdbc jsp jvm java java hibernate spring struts2 sql mongodb mysql git maven linux shell java j2ee switchstring equal java object java javahashcode arraylistlinkedlistvector hashmapconcurrenthashmaphashmap treemaphashmaplindedhashmap collectioncollections try catch finallytryreturnfinally exceptionerror java overrideoverload interfaceabstract static class non static class java java java jvm hibernateidea ubuntuzookeeper mysql nginxmysqlredis ubuntutomcat ubunturedis getpost tcp tcp idea webxml servlet mapping mybatis mybatisresulttypenull zookeeper zookeeper zookeeper nginx nginx location 6 23\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmentallaw\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmentalissues felix ' fables titlemy great gametitle hello\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmental science associates jekyll theme based freelancer bootstrap theme\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmental applications gis winter 2017 dartmouth prof james dietrich jamestdietrichdartmouthedu\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "meteobike mapping urban heat islands bikes meteobike educational raspberry pi zero project university freiburg chair environmental meteorology course tools meteorology 5th term minor meteorology climatology develop system measure analyze visualize urban heat island effect within short period 2 hours measure many systems simultaneously temperature humidity transcects inside outside city tag measurement locations gps system battery operated light mounted bikes communication raspberry pi zero smartphone enabled via wireless network overview students build mobile systems system assembled using following components component model link vendor germany price microcontroller raspberry pi zero w pimoronide 10 eur gps adafruit ultimate gps breakout pimoronide 40 eur temperature humidity sensor dht22 am2302 azdelivery amazonde 5 eur micro sd card noobs 16gb microsd pimoronide 5 eur battery poweradd pilot 2gs powerbank 10000mah poweradd amazonde 15 eur jumper wires elegoo jumper wire gye amazonde 7 eur screen 27inch epaper hat reicheltde 20 eur replaced product workshop 1 setting raspberry pi zero connecting sensors first workshop connect raspberry pi zero mouse keyboard screen set properly connect temperaturerelative humidiy sensor gps working install userinterface collect automatically data store sd card connecting starting raspberry pi zero raspberry pi zero w microcomputer running full operating system providing input output connectivity number interfaces settingup sdcard raspberry pi zero w comes micro sd card contains operating sysetm called raspbian preinstalled cases micro sd card housed inside larger regular sd card adapter pull microsd card insert carefully card slot make sure logo handpainted white number sticker back settingup temporary peripherals mouse keyboard screen first time setup raspberry pi zero w need additional components components need screen hdmi vga dvi connection usb keyboard usb mouse usb hub microusb usba convertor power supply course provided usb hub microusb usba provide screen usb keyboard usb mouse possibly also regular hdmi cable later system assigned wireless networks connect without keybord without mouse without screen using realvnc need phsyical keyboard mouse screen later exercises bike traverses remotely controlled laptop smartphone tablet connection cables supplies need initial setup specific models may vary screen shown first connect usb mouse keyboard raspberry pi zero w two miniusb ports one left usb devices mouse keyboard one right actually supplying power see first connect usb devices left one true usb port need connect two devices must also add initially usb hub setup connect screen tv initial setup connect first minihdmi hdmi coverter use regular hdmi cable connect screen rare cases need minihdmi vga adapter screen support hdmi vga minihdmi dvi adapter screen support hdmi dvi powerup system finally connect power supply right mini usb connector raspberry pi zero w starts green inicator light begins flash instructions follow screen settingup wireless network case firsttime installation follow instructions onscreen setup raspberry pi zero w automatically reboot resizing cases needed os already fully installed operational connect home wireless network click menubar wireless network icon select home network enter password hover mouse network icon read ip number note ip number sheet need later next localize raspberry pi zero w language region check hostname raspberryxx xx number system needed identify system point recommend reboot raspberry pi remote connection via wireless network test communication another device laptop smartphone first activate vnc go settings enable vnc also enable ssh und i2c next laptop smartphone install vnc viewer realvnc mac windows linux install desktop version vnc viewer ios devices use apple app store download vnc viewer android devices use google play download vnc viewer make sure laptop smartphone connected wireless raspberry pi zero w start viewer connect ip address previously noted likely 192168xy enter username pi password previously set able control raspberry pi zero w use mouse keybord remotely installing sensors installing dht22 temperature relative humidity probe dht22 lowcost digital temperature humidity sensor contains capacitive humidity sensor thermistor resistor changes temperature transfers data digitally raspberry pi zero w need three cables connect dht22 raspberry pi zero w one power red one signal orange one ground brown enable communication dht22 first time enter following commands lxterminal command line raspberry pi zero install adafruit dht 22 library library installed access programming language python system already use installing libray skipped someone else already installed library sudo aptget update sudo aptget install buildessential pythondev pythonopenssl git git clone httpsgithubcomadafruitadafruitpythondhtgit cd adafruitpythondht sudo python setuppy install next turn raspberry pi zero disconnect power cable raspberry pi zero connect dht22 sensor physically using presoldered wires power never connect sensors live powered system might damage board connect following color coding pins raspberry pi zero dht22 trh sensor cable color raspberry pi zero pin 1 red cable pin 1 3v pin 2 orange cable pin 7 gpio4 pin 3 cable pin 4 brown cable pin 9 ground double check connection correct wrong connection could also damage sensor raspberry pi zero reconnect power cable raspberry pi zero raspberry pi zero restarts green light flashes started dht 22 sensor polled following commands python version 2 version 3 first start phython development environment python 27 interactive mode python enter import adafruitdht humidity temperature adafruitdhtreadretryadafruitdhtdht224 print temperature humidity display currently measured values system measures temperature humidity every two seconds next exercise calculate vapour pressure using clausiusclapeyron equation first calculate saturation vapour pressure kpa convert relative humidity vapour pressure note temperature needs converted kelvins first import numpy saturationvappress 06113 numpyexp250100004615102731510temperature27315 vappresshumidity1000saturationvappress print vappress also calculate dewpoint temperature installing gps module adafruit ultimate gps 66 channel global positioning system using satellites accurately determine location speed altitude digitally communicates raspberry pi zero w four cables enabling serial communication gps module enable communication raspberry pi zero w first time need enable serial communication system used years follwing changes might already implemented skip section ' connecting gps ' serial communication installed start raspberry ' lxterminal type sudo aptget install gpsd gpsdclients pythongps sudo systemctl stop serialgettyttys0service sudo systemctl disable serialgettyttys0service sudo systemctl stop gpsdsocket sudo systemctl disable gpsdsocket raspberry pi zero need enable serial port gpio pins requires us change configuration file raspberry pi zero w use texteditor example nano command lxterminal edit file configtxt sudo nano bootconfigtxt scroll bottom file mouse arrow keys type new line enableuart1 save ctrl0 german strgo press enter next press ctrlx strgx exit nano editor finally reboot raspberry pi zero rebooted disable standard socket run command lxterminal enable serial port sudo gpsd devttys0 f varrungpsdsock next edit file etcrclocal using nano editor sudo nano etcrclocal insert end line exit 0 following line gpsd devttys0 f varrungpsdsock save ctrl0 german strgo press enter next press ctrlx strgx exit nano command line editor every time raspberry pi zero booted command executed connecting gps turn raspberry pi zero disconnect power cable raspberry pi zero connect gps physically using presoldered four wires following color coding pins raspberry pi zero gps cable color raspberry pi zero pvin black cable pin 4 5v gnd white cable pin 6 ground rx grey cable pin 8 txd tx purple cable pin 10 rxd double check connection correct reconnect power cable raspberry pi zero raspberry pi zero restarts green light flashes testing gps raspberry pi restarted test gps using following command command line cgps note gps searching signal flash red 5 times 10 seconds flashes red 15 seconds connected satellites gps needs outdoors least balcony window sill partial view sky connect satellites cannot connect satellites indoors running recording interface want data gps dht22 automatically collected written file would also benefit system data displayed real time screen done python program meteobike03py download raspberry pi zero place raspberry pis desktop download meteobike03py start meteobike03py using lxterminal assuming file downloaded desktop python desktopmeteobike03py next make changes personalize copy meteobike03py example open python development environment version 27 file open replace 01 line 41 raspberryid system ' two digit number system number 7 enter 07 replace andreas line 42 studentname first name quotes capital letter way idenitify data upload later save modified code file save close python development environment every time meteobike03py started create new datafile contains data sampled example id record raspberrytime gpstime altitude latitude longitude temperature temperatureraw relhumidity relhumidityraw vapourpressure vapourpressureraw velocity 01 8 20180506 082903 20180506t062904000z 281700 47991855 7845193 230 231 419 420 1196 1192 514 01 9 20180506 082911 20180506t062912000z 288000 47991375 7845212 229 230 419 420 1188 1185 668 01 10 20180506 082924 20180506t062925000z 290000 47991242 7845800 230 231 419 420 1196 1192 356 also place link called bash script desktop meteobikesh download meteobikesh ensure works must change permissions file follows make executable way started doubleclick chmod x desktopmeteobikesh doubleclick meteobikesh start user interface later automate startup boot process system ready calibrated please return system hiwi place calibration chamber done first workshop congratulations workshop 2 calibrating system finalize mobile unit second practical workshop enter calibration coefficients sensorcalibration2020readmemdcalibration weather hut system install system protable bikebag insert sensor radiation shield power system battery mobile entering calibration coefficients watched online lecture calibration results enter calibration coefficients derived intercomparison directly python code open file meteobike03py python 2 editor raspberry pi zero w change follwing four lines &#9; temperaturecala1 100000 &#9; temperaturecala0 000000 &#9; vappresscala1 100000 &#9; vappresscala0 000000 replace values 100000 000000 temperature vapour pressure based individual correction coefficients listed sensorcalibration2020readmemdtables 1 3 calibration diretory respecively make sure use delimiter assembly protable system materials needed complete assembly system second workshop include reflective tape scissors sensor screenradiation shield bag gpstrh sensor velcro screw bolt foam assembly screen tube begin assembly meteobike system carefully cut reflective tape length plastic tube wrap tube tape lengthwise cut another piece length repeat step minimal overlap first piece tape two pieces tape cover entire tube cases tape already glued plastic tube tube completely covered tape use scissors puncture hole tape holes tube located sensor screen temperature humitidy sensor connect temperature humidity sensor radiation shield must disconnect temperature humidity sensor raspberry pi please ensure sensor connected source power use cirlce hook loop velcro attach sheild sensor place one piece inside radiaiton shield side 3 holes located close small hole farthest large hole place second piece velcro back side temperature humidity sensor pass wires sensor shield largest hole press sensor shield ensure velcro hold sensor shield together place shield close bag put temperature humidity sensor wires large hole bag must connect radiation shield sensor bag best use wrench screwdriver available insert bolt screw shields two holes hole bag using wrench hold bolt place use screwdriver insert screw bolt hold secure place thin plastic plate holes inside bag apply screw bolt inside also tighten hand though reconnect dht22 sensor physically using presoldered wires raspberry pi w dht22 trh sensor cable color raspberry pi zero pin 1 red cable pin 1 3v pin 2 orange cable pin 7 gpio4 pin 3 cable pin 4 brown cable pin 9 ground please double check make sure connection correct foam arrangement ensure protection sensor special foam used see structured cubical formation allows remove specific size pattern need given 20x28 cubical foam sheet using remove two 7x12 cube pieces one base sensor one altered protect raspberry pi system able remove 6 different 7x12 sheets original 20x28 sheet sizing foam raspberry pi remove foam cubes arrangement found one location foam must use scissors remove half cube power cable guided faced bag connect battery arrange foam battery sensors comfortably situated within bag arrangement within bag consist battery base followed unaltered foam cable battery altered foam raspberry pi within placement battery raspberry pi gps must place raspberry pi top altered foam connect battery cable raspberry pi altered foam cut half cubes way raspberry pi touching metal surface battery could lead shortcuts ultimately damage gps placed front pocket please make sure antenna facing ensure full connection satellites accurate track recorded system complete look similar image connecting raspberry pi smartphone system set similar arranged optionally connect mobile device vnc viewer order see progress collecting data mobile device skip step next week anyway install epaper could place mobile device front pocket behind gps first step enable phone host personal hotspot although need access internet use data plan capacity required order build network wifi communicate raspberry phone however make sure browse web download files connected personal hotspot otherwise charges apply data plan also make sure use personal course password protect connection description german enable personal hotsopt ios smartphone description german enable personal hotsopt android smartphone cases wifi network enabled connect network raspberry pi zero boot raspberry pi zero change wifi network personal hotspot wifi name enter password promted read ip number hover wifi symbol menu bar see eg 17220107 without comes afterwards go back phone start vnc app vnc app create new connection enter local ip number read eg 17220107 without comes afterwards connecting enter username pi previously set vnc password able control raspberry pi zero long phone raspberry close together put phone transparent lid bag also use second outlet power bank keep phone charged measurements case must bring chargercable ready install system bike let ' go test drive make sure indicator changes red yellow soon outdoors recording start good gps connection drive 15 20 minutes come back see data recorded display analyze recorded gps track gps track stored raspberry desktop commaseparated file raspberry wlan host computer easily establish ftp connection copy file host example free cyberduck free filezilla also use vnc software tranfer files first graphical representation track done place website httpwwwgpsvisualizercommapinput top left choose 1400 top right upload choose file click draw map colorcoded drawing temperature track options click advanced options make following settings colorize custom field custom colorization field temperature spectrum direction hue 1 120 hue 2 0 click draw map example also option export google earth workshop 3 installing epaper display feedback buttons workshop finalize meteobike adding epaper display responsive buttons instrument independent computer smartphone epaper uses imaging display technology called microencapsulated electrophoretic display med epaper displays patterns reflecting ambient light background light similar ereader requires little power readable full sunlight also slow update wiring epaper using wireframe 27inch epaper hat hat display black red color resolution 176 x 264 pixels screen look like back first turn raspberry pi w zero disconnect power cable 8 different wires ready connected raspberry pi follows plug white plastic connection back epaper cable color raspberry pi zero vcc grey cable pin 17 33v gnd brown cable pin 20 ground din blue cable pin 19 gpio10 clk yellow cable pin 23 gpio11 cs orange cable pin 24 gpio8 dc green cable pin 22 gpio25 rst white cable pin 11 gpio17 busy purple cable pin 18 gpio24 raspberry pi w zero connect wires exactly according drawing please doblecheck repowering starting raspberry pi w zero connections look like photo programming testing epaper doublechecked connection cable boot ie repower raspberry pi w zero connect via vnc alternatively screen keyboard mouse installation required libraries open lxterminal enter following commands updating python 2 environment downloading required libraries make sure raspberry pi zero w connection internet download drivers sudo aptget update sudo aptget install pythonpip sudo aptget install pythonpil sudo aptget install pythonnumpy sudo pip install rpigpio sudo pip install spidev next download python epaper library waveshare examples sudo git clone httpsgithubcomwaveshareepaper place epaper software homepiepaper raspberry pi test epaper go directory run factory test cd epaperraspberrypijetsonnanopythonexamples python epd2in7btestpy connected epaper correctly see number fancy tests visualisations epaper black red experts details setup programming found wireframe webpage httpswwwwavesharecomwiki27inchepaperhat hardware software setup section update meteobike program epaper version use epaper version meteobike program called meteobikeepaperpy found students university freiburg python script also available ilias place file meteobikeepaperpy raspberry pi ' desktop open file change lines 41 46 systemspecific information meteobike name calibration coefficients raspberryid 52 enter raspberry ' number studentname andreas enter first name spaces special characters temperaturecala1 100000 enter calibration coefficient slope temperature temperaturecala0 000000 enter calibration coefficient offset temperature vappresscala1 100000 enter calibration coefficient slope vapour pressure vappresscala0 000000 enter calibration coefficient offset vapour pressure start epaper version meteobike typing following command lxterminal python desktopmeteobikeepaperpy meteobikeepaperpy onscreen window anymore see anything onscreen happening program display output epaper instead first epaper display welcome screen boot screen left instructions use keys screen install next yet work 10 seconds epaper refresh display latest data measurement screen right refresh every 5 measurements every 40 seconds arrows next measurement values indicate variable increasing unchanged decreasing information displayed red show alerts example gps found enough satellites yet wifi network next change meteobikesh script point meteobikeepaperpy instead meteobike03py every startup raspberry pi w zero epaper version started instead old version make sure file meteobikesh permissions set done previously run chmod x desktopmeteobikesh new feature meteobikeepaperpy write one file per day file already exists given date data appended file written desktop also new column called speed gps time measurements actual speed system calculated enabling keys finally add three feedback buttons follows press key 1 program pause press key 2 program resume press key 4 program exit note key 3 currently assigned function connect three keys need 3wire cable 1 x blue 1 x green 1 x yellow follows connect wires shown drawing connections look similar following photos using epaper screen put top flap behind transparent protection alongside gps need using mobile device anymore make sure gps move epaper also ensure gps epaper touch connectors could cause shortcut use tape tie cables gps place well done ready measurements please test system follows press key 4 exit program reboot automatically reboots measurements take power fits bike see data gps measure records properly data riding around block also make sure charge battery end group exercise come workshop 4 detailed analysis geographic information system use free opensource geographic information system gis qgis perform advanced geographical analysis including statistics specific areas track rasterization many meteobike traces check separate page visualizing meteobike data wit qgis\n",
      "[1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1\n",
      " 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
      " 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0\n",
      " 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1]\n",
      "envirodashboard dashboard stack monitoring environment influxdb grafana grafana influxdb running docker find blog create environmental monitoring dashboard docker raspberry pi\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "enviromonitor indooroutdoor environmental monitor project enviro environmental monitoring board uses openweather api get current weather show display also display turned onoff passing finger near light sensor reduce energy consumption python library steps install found pimoronienviropluspython installing install configure dependencies github git clone httpsgithubcompimoronienviropluspython cd enviropluspython sudo installsh cd note raspbian lite users may first need install git sudo apt install git git clone httpsgithubcomcesnietorenviromonitorgit cd enviromonitor add environment variables make sure valid appid openweather curl httpsapiopenweathermaporgdata25weatherid2172797appiduniqueuuidunitsimperial define city id appid environment variables export openweathermapcityidyourcityid export openweathermapappiduniqueuuid change timezone cityname timezone city python timezone enviromonitorpy running python3 enviromonitorypy want run background process using ssh raspberry pi make sure process reparented init setsid python3 enviromonitorpy devzero errorlog yout want run pi boots refer rclocal\n",
      "[0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      "technical environmental systems general information software installation instructions welcome polimi ' technical environmental systems course attending first session course fill following survey inform us contact information academic background software skills course survey tes survey link survey asked create account following websites insert corresponding account informatio dropbox registration case dropbox account crate free account indicate corresponding email address first section survey github registration case account github please create one username please use human readable format eg mrossi rossimarco rossimarco m007r92 building component library bcl registration please create account nrel ' building component library httpsbclnrelgov username format github account create account dashboard find api key please save number easy access software installation course use energyplus sketchup openstudio downloaded installed also download files windows 64bit following dropbox link important note pay attention softwares installed order given energyplus sketchup openstudio noteworthy case already sketchup software installed computer might reinstall openstudio version might compatible installed version sketchup order check whether correctly installed abovementioned softwares verify openstudio addon added sketchup tools case using another operating system eg linux macos windows 32bits download following links energyplus link download suitable version software based operating system sketchup find suitable installation file sketchup make 2016 operating system link pay attention going use sketchup make sketchup pro commercial software openstudio installation files openstudio different operating system found project description project geometry commercial building first introduced sketchup characteristics building defined employing openstudio latter software next used calculate yearly heating cooling consumption building base case next parametric study conducted order investigate effect changing position wall characteristics buildings yearly energy consumption accordingly simulation performed three different cities three different walls corresponding obtained yearly consumptions compared ones base case pay attention conduct sensitivity analysis walls one city group information send information members group via link till 11122019 assigned timeslot details regarding final exam final written examination include exercises theoretical questions exercises similar topics ones solved class theoretical questions instead posed topics context exercise solved including solar radiation heat transfer windows heat gain infiltration ventilation centralized hvac system solar thermal systems theoretical questions students required write corresponding formulas instead able explain concepts explanation schematic representation needed formulas students required remember formulas related heat transfer walls conduction convection heat transfer series parallel conditions simplified heat transfer wall calculations formulas given exam paper thus students allowed bring formula paper rlf weather data tables along psychometric chart needed also provided exam student bring calculator students clearly remember bring simple calculator\n",
      "[1 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0\n",
      " 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0]\n",
      "bosch integrated environmental unit common unified sensor api supported ieu chips provides full feature access supported chips bmp280 bme280 bme680 bmp388 still providing rich chip specific features multiple heater profiles fifo access tested products adafruit bmp280 adafruit bme280 adafruit bme680 adafruit bmp388 note adafruit nolonger sells bmp085 bmp180 donation legacy chips welcome aid greater product support example usage api api organized around simple sensor class boschsensor provides object interface manipulating sensor method return promise simple demo usage follows const i2c1 await i2copenpromisified1 const addressedi2c1 new i2caddressedbusi2c1 0x77 const sensor await boschieusensoraddressedi2c1 await sensordetectchip await sensorcalibration const result await sensormeasurement boschieu sensoraddressedbus static factory method provide access boschsensor class boschieu sensor detectchip constructing sensor object detectchip method recommended attempt get detect version chip use register interactions sensordetectchip ifsensorvalid alternatively wish set chip initialization also possible sensorchipid chipbmp388 id returns chips id defined vendor valid chip detected valid returns true note legacy id call internal run detectchip sensorid thenid consolelog ' sensors id ' id calibration fetches calibration constants chip values unique chip needed perform compensation raw data values temperature pressure readings note must called measurment call return valid results note method caches results class needed externally though returned user inspection fifo fifo getter method returns static fifo class implementation provides namespace fifo functionality sensorfifoflush profile returns current chip profile device setprofileprofile sets profile chip note set entire profile fields included profile set defaults chip reset write softreset chip returning poweron state sensorresetthen measurement reads calculates related measurement data chip sensormeasurementthenresults process results fifo flush flushes fifo buffer using command register read reads current fifo buffer full specified size parses compensates frame data converter converter class common helps included ft meters altitude pa etc\n",
      "[1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0\n",
      " 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0]\n",
      "xdk iota data market place example add x sensors one specific nodejs server\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmentalpollution info 5100 project 3 project focuses typical dangerous environment pollutants connection health designed map linear regression graph bubble chart presents pollutants distribution relation longevity disease\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "eis document database search app makes archive epa ' environmental impact statements eis searchable linking results back eis documents epagov try eis search tool demo httpseissearchherokuappcom notes current version web app configured make requests user types autocomplete functionality may zero results showing halfway typing given word database currently used tool nonupdating snapshot records found epa ' eis database future enhancements pagination currently access first 10 results guithough remainder currently accessed via api adding facets search index help filter results axes like date range specific metadata fields geography document relevant better textpreprocessing tokenization tuning improved document mappings include relevant metadata fields appropriate weighting add info search page developers tools used app written go search index built bleve similar lightweight elasticsearch written golang using metadata extracted every reachable eis url including text extracted ocr attachedassociated pdfs developer setup install go make sure gopath ends right path profile run locally without cloning install repo ' dependencies go get githubcomedgigovdataarchivingeissearch run directory cd homegobin run eissearch server running httplocalhost8094 port specified command line output clone run clone repo go directory typically homegosrc inside cloned directory go build make file called eissearch run eissearch server running httplocalhost8094 port specified command line output license copyright copyright c 2019 environmental data governance initiative edgi program free software redistribute andor modify terms gnu general public license published free software foundation version 30 program distributed hope useful without warranty without even implied warranty merchantability fitness particular purpose see license file details\n",
      "[1 1 0 0 1 1 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1\n",
      " 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0]\n",
      "posec learning environmental calibration actions policy selfevolution posec code paper chao zhang yang yu zhihua zhou learning environmental calibration actions policy selfevolution proceedings 27th international joint conference artificial intelligence ijcai ' 18 stockholm sweden requirement python 27 argparse pickle keras 101 theano 082 tabulate scipy numpy instructions mainly use three tasks mujoco environment gym namely pusher striker thrower take pusher task example striker thrower alternative step 1training base policies generating multiple different configuration environmentsbr python changeenvconfigpy pusher using trpo1 generate multiple base policies python runpgpy env pusher agent modularrlagentzootrpoagent step 2optimizing combination weightss batch new configuration environments optimal weights base policies obtained based zoopt2 python getbestweightpy pusher step 3optimizing calibration actions batch new configuration environments optimal calibration actions obtained based zoopt2 python getbestactionpy pusher 1 schulman j levine abbeel p et al trust region policy optimization proceedings 32nd international conference machine learning icml ' 15 pages 18891897 lille france 2015 2 yuren liu yiqi hu hong qian yang yu chao qian zoopt toolbox derivativefree optimization arxiv180100329 2017\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "arcpyhabitat scripts delineating habitat environmental suitability\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "welcome repository share develop code please read collaboration documentation use github\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmentalsoundclassification environmentalsoundclassification using esc10 dataset dependencies python keras librosa sounddevice soundfile scikitlearn dataset uses esc10 dataset sound classification labeled set 400 environmental recordings 10 classes 40 clips per class 5 seconds per clip subset larger esc50 dataset setup repository trained convolution neural network multi layer perceptron svm sound classification achieved classification accuracy approx 80 mfcc melfrequency cepstrum feature used train models features like short term fourier transform chroma melspectrogram also extracted dataset downloaded kept inside dataset folder 10 different classes containing 10 ogg files visualize dataset running visualizedatapy script takes ogg file input converts wav form waveform visualized form plot python visualizedatapy dataset001 dog bark130226aogg sample wav file class generated kept within samplewav folder reference train classify execute mainpy python mainpy cnn training cnn python mainpy mlp training mlp python mainpy svm training svm internally mainpy uses extractfeaturespy nnpy svmpy create train model training done trained models automatically saved h5 format wave plot class baby wave plot class dog\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0]\n",
      "readme readme would normally document whatever steps necessary get application running things may want cover ruby version system dependencies configuration database creation database initialization run test suite services job queues cache servers search engines etc deployment instructions\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      "dvrsty entry environmental hackathon july 1213 2019 project allows specialists identify anomalies temperature co2 dew point humidity using artificial neural network known autoencoders addition reactjs front end back end python using aws sagemaker httpec2174129187236compute1amazonawscom3000 ec2 system host\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "environmentalism h0licow environments tell us kappaext\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "amritsartoday real time environmental data amritsar city backend frontend\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "requiredenvvarplugin require environmental variable application throw routhlessly zerodependency webpack plugin motivation ever found setting default env vars project make sure app get data developer forgets provide run risk serving hard debugging time contributors even worse ending wrong configuration deployment process accidental values environmental variables app get hard reminder face ' something set usage requirement webpack package installed since ' checking webpack plugin ' probably already register plugin provide required env var names parameters const requiredenvvarplugin require ' requiredenvvarplugin ' moduleexports plugins new requiredenvvarplugin ' apiurl ' ' user ' ' pass ' provide variables list revp ' apiurl ' ' user ' ' pass ' array revp ' apiurl ' ' user ' ' pass ' work hood uses webpack ' defineplugin passes object shape ' processenv ' apiurl xxx user xxx pass xxx xxx respective environmental variables derived processenvxxx ' find one throws faq throw ' warn user ' whole purpose plugin developer ' infere code ' find docs ' deduce application working env var ' set surely ' notice bunch logs spitted onto console startup message clear forgot ' launch license mit httpsopensourceorglicensesmitlicensephp\n",
      "[0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 1]\n",
      "r tools synoptic environmental spatial data tools reading plotting manipulating spatial data used australian antarctic division aad common example read environmental layer function date libraryraadtools ice readicec20180601 20190601 plotice available data sources accessed using read functions wide variety data sources data sets oceanography topography meteorology altimetry sea ice ocean colour many data sources mostly remote sensing include reanalysis model output products package uses r raster package always provides data standard raster rasterlayer rasterbrick rasterstack data set invdividually handled function ensure spatial temporal registration correct contents data library listed technical configuration would like collection added please make request via github issue contact one authors directly using raadtools two main ways use typical usecases raadtools read time series gridded data set function date optionally spatial subsetting match data set longitude latitude time corresponding value time series gridded data set examples workflows outlined ropensci blog post access raadtools repository data used raadtools available via nectar research cloud local use within aad two main ways access raadtools neither 1 2 work see local raadtools expert 1 rstudio raadtools server access raadtoolsrstudioserver need load package get started libraryraadtools 2 local computer within aad network installed trying installing devtoolsinstallgithubaustralianantarcticdivisionraadtools libraryraadtools typically provided access wont aware underlying details repository data used raadtools available rdsipublicraad aad scientific data collection anyone nectar account may run creating vm raadclient image search public images raadclient eg raadclient0620181016 choose latest one ensure ssh rstudio port 8787 open use default rstudiorstudio account create welcome make copies data collection use please respect citation usage requests data providers listed summary please note raadtools project released contributor code conduct contributing project agree abide terms\n",
      "[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 0\n",
      " 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0]\n",
      "xnucleoiks01a3 xnucleoiks01a3 motion mems environmental sensor expansion board stm32 nucleo equipped arduino uno r3 connector layout designed around lsm6dso 3d accelerometer 3d gyroscope lis2dw12 3d accelerometer lis2mdl 3d magnetometer hts221 humidity temperature sensor lps22hh pressure temperature sensor stts751 temperature sensor xnucleoiks01a3 interfaces stm32 microcontroller arduino boards via i2c pin examples several examples xnucleoiks01a3 library xnucleoiks01a3helloworld application provides simple example usage xnucleoiks01a3 expansion board shows display hyperterminal values onboard mems environmental sensors xnucleoiks01a3lis2dw126dorientation application shows use xnucleoiks01a3 lis2dw12 accelerometer find 6d orientation display data hyperterminal xnucleoiks01a3lis2dw12wakeupdetection application shows detect wakeup event using xnucleoiks01a3 lis2dw12 accelerometer xnucleoiks01a3lsm6dso6dorientation application shows use xnucleoiks01a3 lsm6dso accelerometer find 6d orientation display data hyperterminal xnucleoiks01a3lsm6dsofreefalldetection application shows detect free fall event using xnucleoiks01a3 lsm6dso accelerometer xnucleoiks01a3lsm6dsopedometer application shows use xnucleoiks01a3 lsm6dso accelerometer count steps xnucleoiks01a3lsm6dsosingletap application shows detect single tap event using xnucleoiks01a3 lsm6dso accelerometer xnucleoiks01a3lsm6dsodoubletap application shows detect double tap event using xnucleoiks01a3 lsm6dso accelerometer xnucleoiks01a3lsm6dsotiltdetection application shows detect tilt event using xnucleoiks01a3 lsm6dso accelerometer xnucleoiks01a3lsm6dsowakeupdetection application shows detect wakeup event using xnucleoiks01a3 lsm6dso accelerometer xnucleoiks01a3lsm6dsoxmlc application shows detect activity using mlc lsm6dsox accelerometer order use application stevalmki197v1 board needed connected xnucleoiks01a3 via dil24 interface xnucleoiks01a3stts751temeperaturelimit application shows detect low temperature high temperature events using xnucleoiks01a3 stts751 temperature sensor dependencies xnucleoiks01a3 library requires following stm32duino libraries stm32duino lsm6dso httpsgithubcomstm32duinolsm6dso stm32duino lis2dw12 httpsgithubcomstm32duinolis2dw12 stm32duino lis2mdl httpsgithubcomstm32duinolis2mdl stm32duino hts221 httpsgithubcomstm32duinohts221 stm32duino lps22hh httpsgithubcomstm32duinolps22hh stm32duino stts751 httpsgithubcomstm32duinostts751 stm32duino lsm6dsox httpsgithubcomstm32duinolsm6dsox documentation find source files httpsgithubcomstm32duinoxnucleoiks01a3 xnucleoiks01a3 datasheet available httpswwwstcomcontentstcomenproductsecosystemsstm32opendevelopmentenvironmentstm32nucleoexpansionboardsstm32odesensehwxnucleoiks01a3html\n",
      "[0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0]\n",
      "sustainable living sustainableliving description sustainable living designed help students live sustainable lives even dont want offers sustainable living suggestions variety user interests saving money saving time social networking sustainable living incorporates gamification awarding points order encourage users participate points given users creating tips events completing tips attending events moderating content users earned points even compare scores users via leaderboard implemented features create event users submit event system approval moderators event approved user host even qr code users attend points complete tip users browse tips system work completing users complete tip receive points attend event users phyiscally events find qr code scan prove attended receive points moderate content tips events created system need moderated public facing moderators task approving denying tips events one one giving feedback whenever deny tip event compare scores leaderboard users get points see points stack users leaderboard page usabilty quality attributes supports small screen devices typical use time minutes provides quick access less 3 clicks frequently used features limits awkward fatiguing movements making buttons large grouped use color help user choose right action give feedback every finished interaction browser back button used undo always available running project project includes livereloading static server port 8080 change port gulpfilejs config build launch rebuild app whenever change application code start server run npm start prefer build without live reload buildoneachchange watcher run npm run build generating additional code add additional functionality application invoking subgenerators included flux generator add components using following commands components yo fluxcomponent componentname actions yo fluxaction actioncreatorname stores yo fluxstore storename\n",
      "[1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0]\n",
      "nag brooklyn ' greenpoint williamsburg toxicity map interactive map neighbors allied good growth showing pollution demographic data neighborhoods greenpoint williamsburg brooklyn new york created summer fall 2015 pratt ' spatial analysis visualization initiative dependencies nodejs cartodbjs mapboxjs bower jquery jquery ui handlebarsjs normalizecss installation bower install download dependencies locally data processing cartodb see sql directory code relating formatting data tables cartodb postgres creating basemap tiles requires using mapbox studio classic mapbox account note time creating project mapbox studio classic replaced newer version software titled mapbox studio basemap directory contains necessary files create basemap tiles mapbox studio classic tm2 files specifying styling basemap ' tiles tm2source contains necessary files point custom data layers data folder created mapbox studio classic adding data layer aka source data contains zipped esri shapefiles required tm2source toxicitybasemaptm2z project ' styles metadata compressed format updating map ' cartodb data layers ' styles make editing cartocss easier cartodb data layers layer ' corresponding cartocss saved mss file mss directory cartotojsjs script used minify mss file compile object returned appcartocss module update cartocss following alter corresponding mss file data layer mss directory save node cartotojsjs update appcartocss module stored inside file jscartojs contributors chris henrick bowon chung\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
      "environmentalcodefestapi api codefest app setting order get everything set run make install install requirements initialize database run start serving api run make run navigate http1270015000 view documentation\n",
      "[0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmentalmonitoring data prediction environmental monitoring\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "html5 environmental thermometer repository contains demo ' developed part article titled create html5 environmental thermometer written sitepoint html5 environmental thermometer simple adaptive environmental thermometer created show potentiality union brand new web technologies html5 css3 geolocation api others demo uses semantic possible detailed html5 markup css3 javascript styling positioning thermometer order look like real environmental thermometer since uses svg background image adapted different sizes without stretched however folder ' also png background image support older browsers ' support svg interesting part demo regards positioning thermometer labels fact since thermometer 90 rotated css3 sufficient center javascript used moreover latter used set number labels dynamically evenly space used pinch make thermometer employ followings html5 markup css3 style demo javascript jquery adjust thermometer position set position labels svg background adaptive much polyfill support browsers ' support meter element geolocation api get user current position google maps api convert geolocation address yahoo weather api retrieve woeid code temperature demo live demo available license html5 environmental thermometer dual licensed mit gpl30 author aurelio de rosa aurelioderosa\n",
      "[0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0]\n",
      "corbabased clientserver system requirements system broken number separate systems need communicate clientserver manner solve overall requirements 1 monitoring station monitoring station standalone monitoring system prototyped corba server supports following functionality least register regional centre upon initial activation remotely activated remotely deactivated remotely reset return upon request current value nitrogen oxides sensor identify anomalous potentially dangerous readings nitrogen oxides alert local server immediately 2 precompile idl open intellij terminal type local server prototyped corba server supports following functionality least receives requests register monitoring stations maintains list connected devices receives alerts connected monitoring stations maintains log alerts triggers alarm environmental centre two alarms happen within specified time frame returns log upon request polls connected monitoring stations requested returns set readings 3 monitoring centre monitoring centre prototyped corba server supports following functionality least receives confirmed alarms local servers alerts operator confirmed alarm received allows agencies eg environment agency local councils local pressure groups etc register notifications particular areas case alarms maintains list connected local servers polls local servers upon request displays results readings returned highlighting readings concern run demo intellij add libraries jacorb lib folder module note add module project required ' know minmum set add jboss library precompile idl open intellij terminal type cd relaywithguisdemosrc pathtojacorbdirbinidl localmonitoringstationlocalmonitoringstationuiidl eg would type cd relaywithguisdemosrc sparejacorb39binidl localmonitoringstationlocalmonitoringstationuiidl run different components system need start following order sensorsensorserver localmonitoringstationlocalmonitoringstationui headquarterheadquarterui\n",
      "[0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1\n",
      " 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "project bootstrapped create react app available scripts project directory run npm start runs app development mode open httplocalhost3000 view browser page reload make edits also see lint errors console npm test launches test runner interactive watch mode see section running tests information npm run build builds app production build folder correctly bundles react production mode optimizes build best performance build minified filenames include hashes app ready deployed see section deployment information npm run eject note oneway operation eject cant go back arent satisfied build tool configuration choices eject time command remove single build dependency project instead copy configuration files transitive dependencies webpack babel eslint etc right project full control commands except eject still work point copied scripts tweak point youre dont ever use eject curated feature set suitable small middle deployments shouldnt feel obligated use feature however understand tool wouldnt useful couldnt customize ready learn learn create react app documentation learn react check react documentation code splitting section moved httpsfacebookgithubiocreatereactappdocscodesplitting analyzing bundle size section moved httpsfacebookgithubiocreatereactappdocsanalyzingthebundlesize making progressive web app section moved httpsfacebookgithubiocreatereactappdocsmakingaprogressivewebapp advanced configuration section moved httpsfacebookgithubiocreatereactappdocsadvancedconfiguration deployment section moved httpsfacebookgithubiocreatereactappdocsdeployment npm run build fails minify section moved httpsfacebookgithubiocreatereactappdocstroubleshootingnpmrunbuildfailstominify\n",
      "[0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0]\n",
      "snapshots environmental twitter activity overview visit website environmentaltwitterherokuappcom default tweet cap set 500 tweets twitter rate limit ' quickly block using website would like increase cap change text box next reload button higher number must multiple 100 twitter may still return fewer tweets ' enough available rate limit reached increase cap risk background since inauguration donald trump 45th president united states epa faced severe funding cuts deregulation one biggest centers community response twitter many users expressed outrage praise recent changes environmental protection us capture well public opinion poll twitter data perform sentiment analysis order better understand public feels epa given time site track store data long periods rather looks quick snapshot twitter activity captured every page load argue provides context long term trend analysis rather allows users get insight public feels epa instant load site methods general sense website read current tweets epa recent tweets tags epa perform sentiment analysis tweets searching positive negative sentiment results graphed various charts look tweet counts retweet counts break sentiment timezone learn methods methods input data input analysis json object returned twitter rest apis focus following attributes input data jsonresponse ' statuses ' contains tweet objects returned latest search tweet ' fulltext ' extracts full text current status tweet ' user ' ' name ' gives username person tweeted current status tweet ' user ' ' timezone ' gives timezone user tweet ' retweetcount ' retweet count current tweet many times users retweeted tweet ' createdat ' gives date time tweet posted output data data plot broken following segments datasentiments sentiment total tweet dataitems raw tweet data eg username text etc datadates dates tweet dataretweets sentiment totals weighted retweet count see methodology datatimezones count tweets timezone datatimezonessentiment overall sentiment timezone display data display data using two histograms sentiment count tweets sentiment count retweets pie chart timezone distribution bar chart overall sentiment timezone deploying deploy website simply push updated files repo automatically deploys heroku app crashes let know restart dynos author web app created nick moolenijzer nickmoolenijzercom contact questions architecture django used django framework serve render html files output python data analysis heroku builds hosts web app redis go heroku addon simple redis implementation libraries pythonoauth2 utilized authorize get requests using twitter auth tokens natural language toolkit necessary tools analyzing tweets sentiment eg tokenizing pos analysis classifying plotly used plot results text analysis numpy helps various calculations scientific analysis djangorq provides framework background workers analyze twitter data web dyno redis provides backend rq background workersqueueing apis twitter rest apis allows programmatic search twitter activity assets google material icons icons web use license written code licensed mit license open source license libraries data external resources may licenses must followed sources tutorials helpful references bird steven ewan klein edward loper natural language processing python beijing ' reilly 2009 httpwwwnltkorgbook1ed kantrowitz mark bill ross names corpus np 29 mar 1994 web 30 jan 2017 httpwww2cscmueduafscsprojectairepositoryaiareasnlpcorporanames liu bing pros cons np 2008 web httpswwwcsuiceduliubfbssentimentanalysishtmldatasets loper edward source code nltkclassifynaivebayes nltkclassifynaivebayes nltk 30 documentation np nd web 30 jan 2017 nltk classifiers classifiers np nd web 30 jan 2017 nltk natural language toolkit natural language toolkit nltk 30 documentation np nd web 30 jan 2017 nltk nltk package nltk package nltk 30 documentation np nd web 30 jan 2017 nltk nltkclassify package nltkclassify package nltk 30 documentation np nd web 30 jan 2017 perkins jacob python nltk demos natural language text processing python nltk demos natural language text processing nlp np nd web 30 jan 2017 poole david alan mackworth artificial intelligence artificial intelligence foundations computational agents 733 bayesian classifiers np 2010 web 30 jan 2017 5 categorizing tagging words nd retrieved march 12 2017 httpwwwnltkorgbookch05html asynchronous tasks jobs django rq enproftme nd retrieved march 11 2017 httpenproftme2016104asynchronoustasksandjobsdjangorq background tasks python rq heroku dev center nd retrieved march 7 2017 httpsdevcenterherokucomarticlespythonrq coolors nd retrieved march 11 2017 httpscoolorsco9f7e69d2bba0f2efc7f7ffe0ffeee2 deploying python django apps heroku heroku dev center nd retrieved february 16 2017 httpsdevcenterherokucomarticlesdeployingpython django connection refused redis heroku stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions11813470connectionrefusedforredisonheroku get searchtweets twitter developers nd retrieved march 9 2017 httpsdevtwittercomrestreferencegetsearchtweets google fonts nd retrieved march 8 2017 httpsfontsgooglecom heroku redis heroku dev center nd retrieved march 11 2017 httpsdevcenterherokucomarticlesherokuredisconnectinginpython histograms nd retrieved march 11 2017 httpsplotlypythonhistograms use sessions django documentation django nd retrieved march 11 2017 httpsdocsdjangoprojectcomen110topicshttpsessions http get request javascript stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions247483httpgetrequestinjavascript javascript whats easiest way call function every 5 seconds jquery stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions2170923whatstheeasiestwaytocallafunctionevery5secondsinjquery joestumppythonoauth2 nd retrieved march 12 2017 httpsgithubcomjoestumppythonoauth2 joestumppythonoauth2 fully tested abstract interface creating oauth clients servers nd retrieved february 16 2017 httpsgithubcomjoestumppythonoauth2 managing static files eg images javascript css django documentation django nd retrieved february 16 2017 httpsdocsdjangoprojectcomen110howtostaticfiles material icons material design nd retrieved march 12 2017 httpsmaterialioicons natural language toolkit nltk 30 documentation nd retrieved march 12 2017 httpwwwnltkorg numpy numpy nd retrieved march 12 2017 httpwwwnumpyorg personal apps heroku nd retrieved march 12 2017 httpsdashboardherokucomapps pie charts nd retrieved march 11 2017 httpsplotlypythonpiecharts pyplot matplotlib 200 documentation nd retrieved march 8 2017 httpmatplotliborgapipyplotapihtml python adding config modes plotlypy offline modebar stack overflow nd retrieved march 9 2017 httpstackoverflowcomquestions36554705addingconfigmodestoplotlypyofflinemodebar python embedding plotly chart django template stack overflow nd retrieved march 9 2017 httpstackoverflowcomquestions36846395embeddingaplotlychartinadjangotemplate python flask passing around background worker job rq redis stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions12162021flaskpassingaroundbackgroundworkerjobrqredis python get job result rq stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions22776924pythonhowtogetjobresultbyrq redis nd retrieved march 12 2017 httpsredisio redis get job id rq python stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions15181630howtogetjobbyidinrqpython redis oom command allowed used memory maxmemory 2016 may 16 retrieved httpsmattiasberedisoomcommandnotallowedusedmemorymaxmemory redis go addons heroku elements nd retrieved march 12 2017 httpselementsherokucomaddonsredistogo rest apis twitter developers nd retrieved february 16 2017 httpsdevtwittercomrestpublic rq simple job queues python nd retrieved march 11 2017 httppythonrqorg simple job queues djangorq imaginary landscape nd retrieved march 11 2017 httpswwwimagescapecomblog20130613simplejobqueuesdjangorq singleuser oauth examples twitter developers nd retrieved february 16 2017 httpsdevtwittercomoauthoverviewsingleuser smistad e nd making charts output images browser django erik smistad retrieved httpswwweriksmistadnomakingchartsandoutputingthemasimagestothebrowserindjango stack overflow nd retrieved march 7 2017 httpstackoverflowcom street nd using redisqueue asynchronous calls django retrieved httpracingtadpolecomblogredisqueuewithdjango web framework perfectionists deadlines django nd retrieved march 12 2017 httpswwwdjangoprojectcom thumbnail gallery matplotlib 200 documentation nd retrieved march 7 2017 httpmatplotliborggalleryhtml uidjangorq nd retrieved march 12 2017 httpsgithubcomuidjangorq visualize data together nd retrieved march 12 2017 httpsplotly worldvectorlogo brand logos free download nd retrieved march 7 2017 httpsworldvectorlogocom\n",
      "[0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 0]\n",
      "environmentmonitor tool continuous gathering aggregation representation environment health provides access environment status information via ui dashboards rest api current environment components states environment components daily statistics particular component availability time quickstart test extension docker git clone httpsgithubcomyagelnasmanitenvironmentmonitorgit dockercompose build without docker quick start test extension documentation see wiki available documentation feature requests bugs found bug would like see new feature implemented raise issue issue tracker contributing eager fix bug introduce new feature clone repository issue pull request license environmentmonitor licensed apache license 20\n",
      "[1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "rpienvironmentalmonitoring raspberry pi home environment monitoring system test config moduleexports port8080 session maxage 20 60 1000 session 20 min db host ' localhost ' user ' root ' password ' 111111 ' database ' rpienvironmentalmonitoring ' port ' 3307 ' set admintable password default localhostportadmin usernameadmin password111111 cd weblib node logmd5js run node server git clone cd web npm install node indexjs\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0]\n",
      "sahana eden sahana eden emergency development environment open source framework rapidly build powerful applications emergency management web based collaboration tool addresses common coordination problems disaster finding missing people managing aid managing volunteers tracking camps effectively government groups civil society ngos victims please see website details httpedensahanafoundationorg note developers get started httpedensahanafoundationorgwikidevelop first pull request sign contributor ' license agreement protects rights code allowing distributed used sahana eden httpbitlyssfecla\n",
      "[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0]\n",
      "envandfiles load configuration environmental variables files according twelvefactor app configuration come environmental variables since environmental variables leak easily people use secrets sensitive information module made support either minimal setup install npm install envandfiles yarn yarn add envandfiles usage const loadconfig require ' envandfiles ' loadconfig conceptual grouping configuration properties case configuration logger logger loggerlevel property equal loglevel environmental variable undefined present level ' loglevel ' server port specify property required port found error given required true coerce value number ' coerced error given type ' number ' variablename ' port ' sql password sqlpassword property equal contents pathtosecret undefined could read filepath ' pathtosecret ' required true thenconfig config object map configuration groups ' get something like logger level undefined server port 8000 sql password ' abc123 ' consolelogconfig catcherror required properties cannot loaded promise reject consoleerrorerror api loadconfigconfigmap load configuration returns promise resolve loaded configuration reject configuration invalid configmap type object object map conceptual groupings necessary configuration find default configuration properties optional one marked required found error given see usage examples config maps loadconfigsyncconfigmap load configuration synchronously returns loaded configuration throws configuration invalid configmap type object asynchronous version license mit matthew fernando garcia\n",
      "[0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      "esc50 classifiers environmental sound classification dataset directory structure &#9; &#9; &#9; &#9; root directory want store data audio &#9; &#9; &#9; contains 2000 recordings categorytargetpkl &#9; &#9; category target dictionary pickled &#9; &#9; &#9; contains pickled dataset using utilspickledataset &#9; model &#9; fold1 &#9; &#9; contains model trained fold 1 validation set also log file training process &#9; fold2 &#9; fold3 &#9; fold4 &#9; fold5 fold folder logcsv file storing training log weightsbesthdf5 storing trained model ' weights steps run get audio files esc50 github httpsgithubcomkaroldvlesc50git run pickledataset utilspy compute features clip store run train mainpy fold run evaluate mainpy evaluate models source code clippy contains class clip audio clip features phase encoded mel filterbank energies pefbes filterbank energies fbes extracted modelpy contains model class makes cnn model ' architechture mainpy contains functions trainpredict evaluate model utilspy contains functions saving loading dataset\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      "appconfiguration appconfiguration simple gem helps configure ruby applications appconfiguration uses yaml config files environmental variales set configuration parameters installation add line application ' gemfile gem ' appconfiguration ' execute bundle install gem install appconfiguration usage appconfiguration comes great default values want setup new config need config appconfigurationnew myconfigurablevariable configfoo myothervariable config ' bar ' default getting variable foo appconfiguration look environmental variable foo cannot find appconfiguration look configyml file current working directory config file try find configyml home directory possible configyml example could look like foo ' foo variable ' bar ' bar variable ' customize configuration appconfiguration customized fit needs example config appconfigurationnew ' setupyml ' baselocalpath ' usrlocal ' baseglobalpath ' config ' useenvvariables true prefix ' myapp ' end set configuration file name passing name new method use configfilename method inside configuration block configfilename sets name config file default configyml baselocalpath sets base path local configuration file config file path look global configuration path default baseglobalpath sets base path global configuration file default useenvvariables flag activates use enviromental variable default true prefix prefix appended looking environmental variables example prefix set myapp foo variable fetched myappfoo environmental variable checked used avoid name collitions default nil variable lookup retrieve variable appconfigurationconfig object foo configfoo foo config ' foo ' environmental variables checked first adding necesary prefix provided environmental variable local config file checked local file value defined given variable global config file checked otherwise returns nil configuration registry create new config object using appconfigurationnew must keep reference configuration instead registers configuration using appconfigurationfor obtain configuration using appconfiguration example appconfigurationfor github somewhere else github appconfigurationgithub githubapikey previous example name configuration file assumed githubyml environmental variables prefixed github change behaviour passing configuration block method example want change local path register configuration follows appconfigurationfor github baselocalpath railsroot end default values change default local path default global path appconfigurationconfig objects need appconfigurationconfigdefaultlocalpath railsroot appconfigurationconfigdefaultglobalpath ' usrconfigs ' contributing fork create feature branch git checkout b mynewfeature commit changes git commit ' add feature ' push branch git push origin mynewfeature create new pull request please add specs new features find bug spec probing bug exists separate commit add bug fix license copyright c 2013 guido marucci blas mit license permission hereby granted free charge person obtaining copy software associated documentation files software deal software without restriction including without limitation rights use copy modify merge publish distribute sublicense andor sell copies software permit persons software furnished subject following conditions copyright notice permission notice shall included copies substantial portions software software provided without warranty kind express implied including limited warranties merchantability fitness particular purpose noninfringement event shall authors copyright holders liable claim damages liability whether action contract tort otherwise arising connection software use dealings software\n",
      "[0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1\n",
      " 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 0 1 0 0 0 1]\n",
      "allay alleviate environmental pain installation requirements python 2 27 greater httpswwwpythonorgdownloads pip httpspippypaioenstableinstalling using brew macos users brew install python httpsbrewsh docker toolbox docker windowsmac httpsdocsdockercomengineinstallation prerequisite install magnet pip install githttpsgithubcombriandleemagnetgiteggmagnet pip install githttpsgithubcombriandleeallaygiteggallay configuring database synchronization ensure volume configured store database files database schema files volumesyml settingsyml add section dbsync settings specified required dbsync user allay host mydbhostcom schemas schema1schema2 schemasvolume volumenameoptionalpath databasevolume volumenameoptionalpath optional properties include integer schemafilemaxage determines schema deemed old days string remotepath determines look database schema files default homedatabaseschemas configure server create user account use database synchronization configure user write database sql dumps desired location default homedatabaseschemas schema files named according schema represent schema file schema1 stored homedatabaseschemasschema1sqlgz setup key access user access new user account currently supports use default key sshidrsapub set next time allay runs try connect host using configured user account run comparison files currently found schemasvolume director corresponding files server download ssh next ensure database container equipped ingest schema files initialization warning allay downloads new schemas deletes contents database data directory force ingestion newly downloaded files\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0]\n",
      "poc currently production ready mileage may vary rebaked environmental device management system environmental inventorydevice management system built hundreds entities thousands environments millions devices rebaked environmental device management system quick getting started development guide build cruton container start cruton cassandra create keyspace tables created sync tables working api discovery entities head entities put entity head entities post one many entities bulk import get entities get entities search get entities search partial match using provided criteria environments head environments put environment head environment post one many environments bulk import get environments get environments search get environments search partial match using provided criteria devices head devices put device head device post one many devices bulk import get devices get devices search get devices search partial matching using provided criteria get ipxe return specific device utilities synchronizing table space backend store quick getting started development guide following guide result running cruton application requirements docker dockercompose build cruton container dockercompose build start cruton cassandra dockercompose create keyspace tables created setup creates basic cassandra container authentication needed ' need create user password howerver need createa keyspace docker exec ti cassandracruton cqlsh localhost e create keyspace exists cruton replication ' class ' ' networktopologystrategy ' ' datacenter1 ' 1 sync tables docker exec ti crutoncruton1 crutonmanage configfile etccrutoncrutonini synctables working api start api ' recommended run service behind webserver like nginx apache using uwsgi etc typical api process envoked running crutonapiwsgi configfile etccrutoncrutonini command need want run api debug mode invoking crutonapidebug configfile etccrutoncrutonini command discovery curl ' http1270015150dicovery ' api endpoints available actions discoverable dicovery endpoint allows user application discover available actions available versions entities head entities curl head ' http1270015150v1entities ' put entity curl h ' contenttype applicationjson ' xput ' http1270015150v1entitiessolo1 ' ' name testentitysolo ' head entities curl head ' http1270015150v1entitiessolo1 ' post one many entities bulk import curl h ' contenttype applicationjson ' xpost ' http1270015150v1entities ' ' entid ent1 tags testentitytagone contacts person1 4155551212 person2 emailperson2examplecom name testentityone entid ent2 tags testentitytagone testentitytagtwo contacts person2 emailperson2examplecom name testentitytwo ' get entities curl ' http1270015150v1entities ' get entities search curl ' http1270015150v1entitiescontactperson1 ' get entities search partial match using provided criteria curl ' http1270015150v1entitiesnameentitytagfuzzytrue ' aware field data module part search criteria environments head environments head environments root curl head ' http1270015150v1entitiesent1environments ' put environment curl h ' contenttype applicationjson ' xput ' http1270015150v1entitiessolo1environmentssoloenv1 ' ' name soloenvironmentone ' head environment head environments root curl head ' http1270015150v1entitiesent1environmentssoloenv1 ' post one many environments bulk import curl h ' contenttype applicationjson ' xpost ' http1270015150v1entitiesent1environments ' ' envid env1 tags testenvironmenttagone contacts person1 4155551212 person2 emailperson2examplecom name testenvironmentone envid env2 tags testenvironmenttagone testenvironmenttagtwo contacts person1 4155551212 name testenvironmenttwo ' get environments curl ' http1270015150v1entitiesxenvironmentsenv2 ' get environments search curl ' http1270015150v1entitiesxenvironmentscontactperson1 ' get environments search partial match using provided criteria curl ' http1270015150v1entitiesxenvironmentstagenvironmenttagfuzzytrue ' aware field data module part search criteria devices head devices curl head http1270015150v1entitiessolo1environmentssoloenv1devices put device curl h ' contenttype applicationjson ' xput ' http1270015150v1entitiessolo1environmentssoloenv1devicessolodev1 ' ' name solodeviceone ' head device curl head http1270015150v1entitiessolo1environmentssoloenv1devicessolodev1 post one many devices bulk import curl h ' contenttype applicationjson ' xpost ' http1270015150v1entitiessolo1environmentssoloenv1devices ' ' devid dev1 tags testenvironmenttagone accessip drac 17216241 mgmt fe806656fc1dcd1ddba rackid testrack1 rowid testrow1 name testdeviceone devid dev2 tags testdevicetagone testdevicetagtwo accessip drac 17216242 mgmt fe806656fc1dcd1ddbb rackid testrack2 rowid testrow1 name testdevicetwo ' get devices curl ' http1270015150v1entitiessolo1environmentssoloenv1devices ' get devices search curl ' http1270015150v1entitiessolo1environmentssoloenv1devicesrowidtestrow1 ' get devices search partial matching using provided criteria curl ' http1270015150v1entitiessolo1environmentssoloenv1devicesnametestfuzzytrue ' aware field data module part search criteria get ipxe return specific device curl ' http1270015150v1entitiestestentity1environmentstestenvironment1adevicestestdevice1aipxe device variable ipxe prefix ipxe endpoint return ipxe config using variables utilities automated data population simply done using ansible playbook helpful playbooks found synchronizing table space backend store crutonmanage configfile etccrutoncrutonini synctables additional documentation data model installation cassandra\n",
      "[0 0 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0\n",
      " 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1]\n",
      "environmental website page sample site one plurality layouts webdev resources implemented menu slogan twocolumn content uncomplicated footer project\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "rpienvironmentalmonitoring raspberry pi home environment monitoring system test config moduleexports port8080 session maxage 20 60 1000 session 20 min db host ' localhost ' user ' root ' password ' 111111 ' database ' rpienvironmentalmonitoring ' port ' 3307 ' set admintable password default localhostportadmin usernameadmin password111111 cd weblib node logmd5js run node server git clone cd web npm install node indexjs\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0]\n",
      "moodcube 3d lattice rgb leds driven ann environmental sensors inputs existing things programmable cube 390 mic acc httpcubetubeorg httpwwwinstructablescomid8x8x8rgbledcube neopixel httpslearnadafruitcomadafruitneopixeluberguideoverview single wire rgb audio spectrum analyzer pi signal flow something acquires sample many sensors samples passed neural network nonlinear processing vector input time series outputs nn passed output processor takes outputs writes leds led drive neopixel dotstar style arduino raspberry pi compatible leds single strip addressable rgb leds 3rd party products also like hkbayi fadecandy board takes usb input drive 8 strips 64 leds ' total 8x64 512 leds could cube 4 sides 1 top 10x10 leds per side 500 total led strips mounted clear plastic rods make shape something like cube use 3d printer make wild shapes mount trees spheres japanese lantern klein bottle maybe hang frame like hanging gardens living trees avatar needs 60 per led full power use 5v 10a acdc adapter power bus spread power strip github markdown httpsguidesgithubcomfeaturesmasteringmarkdown learning stochastic gradient method least mean squares synapse sensors sources audio datachunk int16 fs1chunk 16k 16k audioblrmschunkbands databands int16 fs1chunk 16k 16k proximityfs databands int16 fsfs 0 400 datefs datadtweekday dthour dtminute dtsecond fsfs synapse autostart systemd fcserver synapse processes autostart using pi user system user session homepiconfigsystemduserfcserverservice homepiconfigsystemdusermoodcubeservice services called fcserver moodcube launch following scripts fcserver homepigitmoodcubefadecandyfcserverlaunchsh moodcube homepigitmoodcubelaunch control processes using systemctl user command show service status systemctl user status moodcube reload configuration needed change config file configsystemduser systemctl user daemonreload restart service systemctl user restart moodcube stop service systemctl user stop moodcube follow logs journalctl f journalctl f cat terse\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0]\n",
      "environmental data logger design files software small lowpower temperature humidity logger probably remarkable feature power consumption 32a less better documentation found hackadayio credits hd44780 library sa development i2c library peter fleury\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "electric imp environmental data streaming hub electric imp environmental data streaming electric imp nora motion environmental data streaming tutorials find code materials tutorials well tutorials wiki lot internetconnected devices price going usually cheaper harder program make secure electric imp platform paired hardware makes connecting internet quickly securely seamlessly piece cake hard network work without change thing way focus data want collect send ' super cool looking read\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0]\n",
      "national co2 emissions fossilfuel burning cement manufacture gas flaring 17512014 contributors ta boden rj andres carbon dioxide information analysis center environmental sciences division oak ridge national laboratory oak ridge tennessee 378316290 usa g marland research institute environment energy economics appalachian state university boone north carolina 286082131 usa doi 103334cdiac00001v2017 notes emission estimates expressed thousand metric tons carbon convert estimates units carbon dioxide co2 simply multiply estimates 3667 per capita emission estimates expressed metric tons carbon population estimates available permit calculations global per capita estimates 1950 please note annual sums tallied element eg gas rounded reported totals may differ slightly sum elements due rounding methods publications containing historical energy statistics make possible estimate fossil fuel co2 emissions back 1751 etemad et al 1991 published summary compilation tabulates coal brown coal peat crude oil production nation year footnotes etemad et al1991 publication extend energy statistics time series back 1751 summary compilations fossil fuel trade published mitchell 1983 1992 1993 1995 mitchell ' work tabulates solid liquid fuel imports exports nation year pre1950 production trade data digitized co2 emission calculations made following procedures discussed marland rotty 1984 boden et al 1995 details contents processing historical energy statistics provided andres et al 1999 1950 present co2 emission estimates derived primarily energy statistics published united nations 2016 using methods marland rotty 1984 energy statistics compiled primarily annual questionnaires distributed un statistical office supplemented official national statistical publications stated introduction statistical yearbook cases official sources supplemented sources estimates subjected professional scrutiny debate consistent independent sources data us department interior ' geological survey usgs 2016 used estimate co2 emitted cement production values emissions gas flaring derived primarily un data supplemented data us department energy ' energy information administration 1994 rotty 1974 data provided g marland greater details methods provided marland rotty 1984 boden et al 1995 andres et al 1999 references andres rj dj fielding g marland ta boden n kumar 1999 carbon dioxide emissions fossilfuel use 17511950 tellus 51b75965 boden ta g marland r j andres 1995 estimates global regional national annual co2 emissions fossilfuel burning hydraulic cement production gas flaring 19501992 ornlcdiac90 ndp30r6 oak ridge national laboratory us department energy oak ridge tennessee marland g rm rotty 1984 carbon dioxide emissions fossil fuels procedure estimation results 195082 tellus 36b23261 etemad b j luciani p bairoch jc toutain 1991 world energy production 18001985 librarie droz switzerland mitchell br 1983 international historical statistics americas australasia 17501988 pgs 522525 gale research company detroit united states mitchell br 1992 international historical statistics europe 17501988 pgs 465485 stockton press new york united states mitchell br 1993 international historical statistics americas 17501988 pgs 405414 stockton press new york united states mitchell br 1995 international historical statistics africa asia oceania 17501988 pgs 490497 stockton press new york united states rotty rm 1974 first estimates global flaring natural gas atmospheric environment 868186 united nations 2017 2014 energy statistics yearbook united nations department economic social information policy analysis statistics division new york us department energy 1994 international energy annual 1994 doeeia021991 energy information administration office energy markets end use washington dc us geological survey 2017 2014 minerals yearbook cement hg van oss ed us department interior us geological survey reston virginia licence cdiac page states wish use diagram image graph table materials cdiac website concerned obtaining permission possible copyright restrictions concerns reports graphics data information cdiac website freely publicly available without copyright restrictions however professional courtesy ask original data source acknowledged suggested citations appear bottom page data set citation boden ta g marland rj andres 2017 global regional national fossilfuel co2 emissions carbon dioxide information analysis center oak ridge national laboratory us department energy oak ridge tenn usa httpsdoiorg103334cdiac00001v2017\n",
      "[0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0]\n",
      "coding open data environmental reporting bc repo ' develop collection lessons based data code environmental reporting bc released content guidelines skill focus lesson focus helping learners gain skill ' need work data code released bc enable learners transfer skills projects lesson format anything goes ' looking guidance consider study group lesson one hour handson tutorial designed led instructor workshop lesson like study group longer selfstudy curriculum tutorial designed followed independent learner content format keep simple dependencyfree possible markdown plain text text ipython notebooks knitr scripts good options contributing please place lesson folder make sure everything needed scripts pointers data code etc included clearly labeled lesson folder feel free start brainstorming lesson ideas issue tracker begin\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "epa sms dispatcher simple system environmental protection agency dispatch substitute military service personnel although system designed epa easily modified fit departments well demo demo page httpchunnorrisccdemoepasms demo files sample input txt sample output personnel csv sample output personnel jpg sample output region csv sample output region jpg regionjson whatt regionjson totalstudents regionjson available ansi big5 csv bom utf8 csv csv 1 2 3 4 csv xxxtinputfilecsv 5 6 50 7 49 7 csv na 7 firefox github download zip firefox indexhtml csv txt csv txt eg 144tinputfilecsv txt jsglobaljs printroundn printroundn 3 printroundn 6 jsglobaljs fontcolors fontcolors type1 black type2 229922 type3 0000dd type4 4488ff typedefault black typehome orange typekicked red leftover red shortage blue overheat red todo lists 123456789123 firefox notepad chrome modification httpsstackoverflowcomquestions2541949problemswithjquerygetjsonusinglocalfilesinchrome mac open applicationsgoogle chromeapp args allowfileaccessfromfiles httpeurekaykyueninfo20130924chromebypassaccesscontrolalloworiginonlocalfilesystem license project licensed terms mit license please note project built materials following parties bootstrap flatly jquery please also refer licenses information\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "corporate environmental performance prediction china empirical study energy service companies authors saina zheng chenhang shuchien hsu joseph sarkis jiehhaur chen code originally used paper corporate environmental performance prediction china empirical study energy service companies contains three fundalmental machine learning regression model random forest svm xgboost code well commented easy used anyone beginner level python programming skills evaluation metrics visualization code also included dependencies python tested 35 scikitlearn xgboost pandas citation find work useful research please consider cite articlezheng2020ceppc titlecorporate environmental performance prediction china empirical study energy service companies authorsaina zheng chenhang shuchien hsu joseph sarkis jiehhaur chen journaljournal cleaner production jclp year2020\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0]\n",
      "sensorpuck repository collateral related silicon labs sensor puck note sensor puck longer actively supported code provided android directory sensor puck android app source code ios directory iphone app source code\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmentalinformaticsmarburggithubio\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "pythonbased datacentric integrated modeling platform pydims goals project data model technology building coupled models within water resource domain advancing rapid pace many modeling framworks developed eg openmi csdms oms etc control flow data model components simulation efforts largely focused establishing software interfaces componentizing scientific calculations receive input data supply output data simulation however lack emphasis closing gap observed simulated data component simulations one objective project investigate observed simulation data integrated seamlessly componentbased model simulations coupled modeling workflow coupled modeling platforms typically rely upon single data passing workflow defined coordination mechanism utilize feedforward approach eg oms csdms others use pull driven approach eg openmi offers benefits however rarely ever encounter set models single workflow ideal instance closedsource models coupled computations via reading writing inputoutput files unable interact others individual timesteps unless specifically designed similarly sometimes model coupled along shared boundary conditions require timestep iterations converge solution therefore second objective work investigate methods utilizing multiple workflows within single coupling framework well within single simulation platform language compatibility within water resources community several coupled modeling frameworks exist however often writen different languages eg c python java etc scientists forced choose coupling software compatible models andor operating system moreover many legacy models written c c fortran make compatibility difficult third goal project investigate platform language compatibility issues overcome build system adopted water resources community\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "edit ontology tbd environmental conditions treatments exposures ontology ecto purpose ontology create compositional classes assemble existing obo ontologies exo chebi envo make readymade precomposed classes use describing experimental treatments plants model organisms eg modification diet lighting levels temperature exposures humans organisms stressors variety routes purposes public health environmental monitoring etc stimuli natural experimental kind environmental condition change condition experienced organism population organisms earth scope general include example plant treatment regimens well human clinical exposures although may better handled specialized ontology example class manchester syntax class ecto0000977 annotations rdfslabel exposure ultrafine respirable suspended particulate matter via inhalation annotations iao0000115 exposure event involving interaction exposure receptor ultrafine respirable suspended particulate matter via inhalation annotations oiohasexactsynonym ultrafine respirable suspended particulate matter exposure via inhalation equivalentto exo0000002 ro0002233 envo01000416 bfo0000050 exo0000057 ' exposure event ' ' input ' ultrafine respirable suspended particulate matter ' part ' inhalation quick start public browser yet use one following files subsetsectobasicobo oboedit users ectoowl open protege5 note open owl protege need check repo catalog used relationships ontologies ontologies used composition largely orthogonal exposure ontology exo used upper ontology based classes ' exposure ' different routes ' ingestion ' chemical entities biological interest chebi use entities roles environment ontology envo environmental materials processes nanoparticle ontology npo radiation relations ontology ro relations phenotypic quality ontology pato qualities uberon anatomy ontology tissue types used yet nci thesaurus ncit activities smoking sustainable development goals interface ontology sdgio social entities population community ontology pco population attributes eg overcrowding similar ontologies overlappingnonorthogonal zebrafish experimental conditions ontology zeco zebrafishspecific conditions pombe experimental conditions ontology speco pombasespecific conditions plant environment conditions ontology peco plantspecific environmental conditions treatments gene ontology go subset shadows many classes eg gene expression response x snomed exposure subset closed nci thesaurus ncit broad contains exposure terms experimental conditions ontology xco experimental conditions mammalcentric rat particular wikidata subclasses hazard wikidataq1132455httpswwwwikidataorgwikiq1132455 see merge experiment ontologies aim reuse existing open ontologies far possible orthogonal ontologies via axiomatization note envo may seem envo overlappingnonorthogonal ontology following design patterns considered orthogonal analogous relationship anatomical ontology variantaberrant phenotype ontology another new ontology note unep sustainable development goals ontology httpsgithubcomsdginterfaceontologysdgio built modular fashion using envo seeding creation many useful social classes need eg poverty access resources etc releases release files top level obo owl note testing far stable considered real releases proposed id space tentative modeling model using aligned environmental conditions model phenopackets attempt follow exo possible treat exposures events ontological terms types occurrents specifically interactions receptor typically organism could population organisms stressor agent process potential effect receptor stressor may interact organism kind environmental medium eg air water soil may enter via route eg permeating skin analogous barrier cases route may indirect passive smoking drug use mother pregnancy model permits variety precomposed classes defined generate using dead simple owl design patterns dosdps see srcpatterns list patterns use basic idea term like ' increased exposure arsenic ingestiondiet ' composed using classes ontologies exo chebi see filling slots datamodel annotation guide broadly speaking ontology designed support pre post composed use cases precomposed approach curator uses readymade ecto class expressing combination values required different slots postcomposed approach ecto largely disposed instead description assembled curator filling required slots like ' stressor ' two approaches compatible postcomposed descriptions automatically classified precomposed ecto similarly description uses ecto unwound ' unfolded ' precomposed description using owl equivalence axioms ontology ontology source ontology stored csvs srcontologymodules see makefile ontology compiled csv modules see omn files humanreadable set descriptions see readmeeditorsmd file srcontology directory instructions edit maintain release ontology merge experiment see srcmappings exploration merging multiple exposure ontologies using kboom intent use ontology rather help gap fill understand\n",
      "[1 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 1\n",
      " 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 0 1 0\n",
      " 1 1 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0]\n",
      "environmentalnotices open data application estonian fund nature httpselfondee scrapes official notifications estonian government site parses filters results sends regularily mailing list provides geodata preview implemented nodejs installation npm install create configconfigjson file baseurl sitebaseurl mailfrom mailtosendfrom mailto mailtosendto1 mailtosendto2 mailusername gmailaccounttosentfrom mailpassword gmailaccountpassword running invoke data scraping node scraperjs invoke mailer node mailerjs\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmental monitoring control software component basic system created monitor control preseason started seedlings grow runs raspberry pi model b camera module currently two arduino compatible things stands stuff works reason put force clean bit server contains python basehttpserver based web server providing access camera well arduino frontends via simple web interface configured via webconf use simply run treepy default bind port 8008 enforce basic auth return nothing 404s needs handlers specified webconf useful dotplug bits configuration templates pictures web server component config goes well arduinofrontends arduinos used multiple systems outside web frontend needed layer clients avoid serial contention ' pretty basic sketches speaking arduino sketches mrtg mrtg config client script sensor feeds mrtg installation minimum requirements useful raspberry pi camera module webconf setup looks like baseconfig parallel threading port 8008 auth module authenticator user aber pwd lour handlercamera module camerahandler camera camera resolution 1024x768 lets access 1024x768 snapshot server8008camera timestamp authenticating user aber password lour\n",
      "[1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1\n",
      " 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1\n",
      " 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0]\n",
      "environmentalnotices open data application estonian fund nature httpselfondee scrapes official notifications estonian government site parses filters results sends regularily mailing list provides geodata preview implemented nodejs installation npm install create configconfigjson file baseurl sitebaseurl mailfrom mailtosendfrom mailto mailtosendto1 mailtosendto2 mailusername gmailaccounttosentfrom mailpassword gmailaccountpassword running invoke data scraping node scraperjs invoke mailer node mailerjs\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmental data abstraction layer edal documentation source code issues changelog edal project comprises set libraries deal manipulation visualisation environmental data originally created part ncwms standalone libraries ncwms uses edal consists number modules focused different task modules outlined edal modules edal common edalcommon module contains core data model used edal well inmemory implementations data model common utility methods exceptions edal graphics edalgraphics module contains code generating images core edal data types includes map images well timeseries vertical profile vertical section charts additionally custom sld styled layer descriptor handlers allow precise specification assemble map image allowing arbitrarily complex plotting multiple simultaneous data layers module depends edalcommon module edal cdm edalcdm module uses unidata netcdfjava libraries read data core edal data model reads cfcompliant gridded netcdf files well opendap grib several formats see httpwwwunidataucaredusoftwarethreddscurrentnetcdfjavareferenceformatsfiletypeshtml list also includes data reader capable reading uk met office en34 insitu datasets httpwwwmetofficegovukhadobsen3 httpwwwmetofficegovukhadobsen4 modules depends edalcommon module edal wms edalwms module contains implementation wms web map service standard number custom requests suited exposing environmental data web module complete packaged wms supplies required servlet classes requires data catalogue implemented map wms layer names edal data objects module depends edalcommon module edalgraphics module edal xml catalogue edalxmlcatalogue module contains implementation data catalogue xml format allows configuration set datasets xml provision graphics module module depends edalcommon module edalgraphics module godiva 3 edalgodiva module google web toolkit gwt based wms client supports extended wms requests supplied edalwms module module depend others edal developed primarily factor common functionality original ncwms httpsourceforgenetprojectsncwms caching datasets caching datasets improve performance implemented using ehcache two distinct caches included edal cache datasets featurecache cache maps meshdatasetcache using ncwms2 another cache available cache dynamic datasets dynamiccache configuration caches configured using ehcachexml specified runtime jvm parameter ' dehcacheconfigpathtoehcachexml ' default configuration specified commonsrcmainresourcesehcachexml ehcache cache distributed using terracotta specifying parameters ehcachexml example file provided commonsrcmainresourcesehcacheterracottaxml licence copyright c 2010 university reading rights reserved redistribution use source binary forms without modification permitted provided following conditions met 1 redistributions source code must retain copyright notice list conditions following disclaimer 2 redistributions binary form must reproduce copyright notice list conditions following disclaimer documentation andor materials provided distribution 3 neither name university reading names authors contributors may used endorse promote products derived software without specific prior written permission 4 wish use without modification godiva web interface logo reading escience centre must retained web page software provided author ' ' express implied warranties including limited implied warranties merchantability fitness particular purpose disclaimed event shall author liable direct indirect incidental special exemplary consequential damages including limited procurement substitute goods services loss use data profits business interruption however caused theory liability whether contract strict liability tort including negligence otherwise arising way use software even advised possibility damage authors contributors edal libraries developed reading escience centre maintained guygriffiths contributors yosoyjay kwilcox\n",
      "[0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0\n",
      " 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1\n",
      " 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 0 0]\n",
      "eflowspecies pisces species analysis environmental flow eflow type published versions rmd files github pages branch httpucdcwsgithubioeflowsspecieseflowdistancehtml example\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmentalrecycling\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "rate plate identify environmental impact food developed cssbristol boeing hackathon overview tweet image food account recognise food tweets back environmental impact food icons designed madebyoliver flaticon development setup dependancies install python version 35 required tensorflow install pip make sure pip updated pip install upgrade pip setup clone repo git clone httpsgithubcomharrymtboeinghackathongit navigate directory cd boeinghackathon run pip install r requirementstxt install python dependancies setup database python dbsetuppy run web server locally running python applicationpy api credentials create file ' credentialspy ' consumerkey consumersecret accesstoken accesstokensecret generate via twitter application management httpsappstwittercom credentialspy consumerkey ' ' consumersecret ' ' accesstoken ' ' accesstokensecret ' ' server side extra setup clone repo git clone httpsgithubcomharrymtboeinghackathongit git pull whenever changes setup cron job crontab e show list cron jobs add python twitterbotpy cronfile add crontab l check see worked setup githook create pullphp file 1 line php exec ' cd boeinghackathon git pull ' technologies used python flask tweepy tensorflow bitly leaflet word net mat plot lib hosted aws\n",
      "[0 1 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0]\n",
      "monitoring environmental conditions near underwater datacenters using deep learning last updated august 29 2018 introduction microsoft put cloud artificial intelligence ai tools hands working solve global environmental challenges programs ai earth also use tools understand interaction environment work done concert project natick project natick seeks understand benefits difficulties deploying subsea datacenters worldwide world ' first deployed underwater datacenter designed emphasis sustainability phase 2 extends research accomplished phase 1 deploying fullscale datacenter module north sea powered renewable energy project natick uses ai monitor servers equipment signs failure identify correlations environment server longevity project natick operates like standard land datacenter computers inside used machine learning provide ai applications microsoft datacenter also using ai monitor surrounding aquatic environment first step understanding impact datacenter may monitoring marine life using object detection project natick datacenter equipped various sensors monitor server conditions environment including two underwater cameras available live video streams check livestream project natick homepage cameras allow us monitor surrounding environment two fixed locations outside datacenter real time want count marine life seen cameras manually counting marine life frame video stream requires significant amount effort solve leverage object detection automate monitoring counting marine life frame count number marine creatures model object detection problem object detection combines task classification localization outputs category set coordinates representing bounding box object detected image run please go following steps able run natickodpy perform object detection project natick livestream push data power bi dashboard clone repository directory choice ensure dependencies installed see create power bi streaming dataset see add power bi streaming dataset url line 139 natickodpy run python natickodpy dependencies pip install cython pip install pillow pip install lxml pip install matplotlib pip install imutils pip install opencvpython pip install ignoreinstalled upgrade tensorflow creating power bi streaming dataset create power bi streaming dataset following tutorial creating dataset add following values running code edit line 139 natickodpy use power bi push url finally navigate cloned repo run python natickodpy note repo uses code tensorflow object detection repository edited file utilsvisualizationutilspy displays fish count bottom left corner video getting data want train scratch annotated data located release tab additional information continue reading additional information necessary running code machine deploying model project natick datacenter another question asked deploy model natick datacenter monitor wildlife teeming around data center chose use cpus process input videos tested locally make sure works well however default tensorflow prebuilt binary optimizations avx fma builtin fully utilize modern cpus better utilize cpus built tensorflow binary source code turning optimization intel cpu following intel ' documentation optimization increase processing speed 50 percent around two frame per second three frame per second build command like bazel build configmkl c opt coptmavx coptmavx2 coptmfma coptmavx512f coptmavx512pf coptmavx512cd coptmavx512er coptdeigenusevml tensorflowtoolspippackagebuildpippackage realtime environmental monitoring power bi environmental scientists aquatic scientists may benefit intuitive way monitoring statistics underwater datacenter quickly gain insight going powerful visualization via power bi power bi notion realtime datasets provides ability accept streamed data update dashboards real time intuitive call rest api post data power bi dashboard lines code rest api endpoint given create api streaming dataset format httpsapipowerbicombetatenant iddatasets dataset idrowskeykey id restapiurl ' push api url goes ' ensure timestamp string formatted properly datetimestrftimedatetimenow ymdthmsz data ' sending power bi rest api data ' timestamp 0 fishcount 1 arrowwormcount 2 ' formatnow fishcount arrowwormcount req urllib2requestrestapiurl data response urllib2urlopenreq animals may move quickly need carefully balance capturing data many frames short succession sending power bi dashboard consuming compute resources chose push analyzed data example fish count power bi three times per second achieve balance summary monitoring environmental impact important topic ai help make process scalable automated post explained developed deep learning solution environment monitoring near underwater data center solution show ingest store data train underwater animal detector detect marine life seen cameras model deployed machines data center monitor marine life time also explored analyze video streams leverage power bi ' streaming apis monitor marine life time questions comments please leave message contributing project welcomes contributions suggestions contributions require agree contributor license agreement cla declaring right actually grant us rights use contribution details visit httpsclamicrosoftcom submit pull request clabot automatically determine whether need provide cla decorate pr appropriately eg label comment simply follow instructions provided bot need across repos using cla project adopted microsoft open source code conduct information see code conduct faq contact opencodemicrosoftcom additional questions comments\n",
      "[0 1 0 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 1 0 0 1\n",
      " 1 0 0 1 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 1\n",
      " 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 1 0 1 0 1 1 0 0 1 0 1 1 0 0 0 1 1\n",
      " 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1]\n",
      "sheds gis data repository contains scripts used generate supporting data used spatial hydroecological decision system sheds project page describes datasets created repository\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "multirotors research andrew bennett ' lab using multirotors conduct environmental exploration sensing sampling missions projects code repository contains mission files general architecture several mission types executed drones namely breath condensate collection cetacean wireless tracker tagging large cetacean photogrammetry animal studies pointofinterest data collection environmental exploration waypoint navigation sense avoid unfriendly multirotors missions designed mission file mission file executed generic autonomy structure based upon state configured layer control sclc controls actions drone running code still construction rc override computer control overridden switching ch 6 transmitter value greater 1500 keyboard controls stabilize sort manual l loiter auto r arm disarm p open planner joystick controls specific joystick finalized yet\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "spotfire spotfire crowdsourcing tool support realtime detection monitoring wildfires improving environmental safety preserve wildfire risk spotfire allows users report wildfires different means provides experts means monitor gain insights make predictions give warnings potential disasters project designed nasa space apps 2018 challenge 30 seconds pitch video details please visit nasa space apps 2018 challenge page overview getting started project structure spofi readmemd file requirementstxt python dependencies app android app core backend main service database handlers data opendata serverpy server side onemethod interface handel reports submissions templates &#9; css &#9; js &#9; platformhtml frontpage installation develop environment first clone project git clone recursive j8 httpsgithubcomahmedmaghawryspofigit requirments python 3x firebase keras tensorflow pandas numpy install prerequisites listed requirementstxt pip install r requirementstxt also check readmemd file core folder contributers ahmed ezzat ahmed rizk youssef ahmed yahia elshahawy\n",
      "[0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 0\n",
      " 0 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmental sensing aws iot project environmental sensing ph various gases particulate matter sound capturing images multipart project demonstrate environmental monitoring using several types sensors aws services first part focuses building hardware monitoring environmental parameters co2 particulate matter sound capturing images project used environmental monitoring several use cases industrial manufacturing distribution warehouses etc first version environmental sensor box software along capable following features sense temperature humidity pressure co2 tvoc proximity range publish aws iot core capture upload images amazon s3 bucket project also uses aws systems manager enable remote access raspberry pi use aws iot rules log data amazon elasticsearch service second version project retains temperature humidity pressure co2 tvoc proximity replaces camera range sensor ph sensor atlas scientific smaller enclosure source code remains applications ph ph sensor used monitor several industrial agricultural parameters dough fermentation soil ph different crops plants need specific levels ph soil hardware mechanical list shelf hardware used build environmental sensing unit raspberry pi zero w sparkfun qwiic kit raspberry pi ultrasonic range finder hrxlmaxsonarvr unit supports camera raspberry pi capture images load aws s3 camera used arducam lens board sku b0031 could use compatible camera well information ph sensor ph reading circuit smaller enclosure atlas scientific spear tip ph probe ezo ph circuit ezo carrier board smaller enclosure please note code tested earlier version spear tip probe ezo circuits however new probe circuit work fine also important note default carrier board uart mode reprogrammed support i2c mode used project carrier board interfaces qwiic cable qwiic hat baseplate designed 3d printed house components following case bought amazoncom universal project enclosure image assembled unit first iteration support pm25 particulate matter 25 sensing see sensor pms7003 camera image image version ph support architecture high level architecture first iterationpart project configure setup aws iot read setting aws iot create thing created thing raspberry pi make sure keys present ' keys ' subfolder also copy sampleenv file env provide specifics need logging data aws iot core prior logging data take sampleenv file copy env make sure al parameters set correctly run script rpiqwiicawsiotpy read sensor data log aws iot core script calls two helper modules imagecapturepy capture image using hte picamera package upload s3 note s3 bucket name specified env file ultrasonicpy script reads value range finder sensor connected two flags used control import execution modules s3enable ultraenable env file want exclude one set flag emptry string module included set ' true ' see example s3enable ' true ' ultraenable ' ' env file configured correctly start tbe execution follows python3 rpiqwiicawsiotpy want run program background ensure keeps running disconnect remote session raspberry pi execute following nohup python3 u rpiqwiicawsiotpy outputlog go test secion aws iot console subscribe topic using topic used testing following telemetrythingname sample output unit timestamp 1583361438 time 03042020 173717 tempc 2763 tempf 81752 humidity 34475 pressure 106863 tvoc 0 co2 400 proximity 2556 ambient 128 image pzb827ebed3f9a1583361438 data using ultrasonic sensor readings data packet also provides image captured filename used store s3 bucket storing data amazon elasticsearch use amazon elasticsearch store transformed data later use visualization setup amazon elasticsearch region used create iot thing elasticsearch setup go aws iot console setup iot rule see image setup specific iot rule used transform incoming packets select topic2 thingname timestamp parsetimeyyyymmdd ' ' hhmmsszz timestamp americanewyork ts tempf tempc humidity pressure co2 ambient tvoc proximity ' telemetry ' rule minor transformation incoming data message output look follows thingname pzb827ebed3f9a timestamp 1583361502 ts 20200304t1738260500 tempf 82058 tempc 2781 humidity 34288 pressure 106548 co2 400 ambient 125 tvoc 0 proximity 2555\n",
      "[1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0\n",
      " 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1\n",
      " 1 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 1 0\n",
      " 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 1 0 1 1 0 0 1 0]\n",
      "environment monitoring sensitive healthcare equipment needs suitable operating conditions equipment ' operating environment responsibility customer assist customer maintaining suitable environment install environment monitoring device customer premises monitor data project simulating data monitoring device issuing alerts warnings decomposition top level program runs two processes sender receiver sender responsible simulating monitoring device receiver analyzes data sender sends data receiver using console redirection run command line follows senderexecutable receiverexecutable would make consolewrites sender become consolereads receiver decomposition responsibility within sender receiver naming source files within sender within receiver give internal decomposition code project follows practices tools listed interface document interface sender receiver test cases sender receiver testable sender testable without receiver develop another datasource test confident integration receiver testable without sender enhance without retesting receivers minimum functionality simulating different sequences data monitor sender takes csv file input file contains temperature humidity data sender sends periodically receiver outputs warnings alerts console environmental conditions breach limits temperature warning levels high 37 c low 4 c temperature error levels high 40c low 0 c humidity warning level high 70 humidity error level high 90 extended functionality sender needs send data every 5 minutes receiver ' receive data half hour receiver outputs alert evaluation criteria see evaluation criteria exercise\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "environmentalicious quite tasty looks decent mobile well synopsis environmentalicious web application allows users locate environmental conservation sustainability events community users create account register attend events believe interesting first release candidate application exhibits main core functionalities current state system user able create events find events relative locations search events based criteria event name event description tags may also join events invite friends become event participants installationrunning would like view application without installing server local machine may navigate httpsalsaritedu3000 link may always available please follow instructions install local machine cannot access deployed version order load application locally nodejs must installed local system recent version nodejs 01033 time writing found httpnodejsorg nodejs environment installed open command prompt terminal move root directory project order install dependencies project first type ' npm install ' completed run command ' node serverjs ' navigate browser httplocalhost3000 npm install node serverjs application usage creating event navigate ' create event ' section left hand bar bar home screen login enter desired event information select ' create event ' button finding already created event navigate ' find event ' section left hand bar home screen login enter information event name event location keyword found description event would like attend click ' find event ' button locate result left hand portion screen may click events navigate main event section page joining event main page specific event would like join click ' join event ' button bottom screen pop notify successfully joined event return individual event page able see participant event inviting friends event provide valid line separated email addresses invite friends text box click ' invite friends ' button alert notify friends successfully invited event recieve email letting know marked potential participant known bugs user authentication login functionality selecting ' log ' button main page direct user web application default account contributors danielle gonzalez justin peterson richie kapadia joe ksiazek\n",
      "[1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 1 1 1 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0]\n",
      "monitoring environmental rehabilitation code produced outcome perth hack good monitoring environmental rehabilitation purpose hack produce skeleton solution could evolved time include features ultimate aim submitting application main mobile app stores building architecture rainbow pen event detials perth hack good getting group likeminded people together solve real world problem learn skills collaborative way hosted microsoft hackathon begin friday evening state problem meet team mates brainstorm ideas saturday spend day collaborating coding end hope skeleton solution open sourced allow ongoing development welcome anyone event knowledge coding web mobile development certainly encouraged main emphasis fun learning new skills\n",
      "[0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      "sahana eden sahana eden emergency development environment open source framework rapidly build powerful applications emergency management web based collaboration tool addresses common coordination problems disaster finding missing people managing aid managing volunteers tracking camps effectively government groups civil society ngos victims please see website details httpedensahanafoundationorg note developers get started httpedensahanafoundationorgwikidevelop first pull request sign contributor ' license agreement protects rights code allowing distributed used sahana eden httpbitlyssfecla\n",
      "[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0]\n",
      "environmentalsensors httpsuserimagesgithubusercontentcom122488152977143353faa10c8c1111e782ce36de73631b2dpng\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmentalnewsap\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmentaliottoolkit tvoc\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "requiredenvvarplugin require environmental variable application throw routhlessly zerodependency webpack plugin motivation ever found setting default env vars project make sure app get data developer forgets provide run risk serving hard debugging time contributors even worse ending wrong configuration deployment process accidental values environmental variables app get hard reminder face ' something set usage requirement webpack package installed since ' checking webpack plugin ' probably already register plugin provide required env var names parameters const requiredenvvarplugin require ' requiredenvvarplugin ' moduleexports plugins new requiredenvvarplugin ' apiurl ' ' user ' ' pass ' provide variables list revp ' apiurl ' ' user ' ' pass ' array revp ' apiurl ' ' user ' ' pass ' work hood uses webpack ' defineplugin passes object shape ' processenv ' apiurl xxx user xxx pass xxx xxx respective environmental variables derived processenvxxx ' find one throws faq throw ' warn user ' whole purpose plugin developer ' infere code ' find docs ' deduce application working env var ' set surely ' notice bunch logs spitted onto console startup message clear forgot ' launch license mit httpsopensourceorglicensesmitlicensephp\n",
      "[0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 1]\n",
      "environmental mapping using webgl shaders simulate enviormental reflection launch chrome allowfileaccessfromfiles load local models like osx applicationsgoogle chromeappcontentsmacosgoogle chrome allowfileaccessfromfiles\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "environmentalpollution\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "mycodo environmental regulation system latest version 888 mycodo open source software raspberry pi couples inputs outputs interesting ways sense manipulate environment mycodo manual mycodo api latest version v1 mycodo support android app mycodo wiki mycodo custom inputs controllers repository technical support discussion use mycodo forum donate always made mycodo free ' intend changing however find mycodo useful would like support continued development please consider becoming sponsor githubcomsponsorskizniche table contents donate features uses screenshots install mycodo support manual rest api pid control supported inputs outputs custom inputs outputs controllers links license languages thanks features inputs record measurements sensors gpio pin states analogtodigital converters create custom inputs outputs perform actions switching gpio pins highlow generating pwm signals executing shell scripts python code create custom outputs functions perform tasks coupling inputs outputs interesting ways pid controllers conditional controllers trigger controllers name create custom functions web interface securely accessing mycodo using web browser local network anywhere world internet connection view configure system includes several light dark themes dashboards display configurable widgets including interactive live historical graphs gauges output state indicators measurements create custom widgets alert notifications send emails measurements reach exceed userspecified thresholds important knowing immediately issues arise setpoint tracking changing pid controller setpoint time use things like terrariums reflow ovens thermal cyclers sousvide cooking notes record events alerts important points time overlaid graphs visualize events measurement data cameras remote live streaming image capture timelapse photography energy usage measurement calculating tracking power consumption cost time upgrade system easily upgrade mycodo system latest release get newest features restore previouslybacked version translations enable web interface presented different languages figure automated hydroponic system build uses originally developed cultivate edible mushrooms mycodo evolved much things done mycodo projects hydroponic system automation archive mushroom cultivation archive groundbased plant cultivation maintaining honey bee apiary homeostasis archive maintaining humidity underground artificial bat cave archive remote radiation monitoring mapping archive cooking sousvide archive maintaining light schedule regulating humidity ramping 90 50 4 week period acclimatize micropropagated american chestnut plantlets laboratory ambient outdoor conditions archive featured projects others maintaining aquatic systems eg fish hydroponic aquaponic maintaining terrarium herpetarium vivarium environments incubating young animals eggs aging cheese dryaging curing smoking meat archive fermenting beer food tobacco controlling reflow ovens culturing microorganisms treating agricultural waste water archive let know use mycodo may include list screenshots visit screenshots page wiki install mycodo prerequisites raspberry pi singleboard computer version zero 1 2 3 4 raspberry pi operating system flashed micro sd card active internet connection mycodo tested work raspberry pi os lite 20200527 also desktop version using mycodo version 860 install raspberry pi booted raspberry pi os internet connection run following command terminal initiate mycodo install curl l httpskiznichegithubiomycodoinstall bash install notes make sure install script finishes without errors log output created mycodoinstallsetuplog install successful web user interface accessible navigating web browser https127001 replacing 127001 raspberry pi ' ip address upon first visit prompted create admin user redirected login page logged check time correct top left page incorrect time cause number issues measurement storage retrieval among others also ensure host name version number top left page green indicating daemon running red indicates daemon inactive unresponsive last ensure javablocking plugins browser disabled parts web interface function properly receive error install believe preventing system operating please create issue install log attached would first like attempt diagnose issue see diagnosing issues minimal set anonymous usage statistics collected help improve development identifying information saved information collected used improve mycodo sources access information data collected mainly many features used similar information data ' collected viewed ' view collected statistics ' link settings general page opt option general settings page support making post forum issue tracker github please read manual need assistance mycodo mycodo supposedly operating correctly would like assistance configure system merely discuss something related mycodo search mycodo forum similar discussion similar topic ' already exist forum create new post appropriate subforum bug mycodo software believe bug mycodo software first search guthub issues see issue already recently discussed resolved issue novel significantly mre recent similar one create new issue creating new issue make sure read information issue template follow instructions replace template text information requested eg step 1 steps reproduce issue replaced actual steps reproduce issue information provide easier reproduce diagnose issue issue able reproduced enough information provided may delay prevent solving issue manual mycodo manual may found httpskiznichegithubiomycodo mycodo wiki also contains useful information rest api latest api documentation found api information api endpoint documentation pid control proportionalintegralderivative pid controller control loop feedback mechanism used throughout industry controlling systems efficiently brings measurable condition temperature desired state setpoint welltuned pid controller raise setpoint quickly minimal overshoot maintain setpoint little oscillation top graph visualizes regulation temperature red line desired temperature setpoint configured change course day blue line actual recorded temperature green vertical bars represent long heater activated every 20second period regulation achieved minimal tuning already displays minimal deviation setpoint 05 celsius tuning would reduce variability see pid controller pid tuning sections manual information supported inputs outputs supported inputs outputs devices found supported devices section manual custom inputs outputs controllers mycodo supports importing custom input output controller modules find information manual custom inputs custom outputs custom functions would like add list supported inputs outputs controllers submit pull request module created start new issue additionally another github repository devoted custom inputs outputs controllers necessarily fit builtin set included default mycodo imported found kiznichemycodocustom links thanks using supporting mycodo however depending found documentation may latest version may altered obtained official distribution site able find latest version github web site following links httpsgithubcomkiznichemycodo httpskylegabrielcom license see licensetxt mycodo free software redistribute andor modify terms gnu general public license published free software foundation either version 3 license option later version mycodo distributed hope useful without warranty without even implied warranty merchantability fitness particular purpose see gnu general public license details full copy gnu general public license found httpwwwgnuorglicensesgpl30enhtml software includes third party open source software components please see individual files license information applicable languages native english complete dutch german french italian norwegian polish portuguese russian serbian spanish swedish chinese default mycodo display default language set browser may also force language settings gear icon configure general language would like improve translations submit pull request amended po file mycodomycodomycodoflasktranslations start new issue detailing corrections english native language used software dutch mycodo een geautomatiseerd monitoring en regelsysteem dat gebouwd om op de raspberry pi te draaien versies zero 1 2 3 en 4 oorspronkelijk ontworpen om eetbare paddenstoelen te kweken mycodo uitgegroeid tot het vermogen om veel meer te doen waaronder het kweken van planten het kweken van microorganismen het onderhouden van bijenbijen bij de bijen het incuberen van dieren en eieren het onderhouden van aquatische systemen het ouder worden van kazen het fermenteren van voedsel en tabak het koken eten sousvide en meer het systeem bestaat uit een backend daemon en een frontend gebruikersinterface de backend voert metingen uit van sensoren en apparaten coordineert vervolgens een diverse reeks antwoorden op die metingen inclusief het vermogen om outputs te moduleren relais pwm draadloze outlets omgevingsomstandigheden te regelen met elektrische apparaten onder pidregeling gestage regeling omschakeling tijd timers plannen foto ' maken en video streamen acties activeren wanneer metingen aan bepaalde voorwaarden voldoen relais moduleren opdrachten uitvoeren per email op de hoogte stellen etc en meer de frontend een webinterface die gemakkelijke navigatie en configuratie mogelijk maakt vanaf elk apparaat met een browser french mycodo est un systeme de surveillance et de regulation automatise concu pour fonctionner sur le raspberry pi versions zero 1 2 3 et 4 concu l ' origine pour cultiver des champignons comestibles mycodo ' est developpe pour inclure la capacite de faire beaucoup plus notamment la culture de plantes la culture de microorganismes le maintien de l ' homeostasie du rucher des abeilles la mise en incubation des animaux et des ufs la maintenance des systemes aquatiques le vieillissement des fromages la fermentation nourriture sous vide et plus le systeme comprend un serveur demon et une interface utilisateur interface utilisateur le systeme effectue des mesures partir de capteurs et dappareils puis coordonne un ensemble divers de reponses ces mesures notamment la possibilite de moduler les sorties relais pwm prises sans fil de reguler les conditions environnementales avec des appareils electriques sous controle pid regulation continue ou basculement temps planifiez des minuteries capturez des photos et des flux video declenchez des actions lorsque les mesures repondent certaines conditions moduler des relais executer des commandes notifier par courrier electronique etc etc l ' interface web est une interface web qui facilite la navigation et la configuration partir de tout appareil compatible avec le navigateur german mycodo ist ein automatisiertes uberwachungs und regulierungssystem das fur den raspberry pi versionen zero 1 2 3 und 4 entwickelt wurde ursprunglich fur die kultivierung von speisepilzen konzipiert hat mycodo die fahigkeit zu weitaus mehr erweitert darunter die kultivierung von pflanzen die kultivierung von mikroorganismen die aufrechterhaltung der homoostase der bienenhausbienenhauser die inkubation von tieren und eiern die aufrechterhaltung von wassersystemen das altern von kase das garen von lebensmitteln und tabak sowie das kochen essen sousvide und mehr das system besteht aus einem backend daemon und einem frontend benutzeroberflache das backend fuhrt messungen von sensoren und geraten durch und koordiniert dann eine vielzahl von reaktionen auf diese messungen einschlielich der moglichkeit ausgange relais pwm drahtlose ausgange zu modulieren und umgebungsbedingungen mit elektrischen geraten unter pidsteuerung zu regulieren stetige regelung oder umschaltung zeit zeitplane planen fotos aufnehmen und videos streamen aktionen auslosen wenn messungen bestimmte bedingungen erfullen relais modulieren befehle ausfuhren per email benachrichtigen usw und vieles mehr das frontend ist eine weboberflache die eine einfache navigation und konfiguration von jedem browserfahigen gerat aus ermoglicht italian mycodo e un sistema di monitoraggio e regolazione automatico che e stato creato per funzionare sul raspberry pi versioni zero 1 2 3 e 4 originariamente progettato per coltivare funghi commestibili mycodo e cresciuto fino comprendere la capacita di fare molto di piu coltivando piante coltivando microrganismi mantenendo l ' omeostasi delle api apistiche del miele incubando animali e uova mantenendo sistemi acquatici formaggi stagionati alimenti fermentati e tabacco cucinando cibo sousvide e altro ancora il sistema comprende un backend demone e un frontend interfaccia utente il backend esegue misurazioni da sensori e dispositivi quindi coordina un insieme diversificato di risposte tali misurazioni inclusa la possibilita di modulare le uscite rele pwm prese wireless regola le condizioni ambientali con dispositivi elettrici sotto controllo pid regolazione costante commutazione tempo programmare timer acquisire foto e trasmettere video attivare azioni quando le misurazioni soddisfano determinate condizioni modulazione di rele esecuzione di comandi notifica via email ecc e altro il frontend e un ' interfaccia web che consente una facile navigazione e configurazione da qualsiasi dispositivo abilitato per il browser norwegian mycodo er et automatisert overvakings og reguleringssystem som ble bygget kjre pa raspberry pi versjoner zero 1 2 3 og 4 mycodo er opprinnelig utviklet dyrke spiselige sopp og har vokst til inkludere muligheten til gjre mye mer inkludert dyrking av planter dyrking av mikroorganismer opprettholder honningbi apiary homeostasis inkubering av dyr og egg opprettholde akvatiske systemer aldrende oster fermenterende matvarer og tobakk matlaging mat sousvide og mer systemet bestar av en backend daemon og en frontend brukergrensesnitt backend utfrer malinger fra sensorer og enheter og koordinerer deretter et mangfoldig sett med svar pa disse malingene inkludert muligheten til modulere utganger releer pwm tradlse uttak regulere miljforhold med elektriske enheter pidkontroll stabil regulering eller endring tid planlegge timere ta bilder og streame video utlse handlinger nar malingene oppfyller visse forhold modulere releer utfre kommandoer varsle via epost etc og mer frontend er et webgrensesnitt som gjr det enkelt navigere og konfigurere fra hvilken som helst nettleseraktivert enhet polish mycodo zautomatyzowany system monitorowania regulacji ktory zosta zbudowany pracy na raspberry pi wersje zero 1 2 3 pierwotnie zaprojektowany uprawy grzybow jadalnych mycodo rozwineo sie aby umozliwic znacznie wiecej w tym uprawe roslin hodowle mikroorganizmow utrzymanie homeostazy pszczo miodnych inkubacje zwierzat jaj utrzymanie systemow wodnych dojrzewanie serow fermentacje zywnosci tytoniu gotowanie jedzenie sousvide nie tylko system skada sie z zaplecza demona frontendu interfejsu uzytkownika backend przeprowadza pomiary z czujnikow urzadzen nastepnie koordynuje zroznicowany zestaw odpowiedzi na te pomiary w tym mozliwosc modulacji wyjsc przekazniki pwm wyjscia bezprzewodowe regulacje warunkow srodowiskowych za pomoca urzadzen elektrycznych pod kontrola pid regulacja staa lub przeaczanie czas ustawianie timerow robienie zdjec strumieniowanie wideo wyzwalanie dziaan gdy pomiary speniaja okreslone warunki modulacja przekaznikow wykonywanie polecen powiadamianie przez email itp nie tylko frontend interfejs sieciowy ktory umozliwia atwa nawigacje konfiguracje z dowolnego urzadzenia obsugujacego przegladarke portuguese mycodo e um sistema automatizado de monitoramento e regulacao que foi construido para rodar raspberry pi versoes zero 1 2 3 e 4 originalmente concebido para cultivar cogumelos comestiveis mycodo cresceu para incluir capacidade de fazer muito mais incluindo cultivar plantas cultivar microorganismos manter homeostase apiario de abelhas incubar animais e ovos manter sistemas aquaticos queijos envelhecidos fermentar alimentos e tabaco cozinhar comida sousvide e muito mais sistema compreende um backend daemon e um frontend interface de usuario backend conduz medicoes partir de sensores e dispositivos e coordena um conjunto diversificado de respostas essas medicoes incluindo capacidade de modular saidas reles pwm tomadas sem fio regular condicoes ambientais com dispositivos eletricos sob controle pid regulacao estavel ou troca tempo agendar cronometros capturar fotos e transmitir video acionar acoes quando medicoes atenderem determinadas condicoes modular reles executar comandos notificar por email etc e muito mais frontend e uma interface da web que permite facil navegacao e configuracao partir de qualquer dispositivo habilitado para navegador russian mycodo raspberry pi zero 1 2 3 4 mycodo sousvide serbian 1 2 3 4 spanish mycodo es un sistema automatizado de monitoreo regulacion que fue creado para ejecutarse en la raspberry pi versiones cero 1 2 3 4 originalmente disenado para cultivar hongos comestibles mycodo ha crecido para incluir la capacidad de hacer mucho mas incluido el cultivo de plantas el cultivo de microorganismos el mantenimiento de la homeostasis de las abejas la incubacion de animales huevos el mantenimiento de los sistemas acuaticos el envejecimiento de los quesos la fermentacion de alimentos el tabaco la cocina comida sousvide mas el sistema comprende un backend daemon un frontend interfaz de usuario el backend realiza mediciones desde sensores dispositivos luego coordina un conjunto diverso de respuestas esas mediciones incluida la capacidad de modular salidas reles pwm salidas inalambricas regular las condiciones ambientales con dispositivos electricos bajo control pid regulacion constante cambio tiempo programe temporizadores capture fotos transmita videos active acciones cuando las mediciones cumplan ciertas condiciones module reles ejecute comandos notifique por correo electronico etc mas la interfaz es una interfaz web que permite una facil navegacion configuracion desde cualquier dispositivo con navegador swedish mycodo ar ett automatiserat overvaknings och reglersystem som byggdes att springa pa raspberry pi versioner noll 1 2 3 och 4 mycodo har ursprungligen utformats att odla atliga svampar och har darmed okat mojligheten att gora mycket mer inklusive odling av vaxter odlingsmikroorganismer uppratthallande av honeybee apiary homeostasis inkubering av djur och agg uppratthallande av vattenlevande system aldrande ostar jasning av mat och tobak matlagning mat sousvide och mer systemet innefattar en backend daemon och en frontend anvandargranssnitt bakgrunden utfor matningar fran sensorer och enheter och samordnar sedan en mangd olika svar pa dessa matningar inklusive mojligheten att modulera utgangar relaer pwm tradlosa uttag reglera miljoforhallandena med elektriska enheter pidkontroll standig reglering eller byte tid schemalagg timer ta bilder och stromma video utlos atgarder nar matningar uppfyller vissa villkor modulera relaer utfora kommandon meddela via epost etc och mer frontend ar ett webbgranssnitt som mojliggor enkel navigering och konfiguration fran alla webblasaraktiverade enheter chinese mycodoraspberry pizero1234 mycodosousvide pwmpidweb thanks alembic bootstrap date range picker flask flaskbabel flasklimiter flaskrestplus flaskwtf fontawesome gridstackjs gunicorn highcharts influxdb jquery pyro5 sqlalchemy sqlite toastr\n",
      "[1 1 0 0 1 1 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 0 1 1 1 1 0\n",
      " 1 0 0 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1\n",
      " 1 0 1 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 1 1 0 1 0\n",
      " 0 1 0 0 1 1 0 1 0 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 0]\n",
      "environmental consulting web site project attempt recreate web site environmental consulting firm using bootstrap think ' big improvement\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0]\n",
      "environmentaljeopardy\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "mitiapenvironmentplatform environmental management platform environmental ministry sri lanka developed collaboration wso2 mitiap program\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "gismo gismo free open source grasshopper plugin gis environmental analysis description gismo enables automatic generation urban environment terrain geometry based location ' latitudelongitude coordinates radius includes connection openstreetmap website generation buildings trees roads rivers map elements 3d building elements also used context analysis types isovist visibility solar radiation thermalwind comfort cfd analysis screenshots requirements mcneel rhino 5 32bit 64bit sr9 rhino 6 rhino 7 wip supported moment grasshopper 090075 090076 ghpython plugin 0603 mapwingis 32bit 64bit version 4942 4961 gismo still support 5 version active internet connection installation install upper mentioned requirements rhino 5 grasshopper ghpython mapwingis download latest gismo plugin files single zip file httpsgithubcomstgeorgesgismozipballmaster check downloaded zip file blocked right click choose properties unblock button click click ok unblock button click ok unpack zip file copy content userobjects folder grasshopper ' filespecial foldersuser object folder folder additional info discussion group facebook twitter gismo heavily influenced ladybug free open source environmental plugin grasshopper using code template follows labybug code organization methods ladybug may also copied gismo licensed gpl30 license httpspdxorglicensesgpl30 latest version 003 contributors antonello di nunzio djordje spasic guillaume meunier mathieu venot support various issues questions given alec bennett andrew young bojan savric christopher crosby dragan milenkovic even rouault graham dawson izabela spasic jonathan de ferranti jukka rahkonen menno deijvan rijswijk michal migurski mostapha sadeghipour roudsari paul meems sergei leschinsky timothy logan ulrich deuschle vladimir elistratov osm gdal communities\n",
      "[0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 1 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
      "electricimpenvironmentals demo project collect store chart environmental data electric imp device using nodejs angular mongodb requirements electric imp dev kit environmental tail nodejs environment mongodb database knowledge javascriptnodejs environments server setup server must publicly accessible npm update bower update node serverjs device setup login httpsideelectricimpcom register electric imp device install agentnut devicenut update agentnut environment begin settings const serverurl httpyourhostcom const wundergroundapikey xxxxxxxxxx const wundergroundlocation nyalbany end settings\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "sensorairthingswave hassio support airthings wave airthings wave plus airthings wave mini ble environmental sensors much code build component inspired projects httpairthingscomraspberrypi httpsgithubcommarcelmradonwave aforementioned radonwave project especially useful describes many ble characteristics specific product good troubleshooting tips script provided also useful determining mac address aw device see httpsgithubcommarcelmradonwaveissues3 getting started download customcomponentsairthingswave config directorycustomcomponentsairthingswave example configurationyaml example configurationyaml entry sensor platform airthingswave scaninterval 120 optional configuration variables mac stringoptional airthingswave mac address provided scan airthings devices startup scaninterval stringoptional interval polls defaults 300 seconds 5 minutes limitations may possible wave must connected official app least use program probably get around registering account airthings radon level history stored wave cannot accessed component get around connects regularly radon detector make sure install latest firmware device using official app first known issues yet able specify monitoredconditions configuration translations available yet hardware requirements airthings wave airthings wave plus airthings wave mini raspberry pi 34 builtin bluetooth bluetooth adapter supports bluetooth low energy ble one httpswwwamazoncomdpb01n5mgeusrefcmswrtwdpuxobdncb03p7qzj resources httpsgithubcommarcelmradonwaveissues1 httpscommunityhomeassistantiotradoneyebleinterface94962 httpssupportairthingscomhcenusarticles115002910089howtorespondtoyourradonlevelsmobilesitetrue httpscommunityhomeassistantiotconvertingsensormeasurementunits98807 httpcertiusdownloadscanadameasbwpdf\n",
      "[0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "1javaionetjdbc 2jdbcjava database connection 3oracel 4xmldom4j 5log4j 1log 2 tdetailx131 3logenvironment 4environment 5 6dom4springioc\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "artemis almost realtime environmental monitoring information system getting started ' already got environmental sensors great ' halfway check supported devices see equipment known work devices plugin difficult write see plugin development starting scratch either buy supported devices take look building sensors prerequisites httpd php python 26 pythonrrdtool rrdtool momentjs 172 pythonsqlalchemy pythonargparse installation run setupsh initialise config files storage directories edit artemisconf liking run artemiscollectpy initialise data store add least one node using artemisclipy addnode run artemiscollectpy detect collect data probes update positions probes using artemisclipy updateprobe necessary modify artemiscronand copy etccrond architecture sensors thread crond sensors thread sensors thread collector json javascript display sensors thread sensors thread ' rrd files supported devices exhaustive list devices listed least tested devices may supported yet listed check git repository manufacturermodelworksprotocolmodule swifttechcm2xmlxmlenvswift swifttechcm2snmpsnmpenvswift apcap7953snmpsnmppduapc jacartaunknownsnmpsnmpenvjacarta plugin development plugins different sensors implemented individual modules plugins module expected define class name subclasses node basepy must define least one method fetch class nodeobject def initself ip selfip ip def fetchself pass plugins implementing access snmp devices basepy also provides convenience function getmib fetching contents mib trees walking tree defined point getmibip mib community public addition basepy provides definitions unit symbols lookup table 1wire device families unittemperature unitcurrent unitairflow unithumidity family1wire additional unit definitions 1wire families added needed reference platform 1wire sensors maxim 1wire sensors lowcost readily available accurate devices easily interfaced computer usb interfaces ds1822 temperature 2c 912 bit ds18b20 temperature 05c 912 bit ds18s20 temperature 05c 9 bit base units currently ongoing project develop lowcost base unit around raspberry pi completed recommended base unit time good options low cost development boards systems based around via atom cpu many available 100 existing commercial units cost region 500\n",
      "[1 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "hamlet\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "areawebsite website currently developed area environmental made bootstrap js html css v1 first version supplied client changes suggested v2 currently developed version client\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "modulefile search prefix directory installed software generate environmental modules modulefile installation git clone httpsgithubcomuconnhpcmodulefile pip install user upgrade editable modulefile make sure localbin similar path per pep 370 usage modulefile pathtomyapp10 pathtomymodulefiledirapp10 tests virtual environments tests orchestrated using tox install tox using pip pip install user tox run tests using tox debug failing tests tox pdb add dependencies get import errors need recreate tox environment tox recreate edit files ' likely going create lots linter errors caught tox unit tests text editor ' interactive error reporting use emacs configure python development installing elpy\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1\n",
      " 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0]\n",
      "environmentalmodeling\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "multirotors research andrew bennett ' lab using multirotors conduct environmental exploration sensing sampling missions projects code repository contains mission files general architecture several mission types executed drones namely breath condensate collection cetacean wireless tracker tagging large cetacean photogrammetry animal studies pointofinterest data collection environmental exploration waypoint navigation sense avoid unfriendly multirotors missions designed mission file mission file executed generic autonomy structure based upon state configured layer control sclc controls actions drone running code still construction rc override computer control overridden switching ch 6 transmitter value greater 1500 keyboard controls stabilize sort manual l loiter auto r arm disarm p open planner joystick controls specific joystick finalized yet\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "mining sensor data evaluate indoor environmental quality public educational buildings project collect extract transform load analyse sensor data transmitted large amount sensors installed school buildings across three european countries sensor data report multiple types information including temperature humidity outdoor weather electronic consumption human activities etc using python library pandas matplotlib numpy comfort tools berkeley aim predict overall comfort kpi indoor environmental quality school buildings based findings school management optimise environment quality basic information care collecting data schools six ready step get work time spent school sometimes even school still stay sports activities stay library studying ideally school enough illumination comfortable temperature hot cold enough fresh air cool head crashed study andor stress governments spend lot money education enough money way put money better place instead paying electricity bills really want something making better place study start look need firsthand data tell us part expensive one start work situation sensor data good cutting point observation analysis points sensors geography distribution locations google map country parameter number comment greece sensing endpoints 872 sensor equals 1 sensing endpoint sensing rate 1 minute modified educators 294 greek public schools gaia students 2267 greek public schools gaia italy roma sensing endpoints 118 soon augmented sensing rate 1 minute modified educators 120 university faculty post doc students 1706 university students italyprato sensing endpoints 117 swedensoderhamn sensing endpoints 3 create 20170712t12 add data yet total 16 sites 1922 sensors record till 20170916 part newly installed year history data 2015 data collected different weather condition different cultures different user behaviour pattens good start could see difference find similarity sensor data unit power consumption calculated power consumption mwh power consumption mwh electrical current maa active power mw apparent energy vah apparent power va voltage v power factor raw value reactive energy varh reactive power var environmental parameters noise raw value motion raw value movement raw value luminosity raw value light lux atmospheric pressure kpa external relative humidity relative humidity rain height mm wind direction degrees wind speed msec temperature centigrade external temperature c radiation usvh careful high die external air contaminants raw value external ammonia concentration raw value external carbon dioxide concentration raw value external carbon monoxide concentration raw value external oxygen concentration raw value carbon monoxide concentration raw value methane concentration raw value points sensors connection wifi 2g3g mobile network connection ethernet lowrate wireless personal area networksieee 802154 data variability potential patterns take close look raw data seek changing patterns temperature light motion power consumption demo schools greece one year time interval day power consumption 10 schools greece 3 schools without power consumption sensors data temperature 12 schools greece demo site 8 greece 3 weeks time interval hour temperature 4 weeks main building building floor plan pattens room4ce ground floor heading north lowest temperature time two first floor two classrooms west class 1 2 next similar pattern temperature changing warmest rooms whole school building rooms north cooler demo site greece 4 weeks time interval hour temperature main building building floor plan patterns temperature computer lab stable rest others still fit expectation humidity main building building floor plan patterns see basement highest humidity music class stable remain good dry condition preserving music instruments luminosity main building subsite building pattern rooms use natural light always light turn weekend rooms facing south exposed longer daylight maximum luminosity compared lab basement availability algorithm availability different prediction clean outlier inactive data intuition sensor data reasonable zero value true valuelike motion one walking around sensor data never zero like temperature humidity always zero others type might zero general summary one point sensors even isare sensor data legal zero summary based timestamps always zero long active process put value 0 1 sum sensor data one points sensors normalized value 0 1 output 1 active 0 inactive points sensors visualize heatmap points sensors availabilities table includes large range data missing due sensors longer working whole sites power 2015nov12017oct30 id name inactive start time outlier total number measurements 144024 3048 20151030 1649 73000 144242 1 294 20151030 1090 94900 144243 2449 20151030 1580 64970 155076 gramscikeynes school 456 20160804 3977 3977 155077 sapienza 5822 20161029 5101 177390 155849 6 2298 20151030 1676 52560 155851 5 2923 20160802 3925 75190 155865 46 3872 20160922 3828 53290 155877 2 3518 20170201 4580 46720 157185 331 20170201 4050 123370 159705 soderhamn 000 20170921 4824 70810 19640 172 20151030 2034 112420 27827 8 371 20151030 1071 71540 28843 2 4308 20151030 2217 117530 28850 55o 2123 20151030 2236 91250 visualize heatmap sensor data availabilities table statistic sensors belong three different vendors different connections name inactive outlier total number measurements libelium outdoor weather 1516 1061 31390 synfield outdoor weather 1440 928 10950 electrical power consumption 1868 3340 73010 visualize heatmap category different connections sensors data reliability clean times period sensors inactive clean sensors always inactive site poweron yet counted inactive sensorsmaybe themactived start count inactive missing data remove outliers turkey ' fences replace minmax value outliers statistics outlier observation point distant observations outlier may due variability measurement may indicate experimental error latter sometimes excluded data set3 outliers occur chance distribution often indicate either measurement error population heavytailed distribution former case one wishes discard use statistics robust outliers latter case indicate distribution high skewness one cautious using tools intuitions assume normal distribution frequent cause outliers mixture two distributions may two distinct subpopulations may indicate ' correct trial ' versus ' measurement error ' modeled mixture model output two ways indicate data point outlier realvalued outlier score higher values score make point like outlier binary label binary value yes data point outlier identify outliers using turkey ' fences aka inter quartile range q1 first quartile q3 third quartile interquartile range iqr q3 q1 lower outlier boundary q1 3 iqr upper outlier boundary q3 3 iqr identify outliers using sliding windows w holds last w1 values moving windows data beginning inter quartile range becomes biggest ever seenhere comes outliers replace min max new value nan also outlier replace average minmaxaverage minmaxaverage previous w1 values moving window average smooth shortterm fluctuations highlight longerterm trends cycles sma straightforward calculation average chosen time period main advantage sma offers smoothed line less prone whipsawing response slight temporary price swings back forth therefore provides stable level indicating support resistance sma ' weakness slower respond rapid changes often occur market reversal points sma often favored analysts operating longer time frames daily weekly charts refill nan average whole series values linear fit statistics linear regression linear approach modeling relationship scalar dependent variable one explanatory variables independent variables denoted x visualize one day temperature data processes mentioned accuracy retrieve outdoor weather api openweathermap realtime data response real time request worldweatheronline history data apis response temperature wind humidity pressure cloud accuracy data retrieved api sensors notice api worldweatheronline provide longer 32days data conclusion yes retrieve realtime historybut accuracy pretty enough interpretation orientation prediction deviation assuming indoor temperature rise day time passing put human activity others consideration identify patten peak time intuitively observing temperature peak different rooms east peak temperature mostly arrives early day west peak late day south peak midnoon later rest room facing northmusic roomcomputer labbasement room relatively low variation average temperature put cloud cover persentage orientation room observe time difference indoor vs outdoor reach daily peak temperature predicting orientation using peak temperature using restful api retrieve time sunrise noon sunsetunit hour check temperature daytime sunrisesunset pick hottest time put timehour listpeakathour orientation sum listpeakathour 24hour 360degreelengthlistpeakathour unitdegree simply match orientation 090 degree northeast 90180 degree southeast 180270 degree southwest 270360 degree northwest imagecomp1jpg exmaple8 class 1 id fb8 classroom reach highest temperature hour peakathourlist 18 17 17 17 17 17 17 17 17 17 17 18 17 17 17 17 17 17 17 17 17 17 17 17 17 17 16 16 16 16 18 17 16 16 17 16 17 16 16 17 16 18 17 17 17 16 16 17 17 16 1717 16 16 17 17 17 16 17 17 18 17 17 16 16 17 17 17 1717 17 16 17 17 16 17 15 16 17 16 16 16 16 16 16 17 17 16 17 16 17 17 15 16 17 17 17 16 16 16 total 16 ' clock 33times 18 ' clock 5times15 ' clock 2times 17 ' clock 60times orientation sum16243602615243602172436060lengthpeakathourlist 2502 degree got orientation 2502 degrees looks like southwest also lot peaks happened morning classlb2 id 0x317 room gets enough exposed sunshinehigh temperature morning also likely facing southeast total 14 ' clock 5times 16 ' clock 3times 10 ' clock 3times 12 ' clock 3times 11 ' clock 3times 15 ' clock 3times13 ' clock 2times 18 ' clock 2times 17 ' clock 2times 7 ' clock 1times 19 ' clock 1times orientation 2057 degreehave peak temperature mornings 7 10 11 takes 250 total got something like heading east south east take close look distribution site rooms different orientation southeast lower temperature compared south southwest room category site site id orientation prediction correct 144024 60 144243 50 155851 20 155865 50 19640 0 27827 25 144242 0 155877 33 159705 28 155849 0 157185 44 rest data category room orientation orientation orientation prediction correct comment n e 0 012 e 35 617 w 56 916 w 0 01 w n 0 011 cloudy coverage impact indoor temperature identify deviation slope deltatemperaturedeltatime slope one room first picture data etl second slop data focusing detecting sudden change indoor temperature slope plot could provide fast efficient way fluctuate exists sep23 top plot peak matching change observed bottom plot well use similar algorithm searching outliers slope detect fluctuate put classrooms one site togetheretl data top slope bottom detect room behavior abnormal room red day time room orange night time comfort wikipedia thermal comfort thermal comfort condition mind expresses satisfaction thermal environment assessed subjective evaluation ansiashrae standard 55 ansiashrae standard 55 thermal environmental conditions human occupancy standard provides minimum requirements acceptable thermal indoor environments purpose standard specify combinations indoor thermal environmental factors personal factors produce thermal environmental conditions acceptable majority occupants within space standard addresses four primary environmental factors temperature thermal radiation humidity air speed two personal factors activity clothing affect thermal comfort applicable healthy adults atmospheric pressures altitudes equivalent 3000 9800 ft indoor spaces designed occupancy least 15 minutes comfort zone refers combinations air temperature mean radiant temperature tr humidity predicted acceptable thermal environment particular values air speed metabolic rate clothing insulation icl intuitively want temperature indoor certain range like 1824 monday friday 800 1800 obviously truth always wish tool cbe thermal comfort tool ashrae55 use choosing adaptive method top user interface chart changes input variables include air temperature mean radiant temperature prevailing mean outdoor temperature personal factors humidity significant method since adaptation considered variable outdoor temperature see explanation first two variables air mean radiant temperature prevailing mean outdoor temperature type outdoor temperature averaged explained standard see wikipedia link brief explanation changing variable makes dot representing current condition move horizontally meaning chart certain conditions indooroutdoor temperature fall inside comfort zone case static sample period 2017sep052017nov04 weekday mondayfriday time 8001600 week year 3644 daytime room comforable n8hours 0 n 1 day comfortable 1 day comfortable 0 following two pictures comfortness ratio per day based hourly temperature site id 27827 8 use sitetemperature sensor outdoor temperature source use worldweatheronline api outdoor temperature source difference might accuracy sitetemperature following two pictures comfortness ratio per day based hourly temperature site id 1442421 use libelium sensor outdoor temperature source use worldweatheronline api outdoor temperature difference might complete nonsense data libelium sensor following two pictures comfortness ratio per day based hourly temperature site id 19640 use libelium sensor outdoor temperature source use worldweatheronline api outdoor temperature retrieve data retrieve data using apis httpsapisparkworksnetswaggeruihtml demo post v1resourcequerytimerange command line curl x post header ' contenttype applicationjson ' header ' accept applicationjson ' header ' authorization bearer cd885cf57fca4be8b32e97225da6763f ' ' queries 1498867200000 granularity day resourceid 156972 resultlimit 0 1500076799000 ' ' httpsapisparkworksnetv1resourcequerytimerange ' reponse body results resourceid156972resourceurigaiaearoom1tempfrom1498867200000to1500076799000granularitydayresultlimit0 average 31995042261495424 summary 47992563392243136 data timestamp 1498856400000 reading 3419535065107274 timestamp 1498942800000 reading 35618584889499054 timestamp 1499979600000 reading 25807027188020786 timestamp 1500066000000 reading 28399119190883642 known issues request data within time range different granularity response time stamps different 5min ' code running time fixed data timestamp 1hour beginning every hour 1day 2100 day 1month 2100 last day month solution use toinstanttoepochmilli 300000300000 change time 5mins interval one hour 5 ' 10 ' 15 ' 55 ' record timestamp cassandra connector data source flink solution reference cassandraconnectoritcase clusterbuilder cb new clusterbuilder override public cluster buildclusterclusterbuilder builder return builderaddcontactpoint127001build string query select resourceidreading gaiareadingdata resourceid155873 inputformattuple2integer float inputsplit source new cassandrainputformatquery cb sourceconfigurenull sourceopennull listtuple2integer float result new arraylist sourcereachedend resultaddsourcenextrecordnew tuple2integer float sourceclose ' read data api resource historical data resource id 90946 20170824t092549323z 20170831t092549080z steps per hour 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 however real data allzeros httpsconsolesparkworksnetresourceview90946 use data extracted api process console data reference data missed time time resource historical data resource id 155918 20170824t092549323z 20170831t092549080z steps per hour 3234 3234 3234 32473637 334425 34259167 3475733 34365334 3332 32764668 32570587 3236722 323155 323068 32241306 31868149 31868149 3185 31838118 31808867 31826338 31822662 31832302 31852188 31842134 31841246 3185319 32140522 33013374 33919827 34664608 3472307 3234 3234 3234 3185 3185 3234 3185 3185 3185 3185 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 31367912 31374935 31410751 31416487 3151673 3194285 3277366 3364148 34232605 33768044 3268922 3230267 32140594 31958946 3187191 31852951 31830269 3164 3146889 31456898 313657 31385254 31381018 3141322 31534771 31668463 3179291 31836 31869188 3238108 33044456 33666306 33827496 3296945 3238393 3223478 32038074 31907423 31856163 31844433 31838556 3169923 316932 31511343 31412098 31391008 31380096 31443954 31619139 31776262 31830036 31832235 31799591 3184828 3209569 32928936 3333732 33126163 32188957 3183223 31623442 31422161 31361742 31356749 313123 30906296 30886333 30878448 30859062 30843264 30859325 30861336 30849495 3085837 3085697 reference building data genome project big data computing naked statistics stripping dread data charles wheelan real time sensor status gaia supervisors professor ioannis chatzigiannakis professor aris anagnostopoulos acknowledgement since first day stepped sapienza ones lead find true love data mining till last six months gave fish also taught fish supports encourage beyond anything could expect blessed without wont standing today\n",
      "[0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 0 0 1 1 0 1 0\n",
      " 0 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 0 1 0 0 1 1 0\n",
      " 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1]\n",
      "air china openair project fetch data official silverlight application ministry environmental protection china http1063720823320035 publish realtime air quality http1063720823320035 silverlight install via pip recommanded pip install openair git clone httpsgithubcomhebingchangairinchina cd airinchina python setuppy install usage encoding utf8 openair import airclass air airclassairchina print airgetallstationsdata type 0 type 0id ' 9 ' 1 ' ' 2 ' shanghai ' shanxi shanxi print airgetprovincestationsdatashanghai type2 print airgetallprovincename 1 id getallprovincenameid airgetprovinceallcityname12 1 id airgetprovinceallstationinfo10 2 id unicode getprovinceallcityname airgetcityallstationinfo10 u aqi 1 id 310000u ' ' airgetcityhistory310000 return values json area co24h 31 latitude 398673 o3 64 pm1024h no2 160 o324h 2 unheathful so224h 41 pm2524h 247 aqi 329 provinceid 1 pm25 279 co 43 o38h 39 longitude 116366 o38h24h 29 so2 53 timepoint 20170215t220000 stationcode 1001a orderid 1 citycode 110000 positionname pm10 primarypollutant pm25 no224h 120 measure ispublish true quality 1 beijing 2 tianjin 31 xinjiang latitude 312472 stationcode 1160a positionname longitude 120561 latitude 312864 stationcode 1161a positionname longitude 120628 latitude 313708 stationcode 1167a positionname longitude 120641 aqi citycode 310000 area unheathful quality pm2524h 31 primarypollutant timepoint 20170201t000000 co24h 07 pm1024h 37 no224h 20 so224h 12 measure o38h24h 90 aqi 45 id 386477 citycode 310000 area unheathful quality pm2524h 21 primarypollutant timepoint 20170202t000000 co24h 06 pm1024h 27 no224h 23 so224h 11 measure o38h24h 87 aqi 44 id 386876 thanks pythonwcfbin httpsgithubcomernwpythonwcfbin license project mit license copyright 2017 permission hereby granted free charge person obtaining copy software associated documentation files software deal software without restriction including without limitation rights use copy modify merge publish distribute sublicense andor sell copies software permit persons software furnished subject following conditions copyright notice permission notice shall included copies substantial portions software software provided without warranty kind express implied including limited warranties merchantability fitness particular purpose noninfringement event shall authors copyright holders liable claim damages liability whether action contract tort otherwise arising connection software use dealings software afterword\n",
      "[0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "python audio feature extraction repository holds library implementations separate utilities used extraction processing features audio files underlying extraction library librosa offers ability extract variety spectral features well miscellaneous features project goals learn feature extraction audio files standardize parameters use extraction large amounts audio samples allow relatively easy interface select extract subsets parameters subsets samples provide pandas wrappings extraction results hold important metadata information extraction process current implementations audiofeatureextractor class defines object used standardize set parameters used feature extraction provides wrapper methods librosa functions handle preprocessing steps preemphasis filtering hard low high cutoffs facilitate data cleaning batchextractor class defines object holds information batch audio samples feature extraction performed implements methods handle batch extraction using set standardized settings easy selection desired features featurevisualizer class defines object handle visualization features matplotlib usage documentation audiofeatureextractor class imported afe module words import audiofeatureextractor object simply put afe import audiofeatureextractor along rest needed imports instantiate audiofeatureextractor object put work object takes parameters instantiation desired sample rate hz use loading analysis audio default 22050 desired number samples use window length framed computations feature extractions number set integer power 2 optimize fourier engine default 1024 desired ratio window length hop framed computations ie overlapping factor setting 4 implies frame jumps 14 window length framed computations default 4 audiofeatureextractor capability retrieving audio string file path instance ' sample rate loading numpy array detect onsets perform preemphasis filtering bandpass filtering noise removal low high regions extract feature using instance ' standardized framing attributes either numpy array audio samples preprocessed stftcqt bandpass noise removal currently following feature extraction methods implemented feature extraction methods begin prefix extract extractstft extracts short time fourier transform extractcqt extracts constantq transform extractchromastft extracts chromagram extractchromacqt extracts chromagram cqt extractchromacens extracts energy normalized variant chromagram extractmelspectrogram extracts melwindowed spectrogram extractmfcc extracts melfrequency cepstral coefficients extractrms extracts framed rootmeansquare extractspectralcentroid extracts spectral centroid extractspectralbandwidth extracts spectral bandwidth extractspectralcontrast extracts spectral contrast extractspectralflatness extracts spectral flatness extractspectralrolloff extracts spectral rolloff extractzerocrossingrate extracts framed zero crossing rate extracttonnetz extracts tonnetz tonal centroid extractpolyfeatures extracts polynomial combinations features given feature matrix audio ultimately would like add functionalities audiofeatureextractor tempo related feature extraction methods feature manipulation tools offered librosa feature inversion tools translate back feature space auditory space hopefully facilitate interesting generative projects later perhaps incorporating utilities could helpful later projects methods feature engineering batchextractor batchextractor somewhat extension audiofeatureextractor handle standardized extraction batch samples order use batchextractor object must import way afe import batchextractor instantiate batchextractor object object accepts instantiation following parameters three parameters accepted instantiation audiofeatureextractor object string path folder containing audio samples either pandas dataframe string path csv file read dataframe metadata information samples specified folder audio details formatting index dataframe discussed indepth number melfrequency cepstral coefficients compute default 12 boolean flag indicating whether preemphasis filtering applied audio computation features default false float 0 1 indicating desired preemphasis filter coefficient option desired appropriately set using boolean flag default 097 boolean flag indicating whether hardbandpass filtering noise higher lower frequencies applied default false hardbandpass noise filtering applied flag appropriately set integer values set upper lower limits noise filtering default none boolean flag indicating whether start audio samples trimmed first computed onset default false batchextractor specified requires index dataframe specified either string pointing csv file passing dataframe particular dataframe needs column named filename indicates audio sample analyzed file path string relative batchextractor ' stored audio folder path columns present index dataframe could depend context project currently batchextractor used perform following tasks methods available set preprocessing options setbpfilter sets bandpass noise filtering flag parameters setpreemphasis sets preemphasis flag parameters settrim sets flag trimming first onset methods extract merge features batch samples stored instance ' index folder audio methods accepts string indicating resultsfolder either save extracted feature matrices csv files look saved extraction results csv files case merging additional options method detailed batchextractfeature accepts string abbreviation single extraction method apply entire batch audio index saves results given resultsfolder batchextractfeatures accepts list string abbreviations extraction methods apply entire batch audio index saves results given resultsfolder mergefeatures accepts list string abbreviations features merge single dataframe words sample audio index feature matrices specified list abbreviations loaded resultsfolder merged saved new dataframe batchextractandmerge performs batch extraction merging features given list string abbreviations audio samples index mergeandflattenfeatures methods nonnull return method loads sample audio index feature matrices given list extraction abbreviations flattens single row creating many many columns concatenates rows appropriately padded dataframe containing feature information samples index would eventually like add following batchextractor implementation featurevisualizer featurevisualizer class defines object could helpful purposes debugging identifying import sonic features general computations stftspectrogram helpful give us good visual description happening audio even though quantities also helpful making specific quantifications purposes analysis featurevisualizer class attempt creating interface visualization features extracted using batchextractor similarly audiofeatureextractor object instantiation object accepts following parameters string path indicating folder containing extracted features following naming convention ' samplenamefeatureabbreviationfeaturescsv ' default figure size use plotting default 18 8 currently class least implementation written currently object capable visualizing simply calling name sample loaded folder extracted features stftspectrograms melwindowed spectrograms chromagrams many feature visualization methods would like implement cqts spectral bandwidth related features tempograms eventually\n",
      "[0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1\n",
      " 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 1 0]\n",
      "earthsim pythonbased tools specifying launching visualizing analyzing environmental simulations hydrology modeling earthsim designed lightweight overview site project relying core code maintained generalpurpose pyviz projects bokeh interactive browserbased plotting holoviews easy construction bokeh plots datasets datashader rendering large datasets images display browsers param specifying parameters interest eg make widgets geoviews holoviews earthspecific projections repository primarily consists three things earthsim python package small amount code specific environmental simulation examples set jupyter notebooks show use various pyviz tools solve earthscience problems website example notebooks already run rendered html simple exploration cases examples notebooks website represent main form documentation even python package please see httpsearthsimpyvizorg information including installation usage instructions\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "mpies metaproteomics environmental sciences mpies workflow create annotated databases metaproteomic analysis workflow uses three different databases metagenome otutable ii assembledderived iii unassembledderived build consensus databases increase mapping sensitivity use mpies research please cite publication werner j geron kerssemakers j et al mpies novel metaproteomics tool creation relevant protein databases automatized protein annotation biol direct 14 21 2019 doi 101186s130620190253x installation easiest way use bioconda create new environment conda env create n mpies file condaenvyml conda activate mpies singlem packaged appimage due python 2 dependency download appimage build image cd appimages appimagesinglemsh appimagetoolx8664appimage singlemx8664appimage singlemappimage usage mpies consists two parts database creation annotation parts written snakemake database creation snakemake snakefile databasecreationsmk configfile databasecreationjson cores 28 annotation snakemake snakefile annotationsmk configfile annotationjson cores 28 detailed explanation mpies workflow database creation preprocessing preprocessing trims raw reads combines single reads one file ampliconderived proteome file order create ampliconderived proteome file two possibilities amplicon data available text file taxon names one per line used downloading proteomes uniprot amplicon data available set option configotutablerunsinglem true taxon file created singlem tool detects otu abundances based metagenome shotgun sequencing data functionalderived subset also possible create subset derived uniprot based taxonomy also restrict gene functional names instead downloading entire proteomes taxa interest toml file created see example taxonomy bacteria genenames dnak soxa proteinnames heat shock protein 70 something commented path needs set snakemake configuration configfunctionalsubsettomlfile assembledderived proteome file raw data available possible run assembly megahit metaspades set configassembledrunassembly true configassembledassembler megahit metaspades please keep mind assemblies take lot time depending size dataset already assembly set configassembledrunassembly false create symlink assembly sampleassemblycontigsfa gene calling yet remember set configassembledrungenecalling true assembly gene calling already performed set configassembledrunassembly configassembledrungenecalling false create symlink assembled proteome sampleproteomeassembledfaa unassembledderived proteome file create unassembledderived proteome file fraggenescan used prior fastqtofasta conversion postprocessing postprocessing three proteomes combined one file short sequences 30 amino acids deleted duplicates removed afterwards fasta headers hashed shorten headers save disk space annotation preprocessing identified proteins inferred proteinpilot resulting excel file used create protein fasta file contains identified proteins taxonomic functional analysis conducted identified proteins taxonomical annotation taxonomic analysis performed blast2lca megan package per default taxonomic analysis set false snake config file prerequisites necessary run taxonomic analysis created proteome fasta file download megan ' forget also download unzip file protacc2taxjune2018x1abinzip page download nrgz fasta file ncbi size 40 gb wget ftpftpncbinlmnihgovblastdbfastanrgz wget ftpftpncbinlmnihgovblastdbfastanrgzmd5 md5sum c nrgzmd5 checksum match download probably complete wget c continues partial download create diamond database file nrgz diamond makedb threads numberofthreads nrgz db nrdmnd set configtaxonomyruntaxonomy true run snakemake remember set paths diamond database binary blast2lca path file protacc2taxjun2018x1abin please note diamond blastp takes long time execute functional annotation different databases used add functional annotation per default funtional annotation set false cog order use cog database prerequisites fulfilled download necessary files ftp server wget ftpftpncbinihgovpubcogcog2014dataprot20032014fagz wget ftpftpncbinihgovpubcogcog2014datacog20032014csv wget ftpftpncbinihgovpubcogcog2014datacognames20032014tab wget ftpftpncbinihgovpubcogcog2014datafun20032014tab create diamond database file prot20032014fagz diamond makedb threads numberofthreads prot20032014fagz db cogdmnd set configfunctionsruncogrunfunctionscog true run snakemake remember set paths diamond database files cogtable cognames cogfunctions uniprotgo order use go ontologies included uniprot database swissprot trembl prerequisites fulfilled download necessary files ftp server swissprot wget ftpftpuniprotorgpubdatabasesuniprotcurrentreleaseknowledgebasecompleteuniprotsprotfastagz wget ftpftpuniprotorgpubdatabasesuniprotcurrentreleaseknowledgebasecompleteuniprotsprotdatgz trembl wget ftpftpuniprotorgpubdatabasesuniprotcurrentreleaseknowledgebasecompleteuniprottremblfastagz wget ftpftpuniprotorgpubdatabasesuniprotcurrentreleaseknowledgebasecompleteuniprottrembldatgz please note trembl quite large 29 gb uniprottremblfastagz 78 gb uniprottrembldatgz create diamond database fasta file swissprot database used diamond makedb threads numberofthreads uniprotsprotfastagz db sprotdmnd use dat file downloaded uniprot create table protein accessions go annotations mainpy prepareuniprotfiles u uniprotsprotdatgz sprottablegz please note input output files must beare compressed gzip set configfunctionsrununiprotrunfunctionsuniprot true run snakemake test data test data set subset ocean sampling day first 18000 lines read file accession number err770958 obtained httpswwwebiacukenadataviewerr770958 data deposited testdata directory repository\n",
      "[0 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1\n",
      " 0 1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0]\n",
      "environmentalinterface underlying middleware servioticy requirements servioticy apikey inside servioticyres directory secretsexample must fulfilled instructions inside deletion requirements order use delete scripts clean service objects additional tools needed curl postgresql client sudo aptget install postgresqlcommon postgresqlclientversion file pgpass root directory following database info content cd echo hostnameportdbnamedbuserdbpassword pgpass preparation phase order create valid servioticy folder several files must created executing firstly models room sensors must created make use generator inside servioticymodels javac modelgeneratorjava java modelgenerator rooms room currently composed 5 sensors xm1000 light power presence air quality additionally actuators also created making use generator inside servioticyactuators javac actuatorgeneratorjava java actuatorgenerator rooms currently room contains computer light hvac actuators order push actuators servioticy store ids database additional scripts created pushactuatorssh script firstly uses createsosh script communicate servioticy obtain ids finally uses script dbpy store ids database usage several options launch interface currently virtual real sensor servers run real sensor server needed firstly required start serial forwarder moment xm1000 motes supported driver specs information refer httpwwwadvanticsyscomshopasxm1000p24html startsfsh serial port used java jar envifacejar comm source port port servers running virtual sensors needed executed follows java sensors port port ids sensors either commands execute sensors sending 2 messages\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1 1 1\n",
      " 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      "coding open data environmental reporting bc repo ' develop collection lessons based data code environmental reporting bc released content guidelines skill focus lesson focus helping learners gain skill ' need work data code released bc enable learners transfer skills projects lesson format anything goes ' looking guidance consider study group lesson one hour handson tutorial designed led instructor workshop lesson like study group longer selfstudy curriculum tutorial designed followed independent learner content format keep simple dependencyfree possible markdown plain text text ipython notebooks knitr scripts good options contributing please place lesson folder make sure everything needed scripts pointers data code etc included clearly labeled lesson folder feel free start brainstorming lesson ideas issue tracker begin\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "pect power externality correlation tool quantifying environmental impacts electricity purchased grid license lgpl version 1200 new google colaboratory option httpscolabresearchgooglecomdrive1uwdtphlkr8tja5r0hpn9ne668kppycx new read paper open access httpsdoiorg101016jsoftx201812001 script used model water consumption water withdrawal co2 emissions nox emissions so2 emissions attributed power generation fuel mix within specific location specified time frame pectipynb file used google colaboratory software requirments running script obtaining outputs however best use google chrome browsers firefox throw network errors script attempts download results file note emissions factors used script calculated egrid excel database included repository database updated every two years recent database found httpswwwepagovenergyemissionsgenerationresourceintegrateddatabaseegrid recent database downloaded included working directory best results findemissionrates script automatically use recent database directory long contains egrid corresponding year name user inputs location location numbers correlate city state etc time frame start end datatime data pulled watttime credentials username password valid watttime api account outputs time array generation fuel type water consumption water withdrawal cos nox so2 emissions emission factors fuel type water consumption withdrawal factors fuel type instructions colaboratory notebook click link provided httpscolabresearchgooglecomdrive1uwdtphlkr8tja5r0hpn9ne668kppycx run cell provide user inputs directed results file downloaded internet browser instructions python file download electricityandenvironment zip file run powerexpy powerexipynb file using jupyter notebook file necessary dependancies python3 urllib numpy pandas note findemissionratespy findemissionratesipynb file must located folder follow command prompts input necessary information corresponding desired data output output file located directory powerexpy file named resultsxlsx cite plewe k smith pect tool computing temporal spatial variation externalities related power generation united states softwarex 9 6167 2019 doi101016jsoftx201812001\n",
      "[1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1\n",
      " 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 1]\n",
      "previous contents repository migrated httpsgithubcomdlfmetadataassessmentdlfmetadataassessmentgithubio october 2019 site previously housed repository please see httpsdlfmetadataassessmentgithubioenvironmentalscanhttpsdlfmetadataassessmentgithubioenvironmentalscan\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "albiorix code used configuration administration bioinformatics computer cluster albiorix department biological environmental sciences university gothenburg\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "pect power externality correlation tool quantifying environmental impacts electricity purchased grid license lgpl version 1200 new google colaboratory option httpscolabresearchgooglecomdrive1uwdtphlkr8tja5r0hpn9ne668kppycx new read paper open access httpsdoiorg101016jsoftx201812001 script used model water consumption water withdrawal co2 emissions nox emissions so2 emissions attributed power generation fuel mix within specific location specified time frame pectipynb file used google colaboratory software requirments running script obtaining outputs however best use google chrome browsers firefox throw network errors script attempts download results file note emissions factors used script calculated egrid excel database included repository database updated every two years recent database found httpswwwepagovenergyemissionsgenerationresourceintegrateddatabaseegrid recent database downloaded included working directory best results findemissionrates script automatically use recent database directory long contains egrid corresponding year name user inputs location location numbers correlate city state etc time frame start end datatime data pulled watttime credentials username password valid watttime api account outputs time array generation fuel type water consumption water withdrawal cos nox so2 emissions emission factors fuel type water consumption withdrawal factors fuel type instructions colaboratory notebook click link provided httpscolabresearchgooglecomdrive1uwdtphlkr8tja5r0hpn9ne668kppycx run cell provide user inputs directed results file downloaded internet browser instructions python file download electricityandenvironment zip file run powerexpy powerexipynb file using jupyter notebook file necessary dependancies python3 urllib numpy pandas note findemissionratespy findemissionratesipynb file must located folder follow command prompts input necessary information corresponding desired data output output file located directory powerexpy file named resultsxlsx cite plewe k smith pect tool computing temporal spatial variation externalities related power generation united states softwarex 9 6167 2019 doi101016jsoftx201812001\n",
      "[1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1\n",
      " 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 1]\n",
      "waved web app visualizing environmental data httpkshskgithubiowaved installation basics client needs use waved web browser server side actions require running web server requirements server include serving static content html javascript css images well dynamic pages php setup accomplished various setups operating systems however document written tested fresh installation ubuntu 1204 lts precise pangolin necessary packages order get waved server running using apache php module including sqlite packages provide command line tools required standard deployment waved packages installed follows aptget update aptget install apache2 php5common php5sqlite libapache2modphp5 aptget install make sqlite3 acl content content needs served web server found waved git repository ' clone content documentroot apache server varwww default cd varwww git clone httpsgithubcomkshskwavedgit initial setup content brought web server initialization actions need performed includes setting directories permissions persisting project state data files actions handled makefile everything set apache server restarted ensure everything served correctly cd waved make service apache2 restart verifying server point waved server running clients able point web browsers waved folder web server however easy things web server verify functionality index page verify get index page waved get 404 error short html page displaying generic message rather 500 lines html curl sxpost localhostwaved project listing verify get listing currently existing projects json response success field true projects array empty curl sxpost localhostwavedphpgetexistingprojectdetailsphp create project verify create project command display json response success true projects array contain newly created project curl sxpost localhostwavedphpcreateprojectphp projecttestproject curl sxpost localhostwavedphpgetexistingprojectdetailsphp delete project verify delete project command display json response success true projects array empty curl sxpost localhostwavedphpdeleteprojectphp projecttestproject curl sxpost localhostwavedphpgetexistingprojectdetailsphp developer instructions download eclipse ide java developers import project file import exiting projects workspace select waved directory finish install jshint plugin help install new software work httpgithubeclipsesourcecomjshinteclipseupdates check jshint click finished\n",
      "[0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 0 0 1\n",
      " 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1\n",
      " 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0]\n",
      "wildlife tracker app forest service track animals environmental impact study description forest service considering proposal timber company clearcut nearby forest douglas fir proposal may approved must complete environmental impact study application developed allow rangers track wildlife sightings area setup create necessary databases launch postgres psql run following commands create database wildlifetracker c wildlifetracker create table animals id serial primary key name varchar create table endangeredanimals id serial primary key name varchar health varchar age varchar create table sightings id serial primary key animalid int location varchar rangername varchar create database wildlifetrackertest template wildlifetracker license copyright c 2017 mit license\n",
      "[0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "ewatec webbased platform buit top odm observational data model sharing environmental data features setup database install postgresql sudo sh c ' echo deb httpaptpostgresqlorgpubreposapt lsbrelease cspgdg main etcaptsourceslistdpgdglist ' wget q httpswwwpostgresqlorgmediakeysaccc4cf8asc sudo aptkey add sudo aptget update sudo aptget install postgresql postgresqlcontrib install postgis sudo aptaddrepository ppaubuntugisubuntugisunstable sudo aptget update sudo aptget install postgis connect postgresql sudo su postgres psql setup virtual environment virtualenv env install gdal virtualenv gdal library must installed sudo aptget install libgdaldev install python binding gdal export cplusincludepathusrincludegdal export cincludepathusrincludegdal env pip install gdal1112 install ibfreetype6dev libxftdev matplotlib sudo aptget install libfreetype6dev libxftdev install gfortran libblasdev liblapackdev libatlasbasedev scipy numpy sudo aptget install gfortran libblasdev liblapackdev libatlasbasedev install requirements env pip install r requirementstxt setup gunicorn setup nginx\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "modulefile search prefix directory installed software generate environmental modules modulefile installation git clone httpsgithubcomuconnhpcmodulefile pip install user upgrade editable modulefile make sure localbin similar path per pep 370 usage modulefile pathtomyapp10 pathtomymodulefiledirapp10 tests virtual environments tests orchestrated using tox install tox using pip pip install user tox run tests using tox debug failing tests tox pdb add dependencies get import errors need recreate tox environment tox recreate edit files ' likely going create lots linter errors caught tox unit tests text editor ' interactive error reporting use emacs configure python development installing elpy\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1\n",
      " 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0]\n",
      "envmon environmental monitoring system\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmental features recognition lower limb prostheses toward predictive walking present robust environmental features recognition system efrs lower limb prosthesis assist control prosthesis predicting locomotion modes amputees estimating environmental features following steps depth sensor inertial measurement unit imu combined stabilize point cloud environments subsequently 2d point cloud extracted origin 3d point cloud classified neural network environmental features including slope road width height stair also estimated via 2d point cloud finally efrs evaluated classifying recognizing five kinds common environments simulation indoor experiments outdoor experiments six healthy subjects three transfemoral amputees databases five healthy subjects three amputees used validate without training classification accuracy five kinds common environments reach 993 985 amputees indoor outdoor experiments respectively locomotion modes predicted least 06 switch actual locomotion modes estimation errors indoor outdoor environments features lower 5 10 respectively overall process efrs takes less 0023 promising results demonstrate robustness potential application presented efrs help control lower limb prostheses repository includes 2d binary image dataset cnn model based keras test train model directly running file classificationpy run python classificationpy uploaded environmental classification algorithm think useful part want upload image preprocessing environmental parameter estimation part please leave message issue send email directly contact related works codes please view homepage httpssitesgooglecomviewkuangenzhang information please contact kuangen zhang kuangenzhangalumniubcca citation find work useful research please consider citing articlezhangenvironmental2019 &#9; title environmental features recognition lower limb prostheses toward predictive walking &#9; volume 27 &#9; issn 15344320 &#9; number 3 &#9; journal ieee transactions neural systems rehabilitation engineering &#9; author zhang k xiong c zhang w liu h lai rong fu c &#9; month mar &#9; year 2019 license mit license\n",
      "[0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0]\n",
      "environmentalsound image data gotten es50 environmental sound dataset kaggle method extraction librosa mel spectrograms img h128 x w157 size 16000 processing ximg pickled downloaded resulting files labels stored ypickle\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "appretrofithellocharts\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmentalgame game developed ' environment sciences ' class universidade federal rio grande brazil\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmentaleventsdetector installation requirement register earth engine api token use application need google earth engine api key generate one please follow instructions order run server must earth engine api token ask access official websiteearth engine requirement run server create token never used python earth engine api must first download required packages get token sudo aptget update sudo aptget install pythondev pythonpip pip install user googleapipythonclient pycrypto earthengineapi packages installed authenticate localbinearthengine authenticate token stored configearthenginecredentials deploy application deploy application execute following command installsh run application run application execute following command runsh go httplocalhost9000indexhtml\n",
      "[1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "environmental ' working python virtual environment lazy open new terminal windowtab hotkeys type conda activate myenvironment created two shell commands window tab supported environments macos developed tested tool macos mojave tool available conda environments linux developed tested tool ubuntu 1804 gnome 3282 tool available conda virtualenv environments install install macos clone repo set permission run commands copy files run commands git clone httpsgithubcomthebarbershopenvironmentalgit sudo chmod x environmentalmacconda sudo cp environmentalmacconda usrlocalbin may delete downloaded files ' want keep around rm r environmental script emulates commandn commandt open new windowterminal fix line 8 script use different combination keys install linux use tool need install three extra tools xdotool xclip wmctrl sudo apt install xdotool xclip wmctrl clone repo set permission run commands copy files run commands git clone httpsgithubcomthebarbershopenvironmentalgit sudo chmod x environmentallinuxconda sudo cp environmentallinuxconda usrlocalbin use virtualenv instead conda replace path accordingly last two commands may delete downloaded files ' want keep around rm r environmental script emulates controlshiftn controlshiftt open new windowterminal fix line 10 window line 11 tab use different combination keys use window open new terminal window environment directory myenvironment currentdirectory window tab open new terminal tab environment directory myenvironment currentdirectory tab license software unlicenced whatever want liable consequences read license note ' plan import tool os environment manager ones using may someday whenever feel like feel free fork modify fit system would deeply appreciate send pull request addition\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1\n",
      " 0 0 0 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1]\n",
      "environmentaldatapredict environmental data predict\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "trafficsignrecognize nhan dien bien bao cam trong anh moi truong co su dung deep learning yeu cau python python 369 packages khuyen khich su dung anaconda 3 tao mot environment moi ten opencv e cai tat ca packages nhu hinh numpy 1172 matplotlib 311 opencv 342 django 225 scikitimage 0150 tensorflow 200 tensorflowmkl 1150 keras 224 pillow 621 run project activate bien moi truong anaconda 3 source ospathanaconda3anaconda3binactivate activate moi truong chua cac packages thiet conda activate opencv di chuyen en thu muc chua project cd parentprojectpathtrafficsignrecognizemaster chay server python managepy runserver sau khi chay server thanh cong truy cap ia chi localhost8000 e thao tac ho tro cac bien bao theo bo bien bao chuan viet nam 101 uong cam 102 cam nguoc chieu 122 dung lai 127 toc toi cho phep tham khao source code train file modelh5 tai githubcomquangkhoiuit98trainmodeltrafficsignrecognize chuc nang chinh trang chu nhan dien bien bao tu anh moi truong trang tra cuu bien bao tra cuu bien bao tu du lieu cua ung dung\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "scripteddechackathon environmental awareness project project project simulates series scenarios series questions determine choices made point system built built project system combinations csshtmljavascriptjquerybootstrap put together became project challenges ran idea going run run difficulties came platform going working cloud9sublime etc learned learned\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "env1005report final report waste aruba written collectively 2017 environmental science class university aruba faculty hotel management tourism studies\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "ee509 applied environmental statistics course boston university earth environment 509\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmental environmental proof column politecnico di torino\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "newproject strojka environmentallab\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "yapec yet another parser environmental configuration ' enough npm modules getting config values enviroment already travis status installation sane use npm npm install yapec otherwise clone repo via git git clone httpsgithubcomsandfoxnodeyapecgit usage var yapec require ' yapec ' var config yapec ' prefix ' configspec processenv opts yapec takes spec form object nested heart ' content leaf every path must string dictates parse corresponding envvar string path converted uppercase dot seperators exchanged underscores optional prefix may supplied first arg act mask searching env object optional options object may supplied far option ' ignoremissing ' accepts bool false default true rather throwing exception env var missing instead returns null value yes realise probably clearest way describe brain failing point time examples examples also found examples folder inside project var yapec require ' yapec ' represents something could expect processenv return var env apppath ' optappy ' appname ' super server ' appserverenabled ' true ' appserverprocs ' 8 ' appservermagic ' 2e2 ' var configspec app path ' string ' name ' string ' server enabled ' bool ' procs ' int ' magic ' float ' var config yapecconfigspec env consolelogconfig outputs following app path ' optappy ' name ' super server ' server enabled true procs 8 magic 200 optionally prefix supplied first arguement acts mask looking enviroment variables example var yapec require ' yapec ' var env fallover ' true ' myappfallover ' false ' var spec fallover ' bool ' var config yapec ' myapp ' spec env consolelogconfig falloverfalse caveats due way modules works certain combinations env var strings forbidden example following would fail could resolved object sane way app could string object time appsuper app appdbnamemegadb appdbport8000 helpers yapec also comes helpers creating configs processenv style objects creating env var strings config object checkout examples folder pretty self explanatory todo document better yapecgetspecprefix processenv yapecgetenvstringsprefix config stability index based nodejs stability index stability 2 unstable testing code tested mocha run npm test usual tests ' bad could complete travis tests upgrades fixes ideas ideas bug fixes suggestions etc gladly excepted feel free raise pull requests issues license mit license copyright c 2013 james edward butler aka sandfox permission hereby granted free charge person obtaining copy software associated documentation files ' software ' deal software without restriction including without limitation rights use copy modify merge publish distribute sublicense andor sell copies software permit persons software furnished subject following conditions copyright notice permission notice shall included copies substantial portions software software provided ' ' without warranty kind express implied including limited warranties merchantability fitness particular purpose noninfringement event shall authors copyright holders liable claim damages liability whether action contract tort otherwise arising connection software use dealings software\n",
      "[0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      "barque v172 environmental dna metabarcoding analysis developed eric normandeau louis bernatchez ' laboratory please see licence information end file description barque edna metabarcoding analysis pipeline annotates reads instead operational taxonomic unit otus using highquality barcoding databases barque also produce otus annotated using database annotated otus used database find read counts per otu per sample effectively annotating reads otus previously found use cases approach implemented barque especially useful species management projects monitoring invasive species confirming presence specific species characterizing metacommunities varied environments improving species distribution knowledge cryptic taxa following loss species medium longterm monitoring since barque depends use highquality barcoding databases especially useful coi amplicons used combination barcode life database bold 12s amplicons mitofish database although also use database example silva database 18s gene custom database installation use barque need local copy repository different releases found recommended always use latest release even developpment version either download archive latest release link get latest commit recommended following git command git clone httpsgithubcomenormandeaubarque dependencies run barque also need following programs installed computer barque work gnu linux osx bash 4 python 35 use miniconda3 install python r 3 ubuntumint sudo aptget install rbasecore java ubuntumint sudo aptget install defaultjre gnu parallel flash read merger v1211 vsearch v2142 v2142 required barque work older versions vsearch preparation install dependencies download copy barque repository see installation edit 02infoprimerscsv provide information describing primers get prepare databases see formatting database section deposit fastagz file 03databases folder give name matches information 02infoprimerscsv file make copy 02infobarqueconfigsh modify parameters run launch barque example barque 02infobarqueconfigsh overview barque steps analyses following steps performed filter trim raw reads trimmomatic merge pairedend reads flash split merged reads amplicon python script look chimeras optional vsearch vsearchglobal merge unique reads python script find species associated unique read vsearch summarize results python script tables phylum genus species counts per sample including multiple hits number retained reads per sample analysis step figure frequent nonannotated sequences blast ncbi ntnr species counts nonannotated sequences sequence groups cases multiple hits running pipeline new project get new copy barque source listed installation section case need modify primer config files running test dataset want test barque jump straight test dataset section end file read readme better understand program ' outputs preparing samples copy pairedend sample files 04data folder need one pair files per sample sequences files must contain sequences primer used pcr depending format received sequences sequencing facility may proceed demultiplexing use barque important file names must follow format sampleidr1001fastqgz sampleidr2001fastqgz notes sample name sampleid must contain underscore followed underscore star string text contain space characters example use dashed separate parts sample names eg popasample001anythingr1001fastqgz formatting database need put database gzipcompressed fasta format fastagz 03databases folder augmented version mitofish 12s database already available barque preformatted bold database downloaded want use newer version bold database need download animal bins page put downloaded fasta files 03databasesboldbins need create folder run commands format bold database format bin individually 10 minutes note speciestoremovetxt file optional ls 1 03databasesboldbinsfasgz parallel 01scriptsutilformatbolddatabasepy preparedfastagz speciestoremovetxt concatenate resulting formatted bins one file 10 seconds gunzip c 03databasesboldbinspreparedfastagz 03databasesboldfasta databases get database format gzipcompressed fasta format fastagz name lines 3 informations separated underscore ex phylumgenusspecies ex familygenusspecies ex mammalrattusnorvegicus configuration file make copy file named 02infobarqueconfigsh modify parameters needed launching barque launch barque executable name configuration file argument like barque 02infomyconfigfilesh results pipeline finished running result files found 12results folder run recomended make copy folder name current date ex cp r 12results 12resultsprojectname20200727someadditionalinfo taxa count tables named primer names primergenustablecsv primerphylumtablecsv primerspeciestablecsv sequence dropout report figure sequencedropoutcsv listing many sequences present sample every analysis step depending library sequencing quality well biological diversity found sample site less sequences lost analysis steps figure sequencedropoutfigurepng shows many sequences retained sample step pipeline frequent nonannotated sequences mostfrequentnonannotatedsequencesfasta sequences frequent samples annotated pipeline fasta file used query ncbi ntnr database using online portal found see species may missed use blastn default parameters ncbi blastn search finished download results text file use following command need adjust input output file names generate report frequently found species nonannotated sequences fasta files sequences multiple hit groups 12results01multihits contains fasta file database sample sequences help understand sequences cannot unambiguously assigned one species example sometimes two different species identical reads database times sample sequences distance sequences two species database summarize species found nonannotated sequences 01scripts10reportspeciesfornonannotatedsequencespy 12resultsncbialignmenttxt 12resultsmostfrequentnonannotatedsequencesspeciesncbicsv 97 sort u k 23 cut c 2 perl pe ' ' missingspecies97percenttxt first result file contain one line per identified taxon number sequences taxon sorted decreasing order species interest found file good idea download representative sequences ncbi add database rerun analysis modify percentage value 97 missingspecies97percenttxt file list sequence identifiers ncbi download online database add database needed one way automatically make file first column one ncbi sequence identifier per line load page httpswwwncbinlmnihgovsitesbatchentrez need rename sequences follow database name format described formatting database section add current database log files parameters barque run three files written 99logfiles folder contain timestamp time run exact barque config file used exact primer file used full log run lather rinse repeat pipeline run normal find unexpected species found proportion reads identified either sequenced species absent database sequences exact distance two sequences database cases need remove unwanted species database download additional sequences nonannotated species ncbi add database improved simply run last part pipeline using new database skipdataprep1 config file avoid repeating initial data preparation steps barque may need repeat step satisfied completeness results note provide justifications publications decide remove species database test dataset test dataset available sister repository github composed 10 mitofish12s metabarcoding samples 10000 forward 10000 reverse sequences download repository move data barquetestdataset04data barque ' 04data folder git barque ' dependencies installed following commands download barque repository test data put appropriate folder git clone httpsgithubcomenormandeaubarque git clone httpsgithubcomenormandeaubarquetestdataset cp barquetestdataset04data barque04data run analysis move barque folder launch cd barque barque 02infobarqueconfigsh analysis test dataset takes 25 seconds linux thinkpad laptop 4 corei7 cpus 2012 70 seconds laptop using one cpu license cc sharealike barque eric normandeau licensed creative commons attributionsharealike 40 international licensebased work httpsgithubcomenormandeaubarque\n",
      "[0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0\n",
      " 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0\n",
      " 1 1 1 0 1 1 1 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 1 0 1 0]\n",
      "utils tools utilties libraries environmental meteorology use arpaesimc contact copyright information mautils copyright c 2020 arpaesimc urpsimarpaeit mautils licensed terms gnu general public license version 2 please see file license details contact informations arpaesimc formerly arpasim agenzia regionale prevenzione ambiente e energia dell ' emiliaromagna arpae servizio idrometeoclima simc address viale silvani 6 40122 bologna italy tel 39 051 6497511 fax 39 051 6497501 email urpsimarpaeit website httpsarpaeitsim\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "uavenvironmentalmonitoring pm25 wiki\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "readme contributing lessons repository interesting teaching specific topic please sing google spreadsheet adding lesson please use standard naming format nnlessonname nn consecutive lesson number lessons 19 use twodigit format ie 08 place data files used workshop data directory also add link lesson index page using header four level title bulleted list links item eg rmarkdown workshop jeff oliver knitr lesson iris analysis reproducible report knitr full lesson\n",
      "[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0]\n",
      "newproject strojka environmentallab\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "grow features monitor enviroment optionally control temperature wemo switches edit script control devices optionally report soil moisture perplant basis 8 email alerts enviroment exceeds alarm values requires ecowitt gw1000 wifi gateway linux apache mysql python3 optional wemo switches automation ip webcam ecowitt soil moisture sensors see full grow list amazon associate earn qualifying purchases installation prepare linux host working mysql python3 place files web root make sure py files execute cgi create database called grow create tables mysql create database grow mysql grow schemamysql cp myconfigsample myconfigpy edit cofiguration configure ecowitt gw1000 post data ecowittpy use ws view app go weather services customized enter server address ecowittpy path upload interval 60 copy growservice etcsystemdsystem edit make growcontrolpy run boot restart crash systemctl daemonreload place systemctl enable grow service grow start service grow status wemo automation install ouimeaux test command line wemo list make sure device names match growcontrolpy webcam setup edit getimagebash fetch image webcam python script add create cronjob run script every minute pathtogetimagebash run script hand test creates output expected fetch outjpg via webserver optionally speciy location xy coordinates 00 top left potssoil sensors config file\n",
      "[0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 1\n",
      " 1 0 1 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1]\n",
      "reactwebpack simplified environmental build processes react webpack requirements node v400 getting started npm install required packages npm start start development deployment npm run build\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmentalscience first website developed using htmlcssjavascript created following mozilla foundation getting started web tutorial\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0]\n",
      "reproducible research ecology evolution behaviour environmental studies aims reproduce figures tables statistical methods numerical modelling selected published papers examples learn collaborate create science make reproductions publically available learn make research reproducible paper selection likely spend lot time single paper selection important please make suggestions raw data must available reproduction appear feasible couple months eight meetings probably good focus papers mostly analyses empirical data rather lots numerical modelling please email authors paper start reproduction telling ' reproduction guidelines reproductions r markdown generously commented use google r style guide data manipulations allowed r open source software required permitted alteration original data files allowed outcome fully reproduced paper would one reproduced raw datasets ideally available online online report reproduction code outstanding issues research ideas parts paper decided reproduce weekly meetings information remote participation individuals might like contribute reproduction outside meeting time may able attend meetings anyone read contribute reproduction github look instructions know git github please look resources get started particularly motivated folk cannot attend weekly meetings may arrange electronic attendance weekly meetings eg via skype communication please use rreebes github repository issues wiki much communication possible email list gaining 1 ects students uzh gain 1 ects actively participating reproduction two papers attending least 20 meetings please make attendance form bring meeting course bio633 see vorlesungsverzeichnis entry\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmentalday\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmental extractors repository contains extractors process data originating gmp 343 co2 sensor thies clima environmental sensors maricopa lightningirrigationweather data environmental logger json 2 netcdf extractor extractor processes environmental logger stream data json files netcdf input evaluation triggered whenever file added dataset checks whether file environmentloggerjson file output dataset containing json file get corresponding nc netcdf file uamacuiuc energy farm dat parser extractors extractor extracts metadata meteorological dat files netcdf well creating entries clowder geostreams database input evaluation triggered whenever 24 dat files added dataset output netcdf metadata generated added dataset datapoints record dat files added geostream\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmentaldata pdf download project python based pdf extraction tool pdf download project web scraping project used download pdf html webpage website httppariveshnicin environment clearance dashboard download installation 1 clone repository git clone httpsgithubcomsaurabhkayasthenvironmentaldatagit download zip file &#9; extract files &#9; 2 download dependencies see 3 change directorycd environmetaldatasrc folder run python3 &#9; workingpdfpy terminal make sure using python version &#9; 36x greater installation guide python 36x httpswwwpythonorgdownloadsreleasepython360 installing dependencies method 1 using requirementstxt pip recommended pip install r requirementstxt method 2 using pip recommended beautifulsoup4 httpspypiorgprojectbeautifulsoup4 pip install beautifulsoup4 allows us search extract content html webpage requests httpspypiorgprojectrequests pip install requests requests module allows send http requests using python http request returns response object response data content encoding status etc pyinstaller httpspypiorgprojectpyinstaller pip install pyinstaller allows us build executable file build executable file run pyinstaller onefile workingpdfpy documentation httpspyinstallerreadthedocsioenstableusagehtml\n",
      "[0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0]\n",
      "mitemp2bt support xiaomi mi temp 2 ble environmental sensor based ha mitempbt component mitemp library ratcashdev installation install three ways download repository extract customcomponentsmitemp2bt add custom repository hacs home assistant community store hacs home assistant community store coming soon configurartion config ' samme mitempbt component execpt platform field example sensor platform mitemp2bt mac ' xxxxxxxxxxxx ' name example forceupdate true timeout 60 median 1 monitoredconditions temperature humidity battery\n",
      "[0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "greening postindustrial city applying keyword extractor methods monitor fastchanging environmental narrative worcester massachusetts population 200000 second largest city boston massachusetts usa important american industrial revolution factories dominated landscape mid20th century city slid physically mentally postindustrial decline first glance worcester might present alltoofamiliar global story gentrification loss city identity community even small survey historic record local public discourse confirm view complicated local story surface answer questions literary geographer sarah luria teams computer scientist ricardo campos developer keyword extractor yake discover create helpful survey image stories told neighborhood time believe interdisciplinary work play crucial role showing artificial intelligence ai track fastdeveloping story urban revitalization environmental cleanup survey curated small corpus 26 englishlanguage texts described canal districtgreen island time majority texts 20182019 examples 1862 1917 1980s 1990s provide historic range corpus includes descriptions canal district industrial revolution altered dramatically building canal railroad peak industrialization identity irish working class neighborhood postindustrial decline stages revitalization majority texts come local major newspaper worcester telegram gazette corpus includes articles new york times boston globe national public radio also included worcesterborn poet mary fells 1984 poem prophecy historian roy rosenzweigs acclaimed history worcesters working class eight hours 1985 description one given dataset details give details text sorted date filename 1 1862lincoln history worcester archiveorg landscape description source william lincoln history worcester lincoln william history worcester massachusetts earliest settlement september 1836 various notices relating history worcester county worcester md phillips co 1862 url httpsarchiveorgdetailshistoryofworcest1836lincpagen6 publication date 1862 description worcesters landscape industrial revolution tokens 256 filename 2 1879abijah perkins marvin history worcester archiveorg railroad descriptionn source abijah perikins marvin history worcester county massachusetts embracing comprehensive history country first settlement present time boston jewett co 1879 pp 8283 url httpsarchiveorgdetailshistoryofworcest03marvpage82 publication date 1879 description description beginning blackstone canal worcester railroad tokens 638 filename 3 1917washburn industrial history worcester archiveorg canal source charles g washburn industrial worcester worcester davis press 1917 p 23 url httpsarchiveorgdetailsindustrialworces00washpagen6 publication date 1917 description description creation blackstone canal importance tokens 199 filename 4 1917washburn industrial history worcester archiveorg entrepreneurial spirit city source charles g washburn industrial worcester worcester davis press 1917 p 31 url httpsarchiveorgdetailsindustrialworces00washpage60 publication date 1917 description introduction steampower worcester industries tokens 72 filename 5 1917washburn industrial history importance steam power source charles g washburn industrial worcester worcester davis press 1917 p 300 url httpsarchiveorgdetailsindustrialworces00washpage60 publication date 1917 description entrepreneurial spirit city tokens 150 filename 6 1983259worcester shedding smokestack image new york times source worcester shedding smokestack image new york times sept 25 1983 publication date 1983259 description tokens 911 filename 7 1984mary fell prophecy poem source mary fell prophecy persistence memory 1984 url httpcapaconncolledufellpersistencehtml publication date 1984 description poem collection worcester tokens 328 filename 8 1985roy rosenzweig eight hours history recreation industrial labor source roy rosenzweig eight hours cambridge uk cambridge 1985 publication date 1985 description history recreation worcesters industrial labor force tokens 287 filename 9 19891012a new look old area new york times lafayette placegreen island source worcester mass new focus old area new york times publication date 19891012 description building new senior affordable housing green island tokens 450 filename 10 19971118bureau urges liability relief brownfields wtg source bronislaus b kush bureau urges liability relief brownfields worcester telegram gazette publication date 19971118 description tokens 585 filename 11 1998167green island businesses say city help killing wtg source bronislaus b kush green island businesses say city help killing worcester telegram gazette publication date 1998167 description tokens 597 filename 12 1999121vacant industrial sites use neighborhood wtg source winston w wiley vacant industrial sites use neighborhood worcester telegram gazette publication date 19991201 description tokens 436 filename 13 2000296green island revitalization plan dropped wtg source lisa eckelbecker green island revitalization plan dropped worcester telegram gazette publication date 2000296 description tokens 446 filename 14 2007259canal district shapes old buildings new life green street wtg source shaun sutner canal district shapes old buildings new life green street worcester telegram gazette publication date 20072509 description tokens 645 filename 15 2011238life green island hope city times local alternative newspaper source maureen schwab life green island hope city times local alternative newspaper publication date 20112308 description tokens 1149 filename 16 2018817woosox ball park long history boston globe source tim logan new home woosox long history boston globe publication date 2018817 description tokens 632 filename 17 20181011time talk gentrification worcester worcester mag source bill shaner time talk gentrification worcester worcester magazine publication date 20181011 description tokens 4165 filename 18 20181023worcester new town national public radio source aaron schachter worcester newit town national public radio wgbh publication date 20181023 description tokens 1184 filename 19 2018worcester city reclaimed vitality magazine source bernard whitmore mayor manager city reclaimed vitality magazine publication date 201811 description tokens 2077 filename 20 2019227worcester organizers hear nashville buffalo tips woosox cba push worcester mag source bill shaner worcester organizers hear nashville buffalo tips woosox cba push worcester magazine publication date 20190227 description tokens 540 filename 212019410a totally cool place live masslive source aviva luttrell totally cool place live masslivecom publication date 20190410 description tokens 497 filename 22 201961new shine old building former walker shoe factory converted studios wtg source scott oconnell new shine old building former walker shoe factory converted studios worcester telegram gazette publication date 20190601 description tokens 468 filename 23 2019620construction woosox regulation killing canal district dreams worcester business journal source renee diaz construction woosox regulation killing canal district dreams worcester business journal publication date 20190620 description tokens 739 filename 24 2019624worcester gets brownfield funds wtg source worcester gets brownfield funds worcester telegram gazette publication date 20190624 description tokens 517 filename 25 2019624worcester pledges 3m green island wtg source kim ring worcester pledges 3m green island worcester telegram gazette publication date 20190624 description tokens 490 filename 26 201976an away game businesses property owners near ballpark site make way development wtg source away game businesses property owners near ballpark site make way development worcester telegram gazette publication date 20190706 description tokens 1322\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1]\n",
      "gemet contents gemet project name prerequisites system packages debian based systems rhel based systems product directory install dependencies build production build staging configuration data import commands documentation docs contents development hints requirements configure deploy running unit tests sentry settings contacts resources hardware software copyright license project name project name gemet general multilingual environmental thesaurus httpwwweioneteuropaeugemet prerequisites system packages packages installed superuser root debian based systems install setting environment aptget install pythonsetuptools pythondev libmysqlclientdev libldap2dev pythonvirtualenv mysqlserver git rhel based systems install python27 puias httpsgistgithubcomnico49616638 run commands curl httpsrawgithubcompypapipmastercontribgetpippy python27 pip27 install virtualenv yum install mysqlserver mysql git mysqldevel product directory create product directory mkdir p varlocalgemet mkdir varlocalgemetlogs create new user adduser edw change product directory ' owner chown edwedw varlocalgemet r install dependencies use virtualenv isolated environments following commands run unprivileged user product directory clone repository git clone httpsgithubcomeeagemet origin gemet cd gemet 21 create activate virtual environment virtualenv nositepackages sandbox echo ' ' sandboxgitignore source sandboxbinactivate 22 make sure setuptools 08 installed pip install u setuptools install dependencies pip install r requirementsdeptxt create local configuration file cd gemet cp localsettingspyexample localsettingspy follow instructions localsettingspy adapt needs set mysql database replace user password mysql credentials dbname name database mysql uuser ppassword e ' create database dbname character set utf8 collate utf8generalci ' database charset must utf8 update local configuration file database credentials database name default section databases dict create initial database structure managepy migrate load fixtures data database managepy loaddata gemetthesaurusfixturesdatajson generate eionet static templates managepy fetchtemplates import data see data import build production setup production environment using unprivileged user cd varlocalgemet source sandboxbinactivate change localsettingspy file setting debug mode debug false allowedhosts ' localhost ' add allowed hosts list needed configure supervisord set wsgi server port cp gemetsupervisordconfexample supervisordconf supervisorctl reload 1devnull binsupervisord build staging setup staging environment using unprivileged user cd varlocalgemet source sandboxbinactivate change localsettingspy file setting debug mode debug false allowedhosts ' localhost ' add allowed hosts list needed configure supervisord set wsgi server port different one production example 8010 cp gemetsupervisordconfexample supervisordconf supervisorctl reload 1devnull binsupervisord configuration details configurable settings found settingspy data import 1 considering dump old database gemetsql import separate database mysql uuser ppassword e ' create database dbname character set utf8 collate utf8generalci ' mysql uuser ppassword dbname gemetsql 2 update import section databases dict local configuration file name database used import gemetold previous example run management command data import managepy import fix romanian characters managepy fixromanian insert data enables search work properly managepy insertdata create reversed relations concepts managepy fixrelations import new terms spreadsheet managepy importspreadsheet spreadsheetname commands 1 romanian terms definitions etc written wrong diacritical marks cedillas instead commas following custom management command fixes characters prints number objects changed managepy fixromanian check consistency excel file xlsx extension containing new terms custom command assures old terms used file defined database new terms used broader narrow relations etc terms also defined file error containing cell term printed respect rules run command providing valid excel file managepy checkspreadsheet filenamexlsx documentation documentation created using sphinx source directories three sections documentation found docs directory order get html output run following command inside one documentation directories api newapi overview make html static html files served via web server apache nginx etc docs contents api old version api user guide kept reference newapi current documentation gemet api duplicated file published web services page overview quick overview technical solution development hints requirements packages installed superuserroot aptget install libxml2dev libxslt1dev use requirementsdevtxt instead requirementsdeptxt pip install r requirementsdevtxt configure deploy copy fabfileenviniexample fabfileenvini configure staging production settings run fab staging deploy fab production deploy running unit tests 0 running tests make sure configured test database parameters cd gemet cp testsettingspyexample testsettingspy parameters values match ones used ' default ' database entry localsettingspy gemet web application managepy test api python apitestsmainpy two optional parameters exist public runs tests production website get calls api methods get requests running tests coverage measurement add localsettingspy testrunner noseargs localsettingsexample run managepy test sentry settings sentry used track errors realtime create account project sentry install proper version raven used sentry pip install r requirementsdeptxt configure local settings project ' dsn contacts project owner sren roug sorenroug eaaeuropaeu people involved project iulia chiriac iuliachiriac eaudewebro andrei melis andreimelis eaudewebro diana boiangiu dianaboiangiu eaudewebro cornel nitu cornelnitu eaudewebro alex eftimie alexeftimie eaudewebro mihai tabara mihaitabara eaudewebro mihai zamfir mihaizamfir eaudewebro resources hardware minimum requirements 2048mb ram 2 cpu 18ghz faster 4gb hard disk space recommended 4096mb ram 4 cpu 24ghz faster 8gb hard disk space software recent linux version apache2 mysql server python 27 copyright license project free software redistribute andor modify terms eupl v11 details licensetxt\n",
      "[0 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1\n",
      " 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0\n",
      " 0 0 0 1 1 0 1 0 0 1 1 1 1 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 1 0 1 0 0 1\n",
      " 0 1 1 0 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 0 1 1 0]\n",
      "openstudioprojectspolimieetbs repository includes files presentations group projects simulation commercial buildings openstudio energyplus context energy environmental technologies building systems politecnico di milano order insert personal contact information members group regular projects fill following form regular project group information form instead would like ask bonus project fill following form bonus project group information form important note one members group fill form insert personal contact information members\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "telecoupling telecoupling new avenue research understand todays hyperconnected world achieve sustainable future telecoupling enables natural social scientists across various disciplines understand generate information managing humans nature sustainably coexist telecoupling framework gains distinction enabling researchers practitioners dive deeply systemic complexities even systems far understand forces affecting sustainability across local global scales essential build comprehensive set spatially explicit tools describing quantifying multiple reciprocal socioeconomic environmental interactions distances telecoupling toolbox telecoupling toolbox designed michigan state universitys center systems integration sustainability first suite geospatial software tools apps developed map identify five major interrelated components telecoupling framework systems flows agents causes effects modular design toolbox allows integration existing tools software assess synergies tradeoffs associated policies localtoglobal interventions use telecoupling toolbox innovative free opensource see license details toolbox provide researchers practitioners useful platform address globally important issues land use land cover change species invasion migration flows ecosystem services trade goods products ' toolbox arcgis toolbox arcgis toolbox large collection mapping analysis tools use within esri ' arcgis desktop version 1031 later systematically study telecoupling test current version arcgis toolbox using data downloading sample data look inside arcgis toolbox project folder code images documentation detailed instructions installation use geoapp geoapp offers dynamic interactive online geoenabled platform along large collection mapping analysis tools systematically study telecoupling check test brand new geoapp beta using data downloading sample data help introductory tutorial need time familiarize app widgets tools look inside geoapp project folder source code images linked geoapp sample data arcgis toolbox data download unzip sample data folder use arcgis toolbox geoapp data repository contains tables spatial data necessary run set telecoupling mapping analysis tools developed information dataset provided please feel free contact us geoapp data download unzip sample data folder use arcgis toolbox geoapp data repository contains tables spatial data necessary run set telecoupling mapping analysis tools developed information dataset provided please feel free contact us credits contacts 2018 michigan state university francesco tonini ftoninimsuedu paul mccord mccordpamsuedu jianguo ' jack ' liu liujimsuedu license telecoupling toolbox software property michigan state university msu made available solely educational noncommercial use see license details toolbox depends r statistical computing software 2018 r foundation statistical computing r free software comes absolutely warranty see copyrights file details toolbox depends esri software 2018 esri see software license agreement details toolbox depends invest natural capital project software 2018 natcap project see software license agreement details\n",
      "[0 0 1 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0\n",
      " 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      "ears environmental audio recognition system ears proof concept implementation convolutional neural network live environmental audio processing recognition lowpower soc devices time developed tested raspberry pi 3 model b ears features background thread audio capture classification bokeh server based dashboard providing live visualization audio streaming device browser caveats ears quite taxing cpu proper cooling solution heatsink advisable nevertheless using bokeh app much work fine even without one live audio stream get choppy outofsync especially using muteunmute button actual production deployments would profit servernode architecture soc devices pushing predictions status updates audio feeds central server handling end user interaction material browsing visualization may implemented future versions promises quick look installation ears developed tested raspberry pi 3 model b device recreate environment used developing demo step 1 prepare raspberry pi device get spare raspberry pi 3 model b blank sd card install raspbian jessie lite distribution tested version april 2017 download raspbian jessie lite image raspberrypiorg use etcher flash sd card see raspberry pi docs details boot device new card attach input display devices configuration login using default credentials user pi password raspberry setup wifi access see wifi config raspberry pi use sudo raspiconfig enable ssh recreate ssh host keys sudo rm etcsshsshhost sudo dpkgreconfigure opensshserver step 2 install python 36 using berry conda install conda armv7l optconda wget httprepocontinuumiominicondaminiconda3latestlinuxarmv7lsh chmod x miniconda3latestlinuxarmv7lsh sudo miniconda3latestlinuxarmv7lsh add export pathoptcondabinpath end homepibashrc reload source homepibashrc install python required packages conda config add channels rpi conda create n ears python36 source activate ears conda install cython numpy pandas scikitlearn cffi h5py make sure portaudio headers available installing pyaudio complain later sudo aptget install portaudio19dev step 3 download ears install requirements download ears source code unpack homepiears install required packages issuing pip install r homepiearsrequirementstxt plug zoom h1 microphone usb port audio device ' one used initial testing switch audio interface mode 441 khz16 bit verify ' listed python sounddevice update allowwebsocketorigin option inside homepiearsrunsh file ip address raspberry pi device finally run app chmod x homepiearsrunsh cd homepiears runsh point web browser httpraspberrypiip5006 training new models time ears comes preloaded rudimentary model trained esc50 dataset convnet consisting 3 layers 3x3 square filters ' recognition capabilities limited actual live scenarios want train model different dataset download source code workstationserver gpu card put audio files wav earsdatasetaudio replace earsdatasetdatasetcsv file new csv filenamecategory run python trainpy result following files generated server file description modelh5 weights learned model modeljson serialized architecture model keras 200 modellabelsjson dataset labels upload new model files raspberry pi device restart app want train completely different model look trainpy case probably know either way photos development field license mit karol j piczak\n",
      "[1 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0\n",
      " 0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0 1 1 1 0 0 1 1 0 0 0 0 0 1 1 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 0]\n",
      "project idea info page actual environmental problems face\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmental council httpsvinaymeldrumgithubioenvironmentalcouncil\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "waved web app visualizing environmental data httpkshskgithubiowaved installation basics client needs use waved web browser server side actions require running web server requirements server include serving static content html javascript css images well dynamic pages php setup accomplished various setups operating systems however document written tested fresh installation ubuntu 1204 lts precise pangolin necessary packages order get waved server running using apache php module including sqlite packages provide command line tools required standard deployment waved packages installed follows aptget update aptget install apache2 php5common php5sqlite libapache2modphp5 aptget install make sqlite3 acl content content needs served web server found waved git repository ' clone content documentroot apache server varwww default cd varwww git clone httpsgithubcomkshskwavedgit initial setup content brought web server initialization actions need performed includes setting directories permissions persisting project state data files actions handled makefile everything set apache server restarted ensure everything served correctly cd waved make service apache2 restart verifying server point waved server running clients able point web browsers waved folder web server however easy things web server verify functionality index page verify get index page waved get 404 error short html page displaying generic message rather 500 lines html curl sxpost localhostwaved project listing verify get listing currently existing projects json response success field true projects array empty curl sxpost localhostwavedphpgetexistingprojectdetailsphp create project verify create project command display json response success true projects array contain newly created project curl sxpost localhostwavedphpcreateprojectphp projecttestproject curl sxpost localhostwavedphpgetexistingprojectdetailsphp delete project verify delete project command display json response success true projects array empty curl sxpost localhostwavedphpdeleteprojectphp projecttestproject curl sxpost localhostwavedphpgetexistingprojectdetailsphp developer instructions download eclipse ide java developers import project file import exiting projects workspace select waved directory finish install jshint plugin help install new software work httpgithubeclipsesourcecomjshinteclipseupdates check jshint click finished\n",
      "[0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 0 0 1\n",
      " 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1\n",
      " 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0]\n",
      "cz manager cz manager django admin app observation data model 2 odm2 odm2 created national science foundation grant ear1224638 support development application comes nsf grant ear1331841 luquillo czo odm2 found httpsgithubcomodm2 django models exist odm2 tables forms odm2core number additional odm2 tables graphing measurement result values via highcharts implemented data logger files imported long data logger file columns results properly setup odm2 tools used conjunction cz manager extensive testing done using cz manager odm2pythonapi wofpy developed using postgresql version odm2 data model additional modifications may needed make work mssql another database example postgresql database named odm2adminexamplepostgresqldb provided custom postgresql format backup restored empty database extrasqlsql file contains extra views used efficiently exporting data emails primary installation see docker folder dockerhub installation instructions see httpodm2githubioczmanager local installation instructions\n",
      "[0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0]\n",
      "envizo envizo app increase visibility environmental issues community nyc liveversion motivation care environment wanted create app encourage users change habits increasing visibility believe users see impact empowered act engage communities features interactive visualization environmental issue personal impact prediction component join community subscribe greennyc suggested goals upload photo testament improved habits ex reusable grocery bag reach target goal personal community activity feed social media sharing progress community progress bar personal contributions technologies frontend redux react css html d3 reactmaterialize materializecss ajax backend express nodejs postgres sql aws pgpromise passport bcrypt\n",
      "[0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "grow features monitor enviroment optionally control temperature wemo switches edit script control devices optionally report soil moisture perplant basis 8 email alerts enviroment exceeds alarm values requires ecowitt gw1000 wifi gateway linux apache mysql python3 optional wemo switches automation ip webcam ecowitt soil moisture sensors see full grow list amazon associate earn qualifying purchases installation prepare linux host working mysql python3 place files web root make sure py files execute cgi create database called grow create tables mysql create database grow mysql grow schemamysql cp myconfigsample myconfigpy edit cofiguration configure ecowitt gw1000 post data ecowittpy use ws view app go weather services customized enter server address ecowittpy path upload interval 60 copy growservice etcsystemdsystem edit make growcontrolpy run boot restart crash systemctl daemonreload place systemctl enable grow service grow start service grow status wemo automation install ouimeaux test command line wemo list make sure device names match growcontrolpy webcam setup edit getimagebash fetch image webcam python script add create cronjob run script every minute pathtogetimagebash run script hand test creates output expected fetch outjpg via webserver optionally speciy location xy coordinates 00 top left potssoil sensors config file\n",
      "[0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 1\n",
      " 1 0 1 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1]\n",
      "checkenv check environment modern bestpractice store application ' configuration environmental variables allows keep config data outside repository store standard systemagnostic location modern builddeploydevelopment tools make easier manage variables perhost ' still often undocumented lead bugs missing module lets define environmental variables application relies envjson file provides method check variables application launch print help screen missing installation npm checkenv usage first define json file called envjson project root see add following line top project ' entry file require ' checkenv ' check default checkenv print pretty error message call processexit1 required variables missing also print error message optional variables missing exit process would like handle errors check takes optional pretty argument causes throw errors instead printing error message result error thrown missing required variables try require ' checkenv ' checkfalse catch e something error configuration json file define environmental variables keys either boolean required value configuration object options json nodeenv description defines current environment validators name options development testing staging production port description port api server run default 3000 nodepath true debug required false description set enables additional debug messages options required defines whether variable required default variables required must explicitly set optional setting false description describes variable used useful new developers setting project printed error output present default defines default value use variable unset implicitly sets required false validators array validators variable must pass see validatorjs details validators format validator validators validator name optionless validators passed strings validators w options must passed objects name validator name options options option format varies see possible validators see validatorjs details contains options string value contain equals options string exact value options date options date alpha alphanumeric ascii base64 boolean date decimal fqdn float options may object min max properties hexcolor hexadecimal ip4 ip options 4 ip6 ip options 6 ip options may number 4 6 iso8601 enum alias options must array possible values int options may object min max properties json length options must object min max lowercase macaddress numeric url uuid3 uuid options 3 uuid4 uuid options 4 uuid5 uuid options 5 uuid options may number 3 4 5 uppercase regex alias matches regexp alias matches matches options must either string representing regex array format regex modifiers see also like module may also want check dotenv load missing environmental variables env approotpath automatically determine root path current application enforcenodepath enforce usage nodepath environmental variable change log 122 better handling syntax errors envjson thanks yalcindo 120 validation via validatorjs 111 prints default value help 110 added support default values added support change filename via setfilename 106 bugfix please use versions 106 105 passes tests node 010 51 100 initial release\n",
      "[0 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 1 0 1 0 0\n",
      " 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1\n",
      " 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 0 0]\n",
      "buildingsimulationprojectpolimites repository includes files presentations group projects simulation buildings openstudio energyplus context echnical environmental systems politecnico di milano order insert personal contact information members group fill following form project group information form important note one members group fill form insert personal contact information members\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "pylcaio object class structure manipulate facilitate hybridization lifecycle assessment lca environmentally extended inputoutput eeio matrices read combine organize manipulate concatenate lca foreground background matrices combine lca system eeio matrices automate hybridization correction doublecounting still beta release documentation demos soon come\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "epaenvironmentaldatasetgateway epa environmental dataset gateway edg opensource metadata catalog built esri ' geoportal server repository contains code core httpsedgepagovmetadata website well several ancillary tomcat webapps epa disclaimer united states environmental protection agency epa github project code provided basis user assumes responsibility use epa relinquished control information longer responsibility protect integrity confidentiality availability information reference specific commercial products processes services service mark trademark manufacturer otherwise constitute imply endorsement recomendation favoring epa epa seal logo shall used manner imply endorsement commercial product activity epa united states government\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "layout title permalink page welcome apes indexhtml collection advice problems environmental statistics apes department biometry environmental system analysis university freiburg professorship theoretical ecology university regensburg website gives basic intros links standard topics statistics statistical programming language r also provide hubs special topics checklists particular situations student looking help following pages may particularly interesting getting started r get error r checklist planning experiment checklist analyzing data\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "installation requires download mysql connector order connect mysql database system usage specializes structured data storing detailed information environmental inspection documents utilizes chartview statistics\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "fish546 bioinformatics environmental sciences winter 2015 repository serves primary framework course specifically please see wiki syllabus content etc issues used primary means assessment communication course description course teach core computing skills well project specific approaches student developing completing research project targeting journal article submission end quarter emphasis developing habits increase automation turn facilitate reproducibility course primary course platform github student creating repository code repository example analyses provided files directory structure contributingmd simply guidelines contributing repository see creating new issue gitignore list files local repo github file size limits notebooks directory ipython notebooks live notebooks rendered nbviewer httpnbvieweripythonorggithubsr320fish5462015treemasternotebooks data raw data including fasta files datafa analyses output analyses performed ipython notebooks scripts scripts call notebooks\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 1 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "visuite04 repository version 04 visuite building environmental performance addon blender article describing visuite published ' open geospatial data software standards ' article openaccess link full text found httprdcubevrj5 article reference used cite visuite research work bibtex formatted reference articlesouthall2017 abstract visuite free opensource addon 3d content creation application blender developed primarily tool contextual performative analysis buildings functionality grown simple static lighting analysis fully parametric lighting shadowing building energy analyses adopts flexible mesh geometry based approach specification calculation points made suitable certain types 3d geospatial analyses data visualisation author southall ryan biljecki filip day 14 doi 101186s4096501700361 issn 23637501 journal open geospatial data software standards month sep number 1 pages 23 title visuite set environmental analysis tools geospatial data applications url httpsdoiorg101186s4096501700361 volume 2 year 2017\n",
      "[0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
      "pylcaio object class hybridize lifecycle assessment lca environmentally extended inputoutput eeio databases create lcaio hybrid database eg combining ecoinvent exiobase data automates hybridization correction doublecounting two available methods stam binary default parameters allow hybridization ecoinvent35 exiobase accept capitalsendogenized version exiobase includes extrapolated additional environmental extensions exiobase useeio includes matching ecoinvent exiobase environmental flows impact world includes regionalized characterization matrices use impact world exported brightway2 interested default hybrid database want cannot run code find httpszenodoorgrecord3890379 software still development system requirements 8gm ram likely run memorryerror making impossible generate database dependencies python 3 pandas numpy scipy pymrio ecospold2matrix pickle brightway2 bw2agg related publications majeaubettez g agez wood r sodersten c margni strmman h samson r 2017 streamlined hybridization software merging ecoinvent exiobase biennial conference international society industrial ecology agez majeaubettez g margni strmman h samson r 2019 lifting veil correction double counting incidents hybrid life cycle assessment journal industrial ecology 117 httpsdoiorghttpsdoiorg101111jiec12945 agez wood r margni strmman h samson r majeaubettez g 2019 hybridization complete lca mrio databases comprehensive product system coverage journal industrial ecology 117 httpsdoiorg101111jiec12979\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      "environmental monitor overview simple mongoose os powered environment monitor consisting ssd1306 oled bme280 sensor connected controller via shared i2c bus install app install start mos tool switch project page find import app build flash alternatively build flash example command line build git clone httpsgithubcommongooseosappsexamplearduinoadafruitbme280jsgit cd examplearduinoadafruitbme280js mos build platform esp32 mos flash wait boot set i2c pins mos console mos configset i2csclgpio22 i2csdagpio23 verify i2c mos configget i2c using example example work properly must ensure i2c spi configuration correct check device ' current configuration using mos configget look i2c spi section mos configget i2c using port devttyusb1 debug false enable true freq 100000 sclgpio 22 sdagpio 23 device boots output look like following watch carefully mgosi2ccreate equivilent spi line boot messages ensure pins initialized correctly via web ui mos console dec 25 132524986 mgosi2ccreate i2c gpio init ok sda 23 scl 22 dec 25 132524992 mgrpcchanneluart 0x3ffbc478 uart0 dec 25 132525001 mgosinit init done ram 317608 total 275252 free 275252 min free dec 25 132525098 starting dec 25 132525424 mongoosepoll new heap free lwm 261716 dec 25 132527426 temperature 22960000 c dec 25 132527433 humidity 43640000 rh dec 25 132527442 pressure 1025687700 hpa dec 25 132529426 temperature 22970000 c dec 25 132529433 humidity 43640000 rh dec 25 132529441 pressure 1025714100 hpa dec 25 132531425 temperature 22960000 c dec 25 132531433 humidity 43650000 rh dec 25 132531441 pressure 1025692000 hpa please note esp8266 esp32 pins choose use i2c ' important ensure configuration pins ' selected i2c sensor address important adafruit bme280 uses address 0x77 many generic bme280 ' utilize 0x76 trouble try switching addresses consult datasheet well known bme280 ' tend selfwarm report higher expected temperatures tolerance bme280 tensor 1c however added heating ' uncommon see temperatures much 18c higher ambient add adjustments code testing environment use sensor using reliable thermometer please report excessive temps mongoose bug\n",
      "[0 1 0 0 0 1 0 0 0 1 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0]\n",
      "environmentaldatapredict environmental data predict\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmental informatics ucsb fork clone repository introduce adding file per github usernamejson data directory ' example github username bbest databbestjson &#9; program lecturer &#9; interests marine biology species distribution modeling spatial decisionmaking &#9; project route ships around marine mammal hot spots using format replace program interests project idea create rmarkdown document also username students folder details project idea commit push changes submit pull request original repository acknowledgements content site draws extensively repositories httpsgithubcomadvancedjsstudents httpsgithubcomdatacarpentryrecology testing cd githubesm2963w2016 bundle exec jekyll serve baseurl ' ' usrlocalbinjekyll serve baseurl ' '\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "table contents generated doctoc obtain library overview changing defaults changing name default properties file changing extension properties file changing location configuration sourced changing location environmental overrides sourced multi environmental variable configuration operational overrides thread safety mapstringstring property merging strictness property values placeholder replacement obtaining resolved unresolved properties one time using environment resolve placeholders trimming property values whitespace thread safety composite builder using spring obtain library dependency groupidorggreencheekgroupid artifactidenvironmentpropertiesmergercoreartifactid version100version dependency maven repositories located httpsrawgithubcomtootedomtootedommvnrepomasterreleases httpsrawgithubcomtootedomtootedommvnrepomastersnapshots overview simple library allows sourcing standard java properties file httpdocsoraclecomjavase6docsapijavautilpropertieshtml use application configuration properties files sourced either classpath classpath filesystem filesystem overridden based either environment variables system properties example imagine architecture defined environment variable env denotes environment current server resides variable different value different environments example ci integration test loadtest staging production library default allows following structure files within project srcmainresources config defaultproperties environments ciproperties integrationproperties testproperties loadtestproperties stagingproperties productionproperties run time given value production env variable lib return properties object combination merge config defaultproperties environments productionproperties gives ability different configuration deployed along application varying configuration based environmental settings achieved following propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder p mergerbuilderbuildproperties idea library distribute along application configuration properties defaultproperties contains set properties contain defaults application configuration lets say something like config defaultproperties contains databaseurljdbcmysqllocalhostadmin databaseusernameuser databasepasswordpass provide overrides defaults within properties files match value env variable exists platform ' architecture example production environment provide config environments productionproperties contains configuration specific live environment databaseurljdbcmysqlbernardappdbwproductionadmin databaseusernameuser databasepasswordpass way varying configuration application distributed along application changing defaults default library reads configuration classpath looking configdefaultproperties files override based value env variable configenvironmentsenvproperties defaults changable changing name default properties file following change name default properties file sourced defaultproperties globalproperties propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder setnameofdefaultpropertiesfileglobal p mergerbuilderbuildproperties changing extension properties file following change extension properties file properties props propertiesmergerbuilder mergerbuilder4 new environmentspecificpropertiesmergerbuilder setnameofdefaultpropertiesfileglobal setextensionforpropertiesfileprops p mergerbuilder4buildproperties separator character changed something else ie via following setextensionseparatorcharforpropertiesfile ' ' changing location configuration sourced default configuration files sourced classpath location config changed either read different location classpath change read file system classpath changes source appconfig classpath propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder setlocationforloadingconfigurationpropertiesclasspathappconfig properties p mergerbuilderbuildproperties filesystem changes source configuration dataopsoverridesmyappconfig propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder setlocationforloadingconfigurationpropertiesfiledataapplicationconfig properties p mergerbuilderbuildproperties changing read cdataopsoverridesmyappconfig windows propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder setlocationforloadingconfigurationpropertiesfilecdataopsoverridesmyappconfig properties p mergerbuilderbuildproperties often helpful operations teams fellow developers deploy configuration properties embedded within jar files distributed filesystem location classpath ie webinfclassess web application helps troubleshooting issues verification configuration quickly extract configuration jar say within webinflib however ' strict rule preference often distributing library use multiple applications avoidable configuration needs distributed jar see operational overrides later changing location environmental overrides sourced default environmental overrides sourced environment directory within location specified configuration sourced example follow defines application configuration read classpath dataconfig environmental configuration sourced dataconfigenvs propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder setlocationforloadingconfigurationpropertiesclasspathdataconfig setrelativelocationoffilesoverridingdefaultpropertiesenvs properties p mergerbuilderbuildproperties multi environmental variable configuration library goes one step futher allows configure environmental setting differ one environmental system property sequence environmental variables example imagine environmental variable env system property osarch configure library merge configuration order fashion sources configdefaultproperties configenvironmentsproductionproperties configenvironmentsproductionx8664properties propertiesmergerbuilder resolverenvandosbuilder new environmentspecificpropertiesmergerbuilder setvariablesusedforswitchingconfigurationnew string envenvosarch running macbook pro osx snow leopardlion env environment variable set production would resulting following files sourced merged config defaultproperties environments productionproperties productionx8664properties operational overrides library also concept operational overrides gives operations department location file system overwrite specific property value used application without modify configuration distribute application useful properties passwords database connection strings etc operations department might know default library look overrides within directory filesystem dataopsoverridesconfig value appname need specify windows machine default cdataopsoverridesconfig example following create propertiesmerger reads operational overrides directory dataopsoverridesbernardconfig windows c propertiesmergerbuilder resolverenvandosbuilder new environmentspecificpropertiesmergerbuilder setvariablesusedforswitchingconfigurationnew string envenvosarch setapplicationnamebernard properties p mergerbuilderbuildproperties given value production env variable configuration sourced order top bottom classpath config defaultproperties environments productionproperties filesystem data opsoverrides bernard config defaultproperties environments productionproperties otherwords files source order classpathconfigdefaultproperties classpathconfigenvironmentsenvproperties filesystemdataopsoverridesbernardconfigdefaultproperties filesystemdataopsoverridesbernardconfigenvironmentsenvproperties location operational overrides loaded changed via setting property mergerbuilder example following defines operational overrides location dataopsapplicationxconfig propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder setvariablesusedforswitchingconfigurationnew string envenvosarch setlocationforloadingoperationaloverridesfiledataopsapplicationxconfig properties p mergerbuilderbuildproperties essence result following sourced classpathconfigdefaultproperties classpathconfigenvironmentsenvproperties filesystemdataopsapplicationxconfigdefaultproperties filesystemdataopsapplicationxconfigenvironmentsenvproperties please note possible set operational overrides point classpath location changing file prefix classpath resource however idea behind operational overrides give ability operational teams adjust application properties quickly easily therefore file location probably preferrable option thread safety propertiesmergerbuilder thread safe intended used single thread order create propertiesmerger instance propertiesmerger instance thread safe use multiple threads builder responsible creating propertiesmerger propertiesmerger created safe use multiple threads properties object returned following java call thread safe propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder properties p mergerbuilderbuildproperties equivalent propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder propertiesmerger merger mergerbuilderbuild properties p mergergetmergedproperties obtaining map instead properties object rather properties object obtain mapstringstring properties propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder propertiesmerger merger mergerbuilderbuild mapstringstring map mergergetmergedpropertiesasmap property merging strictness propertymerger constructed properties files read classpath andor filesystem resolution process merging merger compare properties original properties file defaultproperties compare properties overriding file property defined overriding file exist default properties warning logged letting know new property exists default value example spelling mistake exists prodproperties defaultproperties productinventoryurlhttplocalhost9090apilist prodproperties productinevntoryurlhttpproductslivexxx9090apilist propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder propertiesmerger merger mergerbuilderbuild testing would see 114024431 main warn oguepmenvironmentspecificpropertiesmerger nomatchingpropertywarning property productinevntoryurl overriding properties exist original properties would rather propertiesmerger b strict throw exception fail contructed set merger strict follows propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder setstrictmergingofpropertiestrue propertiesmerger merger mergerbuilderbuild construction propertiesmerger mergerbuilder ' build method would receive runtime exception orggreencheekutilsenvironmentpropertyplaceholderresolverexceptionnomatchingpropertyexception exception thread main orggreencheekutilsenvironmentpropertyplaceholderresolverexceptionnomatchingpropertyexception nomatchingpropertywarning property productinevntoryurl overriding properties exist original properties property values placeholder replacement configurationcode examples replace variables placeholder values properties returned properties object example given following property contained within configdefaultproperties lets say databaseservercnamebernardappdbwproduction databaseurljdbcmysqldatabaseservercnameadmin value databaseurl obtained properties object still contain databaseservercname propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder properties p mergerbuilderbuildproperties results databaseurljdbcmysqldatabaseservercnameadmin databaseservercnamebernardappdbwproduction order placeholder replacement take place use additional builder creates propertiesresolver previous builder propertiesmergerbuilder creates propertiesmerger responsible merging varying properties files differ based environmental settings propertiesresolver takes merged properties propertiesmerger resolves variables values properties propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder propertiesresolverbuilder resolverbuilder new environmentspecificpropertiesresolverbuilder propertiesmerger merger mergerbuilderbuild properties p resolverbuilderbuildpropertiesmerger reduce amount code little pass propertiesmergerbuilder directly buildproperties method propertiesresolverbuilder propertiesresolverbuilder calls build builder obtain propertiesmerger obtains merged properties propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder propertiesresolverbuilder resolverbuilder new environmentspecificpropertiesresolverbuilder properties p resolverbuilderbuildpropertiesmergerbuilder obtaining resolved unresolved properties one time everytime call resolverbuilderbuildpropertiesmergerbuilder obtain properties object new propertiesresolver properties object created therefore really create properties object use multiple place however central place object query return property resolved variable unresolved variables create propertiesresolver object query properties query internal properties object obtained merger create propertiesresolver propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder propertiesresolverbuilder resolverbuilder new environmentspecificpropertiesresolverbuilder propertiesmerger merger mergerbuilderbuild propertiesresolver resolver resolverbuilderbuildmerger query resolved property resolvergetpropertydatabaseurl returns jdbcmysqlbernardappdbwproductionadmin query unresolved property resolvergetunresolvedpropertydatabaseurl returns jdbcmysqldatabaseservercnameadmin using environment resolve placeholders default resolver also resolve variables placeholders within property values environment varibles available java process java system properties set wish behaviour turn creating variableplaceholdervalueresolver passing propertiesresolverbuilder via setpropertyvalueresolver method propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder propertiesresolverbuilder resolverbuilder new environmentspecificpropertiesresolverbuilder valueresolverconfig valueresolver new variableplaceholdervalueresolverconfig setenvironmentpropertiesresolutionenabledfalse setsystempropertiesresolutionenabledfalse resolverbuildersetpropertyvalueresolvernew variableplaceholdervalueresolvervalueresolver p resolverbuilderbuildpropertiesmergerbuilder trimming property values whitespace default property values returned propertiesresolver trimmed whitespace beginning end property value javalangstringtrim turned propertiesresolverbuilder level propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder propertiesresolverbuilder resolverbuilder new environmentspecificpropertiesresolverbuilder settrimmingpropertyvaluesfalse propertiesresolver resolver resolverbuilderbuildmergerbuilderbuild thread safety like propertiesmergerbuilder propertiesresolverbuilder thread safe intended used single thread order construct propertiesresolver safe use across multiple threads goes valueresolver ' configuration valueresolver variableplaceholdervalueresolver thread safe construction like propertiesmergerbuilder obtain propertiesresolver builder propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder propertiesresolverbuilder resolverbuilder new environmentspecificpropertiesresolverbuilder propertiesmerger merger mergerbuilderbuild propertiesresolver resolver resolverbuilderbuildmerger use constructed propertiesresolver multiple threads properties obtain returned via resolverbuilderbuildpropertiesmergerbuilder safe use across multiple threads composite builder composite builder avialable combination propertiesmergerbuilder propertiesresolverbuilder adds method properties buildresolvedproperties returns set properties embedded property values resolved properties come set combined property files source dependent system environment properties defined merger property value contain variables placeholders ie resolved composite builder created means reduce number lines xmlcode generating properties object use spring 31 propertysources object bean idenvironmentalproperties classorgspringframeworkcoreenvpropertiespropertysource constructorarg valuemyenvironmentproperties constructorarg bean factorybeanpropertiesresolver factorymethodbuildresolvedproperties constructorarg bean bean idpropertiesresolver classorggreencheekutilsenvironmentpropertyplaceholderresolverbuildercompositeresolvedpropertiesbuilder constructorarg bean classorggreencheekutilsenvironmentpropertyplaceholderresolvervaluevariableplaceholdervalueresolver constructorarg valuefalse resolve env vars constructorarg valuefalse resolve system properties bean constructorarg property namelocationforloadingconfigurationproperties valueclasspath property namelocationforloadingoperationaloverrides valueclasspathopsoverrides property namerelativelocationoffilesoverridingdefaultproperties valueenvironments bean using spring prior propertysource introduction spring 3 associate profilevaluedev autowired orgspringframeworkcoreenvenvironment way define propertyplaceholderconfigurer follows bean classorgspringframeworkbeansfactoryconfigpropertyplaceholderconfigurer property nameproperties bean factorybeanpropertiesresolver factorymethodbuildresolvedproperties property bean bean idpropertiesresolver classorggreencheekutilsenvironmentpropertyplaceholderresolverbuildercompositeresolvedpropertiesbuilder constructorarg bean classorggreencheekutilsenvironmentpropertyplaceholderresolvervaluevariableplaceholdervalueresolver constructorarg valuefalse resolve env vars constructorarg valuefalse resolve system properties bean constructorarg property namelocationforloadingconfigurationproperties valueclasspath property namelocationforloadingoperationaloverrides valueclasspathopsoverrides property namerelativelocationoffilesoverridingdefaultproperties valueenvironments bean allowed register property placeholder resolve properties within application contexts value annotations valuemessage &#9; private string message introduction spring 311 move use propertysource implementations use autowired environment order obtain properties autowired &#9; private environment env requestmappingvalueheadersnoofheadersmethodrequestmethodget public string returnheadersfinal pathvariablenoofheaders int noheaders &#9; &#9; &#9; &#9; &#9; &#9; model modelhttpservletrequest request string envgetpropertymessage propertiesmerger works within environment properties made available environment object via use custom applicationcontextinitializer set either dispatcherservlet contextloaderlistener dispatcherservlet servlet &#9; &#9; servletnameservletservletname &#9; &#9; servletclassorgspringframeworkwebservletdispatcherservletservletclass &#9; &#9; loadonstartup1loadonstartup &#9; &#9; initparam &#9; &#9; &#9; paramnamecontextinitializerclassesparamname &#9; paramvalueorggreencheekplaygroundwebspringpropertiesmergerapplicationcontextinitializerparamvalue initparam &#9; servlet contextloaderlistener contextparam paramnamecontextinitializerclassesparamname paramvalueorggreencheekplaygroundwebspringpropertiesmergerapplicationcontextinitializerparamvalue contextparam listener &#9; listenerclassorgspringframeworkwebcontextcontextloaderlistenerlistenerclass &#9; listener would make propertysource instance propertiespropertysourcehttpstaticspringsourceorgspringdocs31xjavadocapiorgspringframeworkcoreenvpropertiespropertysourcehtml populated properties obtain either merger resolver public class propertiesmergerapplicationcontextinitializer implements applicationcontextinitializerconfigurableapplicationcontext &#9; private static final properties environmentalproperties &#9; static propertiesmerger merger new environmentspecificpropertiesmergerbuilderbuild environmentalproperties mergergetmergedproperties following resolved properties environmentalproperties new environmentspecificpropertiesresolverbuilderbuildpropertiesmerger &#9; &#9; public void initializeconfigurableapplicationcontext applicationcontext &#9; &#9; initialiseapplicationcontext &#9; &#9; public static void initialiseconfigurableapplicationcontext applicationcontext &#9; add merged properties applicationcontext environment &#9; properties available autowired environment object &#9; &#9; applicationcontextgetenvironment &#9; &#9; getpropertysources &#9; &#9; addfirstnew propertiespropertysourcepenvironmentalproperties &#9; please aware register propertysourcesplaceholderconfigurer beanfactory post processor properties made available value annotations unless register propertysourcesplaceholderconfigurer bean classorgspringframeworkcontextsupportpropertysourcesplaceholderconfigurer property nameproperties &#9; &#9; bean factorybeanpropertiesresolver factorymethodbuildresolvedproperties property bean bean idpropertiesresolver classorggreencheekutilsenvironmentpropertyplaceholderresolverbuildercompositeresolvedpropertiesbuilder constructorarg bean classorggreencheekutilsenvironmentpropertyplaceholderresolvervaluevariableplaceholdervalueresolver constructorarg valuefalse resolve env vars constructorarg valuefalse resolve system properties bean constructorarg property namelocationforloadingconfigurationproperties valueclasspath property namelocationforloadingoperationaloverrides valueclasspathopsoverrides property namerelativelocationoffilesoverridingdefaultproperties valueenvironments bean could also declare java based configuration create propertysourcesplaceholderconfigurer bean propertysourcesplaceholderconfigurer used resolving properties web application components could add configuration propertiesmergerapplicationcontextinitializer example propertysourcesplaceholderconfigurer registered separate context ie configurer ' inherited webapplicationcontext root applicationcontext like beans affects context registered import javautilproperties import orggreencheekutilsenvironmentpropertyplaceholderbuilderenvironmentspecificpropertiesmergerbuilder import orggreencheekutilsenvironmentpropertyplaceholderbuilderenvironmentspecificpropertiesresolverbuilder import orggreencheekutilsenvironmentpropertyplaceholdermergerpropertiesmerger import orgspringframeworkcontextapplicationcontextinitializer import orgspringframeworkcontextconfigurableapplicationcontext import orgspringframeworkcontextannotationbean import orgspringframeworkcontextannotationconfiguration import orgspringframeworkcontextsupportpropertysourcesplaceholderconfigurer import orgspringframeworkcoreenvmutablepropertysources import orgspringframeworkcoreenvpropertiespropertysource configuration public class appconfig implements &#9; &#9; applicationcontextinitializerconfigurableapplicationcontext &#9; private static final properties environmentalproperties &#9; static &#9; &#9; propertiesmerger merger new environmentspecificpropertiesmergerbuilderbuild &#9; &#9; environmentalproperties new environmentspecificpropertiesresolverbuilderbuildpropertiesmerger &#9; &#9; public void initializeconfigurableapplicationcontext applicationcontext &#9; &#9; initialiseapplicationcontext &#9; &#9; public static void initialiseconfigurableapplicationcontext applicationcontext &#9; &#9; applicationcontext &#9; &#9; &#9; &#9; getenvironment &#9; &#9; &#9; &#9; getpropertysources &#9; &#9; &#9; &#9; addfirstnew propertiespropertysourcepenvironmentalproperties &#9; &#9; bean &#9; public static propertysourcesplaceholderconfigurer propertysourcesplaceholderconfigurer &#9; &#9; propertysourcesplaceholderconfigurer config new propertysourcesplaceholderconfigurer &#9; &#9; mutablepropertysources sources new mutablepropertysources &#9; &#9; sourcesaddfirstnew propertiespropertysourcepenvironmentalproperties &#9; &#9; configsetpropertysourcessources &#9; &#9; return config &#9;\n",
      "[0 1 1 0 0 0 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1\n",
      " 0 0 1 1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 1 0\n",
      " 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 1\n",
      " 0 1 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0]\n",
      "environmentalcs program created feb202020 6 months work completed jun222020 program comparison algorithm people working towards environmental benefits monitoring plant life growth certain area upload save images landscapes directory compare overtime new images area provide thorough analysis much plant life change location interest\n",
      "[0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1]\n",
      "qgisapplications environmental gis applications repository includes gis open source environmental applications\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmentalviolence environmentalviolence\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmental sensor data repository esdr esdr open source data repository intended storing retrieving time series environmental data basically data timestamp value esdr store provide ways retrieve quickly securely data stored custom open source datastore provides extremely fast data inserts fetches making fast responsive visualizations esdr web site esdrcmucreatelaborg provides rest api interface datastore making easy readwrite data metadata stored mysql database esdr pronounced like female name esther concepts terminology ' familiar xively ' api ' see lot parallels esdr intention use esdr data repository products visualizations also anyone else wants place store data tools easily visualize first terminology esdr clients users products devices feeds channels tiles understanding entities relate give good understanding data metadata structured system works client esdr uses oauth2 authentication client esdr simply oauth2 client user real surprise heresimply person registered esdr may one products devices feeds user logs heshe behalf oauth2 client product product simply certain kind sensor example speck particle sensor device particular instantiation product ie actual sensor devicesomething put hands ontypically unique serial number feed particular installation device example buy speck register behindthescenes registration process creates esdr device instance speck ' serial number well feed location specified registration example let ' say purchase speck install awning deck registration would give location name eg deck set latitudelongitude house mark exposure outdoors set visibility public private etc data recorded uploaded speck would associated particular feed move speck kitchen would reregister speck associated new feed environmentlocation changed accidentally drop speck sink full water replace new one new one would registered new device different serial number option could associated existing feed old speck one continuous stream data since ' environment measured matters actual device measurement similarly sell speck new owner would register account get new feed channel sensor device measures one aspects environment temperature humidity particle count battery voltage etc considered different channel feed comprises one channels tiles data particular feed ' channel retrieved esdr small chunks json call tiles tile contains 512 data points associated particular starting timestamp duration example tile could represent summary decade ' worth data could contain actual recorded data samples spanning say 1 second eg heart rate data grapher use fetches tiles user pans zooms timelineit requests small subset data needs render plot appropriate analogy panningzooming google mapsthe browser requests map tiles current small region earth ' exploring time esdr also support multitile fetch fetch data multiple channels multiple feeds single get request essential able visualizations lots sensors simultaneously eg air quality cities country data samples stored datastore data entities stored mysql database big win datastore works billions samples time aggregation upon insert yet inserts still fast storing data number different summarization levels thus return summary year ' worth data quickly say five minutes worth summarization computation required fetching tiles visualizations remain responsive fast zoom level ' yet spatiotemporal aggregation ' todo list please see document details use esdr setup install module dependencies npm install install bodytrack datastore following fetch bodytrack datastore terminal window set working directory root esdr repository following git clone httpsgithubcombodytrackdatastoregit follow bodytrack datastore ' build install instructions install mysql necessary esdr tested assumes mysql 56 known issues 55 following create development mysql database user create database exists esdrdev grant privileges esdrdev ' esdrdev ' ' localhost ' identified ' password ' grant selectinsertupdatedeletecreate esdrdev ' esdrdev ' ' localhost ' choose change password make sure matches password configdevjson want able run tests following create test database user create database exists esdrtest grant privileges esdrtest ' esdrtest ' ' localhost ' identified ' password ' grant selectinsertupdatedeletecreate esdrtest ' esdrtest ' ' localhost ' choose change password make sure matches password configtestjson running production following create configprodjson mailconfigprodjson files copy configs need include parts differ configjs following create production database user create database exists esdrprod grant privileges esdrprod ' esdrprod ' ' localhost ' identified ' useagoodpasswordhere ' grant selectinsertupdatedeletecreate esdrprod ' esdrprod ' ' localhost ' make sure user password specify matches configprodjson make sure datastore data directory defined config file exists run nodeenv environment variable may specified running must one dev development test prod production defaults dev unspecified run server development mode following npm start nodeenvdev npm start nodeenvdevelopment npm start run server test mode nodeenvtest npm start run server production mode either following nodeenvprod npm start nodeenvproduction npm start development generate css scss template npm runscript gencss compile handlebars templates npm runscript genhandlebars\n",
      "[0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 1 0 0 1 1 1 0 1 0 0 1 0 1 1 1\n",
      " 0 0 0 1 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 1 0 1\n",
      " 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1\n",
      " 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1]\n",
      "enviro mqtt logger enviroplusmqtt python service publishes environmental data enviro via mqtt setting device set rpi normally would connect enviro board pms5003 sensor using one install enviro library following instructions httpsgithubcompimoronienviropluspython make sure library installed python 3 clone repository usrsrcenviroplusmqtt sudo git clone httpsgithubcomhotplotenviroplusmqtt usrsrcenviroplusmqtt add new file etcsystemdsystemenvloggerservice following content unit descriptionenviro mqtt logger afternetworktarget service execstartusrbinpython3 usrsrcenviroplusmqttsrcmainpy arguments workingdirectoryusrsrcenviroplusmqtt standardoutputinherit standarderrorinherit restartalways userpi install wantedbymultiusertarget note must replace arguments flags appropriate mqtt server enable start service sudo systemctl enable envloggerservice sudo systemctl start envloggerservice supported arguments mqtt host port username password client id specified update interval specified defaults 5 seconds initial delay publishing readings specified defaults 15 seconds using pms5003 sensor enable passing usepms5003 flag usage mainpy h host p port u username p password prefix prefix clientid clientid interval interval delay delay usepms5003 help optional arguments h host host host mqtt host connect p port port port port mqtt host connect u username username username mqtt username connect p password password password password connect prefix prefix topic prefix use publishing readings ie ' loungeenviroplus ' clientid clientid mqtt client identifier use connecting interval interval duration seconds updates delay delay duration seconds allow sensors stabilise starting publish readings usepms5003 set pm readings taken pms5003 sensor help print help message exit published topics readings published following topics prefixproximity prefixlux prefixtemperature prefixpressure prefixhumidity prefixgasoxidising prefixgasreducing prefixgasnh3 prefixparticulate10 prefixparticulate25 prefixparticulate100\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "ceqr app ceqr app collection data tools whose purpose improve accuracy speed environmental review getting started ceqr app runs rails api ember frontend two ways run app run locally use docker architecture todo\n",
      "[0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "repo hosts kaspermarstalgithubio\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "fall 2019 department atmospheric science university utah atmos 5020 environmental programming repository contains lecture notes inclass exercises code data information check canvas page check understanding quizzes assignments homework general information download repository command line navigate desktop cd desktop type following command line git clone httpsgithubcomjohnhorelatmos50202019 download zip file update repository cd atmos50202019 directory type git pull note windows pc need download install git windows use command prompt view jupyter notebooks python notebooks render github ' copy notebook url view nbviewer httpsnbviewerjupyterorg alternatively download notebook right clicking ' raw ' button selecting ' save ' open notebook jupyter lab schedule date topics aug 20 introduction set computers aug 22 programming concepts linux shell scripts aug 27 shell scripts working chpc machine aug 29 html make webpage sep 3 introduction python sep 5 part 2 python jupyter lab loops statements etc sep 10 python functions matplotlib sep 12 supplemental python pandas sep 17 python advanced matplotlib datetime 2d plots etc sep 19 pyhton plotting goes data reading example docs online quick guides log onto chpc computers ssh uxxxxxxxmeteo07chpcutahedu linux cheatsheet 1 linux cheatsheet 2 python cheatsheet numpy cheatsheet matplotlib cheatsheet jupyter notbook shortcuts markdown formatting notes written markdown basic vi commands another vi cheat sheet setting personal computer logon chpc windows user want log onto chpc resources must install putty xming follow instructions logging mac users use terminal like classroom install python recommended way install python personal computer anaconda distribution service install packages anaconda navigator tool environments tab brian ' instructions give details install python anaconda personal computer unidata workshop also instructions set environment also recommend install good text editor like vscode available download anaconda launcher learn python purpose class introduce programming principles programming skill improve hours hours practice plan using python class highly recommended learn resources use classes use capstone research project several free python learning courses really help learn python like codecademy version 2 lot free stuff ' pretty close version 3 unidata training another useful resource\n",
      "[0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0 1]\n",
      "environmental map python configuration environment variables overview environmental allows map class properties environment variables using environmental keep configuration single class ide understands convenient safe type conversions strings stored environment python types created properties also writable assign change environment available child processes installation sudo pip3 install upgrade environmental example import environmental import os class configuration port environmentalint ' myapplicationhttpport ' 80 name environmentalstr ' myapplicationname ' ' name ' config configuration configport 8080 assert osenviron ' myapplicationhttpport ' ' 8080 ' assert isinstanceosenviron ' myapplicationhttpport ' str assert configport 8080 assert isinstanceconfigport int caveats modifying mutable objects configuration like lists work import os environmental class configuration list environmentallist ' list ' osenviron ' list ' assert configlist configlistappend ' test ' assert configlist something reassigns variable configlist ' test ' assert configlist ' test ' license copyright 2015 zalando se licensed apache license version 20 license may use file except compliance license may obtain copy license httpwwwapacheorglicenseslicense20 unless required applicable law agreed writing software distributed license distributed basis without warranties conditions kind either express implied see license specific language governing permissions limitations license\n",
      "[0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0]\n",
      "metabeat metabarcoding environmental dna analysis tool reproducible pipeline analysis metabarcoding data generated either sanger ngs approaches metabeat using number external programs make life easier created self contained environment necessary pieces software docker image image building reprophylo want use ' need docker installed machine use image run metabeat script container process data current working directory subdirectories sudo docker run rm nethost name metabeat v pwdhomeworking chrishahmetabeat metabeatglobalpy h terminal window mount docker container current working directory enter self contained environment using shell sudo docker run nethost name metabeat v pwdhomeworking chrishahmetabeat binbash access container via jupyter notebook simply running startmetabeatnb providing full path desired mounting point script eg startmetabeatnb pwd xt open jupyter notebook new tab default browser first notify connection private click advanced bottom left proceed local host unsafe asked provide password simply password entering password correctly open jupyter notebook good go done stop container simply running stopmetabeatnb within environment execute scripts come metabeat eg metabeatglobalpy executing script without options usually display usage eg usage metabeatglobalpy h q file v f p b string n int e e pcrprimer file trimadapter file trimqual int trimwindow int trimminlength int merge productlength int phred int r file gbout file reccheck cluster clustmatch float clustcov int www minident float minbit int refpkg dir outputprefix metadata metadata mockmetadata version metabeat metabarcoding environmental dna analyses tool optional arguments h help show help message exit q file querylist file file containing list query files v verbose turn verbose output seqinfo write seqinfocsv file f fasta write reffasta file p phyloplace perform phylogenetic placement taxids write taxidtxt file b blast compile local blast db blast queries string marker string marker id default marker n int nthreads int number threads default 1 e extractcentroidreads extract centroid reads files e extractallreads extract reads files version show program ' version number exit query preprocessing parameters group affect query sequences processed pcrprimer file pcr primers provided fasta file clipped reads trimadapter file trim adapters provided file trimqual int minimum phred quality score default 30 trimwindow int sliding window size default 5 trimming average quality drops specified minimum quality subsequent bases removed reads trimminlength int minimum length reads retained trimming default 50 merge attempt merge pairedend reads productlength int estimated length pcr product default 100 phred int phred quality score offset 33 64 default 33 reference parameters group affect reference used analyses r file reflist file file containing list files used reference sequences gbout file output corrected gb file reccheck check records used reference query clustering options parameters group affect read clustering cluster perform clustering query sequences using vsearch clustmatch float identity threshold clustering percent default 1 clustcov int minimum number records cluster default 1 blast search parameters group affect blast search blast based taxonomic assignment www perform online blast search nt database minident float minimum identity threshold percent default 095 minbit int minimum bitscore default 80 phylogenetic placement parameters group affect phylogenetic placement refpkg dir path refpkg biom output arguments groups affect output biom format outputprefix outputprefix outputprefix prefix biom output files default ' metabeat ' metadata metadata comma delimited file containing metadata optional mockmetadata add mock metadata samples biom output versions v 06 docker image version chrishahmetabeatv06 used kitson et al 2015\n",
      "[1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0\n",
      " 0 0 1 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 1 0 0 0 1]\n",
      "environmentalicious quite tasty looks decent mobile well synopsis environmentalicious web application allows users locate environmental conservation sustainability events community users create account register attend events believe interesting first release candidate application exhibits main core functionalities current state system user able create events find events relative locations search events based criteria event name event description tags may also join events invite friends become event participants installationrunning would like view application without installing server local machine may navigate httpsalsaritedu3000 link may always available please follow instructions install local machine cannot access deployed version order load application locally nodejs must installed local system recent version nodejs 01033 time writing found httpnodejsorg nodejs environment installed open command prompt terminal move root directory project order install dependencies project first type ' npm install ' completed run command ' node serverjs ' navigate browser httplocalhost3000 npm install node serverjs application usage creating event navigate ' create event ' section left hand bar bar home screen login enter desired event information select ' create event ' button finding already created event navigate ' find event ' section left hand bar home screen login enter information event name event location keyword found description event would like attend click ' find event ' button locate result left hand portion screen may click events navigate main event section page joining event main page specific event would like join click ' join event ' button bottom screen pop notify successfully joined event return individual event page able see participant event inviting friends event provide valid line separated email addresses invite friends text box click ' invite friends ' button alert notify friends successfully invited event recieve email letting know marked potential participant known bugs user authentication login functionality selecting ' log ' button main page direct user web application default account contributors danielle gonzalez justin peterson richie kapadia joe ksiazek\n",
      "[1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 1 1 1 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0]\n",
      "making sense onboarding marking sense onboarding project means alleviate issue abandonment iot devices related citizen science civil sensing onboaridng used making sense means test effectiveness building communities around grassroots initiatives currently supporting smartcitizen api new smartcitizen kit 15 web app aims solve key issues setup open data sensors within grassroots smartcity communities developing cognitive goals fostering ownership creating context showing playful animations simplifying language multilingual experience helps reduce bottleneck nontechnical citizens installing iot devices tool currently used eu research project current link livedeployment updates handled fork moved master prerequisites need git clone repository get git httpgitscmcom also use number nodejs tools initialize test web app must nodejs package manager npm installed get httpnodejsorg also gulp npm install g gulp sudo using mac clone project clone repository using git clone httpsgithubcomfablabbcnsmartcitizenonboardinggit cd smartcitizenweb install dependencies install tools manage test application npm install need bower install npm install take care use gulp tasks gulp gulp build build optimized version application dist gulp serve launch browser sync server source files gulp servedist launch server optimized application gulp test launch unit tests karma gulp testauto launch unit tests karma watch mode gulp protractor launch e2e tests protractor gulp protractordist launch e2e tests protractor dist files gulp deploy publish project github pages ghpages branch note case see something like error command failed fatal unable read c6a8d370f3e95d9110eca4a03b704bd8940ca40b run rm rf node e consolelogrequire ' path ' joinrequire ' os ' tmpdir ' tmprepo ' work process final documentation coming soon support issues forum forumsmartcitizenme credits work received funding european union ' horizon 2020 research innovation program grant agreement 688620\n",
      "[0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 1\n",
      " 0 0 1 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0]\n",
      "grasp planner based environmental constraint exploitation caution plan running specific branch please read readmemd branch readmemd valid current branch table contents overview structure interfaces flow information list controllers primitives ecs hardware dependencies install minimal dependencies dependencies running gazebo example grasp planner usage examples planning based pcd input planning based continuous rgbd input kuka arm gazebo simulation trik controller using rosservice call planner overview planning framework generates contactrich motion sequences grasp objects within planning framework propose novel view grasp planning centers exploitation environmental contact view grasps sequences constraint exploitations ie consecutive motions constrained features environment ending grasp able generate grasp plans becomes necessary consider planning perception control tightly integrated components result components simplified still yielding reliable grasping performance implementation based clemens eppner oliver brock planning grasp strategies exploit environmental constraints proceedings ieee international conference robotics automation icra pp 4947 4952 2015 structure interfaces flow information structure planning framework consists visual processing component planning module visual processing component detects planar surfaces convex concave edges point cloud represents graph structure component based ecto computation graph framework cpython computations organized directed acyclic graph computing cells connected typed edges single computing cells simple operations clustering segmentation fitting models following diagram shows computation graph grasp planning framework segmentation soup generated different segmentation algorithms based depth color segments planes edges fitted final output geometry graph describes spatial structure environment planning module takes spatial graph input combines information object pose type robotic hand arm planning problem planning problem represented stripslike fashion solved using search output planner sequence motions interspersed contact sensor events summing input planning framework given point cloud provided either real rgbd sensor see example 2 recorded point cloud see example 1 even simulated sensor see example 3 object pose optional also provided ecto graph computation using simple heuristic select point cluster closest largest planar surface scene hand robotspecific information defines particular hand slides across surface closes fingers etc also includes robotspecific things ft sensor thresholds velocities new hands andor arms easily extended usual output robot motion planner jointconfiguration trajectories planner different outputs socalled hybrid automata hybrid automaton finite state machine whose states continuous feedback controllers based position velocity force etc transitions discrete sensor events position trajectories lack expressive power needed capture feedbackdriven contactrich motions considered hybrid automata much suited context consequence entity wants execute generated plans needs capable interpreting hybrid automata descriptions use c library allows serializationdesirialization used wrap robotspecific interfaces shown example 3 primitives controllers jump conditions list primitives positioning sliding caging edgegrasp wallgrasp surfacegrasp primitives based clemens eppner oliver brock planning grasp strategies exploit environmental constraints list controllers joint controller operational space controller sliding controller rbohand controller pisaiithand controller list jump conditions time based ft measurement based joint configuration based frame pose based list ecs surface edge wall hardware dependencies table lists tested hardware dependencies planner soma partner tested tested simulation gazebo f failed tub unipi iit ocado disney hand rbo hand2 pisa iit hand rbo hand2 tpisaiit handrbo hand2 v2 pisaiit hand v2 pisaiit softgripper arms wam kuka iiwa kuka lbr iiwa14 staubli rx160l forcetorque sensor ati ftngamma sensors optoforce hex70xe200n rgbd sensor asus xtion pro live primesense carmine 1089t kinect v2 api rosmoveit install code tested ros indigo ubuntu 14045 lts follow build instructions need build catkin tools aptget install pythoncatkintools minimal dependencies clone repository git clone httpsgithubcomsomaprojectecgraspplannergit build geometry messages ' build projects form repository yet catkin build geometrygraphmsgs clone ros stack ectorbo catkin workspace build git clone httpsgithubcomsomaprojectvisiongit follow instructions httpsgithubcomsomaprojectvisionblobmasterreadmemd get pyddl pip install e githttpsgithubcomgarydoranjrpyddlgiteggpyddl get ros package hybridautomatonmsgs git clone httpsgithubcomturbohybridautomatonmsgsgit dependencies running gazebo example get ros package hybridautomatonmanagerkuka kuka interface needed git clone httpsgithubcomsomaprojecthybridautomatonmanagerkukagit get gazebo multirobot simulator version 226 sudo aptget install rosindigogazebo get iiwastack git clone httpsgithubcomsalvovirgaiiwastackgit cd iiwastack git checkout 94670d70b9bfbf0920c7de539012c805734fdbc5 catkin build iiwa get hybridautomatonlibrary install following readme instructions build hybridautomatonmanagerkuka according instructions forget link robot files grasp planner clone repository catkin workspace build ros package git clone httpsgithubcomsomaprojectecgraspplannergit cd ecgraspplanner git submodule init git submodule update catkin build ecgraspplanner starting planner node plannerpy h rosservicecall fileoutput rvizrobotbaseframe robotbaseframe objectframe objectframe objectparamsfile find path graph turn hybrid automaton optional arguments h help show help message exit rosservicecall whether send hybrid automaton ros service called updatehybridautomaton default false fileoutput whether write hybrid automaton file called hybridautomatonxml default false rviz whether send marker messages seen rviz represent chosen grasping motion default false robotbaseframe robotbaseframe name robot base frame default baselink objectframe objectframe name object frame default object objectparamsfile name file containing parameters objectec selection multiple objects present default objectparamyaml start planner node waits service call calling service step 1 start planner background simulation rosrun ecgraspplanner plannerpy rviz fileoutput robotbaseframe world real world demo rbo lab use instead rosrun ecgraspplanner plannerpy rviz fileoutput step 2 call rosservice rosservice call rungraspplanner objecttype ' apple ' grasptype ' surfacegrasp ' handarmtype ' rbohand2kuka ' objectheuristicfunction random objecttype specified certain objectspecific behaviours right default behaviour objects grasptype one anyedgegraspwallgraspsurfacegrasp version surfacegrasp wallgrasp supported handarmtype match specific robothand combination ie rbohand2kuka rbo hand mounted omn kuka iiwa value must match one class names handarmparameterspy objectheuristicfunction one random deterministic probabilistic parameter selects one three heuristic functions multiobject multiec selection planner assumes ec exploitable objects multiobjectec heuristics random select one objectecpair randomly independent heuristic values deterministic pick maximum heuristic function objectec argmax qobjecti ecj 1n j 1m q taken parameter file multiobjectparamspy contains probability values given objects usecase relevant strategies surface wall edgegrasp default parameter file dataobjectparamyaml probabilistic use heuristic function prior sampling random strategies samples pdf given qn x matrix qij qobjecti ecj simple example objectparams apple surfacegrasp ' success ' 1 success rate surface grasping apple 100 wallgrasp ' success ' 1 success rate wall grasping apple 100 edgegrasp ' success ' 0 success rate edge grasping apple 0 advanced objectec relational parameter definition cucumber surfacegrasp ' success ' 1 ' min ' 014 01 ' max ' 014 005 wallgrasp ' success ' 1 08 07 0 ' angle ' 0 180 360 ' epsilon ' 20 edgegrasp ' success ' 0 objcetifco relative position surfacegrasp strategy success given case 1 object within certain area within ifco min max aprameters defin cropbox inside ifco cropbox helps exclude grasp infeasable due possible collision work space limitation reference frame ifoc frame min vecor min minxdistancex minydistance compare object frame relative ifco frame objectx minxdistance objecty minydistance similarly done max maxxdistancex maxydistance parameter object within cropbox success 0 objectec relative oriantation wallgrasp strategy success depend relative orientation cucumber wall define set possible grasping angles degrees 0 180 360 success rate 1 08 07 angle important last element success rate vector gives success cases epsilon upper lower bound exact orientation 0 precises given angle vector 10 10 deg current orientation reference examples planning based pcd input example shows planned grasp rviz based pcd file contains single colored point cloud tabletop scene banana placed middle roscore want change pcd read change file name ecto graph yaml rosrun ectorboyaml plasmyamlrosnodepy rospack find ecgraspplannerdatageometrygraphexample1yaml debug start visualization rosrun rviz rviz rospack find ecgraspplannerconfigsecgraspsexample1rviz select type grasp want rosrun ecgraspplanner plannerpy rviz robotbaseframe camerargbopticalframe execute grasp rosservice call rungraspplanner objecttype ' apple ' grasptype ' surfacegrasp ' handarmtype ' rbohand2kuka ' rviz able see geometry graph wall grasp published visualizationmsgsmarkerarray topic names geometrygraphmarker plannedgrasppath planning based continuous rgbd input example shows use planner rgbdepth sensor like kinect asus xtion uses camera drivers provided ros plug camera computer roslaunch openni2launch openni2launch depthregistrationtrue set camera resolution qvga rosrun dynamicreconfigure dynparam set cameradriver irmode 7 rosrun dynamicreconfigure dynparam set cameradriver colormode 7 rosrun dynamicreconfigure dynparam set cameradriver depthmode 7 rosrun ectorboyaml plasmyamlrosnodepy rospack find ecgraspplannerdatageometrygraphexample2yaml debug start visualization rosrun rviz rviz rospack find ecgraspplannerconfigsecgraspsexample2rviz select edge grasp visualize result rviz rosrun ecgraspplanner plannerpy robotbaseframe camerargbopticalframe rviz execute grasp rosservice call rungraspplanner objecttype ' punnet ' grasptype ' surfacegrasp ' handarmtype ' rbohand2kuka ' depending input result rviz could look like kuka arm gazebo simulation trik controller example shows execution planned hybrid automaton motion gazebo simulator step 1 make sure simulation time used roslaunch hybridautomatonmanagerkuka launchgazebolaunch step 2 start simulation environment kuka control manager rosrun hybridautomatonmanagerkuka hybridautomatonmanagerkuka step 3 run vision code rosrun ectorboyaml plasmyamlrosnodepy rospack find ecgraspplannerdatageometrygraphexample3yaml debug step 4 optional check potential grasps rosrun rviz rviz rospack find ecgraspplannerconfigsecgraspsrviz rviz able see point cloud simulated gazebo geometry graph published visualizationmsgsmarkerarray topic name geometrygraphmarker step 5 select surface grasp visualize execute roscd hybridautomatonmanagerkukatestxmls rosrun ecgraspplanner plannerpy grasp surfacegrasp rosservicecall rviz handarm rbohand2kuka need ctrlc done hasendxmlsh hybridautomatonxml step 6 rviz able see planned surface grasp gazebo robot moves hand towards cylinder contact httpsyoutubeq91u9r83vl0\n",
      "[0 0 1 0 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 1\n",
      " 0 1 1 1 1 0 0 1 0 0 1 0 1 1 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 0\n",
      " 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0]\n",
      "environmentalpioneer ui marsblue elisao web ps githubgithub1559830979qqcom\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "metapathways 2 masterworker model environmental pathwaygenome database construction grids clouds niels w hanson kishori konwar shangju wu steven j hallam updates july 7 2015 metapathways v252 release minor bug fixes releated gbk input processing sam file rpkm calculations rrna homology search november 27 2014 metapathways v25 released upgrades pipeline last homology searches blastequivalent output evalues reads per kilobase per million mapped rpkm coverage measure contig annotations calculated raw reads fastq mapping files sam using bwa addition cazy sequence database new compatible functional hierachy gui keywordsearch annotation subsetting projection onto different functional hierarcies kegg cog seed metacyc cazy see release page wiki information abstract development highthroughput sequencing technologies past decade generated tidal wave environmental sequence information variety natural human engineered ecosystems resulting flood infor mation public databases archived sequencing projects exponentially expanded computational resource requirements rendering local homologybased search methods inefficient recently introduced metapathways v10 modular annotation analysis pipeline constructing environmental pathwaygenome databases epgdbs environmental sequence information capable using sun grid engine external resource partitioning however commandline interface facile task management introduced user activation barriers concomitant decrease fault tolerance present metapathways v20 incorporating graphical user interface gui refined task management methods metapathways gui provides intuitive display setup process monitoring supports interactive data visualization subsetting via custom knowledge engine data structure masterworker model adopted task management allowing users scavenge computational results number worker grids ad hoc asynchronous distributed network dramatically increases fault tolerance model facilitates use ec2 instances extending epgdb construction amazon elastic cloud installation metapathways v25 requires python 27 greater pathway tools developed sri international full functionality metapathways python codebase well compiled gui binaries mac osx ubuntu selfcontained github distro gui source code obtained please see metapathways v25 wiki installation details template metapathwaysdbszip updated october 2014 contains starter protein taxonomic databases citation using metapathways reserach work please cite following kishori konwar niels w hanson maya p bhatia dongjae kim shangju wu aria hahn connor morganlang hiu kan cheung steven j hallam metapathways v25 quantitative functional taxonomic usability improvements bioinformatics 13 2015 doi101093bioinformaticsbtv361 niels w hanson kishori konwar shangju wu steven j hallam metapathways v20 masterworker model environmental pathwaygenome database construction grids clouds proceedings 2014 ieee conference computational intelligence bioinformatics computational biology cibcb 2014 honolulu hi usa may 2124 2014 doi101109cibcb20146845516\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0\n",
      " 0 0 0 0 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0]\n",
      "urbsville urbanode odyssey urbsville core implementation urbanode project goal world domination taking control physical objects handing steering wheel web system developers designed around nodejs urbsville benefits sharing nearly serverside code clientside blurring lines reality basic usage prefer see code front section else skip architecture heading default server look inside binurbsville would see something looks similar main container named hubhub var hub new urbhub ' hub ' log hub events stdout hubon ' event ' function event consolelogevent run api server named apiserversio using socketio protocol var sioapiprotocol new sioserversioserverprotocol8001 var sioapiserver new apiapiserver ' sio ' sioapiprotocol hub run device server named deviceserversio using socketio protocol var siodeviceprotocol new sioserversioserverprotocol8002 var siodeviceserver new devicedeviceserver ' sio ' siodeviceprotocol hub announce web server via mdns notetermie currently expects nginx serve static content var ad mdnscreateadvertisement ' urbanodeweb ' 8000 sioapiserverlisten siodeviceserverlisten adstart lines fairly self explanatory running leaves empty hub waiting devices connect device server point accessible via api server also announces location network basic api client common client urbsville probably socketio api client accessed via web page one shows totally sweet interface exercising dominance physical realm urbsville makes significant use dojo toolkit javascripty stuff jquery person able mostly ignore play together using directory structure project ' end script srcpublicdojodojojsscript script srcpublicjssocketiojsscript scriptiosetpath ' publicjs ' script script srcpublicjsurbjsscript script require emulates nodejs require function using dojo var sioclient require ' urbprotocolsioclient ' var api require ' urbapi ' var hostname windowlocationhostname var protocol new sioclientsioclientsioclientprotocol hostname port 8001 var client new apiapiclient ' admin ' protocol function newdevicedevice something cool device hook ui clienton ' hubadded ' function hub var devices hubdevices var devices newdevicedevicesd hubon ' deviceadded ' function device newdevicedevice documentready jquery types dojoaddonloadfunction clentconnect script sets api client using socketio protocol demonstrates basic events one handling generate ui device devices simple api act eventemitters nodejs sense basically set modifiable properties suppose device represents basic colored light wanted make background element change whenever light ' color changes var light new coloredlightdevice ' ambientroom ' function setbackgroundcolor listen changes rgb property lighton ' propertyrgb ' function newrgb setbackgroundcolornewrgb change rgb property lightset ' rgb ' 255 200 100 types devices might eventonly like sensor operate way var reader new rfiddevice ' badgereader ' readeron ' rfidadded ' function rfidobject something flashy easily hooked together form sorts wonderful things readeron ' rfidadded ' function rfidobject lightset ' rgb ' 255 0 0 readeron ' rfidremoved ' function rfidobject lightset ' rgb ' 0 0 0 architecture urbsville designed allow styles interactions selfcontained device control device publishing going ' expand components system relate style interaction selfcontained devices hubs urbsville enough operate selfcontained device controller meaning ' provide interfaces interact system listens events devices responds accordingly allowing developer script environment javascript many simple art installations far need go device ' ' device represents basic abstract building block manipulating objects urbsville whichever path go actual physical object talking serial port proprietary network protocol even via http device interface physical object providing world properties events devices like pretty much everything else urbsville eventemitters normal interaction involves listening named events setting properties trigger changes trigger events see device example hub hub also eventemitter main purpose keep track devices hubs also provide way interact devices tracked aggregate forwarding events emitted listeners common practice one hub track devices device controller goal device controller provide interface allow remote controller usually user actively manipulate devices tracked hub using apiserver serverside wrapping hub apiclient clientside providing proxy readily accomplished given transport protocol api server apiserver hub ' main face world provides interface remotely interacting devices tracked hub via transport protocol eg socketio tcp clients connecting apiserver initially given current state system serialized dump hub devices thereafter events hub devices passed along client api client apiclient creates local representation hub devices provided via apiserver transport protocol allows interacted via proxy instances proxy actually two types proxy deviceproxy hubproxy effectively simply intended act exactly like nonproxy counterpart forward write actions across network boundary replay events received boundary proxies built behind scenes example apiclient receives information hub devices server information originating device hub proxied replayed listeners client side properties set client side result rpc actually set server side device publisher ' things twist around bit goal device publisher allow remote devices publish via local hub may turn allow activities control accomplished deviceserver proxying devices provided deviceclient device controller device publisher presents many opportunities organic environment monitoring control device server deviceserver allows remote devices tracked local hub via transport protocol clients connecting deviceserver expected provide serialized device point deviceproxy built deviceserver added hub proxies events generated original device time client side replayed local proxy actions taken result rpcs device client deviceclient wraps local device provides server via transport protocol building running urbsville relies decent number external tools libraries stuff need node 23 httpnodejsorg standard build environment make gcc sort stuff use provided nginx config demo need nginx httpnginxorg use dmx utilities ' need olad httpwwwopendmxnetindexphpopenlightingarchitecture everything order cloning repo running make get set todo ton stuff make urbsville fitter happier productive ' short list make installable maybe npm commandline arguments urbsville script mdnsenabled deviceclient example automatically provide device deviceservers network services advertised mdns static file serving node simple demos small projects device types specific device implementations default html representations devices\n",
      "[0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1\n",
      " 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 1 1 1 0 0 0\n",
      " 1 0 1 0 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1\n",
      " 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 1 0 0 0 0 1 1 0 0]\n",
      "sustainable communities web challenge saturday sunday january 23 24 2021 ' combining economic envronmental data planning input using epa ' new environmental indicator models choose area compete 10000 awards using new inputoutput widgets create interfaces communities using 24 environmental indicators across 388 industries event register online slack clubs project areas demographics industry analytics impacts machine learning expand upon countybased results provide zipcodebased industry lists details add zipcode demographics using uszipcodereadthedocsio python d3 create update data visualizations interplay demographics industries impacts b supply chain inflowoutflow charts updates sankey d3 charts leaflet maps maps us filters industry impact evaluator create embeddable charts use hash parameters python d3 optionally react details c industry level estimates counties zipcodes fill gaps number establishments provided state level details update data processing script work team zipcode industry data prep python useeio updates bioecomony bioproducts local economy inputs new technology additions useeio details e google sheet crowdsource editor rest process allowing editors return update row contributions see contact us additional details avoid overlaps document team ' times help judges award contributions basis reward team members contribute specific coding areas compliment broad areas specific coding area updates html jquery jam stack development embed customize chart displays using ee inputoutput widgets build location profiles using industry impact evaluator add map search filters apply industry icons charts integrate map samples update useeio widgets embed resource event calendars environmental educators react nodejs updates useeiowidgets react d3 update csv files employment industries d3 charts using census industry data income zipcode zcta work data team choose jamstack editor edit csv files directly github using social logins d3 visualizations leaflet maps visualizations material flow regional inputoutput map starters leaflet route maps driving tours deliveries python rlanguage create update scripts pull data preprocess csv json files industry zip code searches local commodity searchs work useeio api update inputoutput charts widgets loaded json files generated api endpoints aws goods services demand vectors food system full system update django census reporter staring python 3 wazimap fork used africa india integrate us demographic data python 2 version set docker deploy heroku using containerization template learn using heroku aws rstudio useeior use lca methodology evaluate new technologies including advanced biofuels microsoft net add useeio widgets net environmental education tools geep partner states countries google rest app google sheet editor crowdsourcing updates code america brigades often use google sheets maintain directories like maps georgia north carolina social login process needed allow contributors return update google sheet row data online form without access edit rows contributors setup needs take minute per sheet avoid zapier timeintensive approaches specific project tasks maintain list time contributions increase award potential let us know ' working avoid overlaps bubble chart d3 view widget modify popups still appear containing div set positionrelative scale size containing div browser resize set default bubble color red pop omit red scale bubbles highlighted create react version industrylist mosaic react view widget details column selected avoid dimming columns add slidershttpsmaterialuicomcomponentsslider right rows adjust levels multiplier effect done include tabs top 20 categories 388 industry sectors x selected mock upstartdataset show list selected sectors x selected tab include duplicate checkboxes x selected tab display parent naics industry categories open reveal subcategories display quantity selected parent category title parenthesis custom sets could use csvjson format toggle matrices using dropdown menu select matrix list parent category include 3dot menu options sort alphabetical change matrix show values show values like sortable example include verticle column name like dataset example highlight action menu checkboxes clicked actions could include display map display bar chart generate report slider details editable number could appear clicking slider editable number could disappear seconds inactivity slide bar could replace bar currently right rows dot could relative rows matching bar length bar could turn green commodity increased default bar could turn red commodity decreased default sliders used show multiplier effects hash syntax 99 300 adjustment could sectors31161599550000300 impact bar chart react view widget details create example three columns one impact area per colums display sector titles left first column display sector name bar display description indicator update use darkly bootstrap similar bubble chart click bubble view impact chart last airbender potential use elementary school education interface epa indicators could organized air water land fire energy plus two additional categories prosperity economy wellness health airbender categories added primary secondary columns lciaindicatorsetscsv biomodeling branch heres airbender api relating four nation categories characters use bea commodities estimate null industries protect privacy individual firms census omits payroll empolyee count data industries state county level like automobile manufacturing georgia 89 industries number establishments available county state lever estimates omitted industry values could generated using state bea commodity data crosswalk file average states could used long industry least one payroll value another state data integration us bureau economic analysis expand industry level data community info page updates farm fresh federal usda location data maps initially merged aglanta preprocess uszipcode programmable database python github zip map international harmonized system hs code crosswalk event register online slack groups\n",
      "[1 1 0 1 1 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 0 1 0 1 0 1 0 0\n",
      " 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0\n",
      " 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1]\n",
      "scscore root south coast science environmental monitoring applications contains library classes required libraries third party awsiotpythonsdk pytz tzlocal branches stable branch repository master deployment purposes use git clone branchmaster httpsgithubcomsouthcoastsciencescscoregit\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "libaudioverse github ' trying raise money project put months fulltime work consequently gofundme introduction libaudioverse highly flexible realtime audio synthesis library designed bound many languages possible potential applications include games realtime music synthesis voice chat implementations webaudio libaudioverse supports best possible backends platform uses sse2 threads increased performance core libaudioverse concept node piece meaningful audio architecture connected acyclic configuration allowing creation much complex effects possible schedule property changes envelopes sampleperfect accuracy complex effects nodes connected directly properties nodes overview offered nodes environment source nodes come together act fully functional 3d audio environment including support hrtf surround sound reverb fdn reverberator environmental reverb capable representing everything bathroom cathedral want play schroeder allpass sections try nested allpass network node variety lowerlevel filters available biquad firstorder onepole convolution possible implement iir filter either cascading lower level filters using iir filter node directly oscillator options include sine square well configurable noise generator several delay line types delay lines offer support feedback filtered delay line allows filtering feedback record audio recorder intercept audio anywhere graph nodes graph listener finally none meet needs possible create node via custom node note prealpha supports windows linux mac planned licensing see file copyright legalese file definitive following summary nonlegalese version libaudioverse duallicensed gpl v3 later see gpl v3 mpl2 documentation examples two sources libaudioverse documentation first languageagnostic manual discusses libaudioverse general perspective manual contains reference c api overview libaudioverse ' core concepts examples manual python second source documentation api reference language choice moment means python api reference api references contain installation instructions notes specific language question examples supported languages may found github repository sets examples aim equivalent demonstrate critical features libaudioverse library easy many cases examples enough get started getting help libaudioverse google group subscribe directly without gmail address via emailing empty email libaudioversesubscribecamlornnet clicking link confirmation email sent prefer questions come via avenue results answers searchable future need contact realtime via libaudioverse irc channel libaudioverse chatfreenodenet please report bugs make feature requests using github issue tracker saves time issues cannot fix immediately building see info supported platforms build instructions bindings moment python c supported languages get python bindings via pip windows linux currently requires building libaudioverse languages become available libaudioverse attempt upload binaries package managers goal minimize number use cases require building libaudioverse libaudioverse ' approach bindings possible add languages short order seriously considering using libaudioverse specific language wish talk addition new language mostly onetime process bindings literally maintain language add next primarily based interest note language must support c callbacks least 2 levels pointer indirection thread primitives order successfully bound libaudioverse language currently aware fails implement three things angelscript bgt scripting environment\n",
      "[0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 1 1 0 1 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 1 1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 1 0]\n",
      "environmentalapp\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmentalsound image data gotten es50 environmental sound dataset kaggle method extraction librosa mel spectrograms img h128 x w157 size 16000 processing ximg pickled downloaded resulting files labels stored ypickle\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmental sensing aws iot project environmental sensing ph various gases particulate matter sound capturing images multipart project demonstrate environmental monitoring using several types sensors aws services first part focuses building hardware monitoring environmental parameters co2 particulate matter sound capturing images project used environmental monitoring several use cases industrial manufacturing distribution warehouses etc first version environmental sensor box software along capable following features sense temperature humidity pressure co2 tvoc proximity range publish aws iot core capture upload images amazon s3 bucket project also uses aws systems manager enable remote access raspberry pi use aws iot rules log data amazon elasticsearch service second version project retains temperature humidity pressure co2 tvoc proximity replaces camera range sensor ph sensor atlas scientific smaller enclosure source code remains applications ph ph sensor used monitor several industrial agricultural parameters dough fermentation soil ph different crops plants need specific levels ph soil hardware mechanical list shelf hardware used build environmental sensing unit raspberry pi zero w sparkfun qwiic kit raspberry pi ultrasonic range finder hrxlmaxsonarvr unit supports camera raspberry pi capture images load aws s3 camera used arducam lens board sku b0031 could use compatible camera well information ph sensor ph reading circuit smaller enclosure atlas scientific spear tip ph probe ezo ph circuit ezo carrier board smaller enclosure please note code tested earlier version spear tip probe ezo circuits however new probe circuit work fine also important note default carrier board uart mode reprogrammed support i2c mode used project carrier board interfaces qwiic cable qwiic hat baseplate designed 3d printed house components following case bought amazoncom universal project enclosure image assembled unit first iteration support pm25 particulate matter 25 sensing see sensor pms7003 camera image image version ph support architecture high level architecture first iterationpart project configure setup aws iot read setting aws iot create thing created thing raspberry pi make sure keys present ' keys ' subfolder also copy sampleenv file env provide specifics need logging data aws iot core prior logging data take sampleenv file copy env make sure al parameters set correctly run script rpiqwiicawsiotpy read sensor data log aws iot core script calls two helper modules imagecapturepy capture image using hte picamera package upload s3 note s3 bucket name specified env file ultrasonicpy script reads value range finder sensor connected two flags used control import execution modules s3enable ultraenable env file want exclude one set flag emptry string module included set ' true ' see example s3enable ' true ' ultraenable ' ' env file configured correctly start tbe execution follows python3 rpiqwiicawsiotpy want run program background ensure keeps running disconnect remote session raspberry pi execute following nohup python3 u rpiqwiicawsiotpy outputlog go test secion aws iot console subscribe topic using topic used testing following telemetrythingname sample output unit timestamp 1583361438 time 03042020 173717 tempc 2763 tempf 81752 humidity 34475 pressure 106863 tvoc 0 co2 400 proximity 2556 ambient 128 image pzb827ebed3f9a1583361438 data using ultrasonic sensor readings data packet also provides image captured filename used store s3 bucket storing data amazon elasticsearch use amazon elasticsearch store transformed data later use visualization setup amazon elasticsearch region used create iot thing elasticsearch setup go aws iot console setup iot rule see image setup specific iot rule used transform incoming packets select topic2 thingname timestamp parsetimeyyyymmdd ' ' hhmmsszz timestamp americanewyork ts tempf tempc humidity pressure co2 ambient tvoc proximity ' telemetry ' rule minor transformation incoming data message output look follows thingname pzb827ebed3f9a timestamp 1583361502 ts 20200304t1738260500 tempf 82058 tempc 2781 humidity 34288 pressure 106548 co2 400 ambient 125 tvoc 0 proximity 2555\n",
      "[1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0\n",
      " 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1\n",
      " 1 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 1 0\n",
      " 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 1 0 1 1 0 0 1 0]\n",
      "ecosiapluginreact easy use tool makes planting trees even easier boilerplate code making search extension ecosia forked kryptokinght ' reactextensionboilerplate allows developers easily create cool features like duckduckgo ' password generation feature info google ' timer feature react example plugin echos hello world search ecosia possibilities truly endless idea cool new features help reel new users ecosia new ecosia users trees planted installation clone repo git clone gitgithubcomnbennett320ecosiapluginreactgit sure seems work cd ecosiapluginreact install dependencies yarn yarn install usage open development window firefox yarn run startfirefox open development window chrome yarn run startchrome build files ' extension ' yarn run build compress build folder manifestnamezip crx npm run build npm run compress options info details found kryptokinght ' repo\n",
      "[0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 1 1 0 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "environmentalimpacttools environmental impact tools provide analysis reporting tools scientists planners analysts understand potential impact development projects natural environment environmental impact tools leverage core arcgis platform help organizations analysis reporting workflows features github repository houses environmental analysis toolset used analyze data report results toolset includes following tools basic proximity analysis distance analysis feature comparison analysis analysis summary impact report requirements start using tools downloading repository zip file unzipping suitable location clone repository git tool requirements using tools include arcgis pro 131 information requirements use tools see environmental analysis help resources learn esri ' arcgis state government maps apps show list state government github repositories additional information sample data available tools issues find bug want request new feature please let us know submitting issue contributing esri welcomes contributions anyone everyone please see guidelines contributing licensing copyright 2016 esri licensed apache license version 20 license may use file except compliance license may obtain copy license httpwwwapacheorglicenseslicense20 unless required applicable law agreed writing software distributed license distributed basis without warranties conditions kind either express implied see license specific language governing permissions limitations license copy license available repository ' licensetxt file esri tags arcgissolutions stategovernment state government environmental analysis impact report esri language python\n",
      "[0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0]\n",
      "environmentalsetupitmo544444fall2015 environmental setup itmo544444fall2015\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "noisecapture app noisecapture app android app dedicated measurement environmental noise description noisecapture app android app project measuring environmental noise using smartphone goal produce relevant noise indicators audio measurements including geospatial representation measurements shared community order produce participatory noise maps noisecapture app component global infrastructure ie spatial data infrastructure sdi called onomap sdi allows process represent geospatial information like noise maps full description whole onomap sdi including noisecapture app given wiki pages user guide use noisecapture app proposed within noisecapture app see ' help ' page menu noisecapture app features noisecapture app features divided 3 parts measurement sound level calibration done user start measurement order record second laeq average sound energy period 1s spectrum repartition sound analysed stored using fourrier transform device location recorded measuring sound level user hability provide feedback feeling noise environment extented report advanced statistics computed locally phone shown user user ' measurement locations noise levels displayed map share results community anonymous results transfered virtual hubs web server postprocessed order build noise map merge community results participative noise maps displayed within noisecapture app online httpsonomapnoiseplanetorg developments noisecapture app collaboration environmental acoustic research unit ifsttar labsticc cnrs need information project developped environmental acoustic research unit labsticc topic go httpwwwnoiseplanetorg funding application developed initial funding european project energicod help geopal program license noisecapture app released general public license version 3 please refer gplv3 details follow us follow developement noisecapture app twitter noiseplanet\n",
      "[0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0\n",
      " 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0]\n",
      "atmos 6910 fall 2018 environmental programming atmospheric science university utah fall semester 2018 second half mwf 940am1030am wbb711 instructor email phone number office hours office location chris galli chrisgalliutahedu 8016472263 appointment 482 inscc sally benson sallybensonutahedu 8018591644 appointment 603 wbb copy syllabus found course description environmental scientists need ability acquire process display environmental data imagery gridded fields course designed develop skills necessary solve physicallybased problems relating atmospheric science data sets review basic programming concepts students develop code solve problems using programming languages data sources relevant ongoing future research course particularly relevant firstyear graduate students begin research leading towards thesis proposal assumed students exposure practical experience working common programming language used within physical sciences python matlab idl requirement using one language another however important student comfortable working language available moduleapi bindings common data libraries specifically netcdf4 hdf csv parsing course outcomes end course able write computer programs analyzing data acquire use data multiple file formats create custom ways display data check chpc ' intro python series ongoing class links october 15 lecture 1 introduction october 17 lecture 2 data types idl example file lecture02variablesdatatypespro homework assignment 1 october 19 lecture 3 basic programs arrays october 22 lecture 4 io part supplemental slides october 24 lecture 6 io netcdf hdf october 26 lecture 6 io part ii supplemental slides example06py october 29 lecture 7 final project review october 31 lecture 8 basic control structures november 2 lecture 9 arrays part homework assignment 2 november 5 lecture 10 code design arrays november 7 project reviews approach discussions questions homework assignment 3 november 9 lecture 11 arrays part ii november 12 lecture 12 optimization november 14 lecture 13 numerical applications november 16 lecture 14 intro debugging debug exercise\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1]\n",
      "environmentallogger log environmental data temperature pressure humidity ambient light using tessel 2 data streamed using socketio dygraphs bme280 pins 0 1 photoresistor pin 7 port\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "elite dangerous immersion toolkit elite dangerous immersion toolkit edit application integrates elite dangerous commander log provides way external actions trigger events log started looks current game log list event methods provided actions based events log example get heatwarning event trigger environmental effects set timestamp20171105t211328z eventheatwarning also provides way create environmental schemes ambient light currently app ships star colours could extended include things like star system economy types currently implemented plugin philips hue light control features added play sounds trigger webhooks create streaming endpoints write another file better api endpoint behind token based authentication better docs create tool started experiment philips hue api integrating game events started experiment using light triggering certain events got working realised could add outputs app playing additional sound triggering webhook peripheral network service app built nodejs 8 uses asyncawait code achive well structured layout writing light recipies installing currently application alpha software yet available via npm binary require node 8 run installing node also need run npm install g windowsbuildtools install required build tools done clone repo git clone httpsgithubcomedittoolkitgit edit cd edit npm install npm start running go httplocalhost12342hubs click manage hubs find available hubs network select one want use client next go httplocalhost12342settings enter username associated hub docs soon also need enter location elite dangerous logs windows usually cusersusernamedocumentssave gamesfrontier developmentselite dangerous thanks millstonebarn name suggestion\n",
      "[0 1 0 0 1 1 1 1 1 1 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0\n",
      " 1 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1]\n",
      "environmentalissues\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "httpenvironmentalcomputingnet\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmentalissues\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "environmentalproject\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "esc50 dataset environmental sound classification overview download results repository content license citing caveats changelog esc50 dataset labeled collection 2000 environmental audio recordings suitable benchmarking methods environmental sound classification dataset consists 5secondlong recordings organized 50 semantical classes 40 examples per class loosely arranged 5 major categories animals natural soundscapes water sounds human nonspeech sounds interiordomestic sounds exteriorurban noises dog rain crying baby door knock helicopter rooster sea waves sneezing mouse click chainsaw pig crackling fire clapping keyboard typing siren cow crickets breathing door wood creaks car horn frog chirping birds coughing opening engine cat water drops footsteps washing machine train hen wind laughing vacuum cleaner church bells insects flying pouring water brushing teeth clock alarm airplane sheep toilet flush snoring clock tick fireworks crow thunderstorm drinking sipping glass breaking hand saw clips dataset manually extracted public field recordings gathered freesoundorg project dataset prearranged 5 folds comparable crossvalidation making sure fragments original source file contained single fold thorough description dataset available original paper supplementary materials github esc dataset environmental sound classification paper replication data download dataset downloaded single zip file 600 mb download esc50 dataset results numerous machine learning signal processing approaches evaluated esc50 dataset listed know reference message open pull request directly terms used table cnn convolutional neural network crnn convolutional recurrent neural network gmm gaussian mixture model gtcc gammatone cepstral coefficients gtsc gammatone spectral coefficients knn kneareast neighbors mfcc melfrequency cepstral coefficients mlp multilayer perceptron rbm restricted boltzmann machine rnn recurrent neural network svm support vector machine teo teager energy operator zcr zerocrossing rate title notes accuracy paper code unsupervised filterbank learning using convolutional restricted boltzmann machine environmental sound classification cnn filterbanks learned using convolutional rbm fusion gtsc mel energies 8650 sailor2017 learning betweenclass examples deep sound recognition envnetv2 tokozume2017a data augmentation betweenclass learning 8490 tokozume2017b novel phase encoded mel filterbank energies environmental sound classification cnn working phase encoded mel filterbank energies pefbes fusion mel energies 8415 tak2017 knowledge transfer weakly labeled audio using convolutional neural network sound events scenes cnn pretrained audioset 8350 kumar2017 unsupervised filterbank learning using convolutional restricted boltzmann machine environmental sound classification cnn filterbanks learned using convolutional rbm fusion gtsc 8300 sailor2017 deep multimodal clustering unsupervised audiovisual learning cnn unsupervised audiovisual learning 8260 hu2019 novel teobased gammatone features environmental sound classification fusion gtsc teogtsc cnn 8195 agrawal2017 learning betweenclass examples deep sound recognition envnetv2 tokozume2017a betweenclass learning 8180 tokozume2017b human accuracy crowdsourcing experiment classifying esc50 human listeners 8130 piczak2015a objects sound look listen learn l3 network arandjelovic2017a stride 2 larger batches learning rate schedule 7980 arandjelovic2017b look listen learn 8layer convolutional subnetwork pretrained audiovisual correspondence task 7930 arandjelovic2017a learning environmental sounds multiscale convolutional neural network multiscale convolutions feature fusion waveform spectrogram 7910 zhu2018 novel teobased gammatone features environmental sound classification gtsc cnn 7910 agrawal2017 learning betweenclass examples deep sound recognition envnetv2 tokozume2017a data augmentation 7880 tokozume2017b unsupervised filterbank learning using convolutional restricted boltzmann machine environmental sound classification cnn filterbanks learned using convolutional rbm 7845 sailor2017 learning betweenclass examples deep sound recognition baseline cnn piczak2015b batch normalization betweenclass learning 7690 tokozume2017b novel teobased gammatone features environmental sound classification teogtsc cnn 7485 agrawal2017 learning betweenclass examples deep sound recognition envnetv2 tokozume2017a 7440 tokozume2017b soundnet learning sound representations unlabeled video 8layer cnn raw audio transfer learning unlabeled videos 7420 aytar2016 learning betweenclass examples deep sound recognition 18layer cnn raw waveforms dai2016 betweenclass learning 7330 tokozume2017b novel phase encoded mel filterbank energies environmental sound classification cnn working phase encoded mel filterbank energies pefbes 7325 tak2017 classifying environmental sounds using image recognition networks 16 khz sampling rate googlenet spectrograms 40 ms frame length 7320 boddapati2017 learning betweenclass examples deep sound recognition baseline cnn piczak2015b batch normalization 7240 tokozume2017b novel teobased gammatone features environmental sound classification fusion mfcc teogtcc gmm 7225 agrawal2017 learning environmental sounds endtoend convolutional neural network envnet combination spectrogram raw waveform cnn 7100 tokozume2017a novel teobased gammatone features environmental sound classification teogtcc gmm 6885 agrawal2017 classifying environmental sounds using image recognition networks 16 khz sampling rate alexnet spectrograms 30 ms frame length 6870 boddapati2017 deep convolutional neural networks raw waveforms 18layer cnn raw waveforms 6850 dai2016 tokozume2017b classifying environmental sounds using image recognition networks 32 khz sampling rate googlenet spectrograms 30 ms frame length 6780 boddapati2017 wsnet learning compact efficient networks weight sampling soundnet 8layer cnn architecture 100x model compression 6625 jin2017 soundnet learning sound representations unlabeled video 5layer cnn raw audio transfer learning unlabeled videos 6610 aytar2016 wsnet learning compact efficient networks weight sampling soundnet 8layer cnn architecture 180x model compression 6580 jin2017 soundnet learning sound representations unlabeled video 5layer cnn trained raw audio esc50 6500 aytar2016 environmental sound classification convolutional neural networks cnn baseline cnn 2 convolutional 2 fullyconnected layers melspectrograms input vertical filters first layer 6450 piczak2015b audeep unsupervised learning representations audio deep recurrent neural networks mlp classifier features extracted rnn autoencoder 6430 freitag2017 classifying environmental sounds using image recognition networks 32 khz sampling rate alexnet spectrograms 30 ms frame length 6320 boddapati2017 classifying environmental sounds using image recognition networks crnn 6030 boddapati2017 comparison timefrequency representations environmental sound classification using convolutional neural networks 3layer cnn vertical filters wideband melstft median accuracy 5637 huzaifah2017 comparison timefrequency representations environmental sound classification using convolutional neural networks 3layer cnn square filters wideband melstft median accuracy 5400 huzaifah2017 soundnet learning sound representations unlabeled video 8layer cnn trained raw audio esc50 5110 aytar2016 comparison timefrequency representations environmental sound classification using convolutional neural networks 5layer cnn square filters wideband melstft median accuracy 5087 huzaifah2017 comparison timefrequency representations environmental sound classification using convolutional neural networks 5layer cnn vertical filters wideband melstft median accuracy 4625 huzaifah2017 baseline random forest baseline ml approach mfcc zcr random forest 4430 piczak2015a soundnet learning sound representations unlabeled video convolutional autoencoder trained unlabeled videos 3990 aytar2016 baseline svm baseline ml approach mfcc zcr svm 3960 piczak2015a baseline knn baseline ml approach mfcc zcr knn 3220 piczak2015a mixture modelbased realtime audio sources classification method dictionary sound models used classification accuracy computed segments instead files 9400 baelde2017 nels neverending learner sounds largescale audio crawling classifiers trained aed datasets including esc50 na elizalde2017 utilizing domain knowledge endtoend audio processing endtoend cnn learned melspectrogram transformation na tax2017 deep neural network based learning transferring midlevel audio features acoustic scene classification transfer learning various datasets including esc50 na mun2017 features kernels audio event recognition mfcc gmm svm na kumar2016b realtime environmental sound recognition system android os realtime sound recognition android evaluated esc10 na pillos2016 comparing time frequency domain audio event recognition using deep learning discriminatory effectiveness different signal representations compared esc10 freiburg106 na hertel2016 audio event scene recognition unified approach using strongly weakly labeled data combination weakly labeled data youtube strong labeling esc10 acoustic event detection na kumar2016a repository content audiowav 2000 audio recordings wav format 5 seconds 441 khz mono following naming convention foldclipidtaketargetwav fold index crossvalidation fold clipid id original freesound clip take letter disambiguating different fragments freesound clip target class numeric format 0 49 metaesc50csv csv file following structure filename fold target category esc10 srcfile take esc10 column indicates given file belongs esc10 subset 10 selected classes cc license metaesc50humanxlsx additional data pertaining crowdsourcing experiment human classification accuracy license dataset available terms creative commons attribution noncommercial license smaller subset clips tagged esc10 distributed cc attribution attributions clip available license file citing find dataset useful academic setting please cite k j piczak esc dataset environmental sound classification proceedings 23rd annual acm conference multimedia brisbane australia 2015 doi httpdxdoiorg10114527333732806390 inproceedingspiczak2015dataset title esc dataset environmental sound classification author piczak karol j booktitle proceedings 23rd annual acm conference multimedia date 20151013 url httpdlacmorgcitationcfmdoid27333732806390 doi 10114527333732806390 location brisbane australia isbn 9781450334594 publisher acm press pages 10151018 caveats please aware potential information leakage training models esc50 original freesound recordings already preprocessed manner might class dependent mostly bandlimiting unfortunately issue went unnoticed creating original version dataset due number methods already evaluated esc50 changes rectifying issue made order preserve comparability changelog v200 20171213 change wav version default v200pre 20161010 wavfiles branch replace ogg recordings cropped wav files easier loading framelevel precision ogg recordings slightly different length loaded move recordings one directory structure meta csv file v100 20150415 initial version dataset ogg format\n",
      "[0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 1 1\n",
      " 0 1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1]\n",
      "image dehazing via joint estimation transmittance map environmental illumination input transmittance map dehazed image haze limits visibility outdoor images due existence fog smoke dust atmosphere work present end end system takes hazy image input returns dehazed image proposed method learns mapping hazy image corresponding transmittance map environmental illumination using multiscale convolutional neural network repository contains python implementation authors sanchayan santra ranjan mondal pranoy panda nishant mohanty shubham bhuyan paper httpsarxivorgabs181201273 conference 9th international conference advances pattern recognition icapr 2017 requirements python 27 35 tensorflow requirements numpy pip work scikitimage keras scipy matplolib folders files important using proposed dehazing network new project finalcodepy networkpy weightsh5 important retraining proposed dehazing network new data preprocesspy helperfunctionspy running program python srcfinalassemblyfinalcodepy pathtohazzyimage example running mountain image python srcfinalassemblyfinalcodepy resultsmountaininputpng license citation software released lgpl please cite paper publications helps research inproceedingssantra2017image titleimage dehazing via joint estimation transmittance map environmental illumination authorsantra sanchayan mondal ranjan panda pranoy mohanty nishant bhuyan shubham booktitle2017 ninth international conference advances pattern recognition icapr pages16 year2017 organizationieee\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      "softwareengineering progetto\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Show sentences and vector space representation.\n",
    "# purely to visualize what's happening.\n",
    "for i, v in zip(X_train.clean, bow_array):\n",
    "    print(i)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow = bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<234x142 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4862 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english', min_df=20, \n",
    "                             ngram_range=(1,2), \n",
    "                             binary=True)\n",
    "\n",
    "tfidf_sparse_matrix = tfidf.fit_transform(X_train.clean)\n",
    "tfidf_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>access</th>\n",
       "      <th>add</th>\n",
       "      <th>allows</th>\n",
       "      <th>analysis</th>\n",
       "      <th>api</th>\n",
       "      <th>app</th>\n",
       "      <th>application</th>\n",
       "      <th>available</th>\n",
       "      <th>based</th>\n",
       "      <th>build</th>\n",
       "      <th>...</th>\n",
       "      <th>uses</th>\n",
       "      <th>using</th>\n",
       "      <th>value</th>\n",
       "      <th>values</th>\n",
       "      <th>version</th>\n",
       "      <th>want</th>\n",
       "      <th>way</th>\n",
       "      <th>web</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156506</td>\n",
       "      <td>0.179983</td>\n",
       "      <td>0.200383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175979</td>\n",
       "      <td>0.186493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200548</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.146907</td>\n",
       "      <td>0.149583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212915</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows Ã— 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     access       add  allows  analysis  api  app  application  available  \\\n",
       "0       0.0  0.276654     0.0       0.0  0.0  0.0          0.0   0.000000   \n",
       "1       0.0  0.000000     0.0       0.0  0.0  0.0          0.0   0.000000   \n",
       "2       0.0  0.000000     0.0       0.0  0.0  0.0          0.0   0.000000   \n",
       "3       0.0  0.000000     0.0       0.0  0.0  0.0          0.0   0.000000   \n",
       "4       0.0  0.000000     0.0       0.0  0.0  0.0          0.0   0.000000   \n",
       "..      ...       ...     ...       ...  ...  ...          ...        ...   \n",
       "229     0.0  0.000000     0.0       0.0  0.0  0.0          0.0   0.000000   \n",
       "230     0.0  0.000000     0.0       0.0  0.0  0.0          0.0   0.000000   \n",
       "231     0.0  0.000000     0.0       0.0  0.0  0.0          0.0   0.146907   \n",
       "232     0.0  0.000000     0.0       0.0  0.0  0.0          0.0   0.000000   \n",
       "233     0.0  0.000000     0.0       0.0  0.0  0.0          0.0   0.000000   \n",
       "\n",
       "        based     build  ...  uses     using  value  values   version  \\\n",
       "0    0.000000  0.000000  ...   0.0  0.200326    0.0     0.0  0.000000   \n",
       "1    0.000000  0.000000  ...   0.0  0.117245    0.0     0.0  0.156506   \n",
       "2    0.175979  0.186493  ...   0.0  0.000000    0.0     0.0  0.000000   \n",
       "3    0.000000  0.000000  ...   0.0  0.000000    0.0     0.0  0.000000   \n",
       "4    0.000000  0.000000  ...   0.0  0.000000    0.0     0.0  0.000000   \n",
       "..        ...       ...  ...   ...       ...    ...     ...       ...   \n",
       "229  0.000000  0.000000  ...   0.0  0.000000    0.0     0.0  0.000000   \n",
       "230  0.000000  0.000000  ...   0.0  0.000000    0.0     0.0  0.000000   \n",
       "231  0.149583  0.000000  ...   0.0  0.105442    0.0     0.0  0.140751   \n",
       "232  0.000000  0.000000  ...   0.0  0.156853    0.0     0.0  0.000000   \n",
       "233  0.000000  0.000000  ...   0.0  0.000000    0.0     0.0  0.000000   \n",
       "\n",
       "         want       way  web      work   working  \n",
       "0    0.000000  0.000000  0.0  0.000000  0.000000  \n",
       "1    0.179983  0.200383  0.0  0.000000  0.000000  \n",
       "2    0.000000  0.000000  0.0  0.000000  0.000000  \n",
       "3    0.000000  0.000000  0.0  0.200548  0.000000  \n",
       "4    0.000000  0.000000  0.0  0.000000  0.000000  \n",
       "..        ...       ...  ...       ...       ...  \n",
       "229  0.000000  0.000000  0.0  0.000000  0.000000  \n",
       "230  0.000000  0.000000  0.0  0.000000  0.000000  \n",
       "231  0.000000  0.000000  0.0  0.000000  0.175556  \n",
       "232  0.000000  0.000000  0.0  0.212915  0.000000  \n",
       "233  0.000000  0.000000  0.0  0.000000  0.000000  \n",
       "\n",
       "[234 rows x 142 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf_sparse_matrix.todense(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 26,\n",
       " 'code': 15,\n",
       " 'user': 131,\n",
       " 'instructions': 61,\n",
       " 'using': 133,\n",
       " 'repository': 98,\n",
       " 'github': 51,\n",
       " 'clone': 14,\n",
       " 'local': 67,\n",
       " 'add': 1,\n",
       " 'git': 49,\n",
       " 'update': 127,\n",
       " 'files': 45,\n",
       " 'environmental': 41,\n",
       " 'program': 89,\n",
       " 'want': 137,\n",
       " 'read': 97,\n",
       " 'tool': 125,\n",
       " 'installation': 59,\n",
       " 'need': 76,\n",
       " 'install': 58,\n",
       " 'dependencies': 29,\n",
       " 'source': 116,\n",
       " 'directory': 36,\n",
       " 'simple': 114,\n",
       " 'cd': 10,\n",
       " 'make': 70,\n",
       " 'run': 104,\n",
       " 'help': 52,\n",
       " 'page': 85,\n",
       " 'version': 136,\n",
       " 'way': 138,\n",
       " 'note': 79,\n",
       " 'folder': 46,\n",
       " 'number': 80,\n",
       " 'example': 42,\n",
       " 'output': 84,\n",
       " 'file': 44,\n",
       " 'time': 124,\n",
       " 'license': 63,\n",
       " 'free': 48,\n",
       " 'software': 115,\n",
       " 'public': 95,\n",
       " 'details': 32,\n",
       " 'copy': 21,\n",
       " 'open': 82,\n",
       " 'interface': 62,\n",
       " 'based': 8,\n",
       " 'requirements': 101,\n",
       " 'test': 123,\n",
       " 'development': 34,\n",
       " 'environment': 40,\n",
       " 'information': 56,\n",
       " 'documentation': 37,\n",
       " 'usage': 128,\n",
       " 'python': 96,\n",
       " 'line': 65,\n",
       " 'set': 112,\n",
       " 'use': 129,\n",
       " 'sudo': 119,\n",
       " 'build': 9,\n",
       " 'pip': 86,\n",
       " 'git clone': 50,\n",
       " 'pip install': 87,\n",
       " 'model': 72,\n",
       " 'new': 78,\n",
       " 'needs': 77,\n",
       " 'different': 35,\n",
       " 'like': 64,\n",
       " 'designed': 31,\n",
       " 'change': 11,\n",
       " 'including': 55,\n",
       " 'order': 83,\n",
       " 'work': 140,\n",
       " 'developed': 33,\n",
       " 'class': 13,\n",
       " 'config': 17,\n",
       " 'app': 5,\n",
       " 'configuration': 18,\n",
       " 'application': 6,\n",
       " 'value': 134,\n",
       " 'api': 4,\n",
       " 'process': 88,\n",
       " 'provides': 94,\n",
       " 'tools': 126,\n",
       " 'control': 20,\n",
       " 'module': 73,\n",
       " 'available': 7,\n",
       " 'multiple': 75,\n",
       " 'features': 43,\n",
       " 'access': 0,\n",
       " 'running': 105,\n",
       " 'used': 130,\n",
       " 'start': 118,\n",
       " 'project': 90,\n",
       " 'following': 47,\n",
       " 'specific': 117,\n",
       " 'default': 28,\n",
       " 'current': 25,\n",
       " 'create': 22,\n",
       " 'server': 110,\n",
       " 'list': 66,\n",
       " 'look': 69,\n",
       " 'script': 106,\n",
       " 'end': 39,\n",
       " 'service': 111,\n",
       " 'created': 23,\n",
       " 'database': 27,\n",
       " 'location': 68,\n",
       " 'web': 139,\n",
       " 'sure': 121,\n",
       " 'installed': 60,\n",
       " 'required': 100,\n",
       " 'description': 30,\n",
       " 'request': 99,\n",
       " 'make sure': 71,\n",
       " 'analysis': 3,\n",
       " 'allows': 2,\n",
       " 'results': 103,\n",
       " 'input': 57,\n",
       " 'object': 81,\n",
       " 'contains': 19,\n",
       " 'search': 107,\n",
       " 'creating': 24,\n",
       " 'command': 16,\n",
       " 'download': 38,\n",
       " 'image': 53,\n",
       " 'provide': 92,\n",
       " 'check': 12,\n",
       " 'uses': 132,\n",
       " 'support': 120,\n",
       " 'research': 102,\n",
       " 'include': 54,\n",
       " 'monitoring': 74,\n",
       " 'projects': 91,\n",
       " 'sensors': 109,\n",
       " 'temperature': 122,\n",
       " 'sensor': 108,\n",
       " 'values': 135,\n",
       " 'working': 141,\n",
       " 'provided': 93,\n",
       " 'setup': 113}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get vocabularies.\n",
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.27665357, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.17555646],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.21291492,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform to document-term matrix\n",
    "vector_spaces = tfidf.transform(X_train.clean)\n",
    "vector_spaces.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environmentaldataanalytics data analytics course duke university course code env 872l user kateri salk instructions using repository fork repository github account clone forked repository onto local drive pull updates repository add repository upstream remote git remote add upstream httpsgithubcomkaterisalkenvironmentaldataanalytics verify repository upstream remote git remote v repository listed origin repository listed upstream pull updates repository git pull upstream master git fetch upstream git merge upstreammaster conflict arises merge update files liking stage commit testing merge error taylor\n",
      "  (0, 133)\t0.20032584697705205\n",
      "  (0, 131)\t0.2791028227330898\n",
      "  (0, 127)\t0.34710454361729953\n",
      "  (0, 98)\t0.247413767015319\n",
      "  (0, 67)\t0.3293833913226699\n",
      "  (0, 61)\t0.3215611267079073\n",
      "  (0, 51)\t0.32539702637573514\n",
      "  (0, 49)\t0.28161256203573326\n",
      "  (0, 45)\t0.23384173274879666\n",
      "  (0, 26)\t0.19053482266623098\n",
      "  (0, 15)\t0.22767988999020847\n",
      "  (0, 14)\t0.28953651678151426\n",
      "  (0, 1)\t0.2766535650016892\n",
      "minced mining crisprs environmental datasets minced program find clustered regularly interspaced short palindromic repeats crisprs full genomes environmental datasets assembled contigs metagenomes iff want identify crisprs raw short read data size range 100200bp try using crass httpsgithubcomctskennertoncrass minced runs commandline derived crt httpwwwroom220comcrt charles bland et al crispr recognition tool crt tool automatic detection clustered regularly interspaced palindromic repeats bmc bioinformatics 8 1 2007 209 installation need install dependencies first java httpwwwjavacomendownload makefile source directory installation simple cd downloadfolder make run minced minced options filefa help page obtained typing minced help get minced version way minced version note always keep minced mincedjar folder examples finding crisprs e coli genome minced ecolifna find repeats short sequences need decrease minimum number repeats find example 100 bp reads could possibly find 2 repeats minced minnr 2 metagenomefna output large save file minced minnr 2 metagenomefna metagenomecrisprs also save table output gff output time minced ecolifna outtxt outgff copyright license copyright 2011 florent angly florentanglygmailcom 20132019 connor skennerton cskennertongmailcom minced free software redistribute andor modify terms gnu general public license published free software foundation either version 3 license option later version minced distributed hope useful without warranty without even implied warranty merchantability fitness particular purpose see gnu general public license details received copy gnu general public license along minced see httpwwwgnuorglicenses bugs complex software bugs lurking program exception find bug please post issue github httpsgithubcomctskennertonmincedissues\n",
      "  (0, 138)\t0.2003831116561402\n",
      "  (0, 137)\t0.17998250073418773\n",
      "  (0, 136)\t0.1565058719380452\n",
      "  (0, 133)\t0.1172450271071053\n",
      "  (0, 125)\t0.1952071022787805\n",
      "  (0, 124)\t0.15397414596208742\n",
      "  (0, 116)\t0.16191747204551216\n",
      "  (0, 115)\t0.16335095301386288\n",
      "  (0, 114)\t0.1977388282547383\n",
      "  (0, 104)\t0.12822454140917047\n",
      "  (0, 97)\t0.18193305520517364\n",
      "  (0, 95)\t0.2003831116561402\n",
      "  (0, 89)\t0.2003831116561402\n",
      "  (0, 85)\t0.1762633784170012\n",
      "  (0, 84)\t0.17809387920122638\n",
      "  (0, 80)\t0.17448752768861728\n",
      "  (0, 79)\t0.1678710948697007\n",
      "  (0, 76)\t0.15781332196603468\n",
      "  (0, 70)\t0.13971682721918066\n",
      "  (0, 63)\t0.16632590197819203\n",
      "  (0, 59)\t0.16335095301386288\n",
      "  (0, 58)\t0.13779773880637317\n",
      "  (0, 52)\t0.18193305520517364\n",
      "  (0, 51)\t0.190445635217331\n",
      "  (0, 48)\t0.1927787413707058\n",
      "  (0, 46)\t0.18193305520517364\n",
      "  (0, 44)\t0.13325457137192417\n",
      "  (0, 42)\t0.15781332196603468\n",
      "  (0, 41)\t0.08310218824840138\n",
      "  (0, 36)\t0.1678710948697007\n",
      "  (0, 32)\t0.18603720528465115\n",
      "  (0, 29)\t0.18603720528465115\n",
      "  (0, 26)\t0.11151461873468971\n",
      "  (0, 21)\t0.190445635217331\n",
      "  (0, 10)\t0.1762633784170012\n",
      "open simulation interface osi open simulation interface 1 osi generic interface based google ' protocol buffers environmental perception automated driving functions virtual scenarios complexity automated driving functions rapidly increases requirements test development methods growing testing virtual environments offers advantage completely controlled reproducible environment conditions context osi defines generic interfaces ensure modularity integrability interchangeability individual components information osi see official documentation official reference documentation defined protobuf messages 1 hanke hirsenkorn n vandriesten c garciaramos p schiementz schneider biebl e 2017 february 03 generic interface environment perception automated driving functions virtual scenarios retrieved january 25 2020 httpswwwhoteitumdeforschungautomotiveveroeffentlichungen usage example writing reading osi message python osi3osisensorviewpb2 import sensorview osi3osisensordatapb2 import sensordata def main initialize sensorview sensordata sensorview sensorview sensordata sensordata clear sensordata sensordataclear get boundary line attributes sensorview svgroundtruth sensorviewglobalgroundtruth svlaneboundary svgroundtruthlaneboundaryadd svboundaryline svlaneboundaryboundarylineadd svboundarylinepositionx 169920 svboundarylinepositiony 10016 svboundarylinepositionz 00 svboundarylinewidth 013 svboundarylineheight 00 set boundary line attributes sensordata sdlaneboundary sensordatalaneboundaryadd sdboundaryline sdlaneboundaryboundarylineadd sdboundarylinepositionx svboundarylinepositionx sdboundarylinepositiony svboundarylinepositiony sdboundarylinepositionz svboundarylinepositionz sdboundarylinewidth svboundarylinewidth sdboundarylineheight svboundarylineheight serialize sensordata send stringbuffer sensordataserializetostring clear sensordata show parsing string sensordataclear received string buffer parsed sensordataparsefromstringstringbuffer print sensordata printsensordata name main main output laneboundary boundaryline position x 16992 10016 z 00 width 013 height 00 see google ' documentation tutorials use protocol buffers python c installation dependencies install cmake 3102 sudo aptget install cmake install pip3 missing python packages sudo aptget install python3pip python3setuptools install protobuf 300 sudo aptget install libprotobufdev protobufcompiler build install c usage git clone httpsgithubcomopensimulationinterfaceopensimulationinterfacegit cd opensimulationinterface mkdir build cd build cmake make sudo make install install python usage local git clone httpsgithubcomopensimulationinterfaceopensimulationinterfacegit cd opensimulationinterface sudo pip3 install virtualenv virtualenv p python3 venv source venvbinactivate python3 pip install global git clone httpsgithubcomopensimulationinterfaceopensimulationinterfacegit cd opensimulationinterface sudo pip3 install windows installation see information\n",
      "  (0, 129)\t0.12920549851467236\n",
      "  (0, 128)\t0.1846144598613694\n",
      "  (0, 123)\t0.19912340509121976\n",
      "  (0, 119)\t0.21494090207767297\n",
      "  (0, 116)\t0.1713148615249171\n",
      "  (0, 112)\t0.15667383005066132\n",
      "  (0, 101)\t0.19912340509121976\n",
      "  (0, 96)\t0.1543424867720994\n",
      "  (0, 87)\t0.2092152227465484\n",
      "  (0, 86)\t0.20396726162811682\n",
      "  (0, 84)\t0.18843011732061596\n",
      "  (0, 82)\t0.1713148615249171\n",
      "  (0, 70)\t0.14782573248813344\n",
      "  (0, 67)\t0.20396726162811682\n",
      "  (0, 65)\t0.20149874632498765\n",
      "  (0, 62)\t0.2092152227465484\n",
      "  (0, 59)\t0.17283153906742826\n",
      "  (0, 58)\t0.14579526374661445\n",
      "  (0, 56)\t0.16697251419413903\n",
      "  (0, 50)\t0.18843011732061596\n",
      "  (0, 49)\t0.17438566919798845\n",
      "  (0, 42)\t0.16697251419413903\n",
      "  (0, 41)\t0.08792528497598336\n",
      "  (0, 40)\t0.15320841875046384\n",
      "  (0, 37)\t0.190428350941144\n",
      "  (0, 34)\t0.190428350941144\n",
      "  (0, 29)\t0.19683445930321974\n",
      "  (0, 14)\t0.1792924962977762\n",
      "  (0, 10)\t0.1864933776691802\n",
      "  (0, 9)\t0.1864933776691802\n",
      "  (0, 8)\t0.175979148546685\n",
      "community water model cwatm iiasa 13rd october 2020 cwatm represents one new key elements iiasaas water program assess water supply water demand environmental needs global regional level hydrologic model open source flexible link different aspects water energy food nexus cwatm basis develop nextgeneration global hydroeconomic modeling coupled existing iiasa models like message globiom httpwwwiiasaacatcwatm model design processes included community water model cwatm designed purpose assess water availability water demand environmental needs includes accounting future water demands evolve response socioeconomic change water availability change response climate figure 1 schematic view cwatm processes modules hydrological processes eg snow soil groundwater etc located folder hydrologicalmodules kinematic routing c routines speeding computational time folder hydrologicalmodulesroutingreservoirs figure 2 schematic graph cwatm modules nextgeneration global hydroeconomic modeling framework community water model help develop nextgeneration hydroeconomic modeling tool represents economic tradeoffs among water supply technologies demands tool track water use sectors identify leastcost solutions meeting future water demands policy constraints addition tool track energy requirements associated water supply system eg desalination water conveyance facilitate linkage energyeconomic tool tool also incorporate environmental flow requirements ensure sufficient water environmental needs nexus framework iiasa nexus framework water energy food ecosystem cwatm coupled existing iiasa models including integrated assessment model message global land ecosystem model globiom order realize improved assessments waterenergyfoodecosystem nexus associated feedback figure 3 iiasa model nexus short medium vision vision short medium term work introduce water quality eg salinization deltas eutrophication associated mega cities cwatm consider qualitative quantitative measures transboundary river groundwater governance integrated modelling framework link full model documentation httpscwatmiiasaacat\n",
      "  (0, 140)\t0.20054768806536857\n",
      "  (0, 129)\t0.15388286525109968\n",
      "  (0, 125)\t0.24598363081990676\n",
      "  (0, 124)\t0.19402531482721402\n",
      "  (0, 116)\t0.20403482866138192\n",
      "  (0, 101)\t0.23715461389990833\n",
      "  (0, 89)\t0.2525060040580614\n",
      "  (0, 83)\t0.2244189812835596\n",
      "  (0, 82)\t0.20403482866138192\n",
      "  (0, 78)\t0.18247017912503477\n",
      "  (0, 77)\t0.2559931446540747\n",
      "  (0, 72)\t0.23998362906724485\n",
      "  (0, 64)\t0.197215583728997\n",
      "  (0, 55)\t0.2525060040580614\n",
      "  (0, 52)\t0.2292567891388236\n",
      "  (0, 46)\t0.2292567891388236\n",
      "  (0, 41)\t0.1047184131918915\n",
      "  (0, 37)\t0.22679886386210957\n",
      "  (0, 35)\t0.22679886386210957\n",
      "  (0, 31)\t0.2292567891388236\n",
      "  (0, 11)\t0.23179804961568898\n",
      "environmentalgame game developed ' environment sciences ' class universidade federal rio grande brazil\n",
      "  (0, 40)\t0.45969029601747263\n",
      "  (0, 33)\t0.6361289297145982\n",
      "  (0, 13)\t0.6196973588192289\n",
      "people feel shipping json yml xml config files upgrade using archaic environment variables ' let app load config inject instead unix environment vars ideal configuration yet encounter application ' better override value nearruntime without changebackup config files debug node runjs inject environment variables passwords api keys memory process belonging nonprivileged user source envsproductionsh sudo ehu wwwdata node runjs without run write software inherit inside stagingsh source productionsh inside kevinsh source developmentsh operating system aware provides tools inspect debug optionally pass processes etc directly use config across languages eg supporting bash scripts directly use config terminal eg cd myappdir type config groupsave files keep version control one downside environment variables little convention syntactic sugar highlevel languages ' feel atomic think ' likely let module attempts change environmental ' break 12factor get way environmental impose one way dealing environment variables make vars available nested format inside app eg myappredishost becomes configredishost 3 unix interpret multiple inherited bash environment files isolated environment capture prepare exporting nodejitsu heroku conventions layout environmental tree defaultsh developmentsh testsh productionsh stagingshsh disk envs defaultsh developmentsh productionsh stagingsh testsh could make superdry actually recommend using mainly developmentsh productionsh duplicate keys easily compare side side use defaultsh testsh stagingsh tweaks keep things clear read ' inheritance bitch ' see inheritance bitch one common pitfall reuse variables export mysqlhost127001 export mysqlurlmysqluserpassmysqlhostdbname extend override mysqlhost obviously mysqlurl remain unaware host change ergo duplication vars might lesser evil compared going way dry things inject features instead code make decisions based environment processenvnodeenv production install cronjobs keep responsibility environment files cat envsdefaultsh tlscronjobsinstall0 cat envsproductionsh tlscronjobsinstall1 configcronjobsinstall 1 install cronjobs mandatory unprefixed variables variables mandatory special meaning syntactic sugar access via processenvvar export nodeappprefixmyapp filter nest vars starting myapp right app export nodeenvproduction environment program thinks ' running export deployenvstaging machine actually running export debug used control debug levels per module getting way feel free start hacking prefixing vars myapp actual short abbreviation app name ' use underscore name example tls app name export nodeappprefixtls export tlsredishost127001 export tlsredisuserjane getting started new project type npm install save environmental install node module next ' want set example environment shown layout using templates cp ra nodemodulesenvironmentalenvs envs add envssh project ' gitignore file accidentally committed repository env files git convenient ' still protoyping go live ' want change credentials sync env files separately code accessing config inside app start app ways source envsdevelopmentsh node myappjs source envsproductionsh debug node myappjs source envsstagingsh following seems weird sudo preserve path regardless e sudo ehu wwwdata env pathpath node myappjs source envsdevelopmentsh node myappjs start myapp see upstart example inside app obviously already access processenvmyappredishost environmental also provides syntactic sugar could type configredishost instead ' var config require ' environmental ' config consolelogconfig return redis host ' 127001 ' coffeescript ' cup tea config requireenvironmentalconfig redisclient rediscreateclientconfigredisport configredishost see underscore env var names signifies new nesting level configuration remaining keys lowercased config takes two arguments flat defaulting processenv filter defaulting processenvnodeappprefix changing allow inject reload environment variables capturing specific config file default environmental code capture environment variables current process however also use capture variables isolation produced gives shell file works inherits env new environmental envcapture dirnameenvsproductionsh err flat expecterrtobenull expectflatmyappredishost 127001 notice nest configuration using config method passing flat environment vars config environmentalconfig flat myapp expectconfigtodeepequal redis host 127001 exporting nodejitsu nodejitsu also works environment variables since hard ship want bundle json file environmental create temporary json file commandline example figures vars envsproductionsh even inherits files nodemodulesbinenvironmental fileenvsproductionsh formatjson tmpjitsuenvjson jitsu confirm env load tmpjitsuenvjson jitsu confirm deploy rm tmpjitsuenvjson exporting heroku heroku configset nodemodulesbinenvironmental fileenvsproductionsh formatspace exporting servers generate single file server source nodemodulesbinenvironmental fileenvsproductionsh formatnewline note different source envsproductionsh env output cleansed environment variable declared envproductionsh one ' ancestors could use list inject process upon restarts save file upstart inject nonprivileged process use eg rsync distribute amongst privileged users host echo myappsshhosts rsync recursive links perms times devices specials progress envs hostmyappdirenvs done injecting nonprivileged user process deploy app production run servers might want use upstart respawn process crashes ' upstart file etcinitmyapp could look like root user injects environment keys process memory unpriviliged user big security advantage program cannot even read credentials disk stop runlevel 016 start started networking respawn respawn limit 10 5 limit nofile 32768 32768 prestop exec status myapp grep q stopwaiting initctl emit nowait stopped jobmyapp true script exec bash c cd srvmyappcurrent chown root envssh chmod 600 envssh source envsproductionsh exec sudo ehu wwwdata make start 21 end script todo offer better ways syncing config without git means requiring vars particular environments failing hardearly better compact consise api language tests integrate heroku export target sponsor development like project consider donation ' surprised rewarding see someone spend actual money efforts even 1\n",
      "  (0, 138)\t0.14915617181147808\n",
      "  (0, 137)\t0.13397087499387264\n",
      "  (0, 136)\t0.11649592888024675\n",
      "  (0, 134)\t0.151216037848367\n",
      "  (0, 133)\t0.08727192258216904\n",
      "  (0, 131)\t0.1215910992295334\n",
      "  (0, 130)\t0.10399891943698207\n",
      "  (0, 129)\t0.09089914187924744\n",
      "  (0, 126)\t0.1325650701057809\n",
      "  (0, 119)\t0.151216037848367\n",
      "  (0, 118)\t0.12988066431239062\n",
      "  (0, 117)\t0.1325650701057809\n",
      "  (0, 116)\t0.12052408049808107\n",
      "  (0, 115)\t0.1215910992295334\n",
      "  (0, 112)\t0.1102237665599264\n",
      "  (0, 110)\t0.12495568943720792\n",
      "  (0, 106)\t0.14718788623053272\n",
      "  (0, 105)\t0.1184642144611921\n",
      "  (0, 104)\t0.09544457899073736\n",
      "  (0, 98)\t0.10778576727144545\n",
      "  (0, 97)\t0.13542277997427477\n",
      "  (0, 94)\t0.14349582073978337\n",
      "  (0, 90)\t0.09727708055032905\n",
      "  (0, 89)\t0.14915617181147808\n",
      "  (0, 88)\t0.1384777246217314\n",
      "  :\t:\n",
      "  (0, 45)\t0.10187311275549492\n",
      "  (0, 44)\t0.09918870696210466\n",
      "  (0, 43)\t0.14175916150043413\n",
      "  (0, 42)\t0.11746913585062442\n",
      "  (0, 41)\t0.061857529638319364\n",
      "  (0, 40)\t0.10778576727144545\n",
      "  (0, 39)\t0.151216037848367\n",
      "  (0, 35)\t0.13397087499387264\n",
      "  (0, 34)\t0.13397087499387264\n",
      "  (0, 28)\t0.12613653634102331\n",
      "  (0, 25)\t0.13692391134625548\n",
      "  (0, 22)\t0.10473082262398882\n",
      "  (0, 20)\t0.14718788623053272\n",
      "  (0, 18)\t0.13542277997427477\n",
      "  (0, 17)\t0.13692391134625548\n",
      "  (0, 15)\t0.09918870696210466\n",
      "  (0, 11)\t0.13692391134625548\n",
      "  (0, 10)\t0.13120252768782772\n",
      "  (0, 8)\t0.12380551737678379\n",
      "  (0, 7)\t0.1215910992295334\n",
      "  (0, 6)\t0.13120252768782772\n",
      "  (0, 5)\t0.12495568943720792\n",
      "  (0, 4)\t0.12988066431239062\n",
      "  (0, 1)\t0.12052408049808107\n",
      "  (0, 0)\t0.14349582073978337\n",
      "earth genome environmental data decision making dan hammer chief data scientist earth genome jeff chen chief data scientist us department commerce part commerce data usability project earth genome collaboration commerce data service created tutorial guide though processing visualizating digital elevation model data question feel free reach commerce data service datadocgov earth genome danearthgenomeorg\n",
      "  (0, 111)\t0.46135464547363847\n",
      "  (0, 90)\t0.30886571242003064\n",
      "  (0, 72)\t0.45010134104759236\n",
      "  (0, 48)\t0.4556154301851145\n",
      "  (0, 41)\t0.19640463973831754\n",
      "  (0, 26)\t0.2635548952414486\n",
      "  (0, 23)\t0.4165828369473269\n",
      "wildlife tracker java spark app forest service conduct environmental impact study technologies frameworks used 1 java 11 2 spark core 212 3 gradle 410 4 spark template velocity 5 junit 5 6 postgres database database psql create table animalsid serial primary keyhealth varchar age varchar type varcharname varchar create table locationsid serial primary key name varchar create table rangersid serial primary key firstname varchar lastname varchar badgenumber int create table sightingsid serial primary key ranger varchar location varchar animalid int testing gradle test screenshots homepage comprises list rangers registered system page displays table sigthings table animals displayed new animals added system table displays available locations forest locations added license\n",
      "  (0, 130)\t0.23536913125666947\n",
      "  (0, 123)\t0.3170456325860081\n",
      "  (0, 111)\t0.3288489081305222\n",
      "  (0, 85)\t0.2969360174869454\n",
      "  (0, 78)\t0.24393948073553048\n",
      "  (0, 68)\t0.3247580537310406\n",
      "  (0, 66)\t0.29394439184313126\n",
      "  (0, 63)\t0.28019519075304833\n",
      "  (0, 41)\t0.13999523352237445\n",
      "  (0, 27)\t0.29394439184313126\n",
      "  (0, 22)\t0.23702556594101395\n",
      "  (0, 7)\t0.2751835456477052\n",
      "  (0, 5)\t0.2827982466321218\n",
      "virocon viroconweb virocon software compute environmental contours viroconweb package belonging software virocon using web framework django provides browserbased graphical user interface virocon helps design marine structures need withstand load combinations based wave wind current lets define extreme environmental conditions given return period using environmental contour method following methods available viroconweb additonal methods available viroconcom fitting probabilistic model measurement data using maximum likelihood estimation defining probabilistic model conditonal modeling approach cma computing environmental contour using either inverse first order reliability method iform highest density contour hdc method virocon written python 364 software seperated two main packages viroconweb viroconcom repository viroconweb web application written web framework django 111 second package viroconcom handles statistical computations repository use virocon requirements make sure installed python 364 even python 35 ' work consider using python version management pyenv git latex install run copy virocon locally fist clone repository typing git clone httpsgithubcomviroconorganizationviroconweb shell install required python packages prepare webapplication type cd viroconweb pip install r requirementstxt python managepy collectstatic python managepy migrate shell usage everything set run local copy running managepy using ' runserver ' argument type python managepy runserver shell reach local version virocon httplocalhost8000 ' want work viroconweb ' graphical userer interface want compute environmental contours python use package built needed statistical computations viroconcom documentation code code ' documentation found methods app help page describes implemented methods detail runt app found httplocalhost8000infohelp template located paper softwarex paper virocon software compute multivariate extremes using environmental contour method provides concise description software contributing various ways contribute could improve code improve documentation add feature report bug improvement leave us implement issue spotted bug idea improvement new feature please open issue please open issue cases want work want leave us work fork want work issue please fork repository develop feature copy repository finally file pull request merge repository conventions contribution guide summarize conventions consistent pep8 cite using viroconweb academic work please cite referencing softwarex paper example long environmental contours computed using package viroconweb software virocon viroconweb version 108 viroconcom version 120 1 example short environmental contours computed using software virocon 1 1 af haselsteiner j lemkuhl pape kl windmeier kd thoben virocon software compute multivariate extremes using environmental contour method accepted softwarex license software licensed mit license information read file license\n",
      "  (0, 140)\t0.12712453298587453\n",
      "  (0, 139)\t0.1304800084573829\n",
      "  (0, 137)\t0.14376480690617544\n",
      "  (0, 136)\t0.12501235601835262\n",
      "  (0, 133)\t0.09365193068217298\n",
      "  (0, 131)\t0.1304800084573829\n",
      "  (0, 129)\t0.09754431760488795\n",
      "  (0, 128)\t0.1393755816446719\n",
      "  (0, 121)\t0.14860112947653947\n",
      "  (0, 115)\t0.1304800084573829\n",
      "  (0, 112)\t0.11828166768847281\n",
      "  (0, 105)\t0.12712453298587453\n",
      "  (0, 104)\t0.10242204859430933\n",
      "  (0, 101)\t0.15032918019800076\n",
      "  (0, 100)\t0.1453228533036717\n",
      "  (0, 99)\t0.15794804687084754\n",
      "  (0, 98)\t0.11566543862404455\n",
      "  (0, 97)\t0.1453228533036717\n",
      "  (0, 96)\t0.11652160877593173\n",
      "  (0, 94)\t0.15398607317778323\n",
      "  (0, 87)\t0.15794804687084754\n",
      "  (0, 86)\t0.15398607317778323\n",
      "  (0, 85)\t0.14079407975431515\n",
      "  (0, 83)\t0.14225623074517393\n",
      "  (0, 82)\t0.1293349853924851\n",
      "  :\t:\n",
      "  (0, 63)\t0.13285631149611082\n",
      "  (0, 62)\t0.15794804687084754\n",
      "  (0, 60)\t0.15794804687084754\n",
      "  (0, 58)\t0.1100688413084308\n",
      "  (0, 56)\t0.12605670921961737\n",
      "  (0, 52)\t0.1453228533036717\n",
      "  (0, 50)\t0.14225623074517393\n",
      "  (0, 49)\t0.1316533065352311\n",
      "  (0, 47)\t0.11918676472767024\n",
      "  (0, 44)\t0.10643989079217697\n",
      "  (0, 42)\t0.12605670921961737\n",
      "  (0, 41)\t0.0663796202312834\n",
      "  (0, 37)\t0.14376480690617544\n",
      "  (0, 30)\t0.16227067624498007\n",
      "  (0, 26)\t0.08907464650291516\n",
      "  (0, 25)\t0.1469337247848312\n",
      "  (0, 21)\t0.15212245558016516\n",
      "  (0, 15)\t0.10643989079217697\n",
      "  (0, 14)\t0.13535773944680426\n",
      "  (0, 10)\t0.14079407975431515\n",
      "  (0, 8)\t0.13285631149611082\n",
      "  (0, 7)\t0.1304800084573829\n",
      "  (0, 6)\t0.14079407975431515\n",
      "  (0, 5)\t0.13409056680856823\n",
      "  (0, 1)\t0.1293349853924851\n",
      "general overworld surface expansion incentivises exploring existing biomes completes improves visually\n",
      "\n",
      "snapshots environmental twitter activity overview visit website environmentaltwitterherokuappcom default tweet cap set 500 tweets twitter rate limit ' quickly block using website would like increase cap change text box next reload button higher number must multiple 100 twitter may still return fewer tweets ' enough available rate limit reached increase cap risk background since inauguration donald trump 45th president united states epa faced severe funding cuts deregulation one biggest centers community response twitter many users expressed outrage praise recent changes environmental protection us capture well public opinion poll twitter data perform sentiment analysis order better understand public feels epa given time site track store data long periods rather looks quick snapshot twitter activity captured every page load argue provides context long term trend analysis rather allows users get insight public feels epa instant load site methods general sense website read current tweets epa recent tweets tags epa perform sentiment analysis tweets searching positive negative sentiment results graphed various charts look tweet counts retweet counts break sentiment timezone learn methods methods input data input analysis json object returned twitter rest apis focus following attributes input data jsonresponse ' statuses ' contains tweet objects returned latest search tweet ' fulltext ' extracts full text current status tweet ' user ' ' name ' gives username person tweeted current status tweet ' user ' ' timezone ' gives timezone user tweet ' retweetcount ' retweet count current tweet many times users retweeted tweet ' createdat ' gives date time tweet posted output data data plot broken following segments datasentiments sentiment total tweet dataitems raw tweet data eg username text etc datadates dates tweet dataretweets sentiment totals weighted retweet count see methodology datatimezones count tweets timezone datatimezonessentiment overall sentiment timezone display data display data using two histograms sentiment count tweets sentiment count retweets pie chart timezone distribution bar chart overall sentiment timezone deploying deploy website simply push updated files repo automatically deploys heroku app crashes let know restart dynos author web app created nick moolenijzer nickmoolenijzercom contact questions architecture django used django framework serve render html files output python data analysis heroku builds hosts web app redis go heroku addon simple redis implementation libraries pythonoauth2 utilized authorize get requests using twitter auth tokens natural language toolkit necessary tools analyzing tweets sentiment eg tokenizing pos analysis classifying plotly used plot results text analysis numpy helps various calculations scientific analysis djangorq provides framework background workers analyze twitter data web dyno redis provides backend rq background workersqueueing apis twitter rest apis allows programmatic search twitter activity assets google material icons icons web use license written code licensed mit license open source license libraries data external resources may licenses must followed sources tutorials helpful references bird steven ewan klein edward loper natural language processing python beijing ' reilly 2009 httpwwwnltkorgbook1ed kantrowitz mark bill ross names corpus np 29 mar 1994 web 30 jan 2017 httpwww2cscmueduafscsprojectairepositoryaiareasnlpcorporanames liu bing pros cons np 2008 web httpswwwcsuiceduliubfbssentimentanalysishtmldatasets loper edward source code nltkclassifynaivebayes nltkclassifynaivebayes nltk 30 documentation np nd web 30 jan 2017 nltk classifiers classifiers np nd web 30 jan 2017 nltk natural language toolkit natural language toolkit nltk 30 documentation np nd web 30 jan 2017 nltk nltk package nltk package nltk 30 documentation np nd web 30 jan 2017 nltk nltkclassify package nltkclassify package nltk 30 documentation np nd web 30 jan 2017 perkins jacob python nltk demos natural language text processing python nltk demos natural language text processing nlp np nd web 30 jan 2017 poole david alan mackworth artificial intelligence artificial intelligence foundations computational agents 733 bayesian classifiers np 2010 web 30 jan 2017 5 categorizing tagging words nd retrieved march 12 2017 httpwwwnltkorgbookch05html asynchronous tasks jobs django rq enproftme nd retrieved march 11 2017 httpenproftme2016104asynchronoustasksandjobsdjangorq background tasks python rq heroku dev center nd retrieved march 7 2017 httpsdevcenterherokucomarticlespythonrq coolors nd retrieved march 11 2017 httpscoolorsco9f7e69d2bba0f2efc7f7ffe0ffeee2 deploying python django apps heroku heroku dev center nd retrieved february 16 2017 httpsdevcenterherokucomarticlesdeployingpython django connection refused redis heroku stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions11813470connectionrefusedforredisonheroku get searchtweets twitter developers nd retrieved march 9 2017 httpsdevtwittercomrestreferencegetsearchtweets google fonts nd retrieved march 8 2017 httpsfontsgooglecom heroku redis heroku dev center nd retrieved march 11 2017 httpsdevcenterherokucomarticlesherokuredisconnectinginpython histograms nd retrieved march 11 2017 httpsplotlypythonhistograms use sessions django documentation django nd retrieved march 11 2017 httpsdocsdjangoprojectcomen110topicshttpsessions http get request javascript stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions247483httpgetrequestinjavascript javascript whats easiest way call function every 5 seconds jquery stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions2170923whatstheeasiestwaytocallafunctionevery5secondsinjquery joestumppythonoauth2 nd retrieved march 12 2017 httpsgithubcomjoestumppythonoauth2 joestumppythonoauth2 fully tested abstract interface creating oauth clients servers nd retrieved february 16 2017 httpsgithubcomjoestumppythonoauth2 managing static files eg images javascript css django documentation django nd retrieved february 16 2017 httpsdocsdjangoprojectcomen110howtostaticfiles material icons material design nd retrieved march 12 2017 httpsmaterialioicons natural language toolkit nltk 30 documentation nd retrieved march 12 2017 httpwwwnltkorg numpy numpy nd retrieved march 12 2017 httpwwwnumpyorg personal apps heroku nd retrieved march 12 2017 httpsdashboardherokucomapps pie charts nd retrieved march 11 2017 httpsplotlypythonpiecharts pyplot matplotlib 200 documentation nd retrieved march 8 2017 httpmatplotliborgapipyplotapihtml python adding config modes plotlypy offline modebar stack overflow nd retrieved march 9 2017 httpstackoverflowcomquestions36554705addingconfigmodestoplotlypyofflinemodebar python embedding plotly chart django template stack overflow nd retrieved march 9 2017 httpstackoverflowcomquestions36846395embeddingaplotlychartinadjangotemplate python flask passing around background worker job rq redis stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions12162021flaskpassingaroundbackgroundworkerjobrqredis python get job result rq stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions22776924pythonhowtogetjobresultbyrq redis nd retrieved march 12 2017 httpsredisio redis get job id rq python stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions15181630howtogetjobbyidinrqpython redis oom command allowed used memory maxmemory 2016 may 16 retrieved httpsmattiasberedisoomcommandnotallowedusedmemorymaxmemory redis go addons heroku elements nd retrieved march 12 2017 httpselementsherokucomaddonsredistogo rest apis twitter developers nd retrieved february 16 2017 httpsdevtwittercomrestpublic rq simple job queues python nd retrieved march 11 2017 httppythonrqorg simple job queues djangorq imaginary landscape nd retrieved march 11 2017 httpswwwimagescapecomblog20130613simplejobqueuesdjangorq singleuser oauth examples twitter developers nd retrieved february 16 2017 httpsdevtwittercomoauthoverviewsingleuser smistad e nd making charts output images browser django erik smistad retrieved httpswwweriksmistadnomakingchartsandoutputingthemasimagestothebrowserindjango stack overflow nd retrieved march 7 2017 httpstackoverflowcom street nd using redisqueue asynchronous calls django retrieved httpracingtadpolecomblogredisqueuewithdjango web framework perfectionists deadlines django nd retrieved march 12 2017 httpswwwdjangoprojectcom thumbnail gallery matplotlib 200 documentation nd retrieved march 7 2017 httpmatplotliborggalleryhtml uidjangorq nd retrieved march 12 2017 httpsgithubcomuidjangorq visualize data together nd retrieved march 12 2017 httpsplotly worldvectorlogo brand logos free download nd retrieved march 7 2017 httpsworldvectorlogocom\n",
      "  (0, 139)\t0.13324046404847611\n",
      "  (0, 138)\t0.1634464831207681\n",
      "  (0, 133)\t0.09563324566463421\n",
      "  (0, 131)\t0.13324046404847611\n",
      "  (0, 130)\t0.11396281778952667\n",
      "  (0, 129)\t0.09960798053758721\n",
      "  (0, 126)\t0.14526582594807907\n",
      "  (0, 124)\t0.12559208428808646\n",
      "  (0, 116)\t0.132071216695438\n",
      "  (0, 114)\t0.16128962060495175\n",
      "  (0, 112)\t0.12078405326274354\n",
      "  (0, 107)\t0.15922456779897537\n",
      "  (0, 103)\t0.15724382677298582\n",
      "  (0, 99)\t0.16128962060495175\n",
      "  (0, 97)\t0.14839732645598427\n",
      "  (0, 96)\t0.11898675826688808\n",
      "  (0, 95)\t0.1634464831207681\n",
      "  (0, 94)\t0.15724382677298582\n",
      "  (0, 85)\t0.14377274146077546\n",
      "  (0, 84)\t0.14526582594807907\n",
      "  (0, 83)\t0.14526582594807907\n",
      "  (0, 82)\t0.132071216695438\n",
      "  (0, 81)\t0.1634464831207681\n",
      "  (0, 80)\t0.14232423338191155\n",
      "  (0, 75)\t0.1634464831207681\n",
      "  (0, 69)\t0.15724382677298582\n",
      "  (0, 64)\t0.12765713709406287\n",
      "  (0, 63)\t0.13566704052822343\n",
      "  (0, 62)\t0.16128962060495175\n",
      "  (0, 57)\t0.15724382677298582\n",
      "  (0, 48)\t0.15724382677298582\n",
      "  (0, 47)\t0.12170829867732715\n",
      "  (0, 45)\t0.11163334243719018\n",
      "  (0, 41)\t0.06778395792230937\n",
      "  (0, 38)\t0.15004227778768386\n",
      "  (0, 37)\t0.14680631778373038\n",
      "  (0, 28)\t0.13822138908226325\n",
      "  (0, 26)\t0.09095912374100436\n",
      "  (0, 25)\t0.15004227778768386\n",
      "  (0, 24)\t0.1634464831207681\n",
      "  (0, 23)\t0.14377274146077546\n",
      "  (0, 19)\t0.13955082613898276\n",
      "  (0, 17)\t0.15004227778768386\n",
      "  (0, 16)\t0.14839732645598427\n",
      "  (0, 15)\t0.10869174987102265\n",
      "  (0, 11)\t0.15004227778768386\n",
      "  (0, 7)\t0.13324046404847611\n",
      "  (0, 5)\t0.136927407940292\n",
      "  (0, 3)\t0.15534078218821604\n",
      "  (0, 2)\t0.16128962060495175\n",
      "code data paper learning navigate unseen environments back translation environmental dropout environment installation download roomtoroom navigation data bash tasksr2rdatadownloadsh download image features environments mkdir imgfeatures wget httpswwwdropboxcomso57kxh2mn5rkx4oresnet152imagenetzip p imgfeatures cd imgfeatures unzip resnet152imagenetzip python requirements need python36 python 35 ok since removed allennlp dependencies pip install r pythonrequirementstxt install matterport3d simulators git submodule update init recursive sudo aptget install libjsoncppdev libepoxydev libglmdev libosmesa6 libosmesa6dev libglewdev mkdir build cd build cmake deglrenderingon make j8 code speaker bash runspeakerbash 0 0 id gpu train speaker save snapshot snapspeaker agent bash runagentbash 0 0 id gpu train agent save snapshot snapagent unseen success rate would around 46 agent speaker back translation pretraining speaker agnet bash runbtenvdropbash 0 0 id gpu load pretrained agent run back translation environmental dropout currently result pytorch 11 little bit lower naacl reported number still easily reaches success rate 50 4 wo back translation implementation details training speaker listener drop features much means image feature dropped randomly smaller dropout rate seen used multiple vision papers mlweight increased using back translation since quality generated sentence high rl would misled instead training augmented data finetuning training data trained together semantic views shown fig6 paper semanticviews17drp5sb8fy10c252c90fa24ef3b698c6f54d984c5c14png repo rendered semantic views matterport3d dataset provide preview semantic views rgb views forder semanticviews access full rendered data please first sign terms use agreement form httpsgithubcomniessnermatterport cc ' email us haotancsuncedu would share download link thanks one teaches calibrate camera note would small pixellevel disagreement rgb view semantic view since semantic view rendered 3d annotations rgb view rendered skyboxes still aiming solving todo ' provide test script beam search code trainpy agentpy release pretrained snapshots check pytorch 11 configurations update pip requirement version specifications\n",
      "  (0, 136)\t0.15377673071047349\n",
      "  (0, 133)\t0.11520051444286207\n",
      "  (0, 130)\t0.13728045247727755\n",
      "  (0, 129)\t0.11998850944351172\n",
      "  (0, 127)\t0.19960790179386267\n",
      "  (0, 123)\t0.18491876001313393\n",
      "  (0, 119)\t0.19960790179386267\n",
      "  (0, 107)\t0.19180309101615695\n",
      "  (0, 106)\t0.1942906688866645\n",
      "  (0, 104)\t0.12598856854749554\n",
      "  (0, 101)\t0.18491876001313393\n",
      "  (0, 96)\t0.14333232830246856\n",
      "  (0, 92)\t0.17684397527880052\n",
      "  (0, 87)\t0.1942906688866645\n",
      "  (0, 86)\t0.18941707573887287\n",
      "  (0, 80)\t0.17144482328644267\n",
      "  (0, 79)\t0.16494376747774275\n",
      "  (0, 76)\t0.1550613814931044\n",
      "  (0, 75)\t0.19688884141210514\n",
      "  (0, 70)\t0.13728045247727755\n",
      "  (0, 59)\t0.16050244761970273\n",
      "  (0, 58)\t0.13539482902806466\n",
      "  (0, 53)\t0.18941707573887287\n",
      "  (0, 49)\t0.1619457124961274\n",
      "  (0, 43)\t0.18712465416884708\n",
      "  (0, 41)\t0.08165305662642673\n",
      "  (0, 40)\t0.14227916003108768\n",
      "  (0, 38)\t0.18074203661281865\n",
      "  (0, 32)\t0.18279309820727868\n",
      "  (0, 29)\t0.18279309820727868\n",
      "  (0, 26)\t0.10957003263260238\n",
      "  (0, 15)\t0.13093088511025167\n",
      "  (0, 12)\t0.18712465416884708\n",
      "  (0, 10)\t0.17318970682249812\n",
      "  (0, 9)\t0.17318970682249812\n",
      "  (0, 0)\t0.18941707573887287\n",
      "buzzsense ecological observation increasingly augmented autonomous systems analysis transmission data poses serious problems information manager aim project bridge technological gap needs biologists recent advances mobile imaging solve present buzzsense application bee population counting running android mobile device run application android device running android 42 better need opencv manager available play store also need copy images project samples directory mediasamples mobile device compile application need download open cv android 248 better sdk need download install android ndk native development kit program uses native c libraries wraped easy use java calls hardware accelerated image processing\n",
      "  (0, 132)\t0.26025083428390283\n",
      "  (0, 129)\t0.16280816707237214\n",
      "  (0, 105)\t0.21217957861160355\n",
      "  (0, 104)\t0.1709494351785935\n",
      "  (0, 90)\t0.1742316027976313\n",
      "  (0, 89)\t0.26715150922346215\n",
      "  (0, 82)\t0.21586897552940976\n",
      "  (0, 77)\t0.2708409061412683\n",
      "  (0, 76)\t0.2103973073895643\n",
      "  (0, 58)\t0.1837124575292271\n",
      "  (0, 56)\t0.2103973073895643\n",
      "  (0, 53)\t0.25701333449577374\n",
      "  (0, 38)\t0.24524248055363923\n",
      "  (0, 36)\t0.22380636760643555\n",
      "  (0, 34)\t0.23995333891940673\n",
      "  (0, 26)\t0.14867170416324077\n",
      "  (0, 21)\t0.2539028287006436\n",
      "  (0, 7)\t0.2177800976842307\n",
      "  (0, 6)\t0.23499499122327946\n",
      "  (0, 3)\t0.2539028287006436\n",
      "environmentalsustainability document created thinkchicago ' idea week focuses environmental sustainability chicago selected one 20 total teams pitch solution judges links surveys end document quality app food survey httpswwwsurveymonkeycomr9jyvnzk demographic survey httpswwwsurveymonkeycomr9qb3nyy farmer survey httpswwwsurveymonkeycomr9sq2wzp plan creating web app get experience web backend\n",
      "  (0, 139)\t0.3913089031108738\n",
      "  (0, 41)\t0.1990721543377563\n",
      "  (0, 39)\t0.486648959324849\n",
      "  (0, 24)\t0.48001982343778254\n",
      "  (0, 23)\t0.42224075216212625\n",
      "  (0, 5)\t0.40213694983407433\n",
      "onestop stack onestop distributed scalable eventdriven database search engine environmental data designed receive metadata automated systems manual uploads iso19115 xml metadata implements generic parsing analysis metadata also enabling arbitrary processing flows metadata entities retrievable via rest api exposed streaming events via kafka indexed support wide range search discovery capabilities via elasticsearch developed grant team researchers university colorado legal info documentation overview usage deployment development information project check docs legal software developed onestop project 1553647 msn project 1555839 noaa award numbers na12oar4320137 na17oar4320101 respectively cooperative institute research environmental sciences university colorado code licensed gpl version 2 2020 regents university colorado program free software redistribute andor modify terms gnu general public license published free software foundation version 2 license program distributed hope useful without warranty without even implied warranty merchantability fitness particular purpose see gnu general public license details received copy gnu general public license along program write free software foundation inc 51 franklin street fifth floor boston 021101301 usa\n",
      "  (0, 136)\t0.17932796306102372\n",
      "  (0, 128)\t0.19993175037126049\n",
      "  (0, 120)\t0.21821691042305633\n",
      "  (0, 115)\t0.1871712115673793\n",
      "  (0, 107)\t0.22367270692920857\n",
      "  (0, 102)\t0.22657361573649548\n",
      "  (0, 95)\t0.22960349538418817\n",
      "  (0, 90)\t0.14974343631824164\n",
      "  (0, 89)\t0.22960349538418817\n",
      "  (0, 63)\t0.19057997528580922\n",
      "  (0, 56)\t0.1808260688344368\n",
      "  (0, 48)\t0.22089023615140646\n",
      "  (0, 41)\t0.09522036432217011\n",
      "  (0, 37)\t0.20622801460170076\n",
      "  (0, 34)\t0.20622801460170076\n",
      "  (0, 33)\t0.22960349538418817\n",
      "  (0, 32)\t0.2131656318330896\n",
      "  (0, 31)\t0.20846300397168394\n",
      "  (0, 27)\t0.19993175037126049\n",
      "  (0, 26)\t0.12777596892425172\n",
      "  (0, 21)\t0.21821691042305633\n",
      "  (0, 15)\t0.15268609769578875\n",
      "  (0, 12)\t0.21821691042305633\n",
      "  (0, 4)\t0.19993175037126049\n",
      "  (0, 3)\t0.21821691042305633\n",
      "mixturesworkshop columbia university mailman school public health environmental mixtures workshop 20182019 introduction multiple techniques analyze exposure mixtures environmental health repository guide within repository find code materials used mixtures workshop 20182019 help navigate repository description repository organization repository organized two main folders unsupervised supervised contained materials unsupervised supervised methods correspondingly unsupervised folder subdivide three folders pca fa clustering supervised folder subdivide wqs variable selection bkmr materials respective method within folder note rmd file titled method ' name contains main code addition unsupervised supervised folders find following folders data contains data data dictionary mitroetalmaterials contains code data used mitro et al workshoppaperfigures contains figures include gibson et al paper warning repo created r version 353 results differ newer r versions r version 360 changed default method generating discrete uniform distribution used sample additionally version 313 grpreg package used recreate published results\n",
      "  (0, 136)\t0.2158858324752316\n",
      "  (0, 130)\t0.19272684904085435\n",
      "  (0, 103)\t0.2659210069818804\n",
      "  (0, 98)\t0.19974449167487757\n",
      "  (0, 95)\t0.2764105546850541\n",
      "  (0, 79)\t0.23156313955313043\n",
      "  (0, 75)\t0.2764105546850541\n",
      "  (0, 54)\t0.28022782021901416\n",
      "  (0, 52)\t0.25096035433916103\n",
      "  (0, 47)\t0.20582552591429623\n",
      "  (0, 46)\t0.25096035433916103\n",
      "  (0, 44)\t0.18381274590863977\n",
      "  (0, 41)\t0.11463202542088355\n",
      "  (0, 30)\t0.28022782021901416\n",
      "  (0, 28)\t0.2337514402028299\n",
      "  (0, 26)\t0.15382442844206326\n",
      "  (0, 23)\t0.24313954302950846\n",
      "  (0, 19)\t0.23599970169644174\n",
      "  (0, 15)\t0.18381274590863977\n",
      "neutrino neutrino environmental monitoring home hvac diy projects neutrino designed alternative zoned hvac system supplement zoned hvac system relatively easy implement people ' want retrofit fully zoned system ways may even better zoned system cost effective also allows ability get system control ' going commercial systems offer zoned systems ' always work well ideally zoned system heats cools efficiently unfortunately limitations ability ductwork supply airflow often cause system open bypass relieve pressure essentially connects output input short circuiting system zone needs air getting capacity wasted traditional single zone system air would go rooms might need moment probably would eventually called pressure issue mitigated somewhat different blower speeds furnace means expensive zoning system sometimes zone conflicts cause system act nonintuitively like waiting blower stop one zone kicking request another zone sometimes zoned system overkill structure needs boost higher accuracy someone wants data many reasons end neutrino gives diy user ability go change works first giving average user ability finetune system detailed information room big bonus allows use adjust vent covers appropriately sometimes make difference top users choose sensors hvac system pay attention whether one particular room average multiple 2014 ' make much sense drive hvac hallway temperature unless course enjoy hanging hallway also gives advanced users ability go change system works providing open system starts sensors tiny inexpensive battery powered sensors placed wherever makes sense sense surroundings wall putty doublesided tape shelf etc next sensors grouped together user software however see fit groups represent zones ' match example sensor room driven hvac system could included sensor group controls hvac system b finally users choose set hotcold set points group toggle sensors group ' count ' system average values sensors count whether single sensor ten sensors sensors consist microcontroller temperaturehumiditypressure sensor 24ghz radio battery use radio wifi power efficient inexpensive implement sensors report sensor hubs via radio six sensors assigned single hub sensors assigned id 0 5 via jumpers sensor hubs responsible getting sensor info database ' necessarily correspond sensor groups group span hubs hubs currently consist raspberry pi 24ghz radio attached software sensorlistener listens radio plugs output mysql database eight sensor hubs supported per system sensorlistener assigned hub id 07 via config file sensors told hub report via second set jumpers ' controller controllers computer relays control actual hvac furnace ac humidifier blower controller software looks database sensor group ' readings checks ' set points via controller table adjusts hvac accordingly finally ' web ui user easily see sensor data create sensor groups set heatingcooling points code rpisensorlistener c application raspberry pi requires makemake install rf24 library httpsgithubcommlsorensenrf24treemasterlibrf24rpilibrf24 well aptget install mysql libconfig libs start read config file supply via ' c ' flag see example config start listening six radios assigned gets message puts mysql optionally publishes zabbix via zabbix sender keys ' neutrinosensoridhubidtemperature ' etc arduino code runs sensor microcontrollers also contains schematics controllers requires arduino ide import arduinoversion rf24 library httpsgithubcommlsorensenrf24 bmp180 library httpsgithubcommlsorensenbmp180git rocketscream low power library httpsgithubcomrocketscreamlowpower controller software controls controller web ui code deployment deployment currently adhoc following may help running sensor hub sudo aptget install daemon cd neutrinohub sudo daemon name sensorlistener respawn outputdaemonerr homepineutrinohubsensorlistener c etcsensorlistenercfg stopping sensor hub sudo daemon name sensorlistener stop running controller cd neutrinocontroller screen dms controller sudo controller c etccontrollerconf running web ui cd neutrinoweb sudo hypnotoad neutrinowebapp stopping web ui sudo hypnotoad neutrinowebapp stop\n",
      "  (0, 140)\t0.13504025412540166\n",
      "  (0, 139)\t0.13860466651489994\n",
      "  (0, 137)\t0.15271667555354104\n",
      "  (0, 135)\t0.1656348788512679\n",
      "  (0, 131)\t0.13860466651489994\n",
      "  (0, 129)\t0.103618154013723\n",
      "  (0, 122)\t0.16778306977473903\n",
      "  (0, 119)\t0.17237485827898974\n",
      "  (0, 118)\t0.14805414440549797\n",
      "  (0, 115)\t0.13860466651489994\n",
      "  (0, 112)\t0.12564676611085365\n",
      "  (0, 109)\t0.1656348788512679\n",
      "  (0, 108)\t0.15785414362201328\n",
      "  (0, 105)\t0.13504025412540166\n",
      "  (0, 99)\t0.16778306977473903\n",
      "  (0, 97)\t0.15437173753501113\n",
      "  (0, 91)\t0.17002676662657862\n",
      "  (0, 84)\t0.1511141641942914\n",
      "  (0, 82)\t0.1373883457778128\n",
      "  (0, 77)\t0.17237485827898974\n",
      "  (0, 76)\t0.1339059396908107\n",
      "  (0, 75)\t0.17002676662657862\n",
      "  (0, 74)\t0.1615947337404042\n",
      "  (0, 70)\t0.11855091069833534\n",
      "  (0, 64)\t0.13279655727356207\n",
      "  (0, 58)\t0.11692254793361234\n",
      "  (0, 57)\t0.16357439406295482\n",
      "  (0, 56)\t0.1339059396908107\n",
      "  (0, 52)\t0.15437173753501113\n",
      "  (0, 47)\t0.12660822123922724\n",
      "  (0, 44)\t0.11306763190432101\n",
      "  (0, 42)\t0.1339059396908107\n",
      "  (0, 41)\t0.07051291024822241\n",
      "  (0, 39)\t0.17237485827898974\n",
      "  (0, 35)\t0.15271667555354104\n",
      "  (0, 31)\t0.15437173753501113\n",
      "  (0, 27)\t0.14805414440549797\n",
      "  (0, 26)\t0.09462109804738121\n",
      "  (0, 22)\t0.1193852250338342\n",
      "  (0, 20)\t0.16778306977473903\n",
      "  (0, 19)\t0.14516908100706746\n",
      "  (0, 17)\t0.15608291388366533\n",
      "  (0, 15)\t0.11306763190432101\n",
      "  (0, 11)\t0.15608291388366533\n",
      "  (0, 10)\t0.14956096878237815\n",
      "  (0, 6)\t0.14956096878237815\n",
      "  (0, 2)\t0.16778306977473903\n",
      "envirotreaties\n",
      "\n",
      "environmental stressor aspnet core web application test environment like server cluster provides operations simulate long running startup long running request high cpu usage memory leak memory high throughput running docker image available httpshubdockercomrmatheusnederenvironmentalstressor docker run matheusnederenvironmentalstressorv10alpha4\n",
      "  (0, 139)\t0.26290615276118073\n",
      "  (0, 128)\t0.28082997841788687\n",
      "  (0, 123)\t0.3029005506733041\n",
      "  (0, 110)\t0.2701811216752112\n",
      "  (0, 105)\t0.25614515421950074\n",
      "  (0, 104)\t0.2063717428608501\n",
      "  (0, 99)\t0.3182519209639702\n",
      "  (0, 94)\t0.31026887993493196\n",
      "  (0, 64)\t0.2518892967356829\n",
      "  (0, 53)\t0.31026887993493196\n",
      "  (0, 41)\t0.13374930599008175\n",
      "  (0, 40)\t0.2330560507743545\n",
      "  (0, 7)\t0.26290615276118073\n",
      "  (0, 6)\t0.28368813182479075\n",
      "utah turbulence environmental studies process analysis code utespac created derek jensen eric pardyjak derek591gmailcom version 41 version date 15 january 2017 utespac designed specifically use campbell scientific dataloggers accompanying loggernet software native support sonic anemometers rmyoung 8100 campbell sci csat3 open path gas analyzers licor 7500 campbell sci ec150 irgason krypton hygrometers finewire thermocouples heat flux computations propeller anemometers mean meteorological sensors eg trh pressure solar cup anemometers etc utespac expects 24 48hr csv tables quality controls data computes means fluxes variances derived temperatures potential temperature virtual potential temperature stores output matlab structure netcdf file steps use convert campbell binary files csv files using card convert program loggernet options file processing use time set 2 days 00 h time settings file naming use timedate filenames append last file multiple site files exist array csv options timestamp options include year day hourminutes seconds ' include midnight 2400 array id array datalogger format hourminutes seconds create folder individual site folder name needs preceded keyword site eg site named playa folder name siteplaya place csv files within site folder create subfolder named output output data stored create header files data table syntax 91tablename92headerdat eg playa1hzheaderdat playa20hzheaderdat note 91tablename92 must consistent csv tablenames created step 1 header file single line dat comma delimited file containing variable names heights columns within respective data table header file 3 columns shorter csv data file utespac immediately calculates serial date numbers date vectors columns 1 96 4 contained data tables serial dates stored column 1 columns 2 96 4 deleted thus becoming consistent header file easiest way create header file card convert create ascii t0a5 file need run whole binary file simply stop conversion immediately hundred lines created open file text editor delete lines outside variable headers typically line 5 variable names within header sensor templates defined lines 155169 must consistent template used utespac identify specific sensors header rules creating template header variable names template variable name exact except sensor height replaced wildcard ' ' template eg template ' ux ' header variable name ' ux05 ' ' ux10 ' sensor height must last numeric value header variable name sensors exception solar battery need associated height meters heights within header variable name given tower height need exactly match eg ' fw5 ' ' ux5 ' ' rh5 ' global planar fit used pfinfo structure containing global planar fit coefficients stored site folder need anything note global planar fit must 1 1 set 5 minute local planar fit data global planar fit fail ' 5minavglpflindetrend ' ' 5minavglpfconstdetrend ' output folder must one ' matter fill information section code lines 56 116 run code full example study included utespaczip use getdata structfill structconcat produce complete missing days datasets full experiment see example\n",
      "  (0, 138)\t0.189221331650618\n",
      "  (0, 136)\t0.14778815068046453\n",
      "  (0, 134)\t0.1918345027302207\n",
      "  (0, 133)\t0.11071422124978994\n",
      "  (0, 130)\t0.13193429267522092\n",
      "  (0, 129)\t0.11531575571696227\n",
      "  (0, 124)\t0.1453974474091866\n",
      "  (0, 122)\t0.18672434065003152\n",
      "  (0, 120)\t0.1798373945041339\n",
      "  (0, 117)\t0.16817365846233848\n",
      "  (0, 115)\t0.15425194568652925\n",
      "  (0, 112)\t0.13983120936073218\n",
      "  (0, 109)\t0.18433363737875355\n",
      "  (0, 108)\t0.17567452381380563\n",
      "  (0, 104)\t0.12108215245887752\n",
      "  (0, 89)\t0.189221331650618\n",
      "  (0, 88)\t0.17567452381380563\n",
      "  (0, 84)\t0.16817365846233848\n",
      "  (0, 82)\t0.15289831276065372\n",
      "  (0, 79)\t0.15852030570021666\n",
      "  (0, 77)\t0.1918345027302207\n",
      "  (0, 76)\t0.14902277286652654\n",
      "  (0, 75)\t0.189221331650618\n",
      "  (0, 67)\t0.1820405415137552\n",
      "  (0, 65)\t0.1798373945041339\n",
      "  (0, 56)\t0.14902277286652654\n",
      "  (0, 54)\t0.1918345027302207\n",
      "  (0, 46)\t0.1717989839196784\n",
      "  (0, 45)\t0.12923746849277148\n",
      "  (0, 44)\t0.12583199869057018\n",
      "  (0, 42)\t0.14902277286652654\n",
      "  (0, 41)\t0.07847321360308362\n",
      "  (0, 31)\t0.1717989839196784\n",
      "  (0, 26)\t0.10530300922613883\n",
      "  (0, 24)\t0.189221331650618\n",
      "  (0, 23)\t0.16644512059746608\n",
      "  (0, 22)\t0.13286279395011147\n",
      "  (0, 15)\t0.12583199869057018\n",
      "  (0, 3)\t0.1798373945041339\n",
      "enviro designed environmental monitoring enviro lets measure air quality pollutant gases particulates temperature pressure humidity light noise level learn httpsshoppimoronicomproductsenviroplus installing ' best using oneline install method want uart serial configuration pms5003 particulate matter sensor run automatically note code repository supports enviro enviro mini boards enviro mini board gas sensor breakout pm sensor oneline installs github curl ssl httpsgetpimoronicomenviroplus bash note report issues oneline installer httpsgithubcompimoroniget install configure dependencies github git clone httpsgithubcompimoronienviropluspython cd enviropluspython sudo installsh note raspbian lite users may first need install git sudo apt install git install pypi configure manually run sudo pip install enviroplus note wont perform required configuration changes pi may additionally need enable i2c raspiconfig nonint doi2c 0 enable spi raspiconfig nonint dospi 0 ' using pms5003 sensor need enable serial raspiconfig nonint setconfigvar enableuart 1 bootconfigtxt disable serial terminal sudo raspiconfig nonint doserial 1 add dtoverlaypi3miniuartbt bootconfigtxt install additional dependencies sudo apt install pythonnumpy pythonsmbus pythonpil pythonsetuptools alternate software user projects enviro monitor httpsgithubcomroscoe81enviromonitor mqttall httpsgithubcomrobmarkcolerpienviromqtt upstream see examplesmqttallpy adafruitiopy httpsgithubcomdedsyn4ps3enviropluspythonblobmasterexamplesadafruitiopy uses adafruit blinka bme280 libraries publish adafruit io enviroplusexporter httpsgithubcomtijmenvandenbrinkenviroplusexporter prometheus exporter added support luftdaten influxdb cloud help support gpio pinout httpspinoutxyzpinoutenviroplus support forums httpforumspimoronicomcsupport discord httpsdiscordgghr93byc\n",
      "  (0, 137)\t0.1872523505000869\n",
      "  (0, 133)\t0.12198078602472504\n",
      "  (0, 132)\t0.20309190386234735\n",
      "  (0, 131)\t0.1699490216187718\n",
      "  (0, 122)\t0.20572589126604707\n",
      "  (0, 120)\t0.19813811171339873\n",
      "  (0, 119)\t0.21135607662271283\n",
      "  (0, 115)\t0.1699490216187718\n",
      "  (0, 108)\t0.1935516165622485\n",
      "  (0, 104)\t0.1334037846608391\n",
      "  (0, 100)\t0.1892816917303768\n",
      "  (0, 98)\t0.15065317945379253\n",
      "  (0, 91)\t0.2084769825125908\n",
      "  (0, 87)\t0.20572589126604707\n",
      "  (0, 86)\t0.2005654566463979\n",
      "  (0, 79)\t0.17465174095896752\n",
      "  (0, 76)\t0.16418771468238513\n",
      "  (0, 74)\t0.19813811171339873\n",
      "  (0, 58)\t0.1433636624662652\n",
      "  (0, 52)\t0.1892816917303768\n",
      "  (0, 51)\t0.19813811171339873\n",
      "  (0, 50)\t0.18528744380188303\n",
      "  (0, 49)\t0.17147723166991247\n",
      "  (0, 41)\t0.0864588502645359\n",
      "  (0, 31)\t0.1892816917303768\n",
      "  (0, 29)\t0.1935516165622485\n",
      "  (0, 18)\t0.1892816917303768\n",
      "  (0, 15)\t0.13863698749872247\n",
      "  (0, 14)\t0.1763022217692951\n",
      "  (0, 10)\t0.18338300546459912\n",
      "  (0, 1)\t0.16845763951425682\n",
      "openthc raspberry pi toolkit collection documentation scripts tools using raspberry pi cannabis operations scale support one scales connected rpi via serialusb adapters may need highspeed usb hub four scales used sensor support co2 x ch4 methane humiditytemperature dht11 dht22 lumens light cycle onoff wind speed wind direction solar ph soil liquid vpd vapor pressure deficit floodmoisture sensor ek1361 te215 water level sensor soil moisture httpswwwamazoncomxcsourcemoistureautomaticwateringte215dpb00zr3b60irefpdsim8613encodingutf8pdrdib00zr3b60ipdrdrc3b5e56b9b6511e8800d291f7dc96a5epdrdw8nsu8pdrdwgye39npfrdidesktopdpsimspfrdmatvpdkikx0derpfrdpa180fdfbb54e490485bad852197d6c09pfrdry61esta6t2n3ax4a6qtbpfrdsdesktopdpsimspfrdt40701psc1refridy61esta6t2n3ax4a6qtb httpswwwamazoncomkumanmoisturecompatibleraspberryautomaticdpb071f4rdhyrefpdsim864encodingutf8pdrdib071f4rdhypdrdr520fcfc79b6511e88a22f3d4eee18e06pdrdwuxo65pdrdwgar8odpfrdidesktopdpsimspfrdmatvpdkikx0derpfrdpa180fdfbb54e490485bad852197d6c09pfrdrxp2yx5bb9h3r8mwecg8cpfrdsdesktopdpsimspfrdt40701psc1refridxp2yx5bb9h3r8mwecg8cdpid51roavqo3xlprestsy300ql70dpsrcdetail httpswwwamazoncomgikfunmoisturesensorarduinoek1361dpb00rk1vytirefsr11ieutf8qid1533771952sr81keywordssoilmoisturesensor httpswwwamazoncomctyrzchmoisturesensorautomaticwateringdpb01essmlqurefsr119ieutf8qid1533771976sr819keywordssoilmoisturesensor httpswwwamazoncomdfrobotgravitycapacitivecorrosionresistantdpb01ghy0n4krefsr120ieutf8qid1533771976sr820keywordssoilmoisturesensor httpswwwamazoncomdfrobotgravitycapacitivecorrosionresistantdpb01ghy0n4krefpdsim862encodingutf8pdrdib01ghy0n4kpdrdr520fcfc79b6511e88a22f3d4eee18e06pdrdwuxo65pdrdwgar8odpfrdidesktopdpsimspfrdmatvpdkikx0derpfrdpa180fdfbb54e490485bad852197d6c09pfrdrxp2yx5bb9h3r8mwecg8cpfrdsdesktopdpsimspfrdt40701psc1refridxp2yx5bb9h3r8mwecg8cdpid41w7vqm6gxlprestsy300ql70dpsrcdetail httpswwwamazoncomwingoneersensordropletdetectionarduinodpb06xhdz3q4refpdsim863encodingutf8pdrdib06xhdz3q4pdrdr520fcfc79b6511e88a22f3d4eee18e06pdrdwuxo65pdrdwgar8odpfrdidesktopdpsimspfrdmatvpdkikx0derpfrdpa180fdfbb54e490485bad852197d6c09pfrdrxp2yx5bb9h3r8mwecg8cpfrdsdesktopdpsimspfrdt40701psc1refridxp2yx5bb9h3r8mwecg8c httpswwwamazoncomphantomyoyocompatiblesensitivitymoisturedpb00afcnr3urefpdsim8650encodingutf8pdrdib00afcnr3updrdr520fcfc79b6511e88a22f3d4eee18e06pdrdwuxo65pdrdwgar8odpfrdidesktopdpsimspfrdmatvpdkikx0derpfrdpa180fdfbb54e490485bad852197d6c09pfrdrxp2yx5bb9h3r8mwecg8cpfrdsdesktopdpsimspfrdt40701psc1refridxp2yx5bb9h3r8mwecg8c httpswwwamazoncomdpb01n7na3hprefsxbssxwdsstppvp1pfrdmatvpdkikx0derpfrdp6297546923292665688pdrdwgn1jtppfrdrz9tkr6jwbxesk34wwszepfrdsdesktopsxbottomslotpfrdt301pdrdib01n7na3hppdrdwvhi9npfrdisoilmoisturesensorpdrdr46cb234ec9874ef68c13b213336fca55ieutf8qid1533771976sr1 httpswwwamazoncomdpb00tmd43bsrefpsdc3480689011t4b00zr3b60i control support onoff ac power onoff dc power hardware ' need misc resistors capacators stuff httpswwwamazoncomdpb076lh75jqrefsspadkdetail12psc1pdrdib076lh75jqpdrdwg7ha91pdrdrdt8weqmjthswbh952y2ypdrdwpdyie httpswwwamazoncomdpb07bvtfchprefsspadkdetail3psc1pdrdib07bvtfchppdrdwgtderypdrdr6k5p8ytefm594rdcm0v6pdrdwaahec httpswwwamazoncom24valueelectrolyticcapacitorassortment01ufefbc8d1000ufdpb01msqox0qrefpdbxgy3283encodingutf8pdrdib01msqox0qpdrdr6k5p8ytefm594rdcm0v6pdrdwzmcy1pdrdwgtderypsc1refrid6k5p8ytefm594rdcm0v6dpid51lvgjm9iulprestsy300ql70dpsrcdetail\n",
      "  (0, 133)\t0.24327868071588446\n",
      "  (0, 130)\t0.2899067554365517\n",
      "  (0, 126)\t0.36953758333877157\n",
      "  (0, 120)\t0.39516697660401745\n",
      "  (0, 108)\t0.38601966311437114\n",
      "  (0, 76)\t0.3274562488029085\n",
      "  (0, 37)\t0.3734563964965417\n",
      "  (0, 20)\t0.4103000566512069\n",
      "environmental environmental proof column politecnico di torino\n",
      "  (0, 41)\t1.0\n",
      "enfin environmental finance service overview environmental finance service allows individuals track carbon footprint enfin team redefining individuals ' methods towards watching impact environment using estimations based current environmental research every dollar spent mapped environmental impact history enfin founded impact labs fellowship fellowship designed passionate motivated students come together combine computer science social good learning create humanitarian software development founders strong idea regarding effects individuals climate change enfin highlights belief\n",
      "  (0, 133)\t0.19400145881363728\n",
      "  (0, 115)\t0.27029140565883175\n",
      "  (0, 111)\t0.32300271958034527\n",
      "  (0, 102)\t0.32719188260730686\n",
      "  (0, 41)\t0.1375064354419715\n",
      "  (0, 40)\t0.23960278943459382\n",
      "  (0, 34)\t0.2978110762127405\n",
      "  (0, 31)\t0.3010385940205623\n",
      "  (0, 25)\t0.3043755398264827\n",
      "  (0, 22)\t0.23281178838103628\n",
      "  (0, 11)\t0.3043755398264827\n",
      "  (0, 8)\t0.2752139550685286\n",
      "  (0, 2)\t0.32719188260730686\n",
      "etdenvironmentalsensor project python consisting smaller apps talking microservices enables reading measurements humtemp sensor displaying webpage steps creating project download repo git clone adresurl create venv install required packages python3 venv venv source venvbinactivate pip install upgrade pip pip3 install r requirementstxt permanent alias nano bashrc alias venvsource environmentalsensorsvenvbinactivate reboot type source bashrc config temphum sensor add uncomment dtparamspion dtoverlaymcp2515can0oscillator8000000interrupt25spimaxfrequency1000000 sudo apt update sudo modprobe mcp251x sudo apt install canutils worth rebooting sudo ip link set can0 type bitrate 460800 candump can0 bug fix sudo aptget install libatlasbasedev running app startsh sigoihy\n",
      "  (0, 127)\t0.25656600283910286\n",
      "  (0, 119)\t0.25656600283910286\n",
      "  (0, 116)\t0.20449141519141356\n",
      "  (0, 112)\t0.18701502569792455\n",
      "  (0, 108)\t0.23495309620582894\n",
      "  (0, 105)\t0.200996471116774\n",
      "  (0, 100)\t0.22976981704943006\n",
      "  (0, 96)\t0.1842321983233084\n",
      "  (0, 90)\t0.16504857606229684\n",
      "  (0, 87)\t0.24973149788762444\n",
      "  (0, 86)\t0.24346722527037984\n",
      "  (0, 58)\t0.1740297341769982\n",
      "  (0, 50)\t0.2249211832096217\n",
      "  (0, 49)\t0.2081569104161561\n",
      "  (0, 38)\t0.23231676432648857\n",
      "  (0, 24)\t0.25307105876446334\n",
      "  (0, 22)\t0.17769522940174076\n",
      "  (0, 17)\t0.23231676432648857\n",
      "  (0, 14)\t0.21401398556307347\n",
      "  (0, 5)\t0.21201046018053005\n",
      "  (0, 1)\t0.20449141519141356\n",
      "mesopy mesopy small pure python wrapper around mesowest httpmesowestutahedu api updated daily 45 million observations useful retrieving meteorological data 40000 observation stations united states project created researcher mind would value feedback using mesopy using mesopy need obtain api keytoken filling quick form receive email immediately api key link generate token click link copy token generated instancing meso object like mesotoken ' apitoken ' installation two easy ways install mesopy run pip install mesopy command line window download source folder place mesopypy working directory version 2 updates requests package dependency longer exists function names simplified additional query parameters added function new functions added request services mesowest data latency statistics network information lists may passed parameters usage retrieving data request different types observations simply creating meso object calling function mesopy import meso mesotoken ' apitoken ' precip mprecipstid ' kfnl ' start ' 201504261800 ' end ' 201504271200 ' units ' precipin ' returns following data dictionary units precipitationinches station statusactive mnetid1 periodofrecord start19700101t000000z end20180313t015600z elevation5016 namefort collinsloveland northern colorado regional airport restrictedfalse stidkfnl elevdem5000 longitude10501667 stateco observations obstarttime120150426t181500z totalprecipvalue1009 obendtime120150427t115500z count153 latitude4045 timezoneamericadenver id192 summary dataquerytime50201416016 responsecode1 responsemessageok metadataresponsetime00920295715332 ms numberofobjects1 precipdatatime54969787598 dataparsetime04601478577 retrieve dictionary keysvalues listed merely following let ' print total precip accumulation fort collins airport station precip ' station ' 0 ' stid ' remember stored dictionary precip variable totalprecip precip ' station ' 0 ' observations ' ' totalprecipvalue1 ' print ' total accumulated precip ' station ' ' strtotalprecip ' ' prints total accumulated precip kfnl 009 note one thing example whenever data ' requesting returns ' station ' necessary specify station index value list subsequently referring example pass stidkdenkslc dictionary return list two stations ' relevant info get information kden denver would type ' station ' 0 kden would first list stations ' station ' 1 kslc salt lake city remember specifies dictionary denotes list 0 first position list may useful store precip ' station ' variable reduce clutter example denverprecipobs precip ' station ' 0 saltlakeprecipobs precip ' station ' 1 could write printdenverprecipobs ' observations ' ' totalprecipvalue1 ' returns 013 request api created always return list since user request multiple stations time always stipulation function list latest get latest observation data particular stations attime get latest observation data particular stations specific time precipitation obtain precip totals specified period stations timeseries retrieve observations specified period stations climatology obtain climatology specified period stations metadata retrieve list station metadata based search parameters variables get list sensor variables possible observing stations climatestats retrieve aggregated yearly climate statistics stations timestats obtain statistics specific time frame stations latency retrieve data latency values stations networks obtain metadata concerning observing networks mesowest repository networktypes returns network categories observing networks documentation function well documented docstrings interactive interpreter simply type helpsomefunc code type somefuncdoc example projects found examples path version license 202 released 7 jan 2016 mit license support credits mesopy designed simple possible hope enjoy usage questionscomments please direct supportmesowestorg mesowest group led dr john horel university utah additional facilities provided western region national weather service\n",
      "  (0, 141)\t0.15276506670430592\n",
      "  (0, 136)\t0.12247827915649544\n",
      "  (0, 135)\t0.15276506670430592\n",
      "  (0, 134)\t0.15898135046049555\n",
      "  (0, 133)\t0.09175354880882354\n",
      "  (0, 131)\t0.12783509893885303\n",
      "  (0, 128)\t0.13655035342081698\n",
      "  (0, 124)\t0.12049700243510919\n",
      "  (0, 120)\t0.1490388404309714\n",
      "  (0, 118)\t0.13655035342081698\n",
      "  (0, 117)\t0.1393726100034495\n",
      "  (0, 116)\t0.12671328619129882\n",
      "  (0, 114)\t0.15474634342569218\n",
      "  (0, 111)\t0.15276506670430592\n",
      "  (0, 108)\t0.14558889375963915\n",
      "  (0, 107)\t0.15276506670430592\n",
      "  (0, 104)\t0.10034589107073823\n",
      "  (0, 99)\t0.15474634342569218\n",
      "  (0, 98)\t0.11332082949044239\n",
      "  (0, 96)\t0.1141596445500746\n",
      "  (0, 93)\t0.1490388404309714\n",
      "  (0, 91)\t0.15681570527515684\n",
      "  (0, 90)\t0.10227249605794858\n",
      "  (0, 87)\t0.15474634342569218\n",
      "  (0, 86)\t0.1508646813608753\n",
      "  :\t:\n",
      "  (0, 75)\t0.15681570527515684\n",
      "  (0, 66)\t0.13655035342081698\n",
      "  (0, 65)\t0.1490388404309714\n",
      "  (0, 64)\t0.12247827915649544\n",
      "  (0, 63)\t0.13016323286263112\n",
      "  (0, 59)\t0.12783509893885303\n",
      "  (0, 58)\t0.10783767862295851\n",
      "  (0, 56)\t0.12350146268008014\n",
      "  (0, 47)\t0.11677077616177468\n",
      "  (0, 46)\t0.14237707024842045\n",
      "  (0, 42)\t0.12350146268008014\n",
      "  (0, 39)\t0.15898135046049555\n",
      "  (0, 38)\t0.14395528838012034\n",
      "  (0, 37)\t0.14085060640365213\n",
      "  (0, 36)\t0.13137246906554972\n",
      "  (0, 35)\t0.14085060640365213\n",
      "  (0, 31)\t0.14237707024842045\n",
      "  (0, 26)\t0.08726904897743529\n",
      "  (0, 24)\t0.15681570527515684\n",
      "  (0, 23)\t0.13794009770681653\n",
      "  (0, 21)\t0.1490388404309714\n",
      "  (0, 16)\t0.14237707024842045\n",
      "  (0, 15)\t0.10428228915162023\n",
      "  (0, 8)\t0.13016323286263112\n",
      "  (0, 4)\t0.13655035342081698\n",
      "scee website goal repo make maintain scee website society civil environmental engineering scee oldest largest technical society delhi technological university frontend frontend carried using bootstrap lot frontend tasks done lot still left website needs completed end october backend much backend work backend includes counting number visitors emailer send emails regarding new updates blogs using flask backend backend needs special attention contributions contributions welcome contributor guidelines look scee thanks valuable contributions list contributors follow us instagram printhappy coding\n",
      "  (0, 140)\t0.30796254498618686\n",
      "  (0, 133)\t0.22687428019072178\n",
      "  (0, 80)\t0.337641034535738\n",
      "  (0, 78)\t0.28020258567685236\n",
      "  (0, 77)\t0.39310500702949625\n",
      "  (0, 70)\t0.270358201008613\n",
      "  (0, 69)\t0.37303533688126606\n",
      "  (0, 66)\t0.337641034535738\n",
      "  (0, 41)\t0.1608063864739159\n",
      "  (0, 39)\t0.39310500702949625\n",
      "environmentalquizapp\n",
      "\n",
      "eink mini mqtt information display time headlines environmental data files setup run eink mqtt information display see httpswwwconnectedenvironmentsorgmakingthe files divided two parts scripts process data send mqtt via cron timetomqttpy gets time converts words publishes mqtt topic rsstomqttpy fetches rss news feed reads latest headline publishes mqtt topic clientrawmqttwdpy fetches feed weather display converts data text publish personal weather station darkskytomqttpy fetches weather dark sky converts wind bearing text publishes mqtt feed main script run eink display show mqtt feeds version eink phat thepiphatpy version eink thepiwhatpy check font download background images\n",
      "  (0, 136)\t0.28360226733443866\n",
      "  (0, 124)\t0.279014559421886\n",
      "  (0, 113)\t0.3296785374269792\n",
      "  (0, 106)\t0.3583199744435058\n",
      "  (0, 104)\t0.2323540338854175\n",
      "  (0, 88)\t0.33711561473026014\n",
      "  (0, 56)\t0.2859714806283084\n",
      "  (0, 45)\t0.2480039091114897\n",
      "  (0, 41)\t0.15058840103475257\n",
      "  (0, 38)\t0.33333295063053603\n",
      "  (0, 26)\t0.2020741990218293\n",
      "  (0, 12)\t0.34510407362200024\n",
      "environmentalquizapp\n",
      "\n",
      "coronawhy ties task force worldwide effort volunteers fight coronavirus covid19 understanding covid19 transmission incubation environmental stability documentation httpstasktiesreadthedocsioenlatest task homepage httpsgithubcomcoronawhytaskties main coronawhy homepage httpswwwcoronawhyorg coronawhy coronawhy crowdsourced team 350 engineers researchers project managers sorts professionals diverse backgrounds joined forces tackle greatest global problem todayunderstanding conquering covid19 pandemic team formed response kaggle cord19 competition synthesize flood new knowledge generated every day covid19 goal organization inform policy makers care providers combat virus knowledge latest research disposal coronawhy ties task todo coronawhy ties task force list collaborators pending install also although strictly required usage virtualenv highly recommended order avoid interfering software installed system minimum commands needed create virtualenv using python36 taskties pip install virtualenv virtualenv p python36 taskties afterwards execute command activate virtualenv source tasktiesbinactivate remember execute every time start new console work taskties virtualenv activated clone repository install source running make installdeveop stable branch git clone gitgithubcomcoronawhytasktiesgit cd taskties git checkout stable make installdevelop code installed local system ready help us contribution first please look contributing guide\n",
      "  (0, 140)\t0.16915513895031076\n",
      "  (0, 133)\t0.12461564243675999\n",
      "  (0, 128)\t0.18545669608874407\n",
      "  (0, 124)\t0.16365373944763384\n",
      "  (0, 118)\t0.18545669608874407\n",
      "  (0, 116)\t0.17209642317925505\n",
      "  (0, 115)\t0.17362002001060475\n",
      "  (0, 105)\t0.16915513895031076\n",
      "  (0, 102)\t0.21016969099376873\n",
      "  (0, 100)\t0.19337028711814153\n",
      "  (0, 98)\t0.1539073763549079\n",
      "  (0, 90)\t0.1389020148575077\n",
      "  (0, 87)\t0.21016969099376873\n",
      "  (0, 86)\t0.20489778796430205\n",
      "  (0, 83)\t0.18928976109529677\n",
      "  (0, 78)\t0.1539073763549079\n",
      "  (0, 70)\t0.1485001335471469\n",
      "  (0, 69)\t0.20489778796430205\n",
      "  (0, 67)\t0.20489778796430205\n",
      "  (0, 66)\t0.18545669608874407\n",
      "  (0, 60)\t0.21016969099376873\n",
      "  (0, 58)\t0.14646040153159215\n",
      "  (0, 52)\t0.19337028711814153\n",
      "  (0, 50)\t0.18928976109529677\n",
      "  (0, 49)\t0.17518124029379434\n",
      "  (0, 41)\t0.08832641206193656\n",
      "  (0, 37)\t0.19129711092886265\n",
      "  (0, 22)\t0.14954521864613143\n",
      "  (0, 16)\t0.19337028711814153\n",
      "  (0, 15)\t0.14163162761673398\n",
      "  (0, 14)\t0.18011045300491507\n",
      "  (0, 10)\t0.18734418577465795\n",
      "environmentaleconomic electric power dispatch nsgaii 1 algorithm shared library develpoment environment windows 64 visual studio 2015 visual studio 2015 project 11 nsgaii shared library shared library based nsgaii nondominated sorting genetic algorithm riginal code c dr kalyanmoy deb httpwwwiitkacinkangal 12 environmentaleconomic electric power dispatchshared library shared library based nsgaii shared library developing applications around environmentaleconomic electric power dispatch 2 example python python 35 python packages numpy matplotlib tornado standard ieee sixgenerator 30bus test system abido novel multiobjective evolutionary algorithm environmentaleconomic power dispatch electric power systems research 657181 2003 used demonstrate effectiveness shared library 21 example api python pythonexample run python biobjloaddispatchpy ctypes import import numpy np import pylab plt class nsga2cfgstructure fields nrealcint nobjcint nconcint popsizecint ngencint pcrossrealcdouble pmutrealcdouble etaccdouble etamcdouble class curvecoffstructure fields ccfloat3 ecfloat5 class unitloadstructure fields mincfloat maxcfloat coffcurvecoff class loadvstructure fields xrealcfloat10 cobjcfloat eobjcfloat loadmin 005005005005005005 loadmax cdouble6 loadmax 1515115151515 c10200100 10150120 2018040 1010060 2018040 10150100 e cdouble65 e40915554649020e42857 25436047563850e43333 42585094458610e68000 54263550338020e32000 42585094458610e68000 61315555515110e56667 mydllwindlllibseubiobjloaddispatch fmydllseubiobjloaddispatch unitnumcint totalloadcdouble gansga2cfg popsizecint bestcloadv besteloadv bestloadv unitnum6 uloadunitloadunitnum rangeunitnum uloadimin loadmini uloadimax loadmaxi j range3 uloadicoffcjcij j range5 uloadicoffejeij ganrealunitnum ganobj2 gancon1 gapopsize200 gangen200 gapcrossreal09 gapmutreal01 gaetac20 gaetam15 x pointercdouble gapopsize rangegapopsize xi cdouble ganreal obj pointercdouble gapopsize rangegapopsize obji cdouble ganobj totalload2834 fgaunitnumuloadcdoubletotalloadbyrefxbyrefobjbyrefpopsizebyrefbestcbyrefbestebyrefbest print ' bestc ' printbestccobj printbestceobj print ' load ' rangeganreal printbestcxreali100 print ' beste ' printbestecobj printbesteeobj print ' load ' rangeganreal printbestexreali100 print ' best ' printbestcobj printbesteobj print ' load ' rangeganreal printbestxreali100 print ' paretocobj ' cnpzerosshapegapopsize rangegapopsize ciobji0 printobji0 print ' paretoeobj ' enpzerosshapegapopsize rangegapopsize eiobji1 printobji1 bcnpzerosshape1 bc0bestcobj benpzerosshape1 be0besteobj pltplotce ' b ' label ' pareto ' pltplotbcbe ' ro ' label ' best ' pltminortickson pltxlabel ' ch ' pltylabel ' eth ' pltshow 22 example web application webappexamplewebappexample simple web application based tornado run python apppy 3 ppt chinese ppt designed introduce shared library ' application chinese undergraduate computer design contest 2014 4 award 1st prize 7th china undergraduate computer design contest jiangsu province 3rd prize 7th china undergraduate computer design contest 5 license mit\n",
      "  (0, 139)\t0.23921422436894713\n",
      "  (0, 130)\t0.20460396366154104\n",
      "  (0, 123)\t0.2756045057494758\n",
      "  (0, 114)\t0.2895724791061816\n",
      "  (0, 104)\t0.18777444301568022\n",
      "  (0, 102)\t0.2895724791061816\n",
      "  (0, 96)\t0.2136237312910693\n",
      "  (0, 90)\t0.19137964472871927\n",
      "  (0, 63)\t0.24357079588511577\n",
      "  (0, 42)\t0.23110481275238187\n",
      "  (0, 40)\t0.21205408026764505\n",
      "  (0, 31)\t0.26642620618371915\n",
      "  (0, 15)\t0.19514051400511961\n",
      "  (0, 13)\t0.2858649717150122\n",
      "  (0, 8)\t0.24357079588511577\n",
      "  (0, 6)\t0.2581234242881633\n",
      "  (0, 4)\t0.25552283490225786\n",
      "environmentalsamplelogger application helps environmental consultants visualize distribution subsurface soil drilling boreholes user create new borehole location add samples specify parameters colour stratigraphy whether sample odourous save progress come back later\n",
      "  (0, 131)\t0.3975853054011419\n",
      "  (0, 78)\t0.3524438669447046\n",
      "  (0, 68)\t0.46921057605470595\n",
      "  (0, 41)\t0.2022651737540819\n",
      "  (0, 22)\t0.3424546398685535\n",
      "  (0, 6)\t0.42901328609336675\n",
      "  (0, 1)\t0.3940963085016865\n",
      "mhav env check jenkins\n",
      "  (0, 12)\t1.0\n",
      "binsanity v03 please see wiki usage installation requirements httpsgithubcomedgrahambinsanitywiki issue arises process utilizing binsanity please create issue address soon possible expedite response please provide associated error messages project actively improved comments suggestions welcome binsanity forum citation graham ed heidelberg jf tully bj 2017 binsanity unsupervised clustering environmental microbial assemblies using coverage affinity propagation peerj 5e3035 httpsdoiorg107717peerj3035\n",
      "  (0, 133)\t0.25164265796395363\n",
      "  (0, 128)\t0.37450206914969153\n",
      "  (0, 101)\t0.40393437913147046\n",
      "  (0, 92)\t0.38629591368831273\n",
      "  (0, 90)\t0.28049185103732155\n",
      "  (0, 88)\t0.39929110831497444\n",
      "  (0, 59)\t0.35059967157329647\n",
      "  (0, 41)\t0.17836198301481088\n",
      "  (0, 22)\t0.3019842097673299\n",
      "environementalmodellinggithubio environmental modelling courses rudn\n",
      "  (0, 41)\t1.0\n",
      "environmental health channel environmental health channel interactive webbased platform creating sharing environmental sensing health data narratives data shared affected residents collected environmental health project ehp includes physical psychosocial health symptoms particulate pollution pm25 air measurements personal stories residents tool displays data using visualization exploratory data analysis techniques enables researchers health professionals public interactively explore share compelling scientific evidence local impacts oil gas drilling usage first get google map javascript api key replace api key folowing line webvizhtml file script srchttpsmapsgoogleapiscommapsapijskeyyour api keyscript obtain zcta5 json file documented project run following bash commands terminal cd path ehpchannel folder mkdir data cd data mkdir geo cd geo mv path zcta5 json file mv zcta5 json file zcta5json cd py python updatechanneldatapy create data folder web folder website running python command need install dependencies see libraries imported utilpy file utilpy file shared projects libraries used project however run code please install deployment example apache config file https virtualhost 443 servername envhealthchannelorg serveralias wwwenvhealthchannelorg sslengine rewriteengine rewritecond httphost envhealthchannelorg nc rewritecond httphost rewriterule httpenvhealthchannelorg1 lr301 header set cachecontrol maxage0 mustrevalidate documentroot yourpathenvhealthchannelorgwwwweb directory yourpathenvhealthchannelorg addoutputfilterbytype deflate applicationoctetstream allowoverride none allow listing directory ' indexhtml follow symlinks options indexes followsymlinks order allowdeny allow directory sslcertificatefile etcletsencryptliveenvhealthchannelorgcertpem sslcertificatekeyfile etcletsencryptliveenvhealthchannelorgprivkeypem include etcletsencryptoptionssslapacheconf sslcertificatechainfile etcletsencryptliveenvhealthchannelorgchainpem virtualhost virtualhost 80 servername envhealthchannelorg serveralias wwwenvhealthchannelorg rewriteengine rewriterule httpsservernamerequesturi lnerpermanent virtualhost add https support website please refer setup https section readme repository periodically update data channel set cron job crontab e add following line crontab 30 cd yourpathenvhealthchannelorgwwwpy runone python updatechanneldatapy\n",
      "  (0, 139)\t0.1543045323665248\n",
      "  (0, 133)\t0.11075196530091296\n",
      "  (0, 130)\t0.13197927095020132\n",
      "  (0, 128)\t0.16482436047678395\n",
      "  (0, 127)\t0.19189990183790961\n",
      "  (0, 125)\t0.184396479334867\n",
      "  (0, 120)\t0.17989870362716592\n",
      "  (0, 113)\t0.17185755263432725\n",
      "  (0, 112)\t0.13987887980681515\n",
      "  (0, 106)\t0.18678799763085882\n",
      "  (0, 105)\t0.15033637602119815\n",
      "  (0, 104)\t0.12112343108506396\n",
      "  (0, 98)\t0.13678494988511247\n",
      "  (0, 96)\t0.1377974493206584\n",
      "  (0, 95)\t0.18928583989115624\n",
      "  (0, 91)\t0.18928583989115624\n",
      "  (0, 90)\t0.12344895736129195\n",
      "  (0, 83)\t0.16823099125202792\n",
      "  (0, 76)\t0.14907357684720826\n",
      "  (0, 67)\t0.1821026017209065\n",
      "  (0, 65)\t0.17989870362716592\n",
      "  (0, 58)\t0.13016646218083255\n",
      "  (0, 54)\t0.19189990183790961\n",
      "  (0, 47)\t0.14094923975720786\n",
      "  (0, 46)\t0.17185755263432725\n",
      "  (0, 44)\t0.12587489660682588\n",
      "  (0, 42)\t0.14907357684720826\n",
      "  (0, 41)\t0.07849996623659888\n",
      "  (0, 36)\t0.15857434752478847\n",
      "  (0, 29)\t0.17573441375507054\n",
      "  (0, 26)\t0.10533890851819701\n",
      "  (0, 24)\t0.18928583989115624\n",
      "  (0, 22)\t0.1329080887643692\n",
      "  (0, 17)\t0.17376255535115395\n",
      "  (0, 16)\t0.17185755263432725\n",
      "  (0, 15)\t0.12587489660682588\n",
      "  (0, 10)\t0.16650186410403725\n",
      "  (0, 4)\t0.16482436047678395\n",
      "  (0, 3)\t0.17989870362716592\n",
      "  (0, 1)\t0.15295043796795155\n",
      "anomaly detection iotacquired environmental sensor data abstract demand monitoring landfill site increasing landfill site produces methane poisonous gas harmful existence nature monitoring landfill sites made possible using sensors data quality issues arising sensors persist research focusses solving problem anomaly detection turn solving issues related data quality giving indication presence subtle anomaly exhaustive search solve problem apply existing techniques core idea also involved speaking researchers industry basic techniques ranging gaussian mixture model autoencoder implemented finally various problems finding perfect solution reported ensemble approach solving problem anomaly detection ecological monitoring proposed\n",
      "  (0, 133)\t0.23193018666162923\n",
      "  (0, 109)\t0.38615215319822793\n",
      "  (0, 108)\t0.3680125700193739\n",
      "  (0, 107)\t0.38615215319822793\n",
      "  (0, 102)\t0.39116032874876605\n",
      "  (0, 74)\t0.37673317849547694\n",
      "  (0, 72)\t0.37673317849547694\n",
      "  (0, 41)\t0.16438996610776974\n",
      "  (0, 26)\t0.22059448470262336\n",
      "environmentalforecasting\n",
      "\n",
      "lake levels yahara watershed httpwwwyaharainfo madison wisconsin surrounding dane county saw near record level rainfalls late august widespread flooding caused two hundred million dollars damage associated press months leading flood lakes surrounding madison higher maximum level set wisconsin department natural resources 1979 often true lakes currently maximum level kept high questions hope address environment setup install postgresql make sure environment variable named user username value unix variants likely already exists create new user username permissions create database eg sudo u postgres createuser user recommended set sort virtual environment install requirements pip install r requirementstxt code code madisonlakelevels requires python 36 run tests python pytest run top level project running locally run get env set export flaskappapppy export databaseurlpostgresusermadisonlakes heroku ' env var format createdb madisonlakes u user run app flask run run debug mode ' prod export flaskenvdevelopment flask run deploy webapp deployed heroku found httpwwwyaharainfo herokuformat procfile runtimetxt used control deployment freetier database heroku used persist data cron job runs every 30 minutes updates database job created using heroku scheduler hits simple api route webapp causes update running job every 30 minutes nice side effect preventing website going hibernation mode heroku free tier\n",
      "  (0, 134)\t0.21812366169872507\n",
      "  (0, 133)\t0.12588658972931774\n",
      "  (0, 131)\t0.17539075994382208\n",
      "  (0, 130)\t0.15001467729932463\n",
      "  (0, 127)\t0.21812366169872507\n",
      "  (0, 121)\t0.19974910590163927\n",
      "  (0, 119)\t0.21812366169872507\n",
      "  (0, 114)\t0.21231319877917204\n",
      "  (0, 113)\t0.19534245881399132\n",
      "  (0, 112)\t0.15899379398093563\n",
      "  (0, 105)\t0.17088034183549616\n",
      "  (0, 104)\t0.13767535080921087\n",
      "  (0, 101)\t0.2020719454909512\n",
      "  (0, 96)\t0.15662792909583867\n",
      "  (0, 90)\t0.14031866798597473\n",
      "  (0, 87)\t0.21231319877917204\n",
      "  (0, 86)\t0.2069875279341173\n",
      "  (0, 78)\t0.15547706824477\n",
      "  (0, 71)\t0.20448245983552293\n",
      "  (0, 70)\t0.15001467729932463\n",
      "  (0, 58)\t0.1479541421820724\n",
      "  (0, 48)\t0.2069875279341173\n",
      "  (0, 40)\t0.15547706824477\n",
      "  (0, 27)\t0.1873481575551512\n",
      "  (0, 26)\t0.119733820732977\n",
      "  (0, 23)\t0.189254897632582\n",
      "  (0, 22)\t0.15107042115712208\n",
      "  (0, 20)\t0.21231319877917204\n",
      "  (0, 15)\t0.1430761198982819\n",
      "  (0, 5)\t0.18024405954521464\n",
      "  (0, 4)\t0.1873481575551512\n",
      "environmentalissues\n",
      "\n",
      "rgb480p20rgbubuntu 16ros kinectganzhixinxitxytxxyy xml pythonpythonopencvrosrospyoencvhaaropencvxml sample xml xmlcatkinwsxmlrosrosnodemsgubuntu roscorerosroshttpwikirosorgcn tanrgbrgb70y0tanzxyttxy ros 1xy 1rospython2737tensorflow objectdetection api 2\n",
      "  (0, 4)\t1.0\n",
      "privatenotes java linux algorithm environmental configuration etc content java linux java java java java jdbc jdbc jsp jvm java java hibernate spring struts2 sql mongodb mysql git maven linux shell java j2ee switchstring equal java object java javahashcode arraylistlinkedlistvector hashmapconcurrenthashmaphashmap treemaphashmaplindedhashmap collectioncollections try catch finallytryreturnfinally exceptionerror java overrideoverload interfaceabstract static class non static class java java java jvm hibernateidea ubuntuzookeeper mysql nginxmysqlredis ubuntutomcat ubunturedis getpost tcp tcp idea webxml servlet mapping mybatis mybatisresulttypenull zookeeper zookeeper zookeeper nginx nginx location 6 23\n",
      "  (0, 81)\t0.468940588091091\n",
      "  (0, 68)\t0.4511446878066732\n",
      "  (0, 49)\t0.38571468607410675\n",
      "  (0, 41)\t0.19447741232671772\n",
      "  (0, 18)\t0.4257633949088782\n",
      "  (0, 13)\t0.45682758684401364\n",
      "environmentallaw\n",
      "\n",
      "environmentalissues felix ' fables titlemy great gametitle hello\n",
      "\n",
      "environmental science associates jekyll theme based freelancer bootstrap theme\n",
      "  (0, 41)\t0.446952134070063\n",
      "  (0, 8)\t0.8945578739523878\n",
      "environmental applications gis winter 2017 dartmouth prof james dietrich jamestdietrichdartmouthedu\n",
      "  (0, 41)\t1.0\n",
      "meteobike mapping urban heat islands bikes meteobike educational raspberry pi zero project university freiburg chair environmental meteorology course tools meteorology 5th term minor meteorology climatology develop system measure analyze visualize urban heat island effect within short period 2 hours measure many systems simultaneously temperature humidity transcects inside outside city tag measurement locations gps system battery operated light mounted bikes communication raspberry pi zero smartphone enabled via wireless network overview students build mobile systems system assembled using following components component model link vendor germany price microcontroller raspberry pi zero w pimoronide 10 eur gps adafruit ultimate gps breakout pimoronide 40 eur temperature humidity sensor dht22 am2302 azdelivery amazonde 5 eur micro sd card noobs 16gb microsd pimoronide 5 eur battery poweradd pilot 2gs powerbank 10000mah poweradd amazonde 15 eur jumper wires elegoo jumper wire gye amazonde 7 eur screen 27inch epaper hat reicheltde 20 eur replaced product workshop 1 setting raspberry pi zero connecting sensors first workshop connect raspberry pi zero mouse keyboard screen set properly connect temperaturerelative humidiy sensor gps working install userinterface collect automatically data store sd card connecting starting raspberry pi zero raspberry pi zero w microcomputer running full operating system providing input output connectivity number interfaces settingup sdcard raspberry pi zero w comes micro sd card contains operating sysetm called raspbian preinstalled cases micro sd card housed inside larger regular sd card adapter pull microsd card insert carefully card slot make sure logo handpainted white number sticker back settingup temporary peripherals mouse keyboard screen first time setup raspberry pi zero w need additional components components need screen hdmi vga dvi connection usb keyboard usb mouse usb hub microusb usba convertor power supply course provided usb hub microusb usba provide screen usb keyboard usb mouse possibly also regular hdmi cable later system assigned wireless networks connect without keybord without mouse without screen using realvnc need phsyical keyboard mouse screen later exercises bike traverses remotely controlled laptop smartphone tablet connection cables supplies need initial setup specific models may vary screen shown first connect usb mouse keyboard raspberry pi zero w two miniusb ports one left usb devices mouse keyboard one right actually supplying power see first connect usb devices left one true usb port need connect two devices must also add initially usb hub setup connect screen tv initial setup connect first minihdmi hdmi coverter use regular hdmi cable connect screen rare cases need minihdmi vga adapter screen support hdmi vga minihdmi dvi adapter screen support hdmi dvi powerup system finally connect power supply right mini usb connector raspberry pi zero w starts green inicator light begins flash instructions follow screen settingup wireless network case firsttime installation follow instructions onscreen setup raspberry pi zero w automatically reboot resizing cases needed os already fully installed operational connect home wireless network click menubar wireless network icon select home network enter password hover mouse network icon read ip number note ip number sheet need later next localize raspberry pi zero w language region check hostname raspberryxx xx number system needed identify system point recommend reboot raspberry pi remote connection via wireless network test communication another device laptop smartphone first activate vnc go settings enable vnc also enable ssh und i2c next laptop smartphone install vnc viewer realvnc mac windows linux install desktop version vnc viewer ios devices use apple app store download vnc viewer android devices use google play download vnc viewer make sure laptop smartphone connected wireless raspberry pi zero w start viewer connect ip address previously noted likely 192168xy enter username pi password previously set able control raspberry pi zero w use mouse keybord remotely installing sensors installing dht22 temperature relative humidity probe dht22 lowcost digital temperature humidity sensor contains capacitive humidity sensor thermistor resistor changes temperature transfers data digitally raspberry pi zero w need three cables connect dht22 raspberry pi zero w one power red one signal orange one ground brown enable communication dht22 first time enter following commands lxterminal command line raspberry pi zero install adafruit dht 22 library library installed access programming language python system already use installing libray skipped someone else already installed library sudo aptget update sudo aptget install buildessential pythondev pythonopenssl git git clone httpsgithubcomadafruitadafruitpythondhtgit cd adafruitpythondht sudo python setuppy install next turn raspberry pi zero disconnect power cable raspberry pi zero connect dht22 sensor physically using presoldered wires power never connect sensors live powered system might damage board connect following color coding pins raspberry pi zero dht22 trh sensor cable color raspberry pi zero pin 1 red cable pin 1 3v pin 2 orange cable pin 7 gpio4 pin 3 cable pin 4 brown cable pin 9 ground double check connection correct wrong connection could also damage sensor raspberry pi zero reconnect power cable raspberry pi zero raspberry pi zero restarts green light flashes started dht 22 sensor polled following commands python version 2 version 3 first start phython development environment python 27 interactive mode python enter import adafruitdht humidity temperature adafruitdhtreadretryadafruitdhtdht224 print temperature humidity display currently measured values system measures temperature humidity every two seconds next exercise calculate vapour pressure using clausiusclapeyron equation first calculate saturation vapour pressure kpa convert relative humidity vapour pressure note temperature needs converted kelvins first import numpy saturationvappress 06113 numpyexp250100004615102731510temperature27315 vappresshumidity1000saturationvappress print vappress also calculate dewpoint temperature installing gps module adafruit ultimate gps 66 channel global positioning system using satellites accurately determine location speed altitude digitally communicates raspberry pi zero w four cables enabling serial communication gps module enable communication raspberry pi zero w first time need enable serial communication system used years follwing changes might already implemented skip section ' connecting gps ' serial communication installed start raspberry ' lxterminal type sudo aptget install gpsd gpsdclients pythongps sudo systemctl stop serialgettyttys0service sudo systemctl disable serialgettyttys0service sudo systemctl stop gpsdsocket sudo systemctl disable gpsdsocket raspberry pi zero need enable serial port gpio pins requires us change configuration file raspberry pi zero w use texteditor example nano command lxterminal edit file configtxt sudo nano bootconfigtxt scroll bottom file mouse arrow keys type new line enableuart1 save ctrl0 german strgo press enter next press ctrlx strgx exit nano editor finally reboot raspberry pi zero rebooted disable standard socket run command lxterminal enable serial port sudo gpsd devttys0 f varrungpsdsock next edit file etcrclocal using nano editor sudo nano etcrclocal insert end line exit 0 following line gpsd devttys0 f varrungpsdsock save ctrl0 german strgo press enter next press ctrlx strgx exit nano command line editor every time raspberry pi zero booted command executed connecting gps turn raspberry pi zero disconnect power cable raspberry pi zero connect gps physically using presoldered four wires following color coding pins raspberry pi zero gps cable color raspberry pi zero pvin black cable pin 4 5v gnd white cable pin 6 ground rx grey cable pin 8 txd tx purple cable pin 10 rxd double check connection correct reconnect power cable raspberry pi zero raspberry pi zero restarts green light flashes testing gps raspberry pi restarted test gps using following command command line cgps note gps searching signal flash red 5 times 10 seconds flashes red 15 seconds connected satellites gps needs outdoors least balcony window sill partial view sky connect satellites cannot connect satellites indoors running recording interface want data gps dht22 automatically collected written file would also benefit system data displayed real time screen done python program meteobike03py download raspberry pi zero place raspberry pis desktop download meteobike03py start meteobike03py using lxterminal assuming file downloaded desktop python desktopmeteobike03py next make changes personalize copy meteobike03py example open python development environment version 27 file open replace 01 line 41 raspberryid system ' two digit number system number 7 enter 07 replace andreas line 42 studentname first name quotes capital letter way idenitify data upload later save modified code file save close python development environment every time meteobike03py started create new datafile contains data sampled example id record raspberrytime gpstime altitude latitude longitude temperature temperatureraw relhumidity relhumidityraw vapourpressure vapourpressureraw velocity 01 8 20180506 082903 20180506t062904000z 281700 47991855 7845193 230 231 419 420 1196 1192 514 01 9 20180506 082911 20180506t062912000z 288000 47991375 7845212 229 230 419 420 1188 1185 668 01 10 20180506 082924 20180506t062925000z 290000 47991242 7845800 230 231 419 420 1196 1192 356 also place link called bash script desktop meteobikesh download meteobikesh ensure works must change permissions file follows make executable way started doubleclick chmod x desktopmeteobikesh doubleclick meteobikesh start user interface later automate startup boot process system ready calibrated please return system hiwi place calibration chamber done first workshop congratulations workshop 2 calibrating system finalize mobile unit second practical workshop enter calibration coefficients sensorcalibration2020readmemdcalibration weather hut system install system protable bikebag insert sensor radiation shield power system battery mobile entering calibration coefficients watched online lecture calibration results enter calibration coefficients derived intercomparison directly python code open file meteobike03py python 2 editor raspberry pi zero w change follwing four lines &#9; temperaturecala1 100000 &#9; temperaturecala0 000000 &#9; vappresscala1 100000 &#9; vappresscala0 000000 replace values 100000 000000 temperature vapour pressure based individual correction coefficients listed sensorcalibration2020readmemdtables 1 3 calibration diretory respecively make sure use delimiter assembly protable system materials needed complete assembly system second workshop include reflective tape scissors sensor screenradiation shield bag gpstrh sensor velcro screw bolt foam assembly screen tube begin assembly meteobike system carefully cut reflective tape length plastic tube wrap tube tape lengthwise cut another piece length repeat step minimal overlap first piece tape two pieces tape cover entire tube cases tape already glued plastic tube tube completely covered tape use scissors puncture hole tape holes tube located sensor screen temperature humitidy sensor connect temperature humidity sensor radiation shield must disconnect temperature humidity sensor raspberry pi please ensure sensor connected source power use cirlce hook loop velcro attach sheild sensor place one piece inside radiaiton shield side 3 holes located close small hole farthest large hole place second piece velcro back side temperature humidity sensor pass wires sensor shield largest hole press sensor shield ensure velcro hold sensor shield together place shield close bag put temperature humidity sensor wires large hole bag must connect radiation shield sensor bag best use wrench screwdriver available insert bolt screw shields two holes hole bag using wrench hold bolt place use screwdriver insert screw bolt hold secure place thin plastic plate holes inside bag apply screw bolt inside also tighten hand though reconnect dht22 sensor physically using presoldered wires raspberry pi w dht22 trh sensor cable color raspberry pi zero pin 1 red cable pin 1 3v pin 2 orange cable pin 7 gpio4 pin 3 cable pin 4 brown cable pin 9 ground please double check make sure connection correct foam arrangement ensure protection sensor special foam used see structured cubical formation allows remove specific size pattern need given 20x28 cubical foam sheet using remove two 7x12 cube pieces one base sensor one altered protect raspberry pi system able remove 6 different 7x12 sheets original 20x28 sheet sizing foam raspberry pi remove foam cubes arrangement found one location foam must use scissors remove half cube power cable guided faced bag connect battery arrange foam battery sensors comfortably situated within bag arrangement within bag consist battery base followed unaltered foam cable battery altered foam raspberry pi within placement battery raspberry pi gps must place raspberry pi top altered foam connect battery cable raspberry pi altered foam cut half cubes way raspberry pi touching metal surface battery could lead shortcuts ultimately damage gps placed front pocket please make sure antenna facing ensure full connection satellites accurate track recorded system complete look similar image connecting raspberry pi smartphone system set similar arranged optionally connect mobile device vnc viewer order see progress collecting data mobile device skip step next week anyway install epaper could place mobile device front pocket behind gps first step enable phone host personal hotspot although need access internet use data plan capacity required order build network wifi communicate raspberry phone however make sure browse web download files connected personal hotspot otherwise charges apply data plan also make sure use personal course password protect connection description german enable personal hotsopt ios smartphone description german enable personal hotsopt android smartphone cases wifi network enabled connect network raspberry pi zero boot raspberry pi zero change wifi network personal hotspot wifi name enter password promted read ip number hover wifi symbol menu bar see eg 17220107 without comes afterwards go back phone start vnc app vnc app create new connection enter local ip number read eg 17220107 without comes afterwards connecting enter username pi previously set vnc password able control raspberry pi zero long phone raspberry close together put phone transparent lid bag also use second outlet power bank keep phone charged measurements case must bring chargercable ready install system bike let ' go test drive make sure indicator changes red yellow soon outdoors recording start good gps connection drive 15 20 minutes come back see data recorded display analyze recorded gps track gps track stored raspberry desktop commaseparated file raspberry wlan host computer easily establish ftp connection copy file host example free cyberduck free filezilla also use vnc software tranfer files first graphical representation track done place website httpwwwgpsvisualizercommapinput top left choose 1400 top right upload choose file click draw map colorcoded drawing temperature track options click advanced options make following settings colorize custom field custom colorization field temperature spectrum direction hue 1 120 hue 2 0 click draw map example also option export google earth workshop 3 installing epaper display feedback buttons workshop finalize meteobike adding epaper display responsive buttons instrument independent computer smartphone epaper uses imaging display technology called microencapsulated electrophoretic display med epaper displays patterns reflecting ambient light background light similar ereader requires little power readable full sunlight also slow update wiring epaper using wireframe 27inch epaper hat hat display black red color resolution 176 x 264 pixels screen look like back first turn raspberry pi w zero disconnect power cable 8 different wires ready connected raspberry pi follows plug white plastic connection back epaper cable color raspberry pi zero vcc grey cable pin 17 33v gnd brown cable pin 20 ground din blue cable pin 19 gpio10 clk yellow cable pin 23 gpio11 cs orange cable pin 24 gpio8 dc green cable pin 22 gpio25 rst white cable pin 11 gpio17 busy purple cable pin 18 gpio24 raspberry pi w zero connect wires exactly according drawing please doblecheck repowering starting raspberry pi w zero connections look like photo programming testing epaper doublechecked connection cable boot ie repower raspberry pi w zero connect via vnc alternatively screen keyboard mouse installation required libraries open lxterminal enter following commands updating python 2 environment downloading required libraries make sure raspberry pi zero w connection internet download drivers sudo aptget update sudo aptget install pythonpip sudo aptget install pythonpil sudo aptget install pythonnumpy sudo pip install rpigpio sudo pip install spidev next download python epaper library waveshare examples sudo git clone httpsgithubcomwaveshareepaper place epaper software homepiepaper raspberry pi test epaper go directory run factory test cd epaperraspberrypijetsonnanopythonexamples python epd2in7btestpy connected epaper correctly see number fancy tests visualisations epaper black red experts details setup programming found wireframe webpage httpswwwwavesharecomwiki27inchepaperhat hardware software setup section update meteobike program epaper version use epaper version meteobike program called meteobikeepaperpy found students university freiburg python script also available ilias place file meteobikeepaperpy raspberry pi ' desktop open file change lines 41 46 systemspecific information meteobike name calibration coefficients raspberryid 52 enter raspberry ' number studentname andreas enter first name spaces special characters temperaturecala1 100000 enter calibration coefficient slope temperature temperaturecala0 000000 enter calibration coefficient offset temperature vappresscala1 100000 enter calibration coefficient slope vapour pressure vappresscala0 000000 enter calibration coefficient offset vapour pressure start epaper version meteobike typing following command lxterminal python desktopmeteobikeepaperpy meteobikeepaperpy onscreen window anymore see anything onscreen happening program display output epaper instead first epaper display welcome screen boot screen left instructions use keys screen install next yet work 10 seconds epaper refresh display latest data measurement screen right refresh every 5 measurements every 40 seconds arrows next measurement values indicate variable increasing unchanged decreasing information displayed red show alerts example gps found enough satellites yet wifi network next change meteobikesh script point meteobikeepaperpy instead meteobike03py every startup raspberry pi w zero epaper version started instead old version make sure file meteobikesh permissions set done previously run chmod x desktopmeteobikesh new feature meteobikeepaperpy write one file per day file already exists given date data appended file written desktop also new column called speed gps time measurements actual speed system calculated enabling keys finally add three feedback buttons follows press key 1 program pause press key 2 program resume press key 4 program exit note key 3 currently assigned function connect three keys need 3wire cable 1 x blue 1 x green 1 x yellow follows connect wires shown drawing connections look similar following photos using epaper screen put top flap behind transparent protection alongside gps need using mobile device anymore make sure gps move epaper also ensure gps epaper touch connectors could cause shortcut use tape tie cables gps place well done ready measurements please test system follows press key 4 exit program reboot automatically reboots measurements take power fits bike see data gps measure records properly data riding around block also make sure charge battery end group exercise come workshop 4 detailed analysis geographic information system use free opensource geographic information system gis qgis perform advanced geographical analysis including statistics specific areas track rasterization many meteobike traces check separate page visualizing meteobike data wit qgis\n",
      "  (0, 141)\t0.10789507025135617\n",
      "  (0, 140)\t0.08796563747122678\n",
      "  (0, 139)\t0.09028750668039896\n",
      "  (0, 138)\t0.11075595947553177\n",
      "  (0, 137)\t0.09948011283419819\n",
      "  (0, 136)\t0.08650408643118675\n",
      "  (0, 135)\t0.10789507025135617\n",
      "  (0, 133)\t0.06480379191468788\n",
      "  (0, 132)\t0.10789507025135617\n",
      "  (0, 131)\t0.09028750668039896\n",
      "  (0, 130)\t0.07722442837444217\n",
      "  (0, 129)\t0.067497184676094\n",
      "  (0, 127)\t0.1122855136102078\n",
      "  (0, 126)\t0.09843623199892984\n",
      "  (0, 124)\t0.08510474824705122\n",
      "  (0, 123)\t0.10402242475190389\n",
      "  (0, 122)\t0.10929440843549171\n",
      "  (0, 121)\t0.10282667535778148\n",
      "  (0, 120)\t0.1052633072821947\n",
      "  (0, 119)\t0.1122855136102078\n",
      "  (0, 118)\t0.09644292568342319\n",
      "  (0, 117)\t0.09843623199892984\n",
      "  (0, 116)\t0.08949519160590284\n",
      "  (0, 115)\t0.09028750668039896\n",
      "  (0, 113)\t0.10055822530664074\n",
      "  :\t:\n",
      "  (0, 36)\t0.09278588413382388\n",
      "  (0, 35)\t0.09948011283419819\n",
      "  (0, 34)\t0.09948011283419819\n",
      "  (0, 32)\t0.10282667535778148\n",
      "  (0, 30)\t0.1122855136102078\n",
      "  (0, 26)\t0.06163647470802317\n",
      "  (0, 22)\t0.0777679033023358\n",
      "  (0, 21)\t0.1052633072821947\n",
      "  (0, 20)\t0.10929440843549171\n",
      "  (0, 19)\t0.09456358649947756\n",
      "  (0, 18)\t0.10055822530664074\n",
      "  (0, 16)\t0.10055822530664074\n",
      "  (0, 15)\t0.07365260367911822\n",
      "  (0, 14)\t0.09366272235136065\n",
      "  (0, 12)\t0.1052633072821947\n",
      "  (0, 11)\t0.10167289085070343\n",
      "  (0, 10)\t0.09742447572365313\n",
      "  (0, 9)\t0.09742447572365313\n",
      "  (0, 8)\t0.09193182353031608\n",
      "  (0, 7)\t0.09028750668039896\n",
      "  (0, 5)\t0.09278588413382388\n",
      "  (0, 3)\t0.1052633072821947\n",
      "  (0, 2)\t0.10929440843549171\n",
      "  (0, 1)\t0.08949519160590284\n",
      "  (0, 0)\t0.10655286411380395\n",
      "envirodashboard dashboard stack monitoring environment influxdb grafana grafana influxdb running docker find blog create environmental monitoring dashboard docker raspberry pi\n",
      "  (0, 105)\t0.48145803124415365\n",
      "  (0, 74)\t0.5761325233721069\n",
      "  (0, 41)\t0.251399163644042\n",
      "  (0, 40)\t0.43805906739584055\n",
      "  (0, 22)\t0.4256432704210827\n",
      "enviromonitor indooroutdoor environmental monitor project enviro environmental monitoring board uses openweather api get current weather show display also display turned onoff passing finger near light sensor reduce energy consumption python library steps install found pimoronienviropluspython installing install configure dependencies github git clone httpsgithubcompimoronienviropluspython cd enviropluspython sudo installsh cd note raspbian lite users may first need install git sudo apt install git git clone httpsgithubcomcesnietorenviromonitorgit cd enviromonitor add environment variables make sure valid appid openweather curl httpsapiopenweathermaporgdata25weatherid2172797appiduniqueuuidunitsimperial define city id appid environment variables export openweathermapcityidyourcityid export openweathermapappiduniqueuuid change timezone cityname timezone city python timezone enviromonitorpy running python3 enviromonitorypy want run background process using ssh raspberry pi make sure process reparented init setsid python3 enviromonitorpy devzero errorlog yout want run pi boots refer rclocal\n",
      "  (0, 137)\t0.19932119427834602\n",
      "  (0, 133)\t0.1298427276588354\n",
      "  (0, 132)\t0.21618164321033356\n",
      "  (0, 121)\t0.20602646249652268\n",
      "  (0, 119)\t0.22497846087333992\n",
      "  (0, 108)\t0.20602646249652268\n",
      "  (0, 105)\t0.1762504626974398\n",
      "  (0, 104)\t0.14200196477553648\n",
      "  (0, 96)\t0.16155015069585346\n",
      "  (0, 90)\t0.14472835138300957\n",
      "  (0, 88)\t0.20602646249652268\n",
      "  (0, 79)\t0.1859084465309159\n",
      "  (0, 76)\t0.17476998974338723\n",
      "  (0, 74)\t0.21090856778725803\n",
      "  (0, 71)\t0.21090856778725803\n",
      "  (0, 70)\t0.15472906948457893\n",
      "  (0, 58)\t0.1526037795658026\n",
      "  (0, 51)\t0.21090856778725803\n",
      "  (0, 50)\t0.19722964483351632\n",
      "  (0, 49)\t0.18252933283192999\n",
      "  (0, 41)\t0.0920313216076398\n",
      "  (0, 40)\t0.16036312265434538\n",
      "  (0, 29)\t0.20602646249652268\n",
      "  (0, 25)\t0.20371470691705382\n",
      "  (0, 14)\t0.18766530461771377\n",
      "  (0, 11)\t0.20371470691705382\n",
      "  (0, 10)\t0.19520246107425707\n",
      "  (0, 4)\t0.19323579938993965\n",
      "  (0, 1)\t0.17931512103116262\n",
      "technical environmental systems general information software installation instructions welcome polimi ' technical environmental systems course attending first session course fill following survey inform us contact information academic background software skills course survey tes survey link survey asked create account following websites insert corresponding account informatio dropbox registration case dropbox account crate free account indicate corresponding email address first section survey github registration case account github please create one username please use human readable format eg mrossi rossimarco rossimarco m007r92 building component library bcl registration please create account nrel ' building component library httpsbclnrelgov username format github account create account dashboard find api key please save number easy access software installation course use energyplus sketchup openstudio downloaded installed also download files windows 64bit following dropbox link important note pay attention softwares installed order given energyplus sketchup openstudio noteworthy case already sketchup software installed computer might reinstall openstudio version might compatible installed version sketchup order check whether correctly installed abovementioned softwares verify openstudio addon added sketchup tools case using another operating system eg linux macos windows 32bits download following links energyplus link download suitable version software based operating system sketchup find suitable installation file sketchup make 2016 operating system link pay attention going use sketchup make sketchup pro commercial software openstudio installation files openstudio different operating system found project description project geometry commercial building first introduced sketchup characteristics building defined employing openstudio latter software next used calculate yearly heating cooling consumption building base case next parametric study conducted order investigate effect changing position wall characteristics buildings yearly energy consumption accordingly simulation performed three different cities three different walls corresponding obtained yearly consumptions compared ones base case pay attention conduct sensitivity analysis walls one city group information send information members group via link till 11122019 assigned timeslot details regarding final exam final written examination include exercises theoretical questions exercises similar topics ones solved class theoretical questions instead posed topics context exercise solved including solar radiation heat transfer windows heat gain infiltration ventilation centralized hvac system solar thermal systems theoretical questions students required write corresponding formulas instead able explain concepts explanation schematic representation needed formulas students required remember formulas related heat transfer walls conduction convection heat transfer series parallel conditions simplified heat transfer wall calculations formulas given exam paper thus students allowed bring formula paper rlf weather data tables along psychometric chart needed also provided exam student bring calculator students clearly remember bring simple calculator\n",
      "  (0, 136)\t0.1496739665014854\n",
      "  (0, 133)\t0.1121269639431895\n",
      "  (0, 130)\t0.13361780908243326\n",
      "  (0, 129)\t0.11678721520503861\n",
      "  (0, 126)\t0.17031959874474273\n",
      "  (0, 115)\t0.15622024123836853\n",
      "  (0, 114)\t0.1891069925348153\n",
      "  (0, 100)\t0.17399118431205984\n",
      "  (0, 93)\t0.18213216713783667\n",
      "  (0, 90)\t0.12498159064956853\n",
      "  (0, 83)\t0.17031959874474273\n",
      "  (0, 80)\t0.16687067424876909\n",
      "  (0, 79)\t0.16054306665274307\n",
      "  (0, 70)\t0.13361780908243326\n",
      "  (0, 61)\t0.17998512625302518\n",
      "  (0, 60)\t0.1891069925348153\n",
      "  (0, 59)\t0.15622024123836853\n",
      "  (0, 56)\t0.15092434279260075\n",
      "  (0, 55)\t0.1916358457998132\n",
      "  (0, 54)\t0.1942823616323089\n",
      "  (0, 51)\t0.18213216713783667\n",
      "  (0, 48)\t0.18436342688496532\n",
      "  (0, 47)\t0.1426991411045068\n",
      "  (0, 45)\t0.13088657271141282\n",
      "  (0, 44)\t0.12743764821543915\n",
      "  (0, 41)\t0.07947455252679077\n",
      "  (0, 38)\t0.17591983786110477\n",
      "  (0, 35)\t0.17212577682967964\n",
      "  (0, 32)\t0.1779161771184381\n",
      "  (0, 30)\t0.1942823616323089\n",
      "  (0, 26)\t0.10664670342547365\n",
      "  (0, 22)\t0.13455815827872997\n",
      "  (0, 13)\t0.1866857832586135\n",
      "  (0, 12)\t0.18213216713783667\n",
      "  (0, 8)\t0.15906532561837758\n",
      "  (0, 4)\t0.16687067424876909\n",
      "  (0, 3)\t0.18213216713783667\n",
      "  (0, 0)\t0.18436342688496532\n",
      "bosch integrated environmental unit common unified sensor api supported ieu chips provides full feature access supported chips bmp280 bme280 bme680 bmp388 still providing rich chip specific features multiple heater profiles fifo access tested products adafruit bmp280 adafruit bme280 adafruit bme680 adafruit bmp388 note adafruit nolonger sells bmp085 bmp180 donation legacy chips welcome aid greater product support example usage api api organized around simple sensor class boschsensor provides object interface manipulating sensor method return promise simple demo usage follows const i2c1 await i2copenpromisified1 const addressedi2c1 new i2caddressedbusi2c1 0x77 const sensor await boschieusensoraddressedi2c1 await sensordetectchip await sensorcalibration const result await sensormeasurement boschieu sensoraddressedbus static factory method provide access boschsensor class boschieu sensor detectchip constructing sensor object detectchip method recommended attempt get detect version chip use register interactions sensordetectchip ifsensorvalid alternatively wish set chip initialization also possible sensorchipid chipbmp388 id returns chips id defined vendor valid chip detected valid returns true note legacy id call internal run detectchip sensorid thenid consolelog ' sensors id ' id calibration fetches calibration constants chip values unique chip needed perform compensation raw data values temperature pressure readings note must called measurment call return valid results note method caches results class needed externally though returned user inspection fifo fifo getter method returns static fifo class implementation provides namespace fifo functionality sensorfifoflush profile returns current chip profile device setprofileprofile sets profile chip note set entire profile fields included profile set defaults chip reset write softreset chip returning poweron state sensorresetthen measurement reads calculates related measurement data chip sensormeasurementthenresults process results fifo flush flushes fifo buffer using command register read reads current fifo buffer full specified size parses compensates frame data converter converter class common helps included ft meters altitude pa etc\n",
      "  (0, 136)\t0.15636388212198782\n",
      "  (0, 135)\t0.19503000080519087\n",
      "  (0, 133)\t0.1171386566583392\n",
      "  (0, 131)\t0.163202753003959\n",
      "  (0, 129)\t0.12200720525098566\n",
      "  (0, 128)\t0.1743292240310355\n",
      "  (0, 122)\t0.19755942987496117\n",
      "  (0, 120)\t0.1902728535805874\n",
      "  (0, 117)\t0.17793230368437463\n",
      "  (0, 114)\t0.19755942987496117\n",
      "  (0, 112)\t0.14794522183805028\n",
      "  (0, 109)\t0.19503000080519087\n",
      "  (0, 108)\t0.18586842319212588\n",
      "  (0, 104)\t0.12810820980561288\n",
      "  (0, 103)\t0.19260384302543584\n",
      "  (0, 97)\t0.1817679965992348\n",
      "  (0, 94)\t0.19260384302543584\n",
      "  (0, 92)\t0.17981921176709448\n",
      "  (0, 88)\t0.18586842319212588\n",
      "  (0, 81)\t0.20020131425254936\n",
      "  (0, 79)\t0.16771879396503345\n",
      "  (0, 78)\t0.14467287543915253\n",
      "  (0, 75)\t0.20020131425254936\n",
      "  (0, 62)\t0.19755942987496117\n",
      "  (0, 43)\t0.1902728535805874\n",
      "  (0, 42)\t0.1576701459670777\n",
      "  (0, 41)\t0.08302679386046412\n",
      "  (0, 26)\t0.11141344719393043\n",
      "  (0, 25)\t0.18378285438142647\n",
      "  (0, 16)\t0.1817679965992348\n",
      "  (0, 13)\t0.19503000080519087\n",
      "  (0, 4)\t0.1743292240310355\n",
      "  (0, 0)\t0.19260384302543584\n",
      "xdk iota data market place example add x sensors one specific nodejs server\n",
      "  (0, 117)\t0.44307749632676174\n",
      "  (0, 110)\t0.4176443612442077\n",
      "  (0, 109)\t0.48565326630432876\n",
      "  (0, 42)\t0.39262175599372473\n",
      "  (0, 26)\t0.2774358012437491\n",
      "  (0, 1)\t0.4028324187628225\n",
      "environmentalpollution info 5100 project 3 project focuses typical dangerous environment pollutants connection health designed map linear regression graph bubble chart presents pollutants distribution relation longevity disease\n",
      "  (0, 90)\t0.4899509412514268\n",
      "  (0, 40)\t0.542879554252549\n",
      "  (0, 31)\t0.6820776090309625\n",
      "eis document database search app makes archive epa ' environmental impact statements eis searchable linking results back eis documents epagov try eis search tool demo httpseissearchherokuappcom notes current version web app configured make requests user types autocomplete functionality may zero results showing halfway typing given word database currently used tool nonupdating snapshot records found epa ' eis database future enhancements pagination currently access first 10 results guithough remainder currently accessed via api adding facets search index help filter results axes like date range specific metadata fields geography document relevant better textpreprocessing tokenization tuning improved document mappings include relevant metadata fields appropriate weighting add info search page developers tools used app written go search index built bleve similar lightweight elasticsearch written golang using metadata extracted every reachable eis url including text extracted ocr attachedassociated pdfs developer setup install go make sure gopath ends right path profile run locally without cloning install repo ' dependencies go get githubcomedgigovdataarchivingeissearch run directory cd homegobin run eissearch server running httplocalhost8094 port specified command line output clone run clone repo go directory typically homegosrc inside cloned directory go build make file called eissearch run eissearch server running httplocalhost8094 port specified command line output license copyright copyright c 2019 environmental data governance initiative edgi program free software redistribute andor modify terms gnu general public license published free software foundation version 30 program distributed hope useful without warranty without even implied warranty merchantability fitness particular purpose see license file details\n",
      "  (0, 139)\t0.14032989725353562\n",
      "  (0, 136)\t0.13444949370314982\n",
      "  (0, 133)\t0.10072168116479731\n",
      "  (0, 131)\t0.14032989725353562\n",
      "  (0, 130)\t0.12002652966826398\n",
      "  (0, 126)\t0.1529951023161201\n",
      "  (0, 125)\t0.1676965582417932\n",
      "  (0, 121)\t0.15981897516517368\n",
      "  (0, 117)\t0.1529951023161201\n",
      "  (0, 115)\t0.14032989725353562\n",
      "  (0, 113)\t0.1562932231059415\n",
      "  (0, 110)\t0.144213015352928\n",
      "  (0, 107)\t0.1676965582417932\n",
      "  (0, 105)\t0.13672111814844137\n",
      "  (0, 104)\t0.11015385211620751\n",
      "  (0, 103)\t0.16561042632497663\n",
      "  (0, 95)\t0.1721431124290013\n",
      "  (0, 89)\t0.1721431124290013\n",
      "  (0, 85)\t0.15142257407411447\n",
      "  (0, 84)\t0.1529951023161201\n",
      "  (0, 71)\t0.16360612490680926\n",
      "  (0, 70)\t0.12002652966826398\n",
      "  (0, 65)\t0.16360612490680926\n",
      "  (0, 64)\t0.13444949370314982\n",
      "  (0, 63)\t0.14288558655192243\n",
      "  (0, 58)\t0.11837789845540003\n",
      "  (0, 55)\t0.1721431124290013\n",
      "  (0, 54)\t0.17452043109084678\n",
      "  (0, 52)\t0.1562932231059415\n",
      "  (0, 48)\t0.16561042632497663\n",
      "  (0, 44)\t0.11447499977302913\n",
      "  (0, 41)\t0.07139059383052672\n",
      "  (0, 36)\t0.144213015352928\n",
      "  (0, 32)\t0.15981897516517368\n",
      "  (0, 29)\t0.15981897516517368\n",
      "  (0, 27)\t0.14989699405358906\n",
      "  (0, 26)\t0.09579885945310741\n",
      "  (0, 25)\t0.15802569869444205\n",
      "  (0, 16)\t0.1562932231059415\n",
      "  (0, 14)\t0.14557584639676743\n",
      "  (0, 10)\t0.15142257407411447\n",
      "  (0, 9)\t0.15142257407411447\n",
      "  (0, 5)\t0.144213015352928\n",
      "  (0, 4)\t0.14989699405358906\n",
      "  (0, 1)\t0.13909843681028686\n",
      "  (0, 0)\t0.16561042632497663\n",
      "posec learning environmental calibration actions policy selfevolution posec code paper chao zhang yang yu zhihua zhou learning environmental calibration actions policy selfevolution proceedings 27th international joint conference artificial intelligence ijcai ' 18 stockholm sweden requirement python 27 argparse pickle keras 101 theano 082 tabulate scipy numpy instructions mainly use three tasks mujoco environment gym namely pusher striker thrower take pusher task example striker thrower alternative step 1training base policies generating multiple different configuration environmentsbr python changeenvconfigpy pusher using trpo1 generate multiple base policies python runpgpy env pusher agent modularrlagentzootrpoagent step 2optimizing combination weightss batch new configuration environments optimal weights base policies obtained based zoopt2 python getbestweightpy pusher step 3optimizing calibration actions batch new configuration environments optimal calibration actions obtained based zoopt2 python getbestactionpy pusher 1 schulman j levine abbeel p et al trust region policy optimization proceedings 32nd international conference machine learning icml ' 15 pages 18891897 lille france 2015 2 yuren liu yiqi hu hong qian yang yu chao qian zoopt toolbox derivativefree optimization arxiv180100329 2017\n",
      "  (0, 133)\t0.2105192536406502\n",
      "  (0, 129)\t0.21926891191124642\n",
      "  (0, 96)\t0.2619277780376435\n",
      "  (0, 78)\t0.26000320157614615\n",
      "  (0, 75)\t0.35979780250726934\n",
      "  (0, 61)\t0.3379234852412722\n",
      "  (0, 42)\t0.28336163651948937\n",
      "  (0, 41)\t0.14921409528078874\n",
      "  (0, 40)\t0.26000320157614615\n",
      "  (0, 35)\t0.32316749509832965\n",
      "  (0, 18)\t0.3266698122673322\n",
      "  (0, 15)\t0.23926518336505362\n",
      "  (0, 8)\t0.2986463955829045\n",
      "arcpyhabitat scripts delineating habitat environmental suitability\n",
      "  (0, 41)\t1.0\n",
      "welcome repository share develop code please read collaboration documentation use github\n",
      "  (0, 129)\t0.30977983134627995\n",
      "  (0, 98)\t0.36732862507364067\n",
      "  (0, 97)\t0.4615142131551058\n",
      "  (0, 51)\t0.48310829160225854\n",
      "  (0, 37)\t0.4565661919674331\n",
      "  (0, 15)\t0.33803026386095464\n",
      "environmentalsoundclassification environmentalsoundclassification using esc10 dataset dependencies python keras librosa sounddevice soundfile scikitlearn dataset uses esc10 dataset sound classification labeled set 400 environmental recordings 10 classes 40 clips per class 5 seconds per clip subset larger esc50 dataset setup repository trained convolution neural network multi layer perceptron svm sound classification achieved classification accuracy approx 80 mfcc melfrequency cepstrum feature used train models features like short term fourier transform chroma melspectrogram also extracted dataset downloaded kept inside dataset folder 10 different classes containing 10 ogg files visualize dataset running visualizedatapy script takes ogg file input converts wav form waveform visualized form plot python visualizedatapy dataset001 dog bark130226aogg sample wav file class generated kept within samplewav folder reference train classify execute mainpy python mainpy cnn training cnn python mainpy mlp training mlp python mainpy svm training svm internally mainpy uses extractfeaturespy nnpy svmpy create train model training done trained models automatically saved h5 format wave plot class baby wave plot class dog\n",
      "  (0, 133)\t0.1554758201310388\n",
      "  (0, 132)\t0.2588594592969112\n",
      "  (0, 130)\t0.1852751356197377\n",
      "  (0, 113)\t0.24125706364611968\n",
      "  (0, 112)\t0.19636476425395147\n",
      "  (0, 106)\t0.26221672042918515\n",
      "  (0, 105)\t0.2110452062310387\n",
      "  (0, 98)\t0.1920214436573578\n",
      "  (0, 96)\t0.19344281058024723\n",
      "  (0, 72)\t0.2525453919571551\n",
      "  (0, 64)\t0.20753868539483908\n",
      "  (0, 57)\t0.25563926810353826\n",
      "  (0, 46)\t0.24125706364611968\n",
      "  (0, 45)\t0.18148798933642912\n",
      "  (0, 44)\t0.1767056930383396\n",
      "  (0, 43)\t0.2525453919571551\n",
      "  (0, 41)\t0.1101998199104956\n",
      "  (0, 35)\t0.23867048011614392\n",
      "  (0, 29)\t0.24669947869170383\n",
      "  (0, 22)\t0.18657902861177367\n",
      "  (0, 13)\t0.2588594592969112\n",
      "readme readme would normally document whatever steps necessary get application running things may want cover ruby version system dependencies configuration database creation database initialization run test suite services job queues cache servers search engines etc deployment instructions\n",
      "  (0, 137)\t0.31011790542278245\n",
      "  (0, 136)\t0.2696666231095072\n",
      "  (0, 123)\t0.3242780447467457\n",
      "  (0, 107)\t0.33635057539150637\n",
      "  (0, 105)\t0.2742228417776658\n",
      "  (0, 104)\t0.22093662463517186\n",
      "  (0, 61)\t0.3242780447467457\n",
      "  (0, 29)\t0.3205504323933716\n",
      "  (0, 27)\t0.3006498208906996\n",
      "  (0, 18)\t0.3134787980900566\n",
      "  (0, 6)\t0.30370969118910873\n",
      "dvrsty entry environmental hackathon july 1213 2019 project allows specialists identify anomalies temperature co2 dew point humidity using artificial neural network known autoencoders addition reactjs front end back end python using aws sagemaker httpec2174129187236compute1amazonawscom3000 ec2 system host\n",
      "  (0, 133)\t0.2775214613179778\n",
      "  (0, 122)\t0.4680519927419075\n",
      "  (0, 96)\t0.3452918365597966\n",
      "  (0, 90)\t0.3093374907795344\n",
      "  (0, 41)\t0.196704638912744\n",
      "  (0, 39)\t0.48086136476346714\n",
      "  (0, 2)\t0.4680519927419075\n",
      "environmentalism h0licow environments tell us kappaext\n",
      "\n",
      "amritsartoday real time environmental data amritsar city backend frontend\n",
      "  (0, 124)\t0.7421020641275183\n",
      "  (0, 41)\t0.40052377006096307\n",
      "  (0, 26)\t0.5374618461191727\n",
      "requiredenvvarplugin require environmental variable application throw routhlessly zerodependency webpack plugin motivation ever found setting default env vars project make sure app get data developer forgets provide run risk serving hard debugging time contributors even worse ending wrong configuration deployment process accidental values environmental variables app get hard reminder face ' something set usage requirement webpack package installed since ' checking webpack plugin ' probably already register plugin provide required env var names parameters const requiredenvvarplugin require ' requiredenvvarplugin ' moduleexports plugins new requiredenvvarplugin ' apiurl ' ' user ' ' pass ' provide variables list revp ' apiurl ' ' user ' ' pass ' array revp ' apiurl ' ' user ' ' pass ' work hood uses webpack ' defineplugin passes object shape ' processenv ' apiurl xxx user xxx pass xxx xxx respective environmental variables derived processenvxxx ' find one throws faq throw ' warn user ' whole purpose plugin developer ' infere code ' find docs ' deduce application working env var ' set surely ' notice bunch logs spitted onto console startup message clear forgot ' launch license mit httpsopensourceorglicensesmitlicensephp\n",
      "  (0, 141)\t0.22061443561717975\n",
      "  (0, 140)\t0.1798644684989786\n",
      "  (0, 135)\t0.22061443561717975\n",
      "  (0, 132)\t0.22061443561717975\n",
      "  (0, 131)\t0.1846120242859585\n",
      "  (0, 128)\t0.1971980885628144\n",
      "  (0, 124)\t0.17401477156579706\n",
      "  (0, 121)\t0.21025102349532773\n",
      "  (0, 112)\t0.16735297894328477\n",
      "  (0, 104)\t0.14491370705793646\n",
      "  (0, 100)\t0.205612694546727\n",
      "  (0, 92)\t0.20340826413034507\n",
      "  (0, 90)\t0.1476959980690965\n",
      "  (0, 88)\t0.21025102349532773\n",
      "  (0, 81)\t0.22646413255036132\n",
      "  (0, 78)\t0.16365135944394504\n",
      "  (0, 71)\t0.21523323607982225\n",
      "  (0, 70)\t0.15790178033155075\n",
      "  (0, 66)\t0.1971980885628144\n",
      "  (0, 63)\t0.18797418006355968\n",
      "  (0, 60)\t0.22347568037110074\n",
      "  (0, 41)\t0.09391841866896357\n",
      "  (0, 28)\t0.19151337110931915\n",
      "  (0, 26)\t0.12602889130583042\n",
      "  (0, 18)\t0.205612694546727\n",
      "  (0, 15)\t0.1505984245114317\n",
      "  (0, 6)\t0.19920507653409872\n",
      "  (0, 5)\t0.1897204887464939\n",
      "r tools synoptic environmental spatial data tools reading plotting manipulating spatial data used australian antarctic division aad common example read environmental layer function date libraryraadtools ice readicec20180601 20190601 plotice available data sources accessed using read functions wide variety data sources data sets oceanography topography meteorology altimetry sea ice ocean colour many data sources mostly remote sensing include reanalysis model output products package uses r raster package always provides data standard raster rasterlayer rasterbrick rasterstack data set invdividually handled function ensure spatial temporal registration correct contents data library listed technical configuration would like collection added please make request via github issue contact one authors directly using raadtools two main ways use typical usecases raadtools read time series gridded data set function date optionally spatial subsetting match data set longitude latitude time corresponding value time series gridded data set examples workflows outlined ropensci blog post access raadtools repository data used raadtools available via nectar research cloud local use within aad two main ways access raadtools neither 1 2 work see local raadtools expert 1 rstudio raadtools server access raadtoolsrstudioserver need load package get started libraryraadtools 2 local computer within aad network installed trying installing devtoolsinstallgithubaustralianantarcticdivisionraadtools libraryraadtools typically provided access wont aware underlying details repository data used raadtools available rdsipublicraad aad scientific data collection anyone nectar account may run creating vm raadclient image search public images raadclient eg raadclient0620181016 choose latest one ensure ssh rstudio port 8787 open use default rstudiorstudio account create welcome make copies data collection use please respect citation usage requests data providers listed summary please note raadtools project released contributor code conduct contributing project agree abide terms\n",
      "  (0, 140)\t0.14117599558033225\n",
      "  (0, 134)\t0.18020694931421566\n",
      "  (0, 133)\t0.10400356439103012\n",
      "  (0, 132)\t0.1731607295624668\n",
      "  (0, 130)\t0.12393743593855056\n",
      "  (0, 129)\t0.10832618871924857\n",
      "  (0, 128)\t0.154781190035607\n",
      "  (0, 126)\t0.157980246072463\n",
      "  (0, 124)\t0.13658455628564017\n",
      "  (0, 112)\t0.131355701394613\n",
      "  (0, 110)\t0.14891200638065766\n",
      "  (0, 107)\t0.1731607295624668\n",
      "  (0, 104)\t0.11374307020097735\n",
      "  (0, 102)\t0.17540652652339406\n",
      "  (0, 99)\t0.17540652652339406\n",
      "  (0, 98)\t0.1284502925473852\n",
      "  (0, 97)\t0.16138583178118796\n",
      "  (0, 95)\t0.17775216885715894\n",
      "  (0, 94)\t0.17100662378673195\n",
      "  (0, 93)\t0.16893701484858945\n",
      "  (0, 90)\t0.11592689620492742\n",
      "  (0, 84)\t0.157980246072463\n",
      "  (0, 82)\t0.143630776037389\n",
      "  (0, 79)\t0.14891200638065766\n",
      "  (0, 76)\t0.1399901419943651\n",
      "  (0, 72)\t0.16893701484858945\n",
      "  (0, 70)\t0.12393743593855056\n",
      "  (0, 67)\t0.17100662378673195\n",
      "  (0, 64)\t0.1388303532465674\n",
      "  (0, 60)\t0.17540652652339406\n",
      "  (0, 54)\t0.18020694931421566\n",
      "  (0, 53)\t0.17100662378673195\n",
      "  (0, 51)\t0.16893701484858945\n",
      "  (0, 42)\t0.1399901419943651\n",
      "  (0, 41)\t0.07371676223531992\n",
      "  (0, 32)\t0.16502646582421185\n",
      "  (0, 28)\t0.150319243477804\n",
      "  (0, 26)\t0.09892033902230739\n",
      "  (0, 24)\t0.17775216885715894\n",
      "  (0, 22)\t0.1248096585043613\n",
      "  (0, 18)\t0.16138583178118796\n",
      "  (0, 15)\t0.11820501675878033\n",
      "  (0, 7)\t0.14490236199607523\n",
      "  (0, 0)\t0.17100662378673195\n",
      "xnucleoiks01a3 xnucleoiks01a3 motion mems environmental sensor expansion board stm32 nucleo equipped arduino uno r3 connector layout designed around lsm6dso 3d accelerometer 3d gyroscope lis2dw12 3d accelerometer lis2mdl 3d magnetometer hts221 humidity temperature sensor lps22hh pressure temperature sensor stts751 temperature sensor xnucleoiks01a3 interfaces stm32 microcontroller arduino boards via i2c pin examples several examples xnucleoiks01a3 library xnucleoiks01a3helloworld application provides simple example usage xnucleoiks01a3 expansion board shows display hyperterminal values onboard mems environmental sensors xnucleoiks01a3lis2dw126dorientation application shows use xnucleoiks01a3 lis2dw12 accelerometer find 6d orientation display data hyperterminal xnucleoiks01a3lis2dw12wakeupdetection application shows detect wakeup event using xnucleoiks01a3 lis2dw12 accelerometer xnucleoiks01a3lsm6dso6dorientation application shows use xnucleoiks01a3 lsm6dso accelerometer find 6d orientation display data hyperterminal xnucleoiks01a3lsm6dsofreefalldetection application shows detect free fall event using xnucleoiks01a3 lsm6dso accelerometer xnucleoiks01a3lsm6dsopedometer application shows use xnucleoiks01a3 lsm6dso accelerometer count steps xnucleoiks01a3lsm6dsosingletap application shows detect single tap event using xnucleoiks01a3 lsm6dso accelerometer xnucleoiks01a3lsm6dsodoubletap application shows detect double tap event using xnucleoiks01a3 lsm6dso accelerometer xnucleoiks01a3lsm6dsotiltdetection application shows detect tilt event using xnucleoiks01a3 lsm6dso accelerometer xnucleoiks01a3lsm6dsowakeupdetection application shows detect wakeup event using xnucleoiks01a3 lsm6dso accelerometer xnucleoiks01a3lsm6dsoxmlc application shows detect activity using mlc lsm6dsox accelerometer order use application stevalmki197v1 board needed connected xnucleoiks01a3 via dil24 interface xnucleoiks01a3stts751temeperaturelimit application shows detect low temperature high temperature events using xnucleoiks01a3 stts751 temperature sensor dependencies xnucleoiks01a3 library requires following stm32duino libraries stm32duino lsm6dso httpsgithubcomstm32duinolsm6dso stm32duino lis2dw12 httpsgithubcomstm32duinolis2dw12 stm32duino lis2mdl httpsgithubcomstm32duinolis2mdl stm32duino hts221 httpsgithubcomstm32duinohts221 stm32duino lps22hh httpsgithubcomstm32duinolps22hh stm32duino stts751 httpsgithubcomstm32duinostts751 stm32duino lsm6dsox httpsgithubcomstm32duinolsm6dsox documentation find source files httpsgithubcomstm32duinoxnucleoiks01a3 xnucleoiks01a3 datasheet available httpswwwstcomcontentstcomenproductsecosystemsstm32opendevelopmentenvironmentstm32nucleoexpansionboardsstm32odesensehwxnucleoiks01a3html\n",
      "  (0, 135)\t0.23981364198842803\n",
      "  (0, 133)\t0.1440365469665766\n",
      "  (0, 129)\t0.15002303296555072\n",
      "  (0, 128)\t0.214359462376552\n",
      "  (0, 122)\t0.24292388961632463\n",
      "  (0, 116)\t0.1989170384658421\n",
      "  (0, 114)\t0.24292388961632463\n",
      "  (0, 109)\t0.23981364198842803\n",
      "  (0, 108)\t0.22854834288224926\n",
      "  (0, 94)\t0.23683037925551764\n",
      "  (0, 83)\t0.21878989692751497\n",
      "  (0, 62)\t0.24292388961632463\n",
      "  (0, 48)\t0.23683037925551764\n",
      "  (0, 47)\t0.18330908834919776\n",
      "  (0, 45)\t0.16813484745019477\n",
      "  (0, 42)\t0.19387505399736218\n",
      "  (0, 41)\t0.10209176914370609\n",
      "  (0, 37)\t0.22111008509111163\n",
      "  (0, 31)\t0.22350635841376928\n",
      "  (0, 29)\t0.22854834288224926\n",
      "  (0, 26)\t0.13699668988234312\n",
      "  (0, 7)\t0.20067808244287091\n",
      "  (0, 6)\t0.21654111061491046\n",
      "sustainable living sustainableliving description sustainable living designed help students live sustainable lives even dont want offers sustainable living suggestions variety user interests saving money saving time social networking sustainable living incorporates gamification awarding points order encourage users participate points given users creating tips events completing tips attending events moderating content users earned points even compare scores users via leaderboard implemented features create event users submit event system approval moderators event approved user host even qr code users attend points complete tip users browse tips system work completing users complete tip receive points attend event users phyiscally events find qr code scan prove attended receive points moderate content tips events created system need moderated public facing moderators task approving denying tips events one one giving feedback whenever deny tip event compare scores leaderboard users get points see points stack users leaderboard page usabilty quality attributes supports small screen devices typical use time minutes provides quick access less 3 clicks frequently used features limits awkward fatiguing movements making buttons large grouped use color help user choose right action give feedback every finished interaction browser back button used undo always available running project project includes livereloading static server port 8080 change port gulpfilejs config build launch rebuild app whenever change application code start server run npm start prefer build without live reload buildoneachchange watcher run npm run build generating additional code add additional functionality application invoking subgenerators included flux generator add components using following commands components yo fluxcomponent componentname actions yo fluxaction actioncreatorname stores yo fluxstore storename\n",
      "  (0, 140)\t0.16229551627046443\n",
      "  (0, 137)\t0.18353958130925013\n",
      "  (0, 133)\t0.1195621968694106\n",
      "  (0, 131)\t0.16657933632620328\n",
      "  (0, 130)\t0.1424781179562434\n",
      "  (0, 129)\t0.12453147329708976\n",
      "  (0, 124)\t0.15701721093467855\n",
      "  (0, 118)\t0.17793600847313806\n",
      "  (0, 110)\t0.17118881191574487\n",
      "  (0, 105)\t0.16229551627046443\n",
      "  (0, 104)\t0.130758704584103\n",
      "  (0, 95)\t0.204343379299578\n",
      "  (0, 94)\t0.19658872019318843\n",
      "  (0, 90)\t0.13326922464311874\n",
      "  (0, 85)\t0.17974695619208708\n",
      "  (0, 83)\t0.18161363404216943\n",
      "  (0, 76)\t0.16093226241725392\n",
      "  (0, 52)\t0.1855286855247448\n",
      "  (0, 47)\t0.15216164071362193\n",
      "  (0, 43)\t0.19420950374273543\n",
      "  (0, 31)\t0.1855286855247448\n",
      "  (0, 30)\t0.20716538781434682\n",
      "  (0, 24)\t0.204343379299578\n",
      "  (0, 23)\t0.17974695619208708\n",
      "  (0, 22)\t0.1434808224956313\n",
      "  (0, 17)\t0.1875852297065763\n",
      "  (0, 15)\t0.13588814544402453\n",
      "  (0, 11)\t0.1875852297065763\n",
      "  (0, 9)\t0.17974695619208708\n",
      "  (0, 7)\t0.16657933632620328\n",
      "  (0, 6)\t0.17974695619208708\n",
      "  (0, 5)\t0.17118881191574487\n",
      "  (0, 1)\t0.1651175247852333\n",
      "  (0, 0)\t0.19658872019318843\n",
      "nag brooklyn ' greenpoint williamsburg toxicity map interactive map neighbors allied good growth showing pollution demographic data neighborhoods greenpoint williamsburg brooklyn new york created summer fall 2015 pratt ' spatial analysis visualization initiative dependencies nodejs cartodbjs mapboxjs bower jquery jquery ui handlebarsjs normalizecss installation bower install download dependencies locally data processing cartodb see sql directory code relating formatting data tables cartodb postgres creating basemap tiles requires using mapbox studio classic mapbox account note time creating project mapbox studio classic replaced newer version software titled mapbox studio basemap directory contains necessary files create basemap tiles mapbox studio classic tm2 files specifying styling basemap ' tiles tm2source contains necessary files point custom data layers data folder created mapbox studio classic adding data layer aka source data contains zipped esri shapefiles required tm2source toxicitybasemaptm2z project ' styles metadata compressed format updating map ' cartodb data layers ' styles make editing cartocss easier cartodb data layers layer ' corresponding cartocss saved mss file mss directory cartotojsjs script used minify mss file compile object returned appcartocss module update cartocss following alter corresponding mss file data layer mss directory save node cartotojsjs update appcartocss module stored inside file jscartojs contributors chris henrick bowon chung\n",
      "  (0, 136)\t0.17117857578244475\n",
      "  (0, 133)\t0.1282369569220592\n",
      "  (0, 130)\t0.15281552826138636\n",
      "  (0, 127)\t0.22219614233005894\n",
      "  (0, 124)\t0.16840949599349328\n",
      "  (0, 116)\t0.17709752302467363\n",
      "  (0, 115)\t0.1786653953832945\n",
      "  (0, 106)\t0.21627719508783005\n",
      "  (0, 100)\t0.19898960270384544\n",
      "  (0, 90)\t0.14293848948143786\n",
      "  (0, 81)\t0.21916938476104772\n",
      "  (0, 79)\t0.1836093085773198\n",
      "  (0, 78)\t0.15837990484723796\n",
      "  (0, 73)\t0.22219614233005894\n",
      "  (0, 70)\t0.15281552826138636\n",
      "  (0, 59)\t0.1786653953832945\n",
      "  (0, 58)\t0.15071652189672408\n",
      "  (0, 47)\t0.16320163292662637\n",
      "  (0, 46)\t0.19898960270384544\n",
      "  (0, 45)\t0.14969187781605756\n",
      "  (0, 44)\t0.14574742443514113\n",
      "  (0, 38)\t0.20119535815631412\n",
      "  (0, 36)\t0.1836093085773198\n",
      "  (0, 29)\t0.20347852415262324\n",
      "  (0, 26)\t0.12196931257303306\n",
      "  (0, 24)\t0.21916938476104772\n",
      "  (0, 23)\t0.1927883836330981\n",
      "  (0, 22)\t0.15389098339846016\n",
      "  (0, 19)\t0.18712711417092895\n",
      "  (0, 15)\t0.14574742443514113\n",
      "  (0, 3)\t0.20830025223201165\n",
      "environmentalcodefestapi api codefest app setting order get everything set run make install install requirements initialize database run start serving api run make run navigate http1270015000 view documentation\n",
      "  (0, 118)\t0.32075396070534046\n",
      "  (0, 112)\t0.272209184293373\n",
      "  (0, 104)\t0.23571042619168472\n",
      "  (0, 101)\t0.3459621792361424\n",
      "  (0, 83)\t0.3273833831442288\n",
      "  (0, 70)\t0.25683626962558775\n",
      "  (0, 58)\t0.25330848046205384\n",
      "  (0, 37)\t0.33085516617076005\n",
      "  (0, 27)\t0.32075396070534046\n",
      "  (0, 5)\t0.30859121726733635\n",
      "  (0, 4)\t0.32075396070534046\n",
      "environmentalmonitoring data prediction environmental monitoring\n",
      "  (0, 74)\t0.8075893407612512\n",
      "  (0, 41)\t0.35239684725122267\n",
      "  (0, 26)\t0.4728804486719727\n",
      "html5 environmental thermometer repository contains demo ' developed part article titled create html5 environmental thermometer written sitepoint html5 environmental thermometer simple adaptive environmental thermometer created show potentiality union brand new web technologies html5 css3 geolocation api others demo uses semantic possible detailed html5 markup css3 javascript styling positioning thermometer order look like real environmental thermometer since uses svg background image adapted different sizes without stretched however folder ' also png background image support older browsers ' support svg interesting part demo regards positioning thermometer labels fact since thermometer 90 rotated css3 sufficient center javascript used moreover latter used set number labels dynamically evenly space used pinch make thermometer employ followings html5 markup css3 style demo javascript jquery adjust thermometer position set position labels svg background adaptive much polyfill support browsers ' support meter element geolocation api get user current position google maps api convert geolocation address yahoo weather api retrieve woeid code temperature demo live demo available license html5 environmental thermometer dual licensed mit gpl30 author aurelio de rosa aurelioderosa\n",
      "  (0, 139)\t0.18275634789993703\n",
      "  (0, 132)\t0.2183968715111921\n",
      "  (0, 131)\t0.18275634789993703\n",
      "  (0, 130)\t0.15631458899769626\n",
      "  (0, 122)\t0.2212293557098621\n",
      "  (0, 120)\t0.21306976251830792\n",
      "  (0, 114)\t0.2212293557098621\n",
      "  (0, 112)\t0.16567078639728697\n",
      "  (0, 98)\t0.16200637470129337\n",
      "  (0, 83)\t0.1992506706917498\n",
      "  (0, 80)\t0.19521590003674222\n",
      "  (0, 78)\t0.16200637470129337\n",
      "  (0, 70)\t0.15631458899769626\n",
      "  (0, 69)\t0.21568003170857988\n",
      "  (0, 64)\t0.17509810045531238\n",
      "  (0, 63)\t0.18608470808320055\n",
      "  (0, 53)\t0.21568003170857988\n",
      "  (0, 46)\t0.2035459243923323\n",
      "  (0, 41)\t0.09297437294707431\n",
      "  (0, 35)\t0.201363652388893\n",
      "  (0, 33)\t0.22418776867493143\n",
      "  (0, 25)\t0.2058021856565169\n",
      "  (0, 23)\t0.19720271423982402\n",
      "  (0, 22)\t0.1574146691377826\n",
      "  (0, 19)\t0.19141181707608476\n",
      "  (0, 15)\t0.14908464478219247\n",
      "  (0, 7)\t0.18275634789993703\n",
      "  (0, 4)\t0.19521590003674222\n",
      "corbabased clientserver system requirements system broken number separate systems need communicate clientserver manner solve overall requirements 1 monitoring station monitoring station standalone monitoring system prototyped corba server supports following functionality least register regional centre upon initial activation remotely activated remotely deactivated remotely reset return upon request current value nitrogen oxides sensor identify anomalous potentially dangerous readings nitrogen oxides alert local server immediately 2 precompile idl open intellij terminal type local server prototyped corba server supports following functionality least receives requests register monitoring stations maintains list connected devices receives alerts connected monitoring stations maintains log alerts triggers alarm environmental centre two alarms happen within specified time frame returns log upon request polls connected monitoring stations requested returns set readings 3 monitoring centre monitoring centre prototyped corba server supports following functionality least receives confirmed alarms local servers alerts operator confirmed alarm received allows agencies eg environment agency local councils local pressure groups etc register notifications particular areas case alarms maintains list connected local servers polls local servers upon request displays results readings returned highlighting readings concern run demo intellij add libraries jacorb lib folder module note add module project required ' know minmum set add jboss library precompile idl open intellij terminal type cd relaywithguisdemosrc pathtojacorbdirbinidl localmonitoringstationlocalmonitoringstationuiidl eg would type cd relaywithguisdemosrc sparejacorb39binidl localmonitoringstationlocalmonitoringstationuiidl run different components system need start following order sensorsensorserver localmonitoringstationlocalmonitoringstationui headquarterheadquarterui\n",
      "  (0, 134)\t0.21522808658453618\n",
      "  (0, 124)\t0.16312818577877808\n",
      "  (0, 118)\t0.18486112493117515\n",
      "  (0, 112)\t0.1568831633892048\n",
      "  (0, 110)\t0.1778513332850972\n",
      "  (0, 108)\t0.19709745162614326\n",
      "  (0, 104)\t0.13584772093844977\n",
      "  (0, 103)\t0.20423978415352123\n",
      "  (0, 101)\t0.19938945569556393\n",
      "  (0, 100)\t0.1927493024453461\n",
      "  (0, 99)\t0.20949475712084367\n",
      "  (0, 90)\t0.138455948279584\n",
      "  (0, 83)\t0.18868188052528206\n",
      "  (0, 82)\t0.17154375687963924\n",
      "  (0, 80)\t0.18486112493117515\n",
      "  (0, 79)\t0.1778513332850972\n",
      "  (0, 76)\t0.16719560769884212\n",
      "  (0, 74)\t0.20176797064449845\n",
      "  (0, 73)\t0.21522808658453618\n",
      "  (0, 67)\t0.20423978415352123\n",
      "  (0, 66)\t0.18486112493117515\n",
      "  (0, 47)\t0.15808364093960153\n",
      "  (0, 46)\t0.1927493024453461\n",
      "  (0, 41)\t0.08804276275411936\n",
      "  (0, 40)\t0.15341312192124631\n",
      "  (0, 35)\t0.19068278400404257\n",
      "  (0, 25)\t0.19488588555849054\n",
      "  (0, 10)\t0.18674255317826882\n",
      "  (0, 2)\t0.20949475712084367\n",
      "  (0, 1)\t0.17154375687963924\n",
      "project bootstrapped create react app available scripts project directory run npm start runs app development mode open httplocalhost3000 view browser page reload make edits also see lint errors console npm test launches test runner interactive watch mode see section running tests information npm run build builds app production build folder correctly bundles react production mode optimizes build best performance build minified filenames include hashes app ready deployed see section deployment information npm run eject note oneway operation eject cant go back arent satisfied build tool configuration choices eject time command remove single build dependency project instead copy configuration files transitive dependencies webpack babel eslint etc right project full control commands except eject still work point copied scripts tweak point youre dont ever use eject curated feature set suitable small middle deployments shouldnt feel obligated use feature however understand tool wouldnt useful couldnt customize ready learn learn create react app documentation learn react check react documentation code splitting section moved httpsfacebookgithubiocreatereactappdocscodesplitting analyzing bundle size section moved httpsfacebookgithubiocreatereactappdocsanalyzingthebundlesize making progressive web app section moved httpsfacebookgithubiocreatereactappdocsmakingaprogressivewebapp advanced configuration section moved httpsfacebookgithubiocreatereactappdocsadvancedconfiguration deployment section moved httpsfacebookgithubiocreatereactappdocsdeployment npm run build fails minify section moved httpsfacebookgithubiocreatereactappdocstroubleshootingnpmrunbuildfailstominify\n",
      "  (0, 140)\t0.16527310227674097\n",
      "  (0, 139)\t0.16963551626375098\n",
      "  (0, 129)\t0.1268162140018944\n",
      "  (0, 125)\t0.20271725975545132\n",
      "  (0, 124)\t0.15989795749359478\n",
      "  (0, 123)\t0.19544118975684655\n",
      "  (0, 118)\t0.18120054578764636\n",
      "  (0, 112)\t0.1537765976572958\n",
      "  (0, 105)\t0.16527310227674097\n",
      "  (0, 104)\t0.13315769438933972\n",
      "  (0, 90)\t0.13571427418905554\n",
      "  (0, 85)\t0.1830447184083669\n",
      "  (0, 82)\t0.1681468853152691\n",
      "  (0, 79)\t0.17432956048665404\n",
      "  (0, 70)\t0.14509212024032458\n",
      "  (0, 56)\t0.16388483722365504\n",
      "  (0, 54)\t0.21096618757712568\n",
      "  (0, 46)\t0.18893252335388572\n",
      "  (0, 45)\t0.14212634136196886\n",
      "  (0, 37)\t0.1869069256540781\n",
      "  (0, 36)\t0.17432956048665404\n",
      "  (0, 34)\t0.1869069256540781\n",
      "  (0, 29)\t0.1931945714454998\n",
      "  (0, 22)\t0.14611322109202918\n",
      "  (0, 21)\t0.19777260587838896\n",
      "  (0, 20)\t0.2053463882364679\n",
      "  (0, 18)\t0.18893252335388572\n",
      "  (0, 16)\t0.18893252335388572\n",
      "  (0, 15)\t0.13838124352578982\n",
      "  (0, 12)\t0.19777260587838896\n",
      "  (0, 9)\t0.1830447184083669\n",
      "  (0, 7)\t0.16963551626375098\n",
      "  (0, 5)\t0.17432956048665404\n",
      "snapshots environmental twitter activity overview visit website environmentaltwitterherokuappcom default tweet cap set 500 tweets twitter rate limit ' quickly block using website would like increase cap change text box next reload button higher number must multiple 100 twitter may still return fewer tweets ' enough available rate limit reached increase cap risk background since inauguration donald trump 45th president united states epa faced severe funding cuts deregulation one biggest centers community response twitter many users expressed outrage praise recent changes environmental protection us capture well public opinion poll twitter data perform sentiment analysis order better understand public feels epa given time site track store data long periods rather looks quick snapshot twitter activity captured every page load argue provides context long term trend analysis rather allows users get insight public feels epa instant load site methods general sense website read current tweets epa recent tweets tags epa perform sentiment analysis tweets searching positive negative sentiment results graphed various charts look tweet counts retweet counts break sentiment timezone learn methods methods input data input analysis json object returned twitter rest apis focus following attributes input data jsonresponse ' statuses ' contains tweet objects returned latest search tweet ' fulltext ' extracts full text current status tweet ' user ' ' name ' gives username person tweeted current status tweet ' user ' ' timezone ' gives timezone user tweet ' retweetcount ' retweet count current tweet many times users retweeted tweet ' createdat ' gives date time tweet posted output data data plot broken following segments datasentiments sentiment total tweet dataitems raw tweet data eg username text etc datadates dates tweet dataretweets sentiment totals weighted retweet count see methodology datatimezones count tweets timezone datatimezonessentiment overall sentiment timezone display data display data using two histograms sentiment count tweets sentiment count retweets pie chart timezone distribution bar chart overall sentiment timezone deploying deploy website simply push updated files repo automatically deploys heroku app crashes let know restart dynos author web app created nick moolenijzer nickmoolenijzercom contact questions architecture django used django framework serve render html files output python data analysis heroku builds hosts web app redis go heroku addon simple redis implementation libraries pythonoauth2 utilized authorize get requests using twitter auth tokens natural language toolkit necessary tools analyzing tweets sentiment eg tokenizing pos analysis classifying plotly used plot results text analysis numpy helps various calculations scientific analysis djangorq provides framework background workers analyze twitter data web dyno redis provides backend rq background workersqueueing apis twitter rest apis allows programmatic search twitter activity assets google material icons icons web use license written code licensed mit license open source license libraries data external resources may licenses must followed sources tutorials helpful references bird steven ewan klein edward loper natural language processing python beijing ' reilly 2009 httpwwwnltkorgbook1ed kantrowitz mark bill ross names corpus np 29 mar 1994 web 30 jan 2017 httpwww2cscmueduafscsprojectairepositoryaiareasnlpcorporanames liu bing pros cons np 2008 web httpswwwcsuiceduliubfbssentimentanalysishtmldatasets loper edward source code nltkclassifynaivebayes nltkclassifynaivebayes nltk 30 documentation np nd web 30 jan 2017 nltk classifiers classifiers np nd web 30 jan 2017 nltk natural language toolkit natural language toolkit nltk 30 documentation np nd web 30 jan 2017 nltk nltk package nltk package nltk 30 documentation np nd web 30 jan 2017 nltk nltkclassify package nltkclassify package nltk 30 documentation np nd web 30 jan 2017 perkins jacob python nltk demos natural language text processing python nltk demos natural language text processing nlp np nd web 30 jan 2017 poole david alan mackworth artificial intelligence artificial intelligence foundations computational agents 733 bayesian classifiers np 2010 web 30 jan 2017 5 categorizing tagging words nd retrieved march 12 2017 httpwwwnltkorgbookch05html asynchronous tasks jobs django rq enproftme nd retrieved march 11 2017 httpenproftme2016104asynchronoustasksandjobsdjangorq background tasks python rq heroku dev center nd retrieved march 7 2017 httpsdevcenterherokucomarticlespythonrq coolors nd retrieved march 11 2017 httpscoolorsco9f7e69d2bba0f2efc7f7ffe0ffeee2 deploying python django apps heroku heroku dev center nd retrieved february 16 2017 httpsdevcenterherokucomarticlesdeployingpython django connection refused redis heroku stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions11813470connectionrefusedforredisonheroku get searchtweets twitter developers nd retrieved march 9 2017 httpsdevtwittercomrestreferencegetsearchtweets google fonts nd retrieved march 8 2017 httpsfontsgooglecom heroku redis heroku dev center nd retrieved march 11 2017 httpsdevcenterherokucomarticlesherokuredisconnectinginpython histograms nd retrieved march 11 2017 httpsplotlypythonhistograms use sessions django documentation django nd retrieved march 11 2017 httpsdocsdjangoprojectcomen110topicshttpsessions http get request javascript stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions247483httpgetrequestinjavascript javascript whats easiest way call function every 5 seconds jquery stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions2170923whatstheeasiestwaytocallafunctionevery5secondsinjquery joestumppythonoauth2 nd retrieved march 12 2017 httpsgithubcomjoestumppythonoauth2 joestumppythonoauth2 fully tested abstract interface creating oauth clients servers nd retrieved february 16 2017 httpsgithubcomjoestumppythonoauth2 managing static files eg images javascript css django documentation django nd retrieved february 16 2017 httpsdocsdjangoprojectcomen110howtostaticfiles material icons material design nd retrieved march 12 2017 httpsmaterialioicons natural language toolkit nltk 30 documentation nd retrieved march 12 2017 httpwwwnltkorg numpy numpy nd retrieved march 12 2017 httpwwwnumpyorg personal apps heroku nd retrieved march 12 2017 httpsdashboardherokucomapps pie charts nd retrieved march 11 2017 httpsplotlypythonpiecharts pyplot matplotlib 200 documentation nd retrieved march 8 2017 httpmatplotliborgapipyplotapihtml python adding config modes plotlypy offline modebar stack overflow nd retrieved march 9 2017 httpstackoverflowcomquestions36554705addingconfigmodestoplotlypyofflinemodebar python embedding plotly chart django template stack overflow nd retrieved march 9 2017 httpstackoverflowcomquestions36846395embeddingaplotlychartinadjangotemplate python flask passing around background worker job rq redis stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions12162021flaskpassingaroundbackgroundworkerjobrqredis python get job result rq stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions22776924pythonhowtogetjobresultbyrq redis nd retrieved march 12 2017 httpsredisio redis get job id rq python stack overflow nd retrieved march 11 2017 httpstackoverflowcomquestions15181630howtogetjobbyidinrqpython redis oom command allowed used memory maxmemory 2016 may 16 retrieved httpsmattiasberedisoomcommandnotallowedusedmemorymaxmemory redis go addons heroku elements nd retrieved march 12 2017 httpselementsherokucomaddonsredistogo rest apis twitter developers nd retrieved february 16 2017 httpsdevtwittercomrestpublic rq simple job queues python nd retrieved march 11 2017 httppythonrqorg simple job queues djangorq imaginary landscape nd retrieved march 11 2017 httpswwwimagescapecomblog20130613simplejobqueuesdjangorq singleuser oauth examples twitter developers nd retrieved february 16 2017 httpsdevtwittercomoauthoverviewsingleuser smistad e nd making charts output images browser django erik smistad retrieved httpswwweriksmistadnomakingchartsandoutputingthemasimagestothebrowserindjango stack overflow nd retrieved march 7 2017 httpstackoverflowcom street nd using redisqueue asynchronous calls django retrieved httpracingtadpolecomblogredisqueuewithdjango web framework perfectionists deadlines django nd retrieved march 12 2017 httpswwwdjangoprojectcom thumbnail gallery matplotlib 200 documentation nd retrieved march 7 2017 httpmatplotliborggalleryhtml uidjangorq nd retrieved march 12 2017 httpsgithubcomuidjangorq visualize data together nd retrieved march 12 2017 httpsplotly worldvectorlogo brand logos free download nd retrieved march 7 2017 httpsworldvectorlogocom\n",
      "  (0, 139)\t0.13324046404847611\n",
      "  (0, 138)\t0.1634464831207681\n",
      "  (0, 133)\t0.09563324566463421\n",
      "  (0, 131)\t0.13324046404847611\n",
      "  (0, 130)\t0.11396281778952667\n",
      "  (0, 129)\t0.09960798053758721\n",
      "  (0, 126)\t0.14526582594807907\n",
      "  (0, 124)\t0.12559208428808646\n",
      "  (0, 116)\t0.132071216695438\n",
      "  (0, 114)\t0.16128962060495175\n",
      "  (0, 112)\t0.12078405326274354\n",
      "  (0, 107)\t0.15922456779897537\n",
      "  (0, 103)\t0.15724382677298582\n",
      "  (0, 99)\t0.16128962060495175\n",
      "  (0, 97)\t0.14839732645598427\n",
      "  (0, 96)\t0.11898675826688808\n",
      "  (0, 95)\t0.1634464831207681\n",
      "  (0, 94)\t0.15724382677298582\n",
      "  (0, 85)\t0.14377274146077546\n",
      "  (0, 84)\t0.14526582594807907\n",
      "  (0, 83)\t0.14526582594807907\n",
      "  (0, 82)\t0.132071216695438\n",
      "  (0, 81)\t0.1634464831207681\n",
      "  (0, 80)\t0.14232423338191155\n",
      "  (0, 75)\t0.1634464831207681\n",
      "  (0, 69)\t0.15724382677298582\n",
      "  (0, 64)\t0.12765713709406287\n",
      "  (0, 63)\t0.13566704052822343\n",
      "  (0, 62)\t0.16128962060495175\n",
      "  (0, 57)\t0.15724382677298582\n",
      "  (0, 48)\t0.15724382677298582\n",
      "  (0, 47)\t0.12170829867732715\n",
      "  (0, 45)\t0.11163334243719018\n",
      "  (0, 41)\t0.06778395792230937\n",
      "  (0, 38)\t0.15004227778768386\n",
      "  (0, 37)\t0.14680631778373038\n",
      "  (0, 28)\t0.13822138908226325\n",
      "  (0, 26)\t0.09095912374100436\n",
      "  (0, 25)\t0.15004227778768386\n",
      "  (0, 24)\t0.1634464831207681\n",
      "  (0, 23)\t0.14377274146077546\n",
      "  (0, 19)\t0.13955082613898276\n",
      "  (0, 17)\t0.15004227778768386\n",
      "  (0, 16)\t0.14839732645598427\n",
      "  (0, 15)\t0.10869174987102265\n",
      "  (0, 11)\t0.15004227778768386\n",
      "  (0, 7)\t0.13324046404847611\n",
      "  (0, 5)\t0.136927407940292\n",
      "  (0, 3)\t0.15534078218821604\n",
      "  (0, 2)\t0.16128962060495175\n",
      "environmentmonitor tool continuous gathering aggregation representation environment health provides access environment status information via ui dashboards rest api current environment components states environment components daily statistics particular component availability time quickstart test extension docker git clone httpsgithubcomyagelnasmanitenvironmentmonitorgit dockercompose build without docker quick start test extension documentation see wiki available documentation feature requests bugs found bug would like see new feature implemented raise issue issue tracker contributing eager fix bug introduce new feature clone repository issue pull request license environmentmonitor licensed apache license 20\n",
      "  (0, 125)\t0.24729507302647305\n",
      "  (0, 124)\t0.1950597453954538\n",
      "  (0, 123)\t0.23841898490343244\n",
      "  (0, 118)\t0.22104680310423241\n",
      "  (0, 99)\t0.2505023505937276\n",
      "  (0, 98)\t0.18344300440428873\n",
      "  (0, 94)\t0.24421874188336057\n",
      "  (0, 78)\t0.18344300440428873\n",
      "  (0, 64)\t0.19826702296270834\n",
      "  (0, 63)\t0.2107073748635943\n",
      "  (0, 56)\t0.1999233456393719\n",
      "  (0, 50)\t0.22561545327248372\n",
      "  (0, 49)\t0.2087994337624125\n",
      "  (0, 40)\t0.18344300440428873\n",
      "  (0, 37)\t0.22800802400613482\n",
      "  (0, 25)\t0.2330338625218263\n",
      "  (0, 14)\t0.21467458809543588\n",
      "  (0, 9)\t0.22329651190290434\n",
      "  (0, 7)\t0.20693860716613038\n",
      "  (0, 4)\t0.22104680310423241\n",
      "  (0, 0)\t0.24421874188336057\n",
      "rpienvironmentalmonitoring raspberry pi home environment monitoring system test config moduleexports port8080 session maxage 20 60 1000 session 20 min db host ' localhost ' user ' root ' password ' 111111 ' database ' rpienvironmentalmonitoring ' port ' 3307 ' set admintable password default localhostportadmin usernameadmin password111111 cd weblib node logmd5js run node server git clone cd web npm install node indexjs\n",
      "  (0, 139)\t0.24536209731188244\n",
      "  (0, 131)\t0.24536209731188244\n",
      "  (0, 123)\t0.2826876191735127\n",
      "  (0, 112)\t0.22242363715871355\n",
      "  (0, 110)\t0.2521515984775197\n",
      "  (0, 104)\t0.19260029908939916\n",
      "  (0, 74)\t0.28605979713416435\n",
      "  (0, 58)\t0.2069797670265037\n",
      "  (0, 50)\t0.2675067816440197\n",
      "  (0, 49)\t0.24756843436348425\n",
      "  (0, 40)\t0.21750392985729897\n",
      "  (0, 28)\t0.25453446264077106\n",
      "  (0, 27)\t0.2620898437293535\n",
      "  (0, 17)\t0.2763026099191917\n",
      "  (0, 14)\t0.25453446264077106\n",
      "  (0, 10)\t0.2647572689949541\n",
      "sahana eden sahana eden emergency development environment open source framework rapidly build powerful applications emergency management web based collaboration tool addresses common coordination problems disaster finding missing people managing aid managing volunteers tracking camps effectively government groups civil society ngos victims please see website details httpedensahanafoundationorg note developers get started httpedensahanafoundationorgwikidevelop first pull request sign contributor ' license agreement protects rights code allowing distributed used sahana eden httpbitlyssfecla\n",
      "  (0, 139)\t0.2595318979629549\n",
      "  (0, 130)\t0.2219820128167779\n",
      "  (0, 125)\t0.3101449291572915\n",
      "  (0, 116)\t0.25725438424451175\n",
      "  (0, 99)\t0.31416733389714435\n",
      "  (0, 82)\t0.25725438424451175\n",
      "  (0, 79)\t0.26671349668192795\n",
      "  (0, 63)\t0.26425849512575045\n",
      "  (0, 40)\t0.23006490549562356\n",
      "  (0, 34)\t0.2859560911879008\n",
      "  (0, 32)\t0.2955758022125028\n",
      "  (0, 15)\t0.21171478453180828\n",
      "  (0, 9)\t0.2800471518402749\n",
      "  (0, 8)\t0.26425849512575045\n",
      "envandfiles load configuration environmental variables files according twelvefactor app configuration come environmental variables since environmental variables leak easily people use secrets sensitive information module made support either minimal setup install npm install envandfiles yarn yarn add envandfiles usage const loadconfig require ' envandfiles ' loadconfig conceptual grouping configuration properties case configuration logger logger loggerlevel property equal loglevel environmental variable undefined present level ' loglevel ' server port specify property required port found error given required true coerce value number ' coerced error given type ' number ' variablename ' port ' sql password sqlpassword property equal contents pathtosecret undefined could read filepath ' pathtosecret ' required true thenconfig config object map configuration groups ' get something like logger level undefined server port 8000 sql password ' abc123 ' consolelogconfig catcherror required properties cannot loaded promise reject consoleerrorerror api loadconfigconfigmap load configuration returns promise resolve loaded configuration reject configuration invalid configmap type object object map conceptual groupings necessary configuration find default configuration properties optional one marked required found error given see usage examples config maps loadconfigsyncconfigmap load configuration synchronously returns loaded configuration throws configuration invalid configmap type object asynchronous version license mit matthew fernando garcia\n",
      "  (0, 136)\t0.1885576204359666\n",
      "  (0, 134)\t0.24475478707718043\n",
      "  (0, 129)\t0.14712725206080962\n",
      "  (0, 128)\t0.21022184413467096\n",
      "  (0, 120)\t0.22944810539256613\n",
      "  (0, 113)\t0.21919218457000067\n",
      "  (0, 110)\t0.20225039352607516\n",
      "  (0, 100)\t0.21919218457000067\n",
      "  (0, 97)\t0.21919218457000067\n",
      "  (0, 81)\t0.2414207354749832\n",
      "  (0, 80)\t0.21022184413467096\n",
      "  (0, 73)\t0.24475478707718043\n",
      "  (0, 64)\t0.1885576204359666\n",
      "  (0, 63)\t0.20038875158811145\n",
      "  (0, 58)\t0.16601813982463356\n",
      "  (0, 56)\t0.190132830765546\n",
      "  (0, 45)\t0.1648894679171758\n",
      "  (0, 41)\t0.10012116909800867\n",
      "  (0, 28)\t0.2041616850572281\n",
      "  (0, 18)\t0.21919218457000067\n",
      "  (0, 17)\t0.22162188114552162\n",
      "  (0, 5)\t0.20225039352607516\n",
      "  (0, 4)\t0.21022184413467096\n",
      "  (0, 1)\t0.19507749362908824\n",
      "esc50 classifiers environmental sound classification dataset directory structure &#9; &#9; &#9; &#9; root directory want store data audio &#9; &#9; &#9; contains 2000 recordings categorytargetpkl &#9; &#9; category target dictionary pickled &#9; &#9; &#9; contains pickled dataset using utilspickledataset &#9; model &#9; fold1 &#9; &#9; contains model trained fold 1 validation set also log file training process &#9; fold2 &#9; fold3 &#9; fold4 &#9; fold5 fold folder logcsv file storing training log weightsbesthdf5 storing trained model ' weights steps run get audio files esc50 github httpsgithubcomkaroldvlesc50git run pickledataset utilspy compute features clip store run train mainpy fold run evaluate mainpy evaluate models source code clippy contains class clip audio clip features phase encoded mel filterbank energies pefbes filterbank energies fbes extracted modelpy contains model class makes cnn model ' architechture mainpy contains functions trainpredict evaluate model utilspy contains functions saving loading dataset\n",
      "  (0, 137)\t0.2664177847724032\n",
      "  (0, 133)\t0.17355109674571845\n",
      "  (0, 116)\t0.2396771577366957\n",
      "  (0, 112)\t0.2191936995075173\n",
      "  (0, 104)\t0.18980344275880778\n",
      "  (0, 88)\t0.2753802170489064\n",
      "  (0, 72)\t0.2819057633225605\n",
      "  (0, 51)\t0.2819057633225605\n",
      "  (0, 46)\t0.26930507880997995\n",
      "  (0, 45)\t0.2025873834848771\n",
      "  (0, 44)\t0.19724910794597397\n",
      "  (0, 43)\t0.2819057633225605\n",
      "  (0, 41)\t0.12301140840117715\n",
      "  (0, 36)\t0.24848996452469166\n",
      "  (0, 26)\t0.1650687015228911\n",
      "  (0, 19)\t0.2532508309204855\n",
      "  (0, 15)\t0.19724910794597397\n",
      "  (0, 13)\t0.28895389023269613\n",
      "appconfiguration appconfiguration simple gem helps configure ruby applications appconfiguration uses yaml config files environmental variales set configuration parameters installation add line application ' gemfile gem ' appconfiguration ' execute bundle install gem install appconfiguration usage appconfiguration comes great default values want setup new config need config appconfigurationnew myconfigurablevariable configfoo myothervariable config ' bar ' default getting variable foo appconfiguration look environmental variable foo cannot find appconfiguration look configyml file current working directory config file try find configyml home directory possible configyml example could look like foo ' foo variable ' bar ' bar variable ' customize configuration appconfiguration customized fit needs example config appconfigurationnew ' setupyml ' baselocalpath ' usrlocal ' baseglobalpath ' config ' useenvvariables true prefix ' myapp ' end set configuration file name passing name new method use configfilename method inside configuration block configfilename sets name config file default configyml baselocalpath sets base path local configuration file config file path look global configuration path default baseglobalpath sets base path global configuration file default useenvvariables flag activates use enviromental variable default true prefix prefix appended looking environmental variables example prefix set myapp foo variable fetched myappfoo environmental variable checked used avoid name collitions default nil variable lookup retrieve variable appconfigurationconfig object foo configfoo foo config ' foo ' environmental variables checked first adding necesary prefix provided environmental variable local config file checked local file value defined given variable global config file checked otherwise returns nil configuration registry create new config object using appconfigurationnew must keep reference configuration instead registers configuration using appconfigurationfor obtain configuration using appconfiguration example appconfigurationfor github somewhere else github appconfigurationgithub githubapikey previous example name configuration file assumed githubyml environmental variables prefixed github change behaviour passing configuration block method example want change local path register configuration follows appconfigurationfor github baselocalpath railsroot end default values change default local path default global path appconfigurationconfig objects need appconfigurationconfigdefaultlocalpath railsroot appconfigurationconfigdefaultglobalpath ' usrconfigs ' contributing fork create feature branch git checkout b mynewfeature commit changes git commit ' add feature ' push branch git push origin mynewfeature create new pull request please add specs new features find bug spec probing bug exists separate commit add bug fix license copyright c 2013 guido marucci blas mit license permission hereby granted free charge person obtaining copy software associated documentation files software deal software without restriction including without limitation rights use copy modify merge publish distribute sublicense andor sell copies software permit persons software furnished subject following conditions copyright notice permission notice shall included copies substantial portions software software provided without warranty kind express implied including limited warranties merchantability fitness particular purpose noninfringement event shall authors copyright holders liable claim damages liability whether action contract tort otherwise arising connection software use dealings software\n",
      "  (0, 141)\t0.1624121511686881\n",
      "  (0, 137)\t0.14974529500065703\n",
      "  (0, 135)\t0.1624121511686881\n",
      "  (0, 134)\t0.16902099204375495\n",
      "  (0, 133)\t0.09754776769905484\n",
      "  (0, 132)\t0.1624121511686881\n",
      "  (0, 130)\t0.11624428721207287\n",
      "  (0, 129)\t0.10160207445563849\n",
      "  (0, 128)\t0.14517348187230822\n",
      "  (0, 115)\t0.13590786075267028\n",
      "  (0, 114)\t0.16451854513245753\n",
      "  (0, 113)\t0.15136815474247167\n",
      "  (0, 112)\t0.12320207985769024\n",
      "  (0, 99)\t0.16451854513245753\n",
      "  (0, 93)\t0.15845061442570388\n",
      "  (0, 81)\t0.16671858678313486\n",
      "  (0, 78)\t0.12047701799120868\n",
      "  (0, 77)\t0.16902099204375495\n",
      "  (0, 76)\t0.13130055620095438\n",
      "  (0, 69)\t0.16039175685777254\n",
      "  (0, 67)\t0.16039175685777254\n",
      "  (0, 65)\t0.15845061442570388\n",
      "  (0, 64)\t0.13021275883542577\n",
      "  (0, 63)\t0.1383830158841866\n",
      "  (0, 59)\t0.13590786075267028\n",
      "  (0, 58)\t0.11464760720520589\n",
      "  (0, 55)\t0.16671858678313486\n",
      "  (0, 51)\t0.15845061442570388\n",
      "  (0, 49)\t0.13712996698695717\n",
      "  (0, 48)\t0.16039175685777254\n",
      "  (0, 47)\t0.12414482812867211\n",
      "  (0, 45)\t0.1138681771161418\n",
      "  (0, 44)\t0.11086769557527643\n",
      "  (0, 43)\t0.15845061442570388\n",
      "  (0, 42)\t0.13130055620095438\n",
      "  (0, 41)\t0.0691409533909939\n",
      "  (0, 39)\t0.16902099204375495\n",
      "  (0, 37)\t0.14974529500065703\n",
      "  (0, 36)\t0.13966861511982348\n",
      "  (0, 28)\t0.1409885010127128\n",
      "  (0, 25)\t0.15304603704444422\n",
      "  (0, 22)\t0.1170623684454399\n",
      "  (0, 21)\t0.15845061442570388\n",
      "  (0, 18)\t0.15136815474247167\n",
      "  (0, 17)\t0.15304603704444422\n",
      "  (0, 11)\t0.15304603704444422\n",
      "  (0, 6)\t0.14665098824161757\n",
      "  (0, 1)\t0.13471520574672316\n",
      "allay alleviate environmental pain installation requirements python 2 27 greater httpswwwpythonorgdownloads pip httpspippypaioenstableinstalling using brew macos users brew install python httpsbrewsh docker toolbox docker windowsmac httpsdocsdockercomengineinstallation prerequisite install magnet pip install githttpsgithubcombriandleemagnetgiteggmagnet pip install githttpsgithubcombriandleeallaygiteggallay configuring database synchronization ensure volume configured store database files database schema files volumesyml settingsyml add section dbsync settings specified required dbsync user allay host mydbhostcom schemas schema1schema2 schemasvolume volumenameoptionalpath databasevolume volumenameoptionalpath optional properties include integer schemafilemaxage determines schema deemed old days string remotepath determines look database schema files default homedatabaseschemas configure server create user account use database synchronization configure user write database sql dumps desired location default homedatabaseschemas schema files named according schema represent schema file schema1 stored homedatabaseschemasschema1sqlgz setup key access user access new user account currently supports use default key sshidrsapub set next time allay runs try connect host using configured user account run comparison files currently found schemasvolume director corresponding files server download ssh next ensure database container equipped ingest schema files initialization warning allay downloads new schemas deletes contents database data directory force ingestion newly downloaded files\n",
      "  (0, 133)\t0.13214640905786532\n",
      "  (0, 131)\t0.18411221686394144\n",
      "  (0, 129)\t0.1376387139228465\n",
      "  (0, 124)\t0.17354365450445947\n",
      "  (0, 113)\t0.20505603118098548\n",
      "  (0, 112)\t0.16689989761612833\n",
      "  (0, 110)\t0.18920685097695555\n",
      "  (0, 104)\t0.14452137645748017\n",
      "  (0, 101)\t0.21212014739125956\n",
      "  (0, 100)\t0.20505603118098548\n",
      "  (0, 96)\t0.16441638805761297\n",
      "  (0, 87)\t0.2228706558385883\n",
      "  (0, 86)\t0.2172801614141115\n",
      "  (0, 78)\t0.16320829965740283\n",
      "  (0, 69)\t0.2172801614141115\n",
      "  (0, 68)\t0.2172801614141115\n",
      "  (0, 59)\t0.18411221686394144\n",
      "  (0, 58)\t0.15531128960310794\n",
      "  (0, 54)\t0.22897004904189783\n",
      "  (0, 45)\t0.15425540806105942\n",
      "  (0, 44)\t0.15019070345097524\n",
      "  (0, 41)\t0.09366414962610782\n",
      "  (0, 38)\t0.20732903164278452\n",
      "  (0, 36)\t0.18920685097695555\n",
      "  (0, 28)\t0.19099487939857515\n",
      "  (0, 27)\t0.1966642063920702\n",
      "  (0, 26)\t0.12568768831265126\n",
      "  (0, 22)\t0.15858252823989055\n",
      "  (0, 1)\t0.18249654610080285\n",
      "  (0, 0)\t0.2172801614141115\n",
      "poc currently production ready mileage may vary rebaked environmental device management system environmental inventorydevice management system built hundreds entities thousands environments millions devices rebaked environmental device management system quick getting started development guide build cruton container start cruton cassandra create keyspace tables created sync tables working api discovery entities head entities put entity head entities post one many entities bulk import get entities get entities search get entities search partial match using provided criteria environments head environments put environment head environment post one many environments bulk import get environments get environments search get environments search partial match using provided criteria devices head devices put device head device post one many devices bulk import get devices get devices search get devices search partial matching using provided criteria get ipxe return specific device utilities synchronizing table space backend store quick getting started development guide following guide result running cruton application requirements docker dockercompose build cruton container dockercompose build start cruton cassandra dockercompose create keyspace tables created setup creates basic cassandra container authentication needed ' need create user password howerver need createa keyspace docker exec ti cassandracruton cqlsh localhost e create keyspace exists cruton replication ' class ' ' networktopologystrategy ' ' datacenter1 ' 1 sync tables docker exec ti crutoncruton1 crutonmanage configfile etccrutoncrutonini synctables working api start api ' recommended run service behind webserver like nginx apache using uwsgi etc typical api process envoked running crutonapiwsgi configfile etccrutoncrutonini command need want run api debug mode invoking crutonapidebug configfile etccrutoncrutonini command discovery curl ' http1270015150dicovery ' api endpoints available actions discoverable dicovery endpoint allows user application discover available actions available versions entities head entities curl head ' http1270015150v1entities ' put entity curl h ' contenttype applicationjson ' xput ' http1270015150v1entitiessolo1 ' ' name testentitysolo ' head entities curl head ' http1270015150v1entitiessolo1 ' post one many entities bulk import curl h ' contenttype applicationjson ' xpost ' http1270015150v1entities ' ' entid ent1 tags testentitytagone contacts person1 4155551212 person2 emailperson2examplecom name testentityone entid ent2 tags testentitytagone testentitytagtwo contacts person2 emailperson2examplecom name testentitytwo ' get entities curl ' http1270015150v1entities ' get entities search curl ' http1270015150v1entitiescontactperson1 ' get entities search partial match using provided criteria curl ' http1270015150v1entitiesnameentitytagfuzzytrue ' aware field data module part search criteria environments head environments head environments root curl head ' http1270015150v1entitiesent1environments ' put environment curl h ' contenttype applicationjson ' xput ' http1270015150v1entitiessolo1environmentssoloenv1 ' ' name soloenvironmentone ' head environment head environments root curl head ' http1270015150v1entitiesent1environmentssoloenv1 ' post one many environments bulk import curl h ' contenttype applicationjson ' xpost ' http1270015150v1entitiesent1environments ' ' envid env1 tags testenvironmenttagone contacts person1 4155551212 person2 emailperson2examplecom name testenvironmentone envid env2 tags testenvironmenttagone testenvironmenttagtwo contacts person1 4155551212 name testenvironmenttwo ' get environments curl ' http1270015150v1entitiesxenvironmentsenv2 ' get environments search curl ' http1270015150v1entitiesxenvironmentscontactperson1 ' get environments search partial match using provided criteria curl ' http1270015150v1entitiesxenvironmentstagenvironmenttagfuzzytrue ' aware field data module part search criteria devices head devices curl head http1270015150v1entitiessolo1environmentssoloenv1devices put device curl h ' contenttype applicationjson ' xput ' http1270015150v1entitiessolo1environmentssoloenv1devicessolodev1 ' ' name solodeviceone ' head device curl head http1270015150v1entitiessolo1environmentssoloenv1devicessolodev1 post one many devices bulk import curl h ' contenttype applicationjson ' xpost ' http1270015150v1entitiessolo1environmentssoloenv1devices ' ' devid dev1 tags testenvironmenttagone accessip drac 17216241 mgmt fe806656fc1dcd1ddba rackid testrack1 rowid testrow1 name testdeviceone devid dev2 tags testdevicetagone testdevicetagtwo accessip drac 17216242 mgmt fe806656fc1dcd1ddbb rackid testrack2 rowid testrow1 name testdevicetwo ' get devices curl ' http1270015150v1entitiessolo1environmentssoloenv1devices ' get devices search curl ' http1270015150v1entitiessolo1environmentssoloenv1devicesrowidtestrow1 ' get devices search partial matching using provided criteria curl ' http1270015150v1entitiessolo1environmentssoloenv1devicesnametestfuzzytrue ' aware field data module part search criteria get ipxe return specific device curl ' http1270015150v1entitiestestentity1environmentstestenvironment1adevicestestdevice1aipxe device variable ipxe prefix ipxe endpoint return ipxe config using variables utilities automated data population simply done using ansible playbook helpful playbooks found synchronizing table space backend store crutonmanage configfile etccrutoncrutonini synctables additional documentation data model installation cassandra\n",
      "  (0, 141)\t0.1927429320168927\n",
      "  (0, 137)\t0.17771051615579878\n",
      "  (0, 133)\t0.11576500048010811\n",
      "  (0, 131)\t0.16128891451234909\n",
      "  (0, 118)\t0.17228490815387018\n",
      "  (0, 117)\t0.17584573537946543\n",
      "  (0, 113)\t0.17963644806815088\n",
      "  (0, 111)\t0.1927429320168927\n",
      "  (0, 107)\t0.1927429320168927\n",
      "  (0, 105)\t0.1571411450350873\n",
      "  (0, 104)\t0.1266059163791578\n",
      "  (0, 101)\t0.18582486758181185\n",
      "  (0, 93)\t0.18804157068622254\n",
      "  (0, 88)\t0.18368878996822244\n",
      "  (0, 76)\t0.1558211869956428\n",
      "  (0, 73)\t0.2005859866056497\n",
      "  (0, 72)\t0.18804157068622254\n",
      "  (0, 64)\t0.15453024138496324\n",
      "  (0, 59)\t0.16128891451234909\n",
      "  (0, 47)\t0.14732911297628717\n",
      "  (0, 41)\t0.08205315909634182\n",
      "  (0, 40)\t0.14297633225828704\n",
      "  (0, 37)\t0.17771051615579878\n",
      "  (0, 34)\t0.17771051615579878\n",
      "  (0, 26)\t0.11010692913710866\n",
      "  (0, 23)\t0.17403834167251458\n",
      "  (0, 22)\t0.13892399035821554\n",
      "  (0, 17)\t0.18162767810934125\n",
      "  (0, 16)\t0.17963644806815088\n",
      "  (0, 13)\t0.1927429320168927\n",
      "  (0, 9)\t0.17403834167251458\n",
      "  (0, 7)\t0.16128891451234909\n",
      "  (0, 6)\t0.17403834167251458\n",
      "  (0, 4)\t0.17228490815387018\n",
      "  (0, 2)\t0.19524269909489864\n",
      "environmental website page sample site one plurality layouts webdev resources implemented menu slogan twocolumn content uncomplicated footer project\n",
      "  (0, 90)\t0.556976924981095\n",
      "  (0, 85)\t0.7512230014294572\n",
      "  (0, 41)\t0.3541760962599275\n",
      "rpienvironmentalmonitoring raspberry pi home environment monitoring system test config moduleexports port8080 session maxage 20 60 1000 session 20 min db host ' localhost ' user ' root ' password ' 111111 ' database ' rpienvironmentalmonitoring ' port ' 3307 ' set admintable password default localhostportadmin usernameadmin password111111 cd weblib node logmd5js run node server git clone cd web npm install node indexjs\n",
      "  (0, 139)\t0.24536209731188244\n",
      "  (0, 131)\t0.24536209731188244\n",
      "  (0, 123)\t0.2826876191735127\n",
      "  (0, 112)\t0.22242363715871355\n",
      "  (0, 110)\t0.2521515984775197\n",
      "  (0, 104)\t0.19260029908939916\n",
      "  (0, 74)\t0.28605979713416435\n",
      "  (0, 58)\t0.2069797670265037\n",
      "  (0, 50)\t0.2675067816440197\n",
      "  (0, 49)\t0.24756843436348425\n",
      "  (0, 40)\t0.21750392985729897\n",
      "  (0, 28)\t0.25453446264077106\n",
      "  (0, 27)\t0.2620898437293535\n",
      "  (0, 17)\t0.2763026099191917\n",
      "  (0, 14)\t0.25453446264077106\n",
      "  (0, 10)\t0.2647572689949541\n",
      "moodcube 3d lattice rgb leds driven ann environmental sensors inputs existing things programmable cube 390 mic acc httpcubetubeorg httpwwwinstructablescomid8x8x8rgbledcube neopixel httpslearnadafruitcomadafruitneopixeluberguideoverview single wire rgb audio spectrum analyzer pi signal flow something acquires sample many sensors samples passed neural network nonlinear processing vector input time series outputs nn passed output processor takes outputs writes leds led drive neopixel dotstar style arduino raspberry pi compatible leds single strip addressable rgb leds 3rd party products also like hkbayi fadecandy board takes usb input drive 8 strips 64 leds ' total 8x64 512 leds could cube 4 sides 1 top 10x10 leds per side 500 total led strips mounted clear plastic rods make shape something like cube use 3d printer make wild shapes mount trees spheres japanese lantern klein bottle maybe hang frame like hanging gardens living trees avatar needs 60 per led full power use 5v 10a acdc adapter power bus spread power strip github markdown httpsguidesgithubcomfeaturesmasteringmarkdown learning stochastic gradient method least mean squares synapse sensors sources audio datachunk int16 fs1chunk 16k 16k audioblrmschunkbands databands int16 fs1chunk 16k 16k proximityfs databands int16 fsfs 0 400 datefs datadtweekday dthour dtminute dtsecond fsfs synapse autostart systemd fcserver synapse processes autostart using pi user system user session homepiconfigsystemduserfcserverservice homepiconfigsystemdusermoodcubeservice services called fcserver moodcube launch following scripts fcserver homepigitmoodcubefadecandyfcserverlaunchsh moodcube homepigitmoodcubelaunch control processes using systemctl user command show service status systemctl user status moodcube reload configuration needed change config file configsystemduser systemctl user daemonreload restart service systemctl user restart moodcube stop service systemctl user stop moodcube follow logs journalctl f journalctl f cat terse\n",
      "  (0, 133)\t0.15589769465138506\n",
      "  (0, 131)\t0.21720355756073387\n",
      "  (0, 129)\t0.16237715688480991\n",
      "  (0, 124)\t0.2047354585834762\n",
      "  (0, 111)\t0.2595618592594001\n",
      "  (0, 109)\t0.2595618592594001\n",
      "  (0, 84)\t0.23680684702840474\n",
      "  (0, 77)\t0.27012389549091453\n",
      "  (0, 70)\t0.18577786883513925\n",
      "  (0, 64)\t0.20810182944695246\n",
      "  (0, 57)\t0.2563329302660659\n",
      "  (0, 51)\t0.2532306590681939\n",
      "  (0, 47)\t0.19840425839227002\n",
      "  (0, 44)\t0.17718517357383495\n",
      "  (0, 41)\t0.11049884065936706\n",
      "  (0, 20)\t0.2629282301228764\n",
      "  (0, 18)\t0.24191170054026873\n",
      "  (0, 17)\t0.24459323789313644\n",
      "  (0, 16)\t0.24191170054026873\n",
      "  (0, 11)\t0.24459323789313644\n",
      "environmental data logger design files software small lowpower temperature humidity logger probably remarkable feature power consumption 32a less better documentation found hackadayio credits hd44780 library sa development i2c library peter fleury\n",
      "  (0, 122)\t0.4815113636152513\n",
      "  (0, 115)\t0.39777387591387836\n",
      "  (0, 45)\t0.33326833270639783\n",
      "  (0, 41)\t0.20236110599052373\n",
      "  (0, 37)\t0.43827315110695786\n",
      "  (0, 34)\t0.43827315110695786\n",
      "  (0, 26)\t0.2715478624198261\n",
      "electric imp environmental data streaming hub electric imp environmental data streaming electric imp nora motion environmental data streaming tutorials find code materials tutorials well tutorials wiki lot internetconnected devices price going usually cheaper harder program make secure electric imp platform paired hardware makes connecting internet quickly securely seamlessly piece cake hard network work without change thing way focus data want collect send ' super cool looking read\n",
      "  (0, 140)\t0.31117182697637247\n",
      "  (0, 138)\t0.39179087708874244\n",
      "  (0, 137)\t0.35190341761075195\n",
      "  (0, 97)\t0.35571715940106974\n",
      "  (0, 89)\t0.39179087708874244\n",
      "  (0, 70)\t0.2731756076040639\n",
      "  (0, 41)\t0.16248215207729702\n",
      "  (0, 26)\t0.21803439382283898\n",
      "  (0, 15)\t0.26054054636839863\n",
      "  (0, 11)\t0.35966020493321915\n",
      "national co2 emissions fossilfuel burning cement manufacture gas flaring 17512014 contributors ta boden rj andres carbon dioxide information analysis center environmental sciences division oak ridge national laboratory oak ridge tennessee 378316290 usa g marland research institute environment energy economics appalachian state university boone north carolina 286082131 usa doi 103334cdiac00001v2017 notes emission estimates expressed thousand metric tons carbon convert estimates units carbon dioxide co2 simply multiply estimates 3667 per capita emission estimates expressed metric tons carbon population estimates available permit calculations global per capita estimates 1950 please note annual sums tallied element eg gas rounded reported totals may differ slightly sum elements due rounding methods publications containing historical energy statistics make possible estimate fossil fuel co2 emissions back 1751 etemad et al 1991 published summary compilation tabulates coal brown coal peat crude oil production nation year footnotes etemad et al1991 publication extend energy statistics time series back 1751 summary compilations fossil fuel trade published mitchell 1983 1992 1993 1995 mitchell ' work tabulates solid liquid fuel imports exports nation year pre1950 production trade data digitized co2 emission calculations made following procedures discussed marland rotty 1984 boden et al 1995 details contents processing historical energy statistics provided andres et al 1999 1950 present co2 emission estimates derived primarily energy statistics published united nations 2016 using methods marland rotty 1984 energy statistics compiled primarily annual questionnaires distributed un statistical office supplemented official national statistical publications stated introduction statistical yearbook cases official sources supplemented sources estimates subjected professional scrutiny debate consistent independent sources data us department interior ' geological survey usgs 2016 used estimate co2 emitted cement production values emissions gas flaring derived primarily un data supplemented data us department energy ' energy information administration 1994 rotty 1974 data provided g marland greater details methods provided marland rotty 1984 boden et al 1995 andres et al 1999 references andres rj dj fielding g marland ta boden n kumar 1999 carbon dioxide emissions fossilfuel use 17511950 tellus 51b75965 boden ta g marland r j andres 1995 estimates global regional national annual co2 emissions fossilfuel burning hydraulic cement production gas flaring 19501992 ornlcdiac90 ndp30r6 oak ridge national laboratory us department energy oak ridge tennessee marland g rm rotty 1984 carbon dioxide emissions fossil fuels procedure estimation results 195082 tellus 36b23261 etemad b j luciani p bairoch jc toutain 1991 world energy production 18001985 librarie droz switzerland mitchell br 1983 international historical statistics americas australasia 17501988 pgs 522525 gale research company detroit united states mitchell br 1992 international historical statistics europe 17501988 pgs 465485 stockton press new york united states mitchell br 1993 international historical statistics americas 17501988 pgs 405414 stockton press new york united states mitchell br 1995 international historical statistics africa asia oceania 17501988 pgs 490497 stockton press new york united states rotty rm 1974 first estimates global flaring natural gas atmospheric environment 868186 united nations 2017 2014 energy statistics yearbook united nations department economic social information policy analysis statistics division new york us department energy 1994 international energy annual 1994 doeeia021991 energy information administration office energy markets end use washington dc us geological survey 2017 2014 minerals yearbook cement hg van oss ed us department interior us geological survey reston virginia licence cdiac page states wish use diagram image graph table materials cdiac website concerned obtaining permission possible copyright restrictions concerns reports graphics data information cdiac website freely publicly available without copyright restrictions however professional courtesy ask original data source acknowledged suggested citations appear bottom page data set citation boden ta g marland rj andres 2017 global regional national fossilfuel co2 emissions carbon dioxide information analysis center oak ridge national laboratory us department energy oak ridge tenn usa httpsdoiorg103334cdiac00001v2017\n",
      "  (0, 140)\t0.19601680156095316\n",
      "  (0, 135)\t0.24042622986484943\n",
      "  (0, 133)\t0.14440447867263687\n",
      "  (0, 130)\t0.1720818024797742\n",
      "  (0, 129)\t0.15040625674888786\n",
      "  (0, 124)\t0.18964178545848337\n",
      "  (0, 116)\t0.19942515870940902\n",
      "  (0, 112)\t0.18238174519914427\n",
      "  (0, 103)\t0.2374353465872227\n",
      "  (0, 102)\t0.24354442241186625\n",
      "  (0, 93)\t0.23456178353658486\n",
      "  (0, 85)\t0.21709425036963684\n",
      "  (0, 79)\t0.20675792003288146\n",
      "  (0, 78)\t0.17834770990072538\n",
      "  (0, 70)\t0.1720818024797742\n",
      "  (0, 56)\t0.19437029482951243\n",
      "  (0, 53)\t0.2374353465872227\n",
      "  (0, 47)\t0.1837773391302188\n",
      "  (0, 41)\t0.10235255572590922\n",
      "  (0, 40)\t0.17834770990072538\n",
      "  (0, 39)\t0.2502096031157751\n",
      "  (0, 32)\t0.22913215430709147\n",
      "  (0, 26)\t0.13734663874528494\n",
      "  (0, 7)\t0.20119070115525398\n",
      "  (0, 3)\t0.23456178353658486\n",
      "coding open data environmental reporting bc repo ' develop collection lessons based data code environmental reporting bc released content guidelines skill focus lesson focus helping learners gain skill ' need work data code released bc enable learners transfer skills projects lesson format anything goes ' looking guidance consider study group lesson one hour handson tutorial designed led instructor workshop lesson like study group longer selfstudy curriculum tutorial designed followed independent learner content format keep simple dependencyfree possible markdown plain text text ipython notebooks knitr scripts good options contributing please place lesson folder make sure everything needed scripts pointers data code etc included clearly labeled lesson folder feel free start brainstorming lesson ideas issue tracker begin\n",
      "  (0, 140)\t0.23234942146033344\n",
      "  (0, 121)\t0.2716028578532718\n",
      "  (0, 118)\t0.25474104014553445\n",
      "  (0, 114)\t0.28868650644568256\n",
      "  (0, 91)\t0.2925469972958641\n",
      "  (0, 82)\t0.23638953335516838\n",
      "  (0, 76)\t0.23039772709824663\n",
      "  (0, 71)\t0.27803889394900727\n",
      "  (0, 70)\t0.20397795970359106\n",
      "  (0, 64)\t0.22848893061015196\n",
      "  (0, 48)\t0.28144508518888356\n",
      "  (0, 46)\t0.26561105159635\n",
      "  (0, 41)\t0.12132407486766618\n",
      "  (0, 31)\t0.26561105159635\n",
      "  (0, 26)\t0.16280447287098973\n",
      "  (0, 15)\t0.19454346431000386\n",
      "  (0, 8)\t0.24282556945090386\n",
      "epa sms dispatcher simple system environmental protection agency dispatch substitute military service personnel although system designed epa easily modified fit departments well demo demo page httpchunnorrisccdemoepasms demo files sample input txt sample output personnel csv sample output personnel jpg sample output region csv sample output region jpg regionjson whatt regionjson totalstudents regionjson available ansi big5 csv bom utf8 csv csv 1 2 3 4 csv xxxtinputfilecsv 5 6 50 7 49 7 csv na 7 firefox github download zip firefox indexhtml csv txt csv txt eg 144tinputfilecsv txt jsglobaljs printroundn printroundn 3 printroundn 6 jsglobaljs fontcolors fontcolors type1 black type2 229922 type3 0000dd type4 4488ff typedefault black typehome orange typekicked red leftover red shortage blue overheat red todo lists 123456789123 firefox notepad chrome modification httpsstackoverflowcomquestions2541949problemswithjquerygetjsonusinglocalfilesinchrome mac open applicationsgoogle chromeapp args allowfileaccessfromfiles httpeurekaykyueninfo20130924chromebypassaccesscontrolalloworiginonlocalfilesystem license project licensed terms mit license please note project built materials following parties bootstrap flatly jquery please also refer licenses information\n",
      "  (0, 114)\t0.28571094415757464\n",
      "  (0, 111)\t0.28205287747778574\n",
      "  (0, 90)\t0.1888275403683427\n",
      "  (0, 85)\t0.25468127181904915\n",
      "  (0, 84)\t0.25732614491735845\n",
      "  (0, 82)\t0.23395300873399627\n",
      "  (0, 79)\t0.24255534148407026\n",
      "  (0, 63)\t0.2403227070347057\n",
      "  (0, 57)\t0.27854416199724513\n",
      "  (0, 56)\t0.22802296148671874\n",
      "  (0, 51)\t0.2751730792019035\n",
      "  (0, 47)\t0.21559597447427842\n",
      "  (0, 45)\t0.19774904018973335\n",
      "  (0, 41)\t0.1200735580137247\n",
      "  (0, 38)\t0.26578722604395616\n",
      "  (0, 31)\t0.2628733336539165\n",
      "  (0, 7)\t0.23602423169265457\n",
      "corporate environmental performance prediction china empirical study energy service companies authors saina zheng chenhang shuchien hsu joseph sarkis jiehhaur chen code originally used paper corporate environmental performance prediction china empirical study energy service companies contains three fundalmental machine learning regression model random forest svm xgboost code well commented easy used anyone beginner level python programming skills evaluation metrics visualization code also included dependencies python tested 35 scikitlearn xgboost pandas citation find work useful research please consider cite articlezheng2020ceppc titlecorporate environmental performance prediction china empirical study energy service companies authorsaina zheng chenhang shuchien hsu joseph sarkis jiehhaur chen journaljournal cleaner production jclp year2020\n",
      "  (0, 140)\t0.30733998811679597\n",
      "  (0, 130)\t0.26981166261303763\n",
      "  (0, 111)\t0.3769707190465065\n",
      "  (0, 102)\t0.3818598165764854\n",
      "  (0, 96)\t0.28170604851326403\n",
      "  (0, 72)\t0.36777569672960597\n",
      "  (0, 41)\t0.16048131083672842\n",
      "  (0, 29)\t0.3592624357765535\n",
      "  (0, 19)\t0.3303923257594477\n",
      "  (0, 15)\t0.2573321923224345\n",
      "sensorpuck repository collateral related silicon labs sensor puck note sensor puck longer actively supported code provided android directory sensor puck android app source code ios directory iphone app source code\n",
      "  (0, 116)\t0.3449241273944626\n",
      "  (0, 108)\t0.3963051046009174\n",
      "  (0, 98)\t0.3084687439058113\n",
      "  (0, 93)\t0.4056961470159189\n",
      "  (0, 79)\t0.3576068115515607\n",
      "  (0, 36)\t0.3576068115515607\n",
      "  (0, 15)\t0.28386508368204255\n",
      "  (0, 5)\t0.3576068115515607\n",
      "environmentalinformaticsmarburggithubio\n",
      "\n",
      "pythonbased datacentric integrated modeling platform pydims goals project data model technology building coupled models within water resource domain advancing rapid pace many modeling framworks developed eg openmi csdms oms etc control flow data model components simulation efforts largely focused establishing software interfaces componentizing scientific calculations receive input data supply output data simulation however lack emphasis closing gap observed simulated data component simulations one objective project investigate observed simulation data integrated seamlessly componentbased model simulations coupled modeling workflow coupled modeling platforms typically rely upon single data passing workflow defined coordination mechanism utilize feedforward approach eg oms csdms others use pull driven approach eg openmi offers benefits however rarely ever encounter set models single workflow ideal instance closedsource models coupled computations via reading writing inputoutput files unable interact others individual timesteps unless specifically designed similarly sometimes model coupled along shared boundary conditions require timestep iterations converge solution therefore second objective work investigate methods utilizing multiple workflows within single coupling framework well within single simulation platform language compatibility within water resources community several coupled modeling frameworks exist however often writen different languages eg c python java etc scientists forced choose coupling software compatible models andor operating system moreover many legacy models written c c fortran make compatibility difficult third goal project investigate platform language compatibility issues overcome build system adopted water resources community\n",
      "  (0, 140)\t0.22529347132053346\n",
      "  (0, 129)\t0.17287062854531554\n",
      "  (0, 115)\t0.23124013400751472\n",
      "  (0, 112)\t0.20962191074541706\n",
      "  (0, 96)\t0.2065026876275702\n",
      "  (0, 90)\t0.1850000969220139\n",
      "  (0, 84)\t0.25211026769409023\n",
      "  (0, 75)\t0.28366297678273267\n",
      "  (0, 72)\t0.26959545320231165\n",
      "  (0, 70)\t0.19778358958534062\n",
      "  (0, 57)\t0.2728982057703629\n",
      "  (0, 45)\t0.19374076223189104\n",
      "  (0, 35)\t0.25478380640515236\n",
      "  (0, 33)\t0.28366297678273267\n",
      "  (0, 31)\t0.2575450175823009\n",
      "  (0, 26)\t0.1578604526281408\n",
      "  (0, 20)\t0.2799197207024199\n",
      "  (0, 9)\t0.24951900490170745\n",
      "edit ontology tbd environmental conditions treatments exposures ontology ecto purpose ontology create compositional classes assemble existing obo ontologies exo chebi envo make readymade precomposed classes use describing experimental treatments plants model organisms eg modification diet lighting levels temperature exposures humans organisms stressors variety routes purposes public health environmental monitoring etc stimuli natural experimental kind environmental condition change condition experienced organism population organisms earth scope general include example plant treatment regimens well human clinical exposures although may better handled specialized ontology example class manchester syntax class ecto0000977 annotations rdfslabel exposure ultrafine respirable suspended particulate matter via inhalation annotations iao0000115 exposure event involving interaction exposure receptor ultrafine respirable suspended particulate matter via inhalation annotations oiohasexactsynonym ultrafine respirable suspended particulate matter exposure via inhalation equivalentto exo0000002 ro0002233 envo01000416 bfo0000050 exo0000057 ' exposure event ' ' input ' ultrafine respirable suspended particulate matter ' part ' inhalation quick start public browser yet use one following files subsetsectobasicobo oboedit users ectoowl open protege5 note open owl protege need check repo catalog used relationships ontologies ontologies used composition largely orthogonal exposure ontology exo used upper ontology based classes ' exposure ' different routes ' ingestion ' chemical entities biological interest chebi use entities roles environment ontology envo environmental materials processes nanoparticle ontology npo radiation relations ontology ro relations phenotypic quality ontology pato qualities uberon anatomy ontology tissue types used yet nci thesaurus ncit activities smoking sustainable development goals interface ontology sdgio social entities population community ontology pco population attributes eg overcrowding similar ontologies overlappingnonorthogonal zebrafish experimental conditions ontology zeco zebrafishspecific conditions pombe experimental conditions ontology speco pombasespecific conditions plant environment conditions ontology peco plantspecific environmental conditions treatments gene ontology go subset shadows many classes eg gene expression response x snomed exposure subset closed nci thesaurus ncit broad contains exposure terms experimental conditions ontology xco experimental conditions mammalcentric rat particular wikidata subclasses hazard wikidataq1132455httpswwwwikidataorgwikiq1132455 see merge experiment ontologies aim reuse existing open ontologies far possible orthogonal ontologies via axiomatization note envo may seem envo overlappingnonorthogonal ontology following design patterns considered orthogonal analogous relationship anatomical ontology variantaberrant phenotype ontology another new ontology note unep sustainable development goals ontology httpsgithubcomsdginterfaceontologysdgio built modular fashion using envo seeding creation many useful social classes need eg poverty access resources etc releases release files top level obo owl note testing far stable considered real releases proposed id space tentative modeling model using aligned environmental conditions model phenopackets attempt follow exo possible treat exposures events ontological terms types occurrents specifically interactions receptor typically organism could population organisms stressor agent process potential effect receptor stressor may interact organism kind environmental medium eg air water soil may enter via route eg permeating skin analogous barrier cases route may indirect passive smoking drug use mother pregnancy model permits variety precomposed classes defined generate using dead simple owl design patterns dosdps see srcpatterns list patterns use basic idea term like ' increased exposure arsenic ingestiondiet ' composed using classes ontologies exo chebi see filling slots datamodel annotation guide broadly speaking ontology designed support pre post composed use cases precomposed approach curator uses readymade ecto class expressing combination values required different slots postcomposed approach ecto largely disposed instead description assembled curator filling required slots like ' stressor ' two approaches compatible postcomposed descriptions automatically classified precomposed ecto similarly description uses ecto unwound ' unfolded ' precomposed description using owl equivalence axioms ontology ontology source ontology stored csvs srcontologymodules see makefile ontology compiled csv modules see omn files humanreadable set descriptions see readmeeditorsmd file srcontology directory instructions edit maintain release ontology merge experiment see srcmappings exploration merging multiple exposure ontologies using kboom intent use ontology rather help gap fill understand\n",
      "  (0, 135)\t0.16499357715915916\n",
      "  (0, 133)\t0.09909822030397868\n",
      "  (0, 132)\t0.16499357715915916\n",
      "  (0, 130)\t0.11809190773857745\n",
      "  (0, 129)\t0.10321696739190131\n",
      "  (0, 122)\t0.16713345076152167\n",
      "  (0, 120)\t0.160969074598427\n",
      "  (0, 118)\t0.147480911436757\n",
      "  (0, 116)\t0.13685640842721136\n",
      "  (0, 114)\t0.16713345076152167\n",
      "  (0, 112)\t0.12516028956513023\n",
      "  (0, 100)\t0.15377404424008703\n",
      "  (0, 95)\t0.16936846051437798\n",
      "  (0, 88)\t0.1572429672193543\n",
      "  (0, 82)\t0.13685640842721136\n",
      "  (0, 79)\t0.1418885487302646\n",
      "  (0, 78)\t0.1223919147723857\n",
      "  (0, 76)\t0.13338748544794413\n",
      "  (0, 75)\t0.16936846051437798\n",
      "  (0, 74)\t0.160969074598427\n",
      "  (0, 72)\t0.160969074598427\n",
      "  (0, 70)\t0.11809190773857745\n",
      "  (0, 66)\t0.147480911436757\n",
      "  (0, 64)\t0.13228239831455307\n",
      "  (0, 62)\t0.16713345076152167\n",
      "  (0, 61)\t0.15907151202184194\n",
      "  (0, 57)\t0.1629410701131578\n",
      "  (0, 54)\t0.17170746087417996\n",
      "  (0, 52)\t0.15377404424008703\n",
      "  (0, 47)\t0.12611802215145843\n",
      "  (0, 45)\t0.1156780310573649\n",
      "  (0, 44)\t0.11262985898978843\n",
      "  (0, 42)\t0.13338748544794413\n",
      "  (0, 41)\t0.07023989982329674\n",
      "  (0, 40)\t0.1223919147723857\n",
      "  (0, 36)\t0.1418885487302646\n",
      "  (0, 35)\t0.15212539029330518\n",
      "  (0, 34)\t0.15212539029330518\n",
      "  (0, 31)\t0.15377404424008703\n",
      "  (0, 30)\t0.17170746087417996\n",
      "  (0, 22)\t0.11892299179311845\n",
      "  (0, 19)\t0.14460701836701625\n",
      "  (0, 13)\t0.16499357715915916\n",
      "  (0, 12)\t0.160969074598427\n",
      "  (0, 11)\t0.15547859529160876\n",
      "  (0, 8)\t0.1405825158062841\n",
      "  (0, 0)\t0.1629410701131578\n",
      "environmentalnotices open data application estonian fund nature httpselfondee scrapes official notifications estonian government site parses filters results sends regularily mailing list provides geodata preview implemented nodejs installation npm install create configconfigjson file baseurl sitebaseurl mailfrom mailtosendfrom mailto mailtosendto1 mailtosendto2 mailusername gmailaccounttosentfrom mailpassword gmailaccountpassword running invoke data scraping node scraperjs invoke mailer node mailerjs\n",
      "  (0, 105)\t0.2991414476022495\n",
      "  (0, 103)\t0.3623503328512236\n",
      "  (0, 94)\t0.3623503328512236\n",
      "  (0, 82)\t0.30434294504132237\n",
      "  (0, 66)\t0.3279698440129207\n",
      "  (0, 59)\t0.3070373412300544\n",
      "  (0, 58)\t0.25900706772755544\n",
      "  (0, 44)\t0.25046764984171177\n",
      "  (0, 26)\t0.20960485024949083\n",
      "  (0, 22)\t0.26446239508537545\n",
      "  (0, 6)\t0.33130776445969146\n",
      "environmental monitoring control software component basic system created monitor control preseason started seedlings grow runs raspberry pi model b camera module currently two arduino compatible things stands stuff works reason put force clean bit server contains python basehttpserver based web server providing access camera well arduino frontends via simple web interface configured via webconf use simply run treepy default bind port 8008 enforce basic auth return nothing 404s needs handlers specified webconf useful dotplug bits configuration templates pictures web server component config goes well arduinofrontends arduinos used multiple systems outside web frontend needed layer clients avoid serial contention ' pretty basic sketches speaking arduino sketches mrtg mrtg config client script sensor feeds mrtg installation minimum requirements useful raspberry pi camera module webconf setup looks like baseconfig parallel threading port 8008 auth module authenticator user aber pwd lour handlercamera module camerahandler camera camera resolution 1024x768 lets access 1024x768 snapshot server8008camera timestamp authenticating user aber password lour\n",
      "  (0, 139)\t0.1708581068438245\n",
      "  (0, 131)\t0.1708581068438245\n",
      "  (0, 130)\t0.146137822598862\n",
      "  (0, 129)\t0.12773019895064913\n",
      "  (0, 115)\t0.1708581068438245\n",
      "  (0, 114)\t0.20682635284199122\n",
      "  (0, 113)\t0.19029419058259764\n",
      "  (0, 110)\t0.17558598180203447\n",
      "  (0, 108)\t0.19458695594358666\n",
      "  (0, 106)\t0.20682635284199122\n",
      "  (0, 104)\t0.13411738341207713\n",
      "  (0, 101)\t0.1968497659961735\n",
      "  (0, 96)\t0.152580167009684\n",
      "  (0, 77)\t0.2124866549846985\n",
      "  (0, 75)\t0.20959216012738696\n",
      "  (0, 74)\t0.19919798501047806\n",
      "  (0, 73)\t0.2124866549846985\n",
      "  (0, 72)\t0.19919798501047806\n",
      "  (0, 64)\t0.16369844494881583\n",
      "  (0, 62)\t0.20682635284199122\n",
      "  (0, 59)\t0.1708581068438245\n",
      "  (0, 41)\t0.08692133285256069\n",
      "  (0, 28)\t0.1772452913052525\n",
      "  (0, 23)\t0.1843639512753234\n",
      "  (0, 20)\t0.20682635284199122\n",
      "  (0, 19)\t0.1789500669550617\n",
      "  (0, 18)\t0.19029419058259764\n",
      "  (0, 17)\t0.1924035593272319\n",
      "  (0, 8)\t0.1739697761584145\n",
      "  (0, 0)\t0.20163831421013365\n",
      "environmentalnotices open data application estonian fund nature httpselfondee scrapes official notifications estonian government site parses filters results sends regularily mailing list provides geodata preview implemented nodejs installation npm install create configconfigjson file baseurl sitebaseurl mailfrom mailtosendfrom mailto mailtosendto1 mailtosendto2 mailusername gmailaccounttosentfrom mailpassword gmailaccountpassword running invoke data scraping node scraperjs invoke mailer node mailerjs\n",
      "  (0, 105)\t0.2991414476022495\n",
      "  (0, 103)\t0.3623503328512236\n",
      "  (0, 94)\t0.3623503328512236\n",
      "  (0, 82)\t0.30434294504132237\n",
      "  (0, 66)\t0.3279698440129207\n",
      "  (0, 59)\t0.3070373412300544\n",
      "  (0, 58)\t0.25900706772755544\n",
      "  (0, 44)\t0.25046764984171177\n",
      "  (0, 26)\t0.20960485024949083\n",
      "  (0, 22)\t0.26446239508537545\n",
      "  (0, 6)\t0.33130776445969146\n",
      "environmental data abstraction layer edal documentation source code issues changelog edal project comprises set libraries deal manipulation visualisation environmental data originally created part ncwms standalone libraries ncwms uses edal consists number modules focused different task modules outlined edal modules edal common edalcommon module contains core data model used edal well inmemory implementations data model common utility methods exceptions edal graphics edalgraphics module contains code generating images core edal data types includes map images well timeseries vertical profile vertical section charts additionally custom sld styled layer descriptor handlers allow precise specification assemble map image allowing arbitrarily complex plotting multiple simultaneous data layers module depends edalcommon module edal cdm edalcdm module uses unidata netcdfjava libraries read data core edal data model reads cfcompliant gridded netcdf files well opendap grib several formats see httpwwwunidataucaredusoftwarethreddscurrentnetcdfjavareferenceformatsfiletypeshtml list also includes data reader capable reading uk met office en34 insitu datasets httpwwwmetofficegovukhadobsen3 httpwwwmetofficegovukhadobsen4 modules depends edalcommon module edal wms edalwms module contains implementation wms web map service standard number custom requests suited exposing environmental data web module complete packaged wms supplies required servlet classes requires data catalogue implemented map wms layer names edal data objects module depends edalcommon module edalgraphics module edal xml catalogue edalxmlcatalogue module contains implementation data catalogue xml format allows configuration set datasets xml provision graphics module module depends edalcommon module edalgraphics module godiva 3 edalgodiva module google web toolkit gwt based wms client supports extended wms requests supplied edalwms module module depend others edal developed primarily factor common functionality original ncwms httpsourceforgenetprojectsncwms caching datasets caching datasets improve performance implemented using ehcache two distinct caches included edal cache datasets featurecache cache maps meshdatasetcache using ncwms2 another cache available cache dynamic datasets dynamiccache configuration caches configured using ehcachexml specified runtime jvm parameter ' dehcacheconfigpathtoehcachexml ' default configuration specified commonsrcmainresourcesehcachexml ehcache cache distributed using terracotta specifying parameters ehcachexml example file provided commonsrcmainresourcesehcacheterracottaxml licence copyright c 2010 university reading rights reserved redistribution use source binary forms without modification permitted provided following conditions met 1 redistributions source code must retain copyright notice list conditions following disclaimer 2 redistributions binary form must reproduce copyright notice list conditions following disclaimer documentation andor materials provided distribution 3 neither name university reading names authors contributors may used endorse promote products derived software without specific prior written permission 4 wish use without modification godiva web interface logo reading escience centre must retained web page software provided author ' ' express implied warranties including limited implied warranties merchantability fitness particular purpose disclaimed event shall author liable direct indirect incidental special exemplary consequential damages including limited procurement substitute goods services loss use data profits business interruption however caused theory liability whether contract strict liability tort including negligence otherwise arising way use software even advised possibility damage authors contributors edal libraries developed reading escience centre maintained guygriffiths contributors yosoyjay kwilcox\n",
      "  (0, 139)\t0.15007858366311252\n",
      "  (0, 138)\t0.18410185574374135\n",
      "  (0, 133)\t0.10771879370844138\n",
      "  (0, 132)\t0.1793464004369381\n",
      "  (0, 130)\t0.12836474569682452\n",
      "  (0, 129)\t0.11219583140437839\n",
      "  (0, 117)\t0.16362363767367316\n",
      "  (0, 116)\t0.1487615739397603\n",
      "  (0, 115)\t0.15007858366311252\n",
      "  (0, 112)\t0.13604800742939033\n",
      "  (0, 111)\t0.1793464004369381\n",
      "  (0, 100)\t0.16715087817319393\n",
      "  (0, 97)\t0.16715087817319393\n",
      "  (0, 93)\t0.17497180561789072\n",
      "  (0, 90)\t0.12006805238528409\n",
      "  (0, 85)\t0.1619418662482722\n",
      "  (0, 80)\t0.16031030452674155\n",
      "  (0, 75)\t0.18410185574374135\n",
      "  (0, 73)\t0.18664432619849444\n",
      "  (0, 72)\t0.17497180561789072\n",
      "  (0, 66)\t0.16031030452674155\n",
      "  (0, 62)\t0.18167242205900122\n",
      "  (0, 55)\t0.18410185574374135\n",
      "  (0, 53)\t0.17711534540491888\n",
      "  (0, 47)\t0.1370890533591566\n",
      "  (0, 45)\t0.12574088541493902\n",
      "  (0, 44)\t0.1224275522680074\n",
      "  (0, 42)\t0.1449908886777248\n",
      "  (0, 41)\t0.0763500823320388\n",
      "  (0, 37)\t0.1653588074998231\n",
      "  (0, 35)\t0.1653588074998231\n",
      "  (0, 33)\t0.18410185574374135\n",
      "  (0, 28)\t0.1556889677137936\n",
      "  (0, 26)\t0.10245398467931752\n",
      "  (0, 23)\t0.1619418662482722\n",
      "  (0, 19)\t0.15718641094146898\n",
      "  (0, 18)\t0.16715087817319393\n",
      "  (0, 15)\t0.1224275522680074\n",
      "  (0, 8)\t0.1528118161224216\n",
      "  (0, 7)\t0.15007858366311252\n",
      "  (0, 2)\t0.18167242205900122\n",
      "eflowspecies pisces species analysis environmental flow eflow type published versions rmd files github pages branch httpucdcwsgithubioeflowsspecieseflowdistancehtml example\n",
      "  (0, 51)\t0.5428445689163325\n",
      "  (0, 45)\t0.3901071746798687\n",
      "  (0, 42)\t0.4498297093243672\n",
      "  (0, 41)\t0.23687374879569884\n",
      "  (0, 3)\t0.5428445689163325\n",
      "environmentalrecycling\n",
      "\n",
      "rate plate identify environmental impact food developed cssbristol boeing hackathon overview tweet image food account recognise food tweets back environmental impact food icons designed madebyoliver flaticon development setup dependancies install python version 35 required tensorflow install pip make sure pip updated pip install upgrade pip setup clone repo git clone httpsgithubcomharrymtboeinghackathongit navigate directory cd boeinghackathon run pip install r requirementstxt install python dependancies setup database python dbsetuppy run web server locally running python applicationpy api credentials create file ' credentialspy ' consumerkey consumersecret accesstoken accesstokensecret generate via twitter application management httpsappstwittercom credentialspy consumerkey ' ' consumersecret ' ' accesstoken ' ' accesstokensecret ' ' server side extra setup clone repo git clone httpsgithubcomharrymtboeinghackathongit git pull whenever changes setup cron job crontab e show list cron jobs add python twitterbotpy cronfile add crontab l check see worked setup githook create pullphp file 1 line php exec ' cd boeinghackathon git pull ' technologies used python flask tweepy tensorflow bitly leaflet word net mat plot lib hosted aws\n",
      "  (0, 139)\t0.16593801427060337\n",
      "  (0, 136)\t0.1589845246197283\n",
      "  (0, 130)\t0.1419295843775841\n",
      "  (0, 121)\t0.18898355874769676\n",
      "  (0, 113)\t0.1848144094290562\n",
      "  (0, 110)\t0.17052974361126727\n",
      "  (0, 105)\t0.1616706867063377\n",
      "  (0, 104)\t0.13025529015671422\n",
      "  (0, 100)\t0.1848144094290562\n",
      "  (0, 96)\t0.14818641268106217\n",
      "  (0, 87)\t0.20087050549379107\n",
      "  (0, 86)\t0.19583186352103096\n",
      "  (0, 71)\t0.1934618069340903\n",
      "  (0, 70)\t0.1419295843775841\n",
      "  (0, 66)\t0.17725096380171632\n",
      "  (0, 65)\t0.1934618069340903\n",
      "  (0, 58)\t0.13998010251319623\n",
      "  (0, 53)\t0.19583186352103096\n",
      "  (0, 50)\t0.18091443069751922\n",
      "  (0, 49)\t0.16743015667224373\n",
      "  (0, 44)\t0.13536498292765356\n",
      "  (0, 41)\t0.08441831434133913\n",
      "  (0, 36)\t0.17052974361126727\n",
      "  (0, 34)\t0.18283296316461609\n",
      "  (0, 33)\t0.20355666758040047\n",
      "  (0, 31)\t0.1848144094290562\n",
      "  (0, 27)\t0.17725096380171632\n",
      "  (0, 22)\t0.14292842855499346\n",
      "  (0, 14)\t0.17214127103077698\n",
      "  (0, 12)\t0.1934618069340903\n",
      "  (0, 10)\t0.17905493946315018\n",
      "  (0, 6)\t0.17905493946315018\n",
      "  (0, 4)\t0.17725096380171632\n",
      "  (0, 1)\t0.1644818306304465\n",
      "monitoring environmental conditions near underwater datacenters using deep learning last updated august 29 2018 introduction microsoft put cloud artificial intelligence ai tools hands working solve global environmental challenges programs ai earth also use tools understand interaction environment work done concert project natick project natick seeks understand benefits difficulties deploying subsea datacenters worldwide world ' first deployed underwater datacenter designed emphasis sustainability phase 2 extends research accomplished phase 1 deploying fullscale datacenter module north sea powered renewable energy project natick uses ai monitor servers equipment signs failure identify correlations environment server longevity project natick operates like standard land datacenter computers inside used machine learning provide ai applications microsoft datacenter also using ai monitor surrounding aquatic environment first step understanding impact datacenter may monitoring marine life using object detection project natick datacenter equipped various sensors monitor server conditions environment including two underwater cameras available live video streams check livestream project natick homepage cameras allow us monitor surrounding environment two fixed locations outside datacenter real time want count marine life seen cameras manually counting marine life frame video stream requires significant amount effort solve leverage object detection automate monitoring counting marine life frame count number marine creatures model object detection problem object detection combines task classification localization outputs category set coordinates representing bounding box object detected image run please go following steps able run natickodpy perform object detection project natick livestream push data power bi dashboard clone repository directory choice ensure dependencies installed see create power bi streaming dataset see add power bi streaming dataset url line 139 natickodpy run python natickodpy dependencies pip install cython pip install pillow pip install lxml pip install matplotlib pip install imutils pip install opencvpython pip install ignoreinstalled upgrade tensorflow creating power bi streaming dataset create power bi streaming dataset following tutorial creating dataset add following values running code edit line 139 natickodpy use power bi push url finally navigate cloned repo run python natickodpy note repo uses code tensorflow object detection repository edited file utilsvisualizationutilspy displays fish count bottom left corner video getting data want train scratch annotated data located release tab additional information continue reading additional information necessary running code machine deploying model project natick datacenter another question asked deploy model natick datacenter monitor wildlife teeming around data center chose use cpus process input videos tested locally make sure works well however default tensorflow prebuilt binary optimizations avx fma builtin fully utilize modern cpus better utilize cpus built tensorflow binary source code turning optimization intel cpu following intel ' documentation optimization increase processing speed 50 percent around two frame per second three frame per second build command like bazel build configmkl c opt coptmavx coptmavx2 coptmfma coptmavx512f coptmavx512pf coptmavx512cd coptmavx512er coptdeigenusevml tensorflowtoolspippackagebuildpippackage realtime environmental monitoring power bi environmental scientists aquatic scientists may benefit intuitive way monitoring statistics underwater datacenter quickly gain insight going powerful visualization via power bi power bi notion realtime datasets provides ability accept streamed data update dashboards real time intuitive call rest api post data power bi dashboard lines code rest api endpoint given create api streaming dataset format httpsapipowerbicombetatenant iddatasets dataset idrowskeykey id restapiurl ' push api url goes ' ensure timestamp string formatted properly datetimestrftimedatetimenow ymdthmsz data ' sending power bi rest api data ' timestamp 0 fishcount 1 arrowwormcount 2 ' formatnow fishcount arrowwormcount req urllib2requestrestapiurl data response urllib2urlopenreq animals may move quickly need carefully balance capturing data many frames short succession sending power bi dashboard consuming compute resources chose push analyzed data example fish count power bi three times per second achieve balance summary monitoring environmental impact important topic ai help make process scalable automated post explained developed deep learning solution environment monitoring near underwater data center solution show ingest store data train underwater animal detector detect marine life seen cameras model deployed machines data center monitor marine life time also explored analyze video streams leverage power bi ' streaming apis monitor marine life time questions comments please leave message contributing project welcomes contributions suggestions contributions require agree contributor license agreement cla declaring right actually grant us rights use contribution details visit httpsclamicrosoftcom submit pull request clabot automatically determine whether need provide cla decorate pr appropriately eg label comment simply follow instructions provided bot need across repos using cla project adopted microsoft open source code conduct information see code conduct faq contact opencodemicrosoftcom additional questions comments\n",
      "  (0, 141)\t0.13151181817483248\n",
      "  (0, 140)\t0.1072201064775135\n",
      "  (0, 138)\t0.13499891672893338\n",
      "  (0, 137)\t0.1212549422377196\n",
      "  (0, 135)\t0.13151181817483248\n",
      "  (0, 133)\t0.0789884512746493\n",
      "  (0, 132)\t0.13151181817483248\n",
      "  (0, 130)\t0.09412779434107055\n",
      "  (0, 129)\t0.08227139069242127\n",
      "  (0, 127)\t0.13686326924086428\n",
      "  (0, 126)\t0.11998257023514168\n",
      "  (0, 124)\t0.10373300792341264\n",
      "  (0, 121)\t0.1253340213011735\n",
      "  (0, 116)\t0.10908445898944442\n",
      "  (0, 112)\t0.09976180604970328\n",
      "  (0, 110)\t0.11309543888308597\n",
      "  (0, 109)\t0.13151181817483248\n",
      "  (0, 105)\t0.1072201064775135\n",
      "  (0, 104)\t0.08638539468339396\n",
      "  (0, 102)\t0.13321745225439155\n",
      "  (0, 99)\t0.13321745225439155\n",
      "  (0, 98)\t0.09755521104975363\n",
      "  (0, 96)\t0.09827732701503637\n",
      "  (0, 94)\t0.1298758215616073\n",
      "  (0, 93)\t0.12830399846376211\n",
      "  :\t:\n",
      "  (0, 53)\t0.1298758215616073\n",
      "  (0, 52)\t0.12256903871235536\n",
      "  (0, 47)\t0.10052518821234228\n",
      "  (0, 44)\t0.08977414631257857\n",
      "  (0, 42)\t0.10631947640062632\n",
      "  (0, 41)\t0.05598628197065586\n",
      "  (0, 40)\t0.09755521104975363\n",
      "  (0, 37)\t0.1212549422377196\n",
      "  (0, 36)\t0.11309543888308597\n",
      "  (0, 33)\t0.13499891672893338\n",
      "  (0, 32)\t0.1253340213011735\n",
      "  (0, 31)\t0.12256903871235536\n",
      "  (0, 29)\t0.1253340213011735\n",
      "  (0, 28)\t0.11416420493481381\n",
      "  (0, 26)\t0.07512785186436557\n",
      "  (0, 24)\t0.13499891672893338\n",
      "  (0, 22)\t0.09479022846093552\n",
      "  (0, 16)\t0.12256903871235536\n",
      "  (0, 15)\t0.08977414631257857\n",
      "  (0, 14)\t0.11416420493481381\n",
      "  (0, 12)\t0.12830399846376211\n",
      "  (0, 9)\t0.11874935441720431\n",
      "  (0, 7)\t0.11005020094384113\n",
      "  (0, 4)\t0.11755295656399843\n",
      "  (0, 1)\t0.10908445898944442\n",
      "sheds gis data repository contains scripts used generate supporting data used spatial hydroecological decision system sheds project page describes datasets created repository\n",
      "  (0, 130)\t0.347760992699609\n",
      "  (0, 98)\t0.3604237969791605\n",
      "  (0, 90)\t0.3252838998928347\n",
      "  (0, 85)\t0.438726878321698\n",
      "  (0, 26)\t0.27756452306820084\n",
      "  (0, 23)\t0.438726878321698\n",
      "  (0, 19)\t0.42584357575092513\n",
      "multirotors research andrew bennett ' lab using multirotors conduct environmental exploration sensing sampling missions projects code repository contains mission files general architecture several mission types executed drones namely breath condensate collection cetacean wireless tracker tagging large cetacean photogrammetry animal studies pointofinterest data collection environmental exploration waypoint navigation sense avoid unfriendly multirotors missions designed mission file mission file executed generic autonomy structure based upon state configured layer control sclc controls actions drone running code still construction rc override computer control overridden switching ch 6 transmitter value greater 1500 keyboard controls stabilize sort manual l loiter auto r arm disarm p open planner joystick controls specific joystick finalized yet\n",
      "  (0, 134)\t0.3058358035884785\n",
      "  (0, 133)\t0.17650825238784276\n",
      "  (0, 117)\t0.2681140527185312\n",
      "  (0, 105)\t0.2395949447012164\n",
      "  (0, 102)\t0.29768883052566136\n",
      "  (0, 98)\t0.2179976887234599\n",
      "  (0, 91)\t0.30166970590703907\n",
      "  (0, 82)\t0.2437610423826559\n",
      "  (0, 45)\t0.20603929151270858\n",
      "  (0, 44)\t0.200610056527711\n",
      "  (0, 41)\t0.1251074129048662\n",
      "  (0, 31)\t0.27389379676214876\n",
      "  (0, 26)\t0.16788132472838863\n",
      "  (0, 20)\t0.29768883052566136\n",
      "  (0, 19)\t0.2575659988311006\n",
      "  (0, 15)\t0.200610056527711\n",
      "  (0, 8)\t0.2503977781350452\n",
      "spotfire spotfire crowdsourcing tool support realtime detection monitoring wildfires improving environmental safety preserve wildfire risk spotfire allows users report wildfires different means provides experts means monitor gain insights make predictions give warnings potential disasters project designed nasa space apps 2018 challenge 30 seconds pitch video details please visit nasa space apps 2018 challenge page overview getting started project structure spofi readmemd file requirementstxt python dependencies app android app core backend main service database handlers data opendata serverpy server side onemethod interface handel reports submissions templates &#9; css &#9; js &#9; platformhtml frontpage installation develop environment first clone project git clone recursive j8 httpsgithubcomahmedmaghawryspofigit requirments python 3x firebase keras tensorflow pandas numpy install prerequisites listed requirementstxt pip install r requirementstxt also check readmemd file core folder contributers ahmed ezzat ahmed rizk youssef ahmed yahia elshahawy\n",
      "  (0, 125)\t0.204458041917979\n",
      "  (0, 120)\t0.19947092710157951\n",
      "  (0, 111)\t0.204458041917979\n",
      "  (0, 110)\t0.1758265706063772\n",
      "  (0, 96)\t0.1527892331297155\n",
      "  (0, 94)\t0.20191460005270273\n",
      "  (0, 90)\t0.13687968550131233\n",
      "  (0, 87)\t0.2071097473614519\n",
      "  (0, 86)\t0.20191460005270273\n",
      "  (0, 85)\t0.18461656769803556\n",
      "  (0, 74)\t0.19947092710157951\n",
      "  (0, 70)\t0.14633806138585098\n",
      "  (0, 62)\t0.2071097473614519\n",
      "  (0, 59)\t0.17109221748987916\n",
      "  (0, 58)\t0.14432802663522115\n",
      "  (0, 50)\t0.18653381661830032\n",
      "  (0, 49)\t0.17263070734965896\n",
      "  (0, 46)\t0.19055493264933765\n",
      "  (0, 44)\t0.13956955674908758\n",
      "  (0, 41)\t0.08704043290444555\n",
      "  (0, 40)\t0.15166657800754887\n",
      "  (0, 35)\t0.18851194065193277\n",
      "  (0, 32)\t0.194853579979234\n",
      "  (0, 31)\t0.19055493264933765\n",
      "  (0, 29)\t0.194853579979234\n",
      "  (0, 27)\t0.1827565587207727\n",
      "  (0, 26)\t0.11679933939679744\n",
      "  (0, 14)\t0.17748815370390678\n",
      "  (0, 12)\t0.19947092710157951\n",
      "  (0, 5)\t0.1758265706063772\n",
      "  (0, 2)\t0.2071097473614519\n",
      "environmental sensing aws iot project environmental sensing ph various gases particulate matter sound capturing images multipart project demonstrate environmental monitoring using several types sensors aws services first part focuses building hardware monitoring environmental parameters co2 particulate matter sound capturing images project used environmental monitoring several use cases industrial manufacturing distribution warehouses etc first version environmental sensor box software along capable following features sense temperature humidity pressure co2 tvoc proximity range publish aws iot core capture upload images amazon s3 bucket project also uses aws systems manager enable remote access raspberry pi use aws iot rules log data amazon elasticsearch service second version project retains temperature humidity pressure co2 tvoc proximity replaces camera range sensor ph sensor atlas scientific smaller enclosure source code remains applications ph ph sensor used monitor several industrial agricultural parameters dough fermentation soil ph different crops plants need specific levels ph soil hardware mechanical list shelf hardware used build environmental sensing unit raspberry pi zero w sparkfun qwiic kit raspberry pi ultrasonic range finder hrxlmaxsonarvr unit supports camera raspberry pi capture images load aws s3 camera used arducam lens board sku b0031 could use compatible camera well information ph sensor ph reading circuit smaller enclosure atlas scientific spear tip ph probe ezo ph circuit ezo carrier board smaller enclosure please note code tested earlier version spear tip probe ezo circuits however new probe circuit work fine also important note default carrier board uart mode reprogrammed support i2c mode used project carrier board interfaces qwiic cable qwiic hat baseplate designed 3d printed house components following case bought amazoncom universal project enclosure image assembled unit first iteration support pm25 particulate matter 25 sensing see sensor pms7003 camera image image version ph support architecture high level architecture first iterationpart project configure setup aws iot read setting aws iot create thing created thing raspberry pi make sure keys present ' keys ' subfolder also copy sampleenv file env provide specifics need logging data aws iot core prior logging data take sampleenv file copy env make sure al parameters set correctly run script rpiqwiicawsiotpy read sensor data log aws iot core script calls two helper modules imagecapturepy capture image using hte picamera package upload s3 note s3 bucket name specified env file ultrasonicpy script reads value range finder sensor connected two flags used control import execution modules s3enable ultraenable env file want exclude one set flag emptry string module included set ' true ' see example s3enable ' true ' ultraenable ' ' env file configured correctly start tbe execution follows python3 rpiqwiicawsiotpy want run program background ensure keeps running disconnect remote session raspberry pi execute following nohup python3 u rpiqwiicawsiotpy outputlog go test secion aws iot console subscribe topic using topic used testing following telemetrythingname sample output unit timestamp 1583361438 time 03042020 173717 tempc 2763 tempf 81752 humidity 34475 pressure 106863 tvoc 0 co2 400 proximity 2556 ambient 128 image pzb827ebed3f9a1583361438 data using ultrasonic sensor readings data packet also provides image captured filename used store s3 bucket storing data amazon elasticsearch use amazon elasticsearch store transformed data later use visualization setup amazon elasticsearch region used create iot thing elasticsearch setup go aws iot console setup iot rule see image setup specific iot rule used transform incoming packets select topic2 thingname timestamp parsetimeyyyymmdd ' ' hhmmsszz timestamp americanewyork ts tempf tempc humidity pressure co2 ambient tvoc proximity ' telemetry ' rule minor transformation incoming data message output look follows thingname pzb827ebed3f9a timestamp 1583361502 ts 20200304t1738260500 tempf 82058 tempc 2781 humidity 34288 pressure 106548 co2 400 ambient 125 tvoc 0 proximity 2555\n",
      "  (0, 140)\t0.12219550956268574\n",
      "  (0, 137)\t0.13819058701307665\n",
      "  (0, 136)\t0.12016522842991974\n",
      "  (0, 134)\t0.15597892479998504\n",
      "  (0, 133)\t0.09002074676261769\n",
      "  (0, 132)\t0.14988003802028688\n",
      "  (0, 130)\t0.10727459775402325\n",
      "  (0, 129)\t0.09376221343521611\n",
      "  (0, 124)\t0.11822136890276182\n",
      "  (0, 123)\t0.14450043862482975\n",
      "  (0, 122)\t0.15182389754744482\n",
      "  (0, 121)\t0.14283938993895107\n",
      "  (0, 120)\t0.14622418300337664\n",
      "  (0, 118)\t0.1339715460080298\n",
      "  (0, 117)\t0.13674050315925293\n",
      "  (0, 116)\t0.12432025568245994\n",
      "  (0, 115)\t0.1254208825527412\n",
      "  (0, 113)\t0.13968822298461267\n",
      "  (0, 112)\t0.11369551034435814\n",
      "  (0, 111)\t0.14988003802028688\n",
      "  (0, 109)\t0.14988003802028688\n",
      "  (0, 108)\t0.14283938993895107\n",
      "  (0, 106)\t0.15182389754744482\n",
      "  (0, 105)\t0.12219550956268574\n",
      "  (0, 104)\t0.09845081924372891\n",
      "  :\t:\n",
      "  (0, 76)\t0.12116908872812156\n",
      "  (0, 74)\t0.14622418300337664\n",
      "  (0, 73)\t0.15597892479998504\n",
      "  (0, 71)\t0.14622418300337664\n",
      "  (0, 70)\t0.10727459775402325\n",
      "  (0, 69)\t0.14801554220542956\n",
      "  (0, 66)\t0.1339715460080298\n",
      "  (0, 56)\t0.12116908872812156\n",
      "  (0, 53)\t0.14801554220542956\n",
      "  (0, 47)\t0.11456551388585157\n",
      "  (0, 44)\t0.10231287689050471\n",
      "  (0, 43)\t0.14622418300337664\n",
      "  (0, 42)\t0.12116908872812156\n",
      "  (0, 41)\t0.06380587073338964\n",
      "  (0, 35)\t0.13819058701307665\n",
      "  (0, 31)\t0.13968822298461267\n",
      "  (0, 28)\t0.130109488361254\n",
      "  (0, 26)\t0.08562093848359904\n",
      "  (0, 23)\t0.1353350444237197\n",
      "  (0, 22)\t0.1080295538670876\n",
      "  (0, 21)\t0.14622418300337664\n",
      "  (0, 20)\t0.15182389754744482\n",
      "  (0, 15)\t0.10231287689050471\n",
      "  (0, 9)\t0.1353350444237197\n",
      "  (0, 0)\t0.14801554220542956\n",
      "environment monitoring sensitive healthcare equipment needs suitable operating conditions equipment ' operating environment responsibility customer assist customer maintaining suitable environment install environment monitoring device customer premises monitor data project simulating data monitoring device issuing alerts warnings decomposition top level program runs two processes sender receiver sender responsible simulating monitoring device receiver analyzes data sender sends data receiver using console redirection run command line follows senderexecutable receiverexecutable would make consolewrites sender become consolereads receiver decomposition responsibility within sender receiver naming source files within sender within receiver give internal decomposition code project follows practices tools listed interface document interface sender receiver test cases sender receiver testable sender testable without receiver develop another datasource test confident integration receiver testable without sender enhance without retesting receivers minimum functionality simulating different sequences data monitor sender takes csv file input file contains temperature humidity data sender sends periodically receiver outputs warnings alerts console environmental conditions breach limits temperature warning levels high 37 c low 4 c temperature error levels high 40c low 0 c humidity warning level high 70 humidity error level high 90 extended functionality sender needs send data every 5 minutes receiver ' receive data half hour receiver outputs alert evaluation criteria see evaluation criteria exercise\n",
      "  (0, 133)\t0.1468115924028634\n",
      "  (0, 126)\t0.22300515977407048\n",
      "  (0, 123)\t0.23566055893054447\n",
      "  (0, 122)\t0.2476041242195691\n",
      "  (0, 116)\t0.2027494256718643\n",
      "  (0, 104)\t0.1605598938726024\n",
      "  (0, 90)\t0.16364258603847148\n",
      "  (0, 89)\t0.25091523656695797\n",
      "  (0, 77)\t0.25438040845803794\n",
      "  (0, 74)\t0.23847175153014907\n",
      "  (0, 70)\t0.174950276319912\n",
      "  (0, 65)\t0.23847175153014907\n",
      "  (0, 62)\t0.2476041242195691\n",
      "  (0, 58)\t0.1725472368665732\n",
      "  (0, 57)\t0.241393214709214\n",
      "  (0, 45)\t0.1713741769878968\n",
      "  (0, 44)\t0.16685838453687069\n",
      "  (0, 41)\t0.1040586956218202\n",
      "  (0, 40)\t0.18132063169098175\n",
      "  (0, 35)\t0.22537004928402896\n",
      "  (0, 26)\t0.13963610360789303\n",
      "  (0, 19)\t0.21423176494966192\n",
      "  (0, 16)\t0.22781248982943794\n",
      "  (0, 15)\t0.16685838453687069\n",
      "environmentalicious quite tasty looks decent mobile well synopsis environmentalicious web application allows users locate environmental conservation sustainability events community users create account register attend events believe interesting first release candidate application exhibits main core functionalities current state system user able create events find events relative locations search events based criteria event name event description tags may also join events invite friends become event participants installationrunning would like view application without installing server local machine may navigate httpsalsaritedu3000 link may always available please follow instructions install local machine cannot access deployed version order load application locally nodejs must installed local system recent version nodejs 01033 time writing found httpnodejsorg nodejs environment installed open command prompt terminal move root directory project order install dependencies project first type ' npm install ' completed run command ' node serverjs ' navigate browser httplocalhost3000 npm install node serverjs application usage creating event navigate ' create event ' section left hand bar bar home screen login enter desired event information select ' create event ' button finding already created event navigate ' find event ' section left hand bar home screen login enter information event name event location keyword found description event would like attend click ' find event ' button locate result left hand portion screen may click events navigate main event section page joining event main page specific event would like join click ' join event ' button bottom screen pop notify successfully joined event return individual event page able see participant event inviting friends event provide valid line separated email addresses invite friends text box click ' invite friends ' button alert notify friends successfully invited event recieve email letting know marked potential participant known bugs user authentication login functionality selecting ' log ' button main page direct user web application default account contributors danielle gonzalez justin peterson richie kapadia joe ksiazek\n",
      "  (0, 139)\t0.15443983684497353\n",
      "  (0, 136)\t0.14796816842164828\n",
      "  (0, 131)\t0.15443983684497353\n",
      "  (0, 128)\t0.16496888944030774\n",
      "  (0, 124)\t0.14557455308332873\n",
      "  (0, 117)\t0.16837850737602747\n",
      "  (0, 110)\t0.15871339606119972\n",
      "  (0, 107)\t0.1845581704341597\n",
      "  (0, 104)\t0.12122964016667381\n",
      "  (0, 92)\t0.17016410088516176\n",
      "  (0, 90)\t0.1235572056190368\n",
      "  (0, 85)\t0.1666478640143304\n",
      "  (0, 83)\t0.16837850737602747\n",
      "  (0, 82)\t0.15308455508635607\n",
      "  (0, 68)\t0.18226228139571657\n",
      "  (0, 67)\t0.18226228139571657\n",
      "  (0, 65)\t0.1800564507775222\n",
      "  (0, 64)\t0.14796816842164828\n",
      "  (0, 61)\t0.1779338791995932\n",
      "  (0, 60)\t0.18695178577247926\n",
      "  (0, 58)\t0.13028060079365736\n",
      "  (0, 56)\t0.14920429447589\n",
      "  (0, 41)\t0.07856880022888017\n",
      "  (0, 40)\t0.13690489202822387\n",
      "  (0, 36)\t0.15871339606119972\n",
      "  (0, 30)\t0.19206817243718707\n",
      "  (0, 29)\t0.17588850937905484\n",
      "  (0, 28)\t0.1602132575175048\n",
      "  (0, 25)\t0.17391492191851998\n",
      "  (0, 24)\t0.18945181830702915\n",
      "  (0, 23)\t0.1666478640143304\n",
      "  (0, 22)\t0.1330246314177578\n",
      "  (0, 16)\t0.17200824876858875\n",
      "  (0, 8)\t0.15725249648482348\n",
      "  (0, 7)\t0.15443983684497353\n",
      "  (0, 6)\t0.1666478640143304\n",
      "  (0, 2)\t0.18695178577247926\n",
      "  (0, 0)\t0.18226228139571657\n",
      "monitoring environmental rehabilitation code produced outcome perth hack good monitoring environmental rehabilitation purpose hack produce skeleton solution could evolved time include features ultimate aim submitting application main mobile app stores building architecture rainbow pen event detials perth hack good getting group likeminded people together solve real world problem learn skills collaborative way hosted microsoft hackathon begin friday evening state problem meet team mates brainstorm ideas saturday spend day collaborating coding end hope skeleton solution open sourced allow ongoing development welcome anyone event knowledge coding web mobile development certainly encouraged main emphasis fun learning new skills\n",
      "  (0, 139)\t0.2553868861767305\n",
      "  (0, 138)\t0.31328387122371265\n",
      "  (0, 124)\t0.24072695606276465\n",
      "  (0, 82)\t0.2531457468742274\n",
      "  (0, 78)\t0.22639051420745868\n",
      "  (0, 74)\t0.2977473768394605\n",
      "  (0, 54)\t0.31761036203131027\n",
      "  (0, 43)\t0.2977473768394605\n",
      "  (0, 41)\t0.12992399921554537\n",
      "  (0, 39)\t0.31761036203131027\n",
      "  (0, 34)\t0.2813890557767633\n",
      "  (0, 15)\t0.2083334649942477\n",
      "  (0, 6)\t0.27557448873339846\n",
      "  (0, 5)\t0.26245378681208553\n",
      "sahana eden sahana eden emergency development environment open source framework rapidly build powerful applications emergency management web based collaboration tool addresses common coordination problems disaster finding missing people managing aid managing volunteers tracking camps effectively government groups civil society ngos victims please see website details httpedensahanafoundationorg note developers get started httpedensahanafoundationorgwikidevelop first pull request sign contributor ' license agreement protects rights code allowing distributed used sahana eden httpbitlyssfecla\n",
      "  (0, 139)\t0.2595318979629549\n",
      "  (0, 130)\t0.2219820128167779\n",
      "  (0, 125)\t0.3101449291572915\n",
      "  (0, 116)\t0.25725438424451175\n",
      "  (0, 99)\t0.31416733389714435\n",
      "  (0, 82)\t0.25725438424451175\n",
      "  (0, 79)\t0.26671349668192795\n",
      "  (0, 63)\t0.26425849512575045\n",
      "  (0, 40)\t0.23006490549562356\n",
      "  (0, 34)\t0.2859560911879008\n",
      "  (0, 32)\t0.2955758022125028\n",
      "  (0, 15)\t0.21171478453180828\n",
      "  (0, 9)\t0.2800471518402749\n",
      "  (0, 8)\t0.26425849512575045\n",
      "environmentalsensors httpsuserimagesgithubusercontentcom122488152977143353faa10c8c1111e782ce36de73631b2dpng\n",
      "\n",
      "environmentalnewsap\n",
      "\n",
      "environmentaliottoolkit tvoc\n",
      "\n",
      "requiredenvvarplugin require environmental variable application throw routhlessly zerodependency webpack plugin motivation ever found setting default env vars project make sure app get data developer forgets provide run risk serving hard debugging time contributors even worse ending wrong configuration deployment process accidental values environmental variables app get hard reminder face ' something set usage requirement webpack package installed since ' checking webpack plugin ' probably already register plugin provide required env var names parameters const requiredenvvarplugin require ' requiredenvvarplugin ' moduleexports plugins new requiredenvvarplugin ' apiurl ' ' user ' ' pass ' provide variables list revp ' apiurl ' ' user ' ' pass ' array revp ' apiurl ' ' user ' ' pass ' work hood uses webpack ' defineplugin passes object shape ' processenv ' apiurl xxx user xxx pass xxx xxx respective environmental variables derived processenvxxx ' find one throws faq throw ' warn user ' whole purpose plugin developer ' infere code ' find docs ' deduce application working env var ' set surely ' notice bunch logs spitted onto console startup message clear forgot ' launch license mit httpsopensourceorglicensesmitlicensephp\n",
      "  (0, 141)\t0.22061443561717975\n",
      "  (0, 140)\t0.1798644684989786\n",
      "  (0, 135)\t0.22061443561717975\n",
      "  (0, 132)\t0.22061443561717975\n",
      "  (0, 131)\t0.1846120242859585\n",
      "  (0, 128)\t0.1971980885628144\n",
      "  (0, 124)\t0.17401477156579706\n",
      "  (0, 121)\t0.21025102349532773\n",
      "  (0, 112)\t0.16735297894328477\n",
      "  (0, 104)\t0.14491370705793646\n",
      "  (0, 100)\t0.205612694546727\n",
      "  (0, 92)\t0.20340826413034507\n",
      "  (0, 90)\t0.1476959980690965\n",
      "  (0, 88)\t0.21025102349532773\n",
      "  (0, 81)\t0.22646413255036132\n",
      "  (0, 78)\t0.16365135944394504\n",
      "  (0, 71)\t0.21523323607982225\n",
      "  (0, 70)\t0.15790178033155075\n",
      "  (0, 66)\t0.1971980885628144\n",
      "  (0, 63)\t0.18797418006355968\n",
      "  (0, 60)\t0.22347568037110074\n",
      "  (0, 41)\t0.09391841866896357\n",
      "  (0, 28)\t0.19151337110931915\n",
      "  (0, 26)\t0.12602889130583042\n",
      "  (0, 18)\t0.205612694546727\n",
      "  (0, 15)\t0.1505984245114317\n",
      "  (0, 6)\t0.19920507653409872\n",
      "  (0, 5)\t0.1897204887464939\n",
      "environmental mapping using webgl shaders simulate enviormental reflection launch chrome allowfileaccessfromfiles load local models like osx applicationsgoogle chromeappcontentsmacosgoogle chrome allowfileaccessfromfiles\n",
      "  (0, 133)\t0.4086653946645189\n",
      "  (0, 67)\t0.6719432147277346\n",
      "  (0, 64)\t0.5455116988838145\n",
      "  (0, 41)\t0.28965824304850185\n",
      "environmentalpollution\n",
      "\n",
      "mycodo environmental regulation system latest version 888 mycodo open source software raspberry pi couples inputs outputs interesting ways sense manipulate environment mycodo manual mycodo api latest version v1 mycodo support android app mycodo wiki mycodo custom inputs controllers repository technical support discussion use mycodo forum donate always made mycodo free ' intend changing however find mycodo useful would like support continued development please consider becoming sponsor githubcomsponsorskizniche table contents donate features uses screenshots install mycodo support manual rest api pid control supported inputs outputs custom inputs outputs controllers links license languages thanks features inputs record measurements sensors gpio pin states analogtodigital converters create custom inputs outputs perform actions switching gpio pins highlow generating pwm signals executing shell scripts python code create custom outputs functions perform tasks coupling inputs outputs interesting ways pid controllers conditional controllers trigger controllers name create custom functions web interface securely accessing mycodo using web browser local network anywhere world internet connection view configure system includes several light dark themes dashboards display configurable widgets including interactive live historical graphs gauges output state indicators measurements create custom widgets alert notifications send emails measurements reach exceed userspecified thresholds important knowing immediately issues arise setpoint tracking changing pid controller setpoint time use things like terrariums reflow ovens thermal cyclers sousvide cooking notes record events alerts important points time overlaid graphs visualize events measurement data cameras remote live streaming image capture timelapse photography energy usage measurement calculating tracking power consumption cost time upgrade system easily upgrade mycodo system latest release get newest features restore previouslybacked version translations enable web interface presented different languages figure automated hydroponic system build uses originally developed cultivate edible mushrooms mycodo evolved much things done mycodo projects hydroponic system automation archive mushroom cultivation archive groundbased plant cultivation maintaining honey bee apiary homeostasis archive maintaining humidity underground artificial bat cave archive remote radiation monitoring mapping archive cooking sousvide archive maintaining light schedule regulating humidity ramping 90 50 4 week period acclimatize micropropagated american chestnut plantlets laboratory ambient outdoor conditions archive featured projects others maintaining aquatic systems eg fish hydroponic aquaponic maintaining terrarium herpetarium vivarium environments incubating young animals eggs aging cheese dryaging curing smoking meat archive fermenting beer food tobacco controlling reflow ovens culturing microorganisms treating agricultural waste water archive let know use mycodo may include list screenshots visit screenshots page wiki install mycodo prerequisites raspberry pi singleboard computer version zero 1 2 3 4 raspberry pi operating system flashed micro sd card active internet connection mycodo tested work raspberry pi os lite 20200527 also desktop version using mycodo version 860 install raspberry pi booted raspberry pi os internet connection run following command terminal initiate mycodo install curl l httpskiznichegithubiomycodoinstall bash install notes make sure install script finishes without errors log output created mycodoinstallsetuplog install successful web user interface accessible navigating web browser https127001 replacing 127001 raspberry pi ' ip address upon first visit prompted create admin user redirected login page logged check time correct top left page incorrect time cause number issues measurement storage retrieval among others also ensure host name version number top left page green indicating daemon running red indicates daemon inactive unresponsive last ensure javablocking plugins browser disabled parts web interface function properly receive error install believe preventing system operating please create issue install log attached would first like attempt diagnose issue see diagnosing issues minimal set anonymous usage statistics collected help improve development identifying information saved information collected used improve mycodo sources access information data collected mainly many features used similar information data ' collected viewed ' view collected statistics ' link settings general page opt option general settings page support making post forum issue tracker github please read manual need assistance mycodo mycodo supposedly operating correctly would like assistance configure system merely discuss something related mycodo search mycodo forum similar discussion similar topic ' already exist forum create new post appropriate subforum bug mycodo software believe bug mycodo software first search guthub issues see issue already recently discussed resolved issue novel significantly mre recent similar one create new issue creating new issue make sure read information issue template follow instructions replace template text information requested eg step 1 steps reproduce issue replaced actual steps reproduce issue information provide easier reproduce diagnose issue issue able reproduced enough information provided may delay prevent solving issue manual mycodo manual may found httpskiznichegithubiomycodo mycodo wiki also contains useful information rest api latest api documentation found api information api endpoint documentation pid control proportionalintegralderivative pid controller control loop feedback mechanism used throughout industry controlling systems efficiently brings measurable condition temperature desired state setpoint welltuned pid controller raise setpoint quickly minimal overshoot maintain setpoint little oscillation top graph visualizes regulation temperature red line desired temperature setpoint configured change course day blue line actual recorded temperature green vertical bars represent long heater activated every 20second period regulation achieved minimal tuning already displays minimal deviation setpoint 05 celsius tuning would reduce variability see pid controller pid tuning sections manual information supported inputs outputs supported inputs outputs devices found supported devices section manual custom inputs outputs controllers mycodo supports importing custom input output controller modules find information manual custom inputs custom outputs custom functions would like add list supported inputs outputs controllers submit pull request module created start new issue additionally another github repository devoted custom inputs outputs controllers necessarily fit builtin set included default mycodo imported found kiznichemycodocustom links thanks using supporting mycodo however depending found documentation may latest version may altered obtained official distribution site able find latest version github web site following links httpsgithubcomkiznichemycodo httpskylegabrielcom license see licensetxt mycodo free software redistribute andor modify terms gnu general public license published free software foundation either version 3 license option later version mycodo distributed hope useful without warranty without even implied warranty merchantability fitness particular purpose see gnu general public license details full copy gnu general public license found httpwwwgnuorglicensesgpl30enhtml software includes third party open source software components please see individual files license information applicable languages native english complete dutch german french italian norwegian polish portuguese russian serbian spanish swedish chinese default mycodo display default language set browser may also force language settings gear icon configure general language would like improve translations submit pull request amended po file mycodomycodomycodoflasktranslations start new issue detailing corrections english native language used software dutch mycodo een geautomatiseerd monitoring en regelsysteem dat gebouwd om op de raspberry pi te draaien versies zero 1 2 3 en 4 oorspronkelijk ontworpen om eetbare paddenstoelen te kweken mycodo uitgegroeid tot het vermogen om veel meer te doen waaronder het kweken van planten het kweken van microorganismen het onderhouden van bijenbijen bij de bijen het incuberen van dieren en eieren het onderhouden van aquatische systemen het ouder worden van kazen het fermenteren van voedsel en tabak het koken eten sousvide en meer het systeem bestaat uit een backend daemon en een frontend gebruikersinterface de backend voert metingen uit van sensoren en apparaten coordineert vervolgens een diverse reeks antwoorden op die metingen inclusief het vermogen om outputs te moduleren relais pwm draadloze outlets omgevingsomstandigheden te regelen met elektrische apparaten onder pidregeling gestage regeling omschakeling tijd timers plannen foto ' maken en video streamen acties activeren wanneer metingen aan bepaalde voorwaarden voldoen relais moduleren opdrachten uitvoeren per email op de hoogte stellen etc en meer de frontend een webinterface die gemakkelijke navigatie en configuratie mogelijk maakt vanaf elk apparaat met een browser french mycodo est un systeme de surveillance et de regulation automatise concu pour fonctionner sur le raspberry pi versions zero 1 2 3 et 4 concu l ' origine pour cultiver des champignons comestibles mycodo ' est developpe pour inclure la capacite de faire beaucoup plus notamment la culture de plantes la culture de microorganismes le maintien de l ' homeostasie du rucher des abeilles la mise en incubation des animaux et des ufs la maintenance des systemes aquatiques le vieillissement des fromages la fermentation nourriture sous vide et plus le systeme comprend un serveur demon et une interface utilisateur interface utilisateur le systeme effectue des mesures partir de capteurs et dappareils puis coordonne un ensemble divers de reponses ces mesures notamment la possibilite de moduler les sorties relais pwm prises sans fil de reguler les conditions environnementales avec des appareils electriques sous controle pid regulation continue ou basculement temps planifiez des minuteries capturez des photos et des flux video declenchez des actions lorsque les mesures repondent certaines conditions moduler des relais executer des commandes notifier par courrier electronique etc etc l ' interface web est une interface web qui facilite la navigation et la configuration partir de tout appareil compatible avec le navigateur german mycodo ist ein automatisiertes uberwachungs und regulierungssystem das fur den raspberry pi versionen zero 1 2 3 und 4 entwickelt wurde ursprunglich fur die kultivierung von speisepilzen konzipiert hat mycodo die fahigkeit zu weitaus mehr erweitert darunter die kultivierung von pflanzen die kultivierung von mikroorganismen die aufrechterhaltung der homoostase der bienenhausbienenhauser die inkubation von tieren und eiern die aufrechterhaltung von wassersystemen das altern von kase das garen von lebensmitteln und tabak sowie das kochen essen sousvide und mehr das system besteht aus einem backend daemon und einem frontend benutzeroberflache das backend fuhrt messungen von sensoren und geraten durch und koordiniert dann eine vielzahl von reaktionen auf diese messungen einschlielich der moglichkeit ausgange relais pwm drahtlose ausgange zu modulieren und umgebungsbedingungen mit elektrischen geraten unter pidsteuerung zu regulieren stetige regelung oder umschaltung zeit zeitplane planen fotos aufnehmen und videos streamen aktionen auslosen wenn messungen bestimmte bedingungen erfullen relais modulieren befehle ausfuhren per email benachrichtigen usw und vieles mehr das frontend ist eine weboberflache die eine einfache navigation und konfiguration von jedem browserfahigen gerat aus ermoglicht italian mycodo e un sistema di monitoraggio e regolazione automatico che e stato creato per funzionare sul raspberry pi versioni zero 1 2 3 e 4 originariamente progettato per coltivare funghi commestibili mycodo e cresciuto fino comprendere la capacita di fare molto di piu coltivando piante coltivando microrganismi mantenendo l ' omeostasi delle api apistiche del miele incubando animali e uova mantenendo sistemi acquatici formaggi stagionati alimenti fermentati e tabacco cucinando cibo sousvide e altro ancora il sistema comprende un backend demone e un frontend interfaccia utente il backend esegue misurazioni da sensori e dispositivi quindi coordina un insieme diversificato di risposte tali misurazioni inclusa la possibilita di modulare le uscite rele pwm prese wireless regola le condizioni ambientali con dispositivi elettrici sotto controllo pid regolazione costante commutazione tempo programmare timer acquisire foto e trasmettere video attivare azioni quando le misurazioni soddisfano determinate condizioni modulazione di rele esecuzione di comandi notifica via email ecc e altro il frontend e un ' interfaccia web che consente una facile navigazione e configurazione da qualsiasi dispositivo abilitato per il browser norwegian mycodo er et automatisert overvakings og reguleringssystem som ble bygget kjre pa raspberry pi versjoner zero 1 2 3 og 4 mycodo er opprinnelig utviklet dyrke spiselige sopp og har vokst til inkludere muligheten til gjre mye mer inkludert dyrking av planter dyrking av mikroorganismer opprettholder honningbi apiary homeostasis inkubering av dyr og egg opprettholde akvatiske systemer aldrende oster fermenterende matvarer og tobakk matlaging mat sousvide og mer systemet bestar av en backend daemon og en frontend brukergrensesnitt backend utfrer malinger fra sensorer og enheter og koordinerer deretter et mangfoldig sett med svar pa disse malingene inkludert muligheten til modulere utganger releer pwm tradlse uttak regulere miljforhold med elektriske enheter pidkontroll stabil regulering eller endring tid planlegge timere ta bilder og streame video utlse handlinger nar malingene oppfyller visse forhold modulere releer utfre kommandoer varsle via epost etc og mer frontend er et webgrensesnitt som gjr det enkelt navigere og konfigurere fra hvilken som helst nettleseraktivert enhet polish mycodo zautomatyzowany system monitorowania regulacji ktory zosta zbudowany pracy na raspberry pi wersje zero 1 2 3 pierwotnie zaprojektowany uprawy grzybow jadalnych mycodo rozwineo sie aby umozliwic znacznie wiecej w tym uprawe roslin hodowle mikroorganizmow utrzymanie homeostazy pszczo miodnych inkubacje zwierzat jaj utrzymanie systemow wodnych dojrzewanie serow fermentacje zywnosci tytoniu gotowanie jedzenie sousvide nie tylko system skada sie z zaplecza demona frontendu interfejsu uzytkownika backend przeprowadza pomiary z czujnikow urzadzen nastepnie koordynuje zroznicowany zestaw odpowiedzi na te pomiary w tym mozliwosc modulacji wyjsc przekazniki pwm wyjscia bezprzewodowe regulacje warunkow srodowiskowych za pomoca urzadzen elektrycznych pod kontrola pid regulacja staa lub przeaczanie czas ustawianie timerow robienie zdjec strumieniowanie wideo wyzwalanie dziaan gdy pomiary speniaja okreslone warunki modulacja przekaznikow wykonywanie polecen powiadamianie przez email itp nie tylko frontend interfejs sieciowy ktory umozliwia atwa nawigacje konfiguracje z dowolnego urzadzenia obsugujacego przegladarke portuguese mycodo e um sistema automatizado de monitoramento e regulacao que foi construido para rodar raspberry pi versoes zero 1 2 3 e 4 originalmente concebido para cultivar cogumelos comestiveis mycodo cresceu para incluir capacidade de fazer muito mais incluindo cultivar plantas cultivar microorganismos manter homeostase apiario de abelhas incubar animais e ovos manter sistemas aquaticos queijos envelhecidos fermentar alimentos e tabaco cozinhar comida sousvide e muito mais sistema compreende um backend daemon e um frontend interface de usuario backend conduz medicoes partir de sensores e dispositivos e coordena um conjunto diversificado de respostas essas medicoes incluindo capacidade de modular saidas reles pwm tomadas sem fio regular condicoes ambientais com dispositivos eletricos sob controle pid regulacao estavel ou troca tempo agendar cronometros capturar fotos e transmitir video acionar acoes quando medicoes atenderem determinadas condicoes modular reles executar comandos notificar por email etc e muito mais frontend e uma interface da web que permite facil navegacao e configuracao partir de qualquer dispositivo habilitado para navegador russian mycodo raspberry pi zero 1 2 3 4 mycodo sousvide serbian 1 2 3 4 spanish mycodo es un sistema automatizado de monitoreo regulacion que fue creado para ejecutarse en la raspberry pi versiones cero 1 2 3 4 originalmente disenado para cultivar hongos comestibles mycodo ha crecido para incluir la capacidad de hacer mucho mas incluido el cultivo de plantas el cultivo de microorganismos el mantenimiento de la homeostasis de las abejas la incubacion de animales huevos el mantenimiento de los sistemas acuaticos el envejecimiento de los quesos la fermentacion de alimentos el tabaco la cocina comida sousvide mas el sistema comprende un backend daemon un frontend interfaz de usuario el backend realiza mediciones desde sensores dispositivos luego coordina un conjunto diverso de respuestas esas mediciones incluida la capacidad de modular salidas reles pwm salidas inalambricas regular las condiciones ambientales con dispositivos electricos bajo control pid regulacion constante cambio tiempo programe temporizadores capture fotos transmita videos active acciones cuando las mediciones cumplan ciertas condiciones module reles ejecute comandos notifique por correo electronico etc mas la interfaz es una interfaz web que permite una facil navegacion configuracion desde cualquier dispositivo con navegador swedish mycodo ar ett automatiserat overvaknings och reglersystem som byggdes att springa pa raspberry pi versioner noll 1 2 3 och 4 mycodo har ursprungligen utformats att odla atliga svampar och har darmed okat mojligheten att gora mycket mer inklusive odling av vaxter odlingsmikroorganismer uppratthallande av honeybee apiary homeostasis inkubering av djur och agg uppratthallande av vattenlevande system aldrande ostar jasning av mat och tobak matlagning mat sousvide och mer systemet innefattar en backend daemon och en frontend anvandargranssnitt bakgrunden utfor matningar fran sensorer och enheter och samordnar sedan en mangd olika svar pa dessa matningar inklusive mojligheten att modulera utgangar relaer pwm tradlosa uttag reglera miljoforhallandena med elektriska enheter pidkontroll standig reglering eller byte tid schemalagg timer ta bilder och stromma video utlos atgarder nar matningar uppfyller vissa villkor modulera relaer utfora kommandon meddela via epost etc och mer frontend ar ett webbgranssnitt som mojliggor enkel navigering och konfiguration fran alla webblasaraktiverade enheter chinese mycodoraspberry pizero1234 mycodosousvide pwmpidweb thanks alembic bootstrap date range picker flask flaskbabel flasklimiter flaskrestplus flaskwtf fontawesome gridstackjs gunicorn highcharts influxdb jquery pyro5 sqlalchemy sqlite toastr\n",
      "  (0, 140)\t0.09959414267073462\n",
      "  (0, 139)\t0.10222294841725944\n",
      "  (0, 136)\t0.09793938375592631\n",
      "  (0, 133)\t0.07337044649585046\n",
      "  (0, 132)\t0.1221581213868584\n",
      "  (0, 131)\t0.10222294841725944\n",
      "  (0, 130)\t0.08743301314340897\n",
      "  (0, 129)\t0.07641988887652493\n",
      "  (0, 128)\t0.10919207518094451\n",
      "  (0, 124)\t0.0963550618461239\n",
      "  (0, 122)\t0.12374244329666081\n",
      "  (0, 121)\t0.11641971649770592\n",
      "  (0, 120)\t0.11917845587017345\n",
      "  (0, 118)\t0.10919207518094451\n",
      "  (0, 116)\t0.10132589426250097\n",
      "  (0, 115)\t0.10222294841725944\n",
      "  (0, 112)\t0.09266630925131608\n",
      "  (0, 109)\t0.1221581213868584\n",
      "  (0, 107)\t0.1221581213868584\n",
      "  (0, 106)\t0.12374244329666081\n",
      "  (0, 105)\t0.09959414267073462\n",
      "  (0, 104)\t0.0802412868762633\n",
      "  (0, 99)\t0.12374244329666081\n",
      "  (0, 98)\t0.09061665695697141\n",
      "  (0, 97)\t0.11385139158664456\n",
      "  :\t:\n",
      "  (0, 41)\t0.052004292267317155\n",
      "  (0, 40)\t0.09061665695697141\n",
      "  (0, 37)\t0.11263075941160162\n",
      "  (0, 35)\t0.11263075941160162\n",
      "  (0, 34)\t0.11263075941160162\n",
      "  (0, 33)\t0.12539720221146913\n",
      "  (0, 32)\t0.11641971649770592\n",
      "  (0, 28)\t0.10604434641699781\n",
      "  (0, 26)\t0.06978442983261399\n",
      "  (0, 24)\t0.12539720221146913\n",
      "  (0, 23)\t0.11030337997626419\n",
      "  (0, 22)\t0.08804833204591006\n",
      "  (0, 21)\t0.11917845587017345\n",
      "  (0, 20)\t0.12374244329666081\n",
      "  (0, 19)\t0.10706429915165346\n",
      "  (0, 18)\t0.11385139158664456\n",
      "  (0, 16)\t0.11385139158664456\n",
      "  (0, 15)\t0.08338901564021\n",
      "  (0, 12)\t0.11917845587017345\n",
      "  (0, 11)\t0.11511340891996795\n",
      "  (0, 9)\t0.11030337997626419\n",
      "  (0, 5)\t0.10505159569015775\n",
      "  (0, 4)\t0.10919207518094451\n",
      "  (0, 1)\t0.10132589426250097\n",
      "  (0, 0)\t0.12063848402163567\n",
      "environmental consulting web site project attempt recreate web site environmental consulting firm using bootstrap think ' big improvement\n",
      "  (0, 139)\t0.6436187741260421\n",
      "  (0, 133)\t0.46195690460799227\n",
      "  (0, 90)\t0.5149172573575663\n",
      "  (0, 41)\t0.3274307712369976\n",
      "environmentaljeopardy\n",
      "\n",
      "mitiapenvironmentplatform environmental management platform environmental ministry sri lanka developed collaboration wso2 mitiap program\n",
      "  (0, 89)\t0.6785332114538318\n",
      "  (0, 41)\t0.2813989372906358\n",
      "  (0, 33)\t0.6785332114538318\n",
      "gismo gismo free open source grasshopper plugin gis environmental analysis description gismo enables automatic generation urban environment terrain geometry based location ' latitudelongitude coordinates radius includes connection openstreetmap website generation buildings trees roads rivers map elements 3d building elements also used context analysis types isovist visibility solar radiation thermalwind comfort cfd analysis screenshots requirements mcneel rhino 5 32bit 64bit sr9 rhino 6 rhino 7 wip supported moment grasshopper 090075 090076 ghpython plugin 0603 mapwingis 32bit 64bit version 4942 4961 gismo still support 5 version active internet connection installation install upper mentioned requirements rhino 5 grasshopper ghpython mapwingis download latest gismo plugin files single zip file httpsgithubcomstgeorgesgismozipballmaster check downloaded zip file blocked right click choose properties unblock button click click ok unblock button click ok unpack zip file copy content userobjects folder grasshopper ' filespecial foldersuser object folder folder additional info discussion group facebook twitter gismo heavily influenced ladybug free open source environmental plugin grasshopper using code template follows labybug code organization methods ladybug may also copied gismo licensed gpl30 license httpspdxorglicensesgpl30 latest version 003 contributors antonello di nunzio djordje spasic guillaume meunier mathieu venot support various issues questions given alec bennett andrew young bojan savric christopher crosby dragan milenkovic even rouault graham dawson izabela spasic jonathan de ferranti jukka rahkonen menno deijvan rijswijk michal migurski mostapha sadeghipour roudsari paul meems sergei leschinsky timothy logan ulrich deuschle vladimir elistratov osm gdal communities\n",
      "  (0, 136)\t0.1875296491397031\n",
      "  (0, 133)\t0.14048622281389053\n",
      "  (0, 130)\t0.16741255304272215\n",
      "  (0, 120)\t0.22819720889853823\n",
      "  (0, 116)\t0.1940139775349942\n",
      "  (0, 101)\t0.2255071363813961\n",
      "  (0, 82)\t0.1940139775349942\n",
      "  (0, 81)\t0.2401045670495581\n",
      "  (0, 68)\t0.23099280099313554\n",
      "  (0, 63)\t0.1992962797789617\n",
      "  (0, 59)\t0.19573161393875593\n",
      "  (0, 58)\t0.16511304841541768\n",
      "  (0, 48)\t0.23099280099313554\n",
      "  (0, 46)\t0.217997200916822\n",
      "  (0, 45)\t0.16399052975873324\n",
      "  (0, 44)\t0.15966929998339455\n",
      "  (0, 41)\t0.09957533229892768\n",
      "  (0, 40)\t0.1735084419941066\n",
      "  (0, 38)\t0.2204136513645413\n",
      "  (0, 30)\t0.24342044219545836\n",
      "  (0, 21)\t0.22819720889853823\n",
      "  (0, 15)\t0.15966929998339455\n",
      "  (0, 12)\t0.22819720889853823\n",
      "  (0, 8)\t0.1992962797789617\n",
      "  (0, 3)\t0.22819720889853823\n",
      "electricimpenvironmentals demo project collect store chart environmental data electric imp device using nodejs angular mongodb requirements electric imp dev kit environmental tail nodejs environment mongodb database knowledge javascriptnodejs environments server setup server must publicly accessible npm update bower update node serverjs device setup login httpsideelectricimpcom register electric imp device install agentnut devicenut update agentnut environment begin settings const serverurl httpyourhostcom const wundergroundapikey xxxxxxxxxx const wundergroundlocation nyalbany end settings\n",
      "  (0, 133)\t0.21412725740544955\n",
      "  (0, 127)\t0.3710182439226462\n",
      "  (0, 113)\t0.33226847315997776\n",
      "  (0, 110)\t0.306586795440475\n",
      "  (0, 101)\t0.34371501825252737\n",
      "  (0, 90)\t0.23867555395080495\n",
      "  (0, 58)\t0.25166314184333566\n",
      "  (0, 41)\t0.15177141489989204\n",
      "  (0, 40)\t0.2644592905747701\n",
      "  (0, 39)\t0.3710182439226462\n",
      "  (0, 27)\t0.31867053705646514\n",
      "  (0, 26)\t0.2036616823710589\n",
      "sensorairthingswave hassio support airthings wave airthings wave plus airthings wave mini ble environmental sensors much code build component inspired projects httpairthingscomraspberrypi httpsgithubcommarcelmradonwave aforementioned radonwave project especially useful describes many ble characteristics specific product good troubleshooting tips script provided also useful determining mac address aw device see httpsgithubcommarcelmradonwaveissues3 getting started download customcomponentsairthingswave config directorycustomcomponentsairthingswave example configurationyaml example configurationyaml entry sensor platform airthingswave scaninterval 120 optional configuration variables mac stringoptional airthingswave mac address provided scan airthings devices startup scaninterval stringoptional interval polls defaults 300 seconds 5 minutes limitations may possible wave must connected official app least use program probably get around registering account airthings radon level history stored wave cannot accessed component get around connects regularly radon detector make sure install latest firmware device using official app first known issues yet able specify monitoredconditions configuration translations available yet hardware requirements airthings wave airthings wave plus airthings wave mini raspberry pi 34 builtin bluetooth bluetooth adapter supports bluetooth low energy ble one httpswwwamazoncomdpb01n5mgeusrefcmswrtwdpuxobdncb03p7qzj resources httpsgithubcommarcelmradonwaveissues1 httpscommunityhomeassistantiotradoneyebleinterface94962 httpssupportairthingscomhcenusarticles115002910089howtorespondtoyourradonlevelsmobilesitetrue httpscommunityhomeassistantiotconvertingsensormeasurementunits98807 httpcertiusdownloadscanadameasbwpdf\n",
      "  (0, 133)\t0.13786845445317053\n",
      "  (0, 129)\t0.14359858051954746\n",
      "  (0, 121)\t0.21876119265980962\n",
      "  (0, 120)\t0.22394506643578177\n",
      "  (0, 117)\t0.20942063368378666\n",
      "  (0, 109)\t0.2295440766530086\n",
      "  (0, 108)\t0.21876119265980962\n",
      "  (0, 106)\t0.23252113381284353\n",
      "  (0, 101)\t0.2213051197358363\n",
      "  (0, 93)\t0.22394506643578177\n",
      "  (0, 91)\t0.2356305472752535\n",
      "  (0, 90)\t0.15367417552378526\n",
      "  (0, 89)\t0.2356305472752535\n",
      "  (0, 71)\t0.22394506643578177\n",
      "  (0, 70)\t0.16429304939485792\n",
      "  (0, 58)\t0.1620363928870211\n",
      "  (0, 42)\t0.1855727217470978\n",
      "  (0, 41)\t0.09771988235387769\n",
      "  (0, 38)\t0.21630654483654219\n",
      "  (0, 18)\t0.21393512163349207\n",
      "  (0, 17)\t0.21630654483654219\n",
      "  (0, 15)\t0.15669408125160078\n",
      "  (0, 9)\t0.20726814738885924\n",
      "  (0, 7)\t0.19208442337516368\n",
      "  (0, 5)\t0.19739965922737732\n",
      "1javaionetjdbc 2jdbcjava database connection 3oracel 4xmldom4j 5log4j 1log 2 tdetailx131 3logenvironment 4environment 5 6dom4springioc\n",
      "  (0, 27)\t1.0\n",
      "artemis almost realtime environmental monitoring information system getting started ' already got environmental sensors great ' halfway check supported devices see equipment known work devices plugin difficult write see plugin development starting scratch either buy supported devices take look building sensors prerequisites httpd php python 26 pythonrrdtool rrdtool momentjs 172 pythonsqlalchemy pythonargparse installation run setupsh initialise config files storage directories edit artemisconf liking run artemiscollectpy initialise data store add least one node using artemisclipy addnode run artemiscollectpy detect collect data probes update positions probes using artemisclipy updateprobe necessary modify artemiscronand copy etccrond architecture sensors thread crond sensors thread sensors thread collector json javascript display sensors thread sensors thread ' rrd files supported devices exhaustive list devices listed least tested devices may supported yet listed check git repository manufacturermodelworksprotocolmodule swifttechcm2xmlxmlenvswift swifttechcm2snmpsnmpenvswift apcap7953snmpsnmppduapc jacartaunknownsnmpsnmpenvjacarta plugin development plugins different sensors implemented individual modules plugins module expected define class name subclasses node basepy must define least one method fetch class nodeobject def initself ip selfip ip def fetchself pass plugins implementing access snmp devices basepy also provides convenience function getmib fetching contents mib trees walking tree defined point getmibip mib community public addition basepy provides definitions unit symbols lookup table 1wire device families unittemperature unitcurrent unitairflow unithumidity family1wire additional unit definitions 1wire families added needed reference platform 1wire sensors maxim 1wire sensors lowcost readily available accurate devices easily interfaced computer usb interfaces ds1822 temperature 2c 912 bit ds18b20 temperature 05c 912 bit ds18s20 temperature 05c 9 bit base units currently ongoing project develop lowcost base unit around raspberry pi completed recommended base unit time good options low cost development boards systems based around via atom cpu many available 100 existing commercial units cost region 500\n",
      "  (0, 140)\t0.16562695851269257\n",
      "  (0, 133)\t0.1220164516903544\n",
      "  (0, 127)\t0.21141787451239058\n",
      "  (0, 124)\t0.16024030533238764\n",
      "  (0, 122)\t0.20578604295950892\n",
      "  (0, 109)\t0.2031512854106325\n",
      "  (0, 104)\t0.13344279026928338\n",
      "  (0, 98)\t0.15069722857086668\n",
      "  (0, 96)\t0.15181270844635364\n",
      "  (0, 95)\t0.20853793859093747\n",
      "  (0, 94)\t0.20062409949292048\n",
      "  (0, 90)\t0.1360048438072686\n",
      "  (0, 74)\t0.19819604483443445\n",
      "  (0, 73)\t0.21141787451239058\n",
      "  (0, 69)\t0.20062409949292048\n",
      "  (0, 66)\t0.18158850330887344\n",
      "  (0, 59)\t0.16999871260025035\n",
      "  (0, 56)\t0.16423572112932774\n",
      "  (0, 49)\t0.17152736948101452\n",
      "  (0, 45)\t0.14243063946910858\n",
      "  (0, 41)\t0.08648412975768172\n",
      "  (0, 35)\t0.18730710075985235\n",
      "  (0, 34)\t0.18730710075985235\n",
      "  (0, 26)\t0.11605283759437987\n",
      "  (0, 21)\t0.19819604483443445\n",
      "  (0, 17)\t0.19143579423616636\n",
      "  (0, 13)\t0.2031512854106325\n",
      "  (0, 12)\t0.19819604483443445\n",
      "  (0, 8)\t0.17309473061946865\n",
      "  (0, 7)\t0.16999871260025035\n",
      "  (0, 1)\t0.16850689443414568\n",
      "  (0, 0)\t0.20062409949292048\n",
      "hamlet\n",
      "\n",
      "areawebsite website currently developed area environmental made bootstrap js html css v1 first version supplied client changes suggested v2 currently developed version client\n",
      "  (0, 136)\t0.5850801147716768\n",
      "  (0, 41)\t0.3106684575860487\n",
      "  (0, 33)\t0.7491103848965566\n",
      "modulefile search prefix directory installed software generate environmental modules modulefile installation git clone httpsgithubcomuconnhpcmodulefile pip install user upgrade editable modulefile make sure localbin similar path per pep 370 usage modulefile pathtomyapp10 pathtomymodulefiledirapp10 tests virtual environments tests orchestrated using tox install tox using pip pip install user tox run tests using tox debug failing tests tox pdb add dependencies get import errors need recreate tox environment tox recreate edit files ' likely going create lots linter errors caught tox unit tests text editor ' interactive error reporting use emacs configure python development installing elpy\n",
      "  (0, 133)\t0.13629058903944705\n",
      "  (0, 131)\t0.18988607155232784\n",
      "  (0, 129)\t0.14195513543589677\n",
      "  (0, 128)\t0.2028316979874475\n",
      "  (0, 121)\t0.21625753276798093\n",
      "  (0, 115)\t0.18988607155232784\n",
      "  (0, 107)\t0.22691700970783663\n",
      "  (0, 104)\t0.14905364184021536\n",
      "  (0, 96)\t0.16957257133107573\n",
      "  (0, 87)\t0.22985999529164775\n",
      "  (0, 86)\t0.22409418006014908\n",
      "  (0, 76)\t0.18344889450513263\n",
      "  (0, 71)\t0.22138207857677844\n",
      "  (0, 70)\t0.16241276197607524\n",
      "  (0, 60)\t0.22985999529164775\n",
      "  (0, 59)\t0.18988607155232784\n",
      "  (0, 58)\t0.16018193226283398\n",
      "  (0, 50)\t0.20702387384397908\n",
      "  (0, 49)\t0.19159355889384855\n",
      "  (0, 45)\t0.159092937727548\n",
      "  (0, 41)\t0.09660150597683863\n",
      "  (0, 40)\t0.1683265966515499\n",
      "  (0, 36)\t0.195140476035609\n",
      "  (0, 34)\t0.20921928756472258\n",
      "  (0, 29)\t0.21625753276798093\n",
      "  (0, 22)\t0.16355575864127508\n",
      "  (0, 14)\t0.19698457795664642\n",
      "  (0, 1)\t0.18821973251540744\n",
      "environmentalmodeling\n",
      "\n",
      "multirotors research andrew bennett ' lab using multirotors conduct environmental exploration sensing sampling missions projects code repository contains mission files general architecture several mission types executed drones namely breath condensate collection cetacean wireless tracker tagging large cetacean photogrammetry animal studies pointofinterest data collection environmental exploration waypoint navigation sense avoid unfriendly multirotors missions designed mission file mission file executed generic autonomy structure based upon state configured layer control sclc controls actions drone running code still construction rc override computer control overridden switching ch 6 transmitter value greater 1500 keyboard controls stabilize sort manual l loiter auto r arm disarm p open planner joystick controls specific joystick finalized yet\n",
      "  (0, 134)\t0.3058358035884785\n",
      "  (0, 133)\t0.17650825238784276\n",
      "  (0, 117)\t0.2681140527185312\n",
      "  (0, 105)\t0.2395949447012164\n",
      "  (0, 102)\t0.29768883052566136\n",
      "  (0, 98)\t0.2179976887234599\n",
      "  (0, 91)\t0.30166970590703907\n",
      "  (0, 82)\t0.2437610423826559\n",
      "  (0, 45)\t0.20603929151270858\n",
      "  (0, 44)\t0.200610056527711\n",
      "  (0, 41)\t0.1251074129048662\n",
      "  (0, 31)\t0.27389379676214876\n",
      "  (0, 26)\t0.16788132472838863\n",
      "  (0, 20)\t0.29768883052566136\n",
      "  (0, 19)\t0.2575659988311006\n",
      "  (0, 15)\t0.200610056527711\n",
      "  (0, 8)\t0.2503977781350452\n",
      "mining sensor data evaluate indoor environmental quality public educational buildings project collect extract transform load analyse sensor data transmitted large amount sensors installed school buildings across three european countries sensor data report multiple types information including temperature humidity outdoor weather electronic consumption human activities etc using python library pandas matplotlib numpy comfort tools berkeley aim predict overall comfort kpi indoor environmental quality school buildings based findings school management optimise environment quality basic information care collecting data schools six ready step get work time spent school sometimes even school still stay sports activities stay library studying ideally school enough illumination comfortable temperature hot cold enough fresh air cool head crashed study andor stress governments spend lot money education enough money way put money better place instead paying electricity bills really want something making better place study start look need firsthand data tell us part expensive one start work situation sensor data good cutting point observation analysis points sensors geography distribution locations google map country parameter number comment greece sensing endpoints 872 sensor equals 1 sensing endpoint sensing rate 1 minute modified educators 294 greek public schools gaia students 2267 greek public schools gaia italy roma sensing endpoints 118 soon augmented sensing rate 1 minute modified educators 120 university faculty post doc students 1706 university students italyprato sensing endpoints 117 swedensoderhamn sensing endpoints 3 create 20170712t12 add data yet total 16 sites 1922 sensors record till 20170916 part newly installed year history data 2015 data collected different weather condition different cultures different user behaviour pattens good start could see difference find similarity sensor data unit power consumption calculated power consumption mwh power consumption mwh electrical current maa active power mw apparent energy vah apparent power va voltage v power factor raw value reactive energy varh reactive power var environmental parameters noise raw value motion raw value movement raw value luminosity raw value light lux atmospheric pressure kpa external relative humidity relative humidity rain height mm wind direction degrees wind speed msec temperature centigrade external temperature c radiation usvh careful high die external air contaminants raw value external ammonia concentration raw value external carbon dioxide concentration raw value external carbon monoxide concentration raw value external oxygen concentration raw value carbon monoxide concentration raw value methane concentration raw value points sensors connection wifi 2g3g mobile network connection ethernet lowrate wireless personal area networksieee 802154 data variability potential patterns take close look raw data seek changing patterns temperature light motion power consumption demo schools greece one year time interval day power consumption 10 schools greece 3 schools without power consumption sensors data temperature 12 schools greece demo site 8 greece 3 weeks time interval hour temperature 4 weeks main building building floor plan pattens room4ce ground floor heading north lowest temperature time two first floor two classrooms west class 1 2 next similar pattern temperature changing warmest rooms whole school building rooms north cooler demo site greece 4 weeks time interval hour temperature main building building floor plan patterns temperature computer lab stable rest others still fit expectation humidity main building building floor plan patterns see basement highest humidity music class stable remain good dry condition preserving music instruments luminosity main building subsite building pattern rooms use natural light always light turn weekend rooms facing south exposed longer daylight maximum luminosity compared lab basement availability algorithm availability different prediction clean outlier inactive data intuition sensor data reasonable zero value true valuelike motion one walking around sensor data never zero like temperature humidity always zero others type might zero general summary one point sensors even isare sensor data legal zero summary based timestamps always zero long active process put value 0 1 sum sensor data one points sensors normalized value 0 1 output 1 active 0 inactive points sensors visualize heatmap points sensors availabilities table includes large range data missing due sensors longer working whole sites power 2015nov12017oct30 id name inactive start time outlier total number measurements 144024 3048 20151030 1649 73000 144242 1 294 20151030 1090 94900 144243 2449 20151030 1580 64970 155076 gramscikeynes school 456 20160804 3977 3977 155077 sapienza 5822 20161029 5101 177390 155849 6 2298 20151030 1676 52560 155851 5 2923 20160802 3925 75190 155865 46 3872 20160922 3828 53290 155877 2 3518 20170201 4580 46720 157185 331 20170201 4050 123370 159705 soderhamn 000 20170921 4824 70810 19640 172 20151030 2034 112420 27827 8 371 20151030 1071 71540 28843 2 4308 20151030 2217 117530 28850 55o 2123 20151030 2236 91250 visualize heatmap sensor data availabilities table statistic sensors belong three different vendors different connections name inactive outlier total number measurements libelium outdoor weather 1516 1061 31390 synfield outdoor weather 1440 928 10950 electrical power consumption 1868 3340 73010 visualize heatmap category different connections sensors data reliability clean times period sensors inactive clean sensors always inactive site poweron yet counted inactive sensorsmaybe themactived start count inactive missing data remove outliers turkey ' fences replace minmax value outliers statistics outlier observation point distant observations outlier may due variability measurement may indicate experimental error latter sometimes excluded data set3 outliers occur chance distribution often indicate either measurement error population heavytailed distribution former case one wishes discard use statistics robust outliers latter case indicate distribution high skewness one cautious using tools intuitions assume normal distribution frequent cause outliers mixture two distributions may two distinct subpopulations may indicate ' correct trial ' versus ' measurement error ' modeled mixture model output two ways indicate data point outlier realvalued outlier score higher values score make point like outlier binary label binary value yes data point outlier identify outliers using turkey ' fences aka inter quartile range q1 first quartile q3 third quartile interquartile range iqr q3 q1 lower outlier boundary q1 3 iqr upper outlier boundary q3 3 iqr identify outliers using sliding windows w holds last w1 values moving windows data beginning inter quartile range becomes biggest ever seenhere comes outliers replace min max new value nan also outlier replace average minmaxaverage minmaxaverage previous w1 values moving window average smooth shortterm fluctuations highlight longerterm trends cycles sma straightforward calculation average chosen time period main advantage sma offers smoothed line less prone whipsawing response slight temporary price swings back forth therefore provides stable level indicating support resistance sma ' weakness slower respond rapid changes often occur market reversal points sma often favored analysts operating longer time frames daily weekly charts refill nan average whole series values linear fit statistics linear regression linear approach modeling relationship scalar dependent variable one explanatory variables independent variables denoted x visualize one day temperature data processes mentioned accuracy retrieve outdoor weather api openweathermap realtime data response real time request worldweatheronline history data apis response temperature wind humidity pressure cloud accuracy data retrieved api sensors notice api worldweatheronline provide longer 32days data conclusion yes retrieve realtime historybut accuracy pretty enough interpretation orientation prediction deviation assuming indoor temperature rise day time passing put human activity others consideration identify patten peak time intuitively observing temperature peak different rooms east peak temperature mostly arrives early day west peak late day south peak midnoon later rest room facing northmusic roomcomputer labbasement room relatively low variation average temperature put cloud cover persentage orientation room observe time difference indoor vs outdoor reach daily peak temperature predicting orientation using peak temperature using restful api retrieve time sunrise noon sunsetunit hour check temperature daytime sunrisesunset pick hottest time put timehour listpeakathour orientation sum listpeakathour 24hour 360degreelengthlistpeakathour unitdegree simply match orientation 090 degree northeast 90180 degree southeast 180270 degree southwest 270360 degree northwest imagecomp1jpg exmaple8 class 1 id fb8 classroom reach highest temperature hour peakathourlist 18 17 17 17 17 17 17 17 17 17 17 18 17 17 17 17 17 17 17 17 17 17 17 17 17 17 16 16 16 16 18 17 16 16 17 16 17 16 16 17 16 18 17 17 17 16 16 17 17 16 1717 16 16 17 17 17 16 17 17 18 17 17 16 16 17 17 17 1717 17 16 17 17 16 17 15 16 17 16 16 16 16 16 16 17 17 16 17 16 17 17 15 16 17 17 17 16 16 16 total 16 ' clock 33times 18 ' clock 5times15 ' clock 2times 17 ' clock 60times orientation sum16243602615243602172436060lengthpeakathourlist 2502 degree got orientation 2502 degrees looks like southwest also lot peaks happened morning classlb2 id 0x317 room gets enough exposed sunshinehigh temperature morning also likely facing southeast total 14 ' clock 5times 16 ' clock 3times 10 ' clock 3times 12 ' clock 3times 11 ' clock 3times 15 ' clock 3times13 ' clock 2times 18 ' clock 2times 17 ' clock 2times 7 ' clock 1times 19 ' clock 1times orientation 2057 degreehave peak temperature mornings 7 10 11 takes 250 total got something like heading east south east take close look distribution site rooms different orientation southeast lower temperature compared south southwest room category site site id orientation prediction correct 144024 60 144243 50 155851 20 155865 50 19640 0 27827 25 144242 0 155877 33 159705 28 155849 0 157185 44 rest data category room orientation orientation orientation prediction correct comment n e 0 012 e 35 617 w 56 916 w 0 01 w n 0 011 cloudy coverage impact indoor temperature identify deviation slope deltatemperaturedeltatime slope one room first picture data etl second slop data focusing detecting sudden change indoor temperature slope plot could provide fast efficient way fluctuate exists sep23 top plot peak matching change observed bottom plot well use similar algorithm searching outliers slope detect fluctuate put classrooms one site togetheretl data top slope bottom detect room behavior abnormal room red day time room orange night time comfort wikipedia thermal comfort thermal comfort condition mind expresses satisfaction thermal environment assessed subjective evaluation ansiashrae standard 55 ansiashrae standard 55 thermal environmental conditions human occupancy standard provides minimum requirements acceptable thermal indoor environments purpose standard specify combinations indoor thermal environmental factors personal factors produce thermal environmental conditions acceptable majority occupants within space standard addresses four primary environmental factors temperature thermal radiation humidity air speed two personal factors activity clothing affect thermal comfort applicable healthy adults atmospheric pressures altitudes equivalent 3000 9800 ft indoor spaces designed occupancy least 15 minutes comfort zone refers combinations air temperature mean radiant temperature tr humidity predicted acceptable thermal environment particular values air speed metabolic rate clothing insulation icl intuitively want temperature indoor certain range like 1824 monday friday 800 1800 obviously truth always wish tool cbe thermal comfort tool ashrae55 use choosing adaptive method top user interface chart changes input variables include air temperature mean radiant temperature prevailing mean outdoor temperature personal factors humidity significant method since adaptation considered variable outdoor temperature see explanation first two variables air mean radiant temperature prevailing mean outdoor temperature type outdoor temperature averaged explained standard see wikipedia link brief explanation changing variable makes dot representing current condition move horizontally meaning chart certain conditions indooroutdoor temperature fall inside comfort zone case static sample period 2017sep052017nov04 weekday mondayfriday time 8001600 week year 3644 daytime room comforable n8hours 0 n 1 day comfortable 1 day comfortable 0 following two pictures comfortness ratio per day based hourly temperature site id 27827 8 use sitetemperature sensor outdoor temperature source use worldweatheronline api outdoor temperature source difference might accuracy sitetemperature following two pictures comfortness ratio per day based hourly temperature site id 1442421 use libelium sensor outdoor temperature source use worldweatheronline api outdoor temperature difference might complete nonsense data libelium sensor following two pictures comfortness ratio per day based hourly temperature site id 19640 use libelium sensor outdoor temperature source use worldweatheronline api outdoor temperature retrieve data retrieve data using apis httpsapisparkworksnetswaggeruihtml demo post v1resourcequerytimerange command line curl x post header ' contenttype applicationjson ' header ' accept applicationjson ' header ' authorization bearer cd885cf57fca4be8b32e97225da6763f ' ' queries 1498867200000 granularity day resourceid 156972 resultlimit 0 1500076799000 ' ' httpsapisparkworksnetv1resourcequerytimerange ' reponse body results resourceid156972resourceurigaiaearoom1tempfrom1498867200000to1500076799000granularitydayresultlimit0 average 31995042261495424 summary 47992563392243136 data timestamp 1498856400000 reading 3419535065107274 timestamp 1498942800000 reading 35618584889499054 timestamp 1499979600000 reading 25807027188020786 timestamp 1500066000000 reading 28399119190883642 known issues request data within time range different granularity response time stamps different 5min ' code running time fixed data timestamp 1hour beginning every hour 1day 2100 day 1month 2100 last day month solution use toinstanttoepochmilli 300000300000 change time 5mins interval one hour 5 ' 10 ' 15 ' 55 ' record timestamp cassandra connector data source flink solution reference cassandraconnectoritcase clusterbuilder cb new clusterbuilder override public cluster buildclusterclusterbuilder builder return builderaddcontactpoint127001build string query select resourceidreading gaiareadingdata resourceid155873 inputformattuple2integer float inputsplit source new cassandrainputformatquery cb sourceconfigurenull sourceopennull listtuple2integer float result new arraylist sourcereachedend resultaddsourcenextrecordnew tuple2integer float sourceclose ' read data api resource historical data resource id 90946 20170824t092549323z 20170831t092549080z steps per hour 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 however real data allzeros httpsconsolesparkworksnetresourceview90946 use data extracted api process console data reference data missed time time resource historical data resource id 155918 20170824t092549323z 20170831t092549080z steps per hour 3234 3234 3234 32473637 334425 34259167 3475733 34365334 3332 32764668 32570587 3236722 323155 323068 32241306 31868149 31868149 3185 31838118 31808867 31826338 31822662 31832302 31852188 31842134 31841246 3185319 32140522 33013374 33919827 34664608 3472307 3234 3234 3234 3185 3185 3234 3185 3185 3185 3185 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 31367912 31374935 31410751 31416487 3151673 3194285 3277366 3364148 34232605 33768044 3268922 3230267 32140594 31958946 3187191 31852951 31830269 3164 3146889 31456898 313657 31385254 31381018 3141322 31534771 31668463 3179291 31836 31869188 3238108 33044456 33666306 33827496 3296945 3238393 3223478 32038074 31907423 31856163 31844433 31838556 3169923 316932 31511343 31412098 31391008 31380096 31443954 31619139 31776262 31830036 31832235 31799591 3184828 3209569 32928936 3333732 33126163 32188957 3183223 31623442 31422161 31361742 31356749 313123 30906296 30886333 30878448 30859062 30843264 30859325 30861336 30849495 3085837 3085697 reference building data genome project big data computing naked statistics stripping dread data charles wheelan real time sensor status gaia supervisors professor ioannis chatzigiannakis professor aris anagnostopoulos acknowledgement since first day stepped sapienza ones lead find true love data mining till last six months gave fish also taught fish supports encourage beyond anything could expect blessed without wont standing today\n",
      "  (0, 141)\t0.14136755825166436\n",
      "  (0, 140)\t0.11525538053210671\n",
      "  (0, 138)\t0.1451159864523969\n",
      "  (0, 137)\t0.13034201296878892\n",
      "  (0, 135)\t0.14136755825166436\n",
      "  (0, 134)\t0.14712005700658584\n",
      "  (0, 133)\t0.08490799261807075\n",
      "  (0, 131)\t0.11829756753764573\n",
      "  (0, 129)\t0.08843696161735555\n",
      "  (0, 126)\t0.1289742870435561\n",
      "  (0, 125)\t0.14136755825166436\n",
      "  (0, 124)\t0.11150695233137421\n",
      "  (0, 122)\t0.14320101571917154\n",
      "  (0, 120)\t0.137919338569516\n",
      "  (0, 118)\t0.1263625936083108\n",
      "  (0, 116)\t0.11725945108629567\n",
      "  (0, 109)\t0.14136755825166436\n",
      "  (0, 108)\t0.13472678579847758\n",
      "  (0, 105)\t0.11525538053210671\n",
      "  (0, 103)\t0.13960895701164366\n",
      "  (0, 101)\t0.13629349474759073\n",
      "  (0, 99)\t0.14320101571917154\n",
      "  (0, 97)\t0.13175459027556305\n",
      "  (0, 96)\t0.1056424125560054\n",
      "  (0, 95)\t0.1451159864523969\n",
      "  :\t:\n",
      "  (0, 65)\t0.137919338569516\n",
      "  (0, 64)\t0.11334040979888135\n",
      "  (0, 62)\t0.14320101571917154\n",
      "  (0, 60)\t0.14320101571917154\n",
      "  (0, 57)\t0.13960895701164366\n",
      "  (0, 56)\t0.11428725556338117\n",
      "  (0, 55)\t0.1451159864523969\n",
      "  (0, 54)\t0.14712005700658584\n",
      "  (0, 47)\t0.10805873264922583\n",
      "  (0, 41)\t0.060181997995488366\n",
      "  (0, 40)\t0.1048661798781874\n",
      "  (0, 35)\t0.13034201296878892\n",
      "  (0, 31)\t0.13175459027556305\n",
      "  (0, 26)\t0.0807580727128187\n",
      "  (0, 25)\t0.13321506058124344\n",
      "  (0, 22)\t0.1018939843552729\n",
      "  (0, 16)\t0.13175459027556305\n",
      "  (0, 15)\t0.09650198768802062\n",
      "  (0, 13)\t0.14136755825166436\n",
      "  (0, 12)\t0.137919338569516\n",
      "  (0, 11)\t0.13321506058124344\n",
      "  (0, 8)\t0.1204520038573341\n",
      "  (0, 4)\t0.1263625936083108\n",
      "  (0, 3)\t0.137919338569516\n",
      "  (0, 1)\t0.11725945108629567\n",
      "air china openair project fetch data official silverlight application ministry environmental protection china http1063720823320035 publish realtime air quality http1063720823320035 silverlight install via pip recommanded pip install openair git clone httpsgithubcomhebingchangairinchina cd airinchina python setuppy install usage encoding utf8 openair import airclass air airclassairchina print airgetallstationsdata type 0 type 0id ' 9 ' 1 ' ' 2 ' shanghai ' shanxi shanxi print airgetprovincestationsdatashanghai type2 print airgetallprovincename 1 id getallprovincenameid airgetprovinceallcityname12 1 id airgetprovinceallstationinfo10 2 id unicode getprovinceallcityname airgetcityallstationinfo10 u aqi 1 id 310000u ' ' airgetcityhistory310000 return values json area co24h 31 latitude 398673 o3 64 pm1024h no2 160 o324h 2 unheathful so224h 41 pm2524h 247 aqi 329 provinceid 1 pm25 279 co 43 o38h 39 longitude 116366 o38h24h 29 so2 53 timepoint 20170215t220000 stationcode 1001a orderid 1 citycode 110000 positionname pm10 primarypollutant pm25 no224h 120 measure ispublish true quality 1 beijing 2 tianjin 31 xinjiang latitude 312472 stationcode 1160a positionname longitude 120561 latitude 312864 stationcode 1161a positionname longitude 120628 latitude 313708 stationcode 1167a positionname longitude 120641 aqi citycode 310000 area unheathful quality pm2524h 31 primarypollutant timepoint 20170201t000000 co24h 07 pm1024h 37 no224h 20 so224h 12 measure o38h24h 90 aqi 45 id 386477 citycode 310000 area unheathful quality pm2524h 21 primarypollutant timepoint 20170202t000000 co24h 06 pm1024h 27 no224h 23 so224h 11 measure o38h24h 87 aqi 44 id 386876 thanks pythonwcfbin httpsgithubcomernwpythonwcfbin license project mit license copyright 2017 permission hereby granted free charge person obtaining copy software associated documentation files software deal software without restriction including without limitation rights use copy modify merge publish distribute sublicense andor sell copies software permit persons software furnished subject following conditions copyright notice permission notice shall included copies substantial portions software software provided without warranty kind express implied including limited warranties merchantability fitness particular purpose noninfringement event shall authors copyright holders liable claim damages liability whether action contract tort otherwise arising connection software use dealings software afterword\n",
      "  (0, 135)\t0.23960420457740986\n",
      "  (0, 129)\t0.1498920127476979\n",
      "  (0, 128)\t0.21417225496643494\n",
      "  (0, 115)\t0.20050282344723397\n",
      "  (0, 96)\t0.17905357171875916\n",
      "  (0, 93)\t0.23375980898646032\n",
      "  (0, 90)\t0.16040918645061114\n",
      "  (0, 87)\t0.24271173592025524\n",
      "  (0, 86)\t0.23662354722932238\n",
      "  (0, 63)\t0.20415438259613466\n",
      "  (0, 58)\t0.16913789105948812\n",
      "  (0, 55)\t0.24595742428750184\n",
      "  (0, 50)\t0.21859882026819946\n",
      "  (0, 49)\t0.20230577839899289\n",
      "  (0, 48)\t0.23662354722932238\n",
      "  (0, 47)\t0.18314899828692427\n",
      "  (0, 45)\t0.1679880095686634\n",
      "  (0, 41)\t0.10200260892897253\n",
      "  (0, 37)\t0.22091698213254962\n",
      "  (0, 26)\t0.1368770460130073\n",
      "  (0, 21)\t0.23375980898646032\n",
      "  (0, 14)\t0.20799821562997198\n",
      "  (0, 10)\t0.21635199789717616\n",
      "  (0, 6)\t0.21635199789717616\n",
      "python audio feature extraction repository holds library implementations separate utilities used extraction processing features audio files underlying extraction library librosa offers ability extract variety spectral features well miscellaneous features project goals learn feature extraction audio files standardize parameters use extraction large amounts audio samples allow relatively easy interface select extract subsets parameters subsets samples provide pandas wrappings extraction results hold important metadata information extraction process current implementations audiofeatureextractor class defines object used standardize set parameters used feature extraction provides wrapper methods librosa functions handle preprocessing steps preemphasis filtering hard low high cutoffs facilitate data cleaning batchextractor class defines object holds information batch audio samples feature extraction performed implements methods handle batch extraction using set standardized settings easy selection desired features featurevisualizer class defines object handle visualization features matplotlib usage documentation audiofeatureextractor class imported afe module words import audiofeatureextractor object simply put afe import audiofeatureextractor along rest needed imports instantiate audiofeatureextractor object put work object takes parameters instantiation desired sample rate hz use loading analysis audio default 22050 desired number samples use window length framed computations feature extractions number set integer power 2 optimize fourier engine default 1024 desired ratio window length hop framed computations ie overlapping factor setting 4 implies frame jumps 14 window length framed computations default 4 audiofeatureextractor capability retrieving audio string file path instance ' sample rate loading numpy array detect onsets perform preemphasis filtering bandpass filtering noise removal low high regions extract feature using instance ' standardized framing attributes either numpy array audio samples preprocessed stftcqt bandpass noise removal currently following feature extraction methods implemented feature extraction methods begin prefix extract extractstft extracts short time fourier transform extractcqt extracts constantq transform extractchromastft extracts chromagram extractchromacqt extracts chromagram cqt extractchromacens extracts energy normalized variant chromagram extractmelspectrogram extracts melwindowed spectrogram extractmfcc extracts melfrequency cepstral coefficients extractrms extracts framed rootmeansquare extractspectralcentroid extracts spectral centroid extractspectralbandwidth extracts spectral bandwidth extractspectralcontrast extracts spectral contrast extractspectralflatness extracts spectral flatness extractspectralrolloff extracts spectral rolloff extractzerocrossingrate extracts framed zero crossing rate extracttonnetz extracts tonnetz tonal centroid extractpolyfeatures extracts polynomial combinations features given feature matrix audio ultimately would like add functionalities audiofeatureextractor tempo related feature extraction methods feature manipulation tools offered librosa feature inversion tools translate back feature space auditory space hopefully facilitate interesting generative projects later perhaps incorporating utilities could helpful later projects methods feature engineering batchextractor batchextractor somewhat extension audiofeatureextractor handle standardized extraction batch samples order use batchextractor object must import way afe import batchextractor instantiate batchextractor object object accepts instantiation following parameters three parameters accepted instantiation audiofeatureextractor object string path folder containing audio samples either pandas dataframe string path csv file read dataframe metadata information samples specified folder audio details formatting index dataframe discussed indepth number melfrequency cepstral coefficients compute default 12 boolean flag indicating whether preemphasis filtering applied audio computation features default false float 0 1 indicating desired preemphasis filter coefficient option desired appropriately set using boolean flag default 097 boolean flag indicating whether hardbandpass filtering noise higher lower frequencies applied default false hardbandpass noise filtering applied flag appropriately set integer values set upper lower limits noise filtering default none boolean flag indicating whether start audio samples trimmed first computed onset default false batchextractor specified requires index dataframe specified either string pointing csv file passing dataframe particular dataframe needs column named filename indicates audio sample analyzed file path string relative batchextractor ' stored audio folder path columns present index dataframe could depend context project currently batchextractor used perform following tasks methods available set preprocessing options setbpfilter sets bandpass noise filtering flag parameters setpreemphasis sets preemphasis flag parameters settrim sets flag trimming first onset methods extract merge features batch samples stored instance ' index folder audio methods accepts string indicating resultsfolder either save extracted feature matrices csv files look saved extraction results csv files case merging additional options method detailed batchextractfeature accepts string abbreviation single extraction method apply entire batch audio index saves results given resultsfolder batchextractfeatures accepts list string abbreviations extraction methods apply entire batch audio index saves results given resultsfolder mergefeatures accepts list string abbreviations features merge single dataframe words sample audio index feature matrices specified list abbreviations loaded resultsfolder merged saved new dataframe batchextractandmerge performs batch extraction merging features given list string abbreviations audio samples index mergeandflattenfeatures methods nonnull return method loads sample audio index feature matrices given list extraction abbreviations flattens single row creating many many columns concatenates rows appropriately padded dataframe containing feature information samples index would eventually like add following batchextractor implementation featurevisualizer featurevisualizer class defines object could helpful purposes debugging identifying import sonic features general computations stftspectrogram helpful give us good visual description happening audio even though quantities also helpful making specific quantifications purposes analysis featurevisualizer class attempt creating interface visualization features extracted using batchextractor similarly audiofeatureextractor object instantiation object accepts following parameters string path indicating folder containing extracted features following naming convention ' samplenamefeatureabbreviationfeaturescsv ' default figure size use plotting default 18 8 currently class least implementation written currently object capable visualizing simply calling name sample loaded folder extracted features stftspectrograms melwindowed spectrograms chromagrams many feature visualization methods would like implement cqts spectral bandwidth related features tempograms eventually\n",
      "  (0, 140)\t0.1327917326147113\n",
      "  (0, 138)\t0.1671956934430376\n",
      "  (0, 135)\t0.16287693389307925\n",
      "  (0, 133)\t0.09782692487358394\n",
      "  (0, 130)\t0.1165769491226292\n",
      "  (0, 129)\t0.10189283403630706\n",
      "  (0, 128)\t0.14558893186129263\n",
      "  (0, 126)\t0.14859800002560342\n",
      "  (0, 124)\t0.128472973064753\n",
      "  (0, 118)\t0.14558893186129263\n",
      "  (0, 117)\t0.14859800002560342\n",
      "  (0, 112)\t0.12355465322067366\n",
      "  (0, 103)\t0.16085075772184468\n",
      "  (0, 98)\t0.1208217929125772\n",
      "  (0, 97)\t0.15180133232703674\n",
      "  (0, 96)\t0.12171613104866878\n",
      "  (0, 94)\t0.16085075772184468\n",
      "  (0, 92)\t0.15017382836884619\n",
      "  (0, 91)\t0.1671956934430376\n",
      "  (0, 90)\t0.10904214516368338\n",
      "  (0, 88)\t0.15522575374090347\n",
      "  (0, 83)\t0.14859800002560342\n",
      "  (0, 81)\t0.1671956934430376\n",
      "  (0, 80)\t0.14558893186129263\n",
      "  (0, 78)\t0.1208217929125772\n",
      "  (0, 77)\t0.1695046876083793\n",
      "  (0, 73)\t0.1695046876083793\n",
      "  (0, 69)\t0.16085075772184468\n",
      "  (0, 66)\t0.14558893186129263\n",
      "  (0, 64)\t0.13058539499821606\n",
      "  (0, 62)\t0.16498935582654234\n",
      "  (0, 56)\t0.13167630536618632\n",
      "  (0, 47)\t0.12450009940007341\n",
      "  (0, 46)\t0.15180133232703674\n",
      "  (0, 45)\t0.11419403919727715\n",
      "  (0, 44)\t0.11118497103296635\n",
      "  (0, 43)\t0.15890406022839967\n",
      "  (0, 37)\t0.15017382836884619\n",
      "  (0, 32)\t0.15522575374090347\n",
      "  (0, 30)\t0.1695046876083793\n",
      "  (0, 28)\t0.14139197463914394\n",
      "  (0, 26)\t0.09304558579955098\n",
      "  (0, 25)\t0.1534840163061123\n",
      "  (0, 24)\t0.1671956934430376\n",
      "  (0, 13)\t0.16287693389307925\n",
      "  (0, 7)\t0.13629679486463334\n",
      "  (0, 3)\t0.15890406022839967\n",
      "  (0, 1)\t0.13510072678005303\n",
      "earthsim pythonbased tools specifying launching visualizing analyzing environmental simulations hydrology modeling earthsim designed lightweight overview site project relying core code maintained generalpurpose pyviz projects bokeh interactive browserbased plotting holoviews easy construction bokeh plots datasets datashader rendering large datasets images display browsers param specifying parameters interest eg make widgets geoviews holoviews earthspecific projections repository primarily consists three things earthsim python package small amount code specific environmental simulation examples set jupyter notebooks show use various pyviz tools solve earthscience problems website example notebooks already run rendered html simple exploration cases examples notebooks website represent main form documentation even python package please see httpsearthsimpyvizorg information including installation usage instructions\n",
      "  (0, 129)\t0.16504133483404473\n",
      "  (0, 128)\t0.23581826807259726\n",
      "  (0, 126)\t0.24069221854361397\n",
      "  (0, 117)\t0.24069221854361397\n",
      "  (0, 114)\t0.267242184168898\n",
      "  (0, 112)\t0.20012815508921286\n",
      "  (0, 104)\t0.1732942731211967\n",
      "  (0, 98)\t0.19570159342342877\n",
      "  (0, 96)\t0.1971502012786284\n",
      "  (0, 91)\t0.27081590855064586\n",
      "  (0, 90)\t0.17662146078466495\n",
      "  (0, 70)\t0.1888259903264986\n",
      "  (0, 61)\t0.2543513468911944\n",
      "  (0, 59)\t0.22076729115264032\n",
      "  (0, 56)\t0.21328323438238053\n",
      "  (0, 55)\t0.27081590855064586\n",
      "  (0, 42)\t0.21328323438238053\n",
      "  (0, 41)\t0.11231183320307526\n",
      "  (0, 37)\t0.24324467295022545\n",
      "  (0, 31)\t0.2458808291455841\n",
      "  (0, 15)\t0.18009231175400167\n",
      "mpies metaproteomics environmental sciences mpies workflow create annotated databases metaproteomic analysis workflow uses three different databases metagenome otutable ii assembledderived iii unassembledderived build consensus databases increase mapping sensitivity use mpies research please cite publication werner j geron kerssemakers j et al mpies novel metaproteomics tool creation relevant protein databases automatized protein annotation biol direct 14 21 2019 doi 101186s130620190253x installation easiest way use bioconda create new environment conda env create n mpies file condaenvyml conda activate mpies singlem packaged appimage due python 2 dependency download appimage build image cd appimages appimagesinglemsh appimagetoolx8664appimage singlemx8664appimage singlemappimage usage mpies consists two parts database creation annotation parts written snakemake database creation snakemake snakefile databasecreationsmk configfile databasecreationjson cores 28 annotation snakemake snakefile annotationsmk configfile annotationjson cores 28 detailed explanation mpies workflow database creation preprocessing preprocessing trims raw reads combines single reads one file ampliconderived proteome file order create ampliconderived proteome file two possibilities amplicon data available text file taxon names one per line used downloading proteomes uniprot amplicon data available set option configotutablerunsinglem true taxon file created singlem tool detects otu abundances based metagenome shotgun sequencing data functionalderived subset also possible create subset derived uniprot based taxonomy also restrict gene functional names instead downloading entire proteomes taxa interest toml file created see example taxonomy bacteria genenames dnak soxa proteinnames heat shock protein 70 something commented path needs set snakemake configuration configfunctionalsubsettomlfile assembledderived proteome file raw data available possible run assembly megahit metaspades set configassembledrunassembly true configassembledassembler megahit metaspades please keep mind assemblies take lot time depending size dataset already assembly set configassembledrunassembly false create symlink assembly sampleassemblycontigsfa gene calling yet remember set configassembledrungenecalling true assembly gene calling already performed set configassembledrunassembly configassembledrungenecalling false create symlink assembled proteome sampleproteomeassembledfaa unassembledderived proteome file create unassembledderived proteome file fraggenescan used prior fastqtofasta conversion postprocessing postprocessing three proteomes combined one file short sequences 30 amino acids deleted duplicates removed afterwards fasta headers hashed shorten headers save disk space annotation preprocessing identified proteins inferred proteinpilot resulting excel file used create protein fasta file contains identified proteins taxonomic functional analysis conducted identified proteins taxonomical annotation taxonomic analysis performed blast2lca megan package per default taxonomic analysis set false snake config file prerequisites necessary run taxonomic analysis created proteome fasta file download megan ' forget also download unzip file protacc2taxjune2018x1abinzip page download nrgz fasta file ncbi size 40 gb wget ftpftpncbinlmnihgovblastdbfastanrgz wget ftpftpncbinlmnihgovblastdbfastanrgzmd5 md5sum c nrgzmd5 checksum match download probably complete wget c continues partial download create diamond database file nrgz diamond makedb threads numberofthreads nrgz db nrdmnd set configtaxonomyruntaxonomy true run snakemake remember set paths diamond database binary blast2lca path file protacc2taxjun2018x1abin please note diamond blastp takes long time execute functional annotation different databases used add functional annotation per default funtional annotation set false cog order use cog database prerequisites fulfilled download necessary files ftp server wget ftpftpncbinihgovpubcogcog2014dataprot20032014fagz wget ftpftpncbinihgovpubcogcog2014datacog20032014csv wget ftpftpncbinihgovpubcogcog2014datacognames20032014tab wget ftpftpncbinihgovpubcogcog2014datafun20032014tab create diamond database file prot20032014fagz diamond makedb threads numberofthreads prot20032014fagz db cogdmnd set configfunctionsruncogrunfunctionscog true run snakemake remember set paths diamond database files cogtable cognames cogfunctions uniprotgo order use go ontologies included uniprot database swissprot trembl prerequisites fulfilled download necessary files ftp server swissprot wget ftpftpuniprotorgpubdatabasesuniprotcurrentreleaseknowledgebasecompleteuniprotsprotfastagz wget ftpftpuniprotorgpubdatabasesuniprotcurrentreleaseknowledgebasecompleteuniprotsprotdatgz trembl wget ftpftpuniprotorgpubdatabasesuniprotcurrentreleaseknowledgebasecompleteuniprottremblfastagz wget ftpftpuniprotorgpubdatabasesuniprotcurrentreleaseknowledgebasecompleteuniprottrembldatgz please note trembl quite large 29 gb uniprottremblfastagz 78 gb uniprottrembldatgz create diamond database fasta file swissprot database used diamond makedb threads numberofthreads uniprotsprotfastagz db sprotdmnd use dat file downloaded uniprot create table protein accessions go annotations mainpy prepareuniprotfiles u uniprotsprotdatgz sprottablegz please note input output files must beare compressed gzip set configfunctionsrununiprotrunfunctionsuniprot true run snakemake test data test data set subset ocean sampling day first 18000 lines read file accession number err770958 obtained httpswwwebiacukenadataviewerr770958 data deposited testdata directory repository\n",
      "  (0, 138)\t0.1721221860494753\n",
      "  (0, 132)\t0.16767617240251415\n",
      "  (0, 130)\t0.12001193878119573\n",
      "  (0, 129)\t0.1048951499643777\n",
      "  (0, 128)\t0.14987877199786395\n",
      "  (0, 125)\t0.16767617240251415\n",
      "  (0, 124)\t0.13225848415595945\n",
      "  (0, 123)\t0.16165782167613496\n",
      "  (0, 112)\t0.1271952439144166\n",
      "  (0, 110)\t0.14419548426353798\n",
      "  (0, 104)\t0.11014046138983391\n",
      "  (0, 102)\t0.16985083775159743\n",
      "  (0, 98)\t0.12438185870866869\n",
      "  (0, 97)\t0.15627422349998626\n",
      "  (0, 96)\t0.1253025489003927\n",
      "  (0, 85)\t0.15140416656300834\n",
      "  (0, 84)\t0.15297650364242638\n",
      "  (0, 83)\t0.15297650364242638\n",
      "  (0, 80)\t0.14987877199786395\n",
      "  (0, 79)\t0.14419548426353798\n",
      "  (0, 78)\t0.12438185870866869\n",
      "  (0, 77)\t0.17449921571531116\n",
      "  (0, 65)\t0.16358623631635524\n",
      "  (0, 59)\t0.1403128382109324\n",
      "  (0, 57)\t0.16559029408392534\n",
      "  (0, 53)\t0.16559029408392534\n",
      "  (0, 45)\t0.11755881539587168\n",
      "  (0, 44)\t0.11446108375130924\n",
      "  (0, 42)\t0.13555620401351934\n",
      "  (0, 41)\t0.07138191531507522\n",
      "  (0, 40)\t0.12438185870866869\n",
      "  (0, 38)\t0.15800648848208396\n",
      "  (0, 36)\t0.14419548426353798\n",
      "  (0, 35)\t0.154598764441686\n",
      "  (0, 28)\t0.1455581496363886\n",
      "  (0, 27)\t0.14987877199786395\n",
      "  (0, 26)\t0.095787213774911\n",
      "  (0, 23)\t0.15140416656300834\n",
      "  (0, 22)\t0.12085653525343158\n",
      "  (0, 19)\t0.14695815291604722\n",
      "  (0, 18)\t0.15627422349998626\n",
      "  (0, 17)\t0.15800648848208396\n",
      "  (0, 10)\t0.15140416656300834\n",
      "  (0, 9)\t0.15140416656300834\n",
      "  (0, 8)\t0.14286821682988832\n",
      "  (0, 7)\t0.1403128382109324\n",
      "  (0, 3)\t0.16358623631635524\n",
      "  (0, 1)\t0.13908152746875646\n",
      "environmentalinterface underlying middleware servioticy requirements servioticy apikey inside servioticyres directory secretsexample must fulfilled instructions inside deletion requirements order use delete scripts clean service objects additional tools needed curl postgresql client sudo aptget install postgresqlcommon postgresqlclientversion file pgpass root directory following database info content cd echo hostnameportdbnamedbuserdbpassword pgpass preparation phase order create valid servioticy folder several files must created executing firstly models room sensors must created make use generator inside servioticymodels javac modelgeneratorjava java modelgenerator rooms room currently composed 5 sensors xm1000 light power presence air quality additionally actuators also created making use generator inside servioticyactuators javac actuatorgeneratorjava java actuatorgenerator rooms currently room contains computer light hvac actuators order push actuators servioticy store ids database additional scripts created pushactuatorssh script firstly uses createsosh script communicate servioticy obtain ids finally uses script dbpy store ids database usage several options launch interface currently virtual real sensor servers run real sensor server needed firstly required start serial forwarder moment xm1000 motes supported driver specs information refer httpwwwadvanticsyscomshopasxm1000p24html startsfsh serial port used java jar envifacejar comm source port port servers running virtual sensors needed executed follows java sensors port port ids sensors either commands execute sensors sending 2 messages\n",
      "  (0, 132)\t0.20002962860237566\n",
      "  (0, 130)\t0.14316848481384872\n",
      "  (0, 129)\t0.12513488105630424\n",
      "  (0, 128)\t0.17879818383582893\n",
      "  (0, 126)\t0.18249362905916205\n",
      "  (0, 119)\t0.2081691919061015\n",
      "  (0, 118)\t0.17879818383582893\n",
      "  (0, 116)\t0.1659175891625334\n",
      "  (0, 111)\t0.20002962860237566\n",
      "  (0, 110)\t0.17201829425194304\n",
      "  (0, 109)\t0.20002962860237566\n",
      "  (0, 108)\t0.19063319236288787\n",
      "  (0, 106)\t0.20262390002376376\n",
      "  (0, 105)\t0.16308190682066448\n",
      "  (0, 104)\t0.13139228591773625\n",
      "  (0, 101)\t0.19285002494523487\n",
      "  (0, 100)\t0.18642765062520114\n",
      "  (0, 83)\t0.18249362905916205\n",
      "  (0, 70)\t0.14316848481384872\n",
      "  (0, 62)\t0.20262390002376376\n",
      "  (0, 61)\t0.19285002494523487\n",
      "  (0, 58)\t0.14120198596217898\n",
      "  (0, 56)\t0.1617120474248467\n",
      "  (0, 47)\t0.15289892834244784\n",
      "  (0, 46)\t0.18642765062520114\n",
      "  (0, 45)\t0.14024202631559396\n",
      "  (0, 44)\t0.13654658109226084\n",
      "  (0, 36)\t0.17201829425194304\n",
      "  (0, 27)\t0.17879818383582893\n",
      "  (0, 23)\t0.18061790636387812\n",
      "  (0, 22)\t0.14417604788163307\n",
      "  (0, 19)\t0.17531402540202123\n",
      "  (0, 10)\t0.18061790636387812\n",
      "coding open data environmental reporting bc repo ' develop collection lessons based data code environmental reporting bc released content guidelines skill focus lesson focus helping learners gain skill ' need work data code released bc enable learners transfer skills projects lesson format anything goes ' looking guidance consider study group lesson one hour handson tutorial designed led instructor workshop lesson like study group longer selfstudy curriculum tutorial designed followed independent learner content format keep simple dependencyfree possible markdown plain text text ipython notebooks knitr scripts good options contributing please place lesson folder make sure everything needed scripts pointers data code etc included clearly labeled lesson folder feel free start brainstorming lesson ideas issue tracker begin\n",
      "  (0, 140)\t0.23234942146033344\n",
      "  (0, 121)\t0.2716028578532718\n",
      "  (0, 118)\t0.25474104014553445\n",
      "  (0, 114)\t0.28868650644568256\n",
      "  (0, 91)\t0.2925469972958641\n",
      "  (0, 82)\t0.23638953335516838\n",
      "  (0, 76)\t0.23039772709824663\n",
      "  (0, 71)\t0.27803889394900727\n",
      "  (0, 70)\t0.20397795970359106\n",
      "  (0, 64)\t0.22848893061015196\n",
      "  (0, 48)\t0.28144508518888356\n",
      "  (0, 46)\t0.26561105159635\n",
      "  (0, 41)\t0.12132407486766618\n",
      "  (0, 31)\t0.26561105159635\n",
      "  (0, 26)\t0.16280447287098973\n",
      "  (0, 15)\t0.19454346431000386\n",
      "  (0, 8)\t0.24282556945090386\n",
      "pect power externality correlation tool quantifying environmental impacts electricity purchased grid license lgpl version 1200 new google colaboratory option httpscolabresearchgooglecomdrive1uwdtphlkr8tja5r0hpn9ne668kppycx new read paper open access httpsdoiorg101016jsoftx201812001 script used model water consumption water withdrawal co2 emissions nox emissions so2 emissions attributed power generation fuel mix within specific location specified time frame pectipynb file used google colaboratory software requirments running script obtaining outputs however best use google chrome browsers firefox throw network errors script attempts download results file note emissions factors used script calculated egrid excel database included repository database updated every two years recent database found httpswwwepagovenergyemissionsgenerationresourceintegrateddatabaseegrid recent database downloaded included working directory best results findemissionrates script automatically use recent database directory long contains egrid corresponding year name user inputs location location numbers correlate city state etc time frame start end datatime data pulled watttime credentials username password valid watttime api account outputs time array generation fuel type water consumption water withdrawal cos nox so2 emissions emission factors fuel type water consumption withdrawal factors fuel type instructions colaboratory notebook click link provided httpscolabresearchgooglecomdrive1uwdtphlkr8tja5r0hpn9ne668kppycx run cell provide user inputs directed results file downloaded internet browser instructions python file download electricityandenvironment zip file run powerexpy powerexipynb file using jupyter notebook file necessary dependancies python3 urllib numpy pandas note findemissionratespy findemissionratesipynb file must located folder follow command prompts input necessary information corresponding desired data output output file located directory powerexpy file named resultsxlsx cite plewe k smith pect tool computing temporal spatial variation externalities related power generation united states softwarex 9 6167 2019 doi101016jsoftx201812001\n",
      "  (0, 141)\t0.17896476665334507\n",
      "  (0, 136)\t0.14348369769492356\n",
      "  (0, 133)\t0.10748957733885225\n",
      "  (0, 131)\t0.14975922928755717\n",
      "  (0, 130)\t0.1280915965092139\n",
      "  (0, 129)\t0.11195708828191869\n",
      "  (0, 125)\t0.17896476665334507\n",
      "  (0, 124)\t0.14116262564770662\n",
      "  (0, 118)\t0.15996917792527954\n",
      "  (0, 117)\t0.16327546058297865\n",
      "  (0, 115)\t0.14975922928755717\n",
      "  (0, 106)\t0.18128583870056203\n",
      "  (0, 105)\t0.14590796175280282\n",
      "  (0, 104)\t0.1175555339157291\n",
      "  (0, 103)\t0.17673845911539987\n",
      "  (0, 98)\t0.13275571597776087\n",
      "  (0, 97)\t0.16679519541673646\n",
      "  (0, 96)\t0.13373839051619418\n",
      "  (0, 93)\t0.17459948059749789\n",
      "  (0, 92)\t0.1650069381163125\n",
      "  (0, 84)\t0.16327546058297865\n",
      "  (0, 82)\t0.1484450220481273\n",
      "  (0, 79)\t0.15390326976060692\n",
      "  (0, 78)\t0.13275571597776087\n",
      "  (0, 72)\t0.17459948059749789\n",
      "  (0, 68)\t0.17673845911539987\n",
      "  (0, 63)\t0.15248664566222586\n",
      "  (0, 61)\t0.17254123778843947\n",
      "  (0, 57)\t0.17673845911539987\n",
      "  (0, 56)\t0.14468236048146443\n",
      "  (0, 46)\t0.16679519541673646\n",
      "  (0, 44)\t0.12216703691964108\n",
      "  (0, 41)\t0.07618761589431253\n",
      "  (0, 39)\t0.18624716305376574\n",
      "  (0, 38)\t0.16864408303064662\n",
      "  (0, 36)\t0.15390326976060692\n",
      "  (0, 27)\t0.15996917792527954\n",
      "  (0, 26)\t0.10223597137254306\n",
      "  (0, 19)\t0.15685193171807305\n",
      "  (0, 16)\t0.16679519541673646\n",
      "  (0, 4)\t0.15996917792527954\n",
      "  (0, 0)\t0.17673845911539987\n",
      "previous contents repository migrated httpsgithubcomdlfmetadataassessmentdlfmetadataassessmentgithubio october 2019 site previously housed repository please see httpsdlfmetadataassessmentgithubioenvironmentalscanhttpsdlfmetadataassessmentgithubioenvironmentalscan\n",
      "  (0, 98)\t1.0\n",
      "albiorix code used configuration administration bioinformatics computer cluster albiorix department biological environmental sciences university gothenburg\n",
      "  (0, 130)\t0.5025811721072512\n",
      "  (0, 41)\t0.2989303150223935\n",
      "  (0, 18)\t0.654438910115165\n",
      "  (0, 15)\t0.4793355245870988\n",
      "pect power externality correlation tool quantifying environmental impacts electricity purchased grid license lgpl version 1200 new google colaboratory option httpscolabresearchgooglecomdrive1uwdtphlkr8tja5r0hpn9ne668kppycx new read paper open access httpsdoiorg101016jsoftx201812001 script used model water consumption water withdrawal co2 emissions nox emissions so2 emissions attributed power generation fuel mix within specific location specified time frame pectipynb file used google colaboratory software requirments running script obtaining outputs however best use google chrome browsers firefox throw network errors script attempts download results file note emissions factors used script calculated egrid excel database included repository database updated every two years recent database found httpswwwepagovenergyemissionsgenerationresourceintegrateddatabaseegrid recent database downloaded included working directory best results findemissionrates script automatically use recent database directory long contains egrid corresponding year name user inputs location location numbers correlate city state etc time frame start end datatime data pulled watttime credentials username password valid watttime api account outputs time array generation fuel type water consumption water withdrawal cos nox so2 emissions emission factors fuel type water consumption withdrawal factors fuel type instructions colaboratory notebook click link provided httpscolabresearchgooglecomdrive1uwdtphlkr8tja5r0hpn9ne668kppycx run cell provide user inputs directed results file downloaded internet browser instructions python file download electricityandenvironment zip file run powerexpy powerexipynb file using jupyter notebook file necessary dependancies python3 urllib numpy pandas note findemissionratespy findemissionratesipynb file must located folder follow command prompts input necessary information corresponding desired data output output file located directory powerexpy file named resultsxlsx cite plewe k smith pect tool computing temporal spatial variation externalities related power generation united states softwarex 9 6167 2019 doi101016jsoftx201812001\n",
      "  (0, 141)\t0.17896476665334507\n",
      "  (0, 136)\t0.14348369769492356\n",
      "  (0, 133)\t0.10748957733885225\n",
      "  (0, 131)\t0.14975922928755717\n",
      "  (0, 130)\t0.1280915965092139\n",
      "  (0, 129)\t0.11195708828191869\n",
      "  (0, 125)\t0.17896476665334507\n",
      "  (0, 124)\t0.14116262564770662\n",
      "  (0, 118)\t0.15996917792527954\n",
      "  (0, 117)\t0.16327546058297865\n",
      "  (0, 115)\t0.14975922928755717\n",
      "  (0, 106)\t0.18128583870056203\n",
      "  (0, 105)\t0.14590796175280282\n",
      "  (0, 104)\t0.1175555339157291\n",
      "  (0, 103)\t0.17673845911539987\n",
      "  (0, 98)\t0.13275571597776087\n",
      "  (0, 97)\t0.16679519541673646\n",
      "  (0, 96)\t0.13373839051619418\n",
      "  (0, 93)\t0.17459948059749789\n",
      "  (0, 92)\t0.1650069381163125\n",
      "  (0, 84)\t0.16327546058297865\n",
      "  (0, 82)\t0.1484450220481273\n",
      "  (0, 79)\t0.15390326976060692\n",
      "  (0, 78)\t0.13275571597776087\n",
      "  (0, 72)\t0.17459948059749789\n",
      "  (0, 68)\t0.17673845911539987\n",
      "  (0, 63)\t0.15248664566222586\n",
      "  (0, 61)\t0.17254123778843947\n",
      "  (0, 57)\t0.17673845911539987\n",
      "  (0, 56)\t0.14468236048146443\n",
      "  (0, 46)\t0.16679519541673646\n",
      "  (0, 44)\t0.12216703691964108\n",
      "  (0, 41)\t0.07618761589431253\n",
      "  (0, 39)\t0.18624716305376574\n",
      "  (0, 38)\t0.16864408303064662\n",
      "  (0, 36)\t0.15390326976060692\n",
      "  (0, 27)\t0.15996917792527954\n",
      "  (0, 26)\t0.10223597137254306\n",
      "  (0, 19)\t0.15685193171807305\n",
      "  (0, 16)\t0.16679519541673646\n",
      "  (0, 4)\t0.15996917792527954\n",
      "  (0, 0)\t0.17673845911539987\n",
      "waved web app visualizing environmental data httpkshskgithubiowaved installation basics client needs use waved web browser server side actions require running web server requirements server include serving static content html javascript css images well dynamic pages php setup accomplished various setups operating systems however document written tested fresh installation ubuntu 1204 lts precise pangolin necessary packages order get waved server running using apache php module including sqlite packages provide command line tools required standard deployment waved packages installed follows aptget update aptget install apache2 php5common php5sqlite libapache2modphp5 aptget install make sqlite3 acl content content needs served web server found waved git repository ' clone content documentroot apache server varwww default cd varwww git clone httpsgithubcomkshskwavedgit initial setup content brought web server initialization actions need performed includes setting directories permissions persisting project state data files actions handled makefile everything set apache server restarted ensure everything served correctly cd waved make service apache2 restart verifying server point waved server running clients able point web browsers waved folder web server however easy things web server verify functionality index page verify get index page waved get 404 error short html page displaying generic message rather 500 lines html curl sxpost localhostwaved project listing verify get listing currently existing projects json response success field true projects array empty curl sxpost localhostwavedphpgetexistingprojectdetailsphp create project verify create project command display json response success true projects array contain newly created project curl sxpost localhostwavedphpcreateprojectphp projecttestproject curl sxpost localhostwavedphpgetexistingprojectdetailsphp delete project verify delete project command display json response success true projects array empty curl sxpost localhostwavedphpdeleteprojectphp projecttestproject curl sxpost localhostwavedphpgetexistingprojectdetailsphp developer instructions download eclipse ide java developers import project file import exiting projects workspace select waved directory finish install jshint plugin help install new software work httpgithubeclipsesourcecomjshinteclipseupdates check jshint click finished\n",
      "  (0, 140)\t0.13287685780314046\n",
      "  (0, 139)\t0.13638416694809583\n",
      "  (0, 133)\t0.09788963612261531\n",
      "  (0, 129)\t0.10195815170726544\n",
      "  (0, 127)\t0.16961334737347292\n",
      "  (0, 126)\t0.14869325770846745\n",
      "  (0, 115)\t0.13638416694809583\n",
      "  (0, 113)\t0.15189864348311322\n",
      "  (0, 112)\t0.12363385704556255\n",
      "  (0, 111)\t0.16298134498415703\n",
      "  (0, 110)\t0.14015810135203738\n",
      "  (0, 105)\t0.13287685780314046\n",
      "  (0, 101)\t0.15713150429470588\n",
      "  (0, 100)\t0.15189864348311322\n",
      "  (0, 98)\t0.12089924485695293\n",
      "  (0, 92)\t0.15027009622517515\n",
      "  (0, 91)\t0.16730287304397087\n",
      "  (0, 90)\t0.10911204584929841\n",
      "  (0, 85)\t0.14716494507883007\n",
      "  (0, 83)\t0.14869325770846745\n",
      "  (0, 78)\t0.12089924485695293\n",
      "  (0, 77)\t0.16961334737347292\n",
      "  (0, 76)\t0.13176071551797244\n",
      "  (0, 73)\t0.16961334737347292\n",
      "  (0, 70)\t0.11665167994031761\n",
      "  (0, 65)\t0.15900592453728965\n",
      "  (0, 61)\t0.15713150429470588\n",
      "  (0, 60)\t0.16509512107056012\n",
      "  (0, 59)\t0.13638416694809583\n",
      "  (0, 58)\t0.11504940416750177\n",
      "  (0, 55)\t0.16730287304397087\n",
      "  (0, 54)\t0.16961334737347292\n",
      "  (0, 52)\t0.15189864348311322\n",
      "  (0, 50)\t0.14869325770846745\n",
      "  (0, 49)\t0.1376105562074236\n",
      "  (0, 46)\t0.15189864348311322\n",
      "  (0, 45)\t0.11426724246763705\n",
      "  (0, 44)\t0.11125624536174653\n",
      "  (0, 41)\t0.06938326656019085\n",
      "  (0, 38)\t0.1535824061346932\n",
      "  (0, 36)\t0.14015810135203738\n",
      "  (0, 28)\t0.141482612951082\n",
      "  (0, 26)\t0.09310523200543842\n",
      "  (0, 23)\t0.14716494507883007\n",
      "  (0, 22)\t0.11747262824228284\n",
      "  (0, 16)\t0.15189864348311322\n",
      "  (0, 14)\t0.141482612951082\n",
      "  (0, 12)\t0.15900592453728965\n",
      "  (0, 10)\t0.14716494507883007\n",
      "  (0, 5)\t0.14015810135203738\n",
      "wildlife tracker app forest service track animals environmental impact study description forest service considering proposal timber company clearcut nearby forest douglas fir proposal may approved must complete environmental impact study application developed allow rangers track wildlife sightings area setup create necessary databases launch postgres psql run following commands create database wildlifetracker c wildlifetracker create table animals id serial primary key name varchar create table endangeredanimals id serial primary key name varchar health varchar age varchar create table sightings id serial primary key animalid int location varchar rangername varchar create database wildlifetrackertest template wildlifetracker license copyright c 2017 mit license\n",
      "  (0, 113)\t0.29806644217972184\n",
      "  (0, 111)\t0.31981371608821624\n",
      "  (0, 104)\t0.21007415510532806\n",
      "  (0, 68)\t0.31583525876290025\n",
      "  (0, 63)\t0.2724967696995123\n",
      "  (0, 47)\t0.24445965730560462\n",
      "  (0, 41)\t0.13614883540880648\n",
      "  (0, 33)\t0.32829372923403305\n",
      "  (0, 30)\t0.33282750812336737\n",
      "  (0, 27)\t0.28586820863437507\n",
      "  (0, 22)\t0.23051323929414147\n",
      "  (0, 6)\t0.2887776387423603\n",
      "  (0, 5)\t0.2750283060777366\n",
      "ewatec webbased platform buit top odm observational data model sharing environmental data features setup database install postgresql sudo sh c ' echo deb httpaptpostgresqlorgpubreposapt lsbrelease cspgdg main etcaptsourceslistdpgdglist ' wget q httpswwwpostgresqlorgmediakeysaccc4cf8asc sudo aptkey add sudo aptget update sudo aptget install postgresql postgresqlcontrib install postgis sudo aptaddrepository ppaubuntugisubuntugisunstable sudo aptget update sudo aptget install postgis connect postgresql sudo su postgres psql setup virtual environment virtualenv env install gdal virtualenv gdal library must installed sudo aptget install libgdaldev install python binding gdal export cplusincludepathusrincludegdal export cincludepathusrincludegdal env pip install gdal1112 install ibfreetype6dev libxftdev matplotlib sudo aptget install libfreetype6dev libxftdev install gfortran libblasdev liblapackdev libatlasbasedev scipy numpy sudo aptget install gfortran libblasdev liblapackdev libatlasbasedev install requirements env pip install r requirementstxt setup gunicorn setup nginx\n",
      "  (0, 127)\t0.2943886727433009\n",
      "  (0, 119)\t0.2943886727433009\n",
      "  (0, 113)\t0.26364222355707845\n",
      "  (0, 101)\t0.2727246157911234\n",
      "  (0, 96)\t0.21139150059172737\n",
      "  (0, 87)\t0.28654663280325077\n",
      "  (0, 86)\t0.2793588882030852\n",
      "  (0, 72)\t0.27597794517776875\n",
      "  (0, 60)\t0.28654663280325077\n",
      "  (0, 58)\t0.1996850007222692\n",
      "  (0, 43)\t0.27597794517776875\n",
      "  (0, 41)\t0.12042476650303853\n",
      "  (0, 40)\t0.20983825141270762\n",
      "  (0, 27)\t0.25285278549808127\n",
      "  (0, 26)\t0.16159769322390505\n",
      "  (0, 1)\t0.23463730829275922\n",
      "modulefile search prefix directory installed software generate environmental modules modulefile installation git clone httpsgithubcomuconnhpcmodulefile pip install user upgrade editable modulefile make sure localbin similar path per pep 370 usage modulefile pathtomyapp10 pathtomymodulefiledirapp10 tests virtual environments tests orchestrated using tox install tox using pip pip install user tox run tests using tox debug failing tests tox pdb add dependencies get import errors need recreate tox environment tox recreate edit files ' likely going create lots linter errors caught tox unit tests text editor ' interactive error reporting use emacs configure python development installing elpy\n",
      "  (0, 133)\t0.13629058903944705\n",
      "  (0, 131)\t0.18988607155232784\n",
      "  (0, 129)\t0.14195513543589677\n",
      "  (0, 128)\t0.2028316979874475\n",
      "  (0, 121)\t0.21625753276798093\n",
      "  (0, 115)\t0.18988607155232784\n",
      "  (0, 107)\t0.22691700970783663\n",
      "  (0, 104)\t0.14905364184021536\n",
      "  (0, 96)\t0.16957257133107573\n",
      "  (0, 87)\t0.22985999529164775\n",
      "  (0, 86)\t0.22409418006014908\n",
      "  (0, 76)\t0.18344889450513263\n",
      "  (0, 71)\t0.22138207857677844\n",
      "  (0, 70)\t0.16241276197607524\n",
      "  (0, 60)\t0.22985999529164775\n",
      "  (0, 59)\t0.18988607155232784\n",
      "  (0, 58)\t0.16018193226283398\n",
      "  (0, 50)\t0.20702387384397908\n",
      "  (0, 49)\t0.19159355889384855\n",
      "  (0, 45)\t0.159092937727548\n",
      "  (0, 41)\t0.09660150597683863\n",
      "  (0, 40)\t0.1683265966515499\n",
      "  (0, 36)\t0.195140476035609\n",
      "  (0, 34)\t0.20921928756472258\n",
      "  (0, 29)\t0.21625753276798093\n",
      "  (0, 22)\t0.16355575864127508\n",
      "  (0, 14)\t0.19698457795664642\n",
      "  (0, 1)\t0.18821973251540744\n",
      "envmon environmental monitoring system\n",
      "  (0, 74)\t0.9165417805146188\n",
      "  (0, 41)\t0.3999389510551486\n",
      "environmental features recognition lower limb prostheses toward predictive walking present robust environmental features recognition system efrs lower limb prosthesis assist control prosthesis predicting locomotion modes amputees estimating environmental features following steps depth sensor inertial measurement unit imu combined stabilize point cloud environments subsequently 2d point cloud extracted origin 3d point cloud classified neural network environmental features including slope road width height stair also estimated via 2d point cloud finally efrs evaluated classifying recognizing five kinds common environments simulation indoor experiments outdoor experiments six healthy subjects three transfemoral amputees databases five healthy subjects three amputees used validate without training classification accuracy five kinds common environments reach 993 985 amputees indoor outdoor experiments respectively locomotion modes predicted least 06 switch actual locomotion modes estimation errors indoor outdoor environments features lower 5 10 respectively overall process efrs takes less 0023 promising results demonstrate robustness potential application presented efrs help control lower limb prostheses repository includes 2d binary image dataset cnn model based keras test train model directly running file classificationpy run python classificationpy uploaded environmental classification algorithm think useful part want upload image preprocessing environmental parameter estimation part please leave message issue send email directly contact related works codes please view homepage httpssitesgooglecomviewkuangenzhang information please contact kuangen zhang kuangenzhangalumniubcca citation find work useful research please consider citing articlezhangenvironmental2019 &#9; title environmental features recognition lower limb prostheses toward predictive walking &#9; volume 27 &#9; issn 15344320 &#9; number 3 &#9; journal ieee transactions neural systems rehabilitation engineering &#9; author zhang k xiong c zhang w liu h lai rong fu c &#9; month mar &#9; year 2019 license mit license\n",
      "  (0, 140)\t0.18341687020859956\n",
      "  (0, 137)\t0.20742566607347412\n",
      "  (0, 130)\t0.1610204093697545\n",
      "  (0, 123)\t0.21689682616970282\n",
      "  (0, 108)\t0.21440357292072246\n",
      "  (0, 105)\t0.18341687020859956\n",
      "  (0, 104)\t0.14777581598359707\n",
      "  (0, 103)\t0.2221730372147733\n",
      "  (0, 102)\t0.22788942253837888\n",
      "  (0, 98)\t0.1668835451775813\n",
      "  (0, 96)\t0.16811883820825554\n",
      "  (0, 88)\t0.21440357292072246\n",
      "  (0, 80)\t0.20109283682961013\n",
      "  (0, 72)\t0.2194841863769987\n",
      "  (0, 63)\t0.19168675211403213\n",
      "  (0, 56)\t0.1818762006891842\n",
      "  (0, 55)\t0.23093689795174077\n",
      "  (0, 53)\t0.2221730372147733\n",
      "  (0, 52)\t0.20967363495215074\n",
      "  (0, 47)\t0.17196415863385756\n",
      "  (0, 44)\t0.15357280908646895\n",
      "  (0, 43)\t0.2194841863769987\n",
      "  (0, 41)\t0.09577334840482976\n",
      "  (0, 20)\t0.22788942253837888\n",
      "  (0, 8)\t0.19168675211403213\n",
      "  (0, 6)\t0.2031394636887742\n",
      "environmentalsound image data gotten es50 environmental sound dataset kaggle method extraction librosa mel spectrograms img h128 x w157 size 16000 processing ximg pickled downloaded resulting files labels stored ypickle\n",
      "  (0, 53)\t0.7028233446776355\n",
      "  (0, 45)\t0.49896088590187415\n",
      "  (0, 41)\t0.3029699098535935\n",
      "  (0, 26)\t0.40655456489807557\n",
      "appretrofithellocharts\n",
      "\n",
      "environmentalgame game developed ' environment sciences ' class universidade federal rio grande brazil\n",
      "  (0, 40)\t0.45969029601747263\n",
      "  (0, 33)\t0.6361289297145982\n",
      "  (0, 13)\t0.6196973588192289\n",
      "environmentaleventsdetector installation requirement register earth engine api token use application need google earth engine api key generate one please follow instructions order run server must earth engine api token ask access official websiteearth engine requirement run server create token never used python earth engine api must first download required packages get token sudo aptget update sudo aptget install pythondev pythonpip pip install user googleapipythonclient pycrypto earthengineapi packages installed authenticate localbinearthengine authenticate token stored configearthenginecredentials deploy application deploy application execute following command installsh run application run application execute following command runsh go httplocalhost9000indexhtml\n",
      "  (0, 131)\t0.19476734752484756\n",
      "  (0, 130)\t0.16658779970361026\n",
      "  (0, 129)\t0.1456042824539711\n",
      "  (0, 127)\t0.2422212380804744\n",
      "  (0, 119)\t0.2422212380804744\n",
      "  (0, 110)\t0.20015682351782113\n",
      "  (0, 104)\t0.15288526547950215\n",
      "  (0, 100)\t0.21692324370091767\n",
      "  (0, 96)\t0.17393166155433448\n",
      "  (0, 87)\t0.2357688545507189\n",
      "  (0, 86)\t0.22985482131080381\n",
      "  (0, 83)\t0.2123456999941087\n",
      "  (0, 76)\t0.1881646942139409\n",
      "  (0, 61)\t0.22439618167493117\n",
      "  (0, 60)\t0.2357688545507189\n",
      "  (0, 59)\t0.19476734752484756\n",
      "  (0, 58)\t0.1642996235226212\n",
      "  (0, 47)\t0.17790993655291187\n",
      "  (0, 38)\t0.219327789571953\n",
      "  (0, 22)\t0.16776017863004125\n",
      "  (0, 16)\t0.21692324370091767\n",
      "  (0, 6)\t0.21016314901532482\n",
      "  (0, 4)\t0.20804575863843452\n",
      "  (0, 0)\t0.22985482131080381\n",
      "environmental ' working python virtual environment lazy open new terminal windowtab hotkeys type conda activate myenvironment created two shell commands window tab supported environments macos developed tested tool macos mojave tool available conda environments linux developed tested tool ubuntu 1804 gnome 3282 tool available conda virtualenv environments install install macos clone repo set permission run commands copy files run commands git clone httpsgithubcomthebarbershopenvironmentalgit sudo chmod x environmentalmacconda sudo cp environmentalmacconda usrlocalbin may delete downloaded files ' want keep around rm r environmental script emulates commandn commandt open new windowterminal fix line 8 script use different combination keys install linux use tool need install three extra tools xdotool xclip wmctrl sudo apt install xdotool xclip wmctrl clone repo set permission run commands copy files run commands git clone httpsgithubcomthebarbershopenvironmentalgit sudo chmod x environmentallinuxconda sudo cp environmentallinuxconda usrlocalbin use virtualenv instead conda replace path accordingly last two commands may delete downloaded files ' want keep around rm r environmental script emulates controlshiftn controlshiftt open new windowterminal fix line 10 window line 11 tab use different combination keys use window open new terminal window environment directory myenvironment currentdirectory window tab open new terminal tab environment directory myenvironment currentdirectory tab license software unlicenced whatever want liable consequences read license note ' plan import tool os environment manager ones using may someday whenever feel like feel free fork modify fit system would deeply appreciate send pull request addition\n",
      "  (0, 141)\t0.19701912748756628\n",
      "  (0, 137)\t0.18165320238727048\n",
      "  (0, 133)\t0.118333363249811\n",
      "  (0, 129)\t0.12325156656157808\n",
      "  (0, 126)\t0.1797470495770778\n",
      "  (0, 125)\t0.19701912748756628\n",
      "  (0, 119)\t0.20503618811720756\n",
      "  (0, 115)\t0.16486727102322293\n",
      "  (0, 112)\t0.1494541270683895\n",
      "  (0, 106)\t0.1995743544080933\n",
      "  (0, 104)\t0.12941479575292172\n",
      "  (0, 99)\t0.1995743544080933\n",
      "  (0, 97)\t0.18362186303283345\n",
      "  (0, 96)\t0.14723021466080005\n",
      "  (0, 82)\t0.16342048365556272\n",
      "  (0, 79)\t0.16942937144969905\n",
      "  (0, 78)\t0.14614840574507423\n",
      "  (0, 76)\t0.1592782364816771\n",
      "  (0, 65)\t0.1922134617353651\n",
      "  (0, 64)\t0.15795864994644845\n",
      "  (0, 63)\t0.16786983518420878\n",
      "  (0, 58)\t0.13907685710440637\n",
      "  (0, 50)\t0.1797470495770778\n",
      "  (0, 49)\t0.16634978512234497\n",
      "  (0, 48)\t0.19456822512925698\n",
      "  (0, 45)\t0.13813134511543293\n",
      "  (0, 41)\t0.08387359081651242\n",
      "  (0, 40)\t0.14614840574507423\n",
      "  (0, 36)\t0.16942937144969905\n",
      "  (0, 35)\t0.18165320238727048\n",
      "  (0, 33)\t0.20224318357717774\n",
      "  (0, 23)\t0.1778995570260214\n",
      "  (0, 21)\t0.1922134617353651\n",
      "  (0, 14)\t0.17103050021456656\n",
      "  (0, 7)\t0.16486727102322293\n",
      "environmentaldatapredict environmental data predict\n",
      "  (0, 41)\t0.5975408006708108\n",
      "  (0, 26)\t0.8018385071407373\n",
      "trafficsignrecognize nhan dien bien bao cam trong anh moi truong co su dung deep learning yeu cau python python 369 packages khuyen khich su dung anaconda 3 tao mot environment moi ten opencv e cai tat ca packages nhu hinh numpy 1172 matplotlib 311 opencv 342 django 225 scikitimage 0150 tensorflow 200 tensorflowmkl 1150 keras 224 pillow 621 run project activate bien moi truong anaconda 3 source ospathanaconda3anaconda3binactivate activate moi truong chua cac packages thiet conda activate opencv di chuyen en thu muc chua project cd parentprojectpathtrafficsignrecognizemaster chay server python managepy runserver sau khi chay server thanh cong truy cap ia chi localhost8000 e thao tac ho tro cac bien bao theo bo bien bao chuan viet nam 101 uong cam 102 cam nguoc chieu 122 dung lai 127 toc toi cho phep tham khao source code train file modelh5 tai githubcomquangkhoiuit98trainmodeltrafficsignrecognize chuc nang chinh trang chu nhan dien bien bao tu anh moi truong trang tra cuu bien bao tra cuu bien bao tu du lieu cua ung dung\n",
      "  (0, 116)\t0.3650375722285553\n",
      "  (0, 110)\t0.3784598174887545\n",
      "  (0, 104)\t0.28907797722389644\n",
      "  (0, 96)\t0.32887284945101236\n",
      "  (0, 90)\t0.2946281703276642\n",
      "  (0, 44)\t0.30041801300042087\n",
      "  (0, 40)\t0.3264563782022546\n",
      "  (0, 15)\t0.30041801300042087\n",
      "  (0, 10)\t0.3973799424935417\n",
      "scripteddechackathon environmental awareness project project project simulates series scenarios series questions determine choices made point system built built project system combinations csshtmljavascriptjquerybootstrap put together became project challenges ran idea going run run difficulties came platform going working cloud9sublime etc learned learned\n",
      "  (0, 141)\t0.6965809238910057\n",
      "  (0, 104)\t0.4575590154129841\n",
      "  (0, 90)\t0.466343983802136\n",
      "  (0, 41)\t0.29654350887687053\n",
      "env1005report final report waste aruba written collectively 2017 environmental science class university aruba faculty hotel management tourism studies\n",
      "  (0, 41)\t0.3916961787938874\n",
      "  (0, 13)\t0.9200946166119368\n",
      "ee509 applied environmental statistics course boston university earth environment 509\n",
      "  (0, 41)\t0.49774958827313204\n",
      "  (0, 40)\t0.8673207868914059\n",
      "environmental environmental proof column politecnico di torino\n",
      "  (0, 41)\t1.0\n",
      "newproject strojka environmentallab\n",
      "\n",
      "yapec yet another parser environmental configuration ' enough npm modules getting config values enviroment already travis status installation sane use npm npm install yapec otherwise clone repo via git git clone httpsgithubcomsandfoxnodeyapecgit usage var yapec require ' yapec ' var config yapec ' prefix ' configspec processenv opts yapec takes spec form object nested heart ' content leaf every path must string dictates parse corresponding envvar string path converted uppercase dot seperators exchanged underscores optional prefix may supplied first arg act mask searching env object optional options object may supplied far option ' ignoremissing ' accepts bool false default true rather throwing exception env var missing instead returns null value yes realise probably clearest way describe brain failing point time examples examples also found examples folder inside project var yapec require ' yapec ' represents something could expect processenv return var env apppath ' optappy ' appname ' super server ' appserverenabled ' true ' appserverprocs ' 8 ' appservermagic ' 2e2 ' var configspec app path ' string ' name ' string ' server enabled ' bool ' procs ' int ' magic ' float ' var config yapecconfigspec env consolelogconfig outputs following app path ' optappy ' name ' super server ' server enabled true procs 8 magic 200 optionally prefix supplied first arguement acts mask looking enviroment variables example var yapec require ' yapec ' var env fallover ' true ' myappfallover ' false ' var spec fallover ' bool ' var config yapec ' myapp ' spec env consolelogconfig falloverfalse caveats due way modules works certain combinations env var strings forbidden example following would fail could resolved object sane way app could string object time appsuper app appdbnamemegadb appdbport8000 helpers yapec also comes helpers creating configs processenv style objects creating env var strings config object checkout examples folder pretty self explanatory todo document better yapecgetspecprefix processenv yapecgetenvstringsprefix config stability index based nodejs stability index stability 2 unstable testing code tested mocha run npm test usual tests ' bad could complete travis tests upgrades fixes ideas ideas bug fixes suggestions etc gladly excepted feel free raise pull requests issues license mit license copyright c 2013 james edward butler aka sandfox permission hereby granted free charge person obtaining copy software associated documentation files ' software ' deal software without restriction including without limitation rights use copy modify merge publish distribute sublicense andor sell copies software permit persons software furnished subject following conditions copyright notice permission notice shall included copies substantial portions software software provided ' ' without warranty kind express implied including limited warranties merchantability fitness particular purpose noninfringement event shall authors copyright holders liable claim damages liability whether action contract tort otherwise arising connection software use dealings software\n",
      "  (0, 138)\t0.19928484150264944\n",
      "  (0, 135)\t0.19413720106599713\n",
      "  (0, 134)\t0.20203699095575384\n",
      "  (0, 129)\t0.12144868604584737\n",
      "  (0, 128)\t0.17353118739510168\n",
      "  (0, 124)\t0.15313023647529606\n",
      "  (0, 123)\t0.18716909254877742\n",
      "  (0, 115)\t0.1624556506365485\n",
      "  (0, 110)\t0.16695101826441477\n",
      "  (0, 104)\t0.12752176169080584\n",
      "  (0, 93)\t0.18940183090022514\n",
      "  (0, 90)\t0.12997013361146736\n",
      "  (0, 81)\t0.19928484150264944\n",
      "  (0, 63)\t0.16541429434626473\n",
      "  (0, 59)\t0.1624556506365485\n",
      "  (0, 58)\t0.1370424898110923\n",
      "  (0, 55)\t0.19928484150264944\n",
      "  (0, 50)\t0.17711777302925646\n",
      "  (0, 49)\t0.16391647904145853\n",
      "  (0, 48)\t0.1917221496443617\n",
      "  (0, 47)\t0.14839486630952403\n",
      "  (0, 46)\t0.1809359070781992\n",
      "  (0, 45)\t0.13611080843855533\n",
      "  (0, 42)\t0.1569483705242388\n",
      "  (0, 41)\t0.08264671746401907\n",
      "  (0, 37)\t0.17899604330734534\n",
      "  (0, 28)\t0.16852872628150695\n",
      "  (0, 24)\t0.19928484150264944\n",
      "  (0, 21)\t0.18940183090022514\n",
      "  (0, 18)\t0.1809359070781992\n",
      "  (0, 17)\t0.1829415413332667\n",
      "  (0, 15)\t0.13252422280440054\n",
      "  (0, 14)\t0.16852872628150695\n",
      "  (0, 8)\t0.16541429434626473\n",
      "  (0, 5)\t0.16695101826441477\n",
      "barque v172 environmental dna metabarcoding analysis developed eric normandeau louis bernatchez ' laboratory please see licence information end file description barque edna metabarcoding analysis pipeline annotates reads instead operational taxonomic unit otus using highquality barcoding databases barque also produce otus annotated using database annotated otus used database find read counts per otu per sample effectively annotating reads otus previously found use cases approach implemented barque especially useful species management projects monitoring invasive species confirming presence specific species characterizing metacommunities varied environments improving species distribution knowledge cryptic taxa following loss species medium longterm monitoring since barque depends use highquality barcoding databases especially useful coi amplicons used combination barcode life database bold 12s amplicons mitofish database although also use database example silva database 18s gene custom database installation use barque need local copy repository different releases found recommended always use latest release even developpment version either download archive latest release link get latest commit recommended following git command git clone httpsgithubcomenormandeaubarque dependencies run barque also need following programs installed computer barque work gnu linux osx bash 4 python 35 use miniconda3 install python r 3 ubuntumint sudo aptget install rbasecore java ubuntumint sudo aptget install defaultjre gnu parallel flash read merger v1211 vsearch v2142 v2142 required barque work older versions vsearch preparation install dependencies download copy barque repository see installation edit 02infoprimerscsv provide information describing primers get prepare databases see formatting database section deposit fastagz file 03databases folder give name matches information 02infoprimerscsv file make copy 02infobarqueconfigsh modify parameters run launch barque example barque 02infobarqueconfigsh overview barque steps analyses following steps performed filter trim raw reads trimmomatic merge pairedend reads flash split merged reads amplicon python script look chimeras optional vsearch vsearchglobal merge unique reads python script find species associated unique read vsearch summarize results python script tables phylum genus species counts per sample including multiple hits number retained reads per sample analysis step figure frequent nonannotated sequences blast ncbi ntnr species counts nonannotated sequences sequence groups cases multiple hits running pipeline new project get new copy barque source listed installation section case need modify primer config files running test dataset want test barque jump straight test dataset section end file read readme better understand program ' outputs preparing samples copy pairedend sample files 04data folder need one pair files per sample sequences files must contain sequences primer used pcr depending format received sequences sequencing facility may proceed demultiplexing use barque important file names must follow format sampleidr1001fastqgz sampleidr2001fastqgz notes sample name sampleid must contain underscore followed underscore star string text contain space characters example use dashed separate parts sample names eg popasample001anythingr1001fastqgz formatting database need put database gzipcompressed fasta format fastagz 03databases folder augmented version mitofish 12s database already available barque preformatted bold database downloaded want use newer version bold database need download animal bins page put downloaded fasta files 03databasesboldbins need create folder run commands format bold database format bin individually 10 minutes note speciestoremovetxt file optional ls 1 03databasesboldbinsfasgz parallel 01scriptsutilformatbolddatabasepy preparedfastagz speciestoremovetxt concatenate resulting formatted bins one file 10 seconds gunzip c 03databasesboldbinspreparedfastagz 03databasesboldfasta databases get database format gzipcompressed fasta format fastagz name lines 3 informations separated underscore ex phylumgenusspecies ex familygenusspecies ex mammalrattusnorvegicus configuration file make copy file named 02infobarqueconfigsh modify parameters needed launching barque launch barque executable name configuration file argument like barque 02infomyconfigfilesh results pipeline finished running result files found 12results folder run recomended make copy folder name current date ex cp r 12results 12resultsprojectname20200727someadditionalinfo taxa count tables named primer names primergenustablecsv primerphylumtablecsv primerspeciestablecsv sequence dropout report figure sequencedropoutcsv listing many sequences present sample every analysis step depending library sequencing quality well biological diversity found sample site less sequences lost analysis steps figure sequencedropoutfigurepng shows many sequences retained sample step pipeline frequent nonannotated sequences mostfrequentnonannotatedsequencesfasta sequences frequent samples annotated pipeline fasta file used query ncbi ntnr database using online portal found see species may missed use blastn default parameters ncbi blastn search finished download results text file use following command need adjust input output file names generate report frequently found species nonannotated sequences fasta files sequences multiple hit groups 12results01multihits contains fasta file database sample sequences help understand sequences cannot unambiguously assigned one species example sometimes two different species identical reads database times sample sequences distance sequences two species database summarize species found nonannotated sequences 01scripts10reportspeciesfornonannotatedsequencespy 12resultsncbialignmenttxt 12resultsmostfrequentnonannotatedsequencesspeciesncbicsv 97 sort u k 23 cut c 2 perl pe ' ' missingspecies97percenttxt first result file contain one line per identified taxon number sequences taxon sorted decreasing order species interest found file good idea download representative sequences ncbi add database rerun analysis modify percentage value 97 missingspecies97percenttxt file list sequence identifiers ncbi download online database add database needed one way automatically make file first column one ncbi sequence identifier per line load page httpswwwncbinlmnihgovsitesbatchentrez need rename sequences follow database name format described formatting database section add current database log files parameters barque run three files written 99logfiles folder contain timestamp time run exact barque config file used exact primer file used full log run lather rinse repeat pipeline run normal find unexpected species found proportion reads identified either sequenced species absent database sequences exact distance two sequences database cases need remove unwanted species database download additional sequences nonannotated species ncbi add database improved simply run last part pipeline using new database skipdataprep1 config file avoid repeating initial data preparation steps barque may need repeat step satisfied completeness results note provide justifications publications decide remove species database test dataset test dataset available sister repository github composed 10 mitofish12s metabarcoding samples 10000 forward 10000 reverse sequences download repository move data barquetestdataset04data barque ' 04data folder git barque ' dependencies installed following commands download barque repository test data put appropriate folder git clone httpsgithubcomenormandeaubarque git clone httpsgithubcomenormandeaubarquetestdataset cp barquetestdataset04data barque04data run analysis move barque folder launch cd barque barque 02infobarqueconfigsh analysis test dataset takes 25 seconds linux thinkpad laptop 4 corei7 cpus 2012 70 seconds laptop using one cpu license cc sharealike barque eric normandeau licensed creative commons attributionsharealike 40 international licensebased work httpsgithubcomenormandeaubarque\n",
      "  (0, 140)\t0.10371058776329842\n",
      "  (0, 138)\t0.13058014453942507\n",
      "  (0, 137)\t0.11728603656363698\n",
      "  (0, 136)\t0.10198743402092722\n",
      "  (0, 134)\t0.1323834732355301\n",
      "  (0, 133)\t0.07640300851524126\n",
      "  (0, 130)\t0.09104681198971412\n",
      "  (0, 129)\t0.0795784910603909\n",
      "  (0, 124)\t0.10033762859998893\n",
      "  (0, 123)\t0.12264137590217794\n",
      "  (0, 119)\t0.1323834732355301\n",
      "  (0, 117)\t0.11605531172502105\n",
      "  (0, 116)\t0.10551391645940346\n",
      "  (0, 107)\t0.12720718537611556\n",
      "  (0, 106)\t0.12885699079705387\n",
      "  (0, 105)\t0.10371058776329842\n",
      "  (0, 104)\t0.08355783584917653\n",
      "  (0, 103)\t0.12562473805433516\n",
      "  (0, 100)\t0.11855712015270929\n",
      "  (0, 98)\t0.09436204280830895\n",
      "  (0, 97)\t0.11855712015270929\n",
      "  (0, 96)\t0.09506052253989215\n",
      "  (0, 92)\t0.11728603656363698\n",
      "  (0, 91)\t0.13058014453942507\n",
      "  (0, 90)\t0.08516211621930193\n",
      "  :\t:\n",
      "  (0, 45)\t0.0891857549488944\n",
      "  (0, 44)\t0.08683566717011705\n",
      "  (0, 42)\t0.10283943702767717\n",
      "  (0, 41)\t0.054153744112128865\n",
      "  (0, 39)\t0.1323834732355301\n",
      "  (0, 38)\t0.11987129943972975\n",
      "  (0, 35)\t0.11728603656363698\n",
      "  (0, 33)\t0.13058014453942507\n",
      "  (0, 30)\t0.1323834732355301\n",
      "  (0, 29)\t0.12123159958443559\n",
      "  (0, 28)\t0.11042739262530317\n",
      "  (0, 27)\t0.11370522394624369\n",
      "  (0, 26)\t0.07266877389159687\n",
      "  (0, 25)\t0.11987129943972975\n",
      "  (0, 22)\t0.09168756337658267\n",
      "  (0, 21)\t0.12410436372630147\n",
      "  (0, 19)\t0.11148950225108344\n",
      "  (0, 18)\t0.11855712015270929\n",
      "  (0, 17)\t0.11987129943972975\n",
      "  (0, 16)\t0.11855712015270929\n",
      "  (0, 14)\t0.11042739262530317\n",
      "  (0, 10)\t0.11486246141439294\n",
      "  (0, 7)\t0.10644804783651754\n",
      "  (0, 3)\t0.12410436372630147\n",
      "  (0, 1)\t0.10551391645940346\n",
      "utils tools utilties libraries environmental meteorology use arpaesimc contact copyright information mautils copyright c 2020 arpaesimc urpsimarpaeit mautils licensed terms gnu general public license version 2 please see file license details contact informations arpaesimc formerly arpasim agenzia regionale prevenzione ambiente e energia dell ' emiliaromagna arpae servizio idrometeoclima simc address viale silvani 6 40122 bologna italy tel 39 051 6497511 fax 39 051 6497501 email urpsimarpaeit website httpsarpaeitsim\n",
      "  (0, 136)\t0.33133072893280857\n",
      "  (0, 129)\t0.25852988364235147\n",
      "  (0, 126)\t0.3770336159500325\n",
      "  (0, 95)\t0.42422103163730396\n",
      "  (0, 63)\t0.35212022181926045\n",
      "  (0, 56)\t0.33409866578688696\n",
      "  (0, 44)\t0.28210656711823867\n",
      "  (0, 41)\t0.17593147316002375\n",
      "  (0, 32)\t0.39385003305171146\n",
      "uavenvironmentalmonitoring pm25 wiki\n",
      "\n",
      "readme contributing lessons repository interesting teaching specific topic please sing google spreadsheet adding lesson please use standard naming format nnlessonname nn consecutive lesson number lessons 19 use twodigit format ie 08 place data files used workshop data directory also add link lesson index page using header four level title bulleted list links item eg rmarkdown workshop jeff oliver knitr lesson iris analysis reproducible report knitr full lesson\n",
      "  (0, 133)\t0.20901310798792894\n",
      "  (0, 130)\t0.2490736623619551\n",
      "  (0, 129)\t0.21770016742474085\n",
      "  (0, 117)\t0.3174885632588101\n",
      "  (0, 98)\t0.25814302639038395\n",
      "  (0, 85)\t0.3142253232943915\n",
      "  (0, 80)\t0.3110595081701127\n",
      "  (0, 66)\t0.3110595081701127\n",
      "  (0, 45)\t0.2439824320059286\n",
      "  (0, 36)\t0.29926437091442537\n",
      "  (0, 26)\t0.1987974895219578\n",
      "  (0, 3)\t0.33950808065528115\n",
      "  (0, 1)\t0.28865082728724234\n",
      "newproject strojka environmentallab\n",
      "\n",
      "grow features monitor enviroment optionally control temperature wemo switches edit script control devices optionally report soil moisture perplant basis 8 email alerts enviroment exceeds alarm values requires ecowitt gw1000 wifi gateway linux apache mysql python3 optional wemo switches automation ip webcam ecowitt soil moisture sensors see full grow list amazon associate earn qualifying purchases installation prepare linux host working mysql python3 place files web root make sure py files execute cgi create database called grow create tables mysql create database grow mysql grow schemamysql cp myconfigsample myconfigpy edit cofiguration configure ecowitt gw1000 post data ecowittpy use ws view app go weather services customized enter server address ecowittpy path upload interval 60 copy growservice etcsystemdsystem edit make growcontrolpy run boot restart crash systemctl daemonreload place systemctl enable grow service grow start service grow status wemo automation install ouimeaux test command line wemo list make sure device names match growcontrolpy webcam setup edit getimagebash fetch image webcam python script add create cronjob run script every minute pathtogetimagebash run script hand test creates output expected fetch outjpg via webserver optionally speciy location xy coordinates 00 top left potssoil sensors config file\n",
      "  (0, 141)\t0.18800701324685826\n",
      "  (0, 139)\t0.15732585765913815\n",
      "  (0, 135)\t0.18800701324685826\n",
      "  (0, 129)\t0.11761375254644257\n",
      "  (0, 123)\t0.1812589337283062\n",
      "  (0, 122)\t0.19044535813053748\n",
      "  (0, 121)\t0.17917534203447838\n",
      "  (0, 118)\t0.168051666904598\n",
      "  (0, 113)\t0.17522257090396148\n",
      "  (0, 111)\t0.18800701324685826\n",
      "  (0, 110)\t0.1616792769755856\n",
      "  (0, 109)\t0.18800701324685826\n",
      "  (0, 106)\t0.19044535813053748\n",
      "  (0, 104)\t0.12349506126502623\n",
      "  (0, 96)\t0.1404955613754695\n",
      "  (0, 84)\t0.1715250004497865\n",
      "  (0, 71)\t0.18342116985055615\n",
      "  (0, 70)\t0.13456346146817874\n",
      "  (0, 68)\t0.18566822087668855\n",
      "  (0, 66)\t0.168051666904598\n",
      "  (0, 65)\t0.18342116985055615\n",
      "  (0, 59)\t0.15732585765913815\n",
      "  (0, 58)\t0.13271515740323075\n",
      "  (0, 53)\t0.18566822087668855\n",
      "  (0, 45)\t0.13181289533709092\n",
      "  (0, 44)\t0.12833956179190245\n",
      "  (0, 43)\t0.18342116985055615\n",
      "  (0, 27)\t0.168051666904598\n",
      "  (0, 26)\t0.10740147339377909\n",
      "  (0, 22)\t0.13551046579126594\n",
      "  (0, 21)\t0.18342116985055615\n",
      "  (0, 20)\t0.19044535813053748\n",
      "  (0, 17)\t0.17716487409928078\n",
      "  (0, 16)\t0.17522257090396148\n",
      "  (0, 5)\t0.1616792769755856\n",
      "  (0, 1)\t0.15594524971885454\n",
      "reactwebpack simplified environmental build processes react webpack requirements node v400 getting started npm install required packages npm start start development deployment npm run build\n",
      "  (0, 118)\t0.38560125238581067\n",
      "  (0, 104)\t0.2833643436235003\n",
      "  (0, 101)\t0.4159058528793396\n",
      "  (0, 100)\t0.40205517762097487\n",
      "  (0, 58)\t0.3045202219524404\n",
      "  (0, 41)\t0.18364812825917176\n",
      "  (0, 34)\t0.39774463315500513\n",
      "  (0, 9)\t0.38952571778449013\n",
      "environmentalscience first website developed using htmlcssjavascript created following mozilla foundation getting started web tutorial\n",
      "  (0, 139)\t0.4463798571619924\n",
      "  (0, 133)\t0.3203888161496191\n",
      "  (0, 47)\t0.40774499974158385\n",
      "  (0, 33)\t0.547575530527529\n",
      "  (0, 23)\t0.481664907544151\n",
      "reproducible research ecology evolution behaviour environmental studies aims reproduce figures tables statistical methods numerical modelling selected published papers examples learn collaborate create science make reproductions publically available learn make research reproducible paper selection likely spend lot time single paper selection important please make suggestions raw data must available reproduction appear feasible couple months eight meetings probably good focus papers mostly analyses empirical data rather lots numerical modelling please email authors paper start reproduction telling ' reproduction guidelines reproductions r markdown generously commented use google r style guide data manipulations allowed r open source software required permitted alteration original data files allowed outcome fully reproduced paper would one reproduced raw datasets ideally available online online report reproduction code outstanding issues research ideas parts paper decided reproduce weekly meetings information remote participation individuals might like contribute reproduction outside meeting time may able attend meetings anyone read contribute reproduction github look instructions know git github please look resources get started particularly motivated folk cannot attend weekly meetings may arrange electronic attendance weekly meetings eg via skype communication please use rreebes github repository issues wiki much communication possible email list gaining 1 ects students uzh gain 1 ects actively participating reproduction two papers attending least 20 meetings please make attendance form bring meeting course bio633 see vorlesungsverzeichnis entry\n",
      "  (0, 129)\t0.15608172897983935\n",
      "  (0, 124)\t0.1967977822265875\n",
      "  (0, 118)\t0.2230163918803309\n",
      "  (0, 116)\t0.20695032405075517\n",
      "  (0, 115)\t0.2087824879745928\n",
      "  (0, 102)\t0.2527343965278326\n",
      "  (0, 100)\t0.23253268627904192\n",
      "  (0, 98)\t0.18507753282747566\n",
      "  (0, 97)\t0.23253268627904192\n",
      "  (0, 82)\t0.20695032405075517\n",
      "  (0, 70)\t0.17857518588374124\n",
      "  (0, 69)\t0.2463947991082169\n",
      "  (0, 66)\t0.2230163918803309\n",
      "  (0, 64)\t0.2000336375330791\n",
      "  (0, 61)\t0.2405433646731465\n",
      "  (0, 56)\t0.201704718507568\n",
      "  (0, 51)\t0.24341280421670813\n",
      "  (0, 49)\t0.21065989505576244\n",
      "  (0, 45)\t0.17492499100330797\n",
      "  (0, 41)\t0.1062147560116271\n",
      "  (0, 26)\t0.14252931565688992\n",
      "  (0, 22)\t0.17983192728428848\n",
      "  (0, 15)\t0.17031563288557744\n",
      "  (0, 7)\t0.2087824879745928\n",
      "environmentalday\n",
      "\n",
      "environmental extractors repository contains extractors process data originating gmp 343 co2 sensor thies clima environmental sensors maricopa lightningirrigationweather data environmental logger json 2 netcdf extractor extractor processes environmental logger stream data json files netcdf input evaluation triggered whenever file added dataset checks whether file environmentloggerjson file output dataset containing json file get corresponding nc netcdf file uamacuiuc energy farm dat parser extractors extractor extracts metadata meteorological dat files netcdf well creating entries clowder geostreams database input evaluation triggered whenever 24 dat files added dataset output netcdf metadata generated added dataset datapoints record dat files added geostream\n",
      "  (0, 109)\t0.3286137001766604\n",
      "  (0, 108)\t0.31317699861046316\n",
      "  (0, 98)\t0.24376500393262396\n",
      "  (0, 88)\t0.31317699861046316\n",
      "  (0, 84)\t0.2998051194856136\n",
      "  (0, 57)\t0.32452577174551583\n",
      "  (0, 45)\t0.23039312480777446\n",
      "  (0, 44)\t0.22432215453639717\n",
      "  (0, 41)\t0.13989510245423623\n",
      "  (0, 27)\t0.29373414921423635\n",
      "  (0, 26)\t0.18772488837963427\n",
      "  (0, 24)\t0.3373270490957697\n",
      "  (0, 19)\t0.288010286189868\n",
      "environmentaldata pdf download project python based pdf extraction tool pdf download project web scraping project used download pdf html webpage website httppariveshnicin environment clearance dashboard download installation 1 clone repository git clone httpsgithubcomsaurabhkayasthenvironmentaldatagit download zip file &#9; extract files &#9; 2 download dependencies see 3 change directorycd environmetaldatasrc folder run python3 &#9; workingpdfpy terminal make sure using python version &#9; 36x greater installation guide python 36x httpswwwpythonorgdownloadsreleasepython360 installing dependencies method 1 using requirementstxt pip recommended pip install r requirementstxt method 2 using pip recommended beautifulsoup4 httpspypiorgprojectbeautifulsoup4 pip install beautifulsoup4 allows us search extract content html webpage requests httpspypiorgprojectrequests pip install requests requests module allows send http requests using python http request returns response object response data content encoding status etc pyinstaller httpspypiorgprojectpyinstaller pip install pyinstaller allows us build executable file build executable file run pyinstaller onefile workingpdfpy documentation httpspyinstallerreadthedocsioenstableusagehtml\n",
      "  (0, 139)\t0.16397627134870751\n",
      "  (0, 136)\t0.15710498684633348\n",
      "  (0, 133)\t0.11769384888479768\n",
      "  (0, 130)\t0.14025167254536042\n",
      "  (0, 125)\t0.19595436807610003\n",
      "  (0, 121)\t0.1867493681051391\n",
      "  (0, 107)\t0.19595436807610003\n",
      "  (0, 104)\t0.1287153934993532\n",
      "  (0, 99)\t0.19849578566782353\n",
      "  (0, 98)\t0.14535856928364904\n",
      "  (0, 96)\t0.14643453173035884\n",
      "  (0, 90)\t0.13118668272106915\n",
      "  (0, 87)\t0.19849578566782353\n",
      "  (0, 86)\t0.19351671124062841\n",
      "  (0, 81)\t0.20115019156231725\n",
      "  (0, 73)\t0.20392810174116402\n",
      "  (0, 71)\t0.19117467380140601\n",
      "  (0, 70)\t0.14025167254536042\n",
      "  (0, 59)\t0.16397627134870751\n",
      "  (0, 58)\t0.1383252377342089\n",
      "  (0, 50)\t0.1787756344400751\n",
      "  (0, 49)\t0.16545077342960673\n",
      "  (0, 46)\t0.18262950706563166\n",
      "  (0, 45)\t0.13738483561858508\n",
      "  (0, 44)\t0.13376467875203635\n",
      "  (0, 40)\t0.14535856928364904\n",
      "  (0, 38)\t0.18465391449957796\n",
      "  (0, 37)\t0.18067148574213393\n",
      "  (0, 29)\t0.1867493681051391\n",
      "  (0, 26)\t0.111941504127223\n",
      "  (0, 14)\t0.17010619232084326\n",
      "  (0, 11)\t0.18465391449957796\n",
      "  (0, 9)\t0.17693812637685213\n",
      "  (0, 8)\t0.16696260861594092\n",
      "  (0, 2)\t0.19849578566782353\n",
      "mitemp2bt support xiaomi mi temp 2 ble environmental sensor based ha mitempbt component mitemp library ratcashdev installation install three ways download repository extract customcomponentsmitemp2bt add custom repository hacs home assistant community store hacs home assistant community store coming soon configurartion config ' samme mitempbt component execpt platform field example sensor platform mitemp2bt mac ' xxxxxxxxxxxx ' name example forceupdate true timeout 60 median 1 monitoredconditions temperature humidity battery\n",
      "  (0, 122)\t0.34422555607455824\n",
      "  (0, 120)\t0.33152949910376217\n",
      "  (0, 108)\t0.32385526406158055\n",
      "  (0, 98)\t0.2520765575627898\n",
      "  (0, 59)\t0.28436282915598093\n",
      "  (0, 58)\t0.23987956075745548\n",
      "  (0, 42)\t0.2747228705115475\n",
      "  (0, 41)\t0.14466504739254782\n",
      "  (0, 38)\t0.32022139002150496\n",
      "  (0, 17)\t0.32022139002150496\n",
      "  (0, 8)\t0.2895416474516997\n",
      "  (0, 1)\t0.28186741240951796\n",
      "greening postindustrial city applying keyword extractor methods monitor fastchanging environmental narrative worcester massachusetts population 200000 second largest city boston massachusetts usa important american industrial revolution factories dominated landscape mid20th century city slid physically mentally postindustrial decline first glance worcester might present alltoofamiliar global story gentrification loss city identity community even small survey historic record local public discourse confirm view complicated local story surface answer questions literary geographer sarah luria teams computer scientist ricardo campos developer keyword extractor yake discover create helpful survey image stories told neighborhood time believe interdisciplinary work play crucial role showing artificial intelligence ai track fastdeveloping story urban revitalization environmental cleanup survey curated small corpus 26 englishlanguage texts described canal districtgreen island time majority texts 20182019 examples 1862 1917 1980s 1990s provide historic range corpus includes descriptions canal district industrial revolution altered dramatically building canal railroad peak industrialization identity irish working class neighborhood postindustrial decline stages revitalization majority texts come local major newspaper worcester telegram gazette corpus includes articles new york times boston globe national public radio also included worcesterborn poet mary fells 1984 poem prophecy historian roy rosenzweigs acclaimed history worcesters working class eight hours 1985 description one given dataset details give details text sorted date filename 1 1862lincoln history worcester archiveorg landscape description source william lincoln history worcester lincoln william history worcester massachusetts earliest settlement september 1836 various notices relating history worcester county worcester md phillips co 1862 url httpsarchiveorgdetailshistoryofworcest1836lincpagen6 publication date 1862 description worcesters landscape industrial revolution tokens 256 filename 2 1879abijah perkins marvin history worcester archiveorg railroad descriptionn source abijah perikins marvin history worcester county massachusetts embracing comprehensive history country first settlement present time boston jewett co 1879 pp 8283 url httpsarchiveorgdetailshistoryofworcest03marvpage82 publication date 1879 description description beginning blackstone canal worcester railroad tokens 638 filename 3 1917washburn industrial history worcester archiveorg canal source charles g washburn industrial worcester worcester davis press 1917 p 23 url httpsarchiveorgdetailsindustrialworces00washpagen6 publication date 1917 description description creation blackstone canal importance tokens 199 filename 4 1917washburn industrial history worcester archiveorg entrepreneurial spirit city source charles g washburn industrial worcester worcester davis press 1917 p 31 url httpsarchiveorgdetailsindustrialworces00washpage60 publication date 1917 description introduction steampower worcester industries tokens 72 filename 5 1917washburn industrial history importance steam power source charles g washburn industrial worcester worcester davis press 1917 p 300 url httpsarchiveorgdetailsindustrialworces00washpage60 publication date 1917 description entrepreneurial spirit city tokens 150 filename 6 1983259worcester shedding smokestack image new york times source worcester shedding smokestack image new york times sept 25 1983 publication date 1983259 description tokens 911 filename 7 1984mary fell prophecy poem source mary fell prophecy persistence memory 1984 url httpcapaconncolledufellpersistencehtml publication date 1984 description poem collection worcester tokens 328 filename 8 1985roy rosenzweig eight hours history recreation industrial labor source roy rosenzweig eight hours cambridge uk cambridge 1985 publication date 1985 description history recreation worcesters industrial labor force tokens 287 filename 9 19891012a new look old area new york times lafayette placegreen island source worcester mass new focus old area new york times publication date 19891012 description building new senior affordable housing green island tokens 450 filename 10 19971118bureau urges liability relief brownfields wtg source bronislaus b kush bureau urges liability relief brownfields worcester telegram gazette publication date 19971118 description tokens 585 filename 11 1998167green island businesses say city help killing wtg source bronislaus b kush green island businesses say city help killing worcester telegram gazette publication date 1998167 description tokens 597 filename 12 1999121vacant industrial sites use neighborhood wtg source winston w wiley vacant industrial sites use neighborhood worcester telegram gazette publication date 19991201 description tokens 436 filename 13 2000296green island revitalization plan dropped wtg source lisa eckelbecker green island revitalization plan dropped worcester telegram gazette publication date 2000296 description tokens 446 filename 14 2007259canal district shapes old buildings new life green street wtg source shaun sutner canal district shapes old buildings new life green street worcester telegram gazette publication date 20072509 description tokens 645 filename 15 2011238life green island hope city times local alternative newspaper source maureen schwab life green island hope city times local alternative newspaper publication date 20112308 description tokens 1149 filename 16 2018817woosox ball park long history boston globe source tim logan new home woosox long history boston globe publication date 2018817 description tokens 632 filename 17 20181011time talk gentrification worcester worcester mag source bill shaner time talk gentrification worcester worcester magazine publication date 20181011 description tokens 4165 filename 18 20181023worcester new town national public radio source aaron schachter worcester newit town national public radio wgbh publication date 20181023 description tokens 1184 filename 19 2018worcester city reclaimed vitality magazine source bernard whitmore mayor manager city reclaimed vitality magazine publication date 201811 description tokens 2077 filename 20 2019227worcester organizers hear nashville buffalo tips woosox cba push worcester mag source bill shaner worcester organizers hear nashville buffalo tips woosox cba push worcester magazine publication date 20190227 description tokens 540 filename 212019410a totally cool place live masslive source aviva luttrell totally cool place live masslivecom publication date 20190410 description tokens 497 filename 22 201961new shine old building former walker shoe factory converted studios wtg source scott oconnell new shine old building former walker shoe factory converted studios worcester telegram gazette publication date 20190601 description tokens 468 filename 23 2019620construction woosox regulation killing canal district dreams worcester business journal source renee diaz construction woosox regulation killing canal district dreams worcester business journal publication date 20190620 description tokens 739 filename 24 2019624worcester gets brownfield funds wtg source worcester gets brownfield funds worcester telegram gazette publication date 20190624 description tokens 517 filename 25 2019624worcester pledges 3m green island wtg source kim ring worcester pledges 3m green island worcester telegram gazette publication date 20190624 description tokens 490 filename 26 201976an away game businesses property owners near ballpark site make way development wtg source away game businesses property owners near ballpark site make way development worcester telegram gazette publication date 20190706 description tokens 1322\n",
      "  (0, 141)\t0.2521931927786693\n",
      "  (0, 140)\t0.20561027410240545\n",
      "  (0, 138)\t0.2588802155124245\n",
      "  (0, 129)\t0.15776745376206527\n",
      "  (0, 124)\t0.19892325136865033\n",
      "  (0, 116)\t0.20918544338357026\n",
      "  (0, 95)\t0.2588802155124245\n",
      "  (0, 92)\t0.23252412937117836\n",
      "  (0, 78)\t0.18707642011402545\n",
      "  (0, 70)\t0.18050384606903244\n",
      "  (0, 69)\t0.24905592941336588\n",
      "  (0, 67)\t0.24905592941336588\n",
      "  (0, 53)\t0.24905592941336588\n",
      "  (0, 52)\t0.2350441020257805\n",
      "  (0, 41)\t0.1073619040322004\n",
      "  (0, 34)\t0.23252412937117836\n",
      "  (0, 32)\t0.2403463615240445\n",
      "  (0, 30)\t0.2624553847935893\n",
      "  (0, 22)\t0.1817741606157615\n",
      "  (0, 13)\t0.2521931927786693\n",
      "gemet contents gemet project name prerequisites system packages debian based systems rhel based systems product directory install dependencies build production build staging configuration data import commands documentation docs contents development hints requirements configure deploy running unit tests sentry settings contacts resources hardware software copyright license project name project name gemet general multilingual environmental thesaurus httpwwweioneteuropaeugemet prerequisites system packages packages installed superuser root debian based systems install setting environment aptget install pythonsetuptools pythondev libmysqlclientdev libldap2dev pythonvirtualenv mysqlserver git rhel based systems install python27 puias httpsgistgithubcomnico49616638 run commands curl httpsrawgithubcompypapipmastercontribgetpippy python27 pip27 install virtualenv yum install mysqlserver mysql git mysqldevel product directory create product directory mkdir p varlocalgemet mkdir varlocalgemetlogs create new user adduser edw change product directory ' owner chown edwedw varlocalgemet r install dependencies use virtualenv isolated environments following commands run unprivileged user product directory clone repository git clone httpsgithubcomeeagemet origin gemet cd gemet 21 create activate virtual environment virtualenv nositepackages sandbox echo ' ' sandboxgitignore source sandboxbinactivate 22 make sure setuptools 08 installed pip install u setuptools install dependencies pip install r requirementsdeptxt create local configuration file cd gemet cp localsettingspyexample localsettingspy follow instructions localsettingspy adapt needs set mysql database replace user password mysql credentials dbname name database mysql uuser ppassword e ' create database dbname character set utf8 collate utf8generalci ' database charset must utf8 update local configuration file database credentials database name default section databases dict create initial database structure managepy migrate load fixtures data database managepy loaddata gemetthesaurusfixturesdatajson generate eionet static templates managepy fetchtemplates import data see data import build production setup production environment using unprivileged user cd varlocalgemet source sandboxbinactivate change localsettingspy file setting debug mode debug false allowedhosts ' localhost ' add allowed hosts list needed configure supervisord set wsgi server port cp gemetsupervisordconfexample supervisordconf supervisorctl reload 1devnull binsupervisord build staging setup staging environment using unprivileged user cd varlocalgemet source sandboxbinactivate change localsettingspy file setting debug mode debug false allowedhosts ' localhost ' add allowed hosts list needed configure supervisord set wsgi server port different one production example 8010 cp gemetsupervisordconfexample supervisordconf supervisorctl reload 1devnull binsupervisord configuration details configurable settings found settingspy data import 1 considering dump old database gemetsql import separate database mysql uuser ppassword e ' create database dbname character set utf8 collate utf8generalci ' mysql uuser ppassword dbname gemetsql 2 update import section databases dict local configuration file name database used import gemetold previous example run management command data import managepy import fix romanian characters managepy fixromanian insert data enables search work properly managepy insertdata create reversed relations concepts managepy fixrelations import new terms spreadsheet managepy importspreadsheet spreadsheetname commands 1 romanian terms definitions etc written wrong diacritical marks cedillas instead commas following custom management command fixes characters prints number objects changed managepy fixromanian check consistency excel file xlsx extension containing new terms custom command assures old terms used file defined database new terms used broader narrow relations etc terms also defined file error containing cell term printed respect rules run command providing valid excel file managepy checkspreadsheet filenamexlsx documentation documentation created using sphinx source directories three sections documentation found docs directory order get html output run following command inside one documentation directories api newapi overview make html static html files served via web server apache nginx etc docs contents api old version api user guide kept reference newapi current documentation gemet api duplicated file published web services page overview quick overview technical solution development hints requirements packages installed superuserroot aptget install libxml2dev libxslt1dev use requirementsdevtxt instead requirementsdeptxt pip install r requirementsdevtxt configure deploy copy fabfileenviniexample fabfileenvini configure staging production settings run fab staging deploy fab production deploy running unit tests 0 running tests make sure configured test database parameters cd gemet cp testsettingspyexample testsettingspy parameters values match ones used ' default ' database entry localsettingspy gemet web application managepy test api python apitestsmainpy two optional parameters exist public runs tests production website get calls api methods get requests running tests coverage measurement add localsettingspy testrunner noseargs localsettingsexample run managepy test sentry settings sentry used track errors realtime create account project sentry install proper version raven used sentry pip install r requirementsdeptxt configure local settings project ' dsn contacts project owner sren roug sorenroug eaaeuropaeu people involved project iulia chiriac iuliachiriac eaudewebro andrei melis andreimelis eaudewebro diana boiangiu dianaboiangiu eaudewebro cornel nitu cornelnitu eaudewebro alex eftimie alexeftimie eaudewebro mihai tabara mihaitabara eaudewebro mihai zamfir mihaizamfir eaudewebro resources hardware minimum requirements 2048mb ram 2 cpu 18ghz faster 4gb hard disk space recommended 4096mb ram 4 cpu 24ghz faster 8gb hard disk space software recent linux version apache2 mysql server python 27 copyright license project free software redistribute andor modify terms eupl v11 details licensetxt\n",
      "  (0, 140)\t0.10990336599706356\n",
      "  (0, 139)\t0.11280428559281402\n",
      "  (0, 136)\t0.10807731910540713\n",
      "  (0, 135)\t0.13480299507853163\n",
      "  (0, 133)\t0.08096519351806118\n",
      "  (0, 131)\t0.11280428559281402\n",
      "  (0, 130)\t0.09648340942594176\n",
      "  (0, 129)\t0.08433029083265159\n",
      "  (0, 127)\t0.1402883700184345\n",
      "  (0, 123)\t0.12996455147784264\n",
      "  (0, 121)\t0.1284705944386978\n",
      "  (0, 116)\t0.11181437525827206\n",
      "  (0, 115)\t0.11280428559281402\n",
      "  (0, 113)\t0.1256364161915598\n",
      "  (0, 112)\t0.10225841628974733\n",
      "  (0, 110)\t0.11592573278010217\n",
      "  (0, 107)\t0.13480299507853163\n",
      "  (0, 105)\t0.10990336599706356\n",
      "  (0, 104)\t0.08854725070321538\n",
      "  (0, 101)\t0.12996455147784264\n",
      "  (0, 98)\t0.09999659967853536\n",
      "  (0, 96)\t0.10073678711009174\n",
      "  (0, 95)\t0.138377360757226\n",
      "  (0, 90)\t0.09024732604250675\n",
      "  (0, 87)\t0.13655131386556957\n",
      "  :\t:\n",
      "  (0, 40)\t0.09999659967853536\n",
      "  (0, 37)\t0.12428943351683515\n",
      "  (0, 36)\t0.11592573278010217\n",
      "  (0, 35)\t0.12428943351683515\n",
      "  (0, 34)\t0.12428943351683515\n",
      "  (0, 32)\t0.1284705944386978\n",
      "  (0, 29)\t0.1284705944386978\n",
      "  (0, 28)\t0.11702124546337782\n",
      "  (0, 27)\t0.12049480301532384\n",
      "  (0, 26)\t0.07700797985827579\n",
      "  (0, 25)\t0.1270290678993759\n",
      "  (0, 23)\t0.12172114157680029\n",
      "  (0, 22)\t0.09716242143139739\n",
      "  (0, 21)\t0.13151489739479824\n",
      "  (0, 18)\t0.1256364161915598\n",
      "  (0, 16)\t0.1256364161915598\n",
      "  (0, 14)\t0.11702124546337782\n",
      "  (0, 12)\t0.13151489739479824\n",
      "  (0, 11)\t0.1270290678993759\n",
      "  (0, 10)\t0.12172114157680029\n",
      "  (0, 9)\t0.12172114157680029\n",
      "  (0, 8)\t0.11485867821437254\n",
      "  (0, 6)\t0.12172114157680029\n",
      "  (0, 4)\t0.12049480301532384\n",
      "  (0, 1)\t0.11181437525827206\n",
      "openstudioprojectspolimieetbs repository includes files presentations group projects simulation commercial buildings openstudio energyplus context energy environmental technologies building systems politecnico di milano order insert personal contact information members group regular projects fill following form regular project group information form instead would like ask bonus project fill following form bonus project group information form important note one members group fill form insert personal contact information members\n",
      "  (0, 98)\t0.2984549850099373\n",
      "  (0, 91)\t0.413008174910748\n",
      "  (0, 90)\t0.26935680240920157\n",
      "  (0, 83)\t0.3670679999115577\n",
      "  (0, 79)\t0.3459978934321515\n",
      "  (0, 64)\t0.32257311505805547\n",
      "  (0, 56)\t0.32526789080728913\n",
      "  (0, 47)\t0.30754116790065117\n",
      "  (0, 45)\t0.2820830533570051\n",
      "  (0, 41)\t0.17128131615431952\n",
      "telecoupling telecoupling new avenue research understand todays hyperconnected world achieve sustainable future telecoupling enables natural social scientists across various disciplines understand generate information managing humans nature sustainably coexist telecoupling framework gains distinction enabling researchers practitioners dive deeply systemic complexities even systems far understand forces affecting sustainability across local global scales essential build comprehensive set spatially explicit tools describing quantifying multiple reciprocal socioeconomic environmental interactions distances telecoupling toolbox telecoupling toolbox designed michigan state universitys center systems integration sustainability first suite geospatial software tools apps developed map identify five major interrelated components telecoupling framework systems flows agents causes effects modular design toolbox allows integration existing tools software assess synergies tradeoffs associated policies localtoglobal interventions use telecoupling toolbox innovative free opensource see license details toolbox provide researchers practitioners useful platform address globally important issues land use land cover change species invasion migration flows ecosystem services trade goods products ' toolbox arcgis toolbox arcgis toolbox large collection mapping analysis tools use within esri ' arcgis desktop version 1031 later systematically study telecoupling test current version arcgis toolbox using data downloading sample data look inside arcgis toolbox project folder code images documentation detailed instructions installation use geoapp geoapp offers dynamic interactive online geoenabled platform along large collection mapping analysis tools systematically study telecoupling check test brand new geoapp beta using data downloading sample data help introductory tutorial need time familiarize app widgets tools look inside geoapp project folder source code images linked geoapp sample data arcgis toolbox data download unzip sample data folder use arcgis toolbox geoapp data repository contains tables spatial data necessary run set telecoupling mapping analysis tools developed information dataset provided please feel free contact us geoapp data download unzip sample data folder use arcgis toolbox geoapp data repository contains tables spatial data necessary run set telecoupling mapping analysis tools developed information dataset provided please feel free contact us credits contacts 2018 michigan state university francesco tonini ftoninimsuedu paul mccord mccordpamsuedu jianguo ' jack ' liu liujimsuedu license telecoupling toolbox software property michigan state university msu made available solely educational noncommercial use see license details toolbox depends r statistical computing software 2018 r foundation statistical computing r free software comes absolutely warranty see copyrights file details toolbox depends esri software 2018 esri see software license agreement details toolbox depends invest natural capital project software 2018 natcap project see software license agreement details\n",
      "  (0, 136)\t0.13817456365861816\n",
      "  (0, 133)\t0.10351228526479962\n",
      "  (0, 129)\t0.10781449091683688\n",
      "  (0, 126)\t0.1572339985980942\n",
      "  (0, 124)\t0.1359393751145766\n",
      "  (0, 123)\t0.16615692672784377\n",
      "  (0, 116)\t0.14295231080819593\n",
      "  (0, 115)\t0.1442178902069881\n",
      "  (0, 112)\t0.13073521963916168\n",
      "  (0, 104)\t0.11320578480628629\n",
      "  (0, 102)\t0.17457796294876937\n",
      "  (0, 98)\t0.12784353500156234\n",
      "  (0, 93)\t0.16813901115007426\n",
      "  (0, 92)\t0.15890140860004293\n",
      "  (0, 90)\t0.11537929512406406\n",
      "  (0, 78)\t0.12784353500156234\n",
      "  (0, 76)\t0.13932887394030785\n",
      "  (0, 75)\t0.17691252522847142\n",
      "  (0, 69)\t0.17019884392644075\n",
      "  (0, 67)\t0.17019884392644075\n",
      "  (0, 63)\t0.14684438766655666\n",
      "  (0, 61)\t0.16615692672784377\n",
      "  (0, 59)\t0.1442178902069881\n",
      "  (0, 56)\t0.13932887394030785\n",
      "  (0, 52)\t0.16062349742382545\n",
      "  (0, 48)\t0.17019884392644075\n",
      "  (0, 46)\t0.16062349742382545\n",
      "  (0, 44)\t0.11764665457485576\n",
      "  (0, 41)\t0.07336854814523983\n",
      "  (0, 38)\t0.16240397313925511\n",
      "  (0, 37)\t0.15890140860004293\n",
      "  (0, 33)\t0.17691252522847142\n",
      "  (0, 32)\t0.16424693429171355\n",
      "  (0, 31)\t0.16062349742382545\n",
      "  (0, 26)\t0.09845307140503046\n",
      "  (0, 25)\t0.16240397313925511\n",
      "  (0, 19)\t0.15104815092121018\n",
      "  (0, 15)\t0.11764665457485576\n",
      "  (0, 12)\t0.16813901115007426\n",
      "  (0, 11)\t0.16240397313925511\n",
      "  (0, 9)\t0.1556179017449538\n",
      "  (0, 7)\t0.1442178902069881\n",
      "  (0, 5)\t0.14820859433119302\n",
      "  (0, 3)\t0.16813901115007426\n",
      "  (0, 2)\t0.17457796294876937\n",
      "ears environmental audio recognition system ears proof concept implementation convolutional neural network live environmental audio processing recognition lowpower soc devices time developed tested raspberry pi 3 model b ears features background thread audio capture classification bokeh server based dashboard providing live visualization audio streaming device browser caveats ears quite taxing cpu proper cooling solution heatsink advisable nevertheless using bokeh app much work fine even without one live audio stream get choppy outofsync especially using muteunmute button actual production deployments would profit servernode architecture soc devices pushing predictions status updates audio feeds central server handling end user interaction material browsing visualization may implemented future versions promises quick look installation ears developed tested raspberry pi 3 model b device recreate environment used developing demo step 1 prepare raspberry pi device get spare raspberry pi 3 model b blank sd card install raspbian jessie lite distribution tested version april 2017 download raspbian jessie lite image raspberrypiorg use etcher flash sd card see raspberry pi docs details boot device new card attach input display devices configuration login using default credentials user pi password raspberry setup wifi access see wifi config raspberry pi use sudo raspiconfig enable ssh recreate ssh host keys sudo rm etcsshsshhost sudo dpkgreconfigure opensshserver step 2 install python 36 using berry conda install conda armv7l optconda wget httprepocontinuumiominicondaminiconda3latestlinuxarmv7lsh chmod x miniconda3latestlinuxarmv7lsh sudo miniconda3latestlinuxarmv7lsh add export pathoptcondabinpath end homepibashrc reload source homepibashrc install python required packages conda config add channels rpi conda create n ears python36 source activate ears conda install cython numpy pandas scikitlearn cffi h5py make sure portaudio headers available installing pyaudio complain later sudo aptget install portaudio19dev step 3 download ears install requirements download ears source code unpack homepiears install required packages issuing pip install r homepiearsrequirementstxt plug zoom h1 microphone usb port audio device ' one used initial testing switch audio interface mode 441 khz16 bit verify ' listed python sounddevice update allowwebsocketorigin option inside homepiearsrunsh file ip address raspberry pi device finally run app chmod x homepiearsrunsh cd homepiears runsh point web browser httpraspberrypiip5006 training new models time ears comes preloaded rudimentary model trained esc50 dataset convnet consisting 3 layers 3x3 square filters ' recognition capabilities limited actual live scenarios want train model different dataset download source code workstationserver gpu card put audio files wav earsdatasetaudio replace earsdatasetdatasetcsv file new csv filenamecategory run python trainpy result following files generated server file description modelh5 weights learned model modeljson serialized architecture model keras 200 modellabelsjson dataset labels upload new model files raspberry pi device restart app want train completely different model look trainpy case probably know either way photos development field license mit karol j piczak\n",
      "  (0, 140)\t0.12349687971068282\n",
      "  (0, 139)\t0.12675660260557878\n",
      "  (0, 138)\t0.15549271053785102\n",
      "  (0, 137)\t0.1396623031613755\n",
      "  (0, 136)\t0.1214449762837124\n",
      "  (0, 133)\t0.09097945885405652\n",
      "  (0, 131)\t0.12675660260557878\n",
      "  (0, 130)\t0.1084170616600628\n",
      "  (0, 129)\t0.0947607717784106\n",
      "  (0, 127)\t0.1576400849946422\n",
      "  (0, 124)\t0.1194804148439425\n",
      "  (0, 121)\t0.14436061538078537\n",
      "  (0, 119)\t0.1576400849946422\n",
      "  (0, 116)\t0.12564425416747402\n",
      "  (0, 113)\t0.14117588880858206\n",
      "  (0, 110)\t0.13026412927971243\n",
      "  (0, 104)\t0.0994993107772408\n",
      "  (0, 101)\t0.14603935407165614\n",
      "  (0, 100)\t0.14117588880858206\n",
      "  (0, 96)\t0.11319652284815424\n",
      "  (0, 87)\t0.1534408071108806\n",
      "  (0, 86)\t0.14959189315936486\n",
      "  (0, 78)\t0.1123647845536172\n",
      "  (0, 72)\t0.14778145615815028\n",
      "  (0, 71)\t0.14778145615815028\n",
      "  :\t:\n",
      "  (0, 53)\t0.14959189315936486\n",
      "  (0, 47)\t0.11578562533098212\n",
      "  (0, 45)\t0.10620094523008566\n",
      "  (0, 44)\t0.10340249895777633\n",
      "  (0, 43)\t0.14778145615815028\n",
      "  (0, 41)\t0.06448539697569232\n",
      "  (0, 40)\t0.1123647845536172\n",
      "  (0, 39)\t0.1576400849946422\n",
      "  (0, 38)\t0.14274079211139482\n",
      "  (0, 35)\t0.1396623031613755\n",
      "  (0, 34)\t0.1396623031613755\n",
      "  (0, 33)\t0.15549271053785102\n",
      "  (0, 32)\t0.14436061538078537\n",
      "  (0, 30)\t0.1576400849946422\n",
      "  (0, 28)\t0.13149514160440898\n",
      "  (0, 22)\t0.10918005798141392\n",
      "  (0, 18)\t0.14117588880858206\n",
      "  (0, 17)\t0.14274079211139482\n",
      "  (0, 15)\t0.10340249895777633\n",
      "  (0, 10)\t0.13677634932453966\n",
      "  (0, 8)\t0.12906509494483892\n",
      "  (0, 7)\t0.12675660260557878\n",
      "  (0, 5)\t0.13026412927971243\n",
      "  (0, 1)\t0.12564425416747402\n",
      "  (0, 0)\t0.14959189315936486\n",
      "project idea info page actual environmental problems face\n",
      "  (0, 90)\t0.556976924981095\n",
      "  (0, 85)\t0.7512230014294572\n",
      "  (0, 41)\t0.3541760962599275\n",
      "environmental council httpsvinaymeldrumgithubioenvironmentalcouncil\n",
      "  (0, 41)\t1.0\n",
      "waved web app visualizing environmental data httpkshskgithubiowaved installation basics client needs use waved web browser server side actions require running web server requirements server include serving static content html javascript css images well dynamic pages php setup accomplished various setups operating systems however document written tested fresh installation ubuntu 1204 lts precise pangolin necessary packages order get waved server running using apache php module including sqlite packages provide command line tools required standard deployment waved packages installed follows aptget update aptget install apache2 php5common php5sqlite libapache2modphp5 aptget install make sqlite3 acl content content needs served web server found waved git repository ' clone content documentroot apache server varwww default cd varwww git clone httpsgithubcomkshskwavedgit initial setup content brought web server initialization actions need performed includes setting directories permissions persisting project state data files actions handled makefile everything set apache server restarted ensure everything served correctly cd waved make service apache2 restart verifying server point waved server running clients able point web browsers waved folder web server however easy things web server verify functionality index page verify get index page waved get 404 error short html page displaying generic message rather 500 lines html curl sxpost localhostwaved project listing verify get listing currently existing projects json response success field true projects array empty curl sxpost localhostwavedphpgetexistingprojectdetailsphp create project verify create project command display json response success true projects array contain newly created project curl sxpost localhostwavedphpcreateprojectphp projecttestproject curl sxpost localhostwavedphpgetexistingprojectdetailsphp delete project verify delete project command display json response success true projects array empty curl sxpost localhostwavedphpdeleteprojectphp projecttestproject curl sxpost localhostwavedphpgetexistingprojectdetailsphp developer instructions download eclipse ide java developers import project file import exiting projects workspace select waved directory finish install jshint plugin help install new software work httpgithubeclipsesourcecomjshinteclipseupdates check jshint click finished\n",
      "  (0, 140)\t0.13287685780314046\n",
      "  (0, 139)\t0.13638416694809583\n",
      "  (0, 133)\t0.09788963612261531\n",
      "  (0, 129)\t0.10195815170726544\n",
      "  (0, 127)\t0.16961334737347292\n",
      "  (0, 126)\t0.14869325770846745\n",
      "  (0, 115)\t0.13638416694809583\n",
      "  (0, 113)\t0.15189864348311322\n",
      "  (0, 112)\t0.12363385704556255\n",
      "  (0, 111)\t0.16298134498415703\n",
      "  (0, 110)\t0.14015810135203738\n",
      "  (0, 105)\t0.13287685780314046\n",
      "  (0, 101)\t0.15713150429470588\n",
      "  (0, 100)\t0.15189864348311322\n",
      "  (0, 98)\t0.12089924485695293\n",
      "  (0, 92)\t0.15027009622517515\n",
      "  (0, 91)\t0.16730287304397087\n",
      "  (0, 90)\t0.10911204584929841\n",
      "  (0, 85)\t0.14716494507883007\n",
      "  (0, 83)\t0.14869325770846745\n",
      "  (0, 78)\t0.12089924485695293\n",
      "  (0, 77)\t0.16961334737347292\n",
      "  (0, 76)\t0.13176071551797244\n",
      "  (0, 73)\t0.16961334737347292\n",
      "  (0, 70)\t0.11665167994031761\n",
      "  (0, 65)\t0.15900592453728965\n",
      "  (0, 61)\t0.15713150429470588\n",
      "  (0, 60)\t0.16509512107056012\n",
      "  (0, 59)\t0.13638416694809583\n",
      "  (0, 58)\t0.11504940416750177\n",
      "  (0, 55)\t0.16730287304397087\n",
      "  (0, 54)\t0.16961334737347292\n",
      "  (0, 52)\t0.15189864348311322\n",
      "  (0, 50)\t0.14869325770846745\n",
      "  (0, 49)\t0.1376105562074236\n",
      "  (0, 46)\t0.15189864348311322\n",
      "  (0, 45)\t0.11426724246763705\n",
      "  (0, 44)\t0.11125624536174653\n",
      "  (0, 41)\t0.06938326656019085\n",
      "  (0, 38)\t0.1535824061346932\n",
      "  (0, 36)\t0.14015810135203738\n",
      "  (0, 28)\t0.141482612951082\n",
      "  (0, 26)\t0.09310523200543842\n",
      "  (0, 23)\t0.14716494507883007\n",
      "  (0, 22)\t0.11747262824228284\n",
      "  (0, 16)\t0.15189864348311322\n",
      "  (0, 14)\t0.141482612951082\n",
      "  (0, 12)\t0.15900592453728965\n",
      "  (0, 10)\t0.14716494507883007\n",
      "  (0, 5)\t0.14015810135203738\n",
      "cz manager cz manager django admin app observation data model 2 odm2 odm2 created national science foundation grant ear1224638 support development application comes nsf grant ear1331841 luquillo czo odm2 found httpsgithubcomodm2 django models exist odm2 tables forms odm2core number additional odm2 tables graphing measurement result values via highcharts implemented data logger files imported long data logger file columns results properly setup odm2 tools used conjunction cz manager extensive testing done using cz manager odm2pythonapi wofpy developed using postgresql version odm2 data model additional modifications may needed make work mssql another database example postgresql database named odm2adminexamplepostgresqldb provided custom postgresql format backup restored empty database extrasqlsql file contains extra views used efficiently exporting data emails primary installation see docker folder dockerhub installation instructions see httpodm2githubioczmanager local installation instructions\n",
      "  (0, 140)\t0.17675403440645257\n",
      "  (0, 136)\t0.17381726215942003\n",
      "  (0, 135)\t0.2167993037705529\n",
      "  (0, 133)\t0.13021370611341276\n",
      "  (0, 130)\t0.1551711516258784\n",
      "  (0, 126)\t0.19779315693894148\n",
      "  (0, 120)\t0.21151116244885837\n",
      "  (0, 113)\t0.2020569909644049\n",
      "  (0, 103)\t0.21410233758423886\n",
      "  (0, 93)\t0.21151116244885837\n",
      "  (0, 80)\t0.1937879005319848\n",
      "  (0, 72)\t0.21151116244885837\n",
      "  (0, 70)\t0.1551711516258784\n",
      "  (0, 67)\t0.21410233758423886\n",
      "  (0, 61)\t0.20901779117618238\n",
      "  (0, 59)\t0.18141948971244684\n",
      "  (0, 46)\t0.2020569909644049\n",
      "  (0, 45)\t0.15199935068134815\n",
      "  (0, 44)\t0.14799409427439145\n",
      "  (0, 42)\t0.17526933153842297\n",
      "  (0, 34)\t0.19989068222696788\n",
      "  (0, 33)\t0.22254784066404595\n",
      "  (0, 27)\t0.1937879005319848\n",
      "  (0, 26)\t0.1238494471753009\n",
      "  (0, 23)\t0.195760181238064\n",
      "  (0, 19)\t0.19001164434457096\n",
      "  (0, 6)\t0.195760181238064\n",
      "  (0, 5)\t0.18643961242237908\n",
      "envizo envizo app increase visibility environmental issues community nyc liveversion motivation care environment wanted create app encourage users change habits increasing visibility believe users see impact empowered act engage communities features interactive visualization environmental issue personal impact prediction component join community subscribe greennyc suggested goals upload photo testament improved habits ex reusable grocery bag reach target goal personal community activity feed social media sharing progress community progress bar personal contributions technologies frontend redux react css html d3 reactmaterialize materializecss ajax backend express nodejs postgres sql aws pgpromise passport bcrypt\n",
      "  (0, 43)\t0.49848983473436426\n",
      "  (0, 41)\t0.21751927282941377\n",
      "  (0, 40)\t0.37902389337774794\n",
      "  (0, 22)\t0.36828131535799413\n",
      "  (0, 11)\t0.4814868909757809\n",
      "  (0, 5)\t0.4394011668620202\n",
      "grow features monitor enviroment optionally control temperature wemo switches edit script control devices optionally report soil moisture perplant basis 8 email alerts enviroment exceeds alarm values requires ecowitt gw1000 wifi gateway linux apache mysql python3 optional wemo switches automation ip webcam ecowitt soil moisture sensors see full grow list amazon associate earn qualifying purchases installation prepare linux host working mysql python3 place files web root make sure py files execute cgi create database called grow create tables mysql create database grow mysql grow schemamysql cp myconfigsample myconfigpy edit cofiguration configure ecowitt gw1000 post data ecowittpy use ws view app go weather services customized enter server address ecowittpy path upload interval 60 copy growservice etcsystemdsystem edit make growcontrolpy run boot restart crash systemctl daemonreload place systemctl enable grow service grow start service grow status wemo automation install ouimeaux test command line wemo list make sure device names match growcontrolpy webcam setup edit getimagebash fetch image webcam python script add create cronjob run script every minute pathtogetimagebash run script hand test creates output expected fetch outjpg via webserver optionally speciy location xy coordinates 00 top left potssoil sensors config file\n",
      "  (0, 141)\t0.18800701324685826\n",
      "  (0, 139)\t0.15732585765913815\n",
      "  (0, 135)\t0.18800701324685826\n",
      "  (0, 129)\t0.11761375254644257\n",
      "  (0, 123)\t0.1812589337283062\n",
      "  (0, 122)\t0.19044535813053748\n",
      "  (0, 121)\t0.17917534203447838\n",
      "  (0, 118)\t0.168051666904598\n",
      "  (0, 113)\t0.17522257090396148\n",
      "  (0, 111)\t0.18800701324685826\n",
      "  (0, 110)\t0.1616792769755856\n",
      "  (0, 109)\t0.18800701324685826\n",
      "  (0, 106)\t0.19044535813053748\n",
      "  (0, 104)\t0.12349506126502623\n",
      "  (0, 96)\t0.1404955613754695\n",
      "  (0, 84)\t0.1715250004497865\n",
      "  (0, 71)\t0.18342116985055615\n",
      "  (0, 70)\t0.13456346146817874\n",
      "  (0, 68)\t0.18566822087668855\n",
      "  (0, 66)\t0.168051666904598\n",
      "  (0, 65)\t0.18342116985055615\n",
      "  (0, 59)\t0.15732585765913815\n",
      "  (0, 58)\t0.13271515740323075\n",
      "  (0, 53)\t0.18566822087668855\n",
      "  (0, 45)\t0.13181289533709092\n",
      "  (0, 44)\t0.12833956179190245\n",
      "  (0, 43)\t0.18342116985055615\n",
      "  (0, 27)\t0.168051666904598\n",
      "  (0, 26)\t0.10740147339377909\n",
      "  (0, 22)\t0.13551046579126594\n",
      "  (0, 21)\t0.18342116985055615\n",
      "  (0, 20)\t0.19044535813053748\n",
      "  (0, 17)\t0.17716487409928078\n",
      "  (0, 16)\t0.17522257090396148\n",
      "  (0, 5)\t0.1616792769755856\n",
      "  (0, 1)\t0.15594524971885454\n",
      "checkenv check environment modern bestpractice store application ' configuration environmental variables allows keep config data outside repository store standard systemagnostic location modern builddeploydevelopment tools make easier manage variables perhost ' still often undocumented lead bugs missing module lets define environmental variables application relies envjson file provides method check variables application launch print help screen missing installation npm checkenv usage first define json file called envjson project root see add following line top project ' entry file require ' checkenv ' check default checkenv print pretty error message call processexit1 required variables missing also print error message optional variables missing exit process would like handle errors check takes optional pretty argument causes throw errors instead printing error message result error thrown missing required variables try require ' checkenv ' checkfalse catch e something error configuration json file define environmental variables keys either boolean required value configuration object options json nodeenv description defines current environment validators name options development testing staging production port description port api server run default 3000 nodepath true debug required false description set enables additional debug messages options required defines whether variable required default variables required must explicitly set optional setting false description describes variable used useful new developers setting project printed error output present default defines default value use variable unset implicitly sets required false validators array validators variable must pass see validatorjs details validators format validator validators validator name optionless validators passed strings validators w options must passed objects name validator name options options option format varies see possible validators see validatorjs details contains options string value contain equals options string exact value options date options date alpha alphanumeric ascii base64 boolean date decimal fqdn float options may object min max properties hexcolor hexadecimal ip4 ip options 4 ip6 ip options 6 ip options may number 4 6 iso8601 enum alias options must array possible values int options may object min max properties json length options must object min max lowercase macaddress numeric url uuid3 uuid options 3 uuid4 uuid options 4 uuid5 uuid options 5 uuid options may number 3 4 5 uppercase regex alias matches regexp alias matches matches options must either string representing regex array format regex modifiers see also like module may also want check dotenv load missing environmental variables env approotpath automatically determine root path current application enforcenodepath enforce usage nodepath environmental variable change log 122 better handling syntax errors envjson thanks yalcindo 120 validation via validatorjs 111 prints default value help 110 added support default values added support change filename via setfilename 106 bugfix please use versions 106 105 passes tests node 010 51 100 initial release\n",
      "  (0, 137)\t0.1554697059929288\n",
      "  (0, 135)\t0.16862078632763894\n",
      "  (0, 134)\t0.1754822676703161\n",
      "  (0, 130)\t0.12068803334448171\n",
      "  (0, 129)\t0.10548608317757478\n",
      "  (0, 128)\t0.15072312318432785\n",
      "  (0, 126)\t0.15383830608869556\n",
      "  (0, 120)\t0.16450780933754897\n",
      "  (0, 112)\t0.12791180606448033\n",
      "  (0, 110)\t0.1450078183025598\n",
      "  (0, 104)\t0.11076094438427365\n",
      "  (0, 100)\t0.15715460385183366\n",
      "  (0, 98)\t0.12508257148190083\n",
      "  (0, 94)\t0.16652315708655696\n",
      "  (0, 90)\t0.11288751464601401\n",
      "  (0, 88)\t0.16069978743137273\n",
      "  (0, 84)\t0.15383830608869556\n",
      "  (0, 81)\t0.17309184686314744\n",
      "  (0, 80)\t0.15072312318432785\n",
      "  (0, 78)\t0.12508257148190083\n",
      "  (0, 73)\t0.1754822676703161\n",
      "  (0, 70)\t0.12068803334448171\n",
      "  (0, 68)\t0.16652315708655696\n",
      "  (0, 65)\t0.16450780933754897\n",
      "  (0, 64)\t0.135190486836885\n",
      "  (0, 59)\t0.1411032991270467\n",
      "  (0, 52)\t0.15715460385183366\n",
      "  (0, 47)\t0.12889059338807707\n",
      "  (0, 44)\t0.11510590723485592\n",
      "  (0, 41)\t0.07178404968063572\n",
      "  (0, 40)\t0.12508257148190083\n",
      "  (0, 34)\t0.1554697059929288\n",
      "  (0, 32)\t0.16069978743137273\n",
      "  (0, 30)\t0.1754822676703161\n",
      "  (0, 28)\t0.14637816033374557\n",
      "  (0, 26)\t0.09632683687510607\n",
      "  (0, 25)\t0.15889662765416593\n",
      "  (0, 19)\t0.1477860506171104\n",
      "  (0, 18)\t0.15715460385183366\n",
      "  (0, 17)\t0.15889662765416593\n",
      "  (0, 12)\t0.16450780933754897\n",
      "  (0, 11)\t0.15889662765416593\n",
      "  (0, 6)\t0.1522571111526189\n",
      "  (0, 4)\t0.15072312318432785\n",
      "  (0, 2)\t0.17080770278635693\n",
      "  (0, 1)\t0.13986505172084418\n",
      "buildingsimulationprojectpolimites repository includes files presentations group projects simulation buildings openstudio energyplus context echnical environmental systems politecnico di milano order insert personal contact information members group fill following form project group information form important note one members group fill form insert personal contact information members\n",
      "  (0, 98)\t0.31531002419146276\n",
      "  (0, 91)\t0.436332526387669\n",
      "  (0, 90)\t0.2845685418219855\n",
      "  (0, 83)\t0.3877979117292058\n",
      "  (0, 79)\t0.36553788553625394\n",
      "  (0, 56)\t0.34363717032817387\n",
      "  (0, 47)\t0.324909342986502\n",
      "  (0, 45)\t0.298013499004004\n",
      "  (0, 41)\t0.18095431020649858\n",
      "pylcaio object class structure manipulate facilitate hybridization lifecycle assessment lca environmentally extended inputoutput eeio matrices read combine organize manipulate concatenate lca foreground background matrices combine lca system eeio matrices automate hybridization correction doublecounting still beta release documentation demos soon come\n",
      "  (0, 97)\t0.4798481746581624\n",
      "  (0, 81)\t0.5285101723383102\n",
      "  (0, 37)\t0.47470359001180235\n",
      "  (0, 13)\t0.5148584549583177\n",
      "epaenvironmentaldatasetgateway epa environmental dataset gateway edg opensource metadata catalog built esri ' geoportal server repository contains code core httpsedgepagovmetadata website well several ancillary tomcat webapps epa disclaimer united states environmental protection agency epa github project code provided basis user assumes responsibility use epa relinquished control information longer responsibility protect integrity confidentiality availability information reference specific commercial products processes services service mark trademark manufacturer otherwise constitute imply endorsement recomendation favoring epa epa seal logo shall used manner imply endorsement commercial product activity epa united states government\n",
      "  (0, 131)\t0.2623636287763049\n",
      "  (0, 130)\t0.22440403997658565\n",
      "  (0, 129)\t0.1961379481492419\n",
      "  (0, 117)\t0.28604275364170834\n",
      "  (0, 111)\t0.3135288945172039\n",
      "  (0, 110)\t0.26962358531773156\n",
      "  (0, 98)\t0.23257512442083408\n",
      "  (0, 93)\t0.30588133719664934\n",
      "  (0, 90)\t0.20989996810350559\n",
      "  (0, 56)\t0.25346944756874723\n",
      "  (0, 51)\t0.30588133719664934\n",
      "  (0, 41)\t0.13347330557815518\n",
      "  (0, 20)\t0.3175951873784592\n",
      "  (0, 19)\t0.27478935476563654\n",
      "  (0, 15)\t0.21402478682326478\n",
      "layout title permalink page welcome apes indexhtml collection advice problems environmental statistics apes department biometry environmental system analysis university freiburg professorship theoretical ecology university regensburg website gives basic intros links standard topics statistics statistical programming language r also provide hubs special topics checklists particular situations student looking help following pages may particularly interesting getting started r get error r checklist planning experiment checklist analyzing data\n",
      "  (0, 92)\t0.4309335194290264\n",
      "  (0, 85)\t0.4220287955653481\n",
      "  (0, 52)\t0.4356037473655823\n",
      "  (0, 47)\t0.35726109260505007\n",
      "  (0, 41)\t0.19897222401096842\n",
      "  (0, 26)\t0.26700033016041846\n",
      "  (0, 3)\t0.45598548475169554\n",
      "installation requires download mysql connector order connect mysql database system usage specializes structured data storing detailed information environmental inspection documents utilizes chartview statistics\n",
      "  (0, 128)\t0.39275013529794905\n",
      "  (0, 83)\t0.4008675925355622\n",
      "  (0, 59)\t0.3676830644980753\n",
      "  (0, 56)\t0.3552185326654856\n",
      "  (0, 41)\t0.18705288630348588\n",
      "  (0, 38)\t0.41404842661892594\n",
      "  (0, 27)\t0.39275013529794905\n",
      "  (0, 26)\t0.25100580067767053\n",
      "fish546 bioinformatics environmental sciences winter 2015 repository serves primary framework course specifically please see wiki syllabus content etc issues used primary means assessment communication course description course teach core computing skills well project specific approaches student developing completing research project targeting journal article submission end quarter emphasis developing habits increase automation turn facilitate reproducibility course primary course platform github student creating repository code repository example analyses provided files directory structure contributingmd simply guidelines contributing repository see creating new issue gitignore list files local repo github file size limits notebooks directory ipython notebooks live notebooks rendered nbviewer httpnbvieweripythonorggithubsr320fish5462015treemasternotebooks data raw data including fasta files datafa analyses output analyses performed ipython notebooks scripts scripts call notebooks\n",
      "  (0, 130)\t0.17878079360480076\n",
      "  (0, 117)\t0.2278878335091604\n",
      "  (0, 102)\t0.25302538960756127\n",
      "  (0, 98)\t0.1852906272143338\n",
      "  (0, 93)\t0.243693064610693\n",
      "  (0, 90)\t0.16722552267366741\n",
      "  (0, 84)\t0.2278878335091604\n",
      "  (0, 78)\t0.1852906272143338\n",
      "  (0, 67)\t0.24667849290853322\n",
      "  (0, 66)\t0.22327316827323512\n",
      "  (0, 55)\t0.2564089983999154\n",
      "  (0, 51)\t0.243693064610693\n",
      "  (0, 45)\t0.17512639596659305\n",
      "  (0, 44)\t0.17051173073066778\n",
      "  (0, 42)\t0.20193695708704393\n",
      "  (0, 41)\t0.10633704945244513\n",
      "  (0, 39)\t0.2599500398529252\n",
      "  (0, 36)\t0.21480682149352265\n",
      "  (0, 30)\t0.2599500398529252\n",
      "  (0, 26)\t0.1426934209195072\n",
      "  (0, 24)\t0.2564089983999154\n",
      "  (0, 15)\t0.17051173073066778\n",
      "visuite04 repository version 04 visuite building environmental performance addon blender article describing visuite published ' open geospatial data software standards ' article openaccess link full text found httprdcubevrj5 article reference used cite visuite research work bibtex formatted reference articlesouthall2017 abstract visuite free opensource addon 3d content creation application blender developed primarily tool contextual performative analysis buildings functionality grown simple static lighting analysis fully parametric lighting shadowing building energy analyses adopts flexible mesh geometry based approach specification calculation points made suitable certain types 3d geospatial analyses data visualisation author southall ryan biljecki filip day 14 doi 101186s4096501700361 issn 23637501 journal open geospatial data software standards month sep number 1 pages 23 title visuite set environmental analysis tools geospatial data applications url httpsdoiorg101186s4096501700361 volume 2 year 2017\n",
      "  (0, 140)\t0.2175303524317818\n",
      "  (0, 136)\t0.21391608074596652\n",
      "  (0, 130)\t0.19096840088415287\n",
      "  (0, 126)\t0.24342310081920238\n",
      "  (0, 125)\t0.26681387564668596\n",
      "  (0, 115)\t0.22327210616530002\n",
      "  (0, 114)\t0.27027430107094125\n",
      "  (0, 112)\t0.20239879946187384\n",
      "  (0, 102)\t0.27027430107094125\n",
      "  (0, 98)\t0.19792201424142714\n",
      "  (0, 82)\t0.22131278906891075\n",
      "  (0, 80)\t0.23849385074176746\n",
      "  (0, 48)\t0.2634947321432545\n",
      "  (0, 41)\t0.11358611783300211\n",
      "  (0, 33)\t0.27388857275675654\n",
      "  (0, 26)\t0.1524209276636519\n",
      "  (0, 8)\t0.22733833968732714\n",
      "  (0, 6)\t0.24092112725926543\n",
      "  (0, 3)\t0.26030578518481823\n",
      "pylcaio object class hybridize lifecycle assessment lca environmentally extended inputoutput eeio databases create lcaio hybrid database eg combining ecoinvent exiobase data automates hybridization correction doublecounting two available methods stam binary default parameters allow hybridization ecoinvent35 exiobase accept capitalsendogenized version exiobase includes extrapolated additional environmental extensions exiobase useeio includes matching ecoinvent exiobase environmental flows impact world includes regionalized characterization matrices use impact world exported brightway2 interested default hybrid database want cannot run code find httpszenodoorgrecord3890379 software still development system requirements 8gm ram likely run memorryerror making impossible generate database dependencies python 3 pandas numpy scipy pymrio ecospold2matrix pickle brightway2 bw2agg related publications majeaubettez g agez wood r sodersten c margni strmman h samson r 2017 streamlined hybridization software merging ecoinvent exiobase biennial conference international society industrial ecology agez majeaubettez g margni strmman h samson r 2019 lifting veil correction double counting incidents hybrid life cycle assessment journal industrial ecology 117 httpsdoiorghttpsdoiorg101111jiec12945 agez wood r margni strmman h samson r majeaubettez g 2019 hybridization complete lca mrio databases comprehensive product system coverage journal industrial ecology 117 httpsdoiorg101111jiec12979\n",
      "  (0, 137)\t0.2654771541652669\n",
      "  (0, 136)\t0.2308487398651515\n",
      "  (0, 129)\t0.1801260572738003\n",
      "  (0, 115)\t0.2409453472387895\n",
      "  (0, 104)\t0.1891333113419007\n",
      "  (0, 101)\t0.2775989743651827\n",
      "  (0, 96)\t0.21516966330140272\n",
      "  (0, 81)\t0.295568391417223\n",
      "  (0, 41)\t0.1225770969460769\n",
      "  (0, 34)\t0.2654771541652669\n",
      "  (0, 29)\t0.2744079431409264\n",
      "  (0, 28)\t0.24995260130688993\n",
      "  (0, 27)\t0.25737197838205367\n",
      "  (0, 26)\t0.16448590006665453\n",
      "  (0, 22)\t0.20753496418438366\n",
      "  (0, 15)\t0.19655268841706447\n",
      "  (0, 13)\t0.2879336923002039\n",
      "  (0, 7)\t0.2409453472387895\n",
      "environmental monitor overview simple mongoose os powered environment monitor consisting ssd1306 oled bme280 sensor connected controller via shared i2c bus install app install start mos tool switch project page find import app build flash alternatively build flash example command line build git clone httpsgithubcommongooseosappsexamplearduinoadafruitbme280jsgit cd examplearduinoadafruitbme280js mos build platform esp32 mos flash wait boot set i2c pins mos console mos configset i2csclgpio22 i2csdagpio23 verify i2c mos configget i2c using example example work properly must ensure i2c spi configuration correct check device ' current configuration using mos configget look i2c spi section mos configget i2c using port devttyusb1 debug false enable true freq 100000 sclgpio 22 sdagpio 23 device boots output look like following watch carefully mgosi2ccreate equivilent spi line boot messages ensure pins initialized correctly via web ui mos console dec 25 132524986 mgosi2ccreate i2c gpio init ok sda 23 scl 22 dec 25 132524992 mgrpcchanneluart 0x3ffbc478 uart0 dec 25 132525001 mgosinit init done ram 317608 total 275252 free 275252 min free dec 25 132525098 starting dec 25 132525424 mongoosepoll new heap free lwm 261716 dec 25 132527426 temperature 22960000 c dec 25 132527433 humidity 43640000 rh dec 25 132527442 pressure 1025687700 hpa dec 25 132529426 temperature 22970000 c dec 25 132529433 humidity 43640000 rh dec 25 132529441 pressure 1025714100 hpa dec 25 132531425 temperature 22960000 c dec 25 132531433 humidity 43650000 rh dec 25 132531441 pressure 1025692000 hpa please note esp8266 esp32 pins choose use i2c ' important ensure configuration pins ' selected i2c sensor address important adafruit bme280 uses address 0x77 many generic bme280 ' utilize 0x76 trouble try switching addresses consult datasheet well known bme280 ' tend selfwarm report higher expected temperatures tolerance bme280 tensor 1c however added heating ' uncommon see temperatures much 18c higher ambient add adjustments code testing environment use sensor using reliable thermometer please report excessive temps mongoose bug\n",
      "  (0, 140)\t0.15617958866943937\n",
      "  (0, 139)\t0.1603019776892582\n",
      "  (0, 133)\t0.11505662729684013\n",
      "  (0, 132)\t0.19156352611926414\n",
      "  (0, 129)\t0.11983864202093336\n",
      "  (0, 125)\t0.19156352611926414\n",
      "  (0, 122)\t0.19404799696822736\n",
      "  (0, 118)\t0.17123068616698425\n",
      "  (0, 114)\t0.19404799696822736\n",
      "  (0, 112)\t0.14531563477817183\n",
      "  (0, 108)\t0.18256478692463593\n",
      "  (0, 90)\t0.12824712084079462\n",
      "  (0, 85)\t0.17297339031770137\n",
      "  (0, 84)\t0.17476972447100217\n",
      "  (0, 79)\t0.16473775027312124\n",
      "  (0, 78)\t0.1421014512563111\n",
      "  (0, 69)\t0.18918049101034368\n",
      "  (0, 65)\t0.18689093270875715\n",
      "  (0, 64)\t0.1535846612999025\n",
      "  (0, 58)\t0.13522571888451024\n",
      "  (0, 50)\t0.17476972447100217\n",
      "  (0, 49)\t0.1617434399065105\n",
      "  (0, 48)\t0.18918049101034368\n",
      "  (0, 47)\t0.14642759704043232\n",
      "  (0, 42)\t0.15486770753470963\n",
      "  (0, 41)\t0.08155107075128751\n",
      "  (0, 40)\t0.1421014512563111\n",
      "  (0, 25)\t0.18051628713643667\n",
      "  (0, 18)\t0.17853724155477246\n",
      "  (0, 16)\t0.17853724155477246\n",
      "  (0, 15)\t0.13076735049865942\n",
      "  (0, 14)\t0.1662945426306976\n",
      "  (0, 12)\t0.18689093270875715\n",
      "  (0, 10)\t0.17297339031770137\n",
      "  (0, 9)\t0.17297339031770137\n",
      "  (0, 5)\t0.16473775027312124\n",
      "  (0, 1)\t0.15889525290457307\n",
      "environmentaldatapredict environmental data predict\n",
      "  (0, 41)\t0.5975408006708108\n",
      "  (0, 26)\t0.8018385071407373\n",
      "environmental informatics ucsb fork clone repository introduce adding file per github usernamejson data directory ' example github username bbest databbestjson &#9; program lecturer &#9; interests marine biology species distribution modeling spatial decisionmaking &#9; project route ships around marine mammal hot spots using format replace program interests project idea create rmarkdown document also username students folder details project idea commit push changes submit pull request original repository acknowledgements content site draws extensively repositories httpsgithubcomadvancedjsstudents httpsgithubcomdatacarpentryrecology testing cd githubesm2963w2016 bundle exec jekyll serve baseurl ' ' usrlocalbinjekyll serve baseurl ' '\n",
      "  (0, 133)\t0.18428015639160922\n",
      "  (0, 99)\t0.3107964840350011\n",
      "  (0, 98)\t0.22759643035101218\n",
      "  (0, 90)\t0.20540667704731422\n",
      "  (0, 89)\t0.31495264289970876\n",
      "  (0, 51)\t0.2993333901478732\n",
      "  (0, 46)\t0.28595372181871315\n",
      "  (0, 44)\t0.20944319651086407\n",
      "  (0, 42)\t0.24804347246227748\n",
      "  (0, 41)\t0.13061606641031082\n",
      "  (0, 36)\t0.26385180147520615\n",
      "  (0, 32)\t0.29240442968378827\n",
      "  (0, 26)\t0.1752733731009895\n",
      "  (0, 22)\t0.22114572248593714\n",
      "  (0, 14)\t0.2663452340211062\n",
      "  (0, 10)\t0.27704239354327304\n",
      "table contents generated doctoc obtain library overview changing defaults changing name default properties file changing extension properties file changing location configuration sourced changing location environmental overrides sourced multi environmental variable configuration operational overrides thread safety mapstringstring property merging strictness property values placeholder replacement obtaining resolved unresolved properties one time using environment resolve placeholders trimming property values whitespace thread safety composite builder using spring obtain library dependency groupidorggreencheekgroupid artifactidenvironmentpropertiesmergercoreartifactid version100version dependency maven repositories located httpsrawgithubcomtootedomtootedommvnrepomasterreleases httpsrawgithubcomtootedomtootedommvnrepomastersnapshots overview simple library allows sourcing standard java properties file httpdocsoraclecomjavase6docsapijavautilpropertieshtml use application configuration properties files sourced either classpath classpath filesystem filesystem overridden based either environment variables system properties example imagine architecture defined environment variable env denotes environment current server resides variable different value different environments example ci integration test loadtest staging production library default allows following structure files within project srcmainresources config defaultproperties environments ciproperties integrationproperties testproperties loadtestproperties stagingproperties productionproperties run time given value production env variable lib return properties object combination merge config defaultproperties environments productionproperties gives ability different configuration deployed along application varying configuration based environmental settings achieved following propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder p mergerbuilderbuildproperties idea library distribute along application configuration properties defaultproperties contains set properties contain defaults application configuration lets say something like config defaultproperties contains databaseurljdbcmysqllocalhostadmin databaseusernameuser databasepasswordpass provide overrides defaults within properties files match value env variable exists platform ' architecture example production environment provide config environments productionproperties contains configuration specific live environment databaseurljdbcmysqlbernardappdbwproductionadmin databaseusernameuser databasepasswordpass way varying configuration application distributed along application changing defaults default library reads configuration classpath looking configdefaultproperties files override based value env variable configenvironmentsenvproperties defaults changable changing name default properties file following change name default properties file sourced defaultproperties globalproperties propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder setnameofdefaultpropertiesfileglobal p mergerbuilderbuildproperties changing extension properties file following change extension properties file properties props propertiesmergerbuilder mergerbuilder4 new environmentspecificpropertiesmergerbuilder setnameofdefaultpropertiesfileglobal setextensionforpropertiesfileprops p mergerbuilder4buildproperties separator character changed something else ie via following setextensionseparatorcharforpropertiesfile ' ' changing location configuration sourced default configuration files sourced classpath location config changed either read different location classpath change read file system classpath changes source appconfig classpath propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder setlocationforloadingconfigurationpropertiesclasspathappconfig properties p mergerbuilderbuildproperties filesystem changes source configuration dataopsoverridesmyappconfig propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder setlocationforloadingconfigurationpropertiesfiledataapplicationconfig properties p mergerbuilderbuildproperties changing read cdataopsoverridesmyappconfig windows propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder setlocationforloadingconfigurationpropertiesfilecdataopsoverridesmyappconfig properties p mergerbuilderbuildproperties often helpful operations teams fellow developers deploy configuration properties embedded within jar files distributed filesystem location classpath ie webinfclassess web application helps troubleshooting issues verification configuration quickly extract configuration jar say within webinflib however ' strict rule preference often distributing library use multiple applications avoidable configuration needs distributed jar see operational overrides later changing location environmental overrides sourced default environmental overrides sourced environment directory within location specified configuration sourced example follow defines application configuration read classpath dataconfig environmental configuration sourced dataconfigenvs propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder setlocationforloadingconfigurationpropertiesclasspathdataconfig setrelativelocationoffilesoverridingdefaultpropertiesenvs properties p mergerbuilderbuildproperties multi environmental variable configuration library goes one step futher allows configure environmental setting differ one environmental system property sequence environmental variables example imagine environmental variable env system property osarch configure library merge configuration order fashion sources configdefaultproperties configenvironmentsproductionproperties configenvironmentsproductionx8664properties propertiesmergerbuilder resolverenvandosbuilder new environmentspecificpropertiesmergerbuilder setvariablesusedforswitchingconfigurationnew string envenvosarch running macbook pro osx snow leopardlion env environment variable set production would resulting following files sourced merged config defaultproperties environments productionproperties productionx8664properties operational overrides library also concept operational overrides gives operations department location file system overwrite specific property value used application without modify configuration distribute application useful properties passwords database connection strings etc operations department might know default library look overrides within directory filesystem dataopsoverridesconfig value appname need specify windows machine default cdataopsoverridesconfig example following create propertiesmerger reads operational overrides directory dataopsoverridesbernardconfig windows c propertiesmergerbuilder resolverenvandosbuilder new environmentspecificpropertiesmergerbuilder setvariablesusedforswitchingconfigurationnew string envenvosarch setapplicationnamebernard properties p mergerbuilderbuildproperties given value production env variable configuration sourced order top bottom classpath config defaultproperties environments productionproperties filesystem data opsoverrides bernard config defaultproperties environments productionproperties otherwords files source order classpathconfigdefaultproperties classpathconfigenvironmentsenvproperties filesystemdataopsoverridesbernardconfigdefaultproperties filesystemdataopsoverridesbernardconfigenvironmentsenvproperties location operational overrides loaded changed via setting property mergerbuilder example following defines operational overrides location dataopsapplicationxconfig propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder setvariablesusedforswitchingconfigurationnew string envenvosarch setlocationforloadingoperationaloverridesfiledataopsapplicationxconfig properties p mergerbuilderbuildproperties essence result following sourced classpathconfigdefaultproperties classpathconfigenvironmentsenvproperties filesystemdataopsapplicationxconfigdefaultproperties filesystemdataopsapplicationxconfigenvironmentsenvproperties please note possible set operational overrides point classpath location changing file prefix classpath resource however idea behind operational overrides give ability operational teams adjust application properties quickly easily therefore file location probably preferrable option thread safety propertiesmergerbuilder thread safe intended used single thread order create propertiesmerger instance propertiesmerger instance thread safe use multiple threads builder responsible creating propertiesmerger propertiesmerger created safe use multiple threads properties object returned following java call thread safe propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder properties p mergerbuilderbuildproperties equivalent propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder propertiesmerger merger mergerbuilderbuild properties p mergergetmergedproperties obtaining map instead properties object rather properties object obtain mapstringstring properties propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder propertiesmerger merger mergerbuilderbuild mapstringstring map mergergetmergedpropertiesasmap property merging strictness propertymerger constructed properties files read classpath andor filesystem resolution process merging merger compare properties original properties file defaultproperties compare properties overriding file property defined overriding file exist default properties warning logged letting know new property exists default value example spelling mistake exists prodproperties defaultproperties productinventoryurlhttplocalhost9090apilist prodproperties productinevntoryurlhttpproductslivexxx9090apilist propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder propertiesmerger merger mergerbuilderbuild testing would see 114024431 main warn oguepmenvironmentspecificpropertiesmerger nomatchingpropertywarning property productinevntoryurl overriding properties exist original properties would rather propertiesmerger b strict throw exception fail contructed set merger strict follows propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder setstrictmergingofpropertiestrue propertiesmerger merger mergerbuilderbuild construction propertiesmerger mergerbuilder ' build method would receive runtime exception orggreencheekutilsenvironmentpropertyplaceholderresolverexceptionnomatchingpropertyexception exception thread main orggreencheekutilsenvironmentpropertyplaceholderresolverexceptionnomatchingpropertyexception nomatchingpropertywarning property productinevntoryurl overriding properties exist original properties property values placeholder replacement configurationcode examples replace variables placeholder values properties returned properties object example given following property contained within configdefaultproperties lets say databaseservercnamebernardappdbwproduction databaseurljdbcmysqldatabaseservercnameadmin value databaseurl obtained properties object still contain databaseservercname propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder properties p mergerbuilderbuildproperties results databaseurljdbcmysqldatabaseservercnameadmin databaseservercnamebernardappdbwproduction order placeholder replacement take place use additional builder creates propertiesresolver previous builder propertiesmergerbuilder creates propertiesmerger responsible merging varying properties files differ based environmental settings propertiesresolver takes merged properties propertiesmerger resolves variables values properties propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder propertiesresolverbuilder resolverbuilder new environmentspecificpropertiesresolverbuilder propertiesmerger merger mergerbuilderbuild properties p resolverbuilderbuildpropertiesmerger reduce amount code little pass propertiesmergerbuilder directly buildproperties method propertiesresolverbuilder propertiesresolverbuilder calls build builder obtain propertiesmerger obtains merged properties propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder propertiesresolverbuilder resolverbuilder new environmentspecificpropertiesresolverbuilder properties p resolverbuilderbuildpropertiesmergerbuilder obtaining resolved unresolved properties one time everytime call resolverbuilderbuildpropertiesmergerbuilder obtain properties object new propertiesresolver properties object created therefore really create properties object use multiple place however central place object query return property resolved variable unresolved variables create propertiesresolver object query properties query internal properties object obtained merger create propertiesresolver propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder propertiesresolverbuilder resolverbuilder new environmentspecificpropertiesresolverbuilder propertiesmerger merger mergerbuilderbuild propertiesresolver resolver resolverbuilderbuildmerger query resolved property resolvergetpropertydatabaseurl returns jdbcmysqlbernardappdbwproductionadmin query unresolved property resolvergetunresolvedpropertydatabaseurl returns jdbcmysqldatabaseservercnameadmin using environment resolve placeholders default resolver also resolve variables placeholders within property values environment varibles available java process java system properties set wish behaviour turn creating variableplaceholdervalueresolver passing propertiesresolverbuilder via setpropertyvalueresolver method propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder propertiesresolverbuilder resolverbuilder new environmentspecificpropertiesresolverbuilder valueresolverconfig valueresolver new variableplaceholdervalueresolverconfig setenvironmentpropertiesresolutionenabledfalse setsystempropertiesresolutionenabledfalse resolverbuildersetpropertyvalueresolvernew variableplaceholdervalueresolvervalueresolver p resolverbuilderbuildpropertiesmergerbuilder trimming property values whitespace default property values returned propertiesresolver trimmed whitespace beginning end property value javalangstringtrim turned propertiesresolverbuilder level propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder propertiesresolverbuilder resolverbuilder new environmentspecificpropertiesresolverbuilder settrimmingpropertyvaluesfalse propertiesresolver resolver resolverbuilderbuildmergerbuilderbuild thread safety like propertiesmergerbuilder propertiesresolverbuilder thread safe intended used single thread order construct propertiesresolver safe use across multiple threads goes valueresolver ' configuration valueresolver variableplaceholdervalueresolver thread safe construction like propertiesmergerbuilder obtain propertiesresolver builder propertiesmergerbuilder mergerbuilder new environmentspecificpropertiesmergerbuilder propertiesresolverbuilder resolverbuilder new environmentspecificpropertiesresolverbuilder propertiesmerger merger mergerbuilderbuild propertiesresolver resolver resolverbuilderbuildmerger use constructed propertiesresolver multiple threads properties obtain returned via resolverbuilderbuildpropertiesmergerbuilder safe use across multiple threads composite builder composite builder avialable combination propertiesmergerbuilder propertiesresolverbuilder adds method properties buildresolvedproperties returns set properties embedded property values resolved properties come set combined property files source dependent system environment properties defined merger property value contain variables placeholders ie resolved composite builder created means reduce number lines xmlcode generating properties object use spring 31 propertysources object bean idenvironmentalproperties classorgspringframeworkcoreenvpropertiespropertysource constructorarg valuemyenvironmentproperties constructorarg bean factorybeanpropertiesresolver factorymethodbuildresolvedproperties constructorarg bean bean idpropertiesresolver classorggreencheekutilsenvironmentpropertyplaceholderresolverbuildercompositeresolvedpropertiesbuilder constructorarg bean classorggreencheekutilsenvironmentpropertyplaceholderresolvervaluevariableplaceholdervalueresolver constructorarg valuefalse resolve env vars constructorarg valuefalse resolve system properties bean constructorarg property namelocationforloadingconfigurationproperties valueclasspath property namelocationforloadingoperationaloverrides valueclasspathopsoverrides property namerelativelocationoffilesoverridingdefaultproperties valueenvironments bean using spring prior propertysource introduction spring 3 associate profilevaluedev autowired orgspringframeworkcoreenvenvironment way define propertyplaceholderconfigurer follows bean classorgspringframeworkbeansfactoryconfigpropertyplaceholderconfigurer property nameproperties bean factorybeanpropertiesresolver factorymethodbuildresolvedproperties property bean bean idpropertiesresolver classorggreencheekutilsenvironmentpropertyplaceholderresolverbuildercompositeresolvedpropertiesbuilder constructorarg bean classorggreencheekutilsenvironmentpropertyplaceholderresolvervaluevariableplaceholdervalueresolver constructorarg valuefalse resolve env vars constructorarg valuefalse resolve system properties bean constructorarg property namelocationforloadingconfigurationproperties valueclasspath property namelocationforloadingoperationaloverrides valueclasspathopsoverrides property namerelativelocationoffilesoverridingdefaultproperties valueenvironments bean allowed register property placeholder resolve properties within application contexts value annotations valuemessage &#9; private string message introduction spring 311 move use propertysource implementations use autowired environment order obtain properties autowired &#9; private environment env requestmappingvalueheadersnoofheadersmethodrequestmethodget public string returnheadersfinal pathvariablenoofheaders int noheaders &#9; &#9; &#9; &#9; &#9; &#9; model modelhttpservletrequest request string envgetpropertymessage propertiesmerger works within environment properties made available environment object via use custom applicationcontextinitializer set either dispatcherservlet contextloaderlistener dispatcherservlet servlet &#9; &#9; servletnameservletservletname &#9; &#9; servletclassorgspringframeworkwebservletdispatcherservletservletclass &#9; &#9; loadonstartup1loadonstartup &#9; &#9; initparam &#9; &#9; &#9; paramnamecontextinitializerclassesparamname &#9; paramvalueorggreencheekplaygroundwebspringpropertiesmergerapplicationcontextinitializerparamvalue initparam &#9; servlet contextloaderlistener contextparam paramnamecontextinitializerclassesparamname paramvalueorggreencheekplaygroundwebspringpropertiesmergerapplicationcontextinitializerparamvalue contextparam listener &#9; listenerclassorgspringframeworkwebcontextcontextloaderlistenerlistenerclass &#9; listener would make propertysource instance propertiespropertysourcehttpstaticspringsourceorgspringdocs31xjavadocapiorgspringframeworkcoreenvpropertiespropertysourcehtml populated properties obtain either merger resolver public class propertiesmergerapplicationcontextinitializer implements applicationcontextinitializerconfigurableapplicationcontext &#9; private static final properties environmentalproperties &#9; static propertiesmerger merger new environmentspecificpropertiesmergerbuilderbuild environmentalproperties mergergetmergedproperties following resolved properties environmentalproperties new environmentspecificpropertiesresolverbuilderbuildpropertiesmerger &#9; &#9; public void initializeconfigurableapplicationcontext applicationcontext &#9; &#9; initialiseapplicationcontext &#9; &#9; public static void initialiseconfigurableapplicationcontext applicationcontext &#9; add merged properties applicationcontext environment &#9; properties available autowired environment object &#9; &#9; applicationcontextgetenvironment &#9; &#9; getpropertysources &#9; &#9; addfirstnew propertiespropertysourcepenvironmentalproperties &#9; please aware register propertysourcesplaceholderconfigurer beanfactory post processor properties made available value annotations unless register propertysourcesplaceholderconfigurer bean classorgspringframeworkcontextsupportpropertysourcesplaceholderconfigurer property nameproperties &#9; &#9; bean factorybeanpropertiesresolver factorymethodbuildresolvedproperties property bean bean idpropertiesresolver classorggreencheekutilsenvironmentpropertyplaceholderresolverbuildercompositeresolvedpropertiesbuilder constructorarg bean classorggreencheekutilsenvironmentpropertyplaceholderresolvervaluevariableplaceholdervalueresolver constructorarg valuefalse resolve env vars constructorarg valuefalse resolve system properties bean constructorarg property namelocationforloadingconfigurationproperties valueclasspath property namelocationforloadingoperationaloverrides valueclasspathopsoverrides property namerelativelocationoffilesoverridingdefaultproperties valueenvironments bean could also declare java based configuration create propertysourcesplaceholderconfigurer bean propertysourcesplaceholderconfigurer used resolving properties web application components could add configuration propertiesmergerapplicationcontextinitializer example propertysourcesplaceholderconfigurer registered separate context ie configurer ' inherited webapplicationcontext root applicationcontext like beans affects context registered import javautilproperties import orggreencheekutilsenvironmentpropertyplaceholderbuilderenvironmentspecificpropertiesmergerbuilder import orggreencheekutilsenvironmentpropertyplaceholderbuilderenvironmentspecificpropertiesresolverbuilder import orggreencheekutilsenvironmentpropertyplaceholdermergerpropertiesmerger import orgspringframeworkcontextapplicationcontextinitializer import orgspringframeworkcontextconfigurableapplicationcontext import orgspringframeworkcontextannotationbean import orgspringframeworkcontextannotationconfiguration import orgspringframeworkcontextsupportpropertysourcesplaceholderconfigurer import orgspringframeworkcoreenvmutablepropertysources import orgspringframeworkcoreenvpropertiespropertysource configuration public class appconfig implements &#9; &#9; applicationcontextinitializerconfigurableapplicationcontext &#9; private static final properties environmentalproperties &#9; static &#9; &#9; propertiesmerger merger new environmentspecificpropertiesmergerbuilderbuild &#9; &#9; environmentalproperties new environmentspecificpropertiesresolverbuilderbuildpropertiesmerger &#9; &#9; public void initializeconfigurableapplicationcontext applicationcontext &#9; &#9; initialiseapplicationcontext &#9; &#9; public static void initialiseconfigurableapplicationcontext applicationcontext &#9; &#9; applicationcontext &#9; &#9; &#9; &#9; getenvironment &#9; &#9; &#9; &#9; getpropertysources &#9; &#9; &#9; &#9; addfirstnew propertiespropertysourcepenvironmentalproperties &#9; &#9; bean &#9; public static propertysourcesplaceholderconfigurer propertysourcesplaceholderconfigurer &#9; &#9; propertysourcesplaceholderconfigurer config new propertysourcesplaceholderconfigurer &#9; &#9; mutablepropertysources sources new mutablepropertysources &#9; &#9; sourcesaddfirstnew propertiespropertysourcepenvironmentalproperties &#9; &#9; configsetpropertysourcessources &#9; &#9; return config &#9;\n",
      "  (0, 139)\t0.11958262755018854\n",
      "  (0, 138)\t0.14669237348428862\n",
      "  (0, 135)\t0.14290322631282057\n",
      "  (0, 134)\t0.14871821414740802\n",
      "  (0, 133)\t0.08583034350262331\n",
      "  (0, 130)\t0.10228103970980454\n",
      "  (0, 129)\t0.08939764749932926\n",
      "  (0, 124)\t0.11271824626196131\n",
      "  (0, 123)\t0.13777404353414213\n",
      "  (0, 117)\t0.13037532767673016\n",
      "  (0, 116)\t0.11853323409654874\n",
      "  (0, 114)\t0.14475660052861963\n",
      "  (0, 112)\t0.10840306327712755\n",
      "  (0, 110)\t0.12289164062937638\n",
      "  (0, 105)\t0.11650739343342933\n",
      "  (0, 104)\t0.09386800196277569\n",
      "  (0, 103)\t0.1411255214836171\n",
      "  (0, 99)\t0.14475660052861963\n",
      "  (0, 97)\t0.1331858331908344\n",
      "  (0, 95)\t0.14669237348428862\n",
      "  (0, 92)\t0.13175791113395807\n",
      "  (0, 90)\t0.0956702338109484\n",
      "  (0, 88)\t0.1361903155113176\n",
      "  (0, 83)\t0.13037532767673016\n",
      "  (0, 81)\t0.14669237348428862\n",
      "  :\t:\n",
      "  (0, 42)\t0.11552875177606556\n",
      "  (0, 41)\t0.060835751751450624\n",
      "  (0, 40)\t0.10600533546045832\n",
      "  (0, 39)\t0.14871821414740802\n",
      "  (0, 36)\t0.12289164062937638\n",
      "  (0, 35)\t0.13175791113395807\n",
      "  (0, 28)\t0.12405298201363497\n",
      "  (0, 27)\t0.12773526355839718\n",
      "  (0, 26)\t0.08163534324418649\n",
      "  (0, 25)\t0.13466216850564727\n",
      "  (0, 24)\t0.14669237348428862\n",
      "  (0, 23)\t0.12903529206951977\n",
      "  (0, 22)\t0.10300085313997513\n",
      "  (0, 19)\t0.12524614489805172\n",
      "  (0, 18)\t0.1331858331908344\n",
      "  (0, 17)\t0.13466216850564727\n",
      "  (0, 15)\t0.09755028350753789\n",
      "  (0, 13)\t0.14290322631282057\n",
      "  (0, 11)\t0.13466216850564727\n",
      "  (0, 9)\t0.12903529206951977\n",
      "  (0, 8)\t0.12176046739390221\n",
      "  (0, 7)\t0.11958262755018854\n",
      "  (0, 6)\t0.12903529206951977\n",
      "  (0, 2)\t0.14475660052861963\n",
      "  (0, 1)\t0.11853323409654874\n",
      "environmentalcs program created feb202020 6 months work completed jun222020 program comparison algorithm people working towards environmental benefits monitoring plant life growth certain area upload save images landscapes directory compare overtime new images area provide thorough analysis much plant life change location interest\n",
      "  (0, 141)\t0.322383165440062\n",
      "  (0, 140)\t0.26283536951096775\n",
      "  (0, 92)\t0.2972398423682406\n",
      "  (0, 89)\t0.33093130876036814\n",
      "  (0, 78)\t0.23914320537780787\n",
      "  (0, 74)\t0.31451963585794424\n",
      "  (0, 68)\t0.31837274436809715\n",
      "  (0, 41)\t0.13724268323114072\n",
      "  (0, 36)\t0.27723794020923753\n",
      "  (0, 23)\t0.29109773784808296\n",
      "  (0, 11)\t0.30379171463099996\n",
      "  (0, 3)\t0.31451963585794424\n",
      "qgisapplications environmental gis applications repository includes gis open source environmental applications\n",
      "  (0, 116)\t0.5713631159402619\n",
      "  (0, 98)\t0.5109751643631539\n",
      "  (0, 82)\t0.5713631159402619\n",
      "  (0, 41)\t0.29324522313265\n",
      "environmentalviolence environmentalviolence\n",
      "\n",
      "environmental sensor data repository esdr esdr open source data repository intended storing retrieving time series environmental data basically data timestamp value esdr store provide ways retrieve quickly securely data stored custom open source datastore provides extremely fast data inserts fetches making fast responsive visualizations esdr web site esdrcmucreatelaborg provides rest api interface datastore making easy readwrite data metadata stored mysql database esdr pronounced like female name esther concepts terminology ' familiar xively ' api ' see lot parallels esdr intention use esdr data repository products visualizations also anyone else wants place store data tools easily visualize first terminology esdr clients users products devices feeds channels tiles understanding entities relate give good understanding data metadata structured system works client esdr uses oauth2 authentication client esdr simply oauth2 client user real surprise heresimply person registered esdr may one products devices feeds user logs heshe behalf oauth2 client product product simply certain kind sensor example speck particle sensor device particular instantiation product ie actual sensor devicesomething put hands ontypically unique serial number feed particular installation device example buy speck register behindthescenes registration process creates esdr device instance speck ' serial number well feed location specified registration example let ' say purchase speck install awning deck registration would give location name eg deck set latitudelongitude house mark exposure outdoors set visibility public private etc data recorded uploaded speck would associated particular feed move speck kitchen would reregister speck associated new feed environmentlocation changed accidentally drop speck sink full water replace new one new one would registered new device different serial number option could associated existing feed old speck one continuous stream data since ' environment measured matters actual device measurement similarly sell speck new owner would register account get new feed channel sensor device measures one aspects environment temperature humidity particle count battery voltage etc considered different channel feed comprises one channels tiles data particular feed ' channel retrieved esdr small chunks json call tiles tile contains 512 data points associated particular starting timestamp duration example tile could represent summary decade ' worth data could contain actual recorded data samples spanning say 1 second eg heart rate data grapher use fetches tiles user pans zooms timelineit requests small subset data needs render plot appropriate analogy panningzooming google mapsthe browser requests map tiles current small region earth ' exploring time esdr also support multitile fetch fetch data multiple channels multiple feeds single get request essential able visualizations lots sensors simultaneously eg air quality cities country data samples stored datastore data entities stored mysql database big win datastore works billions samples time aggregation upon insert yet inserts still fast storing data number different summarization levels thus return summary year ' worth data quickly say five minutes worth summarization computation required fetching tiles visualizations remain responsive fast zoom level ' yet spatiotemporal aggregation ' todo list please see document details use esdr setup install module dependencies npm install install bodytrack datastore following fetch bodytrack datastore terminal window set working directory root esdr repository following git clone httpsgithubcombodytrackdatastoregit follow bodytrack datastore ' build install instructions install mysql necessary esdr tested assumes mysql 56 known issues 55 following create development mysql database user create database exists esdrdev grant privileges esdrdev ' esdrdev ' ' localhost ' identified ' password ' grant selectinsertupdatedeletecreate esdrdev ' esdrdev ' ' localhost ' choose change password make sure matches password configdevjson want able run tests following create test database user create database exists esdrtest grant privileges esdrtest ' esdrtest ' ' localhost ' identified ' password ' grant selectinsertupdatedeletecreate esdrtest ' esdrtest ' ' localhost ' choose change password make sure matches password configtestjson running production following create configprodjson mailconfigprodjson files copy configs need include parts differ configjs following create production database user create database exists esdrprod grant privileges esdrprod ' esdrprod ' ' localhost ' identified ' useagoodpasswordhere ' grant selectinsertupdatedeletecreate esdrprod ' esdrprod ' ' localhost ' make sure user password specify matches configprodjson make sure datastore data directory defined config file exists run nodeenv environment variable may specified running must one dev development test prod production defaults dev unspecified run server development mode following npm start nodeenvdev npm start nodeenvdevelopment npm start run server test mode nodeenvtest npm start run server production mode either following nodeenvprod npm start nodeenvproduction npm start development generate css scss template npm runscript gencss compile handlebars templates npm runscript genhandlebars\n",
      "  (0, 141)\t0.13477066113690375\n",
      "  (0, 139)\t0.11277722827718385\n",
      "  (0, 137)\t0.1242596213655105\n",
      "  (0, 134)\t0.14025472035089853\n",
      "  (0, 132)\t0.13477066113690375\n",
      "  (0, 131)\t0.11277722827718385\n",
      "  (0, 129)\t0.08431006330951936\n",
      "  (0, 126)\t0.12295572017716598\n",
      "  (0, 124)\t0.10630349616923927\n",
      "  (0, 123)\t0.12993337808871483\n",
      "  (0, 122)\t0.13651856057096237\n",
      "  (0, 121)\t0.12843977939116075\n",
      "  (0, 120)\t0.13148335213860357\n",
      "  (0, 118)\t0.12046590104675191\n",
      "  (0, 116)\t0.11178755538323404\n",
      "  (0, 113)\t0.12560628095201926\n",
      "  (0, 112)\t0.10223388851377806\n",
      "  (0, 110)\t0.11589792675194457\n",
      "  (0, 109)\t0.13477066113690375\n",
      "  (0, 108)\t0.12843977939116075\n",
      "  (0, 105)\t0.1098770044980569\n",
      "  (0, 104)\t0.08852601169710964\n",
      "  (0, 100)\t0.12560628095201926\n",
      "  (0, 99)\t0.13651856057096237\n",
      "  (0, 98)\t0.09997261442349625\n",
      "  :\t:\n",
      "  (0, 54)\t0.14025472035089853\n",
      "  (0, 50)\t0.12295572017716598\n",
      "  (0, 49)\t0.11379133999228148\n",
      "  (0, 47)\t0.1030161871709391\n",
      "  (0, 45)\t0.09448855520950149\n",
      "  (0, 44)\t0.09199873607908741\n",
      "  (0, 42)\t0.10895405694409256\n",
      "  (0, 41)\t0.057373613569478864\n",
      "  (0, 40)\t0.09997261442349625\n",
      "  (0, 36)\t0.11589792675194457\n",
      "  (0, 35)\t0.1242596213655105\n",
      "  (0, 34)\t0.1242596213655105\n",
      "  (0, 32)\t0.12843977939116075\n",
      "  (0, 29)\t0.12843977939116075\n",
      "  (0, 27)\t0.12046590104675191\n",
      "  (0, 26)\t0.07698950866982654\n",
      "  (0, 25)\t0.12699859861741292\n",
      "  (0, 22)\t0.09713911598435479\n",
      "  (0, 21)\t0.13148335213860357\n",
      "  (0, 19)\t0.11811843712897706\n",
      "  (0, 17)\t0.12699859861741292\n",
      "  (0, 14)\t0.11699317666477413\n",
      "  (0, 11)\t0.12699859861741292\n",
      "  (0, 9)\t0.1216919454577947\n",
      "  (0, 4)\t0.12046590104675191\n",
      "enviro mqtt logger enviroplusmqtt python service publishes environmental data enviro via mqtt setting device set rpi normally would connect enviro board pms5003 sensor using one install enviro library following instructions httpsgithubcompimoronienviropluspython make sure library installed python 3 clone repository usrsrcenviroplusmqtt sudo git clone httpsgithubcomhotplotenviroplusmqtt usrsrcenviroplusmqtt add new file etcsystemdsystemenvloggerservice following content unit descriptionenviro mqtt logger afternetworktarget service execstartusrbinpython3 usrsrcenviroplusmqttsrcmainpy arguments workingdirectoryusrsrcenviroplusmqtt standardoutputinherit standarderrorinherit restartalways userpi install wantedbymultiusertarget note must replace arguments flags appropriate mqtt server enable start service sudo systemctl enable envloggerservice sudo systemctl start envloggerservice supported arguments mqtt host port username password client id specified update interval specified defaults 5 seconds initial delay publishing readings specified defaults 15 seconds using pms5003 sensor enable passing usepms5003 flag usage mainpy h host p port u username p password prefix prefix clientid clientid interval interval delay delay usepms5003 help optional arguments h host host host mqtt host connect p port port port port mqtt host connect u username username username mqtt username connect p password password password password connect prefix prefix topic prefix use publishing readings ie ' loungeenviroplus ' clientid clientid mqtt client identifier use connecting interval interval duration seconds updates delay delay duration seconds allow sensors stabilise starting publish readings usepms5003 set pm readings taken pms5003 sensor help print help message exit published topics readings published following topics prefixproximity prefixlux prefixtemperature prefixpressure prefixhumidity prefixgasoxidising prefixgasreducing prefixgasnh3 prefixparticulate10 prefixparticulate25 prefixparticulate100\n",
      "  (0, 133)\t0.12990351738523248\n",
      "  (0, 129)\t0.13530260257869134\n",
      "  (0, 128)\t0.19332626846423315\n",
      "  (0, 127)\t0.2250837912166585\n",
      "  (0, 121)\t0.20612291989934797\n",
      "  (0, 119)\t0.2250837912166585\n",
      "  (0, 118)\t0.19332626846423315\n",
      "  (0, 112)\t0.16406714269531497\n",
      "  (0, 111)\t0.21628285506239323\n",
      "  (0, 110)\t0.18599548508750888\n",
      "  (0, 109)\t0.21628285506239323\n",
      "  (0, 108)\t0.20612291989934797\n",
      "  (0, 98)\t0.1604382014094371\n",
      "  (0, 96)\t0.1616257851933512\n",
      "  (0, 79)\t0.18599548508750888\n",
      "  (0, 78)\t0.1604382014094371\n",
      "  (0, 71)\t0.21100731089256522\n",
      "  (0, 70)\t0.15480151049047308\n",
      "  (0, 61)\t0.2085198792071035\n",
      "  (0, 60)\t0.2190879216605018\n",
      "  (0, 58)\t0.15267522555414736\n",
      "  (0, 52)\t0.20157566067347077\n",
      "  (0, 50)\t0.19732198374508267\n",
      "  (0, 49)\t0.1826147893561602\n",
      "  (0, 47)\t0.16532259240265437\n",
      "  (0, 44)\t0.14764154997432227\n",
      "  (0, 41)\t0.09207440880213551\n",
      "  (0, 26)\t0.12355441907379155\n",
      "  (0, 14)\t0.18775316569955974\n",
      "  (0, 1)\t0.17939907272674765\n",
      "ceqr app ceqr app collection data tools whose purpose improve accuracy speed environmental review getting started ceqr app runs rails api ember frontend two ways run app run locally use docker architecture todo\n",
      "  (0, 129)\t0.32516870912991563\n",
      "  (0, 126)\t0.47421803804569\n",
      "  (0, 104)\t0.3414288617278119\n",
      "  (0, 41)\t0.22127968038661894\n",
      "  (0, 26)\t0.2969346501236385\n",
      "  (0, 5)\t0.4469974016554701\n",
      "  (0, 4)\t0.4646152546907367\n",
      "repo hosts kaspermarstalgithubio\n",
      "\n",
      "fall 2019 department atmospheric science university utah atmos 5020 environmental programming repository contains lecture notes inclass exercises code data information check canvas page check understanding quizzes assignments homework general information download repository command line navigate desktop cd desktop type following command line git clone httpsgithubcomjohnhorelatmos50202019 download zip file update repository cd atmos50202019 directory type git pull note windows pc need download install git windows use command prompt view jupyter notebooks python notebooks render github ' copy notebook url view nbviewer httpsnbviewerjupyterorg alternatively download notebook right clicking ' raw ' button selecting ' save ' open notebook jupyter lab schedule date topics aug 20 introduction set computers aug 22 programming concepts linux shell scripts aug 27 shell scripts working chpc machine aug 29 html make webpage sep 3 introduction python sep 5 part 2 python jupyter lab loops statements etc sep 10 python functions matplotlib sep 12 supplemental python pandas sep 17 python advanced matplotlib datetime 2d plots etc sep 19 pyhton plotting goes data reading example docs online quick guides log onto chpc computers ssh uxxxxxxxmeteo07chpcutahedu linux cheatsheet 1 linux cheatsheet 2 python cheatsheet numpy cheatsheet matplotlib cheatsheet jupyter notbook shortcuts markdown formatting notes written markdown basic vi commands another vi cheat sheet setting personal computer logon chpc windows user want log onto chpc resources must install putty xming follow instructions logging mac users use terminal like classroom install python recommended way install python personal computer anaconda distribution service install packages anaconda navigator tool environments tab brian ' instructions give details install python anaconda personal computer unidata workshop also instructions set environment also recommend install good text editor like vscode available download anaconda launcher learn python purpose class introduce programming principles programming skill improve hours hours practice plan using python class highly recommended learn resources use classes use capstone research project several free python learning courses really help learn python like codecademy version 2 lot free stuff ' pretty close version 3 unidata training another useful resource\n",
      "  (0, 141)\t0.16845634790567546\n",
      "  (0, 138)\t0.17292304827803343\n",
      "  (0, 137)\t0.15531809246014094\n",
      "  (0, 136)\t0.13505864953020363\n",
      "  (0, 133)\t0.10117802501037293\n",
      "  (0, 131)\t0.14096569566576755\n",
      "  (0, 129)\t0.10538321350513045\n",
      "  (0, 127)\t0.1753111379548953\n",
      "  (0, 125)\t0.16845634790567546\n",
      "  (0, 112)\t0.12778706690273267\n",
      "  (0, 111)\t0.16845634790567546\n",
      "  (0, 102)\t0.17064113169084075\n",
      "  (0, 98)\t0.1249605913801733\n",
      "  (0, 96)\t0.12588556542405885\n",
      "  (0, 90)\t0.11277742712257131\n",
      "  (0, 85)\t0.15210863053148121\n",
      "  (0, 82)\t0.1397286557942582\n",
      "  (0, 79)\t0.14486640716735308\n",
      "  (0, 76)\t0.1361869294657858\n",
      "  (0, 70)\t0.12057033878152029\n",
      "  (0, 65)\t0.16434738187687056\n",
      "  (0, 64)\t0.13505864953020363\n",
      "  (0, 61)\t0.16240999457320815\n",
      "  (0, 58)\t0.118914238047706\n",
      "  (0, 56)\t0.1361869294657858\n",
      "  (0, 52)\t0.157001347212338\n",
      "  (0, 51)\t0.16434738187687056\n",
      "  (0, 50)\t0.15368828349159055\n",
      "  (0, 49)\t0.14223328279825312\n",
      "  (0, 48)\t0.16636076426555277\n",
      "  (0, 47)\t0.12876489971623348\n",
      "  (0, 44)\t0.11499365634244461\n",
      "  (0, 42)\t0.1361869294657858\n",
      "  (0, 41)\t0.0717140461175596\n",
      "  (0, 40)\t0.1249605913801733\n",
      "  (0, 38)\t0.15874167219893515\n",
      "  (0, 36)\t0.14486640716735308\n",
      "  (0, 32)\t0.1605430735408104\n",
      "  (0, 26)\t0.09623289926875606\n",
      "  (0, 21)\t0.16434738187687056\n",
      "  (0, 19)\t0.14764193015912325\n",
      "  (0, 16)\t0.157001347212338\n",
      "  (0, 15)\t0.11499365634244461\n",
      "  (0, 14)\t0.14623541284561306\n",
      "  (0, 13)\t0.16845634790567546\n",
      "  (0, 12)\t0.16434738187687056\n",
      "  (0, 10)\t0.15210863053148121\n",
      "  (0, 7)\t0.14096569566576755\n",
      "environmental map python configuration environment variables overview environmental allows map class properties environment variables using environmental keep configuration single class ide understands convenient safe type conversions strings stored environment python types created properties also writable assign change environment available child processes installation sudo pip3 install upgrade environmental example import environmental import os class configuration port environmentalint ' myapplicationhttpport ' 80 name environmentalstr ' myapplicationname ' ' name ' config configuration configport 8080 assert osenviron ' myapplicationhttpport ' ' 8080 ' assert isinstanceosenviron ' myapplicationhttpport ' str assert configport 8080 assert isinstanceconfigport int caveats modifying mutable objects configuration like lists work import os environmental class configuration list environmentallist ' list ' osenviron ' list ' assert configlist configlistappend ' test ' assert configlist something reassigns variable configlist ' test ' assert configlist ' test ' license copyright 2015 zalando se licensed apache license version 20 license may use file except compliance license may obtain copy license httpwwwapacheorglicenseslicense20 unless required applicable law agreed writing software distributed license distributed basis without warranties conditions kind either express implied see license specific language governing permissions limitations license\n",
      "  (0, 140)\t0.1851626057921095\n",
      "  (0, 136)\t0.18208612494286308\n",
      "  (0, 133)\t0.13640825350760571\n",
      "  (0, 129)\t0.14207769030656817\n",
      "  (0, 123)\t0.21896121919398778\n",
      "  (0, 119)\t0.236354545825603\n",
      "  (0, 117)\t0.20720260484942618\n",
      "  (0, 115)\t0.1900500068891505\n",
      "  (0, 100)\t0.21166927867371\n",
      "  (0, 96)\t0.16971896930734534\n",
      "  (0, 66)\t0.20300680973975274\n",
      "  (0, 64)\t0.18208612494286308\n",
      "  (0, 63)\t0.19351119925279495\n",
      "  (0, 59)\t0.1900500068891505\n",
      "  (0, 58)\t0.16032022296948634\n",
      "  (0, 44)\t0.15503449315717038\n",
      "  (0, 42)\t0.18360727240017566\n",
      "  (0, 41)\t0.09668490546101578\n",
      "  (0, 40)\t0.1684719189339727\n",
      "  (0, 23)\t0.2050729161011575\n",
      "  (0, 21)\t0.22157320552632928\n",
      "  (0, 18)\t0.21166927867371\n",
      "  (0, 17)\t0.21401558551190958\n",
      "  (0, 13)\t0.22711291515847415\n",
      "  (0, 11)\t0.21401558551190958\n",
      "  (0, 7)\t0.1900500068891505\n",
      "  (0, 2)\t0.2300584415254454\n",
      "metabeat metabarcoding environmental dna analysis tool reproducible pipeline analysis metabarcoding data generated either sanger ngs approaches metabeat using number external programs make life easier created self contained environment necessary pieces software docker image image building reprophylo want use ' need docker installed machine use image run metabeat script container process data current working directory subdirectories sudo docker run rm nethost name metabeat v pwdhomeworking chrishahmetabeat metabeatglobalpy h terminal window mount docker container current working directory enter self contained environment using shell sudo docker run nethost name metabeat v pwdhomeworking chrishahmetabeat binbash access container via jupyter notebook simply running startmetabeatnb providing full path desired mounting point script eg startmetabeatnb pwd xt open jupyter notebook new tab default browser first notify connection private click advanced bottom left proceed local host unsafe asked provide password simply password entering password correctly open jupyter notebook good go done stop container simply running stopmetabeatnb within environment execute scripts come metabeat eg metabeatglobalpy executing script without options usually display usage eg usage metabeatglobalpy h q file v f p b string n int e e pcrprimer file trimadapter file trimqual int trimwindow int trimminlength int merge productlength int phred int r file gbout file reccheck cluster clustmatch float clustcov int www minident float minbit int refpkg dir outputprefix metadata metadata mockmetadata version metabeat metabarcoding environmental dna analyses tool optional arguments h help show help message exit q file querylist file file containing list query files v verbose turn verbose output seqinfo write seqinfocsv file f fasta write reffasta file p phyloplace perform phylogenetic placement taxids write taxidtxt file b blast compile local blast db blast queries string marker string marker id default marker n int nthreads int number threads default 1 e extractcentroidreads extract centroid reads files e extractallreads extract reads files version show program ' version number exit query preprocessing parameters group affect query sequences processed pcrprimer file pcr primers provided fasta file clipped reads trimadapter file trim adapters provided file trimqual int minimum phred quality score default 30 trimwindow int sliding window size default 5 trimming average quality drops specified minimum quality subsequent bases removed reads trimminlength int minimum length reads retained trimming default 50 merge attempt merge pairedend reads productlength int estimated length pcr product default 100 phred int phred quality score offset 33 64 default 33 reference parameters group affect reference used analyses r file reflist file file containing list files used reference sequences gbout file output corrected gb file reccheck check records used reference query clustering options parameters group affect read clustering cluster perform clustering query sequences using vsearch clustmatch float identity threshold clustering percent default 1 clustcov int minimum number records cluster default 1 blast search parameters group affect blast search blast based taxonomic assignment www perform online blast search nt database minident float minimum identity threshold percent default 095 minbit int minimum bitscore default 80 phylogenetic placement parameters group affect phylogenetic placement refpkg dir path refpkg biom output arguments groups affect output biom format outputprefix outputprefix outputprefix prefix biom output files default ' metabeat ' metadata metadata comma delimited file containing metadata optional mockmetadata add mock metadata samples biom output versions v 06 docker image version chrishahmetabeatv06 used kitson et al 2015\n",
      "  (0, 141)\t0.17130282657132323\n",
      "  (0, 137)\t0.1579425684271995\n",
      "  (0, 136)\t0.13734079306043254\n",
      "  (0, 133)\t0.10288767319641616\n",
      "  (0, 130)\t0.12260766715363776\n",
      "  (0, 129)\t0.1071639185523972\n",
      "  (0, 128)\t0.15312048765426148\n",
      "  (0, 125)\t0.17130282657132323\n",
      "  (0, 119)\t0.17827344492784752\n",
      "  (0, 115)\t0.1433476530706941\n",
      "  (0, 107)\t0.17130282657132323\n",
      "  (0, 106)\t0.17352452757872944\n",
      "  (0, 105)\t0.1396612681641963\n",
      "  (0, 104)\t0.11252268038810113\n",
      "  (0, 97)\t0.15965426585193782\n",
      "  (0, 93)\t0.16712442959328863\n",
      "  (0, 92)\t0.1579425684271995\n",
      "  (0, 89)\t0.17584500268249323\n",
      "  (0, 88)\t0.163255838238804\n",
      "  (0, 84)\t0.15628521988227972\n",
      "  (0, 82)\t0.1420897104095506\n",
      "  (0, 80)\t0.15312048765426148\n",
      "  (0, 78)\t0.1270721037205071\n",
      "  (0, 76)\t0.13848813802268448\n",
      "  (0, 70)\t0.12260766715363776\n",
      "  (0, 67)\t0.1691718329618058\n",
      "  (0, 66)\t0.15312048765426148\n",
      "  (0, 60)\t0.17352452757872944\n",
      "  (0, 53)\t0.1691718329618058\n",
      "  (0, 52)\t0.15965426585193782\n",
      "  (0, 45)\t0.12010148536398281\n",
      "  (0, 44)\t0.11693675313596458\n",
      "  (0, 41)\t0.07292582890187602\n",
      "  (0, 40)\t0.1270721037205071\n",
      "  (0, 36)\t0.14731427655605553\n",
      "  (0, 28)\t0.14870641490639802\n",
      "  (0, 27)\t0.15312048765426148\n",
      "  (0, 26)\t0.09785898755873446\n",
      "  (0, 25)\t0.16142399785113637\n",
      "  (0, 23)\t0.15467887485323986\n",
      "  (0, 12)\t0.16712442959328863\n",
      "  (0, 8)\t0.14595830176403526\n",
      "  (0, 3)\t0.16712442959328863\n",
      "  (0, 1)\t0.1420897104095506\n",
      "  (0, 0)\t0.1691718329618058\n",
      "environmentalicious quite tasty looks decent mobile well synopsis environmentalicious web application allows users locate environmental conservation sustainability events community users create account register attend events believe interesting first release candidate application exhibits main core functionalities current state system user able create events find events relative locations search events based criteria event name event description tags may also join events invite friends become event participants installationrunning would like view application without installing server local machine may navigate httpsalsaritedu3000 link may always available please follow instructions install local machine cannot access deployed version order load application locally nodejs must installed local system recent version nodejs 01033 time writing found httpnodejsorg nodejs environment installed open command prompt terminal move root directory project order install dependencies project first type ' npm install ' completed run command ' node serverjs ' navigate browser httplocalhost3000 npm install node serverjs application usage creating event navigate ' create event ' section left hand bar bar home screen login enter desired event information select ' create event ' button finding already created event navigate ' find event ' section left hand bar home screen login enter information event name event location keyword found description event would like attend click ' find event ' button locate result left hand portion screen may click events navigate main event section page joining event main page specific event would like join click ' join event ' button bottom screen pop notify successfully joined event return individual event page able see participant event inviting friends event provide valid line separated email addresses invite friends text box click ' invite friends ' button alert notify friends successfully invited event recieve email letting know marked potential participant known bugs user authentication login functionality selecting ' log ' button main page direct user web application default account contributors danielle gonzalez justin peterson richie kapadia joe ksiazek\n",
      "  (0, 139)\t0.15443983684497353\n",
      "  (0, 136)\t0.14796816842164828\n",
      "  (0, 131)\t0.15443983684497353\n",
      "  (0, 128)\t0.16496888944030774\n",
      "  (0, 124)\t0.14557455308332873\n",
      "  (0, 117)\t0.16837850737602747\n",
      "  (0, 110)\t0.15871339606119972\n",
      "  (0, 107)\t0.1845581704341597\n",
      "  (0, 104)\t0.12122964016667381\n",
      "  (0, 92)\t0.17016410088516176\n",
      "  (0, 90)\t0.1235572056190368\n",
      "  (0, 85)\t0.1666478640143304\n",
      "  (0, 83)\t0.16837850737602747\n",
      "  (0, 82)\t0.15308455508635607\n",
      "  (0, 68)\t0.18226228139571657\n",
      "  (0, 67)\t0.18226228139571657\n",
      "  (0, 65)\t0.1800564507775222\n",
      "  (0, 64)\t0.14796816842164828\n",
      "  (0, 61)\t0.1779338791995932\n",
      "  (0, 60)\t0.18695178577247926\n",
      "  (0, 58)\t0.13028060079365736\n",
      "  (0, 56)\t0.14920429447589\n",
      "  (0, 41)\t0.07856880022888017\n",
      "  (0, 40)\t0.13690489202822387\n",
      "  (0, 36)\t0.15871339606119972\n",
      "  (0, 30)\t0.19206817243718707\n",
      "  (0, 29)\t0.17588850937905484\n",
      "  (0, 28)\t0.1602132575175048\n",
      "  (0, 25)\t0.17391492191851998\n",
      "  (0, 24)\t0.18945181830702915\n",
      "  (0, 23)\t0.1666478640143304\n",
      "  (0, 22)\t0.1330246314177578\n",
      "  (0, 16)\t0.17200824876858875\n",
      "  (0, 8)\t0.15725249648482348\n",
      "  (0, 7)\t0.15443983684497353\n",
      "  (0, 6)\t0.1666478640143304\n",
      "  (0, 2)\t0.18695178577247926\n",
      "  (0, 0)\t0.18226228139571657\n",
      "making sense onboarding marking sense onboarding project means alleviate issue abandonment iot devices related citizen science civil sensing onboaridng used making sense means test effectiveness building communities around grassroots initiatives currently supporting smartcitizen api new smartcitizen kit 15 web app aims solve key issues setup open data sensors within grassroots smartcity communities developing cognitive goals fostering ownership creating context showing playful animations simplifying language multilingual experience helps reduce bottleneck nontechnical citizens installing iot devices tool currently used eu research project current link livedeployment updates handled fork moved master prerequisites need git clone repository get git httpgitscmcom also use number nodejs tools initialize test web app must nodejs package manager npm installed get httpnodejsorg also gulp npm install g gulp sudo using mac clone project clone repository using git clone httpsgithubcomfablabbcnsmartcitizenonboardinggit cd smartcitizenweb install dependencies install tools manage test application npm install need bower install npm install take care use gulp tasks gulp gulp build build optimized version application dist gulp serve launch browser sync server source files gulp servedist launch server optimized application gulp test launch unit tests karma gulp testauto launch unit tests karma watch mode gulp protractor launch e2e tests protractor gulp protractordist launch e2e tests protractor dist files gulp deploy publish project github pages ghpages branch note case see something like error command failed fatal unable read c6a8d370f3e95d9110eca4a03b704bd8940ca40b run rm rf node e consolelogrequire ' path ' joinrequire ' os ' tmpdir ' tmprepo ' work process final documentation coming soon support issues forum forumsmartcitizenme credits work received funding european union ' horizon 2020 research innovation program grant agreement 688620\n",
      "  (0, 140)\t0.13806369269437105\n",
      "  (0, 139)\t0.14170790930198135\n",
      "  (0, 136)\t0.13576976134287905\n",
      "  (0, 133)\t0.10171074830516609\n",
      "  (0, 130)\t0.12120516663196937\n",
      "  (0, 129)\t0.10593807798986998\n",
      "  (0, 126)\t0.15449748419247747\n",
      "  (0, 125)\t0.16934330552988222\n",
      "  (0, 123)\t0.16326511689258044\n",
      "  (0, 120)\t0.1652127049423791\n",
      "  (0, 119)\t0.1762341874709903\n",
      "  (0, 116)\t0.14046435615887892\n",
      "  (0, 113)\t0.15782799188113192\n",
      "  (0, 110)\t0.14562915885896918\n",
      "  (0, 109)\t0.16934330552988222\n",
      "  (0, 104)\t0.1112355413240646\n",
      "  (0, 102)\t0.1715395926549904\n",
      "  (0, 98)\t0.12561853482147417\n",
      "  (0, 97)\t0.15782799188113192\n",
      "  (0, 90)\t0.11337122367620905\n",
      "  (0, 89)\t0.17383352400648241\n",
      "  (0, 88)\t0.1613883661335855\n",
      "  (0, 82)\t0.14046435615887892\n",
      "  (0, 80)\t0.15136895311487483\n",
      "  (0, 79)\t0.14562915885896918\n",
      "  (0, 78)\t0.12561853482147417\n",
      "  (0, 76)\t0.13690398190642536\n",
      "  (0, 64)\t0.13576976134287905\n",
      "  (0, 60)\t0.1715395926549904\n",
      "  (0, 58)\t0.11954034618417238\n",
      "  (0, 51)\t0.1652127049423791\n",
      "  (0, 50)\t0.15449748419247747\n",
      "  (0, 49)\t0.14298217054372714\n",
      "  (0, 45)\t0.1187276528803661\n",
      "  (0, 37)\t0.15613587444341123\n",
      "  (0, 29)\t0.1613883661335855\n",
      "  (0, 26)\t0.09673958545047086\n",
      "  (0, 25)\t0.15957748003987812\n",
      "  (0, 24)\t0.17383352400648241\n",
      "  (0, 16)\t0.15782799188113192\n",
      "  (0, 14)\t0.14700537263617594\n",
      "  (0, 10)\t0.15290951403177586\n",
      "  (0, 9)\t0.15290951403177586\n",
      "  (0, 6)\t0.15290951403177586\n",
      "  (0, 5)\t0.14562915885896918\n",
      "  (0, 4)\t0.15136895311487483\n",
      "grasp planner based environmental constraint exploitation caution plan running specific branch please read readmemd branch readmemd valid current branch table contents overview structure interfaces flow information list controllers primitives ecs hardware dependencies install minimal dependencies dependencies running gazebo example grasp planner usage examples planning based pcd input planning based continuous rgbd input kuka arm gazebo simulation trik controller using rosservice call planner overview planning framework generates contactrich motion sequences grasp objects within planning framework propose novel view grasp planning centers exploitation environmental contact view grasps sequences constraint exploitations ie consecutive motions constrained features environment ending grasp able generate grasp plans becomes necessary consider planning perception control tightly integrated components result components simplified still yielding reliable grasping performance implementation based clemens eppner oliver brock planning grasp strategies exploit environmental constraints proceedings ieee international conference robotics automation icra pp 4947 4952 2015 structure interfaces flow information structure planning framework consists visual processing component planning module visual processing component detects planar surfaces convex concave edges point cloud represents graph structure component based ecto computation graph framework cpython computations organized directed acyclic graph computing cells connected typed edges single computing cells simple operations clustering segmentation fitting models following diagram shows computation graph grasp planning framework segmentation soup generated different segmentation algorithms based depth color segments planes edges fitted final output geometry graph describes spatial structure environment planning module takes spatial graph input combines information object pose type robotic hand arm planning problem planning problem represented stripslike fashion solved using search output planner sequence motions interspersed contact sensor events summing input planning framework given point cloud provided either real rgbd sensor see example 2 recorded point cloud see example 1 even simulated sensor see example 3 object pose optional also provided ecto graph computation using simple heuristic select point cluster closest largest planar surface scene hand robotspecific information defines particular hand slides across surface closes fingers etc also includes robotspecific things ft sensor thresholds velocities new hands andor arms easily extended usual output robot motion planner jointconfiguration trajectories planner different outputs socalled hybrid automata hybrid automaton finite state machine whose states continuous feedback controllers based position velocity force etc transitions discrete sensor events position trajectories lack expressive power needed capture feedbackdriven contactrich motions considered hybrid automata much suited context consequence entity wants execute generated plans needs capable interpreting hybrid automata descriptions use c library allows serializationdesirialization used wrap robotspecific interfaces shown example 3 primitives controllers jump conditions list primitives positioning sliding caging edgegrasp wallgrasp surfacegrasp primitives based clemens eppner oliver brock planning grasp strategies exploit environmental constraints list controllers joint controller operational space controller sliding controller rbohand controller pisaiithand controller list jump conditions time based ft measurement based joint configuration based frame pose based list ecs surface edge wall hardware dependencies table lists tested hardware dependencies planner soma partner tested tested simulation gazebo f failed tub unipi iit ocado disney hand rbo hand2 pisa iit hand rbo hand2 tpisaiit handrbo hand2 v2 pisaiit hand v2 pisaiit softgripper arms wam kuka iiwa kuka lbr iiwa14 staubli rx160l forcetorque sensor ati ftngamma sensors optoforce hex70xe200n rgbd sensor asus xtion pro live primesense carmine 1089t kinect v2 api rosmoveit install code tested ros indigo ubuntu 14045 lts follow build instructions need build catkin tools aptget install pythoncatkintools minimal dependencies clone repository git clone httpsgithubcomsomaprojectecgraspplannergit build geometry messages ' build projects form repository yet catkin build geometrygraphmsgs clone ros stack ectorbo catkin workspace build git clone httpsgithubcomsomaprojectvisiongit follow instructions httpsgithubcomsomaprojectvisionblobmasterreadmemd get pyddl pip install e githttpsgithubcomgarydoranjrpyddlgiteggpyddl get ros package hybridautomatonmsgs git clone httpsgithubcomturbohybridautomatonmsgsgit dependencies running gazebo example get ros package hybridautomatonmanagerkuka kuka interface needed git clone httpsgithubcomsomaprojecthybridautomatonmanagerkukagit get gazebo multirobot simulator version 226 sudo aptget install rosindigogazebo get iiwastack git clone httpsgithubcomsalvovirgaiiwastackgit cd iiwastack git checkout 94670d70b9bfbf0920c7de539012c805734fdbc5 catkin build iiwa get hybridautomatonlibrary install following readme instructions build hybridautomatonmanagerkuka according instructions forget link robot files grasp planner clone repository catkin workspace build ros package git clone httpsgithubcomsomaprojectecgraspplannergit cd ecgraspplanner git submodule init git submodule update catkin build ecgraspplanner starting planner node plannerpy h rosservicecall fileoutput rvizrobotbaseframe robotbaseframe objectframe objectframe objectparamsfile find path graph turn hybrid automaton optional arguments h help show help message exit rosservicecall whether send hybrid automaton ros service called updatehybridautomaton default false fileoutput whether write hybrid automaton file called hybridautomatonxml default false rviz whether send marker messages seen rviz represent chosen grasping motion default false robotbaseframe robotbaseframe name robot base frame default baselink objectframe objectframe name object frame default object objectparamsfile name file containing parameters objectec selection multiple objects present default objectparamyaml start planner node waits service call calling service step 1 start planner background simulation rosrun ecgraspplanner plannerpy rviz fileoutput robotbaseframe world real world demo rbo lab use instead rosrun ecgraspplanner plannerpy rviz fileoutput step 2 call rosservice rosservice call rungraspplanner objecttype ' apple ' grasptype ' surfacegrasp ' handarmtype ' rbohand2kuka ' objectheuristicfunction random objecttype specified certain objectspecific behaviours right default behaviour objects grasptype one anyedgegraspwallgraspsurfacegrasp version surfacegrasp wallgrasp supported handarmtype match specific robothand combination ie rbohand2kuka rbo hand mounted omn kuka iiwa value must match one class names handarmparameterspy objectheuristicfunction one random deterministic probabilistic parameter selects one three heuristic functions multiobject multiec selection planner assumes ec exploitable objects multiobjectec heuristics random select one objectecpair randomly independent heuristic values deterministic pick maximum heuristic function objectec argmax qobjecti ecj 1n j 1m q taken parameter file multiobjectparamspy contains probability values given objects usecase relevant strategies surface wall edgegrasp default parameter file dataobjectparamyaml probabilistic use heuristic function prior sampling random strategies samples pdf given qn x matrix qij qobjecti ecj simple example objectparams apple surfacegrasp ' success ' 1 success rate surface grasping apple 100 wallgrasp ' success ' 1 success rate wall grasping apple 100 edgegrasp ' success ' 0 success rate edge grasping apple 0 advanced objectec relational parameter definition cucumber surfacegrasp ' success ' 1 ' min ' 014 01 ' max ' 014 005 wallgrasp ' success ' 1 08 07 0 ' angle ' 0 180 360 ' epsilon ' 20 edgegrasp ' success ' 0 objcetifco relative position surfacegrasp strategy success given case 1 object within certain area within ifco min max aprameters defin cropbox inside ifco cropbox helps exclude grasp infeasable due possible collision work space limitation reference frame ifoc frame min vecor min minxdistancex minydistance compare object frame relative ifco frame objectx minxdistance objecty minydistance similarly done max maxxdistancex maxydistance parameter object within cropbox success 0 objectec relative oriantation wallgrasp strategy success depend relative orientation cucumber wall define set possible grasping angles degrees 0 180 360 success rate 1 08 07 angle important last element success rate vector gives success cases epsilon upper lower bound exact orientation 0 precises given angle vector 10 10 deg current orientation reference examples planning based pcd input example shows planned grasp rviz based pcd file contains single colored point cloud tabletop scene banana placed middle roscore want change pcd read change file name ecto graph yaml rosrun ectorboyaml plasmyamlrosnodepy rospack find ecgraspplannerdatageometrygraphexample1yaml debug start visualization rosrun rviz rviz rospack find ecgraspplannerconfigsecgraspsexample1rviz select type grasp want rosrun ecgraspplanner plannerpy rviz robotbaseframe camerargbopticalframe execute grasp rosservice call rungraspplanner objecttype ' apple ' grasptype ' surfacegrasp ' handarmtype ' rbohand2kuka ' rviz able see geometry graph wall grasp published visualizationmsgsmarkerarray topic names geometrygraphmarker plannedgrasppath planning based continuous rgbd input example shows use planner rgbdepth sensor like kinect asus xtion uses camera drivers provided ros plug camera computer roslaunch openni2launch openni2launch depthregistrationtrue set camera resolution qvga rosrun dynamicreconfigure dynparam set cameradriver irmode 7 rosrun dynamicreconfigure dynparam set cameradriver colormode 7 rosrun dynamicreconfigure dynparam set cameradriver depthmode 7 rosrun ectorboyaml plasmyamlrosnodepy rospack find ecgraspplannerdatageometrygraphexample2yaml debug start visualization rosrun rviz rviz rospack find ecgraspplannerconfigsecgraspsexample2rviz select edge grasp visualize result rviz rosrun ecgraspplanner plannerpy robotbaseframe camerargbopticalframe rviz execute grasp rosservice call rungraspplanner objecttype ' punnet ' grasptype ' surfacegrasp ' handarmtype ' rbohand2kuka ' depending input result rviz could look like kuka arm gazebo simulation trik controller example shows execution planned hybrid automaton motion gazebo simulator step 1 make sure simulation time used roslaunch hybridautomatonmanagerkuka launchgazebolaunch step 2 start simulation environment kuka control manager rosrun hybridautomatonmanagerkuka hybridautomatonmanagerkuka step 3 run vision code rosrun ectorboyaml plasmyamlrosnodepy rospack find ecgraspplannerdatageometrygraphexample3yaml debug step 4 optional check potential grasps rosrun rviz rviz rospack find ecgraspplannerconfigsecgraspsrviz rviz able see point cloud simulated gazebo geometry graph published visualizationmsgsmarkerarray topic name geometrygraphmarker step 5 select surface grasp visualize execute roscd hybridautomatonmanagerkukatestxmls rosrun ecgraspplanner plannerpy grasp surfacegrasp rosservicecall rviz handarm rbohand2kuka need ctrlc done hasendxmlsh hybridautomatonxml step 6 rviz able see planned surface grasp gazebo robot moves hand towards cylinder contact httpsyoutubeq91u9r83vl0\n",
      "  (0, 140)\t0.1049337037167094\n",
      "  (0, 137)\t0.11866925524484569\n",
      "  (0, 136)\t0.10319022787533243\n",
      "  (0, 135)\t0.12870740961722335\n",
      "  (0, 134)\t0.1339447442838814\n",
      "  (0, 133)\t0.07730407118028824\n",
      "  (0, 132)\t0.12870740961722335\n",
      "  (0, 130)\t0.09212057707632218\n",
      "  (0, 129)\t0.08051700393611085\n",
      "  (0, 128)\t0.11504621213649709\n",
      "  (0, 127)\t0.1339447442838814\n",
      "  (0, 126)\t0.11742401579188964\n",
      "  (0, 124)\t0.10152096539245\n",
      "  (0, 121)\t0.12266135045854772\n",
      "  (0, 119)\t0.1339447442838814\n",
      "  (0, 118)\t0.11504621213649709\n",
      "  (0, 117)\t0.11742401579188964\n",
      "  (0, 114)\t0.13037667210010578\n",
      "  (0, 112)\t0.09763444695383555\n",
      "  (0, 111)\t0.12870740961722335\n",
      "  (0, 109)\t0.12870740961722335\n",
      "  (0, 108)\t0.12266135045854772\n",
      "  (0, 107)\t0.12870740961722335\n",
      "  (0, 105)\t0.1049337037167094\n",
      "  (0, 104)\t0.08454327932475379\n",
      "  :\t:\n",
      "  (0, 49)\t0.10867193559584683\n",
      "  (0, 47)\t0.09838155046183088\n",
      "  (0, 45)\t0.09023757156711629\n",
      "  (0, 44)\t0.08785976791172372\n",
      "  (0, 43)\t0.12556799468660423\n",
      "  (0, 42)\t0.10405227902174087\n",
      "  (0, 41)\t0.0547924089754662\n",
      "  (0, 40)\t0.09547490623377436\n",
      "  (0, 35)\t0.11866925524484569\n",
      "  (0, 29)\t0.12266135045854772\n",
      "  (0, 28)\t0.11172972354952715\n",
      "  (0, 25)\t0.12128500754671172\n",
      "  (0, 20)\t0.13037667210010578\n",
      "  (0, 19)\t0.11280435921778369\n",
      "  (0, 18)\t0.11995532942118052\n",
      "  (0, 15)\t0.08785976791172372\n",
      "  (0, 14)\t0.11172972354952715\n",
      "  (0, 13)\t0.12870740961722335\n",
      "  (0, 12)\t0.12556799468660423\n",
      "  (0, 11)\t0.12128500754671172\n",
      "  (0, 10)\t0.11621709754204312\n",
      "  (0, 9)\t0.11621709754204312\n",
      "  (0, 8)\t0.10966494428716458\n",
      "  (0, 4)\t0.11504621213649709\n",
      "  (0, 2)\t0.13037667210010578\n",
      "environmentalpioneer ui marsblue elisao web ps githubgithub1559830979qqcom\n",
      "  (0, 139)\t1.0\n",
      "metapathways 2 masterworker model environmental pathwaygenome database construction grids clouds niels w hanson kishori konwar shangju wu steven j hallam updates july 7 2015 metapathways v252 release minor bug fixes releated gbk input processing sam file rpkm calculations rrna homology search november 27 2014 metapathways v25 released upgrades pipeline last homology searches blastequivalent output evalues reads per kilobase per million mapped rpkm coverage measure contig annotations calculated raw reads fastq mapping files sam using bwa addition cazy sequence database new compatible functional hierachy gui keywordsearch annotation subsetting projection onto different functional hierarcies kegg cog seed metacyc cazy see release page wiki information abstract development highthroughput sequencing technologies past decade generated tidal wave environmental sequence information variety natural human engineered ecosystems resulting flood infor mation public databases archived sequencing projects exponentially expanded computational resource requirements rendering local homologybased search methods inefficient recently introduced metapathways v10 modular annotation analysis pipeline constructing environmental pathwaygenome databases epgdbs environmental sequence information capable using sun grid engine external resource partitioning however commandline interface facile task management introduced user activation barriers concomitant decrease fault tolerance present metapathways v20 incorporating graphical user interface gui refined task management methods metapathways gui provides intuitive display setup process monitoring supports interactive data visualization subsetting via custom knowledge engine data structure masterworker model adopted task management allowing users scavenge computational results number worker grids ad hoc asynchronous distributed network dramatically increases fault tolerance model facilitates use ec2 instances extending epgdb construction amazon elastic cloud installation metapathways v25 requires python 27 greater pathway tools developed sri international full functionality metapathways python codebase well compiled gui binaries mac osx ubuntu selfcontained github distro gui source code obtained please see metapathways v25 wiki installation details template metapathwaysdbszip updated october 2014 contains starter protein taxonomic databases citation using metapathways reserach work please cite following kishori konwar niels w hanson maya p bhatia dongjae kim shangju wu aria hahn connor morganlang hiu kan cheung steven j hallam metapathways v25 quantitative functional taxonomic usability improvements bioinformatics 13 2015 doi101093bioinformaticsbtv361 niels w hanson kishori konwar shangju wu steven j hallam metapathways v20 masterworker model environmental pathwaygenome database construction grids clouds proceedings 2014 ieee conference computational intelligence bioinformatics computational biology cibcb 2014 honolulu hi usa may 2124 2014 doi101109cibcb20146845516\n",
      "  (0, 140)\t0.1468105079998701\n",
      "  (0, 133)\t0.10815447809862294\n",
      "  (0, 131)\t0.15068559840911458\n",
      "  (0, 129)\t0.11264962382725528\n",
      "  (0, 126)\t0.16428543736846085\n",
      "  (0, 116)\t0.14936326184762735\n",
      "  (0, 113)\t0.16782694430722728\n",
      "  (0, 107)\t0.18007179314154936\n",
      "  (0, 103)\t0.17783171428167593\n",
      "  (0, 101)\t0.1736085301058672\n",
      "  (0, 96)\t0.13456565916554802\n",
      "  (0, 95)\t0.18484648258172942\n",
      "  (0, 94)\t0.17783171428167593\n",
      "  (0, 91)\t0.18484648258172942\n",
      "  (0, 88)\t0.17161288065639813\n",
      "  (0, 85)\t0.16259686377295868\n",
      "  (0, 84)\t0.16428543736846085\n",
      "  (0, 80)\t0.16095870296180573\n",
      "  (0, 78)\t0.13357690607453884\n",
      "  (0, 74)\t0.17567950463498086\n",
      "  (0, 72)\t0.17567950463498086\n",
      "  (0, 67)\t0.17783171428167593\n",
      "  (0, 62)\t0.18240722269770704\n",
      "  (0, 59)\t0.15068559840911458\n",
      "  (0, 57)\t0.17783171428167593\n",
      "  (0, 56)\t0.14557732549845656\n",
      "  (0, 51)\t0.17567950463498086\n",
      "  (0, 47)\t0.1376435300531216\n",
      "  (0, 45)\t0.12624946278660157\n",
      "  (0, 44)\t0.12292272837994644\n",
      "  (0, 41)\t0.0766588913886198\n",
      "  (0, 35)\t0.16602762534234103\n",
      "  (0, 34)\t0.16602762534234103\n",
      "  (0, 33)\t0.18484648258172942\n",
      "  (0, 32)\t0.17161288065639813\n",
      "  (0, 27)\t0.16095870296180573\n",
      "  (0, 26)\t0.10286837478061682\n",
      "  (0, 19)\t0.15782217433277865\n",
      "  (0, 15)\t0.12292272837994644\n",
      "  (0, 3)\t0.17567950463498086\n",
      "urbsville urbanode odyssey urbsville core implementation urbanode project goal world domination taking control physical objects handing steering wheel web system developers designed around nodejs urbsville benefits sharing nearly serverside code clientside blurring lines reality basic usage prefer see code front section else skip architecture heading default server look inside binurbsville would see something looks similar main container named hubhub var hub new urbhub ' hub ' log hub events stdout hubon ' event ' function event consolelogevent run api server named apiserversio using socketio protocol var sioapiprotocol new sioserversioserverprotocol8001 var sioapiserver new apiapiserver ' sio ' sioapiprotocol hub run device server named deviceserversio using socketio protocol var siodeviceprotocol new sioserversioserverprotocol8002 var siodeviceserver new devicedeviceserver ' sio ' siodeviceprotocol hub announce web server via mdns notetermie currently expects nginx serve static content var ad mdnscreateadvertisement ' urbanodeweb ' 8000 sioapiserverlisten siodeviceserverlisten adstart lines fairly self explanatory running leaves empty hub waiting devices connect device server point accessible via api server also announces location network basic api client common client urbsville probably socketio api client accessed via web page one shows totally sweet interface exercising dominance physical realm urbsville makes significant use dojo toolkit javascripty stuff jquery person able mostly ignore play together using directory structure project ' end script srcpublicdojodojojsscript script srcpublicjssocketiojsscript scriptiosetpath ' publicjs ' script script srcpublicjsurbjsscript script require emulates nodejs require function using dojo var sioclient require ' urbprotocolsioclient ' var api require ' urbapi ' var hostname windowlocationhostname var protocol new sioclientsioclientsioclientprotocol hostname port 8001 var client new apiapiclient ' admin ' protocol function newdevicedevice something cool device hook ui clienton ' hubadded ' function hub var devices hubdevices var devices newdevicedevicesd hubon ' deviceadded ' function device newdevicedevice documentready jquery types dojoaddonloadfunction clentconnect script sets api client using socketio protocol demonstrates basic events one handling generate ui device devices simple api act eventemitters nodejs sense basically set modifiable properties suppose device represents basic colored light wanted make background element change whenever light ' color changes var light new coloredlightdevice ' ambientroom ' function setbackgroundcolor listen changes rgb property lighton ' propertyrgb ' function newrgb setbackgroundcolornewrgb change rgb property lightset ' rgb ' 255 200 100 types devices might eventonly like sensor operate way var reader new rfiddevice ' badgereader ' readeron ' rfidadded ' function rfidobject something flashy easily hooked together form sorts wonderful things readeron ' rfidadded ' function rfidobject lightset ' rgb ' 255 0 0 readeron ' rfidremoved ' function rfidobject lightset ' rgb ' 0 0 0 architecture urbsville designed allow styles interactions selfcontained device control device publishing going ' expand components system relate style interaction selfcontained devices hubs urbsville enough operate selfcontained device controller meaning ' provide interfaces interact system listens events devices responds accordingly allowing developer script environment javascript many simple art installations far need go device ' ' device represents basic abstract building block manipulating objects urbsville whichever path go actual physical object talking serial port proprietary network protocol even via http device interface physical object providing world properties events devices like pretty much everything else urbsville eventemitters normal interaction involves listening named events setting properties trigger changes trigger events see device example hub hub also eventemitter main purpose keep track devices hubs also provide way interact devices tracked aggregate forwarding events emitted listeners common practice one hub track devices device controller goal device controller provide interface allow remote controller usually user actively manipulate devices tracked hub using apiserver serverside wrapping hub apiclient clientside providing proxy readily accomplished given transport protocol api server apiserver hub ' main face world provides interface remotely interacting devices tracked hub via transport protocol eg socketio tcp clients connecting apiserver initially given current state system serialized dump hub devices thereafter events hub devices passed along client api client apiclient creates local representation hub devices provided via apiserver transport protocol allows interacted via proxy instances proxy actually two types proxy deviceproxy hubproxy effectively simply intended act exactly like nonproxy counterpart forward write actions across network boundary replay events received boundary proxies built behind scenes example apiclient receives information hub devices server information originating device hub proxied replayed listeners client side properties set client side result rpc actually set server side device publisher ' things twist around bit goal device publisher allow remote devices publish via local hub may turn allow activities control accomplished deviceserver proxying devices provided deviceclient device controller device publisher presents many opportunities organic environment monitoring control device server deviceserver allows remote devices tracked local hub via transport protocol clients connecting deviceserver expected provide serialized device point deviceproxy built deviceserver added hub proxies events generated original device time client side replayed local proxy actions taken result rpcs device client deviceclient wraps local device provides server via transport protocol building running urbsville relies decent number external tools libraries stuff need node 23 httpnodejsorg standard build environment make gcc sort stuff use provided nginx config demo need nginx httpnginxorg use dmx utilities ' need olad httpwwwopendmxnetindexphpopenlightingarchitecture everything order cloning repo running make get set todo ton stuff make urbsville fitter happier productive ' short list make installable maybe npm commandline arguments urbsville script mdnsenabled deviceclient example automatically provide device deviceservers network services advertised mdns static file serving node simple demos small projects device types specific device implementations default html representations devices\n",
      "  (0, 139)\t0.1321960694760773\n",
      "  (0, 138)\t0.16216532111740778\n",
      "  (0, 133)\t0.09488363222380523\n",
      "  (0, 131)\t0.1321960694760773\n",
      "  (0, 129)\t0.09882721145978503\n",
      "  (0, 128)\t0.1412086364202347\n",
      "  (0, 126)\t0.1441271715516188\n",
      "  (0, 124)\t0.1246076409201993\n",
      "  (0, 117)\t0.1441271715516188\n",
      "  (0, 114)\t0.16002536499351236\n",
      "  (0, 112)\t0.11983729725614448\n",
      "  (0, 110)\t0.1358541135571874\n",
      "  (0, 108)\t0.15055551780501616\n",
      "  (0, 106)\t0.16002536499351236\n",
      "  (0, 105)\t0.12879646310111548\n",
      "  (0, 104)\t0.10376909391661956\n",
      "  (0, 94)\t0.15601128378840737\n",
      "  (0, 93)\t0.1541231560642892\n",
      "  (0, 92)\t0.14565558836694148\n",
      "  (0, 91)\t0.16216532111740778\n",
      "  (0, 90)\t0.10576142316622605\n",
      "  (0, 85)\t0.14264579048598824\n",
      "  (0, 83)\t0.1441271715516188\n",
      "  (0, 81)\t0.16216532111740778\n",
      "  (0, 80)\t0.1412086364202347\n",
      "  :\t:\n",
      "  (0, 76)\t0.12771459541532018\n",
      "  (0, 74)\t0.1541231560642892\n",
      "  (0, 70)\t0.11306952948402096\n",
      "  (0, 69)\t0.15601128378840737\n",
      "  (0, 68)\t0.15601128378840737\n",
      "  (0, 67)\t0.15601128378840737\n",
      "  (0, 66)\t0.1412086364202347\n",
      "  (0, 64)\t0.12665650697722008\n",
      "  (0, 62)\t0.16002536499351236\n",
      "  (0, 56)\t0.12771459541532018\n",
      "  (0, 44)\t0.10783977840394245\n",
      "  (0, 42)\t0.12771459541532018\n",
      "  (0, 40)\t0.1171866597887239\n",
      "  (0, 39)\t0.1644048451898889\n",
      "  (0, 36)\t0.1358541135571874\n",
      "  (0, 31)\t0.1472341260467397\n",
      "  (0, 28)\t0.13713795193291184\n",
      "  (0, 25)\t0.14886618356082196\n",
      "  (0, 20)\t0.16002536499351236\n",
      "  (0, 17)\t0.14886618356082196\n",
      "  (0, 15)\t0.10783977840394245\n",
      "  (0, 11)\t0.14886618356082196\n",
      "  (0, 9)\t0.14264579048598824\n",
      "  (0, 4)\t0.1412086364202347\n",
      "  (0, 2)\t0.16002536499351236\n",
      "sustainable communities web challenge saturday sunday january 23 24 2021 ' combining economic envronmental data planning input using epa ' new environmental indicator models choose area compete 10000 awards using new inputoutput widgets create interfaces communities using 24 environmental indicators across 388 industries event register online slack clubs project areas demographics industry analytics impacts machine learning expand upon countybased results provide zipcodebased industry lists details add zipcode demographics using uszipcodereadthedocsio python d3 create update data visualizations interplay demographics industries impacts b supply chain inflowoutflow charts updates sankey d3 charts leaflet maps maps us filters industry impact evaluator create embeddable charts use hash parameters python d3 optionally react details c industry level estimates counties zipcodes fill gaps number establishments provided state level details update data processing script work team zipcode industry data prep python useeio updates bioecomony bioproducts local economy inputs new technology additions useeio details e google sheet crowdsource editor rest process allowing editors return update row contributions see contact us additional details avoid overlaps document team ' times help judges award contributions basis reward team members contribute specific coding areas compliment broad areas specific coding area updates html jquery jam stack development embed customize chart displays using ee inputoutput widgets build location profiles using industry impact evaluator add map search filters apply industry icons charts integrate map samples update useeio widgets embed resource event calendars environmental educators react nodejs updates useeiowidgets react d3 update csv files employment industries d3 charts using census industry data income zipcode zcta work data team choose jamstack editor edit csv files directly github using social logins d3 visualizations leaflet maps visualizations material flow regional inputoutput map starters leaflet route maps driving tours deliveries python rlanguage create update scripts pull data preprocess csv json files industry zip code searches local commodity searchs work useeio api update inputoutput charts widgets loaded json files generated api endpoints aws goods services demand vectors food system full system update django census reporter staring python 3 wazimap fork used africa india integrate us demographic data python 2 version set docker deploy heroku using containerization template learn using heroku aws rstudio useeior use lca methodology evaluate new technologies including advanced biofuels microsoft net add useeio widgets net environmental education tools geep partner states countries google rest app google sheet editor crowdsourcing updates code america brigades often use google sheets maintain directories like maps georgia north carolina social login process needed allow contributors return update google sheet row data online form without access edit rows contributors setup needs take minute per sheet avoid zapier timeintensive approaches specific project tasks maintain list time contributions increase award potential let us know ' working avoid overlaps bubble chart d3 view widget modify popups still appear containing div set positionrelative scale size containing div browser resize set default bubble color red pop omit red scale bubbles highlighted create react version industrylist mosaic react view widget details column selected avoid dimming columns add slidershttpsmaterialuicomcomponentsslider right rows adjust levels multiplier effect done include tabs top 20 categories 388 industry sectors x selected mock upstartdataset show list selected sectors x selected tab include duplicate checkboxes x selected tab display parent naics industry categories open reveal subcategories display quantity selected parent category title parenthesis custom sets could use csvjson format toggle matrices using dropdown menu select matrix list parent category include 3dot menu options sort alphabetical change matrix show values show values like sortable example include verticle column name like dataset example highlight action menu checkboxes clicked actions could include display map display bar chart generate report slider details editable number could appear clicking slider editable number could disappear seconds inactivity slide bar could replace bar currently right rows dot could relative rows matching bar length bar could turn green commodity increased default bar could turn red commodity decreased default sliders used show multiplier effects hash syntax 99 300 adjustment could sectors31161599550000300 impact bar chart react view widget details create example three columns one impact area per colums display sector titles left first column display sector name bar display description indicator update use darkly bootstrap similar bubble chart click bubble view impact chart last airbender potential use elementary school education interface epa indicators could organized air water land fire energy plus two additional categories prosperity economy wellness health airbender categories added primary secondary columns lciaindicatorsetscsv biomodeling branch heres airbender api relating four nation categories characters use bea commodities estimate null industries protect privacy individual firms census omits payroll empolyee count data industries state county level like automobile manufacturing georgia 89 industries number establishments available county state lever estimates omitted industry values could generated using state bea commodity data crosswalk file average states could used long industry least one payroll value another state data integration us bureau economic analysis expand industry level data community info page updates farm fresh federal usda location data maps initially merged aglanta preprocess uszipcode programmable database python github zip map international harmonized system hs code crosswalk event register online slack groups\n",
      "  (0, 141)\t0.14869304522732202\n",
      "  (0, 140)\t0.1212277676865865\n",
      "  (0, 139)\t0.12442759695151093\n",
      "  (0, 136)\t0.11921356560680259\n",
      "  (0, 135)\t0.14869304522732202\n",
      "  (0, 134)\t0.15474363114755793\n",
      "  (0, 133)\t0.08930781674848146\n",
      "  (0, 130)\t0.10642502381419681\n",
      "  (0, 129)\t0.09301965243062808\n",
      "  (0, 127)\t0.15474363114755793\n",
      "  (0, 126)\t0.13565757047588614\n",
      "  (0, 124)\t0.1172851007064392\n",
      "  (0, 117)\t0.13565757047588614\n",
      "  (0, 113)\t0.13858194548338623\n",
      "  (0, 112)\t0.11279508522334937\n",
      "  (0, 107)\t0.14869304522732202\n",
      "  (0, 106)\t0.15062151012768543\n",
      "  (0, 103)\t0.14684331550889743\n",
      "  (0, 96)\t0.11111666794265072\n",
      "  (0, 93)\t0.14506614318917074\n",
      "  (0, 92)\t0.1370961702181069\n",
      "  (0, 90)\t0.09954637673343825\n",
      "  (0, 88)\t0.14170815639612208\n",
      "  (0, 85)\t0.1342632424380224\n",
      "  (0, 82)\t0.1233356866266751\n",
      "  :\t:\n",
      "  (0, 57)\t0.14684331550889743\n",
      "  (0, 55)\t0.15263571220746935\n",
      "  (0, 54)\t0.15474363114755793\n",
      "  (0, 52)\t0.13858194548338623\n",
      "  (0, 51)\t0.14506614318917074\n",
      "  (0, 45)\t0.10424962595500331\n",
      "  (0, 44)\t0.10150259788937387\n",
      "  (0, 42)\t0.12020947571393929\n",
      "  (0, 41)\t0.06330055254886176\n",
      "  (0, 34)\t0.1370961702181069\n",
      "  (0, 32)\t0.14170815639612208\n",
      "  (0, 30)\t0.15474363114755793\n",
      "  (0, 28)\t0.12907907078849992\n",
      "  (0, 27)\t0.1329105424102567\n",
      "  (0, 26)\t0.08494285327459232\n",
      "  (0, 22)\t0.10717400096250342\n",
      "  (0, 15)\t0.10150259788937387\n",
      "  (0, 11)\t0.14011809550183035\n",
      "  (0, 9)\t0.1342632424380224\n",
      "  (0, 7)\t0.12442759695151093\n",
      "  (0, 5)\t0.12787067688844958\n",
      "  (0, 4)\t0.1329105424102567\n",
      "  (0, 3)\t0.14506614318917074\n",
      "  (0, 1)\t0.1233356866266751\n",
      "  (0, 0)\t0.14684331550889743\n",
      "scscore root south coast science environmental monitoring applications contains library classes required libraries third party awsiotpythonsdk pytz tzlocal branches stable branch repository master deployment purposes use git clone branchmaster httpsgithubcomsouthcoastsciencescscoregit\n",
      "  (0, 129)\t0.255174522759635\n",
      "  (0, 100)\t0.3801624804844055\n",
      "  (0, 98)\t0.30257911301637347\n",
      "  (0, 74)\t0.3979501416056578\n",
      "  (0, 50)\t0.37214024026516196\n",
      "  (0, 49)\t0.34440314402457933\n",
      "  (0, 41)\t0.17364812558425\n",
      "  (0, 19)\t0.35749962270633834\n",
      "  (0, 14)\t0.3540938868942428\n",
      "libaudioverse github ' trying raise money project put months fulltime work consequently gofundme introduction libaudioverse highly flexible realtime audio synthesis library designed bound many languages possible potential applications include games realtime music synthesis voice chat implementations webaudio libaudioverse supports best possible backends platform uses sse2 threads increased performance core libaudioverse concept node piece meaningful audio architecture connected acyclic configuration allowing creation much complex effects possible schedule property changes envelopes sampleperfect accuracy complex effects nodes connected directly properties nodes overview offered nodes environment source nodes come together act fully functional 3d audio environment including support hrtf surround sound reverb fdn reverberator environmental reverb capable representing everything bathroom cathedral want play schroeder allpass sections try nested allpass network node variety lowerlevel filters available biquad firstorder onepole convolution possible implement iir filter either cascading lower level filters using iir filter node directly oscillator options include sine square well configurable noise generator several delay line types delay lines offer support feedback filtered delay line allows filtering feedback record audio recorder intercept audio anywhere graph nodes graph listener finally none meet needs possible create node via custom node note prealpha supports windows linux mac planned licensing see file copyright legalese file definitive following summary nonlegalese version libaudioverse duallicensed gpl v3 later see gpl v3 mpl2 documentation examples two sources libaudioverse documentation first languageagnostic manual discusses libaudioverse general perspective manual contains reference c api overview libaudioverse ' core concepts examples manual python second source documentation api reference language choice moment means python api reference api references contain installation instructions notes specific language question examples supported languages may found github repository sets examples aim equivalent demonstrate critical features libaudioverse library easy many cases examples enough get started getting help libaudioverse google group subscribe directly without gmail address via emailing empty email libaudioversesubscribecamlornnet clicking link confirmation email sent prefer questions come via avenue results answers searchable future need contact realtime via libaudioverse irc channel libaudioverse chatfreenodenet please report bugs make feature requests using github issue tracker saves time issues cannot fix immediately building see info supported platforms build instructions bindings moment python c supported languages get python bindings via pip windows linux currently requires building libaudioverse languages become available libaudioverse attempt upload binaries package managers goal minimize number use cases require building libaudioverse libaudioverse ' approach bindings possible add languages short order seriously considering using libaudioverse specific language wish talk addition new language mostly onetime process bindings literally maintain language add next primarily based interest note language must support c callbacks least 2 levels pointer indirection thread primitives order successfully bound libaudioverse language currently aware fails implement three things angelscript bgt scripting environment\n",
      "  (0, 140)\t0.1388205170459603\n",
      "  (0, 137)\t0.1569917651531943\n",
      "  (0, 136)\t0.13651401104088776\n",
      "  (0, 133)\t0.10226829656157929\n",
      "  (0, 132)\t0.1702715954727519\n",
      "  (0, 129)\t0.10651879921801198\n",
      "  (0, 124)\t0.13430568451898436\n",
      "  (0, 120)\t0.16611835215383763\n",
      "  (0, 117)\t0.15534439373121464\n",
      "  (0, 116)\t0.14123434023794215\n",
      "  (0, 103)\t0.1681534302965124\n",
      "  (0, 98)\t0.1263071384964049\n",
      "  (0, 96)\t0.1272420798517254\n",
      "  (0, 90)\t0.11399269121175849\n",
      "  (0, 88)\t0.16227304945017246\n",
      "  (0, 86)\t0.1681534302965124\n",
      "  (0, 83)\t0.15534439373121464\n",
      "  (0, 80)\t0.1521987129710414\n",
      "  (0, 79)\t0.14642745485971365\n",
      "  (0, 78)\t0.1263071384964049\n",
      "  (0, 77)\t0.17720025119170973\n",
      "  (0, 76)\t0.1376544490662867\n",
      "  (0, 70)\t0.12186957752708116\n",
      "  (0, 65)\t0.16611835215383763\n",
      "  (0, 61)\t0.16416008800205886\n",
      "  (0, 59)\t0.14248471017177955\n",
      "  (0, 55)\t0.17478642799972788\n",
      "  (0, 54)\t0.17720025119170973\n",
      "  (0, 52)\t0.158693158278517\n",
      "  (0, 51)\t0.16611835215383763\n",
      "  (0, 47)\t0.13015244120007008\n",
      "  (0, 44)\t0.11623280201727385\n",
      "  (0, 43)\t0.16611835215383763\n",
      "  (0, 41)\t0.07248682048527294\n",
      "  (0, 40)\t0.1263071384964049\n",
      "  (0, 37)\t0.1569917651531943\n",
      "  (0, 31)\t0.158693158278517\n",
      "  (0, 22)\t0.12272724732474945\n",
      "  (0, 19)\t0.1492328862605216\n",
      "  (0, 18)\t0.158693158278517\n",
      "  (0, 9)\t0.15374771878749757\n",
      "  (0, 8)\t0.14507964294160733\n",
      "  (0, 7)\t0.14248471017177955\n",
      "  (0, 4)\t0.1521987129710414\n",
      "  (0, 2)\t0.1724799219946553\n",
      "  (0, 1)\t0.14123434023794215\n",
      "environmentalapp\n",
      "\n",
      "environmentalsound image data gotten es50 environmental sound dataset kaggle method extraction librosa mel spectrograms img h128 x w157 size 16000 processing ximg pickled downloaded resulting files labels stored ypickle\n",
      "  (0, 53)\t0.7028233446776355\n",
      "  (0, 45)\t0.49896088590187415\n",
      "  (0, 41)\t0.3029699098535935\n",
      "  (0, 26)\t0.40655456489807557\n",
      "environmental sensing aws iot project environmental sensing ph various gases particulate matter sound capturing images multipart project demonstrate environmental monitoring using several types sensors aws services first part focuses building hardware monitoring environmental parameters co2 particulate matter sound capturing images project used environmental monitoring several use cases industrial manufacturing distribution warehouses etc first version environmental sensor box software along capable following features sense temperature humidity pressure co2 tvoc proximity range publish aws iot core capture upload images amazon s3 bucket project also uses aws systems manager enable remote access raspberry pi use aws iot rules log data amazon elasticsearch service second version project retains temperature humidity pressure co2 tvoc proximity replaces camera range sensor ph sensor atlas scientific smaller enclosure source code remains applications ph ph sensor used monitor several industrial agricultural parameters dough fermentation soil ph different crops plants need specific levels ph soil hardware mechanical list shelf hardware used build environmental sensing unit raspberry pi zero w sparkfun qwiic kit raspberry pi ultrasonic range finder hrxlmaxsonarvr unit supports camera raspberry pi capture images load aws s3 camera used arducam lens board sku b0031 could use compatible camera well information ph sensor ph reading circuit smaller enclosure atlas scientific spear tip ph probe ezo ph circuit ezo carrier board smaller enclosure please note code tested earlier version spear tip probe ezo circuits however new probe circuit work fine also important note default carrier board uart mode reprogrammed support i2c mode used project carrier board interfaces qwiic cable qwiic hat baseplate designed 3d printed house components following case bought amazoncom universal project enclosure image assembled unit first iteration support pm25 particulate matter 25 sensing see sensor pms7003 camera image image version ph support architecture high level architecture first iterationpart project configure setup aws iot read setting aws iot create thing created thing raspberry pi make sure keys present ' keys ' subfolder also copy sampleenv file env provide specifics need logging data aws iot core prior logging data take sampleenv file copy env make sure al parameters set correctly run script rpiqwiicawsiotpy read sensor data log aws iot core script calls two helper modules imagecapturepy capture image using hte picamera package upload s3 note s3 bucket name specified env file ultrasonicpy script reads value range finder sensor connected two flags used control import execution modules s3enable ultraenable env file want exclude one set flag emptry string module included set ' true ' see example s3enable ' true ' ultraenable ' ' env file configured correctly start tbe execution follows python3 rpiqwiicawsiotpy want run program background ensure keeps running disconnect remote session raspberry pi execute following nohup python3 u rpiqwiicawsiotpy outputlog go test secion aws iot console subscribe topic using topic used testing following telemetrythingname sample output unit timestamp 1583361438 time 03042020 173717 tempc 2763 tempf 81752 humidity 34475 pressure 106863 tvoc 0 co2 400 proximity 2556 ambient 128 image pzb827ebed3f9a1583361438 data using ultrasonic sensor readings data packet also provides image captured filename used store s3 bucket storing data amazon elasticsearch use amazon elasticsearch store transformed data later use visualization setup amazon elasticsearch region used create iot thing elasticsearch setup go aws iot console setup iot rule see image setup specific iot rule used transform incoming packets select topic2 thingname timestamp parsetimeyyyymmdd ' ' hhmmsszz timestamp americanewyork ts tempf tempc humidity pressure co2 ambient tvoc proximity ' telemetry ' rule minor transformation incoming data message output look follows thingname pzb827ebed3f9a timestamp 1583361502 ts 20200304t1738260500 tempf 82058 tempc 2781 humidity 34288 pressure 106548 co2 400 ambient 125 tvoc 0 proximity 2555\n",
      "  (0, 140)\t0.12219550956268574\n",
      "  (0, 137)\t0.13819058701307665\n",
      "  (0, 136)\t0.12016522842991974\n",
      "  (0, 134)\t0.15597892479998504\n",
      "  (0, 133)\t0.09002074676261769\n",
      "  (0, 132)\t0.14988003802028688\n",
      "  (0, 130)\t0.10727459775402325\n",
      "  (0, 129)\t0.09376221343521611\n",
      "  (0, 124)\t0.11822136890276182\n",
      "  (0, 123)\t0.14450043862482975\n",
      "  (0, 122)\t0.15182389754744482\n",
      "  (0, 121)\t0.14283938993895107\n",
      "  (0, 120)\t0.14622418300337664\n",
      "  (0, 118)\t0.1339715460080298\n",
      "  (0, 117)\t0.13674050315925293\n",
      "  (0, 116)\t0.12432025568245994\n",
      "  (0, 115)\t0.1254208825527412\n",
      "  (0, 113)\t0.13968822298461267\n",
      "  (0, 112)\t0.11369551034435814\n",
      "  (0, 111)\t0.14988003802028688\n",
      "  (0, 109)\t0.14988003802028688\n",
      "  (0, 108)\t0.14283938993895107\n",
      "  (0, 106)\t0.15182389754744482\n",
      "  (0, 105)\t0.12219550956268574\n",
      "  (0, 104)\t0.09845081924372891\n",
      "  :\t:\n",
      "  (0, 76)\t0.12116908872812156\n",
      "  (0, 74)\t0.14622418300337664\n",
      "  (0, 73)\t0.15597892479998504\n",
      "  (0, 71)\t0.14622418300337664\n",
      "  (0, 70)\t0.10727459775402325\n",
      "  (0, 69)\t0.14801554220542956\n",
      "  (0, 66)\t0.1339715460080298\n",
      "  (0, 56)\t0.12116908872812156\n",
      "  (0, 53)\t0.14801554220542956\n",
      "  (0, 47)\t0.11456551388585157\n",
      "  (0, 44)\t0.10231287689050471\n",
      "  (0, 43)\t0.14622418300337664\n",
      "  (0, 42)\t0.12116908872812156\n",
      "  (0, 41)\t0.06380587073338964\n",
      "  (0, 35)\t0.13819058701307665\n",
      "  (0, 31)\t0.13968822298461267\n",
      "  (0, 28)\t0.130109488361254\n",
      "  (0, 26)\t0.08562093848359904\n",
      "  (0, 23)\t0.1353350444237197\n",
      "  (0, 22)\t0.1080295538670876\n",
      "  (0, 21)\t0.14622418300337664\n",
      "  (0, 20)\t0.15182389754744482\n",
      "  (0, 15)\t0.10231287689050471\n",
      "  (0, 9)\t0.1353350444237197\n",
      "  (0, 0)\t0.14801554220542956\n",
      "ecosiapluginreact easy use tool makes planting trees even easier boilerplate code making search extension ecosia forked kryptokinght ' reactextensionboilerplate allows developers easily create cool features like duckduckgo ' password generation feature info google ' timer feature react example plugin echos hello world search ecosia possibilities truly endless idea cool new features help reel new users ecosia new ecosia users trees planted installation clone repo git clone gitgithubcomnbennett320ecosiapluginreactgit sure seems work cd ecosiapluginreact install dependencies yarn yarn install usage open development window firefox yarn run startfirefox open development window chrome yarn run startchrome build files ' extension ' yarn run build compress build folder manifestnamezip crx npm run build npm run compress options info details found kryptokinght ' repo\n",
      "  (0, 140)\t0.179124774689805\n",
      "  (0, 129)\t0.1374447834957852\n",
      "  (0, 128)\t0.19638711012717294\n",
      "  (0, 125)\t0.2197071573003326\n",
      "  (0, 121)\t0.20938636477896325\n",
      "  (0, 107)\t0.2197071573003326\n",
      "  (0, 104)\t0.1443177484849637\n",
      "  (0, 82)\t0.18223941180977501\n",
      "  (0, 78)\t0.16297834215234908\n",
      "  (0, 64)\t0.17614861253977845\n",
      "  (0, 59)\t0.18385280612239938\n",
      "  (0, 58)\t0.15509245884058678\n",
      "  (0, 52)\t0.2047671109886571\n",
      "  (0, 50)\t0.20044608764290667\n",
      "  (0, 49)\t0.18550604133123116\n",
      "  (0, 46)\t0.2047671109886571\n",
      "  (0, 45)\t0.1540380650162925\n",
      "  (0, 43)\t0.21434808798144978\n",
      "  (0, 42)\t0.1776201580194689\n",
      "  (0, 34)\t0.20257174630685498\n",
      "  (0, 32)\t0.20938636477896325\n",
      "  (0, 29)\t0.20938636477896325\n",
      "  (0, 22)\t0.15835908836204296\n",
      "  (0, 15)\t0.14997908750055877\n",
      "  (0, 14)\t0.1907257711115779\n",
      "  (0, 10)\t0.19838584434723097\n",
      "  (0, 9)\t0.19838584434723097\n",
      "  (0, 2)\t0.22255663516639262\n",
      "environmentalimpacttools environmental impact tools provide analysis reporting tools scientists planners analysts understand potential impact development projects natural environment environmental impact tools leverage core arcgis platform help organizations analysis reporting workflows features github repository houses environmental analysis toolset used analyze data report results toolset includes following tools basic proximity analysis distance analysis feature comparison analysis analysis summary impact report requirements start using tools downloading repository zip file unzipping suitable location clone repository git tool requirements using tools include arcgis pro 131 information requirements use tools see environmental analysis help resources learn esri ' arcgis state government maps apps show list state government github repositories additional information sample data available tools issues find bug want request new feature please let us know submitting issue contributing esri welcomes contributions anyone everyone please see guidelines contributing licensing copyright 2016 esri licensed apache license version 20 license may use file except compliance license may obtain copy license httpwwwapacheorglicenseslicense20 unless required applicable law agreed writing software distributed license distributed basis without warranties conditions kind either express implied see license specific language governing permissions limitations license copy license available repository ' licensetxt file esri tags arcgissolutions stategovernment state government environmental analysis impact report esri language python\n",
      "  (0, 137)\t0.17325232989227785\n",
      "  (0, 136)\t0.15065357378901165\n",
      "  (0, 133)\t0.11286082831235388\n",
      "  (0, 130)\t0.13449232976615647\n",
      "  (0, 129)\t0.11755158064399167\n",
      "  (0, 126)\t0.17143433047824858\n",
      "  (0, 125)\t0.187907630704982\n",
      "  (0, 118)\t0.16796283297476164\n",
      "  (0, 117)\t0.17143433047824858\n",
      "  (0, 115)\t0.15724269350814715\n",
      "  (0, 103)\t0.18557007464577036\n",
      "  (0, 101)\t0.1811631182942934\n",
      "  (0, 100)\t0.17512994635666515\n",
      "  (0, 99)\t0.19034468665316714\n",
      "  (0, 98)\t0.13938951514542874\n",
      "  (0, 96)\t0.1404212939012371\n",
      "  (0, 92)\t0.17325232989227785\n",
      "  (0, 91)\t0.19289009111370947\n",
      "  (0, 78)\t0.13938951514542874\n",
      "  (0, 68)\t0.18557007464577036\n",
      "  (0, 66)\t0.16796283297476164\n",
      "  (0, 63)\t0.1601063987977067\n",
      "  (0, 56)\t0.15191213371924311\n",
      "  (0, 54)\t0.19555392823631768\n",
      "  (0, 52)\t0.17512994635666515\n",
      "  (0, 51)\t0.1833242114351287\n",
      "  (0, 49)\t0.15865664612993172\n",
      "  (0, 47)\t0.14363309857097326\n",
      "  (0, 44)\t0.12827172011060614\n",
      "  (0, 43)\t0.1833242114351287\n",
      "  (0, 41)\t0.07999470878808261\n",
      "  (0, 40)\t0.13938951514542874\n",
      "  (0, 34)\t0.17325232989227785\n",
      "  (0, 26)\t0.10734469981260894\n",
      "  (0, 21)\t0.1833242114351287\n",
      "  (0, 14)\t0.1631208933032927\n",
      "  (0, 7)\t0.15724269350814715\n",
      "  (0, 3)\t0.1833242114351287\n",
      "environmentalsetupitmo544444fall2015 environmental setup itmo544444fall2015\n",
      "  (0, 113)\t0.9096014894112426\n",
      "  (0, 41)\t0.41548180521034755\n",
      "noisecapture app noisecapture app android app dedicated measurement environmental noise description noisecapture app android app project measuring environmental noise using smartphone goal produce relevant noise indicators audio measurements including geospatial representation measurements shared community order produce participatory noise maps noisecapture app component global infrastructure ie spatial data infrastructure sdi called onomap sdi allows process represent geospatial information like noise maps full description whole onomap sdi including noisecapture app given wiki pages user guide use noisecapture app proposed within noisecapture app see ' help ' page menu noisecapture app features noisecapture app features divided 3 parts measurement sound level calibration done user start measurement order record second laeq average sound energy period 1s spectrum repartition sound analysed stored using fourrier transform device location recorded measuring sound level user hability provide feedback feeling noise environment extented report advanced statistics computed locally phone shown user user ' measurement locations noise levels displayed map share results community anonymous results transfered virtual hubs web server postprocessed order build noise map merge community results participative noise maps displayed within noisecapture app online httpsonomapnoiseplanetorg developments noisecapture app collaboration environmental acoustic research unit ifsttar labsticc cnrs need information project developped environmental acoustic research unit labsticc topic go httpwwwnoiseplanetorg funding application developed initial funding european project energicod help geopal program license noisecapture app released general public license version 3 please refer gplv3 details follow us follow developement noisecapture app twitter noiseplanet\n",
      "  (0, 139)\t0.16310620002187023\n",
      "  (0, 136)\t0.156271375109502\n",
      "  (0, 133)\t0.11706935582603056\n",
      "  (0, 131)\t0.16310620002187023\n",
      "  (0, 129)\t0.12193502411870406\n",
      "  (0, 118)\t0.17422608847642262\n",
      "  (0, 110)\t0.1676195692313106\n",
      "  (0, 103)\t0.1924898959561397\n",
      "  (0, 102)\t0.1974425510126682\n",
      "  (0, 95)\t0.2000828724153047\n",
      "  (0, 92)\t0.17971282826060703\n",
      "  (0, 90)\t0.13049059559724516\n",
      "  (0, 89)\t0.2000828724153047\n",
      "  (0, 88)\t0.1857584608893766\n",
      "  (0, 85)\t0.175999278401358\n",
      "  (0, 83)\t0.17782703649853104\n",
      "  (0, 76)\t0.1575768661510251\n",
      "  (0, 68)\t0.1924898959561397\n",
      "  (0, 64)\t0.156271375109502\n",
      "  (0, 63)\t0.1660766915425995\n",
      "  (0, 56)\t0.1575768661510251\n",
      "  (0, 55)\t0.2000828724153047\n",
      "  (0, 52)\t0.18166046016497175\n",
      "  (0, 43)\t0.19016028555654618\n",
      "  (0, 41)\t0.08297767407300378\n",
      "  (0, 40)\t0.14458728498621043\n",
      "  (0, 33)\t0.2000828724153047\n",
      "  (0, 32)\t0.1857584608893766\n",
      "  (0, 30)\t0.20284604277859605\n",
      "  (0, 26)\t0.1113475334738898\n",
      "  (0, 9)\t0.175999278401358\n",
      "  (0, 6)\t0.175999278401358\n",
      "  (0, 5)\t0.1676195692313106\n",
      "  (0, 2)\t0.1974425510126682\n",
      "atmos 6910 fall 2018 environmental programming atmospheric science university utah fall semester 2018 second half mwf 940am1030am wbb711 instructor email phone number office hours office location chris galli chrisgalliutahedu 8016472263 appointment 482 inscc sally benson sallybensonutahedu 8018591644 appointment 603 wbb copy syllabus found course description environmental scientists need ability acquire process display environmental data imagery gridded fields course designed develop skills necessary solve physicallybased problems relating atmospheric science data sets review basic programming concepts students develop code solve problems using programming languages data sources relevant ongoing future research course particularly relevant firstyear graduate students begin research leading towards thesis proposal assumed students exposure practical experience working common programming language used within physical sciences python matlab idl requirement using one language another however important student comfortable working language available moduleapi bindings common data libraries specifically netcdf4 hdf csv parsing course outcomes end course able write computer programs analyzing data acquire use data multiple file formats create custom ways display data check chpc ' intro python series ongoing class links october 15 lecture 1 introduction october 17 lecture 2 data types idl example file lecture02variablesdatatypespro homework assignment 1 october 19 lecture 3 basic programs arrays october 22 lecture 4 io part supplemental slides october 24 lecture 6 io netcdf hdf october 26 lecture 6 io part ii supplemental slides example06py october 29 lecture 7 final project review october 31 lecture 8 basic control structures november 2 lecture 9 arrays part homework assignment 2 november 5 lecture 10 code design arrays november 7 project reviews approach discussions questions homework assignment 3 november 9 lecture 11 arrays part ii november 12 lecture 12 optimization november 14 lecture 13 numerical applications november 16 lecture 14 intro debugging debug exercise\n",
      "  (0, 141)\t0.22963180845641476\n",
      "  (0, 133)\t0.1379211478108836\n",
      "  (0, 130)\t0.16435584223935504\n",
      "  (0, 129)\t0.14365346393287373\n",
      "  (0, 102)\t0.23261000344823943\n",
      "  (0, 96)\t0.17160131040636808\n",
      "  (0, 90)\t0.15373290983203766\n",
      "  (0, 88)\t0.21884480324226144\n",
      "  (0, 80)\t0.20525834392543724\n",
      "  (0, 76)\t0.18564364768768074\n",
      "  (0, 75)\t0.23572060532925104\n",
      "  (0, 68)\t0.22677520692708267\n",
      "  (0, 44)\t0.1567539697685763\n",
      "  (0, 42)\t0.18564364768768074\n",
      "  (0, 41)\t0.09775723091731067\n",
      "  (0, 39)\t0.23897593739641035\n",
      "  (0, 31)\t0.2140168876903927\n",
      "  (0, 30)\t0.23897593739641035\n",
      "  (0, 26)\t0.13118018386853522\n",
      "  (0, 22)\t0.16551251353353183\n",
      "  (0, 21)\t0.224030658296085\n",
      "  (0, 20)\t0.23261000344823943\n",
      "  (0, 15)\t0.1567539697685763\n",
      "  (0, 13)\t0.22963180845641476\n",
      "  (0, 12)\t0.224030658296085\n",
      "  (0, 7)\t0.19215783808973463\n",
      "environmentallogger log environmental data temperature pressure humidity ambient light using tessel 2 data streamed using socketio dygraphs bme280 pins 0 1 photoresistor pin 7 port\n",
      "  (0, 133)\t0.4363754894372357\n",
      "  (0, 122)\t0.7359662076036797\n",
      "  (0, 41)\t0.30929890132631294\n",
      "  (0, 26)\t0.41504742273890366\n",
      "elite dangerous immersion toolkit elite dangerous immersion toolkit edit application integrates elite dangerous commander log provides way external actions trigger events log started looks current game log list event methods provided actions based events log example get heatwarning event trigger environmental effects set timestamp20171105t211328z eventheatwarning also provides way create environmental schemes ambient light currently app ships star colours could extended include things like star system economy types currently implemented plugin philips hue light control features added play sounds trigger webhooks create streaming endpoints write another file better api endpoint behind token based authentication better docs create tool started experiment philips hue api integrating game events started experiment using light triggering certain events got working realised could add outputs app playing additional sound triggering webhook peripheral network service app built nodejs 8 uses asyncawait code achive well structured layout writing light recipies installing currently application alpha software yet available via npm binary require node 8 run installing node also need run npm install g windowsbuildtools install required build tools done clone repo git clone httpsgithubcomedittoolkitgit edit cd edit npm install npm start running go httplocalhost12342hubs click manage hubs find available hubs network select one want use client next go httplocalhost12342settings enter username associated hub docs soon also need enter location elite dangerous logs windows usually cusersusernamedocumentssave gamesfrontier developmentselite dangerous thanks millstonebarn name suggestion\n",
      "  (0, 141)\t0.17773296829654023\n",
      "  (0, 138)\t0.18244564268097463\n",
      "  (0, 137)\t0.16387121023515488\n",
      "  (0, 133)\t0.10674973626725119\n",
      "  (0, 132)\t0.17773296829654023\n",
      "  (0, 129)\t0.11118649773520257\n",
      "  (0, 126)\t0.1621516503056058\n",
      "  (0, 125)\t0.17773296829654023\n",
      "  (0, 118)\t0.15886812449340787\n",
      "  (0, 115)\t0.14872845001182353\n",
      "  (0, 112)\t0.13482409533921794\n",
      "  (0, 111)\t0.17773296829654023\n",
      "  (0, 105)\t0.14490369040435364\n",
      "  (0, 104)\t0.11674640977236517\n",
      "  (0, 100)\t0.16564715912177538\n",
      "  (0, 94)\t0.17552198423269702\n",
      "  (0, 93)\t0.17339772811112403\n",
      "  (0, 76)\t0.1436865248360889\n",
      "  (0, 68)\t0.17552198423269702\n",
      "  (0, 66)\t0.15886812449340787\n",
      "  (0, 64)\t0.1424961123374591\n",
      "  (0, 58)\t0.12546265405667217\n",
      "  (0, 54)\t0.1849652406189796\n",
      "  (0, 50)\t0.1621516503056058\n",
      "  (0, 49)\t0.15006584113084093\n",
      "  (0, 44)\t0.12132617221678692\n",
      "  (0, 43)\t0.17339772811112403\n",
      "  (0, 42)\t0.1436865248360889\n",
      "  (0, 41)\t0.07566322340174289\n",
      "  (0, 25)\t0.16748332100889968\n",
      "  (0, 22)\t0.12810520684515445\n",
      "  (0, 20)\t0.18003806461408003\n",
      "  (0, 15)\t0.12132617221678692\n",
      "  (0, 14)\t0.15428836204898613\n",
      "  (0, 10)\t0.16048500839528812\n",
      "  (0, 9)\t0.16048500839528812\n",
      "  (0, 8)\t0.15143709382543755\n",
      "  (0, 7)\t0.14872845001182353\n",
      "  (0, 6)\t0.16048500839528812\n",
      "  (0, 5)\t0.1528439674278454\n",
      "  (0, 4)\t0.15886812449340787\n",
      "  (0, 1)\t0.14742328834235863\n",
      "environmentalissues\n",
      "\n",
      "httpenvironmentalcomputingnet\n",
      "\n",
      "environmentalissues\n",
      "\n",
      "environmentalproject\n",
      "\n",
      "esc50 dataset environmental sound classification overview download results repository content license citing caveats changelog esc50 dataset labeled collection 2000 environmental audio recordings suitable benchmarking methods environmental sound classification dataset consists 5secondlong recordings organized 50 semantical classes 40 examples per class loosely arranged 5 major categories animals natural soundscapes water sounds human nonspeech sounds interiordomestic sounds exteriorurban noises dog rain crying baby door knock helicopter rooster sea waves sneezing mouse click chainsaw pig crackling fire clapping keyboard typing siren cow crickets breathing door wood creaks car horn frog chirping birds coughing opening engine cat water drops footsteps washing machine train hen wind laughing vacuum cleaner church bells insects flying pouring water brushing teeth clock alarm airplane sheep toilet flush snoring clock tick fireworks crow thunderstorm drinking sipping glass breaking hand saw clips dataset manually extracted public field recordings gathered freesoundorg project dataset prearranged 5 folds comparable crossvalidation making sure fragments original source file contained single fold thorough description dataset available original paper supplementary materials github esc dataset environmental sound classification paper replication data download dataset downloaded single zip file 600 mb download esc50 dataset results numerous machine learning signal processing approaches evaluated esc50 dataset listed know reference message open pull request directly terms used table cnn convolutional neural network crnn convolutional recurrent neural network gmm gaussian mixture model gtcc gammatone cepstral coefficients gtsc gammatone spectral coefficients knn kneareast neighbors mfcc melfrequency cepstral coefficients mlp multilayer perceptron rbm restricted boltzmann machine rnn recurrent neural network svm support vector machine teo teager energy operator zcr zerocrossing rate title notes accuracy paper code unsupervised filterbank learning using convolutional restricted boltzmann machine environmental sound classification cnn filterbanks learned using convolutional rbm fusion gtsc mel energies 8650 sailor2017 learning betweenclass examples deep sound recognition envnetv2 tokozume2017a data augmentation betweenclass learning 8490 tokozume2017b novel phase encoded mel filterbank energies environmental sound classification cnn working phase encoded mel filterbank energies pefbes fusion mel energies 8415 tak2017 knowledge transfer weakly labeled audio using convolutional neural network sound events scenes cnn pretrained audioset 8350 kumar2017 unsupervised filterbank learning using convolutional restricted boltzmann machine environmental sound classification cnn filterbanks learned using convolutional rbm fusion gtsc 8300 sailor2017 deep multimodal clustering unsupervised audiovisual learning cnn unsupervised audiovisual learning 8260 hu2019 novel teobased gammatone features environmental sound classification fusion gtsc teogtsc cnn 8195 agrawal2017 learning betweenclass examples deep sound recognition envnetv2 tokozume2017a betweenclass learning 8180 tokozume2017b human accuracy crowdsourcing experiment classifying esc50 human listeners 8130 piczak2015a objects sound look listen learn l3 network arandjelovic2017a stride 2 larger batches learning rate schedule 7980 arandjelovic2017b look listen learn 8layer convolutional subnetwork pretrained audiovisual correspondence task 7930 arandjelovic2017a learning environmental sounds multiscale convolutional neural network multiscale convolutions feature fusion waveform spectrogram 7910 zhu2018 novel teobased gammatone features environmental sound classification gtsc cnn 7910 agrawal2017 learning betweenclass examples deep sound recognition envnetv2 tokozume2017a data augmentation 7880 tokozume2017b unsupervised filterbank learning using convolutional restricted boltzmann machine environmental sound classification cnn filterbanks learned using convolutional rbm 7845 sailor2017 learning betweenclass examples deep sound recognition baseline cnn piczak2015b batch normalization betweenclass learning 7690 tokozume2017b novel teobased gammatone features environmental sound classification teogtsc cnn 7485 agrawal2017 learning betweenclass examples deep sound recognition envnetv2 tokozume2017a 7440 tokozume2017b soundnet learning sound representations unlabeled video 8layer cnn raw audio transfer learning unlabeled videos 7420 aytar2016 learning betweenclass examples deep sound recognition 18layer cnn raw waveforms dai2016 betweenclass learning 7330 tokozume2017b novel phase encoded mel filterbank energies environmental sound classification cnn working phase encoded mel filterbank energies pefbes 7325 tak2017 classifying environmental sounds using image recognition networks 16 khz sampling rate googlenet spectrograms 40 ms frame length 7320 boddapati2017 learning betweenclass examples deep sound recognition baseline cnn piczak2015b batch normalization 7240 tokozume2017b novel teobased gammatone features environmental sound classification fusion mfcc teogtcc gmm 7225 agrawal2017 learning environmental sounds endtoend convolutional neural network envnet combination spectrogram raw waveform cnn 7100 tokozume2017a novel teobased gammatone features environmental sound classification teogtcc gmm 6885 agrawal2017 classifying environmental sounds using image recognition networks 16 khz sampling rate alexnet spectrograms 30 ms frame length 6870 boddapati2017 deep convolutional neural networks raw waveforms 18layer cnn raw waveforms 6850 dai2016 tokozume2017b classifying environmental sounds using image recognition networks 32 khz sampling rate googlenet spectrograms 30 ms frame length 6780 boddapati2017 wsnet learning compact efficient networks weight sampling soundnet 8layer cnn architecture 100x model compression 6625 jin2017 soundnet learning sound representations unlabeled video 5layer cnn raw audio transfer learning unlabeled videos 6610 aytar2016 wsnet learning compact efficient networks weight sampling soundnet 8layer cnn architecture 180x model compression 6580 jin2017 soundnet learning sound representations unlabeled video 5layer cnn trained raw audio esc50 6500 aytar2016 environmental sound classification convolutional neural networks cnn baseline cnn 2 convolutional 2 fullyconnected layers melspectrograms input vertical filters first layer 6450 piczak2015b audeep unsupervised learning representations audio deep recurrent neural networks mlp classifier features extracted rnn autoencoder 6430 freitag2017 classifying environmental sounds using image recognition networks 32 khz sampling rate alexnet spectrograms 30 ms frame length 6320 boddapati2017 classifying environmental sounds using image recognition networks crnn 6030 boddapati2017 comparison timefrequency representations environmental sound classification using convolutional neural networks 3layer cnn vertical filters wideband melstft median accuracy 5637 huzaifah2017 comparison timefrequency representations environmental sound classification using convolutional neural networks 3layer cnn square filters wideband melstft median accuracy 5400 huzaifah2017 soundnet learning sound representations unlabeled video 8layer cnn trained raw audio esc50 5110 aytar2016 comparison timefrequency representations environmental sound classification using convolutional neural networks 5layer cnn square filters wideband melstft median accuracy 5087 huzaifah2017 comparison timefrequency representations environmental sound classification using convolutional neural networks 5layer cnn vertical filters wideband melstft median accuracy 4625 huzaifah2017 baseline random forest baseline ml approach mfcc zcr random forest 4430 piczak2015a soundnet learning sound representations unlabeled video convolutional autoencoder trained unlabeled videos 3990 aytar2016 baseline svm baseline ml approach mfcc zcr svm 3960 piczak2015a baseline knn baseline ml approach mfcc zcr knn 3220 piczak2015a mixture modelbased realtime audio sources classification method dictionary sound models used classification accuracy computed segments instead files 9400 baelde2017 nels neverending learner sounds largescale audio crawling classifiers trained aed datasets including esc50 na elizalde2017 utilizing domain knowledge endtoend audio processing endtoend cnn learned melspectrogram transformation na tax2017 deep neural network based learning transferring midlevel audio features acoustic scene classification transfer learning various datasets including esc50 na mun2017 features kernels audio event recognition mfcc gmm svm na kumar2016b realtime environmental sound recognition system android os realtime sound recognition android evaluated esc10 na pillos2016 comparing time frequency domain audio event recognition using deep learning discriminatory effectiveness different signal representations compared esc10 freiburg106 na hertel2016 audio event scene recognition unified approach using strongly weakly labeled data combination weakly labeled data youtube strong labeling esc10 acoustic event detection na kumar2016a repository content audiowav 2000 audio recordings wav format 5 seconds 441 khz mono following naming convention foldclipidtaketargetwav fold index crossvalidation fold clipid id original freesound clip take letter disambiguating different fragments freesound clip target class numeric format 0 49 metaesc50csv csv file following structure filename fold target category esc10 srcfile take esc10 column indicates given file belongs esc10 subset 10 selected classes cc license metaesc50humanxlsx additional data pertaining crowdsourcing experiment human classification accuracy license dataset available terms creative commons attribution noncommercial license smaller subset clips tagged esc10 distributed cc attribution attributions clip available license file citing find dataset useful academic setting please cite k j piczak esc dataset environmental sound classification proceedings 23rd annual acm conference multimedia brisbane australia 2015 doi httpdxdoiorg10114527333732806390 inproceedingspiczak2015dataset title esc dataset environmental sound classification author piczak karol j booktitle proceedings 23rd annual acm conference multimedia date 20151013 url httpdlacmorgcitationcfmdoid27333732806390 doi 10114527333732806390 location brisbane australia isbn 9781450334594 publisher acm press pages 10151018 caveats please aware potential information leakage training models esc50 original freesound recordings already preprocessed manner might class dependent mostly bandlimiting unfortunately issue went unnoticed creating original version dataset due number methods already evaluated esc50 changes rectifying issue made order preserve comparability changelog v200 20171213 change wav version default v200pre 20161010 wavfiles branch replace ogg recordings cropped wav files easier loading framelevel precision ogg recordings slightly different length loaded move recordings one directory structure meta csv file v100 20150415 initial version dataset ogg format\n",
      "  (0, 141)\t0.17555646328219449\n",
      "  (0, 136)\t0.14075111530061338\n",
      "  (0, 133)\t0.10544248675416082\n",
      "  (0, 130)\t0.12565214974903646\n",
      "  (0, 124)\t0.13847424702507258\n",
      "  (0, 121)\t0.16730965942025136\n",
      "  (0, 120)\t0.17127431213305774\n",
      "  (0, 116)\t0.14561795346620257\n",
      "  (0, 103)\t0.1733725547685304\n",
      "  (0, 99)\t0.17783333155773534\n",
      "  (0, 98)\t0.13022744316312942\n",
      "  (0, 95)\t0.18021142659857545\n",
      "  (0, 90)\t0.11753078165264567\n",
      "  (0, 83)\t0.1601659529791213\n",
      "  (0, 82)\t0.14561795346620257\n",
      "  (0, 80)\t0.1569226369854139\n",
      "  (0, 72)\t0.17127431213305774\n",
      "  (0, 69)\t0.1733725547685304\n",
      "  (0, 68)\t0.1733725547685304\n",
      "  (0, 63)\t0.14958260617900898\n",
      "  (0, 57)\t0.1733725547685304\n",
      "  (0, 56)\t0.1419269500942893\n",
      "  (0, 55)\t0.18021142659857545\n",
      "  (0, 53)\t0.1733725547685304\n",
      "  (0, 51)\t0.17127431213305774\n",
      "  (0, 47)\t0.1341920958759358\n",
      "  (0, 45)\t0.12308373672199938\n",
      "  (0, 44)\t0.11984042072829194\n",
      "  (0, 43)\t0.17127431213305774\n",
      "  (0, 41)\t0.0747366570662238\n",
      "  (0, 38)\t0.16543233243042194\n",
      "  (0, 36)\t0.15097225130951578\n",
      "  (0, 35)\t0.1618644553027293\n",
      "  (0, 30)\t0.18270016972332453\n",
      "  (0, 28)\t0.15239895797908656\n",
      "  (0, 26)\t0.10028893334713751\n",
      "  (0, 24)\t0.18021142659857545\n",
      "  (0, 15)\t0.11984042072829194\n",
      "  (0, 13)\t0.17555646328219449\n",
      "  (0, 11)\t0.16543233243042194\n",
      "  (0, 8)\t0.14958260617900898\n",
      "  (0, 7)\t0.14690713222070606\n",
      "image dehazing via joint estimation transmittance map environmental illumination input transmittance map dehazed image haze limits visibility outdoor images due existence fog smoke dust atmosphere work present end end system takes hazy image input returns dehazed image proposed method learns mapping hazy image corresponding transmittance map environmental illumination using multiscale convolutional neural network repository contains python implementation authors sanchayan santra ranjan mondal pranoy panda nishant mohanty shubham bhuyan paper httpsarxivorgabs181201273 conference 9th international conference advances pattern recognition icapr 2017 requirements python 27 35 tensorflow requirements numpy pip work scikitimage keras scipy matplolib folders files important using proposed dehazing network new project finalcodepy networkpy weightsh5 important retraining proposed dehazing network new data preprocesspy helperfunctionspy running program python srcfinalassemblyfinalcodepy pathtohazzyimage example running mountain image python srcfinalassemblyfinalcodepy resultsmountaininputpng license citation software released lgpl please cite paper publications helps research inproceedingssantra2017image titleimage dehazing via joint estimation transmittance map environmental illumination authorsantra sanchayan mondal ranjan panda pranoy mohanty nishant bhuyan shubham booktitle2017 ninth international conference advances pattern recognition icapr pages16 year2017 organizationieee\n",
      "  (0, 140)\t0.21291491777527033\n",
      "  (0, 133)\t0.15685322614247718\n",
      "  (0, 115)\t0.21853484626061248\n",
      "  (0, 105)\t0.21291491777527033\n",
      "  (0, 102)\t0.2645397754657458\n",
      "  (0, 101)\t0.2517792930231463\n",
      "  (0, 98)\t0.19372261809461627\n",
      "  (0, 96)\t0.1951565773250581\n",
      "  (0, 90)\t0.17483542773650565\n",
      "  (0, 89)\t0.2680773616011987\n",
      "  (0, 86)\t0.25790405155570945\n",
      "  (0, 78)\t0.19372261809461627\n",
      "  (0, 63)\t0.22251480476442154\n",
      "  (0, 57)\t0.25790405155570945\n",
      "  (0, 53)\t0.25790405155570945\n",
      "  (0, 45)\t0.18309584480427724\n",
      "  (0, 42)\t0.21112646983331101\n",
      "  (0, 41)\t0.11117611252163097\n",
      "  (0, 39)\t0.2717795446601676\n",
      "  (0, 26)\t0.14918694755902692\n",
      "  (0, 19)\t0.22888481028352325\n",
      "softwareengineering progetto\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show sentences and vector space representation.\n",
    "# \n",
    "# (A, B) C\n",
    "# A : Document Index\n",
    "# B : Specific word-vector index\n",
    "# C : TF-IDF score\n",
    "for i, v in zip(X_train.clean, vector_spaces):\n",
    "    print(i)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = tfidf_sparse_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train, y_train):\n",
    "    '''\n",
    "    This function takes in X_train (features using for model) and y_train (target 'win') and performs logistic\n",
    "    regression giving us accuracy of the model and the classification report\n",
    "    '''\n",
    "    # Calling out funtion\n",
    "    logit = LogisticRegression()\n",
    "\n",
    "    # Fit the training data set\n",
    "    logit = logit.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = logit.predict(X_train)\n",
    "\n",
    "    #Accuracy of model\n",
    "    score = logit.score(X_train, y_train)\n",
    "\n",
    "    print(f'The logistic regression models accuracy is {round(score * 100,2)}%\\n')     \n",
    "    print(f'Confusion Matrix\\n\\n {confusion_matrix(y_train, y_pred)}\\n') \n",
    "    \n",
    "    # Coefficients for each feature  \n",
    "    coef_df = pd.DataFrame(logit.coef_)\n",
    "\n",
    "    print(f'Classification Report\\n {classification_report(y_train, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language  \n",
       "Python        83\n",
       "JavaScript    62\n",
       "HTML          49\n",
       "Java          40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Python        83\n",
       "JavaScript    62\n",
       "HTML          49\n",
       "Java          40\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_exp.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language  \n",
       "Python        83\n",
       "JavaScript    62\n",
       "HTML          49\n",
       "Java          40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting baseline\n",
    "baseline = len(train_exp[train_exp.language == 'Python']) / len(train_exp)\n",
    "round(baseline,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<234x142 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4862 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y_train\n",
    "\n",
    "X_bow\n",
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lm = LogisticRegression().fit(X_bow, y)\n",
    "\n",
    "X_train['predicted'] = lm.predict(X_bow)\n",
    "# test['predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41,  2,  5,  1],\n",
       "       [12, 26,  0,  2],\n",
       "       [ 8,  1, 50,  3],\n",
       "       [ 4,  3,  1, 75]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "confusion_matrix(y.language, X_train.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41,  2,  5,  1],\n",
       "       [12, 26,  0,  2],\n",
       "       [ 8,  1, 50,  3],\n",
       "       [ 4,  3,  1, 75]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y.language, X_train.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>language</th>\n",
       "      <th>HTML</th>\n",
       "      <th>Java</th>\n",
       "      <th>JavaScript</th>\n",
       "      <th>Python</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HTML</th>\n",
       "      <td>41</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Java</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JavaScript</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "language    HTML  Java  JavaScript  Python\n",
       "predicted                                 \n",
       "HTML          41    12           8       4\n",
       "Java           2    26           1       3\n",
       "JavaScript     5     0          50       1\n",
       "Python         1     2           3      75"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(X_train.predicted, y_train.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        HTML       0.63      0.84      0.72        49\n",
      "        Java       0.81      0.65      0.72        40\n",
      "  JavaScript       0.89      0.81      0.85        62\n",
      "      Python       0.93      0.90      0.91        83\n",
      "\n",
      "    accuracy                           0.82       234\n",
      "   macro avg       0.82      0.80      0.80       234\n",
      "weighted avg       0.84      0.82      0.82       234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y.language, X_train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "lm_tfidf = LogisticRegression().fit(X_tfidf, y)\n",
    "X_train['pred_tfidf'] = lm_tfidf.predict(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred_tfidf</th>\n",
       "      <th>HTML</th>\n",
       "      <th>Java</th>\n",
       "      <th>JavaScript</th>\n",
       "      <th>Python</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HTML</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Java</th>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JavaScript</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred_tfidf  HTML  Java  JavaScript  Python\n",
       "language                                  \n",
       "HTML          30     0           4      15\n",
       "Java          13    11           2      14\n",
       "JavaScript     8     1          39      14\n",
       "Python         4     0           2      77"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y.language, X_train.pred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        HTML       0.55      0.61      0.58        49\n",
      "        Java       0.92      0.28      0.42        40\n",
      "  JavaScript       0.83      0.63      0.72        62\n",
      "      Python       0.64      0.93      0.76        83\n",
      "\n",
      "    accuracy                           0.67       234\n",
      "   macro avg       0.73      0.61      0.62       234\n",
      "weighted avg       0.72      0.67      0.65       234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y.language, X_train.pred_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decesion Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decesion_tree(X_train, y_train, k):\n",
    "    '''\n",
    "    This function requires X_train, y_train and k (max_depth). A confusion matrix, models accuracy and \n",
    "    classification report are outputed\n",
    "    '''\n",
    "    # Creating the decision tree object\n",
    "    clf = DecisionTreeClassifier(max_depth=k, random_state=123)\n",
    "\n",
    "    # Fitting the data to the trained data\n",
    "    clf.fit(X_bow, y)\n",
    "\n",
    "   # Array of the predicitons\n",
    "    X_train['predicted'] = clf.predict(X_bow)\n",
    "\n",
    "    # Crosstab confusion matrix\n",
    "    pd.crosstab(y.language, X_train.predicted)\n",
    "    \n",
    "    # Classification report\n",
    "    print(classification_report(y.language, X_train.predicted))\n",
    "                                       \n",
    "    clf_tfidf = clf.fit(X_tfidf, y)\n",
    "    X_train['pred_tfidf'] = clf_tfidf.predict(X_tfidf)\n",
    "                                       \n",
    "    # Confusion matrix\n",
    "    # Confusion matrix\n",
    "    print('Accuracy: {:.2%}'.format(accuracy_score(y_train.language, X_train.pred_tfidf)))\n",
    "    print(f'Confusion Matrix: \\n\\n {pd.crosstab(y.language, X_train.pred_tfidf)}\\n' )\n",
    "    print(\"K-Nearest Neighbor Classification Report:\\n\", classification_report(y.language, X_train.pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        HTML       0.26      0.67      0.38        49\n",
      "        Java       0.75      0.07      0.14        40\n",
      "  JavaScript       0.78      0.34      0.47        62\n",
      "      Python       0.66      0.60      0.63        83\n",
      "\n",
      "    accuracy                           0.46       234\n",
      "   macro avg       0.61      0.42      0.40       234\n",
      "weighted avg       0.62      0.46      0.45       234\n",
      "\n",
      "Accuracy: 48.29%\n",
      "Confusion Matrix: \n",
      "\n",
      " pred_tfidf  HTML  Java  JavaScript  Python\n",
      "language                                  \n",
      "HTML          46     0           0       3\n",
      "Java          35     3           1       1\n",
      "JavaScript    37     0          22       3\n",
      "Python        38     0           3      42\n",
      "\n",
      "K-Nearest Neighbor Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        HTML       0.29      0.94      0.45        49\n",
      "        Java       1.00      0.07      0.14        40\n",
      "  JavaScript       0.85      0.35      0.50        62\n",
      "      Python       0.86      0.51      0.64        83\n",
      "\n",
      "    accuracy                           0.48       234\n",
      "   macro avg       0.75      0.47      0.43       234\n",
      "weighted avg       0.76      0.48      0.48       234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decesion_tree(X_train, y_train, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for classification you can change the algorithm to gini or entropy (information gain).  Default is gini.\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, random_state=123)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the data to the trained data\n",
    "clf.fit(X_bow, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of the predicitons\n",
    "X_train['predicted'] = clf.predict(X_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>HTML</th>\n",
       "      <th>Java</th>\n",
       "      <th>JavaScript</th>\n",
       "      <th>Python</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HTML</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Java</th>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JavaScript</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted   HTML  Java  JavaScript  Python\n",
       "language                                  \n",
       "HTML          41     2           5       1\n",
       "Java          12    26           0       2\n",
       "JavaScript     8     1          50       3\n",
       "Python         4     3           1      75"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crosstab confusion matrix\n",
    "pd.crosstab(y.language, X_train.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        HTML       0.63      0.84      0.72        49\n",
      "        Java       0.81      0.65      0.72        40\n",
      "  JavaScript       0.89      0.81      0.85        62\n",
      "      Python       0.93      0.90      0.91        83\n",
      "\n",
      "    accuracy                           0.82       234\n",
      "   macro avg       0.82      0.80      0.80       234\n",
      "weighted avg       0.84      0.82      0.82       234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y.language, X_train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tfidf = clf.fit(X_tfidf, y)\n",
    "X_train['pred_tfidf'] = clf_tfidf.predict(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred_tfidf</th>\n",
       "      <th>HTML</th>\n",
       "      <th>Java</th>\n",
       "      <th>JavaScript</th>\n",
       "      <th>Python</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HTML</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Java</th>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JavaScript</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred_tfidf  HTML  Java  JavaScript  Python\n",
       "language                                  \n",
       "HTML          46     0           0       3\n",
       "Java          35     3           1       1\n",
       "JavaScript    37     0          22       3\n",
       "Python        38     0           3      42"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y.language, X_train.pred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        HTML       0.29      0.94      0.45        49\n",
      "        Java       1.00      0.07      0.14        40\n",
      "  JavaScript       0.85      0.35      0.50        62\n",
      "      Python       0.86      0.51      0.64        83\n",
      "\n",
      "    accuracy                           0.48       234\n",
      "   macro avg       0.75      0.47      0.43       234\n",
      "weighted avg       0.76      0.48      0.48       234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y.language, X_train.pred_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train, y_train, k):\n",
    "    # Random forest object\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=k, random_state=123)\n",
    "\n",
    "    # Fitting the data to the trained data\n",
    "    rf.fit(X_bow, y)\n",
    "\n",
    "    # Array of the predicitons\n",
    "    X_train['predicted'] = rf.predict(X_bow)\n",
    "\n",
    "    # Crosstab confusion matrix\n",
    "    pd.crosstab(y.language, X_train.predicted)\n",
    "    \n",
    "    rf_tfidf = rf.fit(X_tfidf, y)\n",
    "    X_train['pred_tfidf'] = rf_tfidf.predict(X_tfidf)\n",
    "\n",
    "   # Confusion matrix\n",
    "    print('Accuracy: {:.2%}'.format(accuracy_score(y_train.language, X_train.pred_tfidf)))\n",
    "    print(f'Confusion Matrix: \\n\\n {pd.crosstab(y.language, X_train.pred_tfidf)}\\n' )\n",
    "    print(\"K-Nearest Neighbor Classification Report:\\n\", classification_report(y.language, X_train.pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.39%\n",
      "Confusion Matrix: \n",
      "\n",
      " pred_tfidf  HTML  Java  JavaScript  Python\n",
      "language                                  \n",
      "HTML          16     0          17      16\n",
      "Java           0     3          16      21\n",
      "JavaScript     0     0          47      15\n",
      "Python         0     0           3      80\n",
      "\n",
      "K-Nearest Neighbor Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        HTML       1.00      0.33      0.49        49\n",
      "        Java       1.00      0.07      0.14        40\n",
      "  JavaScript       0.57      0.76      0.65        62\n",
      "      Python       0.61      0.96      0.74        83\n",
      "\n",
      "    accuracy                           0.62       234\n",
      "   macro avg       0.79      0.53      0.51       234\n",
      "weighted avg       0.75      0.62      0.56       234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K =4\n",
    "random_forest(X_train, y_train, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest object\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=3, random_state=123)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the data to the trained data\n",
    "rf.fit(X_bow, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of the predicitons\n",
    "X_train['predicted'] = rf.predict(X_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>HTML</th>\n",
       "      <th>JavaScript</th>\n",
       "      <th>Python</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HTML</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Java</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JavaScript</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted   HTML  JavaScript  Python\n",
       "language                            \n",
       "HTML           1           3      45\n",
       "Java           0           4      36\n",
       "JavaScript     0          26      36\n",
       "Python         0           3      80"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crosstab confusion matrix\n",
    "pd.crosstab(y.language, X_train.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        HTML       1.00      0.02      0.04        49\n",
      "        Java       0.00      0.00      0.00        40\n",
      "  JavaScript       0.72      0.42      0.53        62\n",
      "      Python       0.41      0.96      0.57        83\n",
      "\n",
      "    accuracy                           0.46       234\n",
      "   macro avg       0.53      0.35      0.29       234\n",
      "weighted avg       0.54      0.46      0.35       234\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y.language, X_train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "rf_tfidf = rf.fit(X_tfidf, y)\n",
    "X_train['pred_tfidf'] = rf_tfidf.predict(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred_tfidf</th>\n",
       "      <th>HTML</th>\n",
       "      <th>Java</th>\n",
       "      <th>JavaScript</th>\n",
       "      <th>Python</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HTML</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Java</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JavaScript</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred_tfidf  HTML  Java  JavaScript  Python\n",
       "language                                  \n",
       "HTML          11     0           2      36\n",
       "Java           0     1           3      36\n",
       "JavaScript     0     0          29      33\n",
       "Python         0     0           1      82"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y.language, X_train.pred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        HTML       1.00      0.22      0.37        49\n",
      "        Java       1.00      0.03      0.05        40\n",
      "  JavaScript       0.83      0.47      0.60        62\n",
      "      Python       0.44      0.99      0.61        83\n",
      "\n",
      "    accuracy                           0.53       234\n",
      "   macro avg       0.82      0.43      0.41       234\n",
      "weighted avg       0.76      0.53      0.46       234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y.language, X_train.pred_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(X_train, y, k):\n",
    "    # KNN object\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights='uniform')\n",
    "\n",
    "    # Fit the model\n",
    "    knn.fit(X_bow, y)\n",
    "\n",
    "    # Make predictions\n",
    "    X_train['predicted'] = knn.predict(X_bow)\n",
    "    \n",
    "    # Crosstab confusion matrix of predicted\n",
    "    pd.crosstab(y.language, X_train.predicted)\n",
    "    \n",
    "    # Predicted Classification report\n",
    "    print(classification_report(y.language, X_train.predicted))\n",
    "    \n",
    "    knn_tfidf = knn.fit(X_tfidf, y)\n",
    "    X_train['pred_tfidf'] = knn_tfidf.predict(X_tfidf)\n",
    "\n",
    "    # Confusion matrix\n",
    "    print('Accuracy: {:.2%}'.format(accuracy_score(y_train.language, X_train.pred_tfidf)))\n",
    "    print(f'Confusion Matrix: \\n\\n {pd.crosstab(y.language, X_train.pred_tfidf)}\\n' )\n",
    "    print(\"K-Nearest Neighbor Classification Report:\\n\", classification_report(y.language, X_train.pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        HTML       0.39      0.59      0.47        49\n",
      "        Java       0.31      0.50      0.38        40\n",
      "  JavaScript       0.54      0.40      0.46        62\n",
      "      Python       0.76      0.45      0.56        83\n",
      "\n",
      "    accuracy                           0.47       234\n",
      "   macro avg       0.50      0.49      0.47       234\n",
      "weighted avg       0.55      0.47      0.49       234\n",
      "\n",
      "Accuracy: 33.76%\n",
      "Confusion Matrix: \n",
      "\n",
      " pred_tfidf  HTML  Java  JavaScript  Python\n",
      "language                                  \n",
      "HTML          35    13           1       0\n",
      "Java          12    25           2       1\n",
      "JavaScript    19    36           5       2\n",
      "Python        16    49           4      14\n",
      "\n",
      "K-Nearest Neighbor Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        HTML       0.43      0.71      0.53        49\n",
      "        Java       0.20      0.62      0.31        40\n",
      "  JavaScript       0.42      0.08      0.14        62\n",
      "      Python       0.82      0.17      0.28        83\n",
      "\n",
      "    accuracy                           0.34       234\n",
      "   macro avg       0.47      0.40      0.31       234\n",
      "weighted avg       0.53      0.34      0.30       234\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "knn(X_train, y, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    " # KNN object\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the data to the trained data\n",
    "knn.fit(X_bow, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of the predicitons\n",
    "X_train['predicted'] = knn.predict(X_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>HTML</th>\n",
       "      <th>Java</th>\n",
       "      <th>JavaScript</th>\n",
       "      <th>Python</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HTML</th>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Java</th>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JavaScript</th>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted   HTML  Java  JavaScript  Python\n",
       "language                                  \n",
       "HTML          29    11           4       5\n",
       "Java          15    20           5       0\n",
       "JavaScript    14    16          25       7\n",
       "Python        16    18          12      37"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crosstab confusion matrix\n",
    "pd.crosstab(y.language, X_train.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        HTML       0.39      0.59      0.47        49\n",
      "        Java       0.31      0.50      0.38        40\n",
      "  JavaScript       0.54      0.40      0.46        62\n",
      "      Python       0.76      0.45      0.56        83\n",
      "\n",
      "    accuracy                           0.47       234\n",
      "   macro avg       0.50      0.49      0.47       234\n",
      "weighted avg       0.55      0.47      0.49       234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y.language, X_train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "knn_tfidf = knn.fit(X_tfidf, y)\n",
    "X_train['pred_tfidf'] = knn_tfidf.predict(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "\n",
      " pred_tfidf  HTML  Java  JavaScript  Python\n",
      "language                                  \n",
      "HTML          35    13           1       0\n",
      "Java          12    25           2       1\n",
      "JavaScript    19    36           5       2\n",
      "Python        16    49           4      14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Confusion Matrix: \\n\\n {pd.crosstab(y.language, X_train.pred_tfidf)}\\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        HTML       0.43      0.71      0.53        49\n",
      "        Java       0.20      0.62      0.31        40\n",
      "  JavaScript       0.42      0.08      0.14        62\n",
      "      Python       0.82      0.17      0.28        83\n",
      "\n",
      "    accuracy                           0.34       234\n",
      "   macro avg       0.47      0.40      0.31       234\n",
      "weighted avg       0.53      0.34      0.30       234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y.language, X_train.pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 33.76%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(y_train.language, X_train.pred_tfidf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
